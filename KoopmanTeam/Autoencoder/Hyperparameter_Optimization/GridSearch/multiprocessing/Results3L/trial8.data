2021-06-26
loss,6.085267543792725,2.997830390930176,2.9557502269744873,2.2888965606689453,2.2399797439575195,1.8653925657272339,1.9443106651306152,1.5541713237762451,1.2662267684936523,1.1126585006713867,1.0661723613739014,1.0043386220932007,1.055677890777588,1.3107693195343018,0.8652345538139343,0.7605013251304626,0.7435376644134521,1.0082058906555176,1.0949329137802124,0.7636760473251343,1.3953752517700195,1.0400372743606567,0.9417277574539185,0.8588027358055115,0.8591330647468567,0.6736811995506287,1.0670359134674072,0.7469419836997986,0.912417471408844,0.746417760848999,0.9123319387435913,0.9543807506561279,0.8698036074638367,0.6731417775154114,0.6071258783340454,0.6540428996086121,0.5583747029304504,0.798052966594696,0.7276229858398438,0.7986787557601929,0.794097363948822,0.631004273891449,0.5601963996887207,0.6807371377944946,0.6160691976547241,0.4692572057247162,0.47511160373687744,0.744362473487854,0.8190520405769348,0.6072682738304138,0.8052834272384644,0.6405888199806213,0.7494860291481018,0.6058294773101807,0.8236342072486877,0.6017293334007263,0.6601182818412781,0.7185310125350952,0.6306849122047424,0.6447252631187439,0.5845367908477783,0.6729167103767395,0.5875426530838013,0.6773979663848877,0.6177259683609009,0.5211188197135925,0.5518823862075806,0.6763718128204346,0.5427002906799316,0.6637220978736877,0.5490051507949829,0.5020014047622681,0.5114957690238953,0.4729221761226654,0.5292632579803467,0.5813266634941101,0.969624936580658,0.7862857580184937,0.6597685813903809,0.5447443127632141,0.5826950669288635,0.4924356937408447,0.4795217216014862,0.5201922655105591,0.6232042908668518,0.4915201961994171,0.7812817096710205,0.4447835683822632,0.588006854057312,0.6401206254959106,0.4435925781726837,0.4376299977302551,0.4631219506263733,0.636328935623169,0.5102270841598511,0.5354728102684021,0.5670092105865479,0.43940502405166626,0.41931456327438354,0.5178415179252625,
mse,0.42452090978622437,0.4303429424762726,0.4428553283214569,0.40639954805374146,0.3767468333244324,0.35917776823043823,0.35166749358177185,0.3429058790206909,0.35767653584480286,0.34855833649635315,0.3514992892742157,0.35826030373573303,0.383339524269104,0.3810865879058838,0.3839050233364105,0.39367058873176575,0.4001401662826538,0.3989582061767578,0.40807822346687317,0.41512492299079895,0.4020557105541229,0.414892315864563,0.4074972867965698,0.41104403138160706,0.4168766140937805,0.4096144735813141,0.4084848463535309,0.43247345089912415,0.4191184341907501,0.40180864930152893,0.3152129352092743,0.3597654402256012,0.39242857694625854,0.4113357961177826,0.4175253212451935,0.4227483868598938,0.4289780855178833,0.425216406583786,0.42406001687049866,0.4234042465686798,0.4177834391593933,0.41853412985801697,0.4194842278957367,0.42704883217811584,0.420911967754364,0.414459764957428,0.4155547022819519,0.41232070326805115,0.416469007730484,0.4225381910800934,0.42641299962997437,0.42432403564453125,0.42894446849823,0.42677345871925354,0.42922505736351013,0.4312949478626251,0.42017844319343567,0.43513429164886475,0.4395257234573364,0.4396020770072937,0.42823338508605957,0.44024014472961426,0.4400177001953125,0.4429072439670563,0.4454585611820221,0.4273393154144287,0.4447089433670044,0.44657695293426514,0.4320535659790039,0.44190913438796997,0.4467637240886688,0.4498952627182007,0.44947826862335205,0.44275936484336853,0.44819405674934387,0.45183613896369934,0.45260199904441833,0.466298907995224,0.46527960896492004,0.46172896027565,0.4611722230911255,0.46800896525382996,0.4627877175807953,0.460342139005661,0.4628429412841797,0.4668455421924591,0.4562234580516815,0.46601101756095886,0.456514447927475,0.4774883985519409,0.46749961376190186,0.4807952046394348,0.4721715450286865,0.46439528465270996,0.4851376414299011,0.48403021693229675,0.4712030291557312,0.4772089123725891,0.48373302817344666,0.4742065668106079,
mae,0.5171420574188232,0.5137629508972168,0.5164510607719421,0.4834906756877899,0.4592146575450897,0.4436197578907013,0.4351426959037781,0.4227244257926941,0.42355549335479736,0.41594886779785156,0.4165531098842621,0.42001932859420776,0.4373937249183655,0.43244674801826477,0.4335312247276306,0.4385886788368225,0.4441375732421875,0.4409836530685425,0.44890135526657104,0.45480629801750183,0.44199463725090027,0.45326924324035645,0.4453716576099396,0.448648601770401,0.454466313123703,0.44812262058258057,0.44628751277923584,0.4628726541996002,0.4527360796928406,0.4463954269886017,0.4037635028362274,0.4169860780239105,0.43482068181037903,0.44510382413864136,0.44895005226135254,0.4506935477256775,0.45638343691825867,0.453274130821228,0.45188796520233154,0.44997233152389526,0.44663670659065247,0.44734397530555725,0.44333282113075256,0.45031750202178955,0.4475328326225281,0.44003826379776,0.4442637264728546,0.44157302379608154,0.4424285888671875,0.44718989729881287,0.4511645436286926,0.4465292692184448,0.4497276246547699,0.4480988681316376,0.45002225041389465,0.4500623345375061,0.4409416913986206,0.45196792483329773,0.4540990889072418,0.454309344291687,0.443388968706131,0.45699673891067505,0.45489829778671265,0.45648056268692017,0.45775213837623596,0.44491103291511536,0.4560001790523529,0.45860934257507324,0.44579994678497314,0.4522262513637543,0.4555703103542328,0.4601646661758423,0.4595174789428711,0.4530019760131836,0.4569378197193146,0.46048495173454285,0.4632083475589752,0.4746962785720825,0.47243958711624146,0.4669136703014374,0.46986067295074463,0.47279980778694153,0.4672626256942749,0.4647476077079773,0.4678577780723572,0.46987080574035645,0.4620817303657532,0.4715920388698578,0.4600696861743927,0.47975537180900574,0.4709671139717102,0.484252005815506,0.47495949268341064,0.4652484059333801,0.4852026700973511,0.48320290446281433,0.47167178988456726,0.4768877923488617,0.48358115553855896,0.47500523924827576,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 907       
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 908       
=================================================================
Total params: 1,815
Trainable params: 1,815
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 907
Trainable params: 907
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 908
Trainable params: 908
Non-trainable params: 0
_________________________________________________________________
