2021-06-26
loss,9.158843040466309,4.434446811676025,3.204770803451538,3.8599774837493896,2.8755197525024414,3.259798526763916,3.0710504055023193,3.2279086112976074,3.182950019836426,2.0309243202209473,2.705782890319824,3.3467607498168945,2.381836175918579,1.7238601446151733,2.0611698627471924,1.8052914142608643,1.4075008630752563,2.0676140785217285,1.9416505098342896,1.4301364421844482,2.4741268157958984,2.1514763832092285,2.5708858966827393,1.9068684577941895,1.5778095722198486,1.4841740131378174,1.5408090353012085,3.272987127304077,1.8739947080612183,1.7977747917175293,2.482865810394287,1.7865124940872192,2.2941291332244873,1.4963510036468506,1.6342042684555054,1.6001461744308472,1.4574322700500488,1.373688817024231,1.4623749256134033,1.534989356994629,1.6731536388397217,1.4701846837997437,1.5903009176254272,1.583986759185791,1.1261463165283203,1.3857804536819458,1.9574073553085327,2.2824361324310303,2.135240077972412,1.4555751085281372,1.7390681505203247,1.5004370212554932,1.3565272092819214,1.136164665222168,0.9096422791481018,1.3190983533859253,1.377708911895752,1.127403974533081,1.4213954210281372,1.214339256286621,1.044829249382019,0.9502427577972412,1.2721229791641235,1.3169981241226196,1.0315455198287964,1.6018964052200317,0.9548113942146301,0.7854945659637451,0.6614910364151001,1.6387780904769897,0.8128544092178345,0.5942681431770325,0.6165992617607117,0.7879266142845154,0.8631860613822937,0.7140058875083923,0.5685392618179321,0.9349820613861084,0.8165887594223022,0.8699600100517273,0.4895729720592499,0.6385958790779114,0.8176550269126892,0.961650550365448,0.6100175380706787,0.8187828660011292,0.6585125923156738,0.4026912450790405,0.385396271944046,0.6258665323257446,0.5012596249580383,0.7234225273132324,0.7169682383537292,0.6509003639221191,0.6137620806694031,0.7014909982681274,0.4970664083957672,0.5947327613830566,0.754413902759552,0.5571720600128174,
mse,0.5919277667999268,0.4786485731601715,0.36559173464775085,0.3597641885280609,0.38107043504714966,0.3464370667934418,0.3787488043308258,0.36640071868896484,0.3682636320590973,0.35590580105781555,0.3210742175579071,0.3355371952056885,0.34140223264694214,0.32624098658561707,0.31923073530197144,0.3052392899990082,0.2811037302017212,0.293788880109787,0.26326435804367065,0.28031644225120544,0.2834826409816742,0.31025058031082153,0.3139796853065491,0.2729394733905792,0.25372186303138733,0.25582385063171387,0.2527293860912323,0.26684844493865967,0.32139018177986145,0.2888767719268799,0.3112439811229706,0.2893126904964447,0.25207942724227905,0.25006985664367676,0.2657860815525055,0.2538786232471466,0.25152841210365295,0.23338693380355835,0.23929113149642944,0.24320757389068604,0.24887022376060486,0.24884843826293945,0.24337153136730194,0.23874247074127197,0.20420444011688232,0.1828552782535553,0.16394725441932678,0.19837719202041626,0.19029898941516876,0.18382330238819122,0.19051434099674225,0.18089763820171356,0.17025306820869446,0.15288229286670685,0.1355389654636383,0.12209002673625946,0.12904733419418335,0.10963205993175507,0.10778157413005829,0.1133294552564621,0.10567814111709595,0.08677001297473907,0.07992593944072723,0.06286034733057022,0.05297384411096573,0.04790109768509865,0.043599437922239304,0.035864755511283875,0.02512141689658165,0.03402499482035637,0.0232789795845747,0.01757906563580036,0.016938049346208572,0.016465744003653526,0.016284143552184105,0.015092269517481327,0.013943669386208057,0.014100518077611923,0.013852356933057308,0.01332686748355627,0.011266292072832584,0.010392512194812298,0.010394576005637646,0.012194555252790451,0.014828408136963844,0.016799040138721466,0.022252922877669334,0.014420798979699612,0.008387155830860138,0.008458875119686127,0.008571170270442963,0.013643132522702217,0.013351751491427422,0.013036096468567848,0.007946651428937912,0.010552996769547462,0.006797469686716795,0.006435782182961702,0.006715759634971619,0.006563812959939241,
mae,0.6342349648475647,0.560990571975708,0.47350841760635376,0.4471065104007721,0.45643872022628784,0.41927599906921387,0.4268465042114258,0.4119245409965515,0.405670702457428,0.39120304584503174,0.36762210726737976,0.3739660382270813,0.37634289264678955,0.3606899678707123,0.3556665778160095,0.34471142292022705,0.33383041620254517,0.3355676531791687,0.3245711922645569,0.3222299814224243,0.33595722913742065,0.3537009060382843,0.35424572229385376,0.32562804222106934,0.3089829683303833,0.3088871240615845,0.30492204427719116,0.32597291469573975,0.35543492436408997,0.33601826429367065,0.3530137538909912,0.3394288718700409,0.30708515644073486,0.297800213098526,0.3046262860298157,0.3026581108570099,0.2996739149093628,0.29144957661628723,0.29345080256462097,0.28962549567222595,0.2940948009490967,0.29167306423187256,0.28652799129486084,0.28583258390426636,0.27249959111213684,0.2578105032444,0.25139710307121277,0.28707507252693176,0.2753542363643646,0.26336055994033813,0.27231553196907043,0.25939178466796875,0.2500590682029724,0.24727684259414673,0.2391510158777237,0.2322050929069519,0.22845247387886047,0.2179366946220398,0.21893154084682465,0.22037526965141296,0.21478517353534698,0.19953149557113647,0.1946362853050232,0.18217122554779053,0.17480865120887756,0.167867049574852,0.16264751553535461,0.14680622518062592,0.11918026953935623,0.14502529799938202,0.11774355918169022,0.10063409060239792,0.09602902084589005,0.09850746393203735,0.0967467874288559,0.09289851039648056,0.08804336190223694,0.09034276753664017,0.09075681865215302,0.08823210746049881,0.08187995851039886,0.07840140163898468,0.0797606110572815,0.08493445068597794,0.09492850303649902,0.09978068619966507,0.11748352646827698,0.09734547883272171,0.07363013923168182,0.07354017347097397,0.07552025467157364,0.08934681117534637,0.09471574425697327,0.09175480902194977,0.07275693863630295,0.08044923096895218,0.06577692925930023,0.06397874653339386,0.06605172902345657,0.06526964902877808,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8611      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8612      
=================================================================
Total params: 17,223
Trainable params: 17,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 8,612
Trainable params: 8,612
Non-trainable params: 0
_________________________________________________________________
