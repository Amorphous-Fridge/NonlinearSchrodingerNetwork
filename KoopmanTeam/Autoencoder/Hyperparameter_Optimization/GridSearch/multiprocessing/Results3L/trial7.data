2021-06-26
loss,2.8520147800445557,1.2063463926315308,1.3040446043014526,1.8628861904144287,1.3921409845352173,1.0939737558364868,1.0427424907684326,0.7035073041915894,0.6616266369819641,0.6691357493400574,1.137702226638794,0.9711449146270752,0.6988852024078369,0.8237525224685669,1.0672508478164673,0.7015411257743835,0.7152602672576904,0.5926295518875122,0.5541629791259766,2.0943005084991455,1.1708341836929321,0.7974666357040405,0.6977124810218811,0.5563232898712158,0.7120575904846191,0.6577972173690796,0.8963483572006226,0.8650425672531128,0.6639949083328247,0.8765968084335327,0.8635926842689514,0.8659957051277161,0.5539399981498718,0.6333162784576416,0.6637780070304871,0.5802074670791626,0.5467184782028198,0.6606044173240662,0.6441962718963623,1.1733235120773315,0.954567551612854,0.6166855692863464,0.771431028842926,0.495700865983963,0.48767420649528503,0.7955753803253174,0.6677060127258301,0.6059911847114563,0.45223644375801086,0.4095543622970581,0.6356456875801086,0.7343889474868774,1.2184776067733765,1.352942705154419,0.6202180981636047,0.43681153655052185,0.4428222179412842,0.4110238254070282,0.4992678761482239,0.5303459167480469,0.9780102372169495,0.6774607300758362,0.5581192374229431,0.5069865584373474,0.6845184564590454,0.6791074872016907,0.4304099977016449,0.5696882009506226,0.6851691603660583,0.8893516659736633,0.507195234298706,0.45525360107421875,0.4545237421989441,0.43753376603126526,0.6771547198295593,0.5659930109977722,0.513150155544281,0.5379127860069275,0.38593021035194397,0.4734925925731659,0.4787115752696991,0.5323461890220642,0.8092662692070007,0.6238779425621033,0.4705216586589813,0.42117348313331604,0.5758197903633118,0.38849371671676636,0.5588595867156982,0.39693987369537354,0.4065501093864441,0.4667474627494812,0.6330373287200928,0.6254689693450928,1.3630508184432983,0.5781269669532776,0.4295220673084259,0.5980395674705505,0.5541945099830627,0.5777971148490906,
mse,0.3296066224575043,0.41178184747695923,0.4440400302410126,0.48364484310150146,0.4831005334854126,0.47245556116104126,0.4912043511867523,0.4832327961921692,0.4772697687149048,0.47229158878326416,0.49145767092704773,0.49662840366363525,0.5041286945343018,0.48362183570861816,0.48562631011009216,0.5083185434341431,0.48526468873023987,0.48775577545166016,0.485319048166275,0.4482569396495819,0.4739415645599365,0.47564560174942017,0.4871634542942047,0.47942090034484863,0.47770825028419495,0.500248908996582,0.48843804001808167,0.4903729259967804,0.48518654704093933,0.4877301752567291,0.4927312731742859,0.4525843858718872,0.4942382872104645,0.4792262613773346,0.46338358521461487,0.4863028824329376,0.48547065258026123,0.48979368805885315,0.4750761091709137,0.4672219753265381,0.4731197655200958,0.4849556088447571,0.48519977927207947,0.49293404817581177,0.48563888669013977,0.47789183259010315,0.4799371063709259,0.473707377910614,0.48657459020614624,0.4881094992160797,0.4654930830001831,0.4781389534473419,0.4653805196285248,0.4360194504261017,0.4776993691921234,0.4777442216873169,0.4797724783420563,0.47352683544158936,0.4665251672267914,0.46576759219169617,0.4808608889579773,0.4814074635505676,0.48976385593414307,0.46770134568214417,0.4680757224559784,0.48106154799461365,0.46745869517326355,0.47313109040260315,0.48198646306991577,0.46506306529045105,0.49389851093292236,0.4848758280277252,0.4817987084388733,0.4805643558502197,0.4772908687591553,0.48668232560157776,0.48591792583465576,0.46990966796875,0.48631367087364197,0.4756796956062317,0.48289555311203003,0.47841036319732666,0.48593997955322266,0.4873819351196289,0.48702821135520935,0.4843166470527649,0.4919632077217102,0.4821983277797699,0.4854775369167328,0.4798559546470642,0.474044531583786,0.47225242853164673,0.4868067800998688,0.4888550937175751,0.44876155257225037,0.46508774161338806,0.46327659487724304,0.4580007791519165,0.4851226508617401,0.4779701232910156,
mae,0.46105819940567017,0.47393667697906494,0.47616150975227356,0.49413806200027466,0.48817896842956543,0.4751919209957123,0.49202364683151245,0.4857172667980194,0.4828115701675415,0.4811880886554718,0.5087040662765503,0.5030505657196045,0.5161518454551697,0.5133888721466064,0.5074639916419983,0.5233181715011597,0.5130553245544434,0.5137059688568115,0.506992518901825,0.4918445944786072,0.5022298693656921,0.49687156081199646,0.5118383765220642,0.5137481689453125,0.508446991443634,0.5069028735160828,0.5153369307518005,0.5148069262504578,0.5127893686294556,0.5089930891990662,0.5156816840171814,0.49959495663642883,0.5070317983627319,0.5065474510192871,0.4909006953239441,0.5055504441261292,0.5099936127662659,0.5042981505393982,0.5001577734947205,0.4863660931587219,0.4750653803348541,0.4881203770637512,0.5022695660591125,0.5169031023979187,0.5162056088447571,0.49846839904785156,0.4889487028121948,0.4940308630466461,0.5038880705833435,0.5082084536552429,0.4842504560947418,0.4904566705226898,0.49159905314445496,0.48779022693634033,0.507398784160614,0.5001514554023743,0.5042043924331665,0.5014258027076721,0.48712918162345886,0.4877610504627228,0.4910717010498047,0.4953041076660156,0.5130155086517334,0.5007880330085754,0.49783793091773987,0.5029317736625671,0.4912726581096649,0.4893811345100403,0.49891021847724915,0.4685911536216736,0.4882297217845917,0.4849131107330322,0.4885166585445404,0.49327901005744934,0.48048079013824463,0.48463764786720276,0.49604400992393494,0.4863198399543762,0.49794822931289673,0.48764315247535706,0.49673232436180115,0.4952193796634674,0.4980407655239105,0.5016250014305115,0.49807727336883545,0.48251697421073914,0.4921497702598572,0.49893271923065186,0.4915941655635834,0.4923495054244995,0.4871905446052551,0.48522093892097473,0.4911098778247833,0.4956924021244049,0.47276780009269714,0.4831526279449463,0.48066121339797974,0.47704851627349854,0.481134295463562,0.49008694291114807,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1707      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1708      
=================================================================
Total params: 3,415
Trainable params: 3,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 1,707
Trainable params: 1,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 1,708
Trainable params: 1,708
Non-trainable params: 0
_________________________________________________________________
