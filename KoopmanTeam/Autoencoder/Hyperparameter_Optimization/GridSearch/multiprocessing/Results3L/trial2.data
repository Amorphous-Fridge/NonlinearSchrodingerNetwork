2021-06-26
loss,4.572006702423096,3.153139114379883,2.0432724952697754,3.319469928741455,2.137862205505371,1.9785373210906982,1.4251997470855713,1.273522138595581,1.7697978019714355,1.598717212677002,1.3598241806030273,1.3343493938446045,1.074011206626892,1.0155109167099,1.1275254487991333,0.8794100880622864,1.3675601482391357,0.9678504467010498,0.8922663331031799,0.8292366862297058,1.3657898902893066,0.958991289138794,0.7262117862701416,0.6801149845123291,0.7268503308296204,0.6616725921630859,0.7877984642982483,0.7798015475273132,0.9014884233474731,0.5005087852478027,1.1848094463348389,2.146981954574585,1.4527943134307861,0.8102523684501648,0.9728864431381226,0.5936410427093506,0.6508947014808655,0.9080711603164673,0.6919471025466919,0.5851373672485352,0.611822783946991,0.6101182699203491,0.6675052046775818,0.5717838406562805,0.7400514483451843,1.4997082948684692,0.7000425457954407,0.5589345693588257,0.718017041683197,0.8199756741523743,0.47842609882354736,0.4085407257080078,0.5193101167678833,1.2803081274032593,0.9287899732589722,0.57475346326828,0.5641112327575684,0.45123013854026794,0.8804216980934143,0.8802146911621094,0.7328978180885315,0.635252058506012,0.8367276191711426,0.7554255127906799,0.5747566223144531,0.3191165328025818,0.5763952136039734,0.8315109014511108,1.004931926727295,0.8897127509117126,0.6518116593360901,0.48475104570388794,0.5116813778877258,0.5304152965545654,0.4150644540786743,0.7144344449043274,0.6345927715301514,0.9802115559577942,0.5348197817802429,0.5657227039337158,0.554248034954071,0.46694520115852356,0.8772476315498352,0.6145725250244141,0.45237141847610474,0.6271935105323792,0.6173698306083679,0.5355334281921387,0.5219137072563171,0.42451584339141846,0.6979026794433594,0.9306331872940063,0.9717386364936829,0.9109617471694946,0.477552592754364,0.7928392291069031,0.6023116111755371,0.3228064775466919,0.33462145924568176,0.480204313993454,
mse,0.24781079590320587,0.18300633132457733,0.17469875514507294,0.1702442318201065,0.16422542929649353,0.1407536268234253,0.12696753442287445,0.10704434663057327,0.10065712034702301,0.09327851235866547,0.0844898521900177,0.07753242552280426,0.06938116997480392,0.06339666992425919,0.05668143182992935,0.05721297115087509,0.05760364234447479,0.05472639575600624,0.049743980169296265,0.048321522772312164,0.04648696258664131,0.04484044015407562,0.04078497365117073,0.03598116710782051,0.03524220734834671,0.028533298522233963,0.028800390660762787,0.026350248605012894,0.027868960052728653,0.024177275598049164,0.025619346648454666,0.02875516191124916,0.034541305154561996,0.026607181876897812,0.02388945035636425,0.02211468666791916,0.018329448997974396,0.018212269991636276,0.017397213727235794,0.01605054922401905,0.015907548367977142,0.014476566575467587,0.013691918924450874,0.013985943980515003,0.011931611225008965,0.02080621011555195,0.02108408883213997,0.014317815192043781,0.01072241086512804,0.01165583822876215,0.009574299678206444,0.008508249185979366,0.011640528216958046,0.014414722099900246,0.011112533509731293,0.008159770630300045,0.007446122821420431,0.006614826153963804,0.007606299594044685,0.009204521775245667,0.006544570904225111,0.007707779295742512,0.008951923809945583,0.013788236305117607,0.008262550458312035,0.0060633765533566475,0.004612911492586136,0.007436493411660194,0.008331740275025368,0.006957874167710543,0.004188217222690582,0.0047217365354299545,0.00442166905850172,0.0048556216061115265,0.0036300625652074814,0.004163030534982681,0.004826765041798353,0.008079509250819683,0.0052294861525297165,0.00527097936719656,0.005135165993124247,0.0037264779675751925,0.006197269540280104,0.006769883446395397,0.003937930334359407,0.005010515917092562,0.004130000248551369,0.003538793884217739,0.0026555059012025595,0.0027464311569929123,0.005676624830812216,0.006942190695554018,0.00701805017888546,0.0076983217149972916,0.0029178124386817217,0.0048703658394515514,0.003076729364693165,0.002806792501360178,0.004670843482017517,0.003701101755723357,
mae,0.3847512900829315,0.32235968112945557,0.3123524785041809,0.31065523624420166,0.3113095164299011,0.291909396648407,0.2785906195640564,0.2573028802871704,0.2501535713672638,0.24308449029922485,0.23019805550575256,0.2204175740480423,0.20732788741588593,0.19769887626171112,0.18509778380393982,0.18704918026924133,0.18792371451854706,0.1828135848045349,0.1723518967628479,0.1691645383834839,0.16629138588905334,0.16284525394439697,0.15422220528125763,0.14134126901626587,0.13929052650928497,0.12426992505788803,0.12604568898677826,0.12086906284093857,0.12567749619483948,0.11233483254909515,0.11800874769687653,0.1264946013689041,0.14395590126514435,0.12047910690307617,0.11135819554328918,0.10699982941150665,0.09567100554704666,0.09828158468008041,0.09409980475902557,0.09045567363500595,0.09437556564807892,0.08703868091106415,0.08414267748594284,0.08579622954130173,0.08021772652864456,0.10834213346242905,0.1080545037984848,0.08559560030698776,0.07498469948768616,0.07868394255638123,0.07332325726747513,0.06810775399208069,0.07985445857048035,0.09233536571264267,0.07883206009864807,0.06815442442893982,0.06328283250331879,0.060516562312841415,0.06546229869127274,0.07331874221563339,0.06012474372982979,0.06995461881160736,0.07092460244894028,0.08982012420892715,0.07099539041519165,0.061067868024110794,0.053021129220724106,0.06728614866733551,0.0726880431175232,0.06652544438838959,0.04972592741250992,0.054241519421339035,0.052901484072208405,0.05590101704001427,0.047761816531419754,0.05116679146885872,0.054882872849702835,0.06954873353242874,0.057695452123880386,0.05854355916380882,0.055887967348098755,0.04774806648492813,0.06085998937487602,0.06500580161809921,0.04854767024517059,0.0556429959833622,0.05117553845047951,0.04729650542140007,0.04036128893494606,0.04157404974102974,0.05683081969618797,0.06786693632602692,0.06619004905223846,0.0702018141746521,0.04350927844643593,0.05447457358241081,0.04405719414353371,0.04213590547442436,0.053266581147909164,0.045871902257204056,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3347      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3348      
=================================================================
Total params: 6,695
Trainable params: 6,695
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 3,347
Trainable params: 3,347
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 3,348
Trainable params: 3,348
Non-trainable params: 0
_________________________________________________________________
