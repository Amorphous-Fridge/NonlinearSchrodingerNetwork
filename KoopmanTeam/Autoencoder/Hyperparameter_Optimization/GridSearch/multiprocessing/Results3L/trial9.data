2021-06-26
loss,5.686842441558838,2.509275436401367,2.3237249851226807,2.013730525970459,1.8445913791656494,2.926112413406372,1.9367092847824097,1.7724885940551758,2.3532989025115967,1.9025297164916992,1.492524266242981,2.1486847400665283,2.5599684715270996,2.0130820274353027,1.7935476303100586,2.1707191467285156,1.9744000434875488,1.7515794038772583,1.5397175550460815,1.8857295513153076,1.3402352333068848,1.497162938117981,1.9635460376739502,2.092780113220215,1.4484267234802246,2.116279363632202,1.599192500114441,1.575705885887146,2.2407262325286865,1.7458304166793823,1.6954100131988525,1.6744786500930786,1.5491632223129272,1.6646839380264282,1.5793015956878662,1.7978930473327637,1.6335029602050781,1.4074506759643555,1.7475199699401855,1.311050534248352,1.0696117877960205,1.4035547971725464,1.163001298904419,1.022498607635498,1.140176773071289,1.3435510396957397,1.0248571634292603,1.1951491832733154,1.183555006980896,0.6911574602127075,1.2100765705108643,1.503519892692566,1.6653282642364502,0.980704665184021,0.7703561186790466,0.735985279083252,1.3207635879516602,0.7322080731391907,0.9107224345207214,0.6391168236732483,0.6148369312286377,0.6160524487495422,0.7636366486549377,0.8598641157150269,0.7661667466163635,0.7160175442695618,0.7964752316474915,0.8661248087882996,0.7314872145652771,0.7604629397392273,0.7136425971984863,0.6228379607200623,0.6890184879302979,0.7391611337661743,0.7512193918228149,0.8364840745925903,0.8500797152519226,0.6560424566268921,0.5932276844978333,0.5311411619186401,0.3939521312713623,0.5018488764762878,0.7366076111793518,0.6562232375144958,0.6568714380264282,0.6610327363014221,0.5227956175804138,0.7564805746078491,0.6262016296386719,0.43310585618019104,0.4454093873500824,0.4045981168746948,0.6012656688690186,0.4207119345664978,0.3629840612411499,0.42937496304512024,0.4937915802001953,0.3881963789463043,0.3686116933822632,0.7536813616752625,
mse,0.6223179697990417,0.6222318410873413,0.6082382202148438,0.6198614239692688,0.6094669103622437,0.6224243640899658,0.6419362425804138,0.6366083025932312,0.6247579455375671,0.6273097991943359,0.629077136516571,0.6771883964538574,0.6603295207023621,0.6372777819633484,0.627194344997406,0.6343259215354919,0.6281242370605469,0.6167435646057129,0.6137428879737854,0.6115801334381104,0.5929538607597351,0.6005948781967163,0.5791249871253967,0.5775167346000671,0.5577905774116516,0.5635808706283569,0.5517913699150085,0.5431361198425293,0.5475797057151794,0.5472514629364014,0.5270694494247437,0.5076595544815063,0.5417390465736389,0.5309081077575684,0.5125367045402527,0.5209079384803772,0.5336477756500244,0.5107892751693726,0.49631595611572266,0.5097813606262207,0.4906174838542938,0.49053576588630676,0.4418072998523712,0.4256856441497803,0.43181312084198,0.4547174572944641,0.41185158491134644,0.39877334237098694,0.37935870885849,0.3795309066772461,0.3607243597507477,0.36903998255729675,0.3952786326408386,0.43233853578567505,0.3663802742958069,0.3589700758457184,0.3631443679332733,0.35695701837539673,0.3528071641921997,0.3550896942615509,0.3546103239059448,0.34671199321746826,0.34751302003860474,0.3564879596233368,0.3531610369682312,0.35140687227249146,0.3481622338294983,0.33885592222213745,0.3612997829914093,0.3466907739639282,0.35695067048072815,0.34977400302886963,0.3515867590904236,0.34871822595596313,0.3555189073085785,0.348427951335907,0.37574976682662964,0.35834991931915283,0.354277104139328,0.34726929664611816,0.3464418053627014,0.35003700852394104,0.3412330746650696,0.34350231289863586,0.33796584606170654,0.33617106080055237,0.341612309217453,0.35725462436676025,0.3341101408004761,0.33250588178634644,0.3264583349227905,0.32574760913848877,0.30902132391929626,0.3289790749549866,0.3249579668045044,0.3223904073238373,0.32053130865097046,0.3179049491882324,0.31696492433547974,0.3335745632648468,
mae,0.6120193600654602,0.6042450666427612,0.5947928428649902,0.6007835865020752,0.5931894779205322,0.593665599822998,0.6012995839118958,0.6023951172828674,0.5881783366203308,0.5942094922065735,0.5944784879684448,0.6170148253440857,0.6088877320289612,0.5897722840309143,0.594231128692627,0.5956143736839294,0.5906769037246704,0.583623468875885,0.5834660530090332,0.5788887739181519,0.5735958218574524,0.5760480165481567,0.5605717301368713,0.5577335357666016,0.5423152446746826,0.5388228893280029,0.5363578200340271,0.5329089760780334,0.5235285758972168,0.5217153429985046,0.509172797203064,0.49567046761512756,0.5036612153053284,0.49999019503593445,0.4933755397796631,0.49351266026496887,0.5007479190826416,0.4883226454257965,0.48159655928611755,0.4832899570465088,0.4847801923751831,0.47237473726272583,0.44902288913726807,0.4344554841518402,0.4351027011871338,0.4500175416469574,0.42344674468040466,0.41086894273757935,0.396877259016037,0.39452821016311646,0.3804888129234314,0.3856394290924072,0.42140597105026245,0.4309994578361511,0.3867813050746918,0.3765510618686676,0.37534698843955994,0.36753201484680176,0.3645845651626587,0.36309948563575745,0.3645009696483612,0.35819506645202637,0.3578105568885803,0.3696694076061249,0.36112332344055176,0.3601089417934418,0.36035460233688354,0.3572743237018585,0.3671606183052063,0.3587048351764679,0.3627873957157135,0.3581686019897461,0.3639463782310486,0.35940706729888916,0.36385640501976013,0.36257538199424744,0.3781830072402954,0.3621155917644501,0.3584190011024475,0.3503285348415375,0.3455527424812317,0.3437667489051819,0.33881592750549316,0.3386974334716797,0.3336293399333954,0.33768177032470703,0.34054166078567505,0.35141509771347046,0.33548152446746826,0.32625365257263184,0.3182649314403534,0.31651750206947327,0.3158970773220062,0.31892210245132446,0.31277430057525635,0.3125666379928589,0.31513914465904236,0.3071984052658081,0.3046218752861023,0.32386061549186707,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2251      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2252      
=================================================================
Total params: 4,503
Trainable params: 4,503
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 2,251
Trainable params: 2,251
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 2,252
Trainable params: 2,252
Non-trainable params: 0
_________________________________________________________________
