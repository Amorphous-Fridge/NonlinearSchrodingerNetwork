2021-06-26
loss,4.600180149078369,2.2670552730560303,1.6863772869110107,1.9848110675811768,2.172492504119873,1.6385470628738403,1.2302885055541992,1.4946320056915283,2.0644044876098633,1.5295201539993286,1.4507653713226318,1.5291314125061035,1.5989196300506592,1.417695164680481,1.5286247730255127,1.6657345294952393,1.448427438735962,1.572424054145813,2.554990768432617,1.8499157428741455,1.3734127283096313,1.8261889219284058,1.3409812450408936,1.2646903991699219,1.2976270914077759,1.7587220668792725,1.644433617591858,1.0941441059112549,1.02631413936615,1.170835256576538,1.5234971046447754,1.5460407733917236,1.2740678787231445,1.202370047569275,1.5238209962844849,1.1234930753707886,1.0246702432632446,1.250060796737671,1.0604314804077148,1.455701470375061,1.4672719240188599,1.5263117551803589,1.15839421749115,1.1845555305480957,1.0291235446929932,1.3808424472808838,1.2511236667633057,1.5919990539550781,1.404934048652649,0.9827432036399841,1.350602149963379,1.364183783531189,1.3716217279434204,1.6216018199920654,1.2975869178771973,1.376862645149231,1.367185115814209,1.065151333808899,0.9288468956947327,0.9776660203933716,0.838318943977356,0.6411430835723877,0.8348792195320129,0.8738145232200623,0.87885582447052,0.7096816301345825,0.762469470500946,0.6394010186195374,0.7010029554367065,0.5357873439788818,0.7299163341522217,0.7866458296775818,0.9180107116699219,0.6490415334701538,0.6337985992431641,0.5199371576309204,0.4684949815273285,0.5558909773826599,0.467927485704422,0.644666850566864,0.4861031472682953,0.5545881390571594,0.6530129313468933,0.6220809817314148,0.9610653519630432,0.4859025478363037,0.5597401261329651,0.5990163683891296,0.5965503454208374,0.7516793012619019,0.6086501479148865,0.4257780909538269,0.450652152299881,0.7237450480461121,0.41716763377189636,0.4286089837551117,0.4112827181816101,0.4395962655544281,0.42112627625465393,0.5025932192802429,
mse,0.5890956521034241,0.6529350280761719,0.6853379011154175,0.693046510219574,0.6894214153289795,0.6801131963729858,0.684062123298645,0.6806890964508057,0.676480233669281,0.6717836260795593,0.6726706624031067,0.6799226999282837,0.6695862412452698,0.6757661700248718,0.676786482334137,0.6857932209968567,0.663571834564209,0.6703919768333435,0.655190110206604,0.6489970684051514,0.6566615104675293,0.6610796451568604,0.651248037815094,0.6478726267814636,0.6458995938301086,0.6424960494041443,0.6236292719841003,0.6385046243667603,0.6431358456611633,0.6254023313522339,0.6064031720161438,0.6297702193260193,0.6416048407554626,0.6267071962356567,0.6310126781463623,0.637697160243988,0.6389361023902893,0.6305323839187622,0.6283846497535706,0.6106353998184204,0.6288057565689087,0.6147223711013794,0.5951482653617859,0.6184893250465393,0.6048797369003296,0.6077942848205566,0.634407639503479,0.6108444333076477,0.6187838912010193,0.6280885338783264,0.6250864863395691,0.6154935956001282,0.6281685829162598,0.6081165075302124,0.505139172077179,0.6113600730895996,0.6168675422668457,0.611366868019104,0.5695095658302307,0.5642416477203369,0.5744209289550781,0.574229896068573,0.5758733153343201,0.5729493498802185,0.554675281047821,0.563372015953064,0.5702094435691833,0.5687305331230164,0.5687409043312073,0.5730201601982117,0.5666888952255249,0.5695377588272095,0.5740066170692444,0.568683922290802,0.5733320116996765,0.5712844729423523,0.5746312737464905,0.5774601101875305,0.5685825943946838,0.5708995461463928,0.5652165412902832,0.5649663805961609,0.5666022896766663,0.5611498355865479,0.5774703025817871,0.5766008496284485,0.5737902522087097,0.5775258541107178,0.5724021196365356,0.5673410892486572,0.5774843096733093,0.5686275362968445,0.5726127028465271,0.5836976766586304,0.5705400705337524,0.5634918808937073,0.5670238137245178,0.5643869638442993,0.5536705255508423,0.569435179233551,
mae,0.6167845129966736,0.6568233370780945,0.6803557872772217,0.682437539100647,0.6817229986190796,0.675844132900238,0.6768268346786499,0.6721033453941345,0.67121422290802,0.6676456332206726,0.6688326001167297,0.6732999682426453,0.6664477586746216,0.6704965829849243,0.6731139421463013,0.676994800567627,0.661694347858429,0.6673363447189331,0.6535429358482361,0.6472907066345215,0.6514922976493835,0.6559018492698669,0.6441055536270142,0.6425961852073669,0.6418178081512451,0.6399299502372742,0.6222929954528809,0.6334173083305359,0.6349768042564392,0.6191959381103516,0.6021748781204224,0.6228163242340088,0.630098283290863,0.6154975891113281,0.6165158748626709,0.6244475841522217,0.6230402588844299,0.6132266521453857,0.6114794015884399,0.59718918800354,0.6125690937042236,0.5974805355072021,0.5820815563201904,0.6006152629852295,0.5890177488327026,0.594354510307312,0.615517795085907,0.5931834578514099,0.5990724563598633,0.6091740131378174,0.6072900295257568,0.600002110004425,0.6060789227485657,0.5895888209342957,0.5122767686843872,0.5935781598091125,0.5974684357643127,0.5906201004981995,0.556106448173523,0.5496619343757629,0.5571485757827759,0.5556769967079163,0.5675262212753296,0.5644893050193787,0.5381437540054321,0.5454427003860474,0.5504644513130188,0.5507766604423523,0.5509936809539795,0.5551620721817017,0.5482150316238403,0.5505420565605164,0.5535829067230225,0.550468921661377,0.5549962520599365,0.5525131821632385,0.5565685033798218,0.5605747103691101,0.5482310652732849,0.5526061058044434,0.5491683483123779,0.5480210185050964,0.5492770671844482,0.5444008708000183,0.5586019158363342,0.5557091236114502,0.5554381608963013,0.5620368123054504,0.5577134490013123,0.5487958788871765,0.559914767742157,0.5534236431121826,0.5566204786300659,0.5667804479598999,0.5528068542480469,0.5473185181617737,0.5494542121887207,0.5488438606262207,0.536007285118103,0.5531809329986572,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1203      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1204      
=================================================================
Total params: 2,407
Trainable params: 2,407
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 1,203
Trainable params: 1,203
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 1,204
Trainable params: 1,204
Non-trainable params: 0
_________________________________________________________________
