2021-06-26
loss,8.498187065124512,1.9891562461853027,1.6981381177902222,1.9490160942077637,2.695904493331909,2.107558012008667,3.0041143894195557,1.6292229890823364,1.6423016786575317,1.5590510368347168,1.5943256616592407,1.4490922689437866,1.1851104497909546,2.989577293395996,1.7479705810546875,1.1479567289352417,1.3398545980453491,1.260687232017517,1.3203494548797607,1.0554358959197998,1.2267353534698486,0.9486929178237915,1.2550047636032104,1.1147598028182983,1.3969743251800537,0.960805356502533,1.0020731687545776,0.9816442131996155,1.586848497390747,0.7808981537818909,1.1546587944030762,1.0431091785430908,0.8371161818504333,0.816876232624054,1.1562132835388184,1.2458527088165283,0.8665649890899658,1.0322909355163574,0.8387227654457092,0.7163249254226685,0.9841821193695068,0.8792194128036499,1.166962742805481,1.1592967510223389,0.9238483309745789,0.8986578583717346,0.7516902089118958,0.7598487138748169,0.9853237867355347,0.9518280029296875,1.0763617753982544,0.9488948583602905,0.8672727942466736,0.705543577671051,0.6500679850578308,1.0329482555389404,0.8080536723136902,0.9788143634796143,0.7885947227478027,0.7648212909698486,0.7305576205253601,0.6356527209281921,0.8227527737617493,0.7726680040359497,0.8908739686012268,0.7525074481964111,0.9999144673347473,0.9213512539863586,0.5734586715698242,0.7173636555671692,0.8861983418464661,1.055505633354187,0.8858550190925598,0.44753333926200867,0.6017122864723206,0.5941424369812012,0.84566330909729,0.7410888671875,0.5977318286895752,0.6966997385025024,0.7515944838523865,1.1658858060836792,0.5784604549407959,0.6068705916404724,0.7603476047515869,0.8154127597808838,0.48418736457824707,0.6561799049377441,0.796309232711792,0.723450779914856,0.5817028284072876,0.4783284664154053,0.4960520565509796,0.9188287258148193,0.6937460899353027,0.7750574350357056,0.5969135165214539,0.9523059725761414,0.5511516332626343,0.4882766008377075,
mse,0.1599825769662857,0.136973038315773,0.1238282173871994,0.11498131603002548,0.11875084787607193,0.11264004558324814,0.11018198728561401,0.10150150209665298,0.09406593441963196,0.09667875617742538,0.08937086910009384,0.09249748289585114,0.08781395107507706,0.08918185532093048,0.08872351050376892,0.08577779680490494,0.0851554200053215,0.08412827551364899,0.08038745820522308,0.07884509861469269,0.07406504452228546,0.07168900966644287,0.06866953521966934,0.07091113924980164,0.069602832198143,0.0657406747341156,0.06638175994157791,0.06784974038600922,0.07224945724010468,0.07244899123907089,0.07427578419446945,0.06971833109855652,0.06806737184524536,0.06874212622642517,0.0654648095369339,0.06850996613502502,0.06886767596006393,0.0679752379655838,0.06617240607738495,0.06549837440252304,0.0742926225066185,0.08001549541950226,0.07468428462743759,0.07111857086420059,0.06786467880010605,0.06711627542972565,0.06406155228614807,0.0649542585015297,0.0648583397269249,0.06779313832521439,0.06905779987573624,0.06744891405105591,0.0670923963189125,0.06648753583431244,0.06631870567798615,0.07201636582612991,0.07247922569513321,0.06982465833425522,0.06891161948442459,0.06887131184339523,0.06980141997337341,0.06923094391822815,0.07180266082286835,0.07306237518787384,0.07221676409244537,0.07386381179094315,0.07112805545330048,0.07399651408195496,0.07115283608436584,0.07093880325555801,0.07068415731191635,0.07417252659797668,0.07448619604110718,0.06815590709447861,0.06803283095359802,0.06855069100856781,0.06762193888425827,0.07026150077581406,0.06777042150497437,0.07226663082838058,0.07249545305967331,0.06583293527364731,0.06929829716682434,0.0692145898938179,0.07463306188583374,0.07219643890857697,0.07042526453733444,0.07171640545129776,0.0744718536734581,0.08906015753746033,0.0739649087190628,0.07195626944303513,0.06912238895893097,0.06998839229345322,0.07693567872047424,0.07562035322189331,0.0783102959394455,0.06886967271566391,0.08076918870210648,0.07528260350227356,
mae,0.3271223306655884,0.3050173223018646,0.2899121046066284,0.27932989597320557,0.28391873836517334,0.27539965510368347,0.2722271680831909,0.26266464591026306,0.2519393861293793,0.2536572515964508,0.2448684722185135,0.2501315176486969,0.2430742084980011,0.2437891811132431,0.24233697354793549,0.23910515010356903,0.2384587824344635,0.23644022643566132,0.22883257269859314,0.22671636939048767,0.2155430018901825,0.20918309688568115,0.2014342099428177,0.20357151329517365,0.20140323042869568,0.19338840246200562,0.19479484856128693,0.19883960485458374,0.21421584486961365,0.21275116503238678,0.2119181603193283,0.20251421630382538,0.2009529322385788,0.20041967928409576,0.19529493153095245,0.19995687901973724,0.20233744382858276,0.19959557056427002,0.1962977796792984,0.19574010372161865,0.21539565920829773,0.2286619395017624,0.2186429351568222,0.21190065145492554,0.2057068645954132,0.20174388587474823,0.193979412317276,0.19324685633182526,0.1922147572040558,0.1975114643573761,0.19963186979293823,0.19829536974430084,0.19791260361671448,0.1955178827047348,0.19382573664188385,0.20529676973819733,0.20523621141910553,0.2023995816707611,0.2000480592250824,0.2004508525133133,0.20139843225479126,0.2004069834947586,0.20599938929080963,0.2071923315525055,0.20733481645584106,0.20951271057128906,0.20452696084976196,0.20976603031158447,0.20223136246204376,0.20172768831253052,0.20168760418891907,0.2139468640089035,0.21499624848365784,0.19943714141845703,0.199332594871521,0.20234914124011993,0.1977453976869583,0.20404283702373505,0.19936531782150269,0.2099519968032837,0.20965582132339478,0.1986975073814392,0.20298407971858978,0.20413997769355774,0.21506740152835846,0.2121746689081192,0.20713095366954803,0.20959267020225525,0.2139192819595337,0.23826247453689575,0.21219342947006226,0.2116658240556717,0.20571444928646088,0.20477280020713806,0.21980182826519012,0.21720047295093536,0.22319753468036652,0.20641985535621643,0.22679820656776428,0.21949727833271027,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3315      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3316      
=================================================================
Total params: 6,631
Trainable params: 6,631
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 3,315
Trainable params: 3,315
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 3,316
Trainable params: 3,316
Non-trainable params: 0
_________________________________________________________________
