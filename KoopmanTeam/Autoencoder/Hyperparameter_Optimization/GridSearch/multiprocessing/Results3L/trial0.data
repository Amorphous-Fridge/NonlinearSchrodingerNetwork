2021-06-26
loss,5.564401626586914,3.5540170669555664,2.1686549186706543,1.7641732692718506,2.591062068939209,2.1599252223968506,2.0488295555114746,2.155538558959961,1.52994966506958,1.854251742362976,1.762794017791748,1.7546824216842651,2.1076250076293945,1.6083686351776123,2.4582724571228027,1.6855186223983765,2.14804744720459,1.5097650289535522,1.603126883506775,2.1772255897521973,1.5576179027557373,3.3870508670806885,2.2552649974823,2.3088254928588867,1.5166774988174438,1.3954460620880127,2.0761752128601074,2.1029741764068604,1.733154296875,3.041935682296753,1.5341057777404785,1.9257174730300903,1.6898281574249268,1.4682459831237793,1.9514254331588745,1.6067190170288086,1.3223234415054321,1.4184025526046753,1.8258073329925537,2.189927339553833,1.5459812879562378,1.473122239112854,1.9495700597763062,2.1927907466888428,2.362489700317383,1.5342518091201782,1.9284205436706543,2.006993055343628,1.380233645439148,1.593351125717163,1.5312819480895996,1.675323486328125,1.349491834640503,1.5682908296585083,1.3743075132369995,1.3589879274368286,1.8383938074111938,1.7381750345230103,1.483047366142273,1.5535043478012085,1.3608819246292114,1.4395982027053833,1.4878469705581665,1.5392906665802002,1.3379645347595215,1.5840651988983154,1.3769282102584839,1.5165727138519287,1.4374096393585205,1.9269388914108276,2.1416215896606445,2.019793748855591,1.600837230682373,1.790106177330017,1.7312970161437988,1.6345106363296509,1.579674482345581,1.5518522262573242,1.3151875734329224,1.0631464719772339,1.2002487182617188,1.456472635269165,1.2862359285354614,1.3810293674468994,1.2593796253204346,1.3119850158691406,1.1672723293304443,1.4978621006011963,1.7817367315292358,1.33821702003479,2.264477252960205,1.3339124917984009,1.1181538105010986,1.286879539489746,1.3505483865737915,1.0874468088150024,1.1224570274353027,1.2584363222122192,1.3319673538208008,1.3370877504348755,
mse,0.5752350687980652,0.5464480519294739,0.4581398069858551,0.3943191468715668,0.4156463146209717,0.4503954350948334,0.43764182925224304,0.4481472671031952,0.4123561382293701,0.42500627040863037,0.4019217789173126,0.38144707679748535,0.4193873703479767,0.4149356782436371,0.40993374586105347,0.41402432322502136,0.4271935522556305,0.4359810948371887,0.42562901973724365,0.42678147554397583,0.4232713580131531,0.42267337441444397,0.4188513457775116,0.43051519989967346,0.4552687108516693,0.4410882294178009,0.4088543653488159,0.42823532223701477,0.41828322410583496,0.4400502145290375,0.4201054275035858,0.42103537917137146,0.41431403160095215,0.4120691418647766,0.42613545060157776,0.43086421489715576,0.39869144558906555,0.41199493408203125,0.42781898379325867,0.42873597145080566,0.4273359775543213,0.4137896001338959,0.42101603746414185,0.43133094906806946,0.4133013188838959,0.4165809154510498,0.41224583983421326,0.41505682468414307,0.42269423604011536,0.4415423572063446,0.42413851618766785,0.42283838987350464,0.3964998722076416,0.4183932840824127,0.42343294620513916,0.42230772972106934,0.4134298264980316,0.44011151790618896,0.44137611985206604,0.4234740138053894,0.43325451016426086,0.4295092523097992,0.4204767942428589,0.40020787715911865,0.41782090067863464,0.4222826659679413,0.4098336100578308,0.3905668556690216,0.3928498923778534,0.4090915024280548,0.44136208295822144,0.45926856994628906,0.4219324588775635,0.37852492928504944,0.3943568170070648,0.3883616328239441,0.3933824896812439,0.37617698311805725,0.36700087785720825,0.3515525758266449,0.3297567665576935,0.3630341589450836,0.3408225178718567,0.37402743101119995,0.36336126923561096,0.37300169467926025,0.37260711193084717,0.3721393942832947,0.38028523325920105,0.35622477531433105,0.33025383949279785,0.34858664870262146,0.32491058111190796,0.32389137148857117,0.34170955419540405,0.3371506929397583,0.34855860471725464,0.35570085048675537,0.3702141046524048,0.3800595998764038,
mae,0.5844363570213318,0.5466889142990112,0.47727203369140625,0.43630218505859375,0.4501773715019226,0.47686123847961426,0.46999600529670715,0.4728747606277466,0.45320579409599304,0.45861756801605225,0.4377860724925995,0.42193809151649475,0.45403480529785156,0.44903478026390076,0.4443996548652649,0.44939181208610535,0.46089112758636475,0.4653880298137665,0.45806023478507996,0.45876583456993103,0.45844319462776184,0.46028244495391846,0.4576764702796936,0.46203064918518066,0.48075196146965027,0.47311049699783325,0.4546031057834625,0.4673892557621002,0.4557249844074249,0.47168391942977905,0.45980796217918396,0.46307459473609924,0.45723670721054077,0.4525620937347412,0.46444323658943176,0.46599796414375305,0.44104430079460144,0.44901251792907715,0.46253159642219543,0.47103992104530334,0.4663611650466919,0.4599069654941559,0.4614413380622864,0.4673739969730377,0.4629879891872406,0.45767930150032043,0.4591548442840576,0.4575836956501007,0.46235573291778564,0.4748116731643677,0.4670083522796631,0.46213993430137634,0.44352972507476807,0.45998191833496094,0.46205517649650574,0.46364957094192505,0.4536490738391876,0.4693376123905182,0.4750484824180603,0.46385088562965393,0.4680265486240387,0.46613994240760803,0.45971107482910156,0.4473608136177063,0.45371922850608826,0.45887279510498047,0.45621466636657715,0.43823498487472534,0.44364306330680847,0.44764912128448486,0.4707408547401428,0.4886290729045868,0.4670623540878296,0.43057963252067566,0.4342144727706909,0.43003082275390625,0.4314883053302765,0.42256519198417664,0.41557562351226807,0.40671536326408386,0.39395466446876526,0.408825159072876,0.3961726129055023,0.41344010829925537,0.40892693400382996,0.4154776632785797,0.4166026711463928,0.41614583134651184,0.42360377311706543,0.4184408485889435,0.4052700698375702,0.3993891775608063,0.38656651973724365,0.3833695948123932,0.3977535367012024,0.39429205656051636,0.3990741968154907,0.4060516059398651,0.41385504603385925,0.4238620400428772,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5443      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5444      
=================================================================
Total params: 10,887
Trainable params: 10,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 5,443
Trainable params: 5,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 5,444
Trainable params: 5,444
Non-trainable params: 0
_________________________________________________________________
