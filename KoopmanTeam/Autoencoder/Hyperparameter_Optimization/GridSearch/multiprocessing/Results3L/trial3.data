2021-06-26
loss,3.1873040199279785,1.6731462478637695,1.7221304178237915,1.4503059387207031,1.3763673305511475,1.9098411798477173,1.694400429725647,1.3147454261779785,1.7894408702850342,1.4553136825561523,1.791216254234314,2.0269815921783447,1.9637352228164673,1.9029736518859863,2.0298514366149902,1.4425562620162964,1.3979661464691162,1.3396906852722168,1.4234282970428467,1.481016993522644,1.539945125579834,1.466508388519287,1.4614864587783813,1.5963129997253418,1.4822572469711304,1.478972315788269,1.4320788383483887,1.2279939651489258,1.1652426719665527,1.329081416130066,1.6251978874206543,1.4356281757354736,1.365464448928833,1.3660122156143188,1.250312328338623,1.1679539680480957,1.2627477645874023,1.4507023096084595,1.1953842639923096,1.2972930669784546,1.431796669960022,1.007114052772522,1.4732847213745117,1.0075641870498657,1.2272905111312866,1.2931010723114014,1.44932222366333,1.0729992389678955,1.3976447582244873,1.2678176164627075,1.2963685989379883,1.107232689857483,1.1107674837112427,1.0405017137527466,1.0255340337753296,0.9320579767227173,0.9354965090751648,1.3340071439743042,1.1869516372680664,0.9376904964447021,0.9722981452941895,1.387099027633667,0.988659679889679,0.9348817467689514,1.0452722311019897,0.9752744436264038,1.1395312547683716,1.0870665311813354,0.9793439507484436,0.8976914882659912,0.7673746347427368,0.847063422203064,0.8456690311431885,1.015241026878357,0.7526301741600037,1.0612986087799072,1.165046215057373,0.8663756847381592,0.8414459824562073,0.801367998123169,0.9040884971618652,1.0259259939193726,0.8920629620552063,0.8908253312110901,0.6044861674308777,0.8127163648605347,0.8091443777084351,0.7501278519630432,0.6409400701522827,0.6429938673973083,0.5431865453720093,0.8207407593727112,0.6930156946182251,0.8663341403007507,0.5900183320045471,0.5997616052627563,0.6013481020927429,0.7476503849029541,0.6145090460777283,0.964356541633606,
mse,0.42084527015686035,0.4055878520011902,0.40054214000701904,0.4004825949668884,0.40212592482566833,0.4006173312664032,0.3560049533843994,0.34199199080467224,0.3348992168903351,0.3290907144546509,0.327760249376297,0.328347772359848,0.3239593207836151,0.32529956102371216,0.3251523971557617,0.32905614376068115,0.32890334725379944,0.3535985052585602,0.339204877614975,0.33136996626853943,0.3267741799354553,0.3316698968410492,0.3295164406299591,0.32603931427001953,0.3211398422718048,0.32415878772735596,0.329795241355896,0.33225974440574646,0.333907812833786,0.3304545283317566,0.3308763802051544,0.3244229257106781,0.32134583592414856,0.319708913564682,0.32433265447616577,0.31619521975517273,0.32220250368118286,0.31753024458885193,0.32346123456954956,0.31503480672836304,0.317981481552124,0.31359636783599854,0.31648075580596924,0.3200373947620392,0.32311972975730896,0.3153187036514282,0.3232807219028473,0.3166275918483734,0.3142462372779846,0.317007452249527,0.3016991913318634,0.3046075105667114,0.3130203187465668,0.3200928866863251,0.3134565055370331,0.32185256481170654,0.31481462717056274,0.2896699011325836,0.3044642210006714,0.3123103082180023,0.31173720955848694,0.3024725615978241,0.29929620027542114,0.3090974688529968,0.2994278371334076,0.3016115128993988,0.3003002405166626,0.31096577644348145,0.297994464635849,0.3215925097465515,0.3085178732872009,0.3087426424026489,0.30180540680885315,0.29892823100090027,0.2954765260219574,0.2987872064113617,0.31068360805511475,0.31809768080711365,0.31657877564430237,0.29277175664901733,0.2894667685031891,0.29932868480682373,0.3095853626728058,0.3104203939437866,0.3028477728366852,0.2940381169319153,0.3022421896457672,0.30710798501968384,0.3113682270050049,0.29186365008354187,0.2859794795513153,0.3038760721683502,0.2915976643562317,0.2908520996570587,0.31116148829460144,0.31136777997016907,0.30439671874046326,0.3006984293460846,0.3053930997848511,0.2839583158493042,
mae,0.5097078680992126,0.4984065294265747,0.49793103337287903,0.4978281855583191,0.4981301426887512,0.49115824699401855,0.443619966506958,0.43107831478118896,0.4255506098270416,0.4223068654537201,0.420134574174881,0.41999492049217224,0.41754794120788574,0.4182685613632202,0.4173766076564789,0.418740838766098,0.41748401522636414,0.4275605082511902,0.4197767674922943,0.4154984652996063,0.41324493288993835,0.41553133726119995,0.41440993547439575,0.41195178031921387,0.40898263454437256,0.4101555347442627,0.412467360496521,0.4139680862426758,0.4154604971408844,0.4133228063583374,0.41497480869293213,0.4115627408027649,0.40983903408050537,0.40791454911231995,0.4110291004180908,0.4041835069656372,0.4071778953075409,0.4021078050136566,0.40565571188926697,0.3996277153491974,0.3991023600101471,0.39395105838775635,0.3944389820098877,0.3939812481403351,0.39656317234039307,0.3910547196865082,0.3979388177394867,0.3867407739162445,0.3843440115451813,0.38385748863220215,0.37483471632003784,0.3770711123943329,0.38203513622283936,0.3828107714653015,0.37916526198387146,0.38181671500205994,0.3756960332393646,0.36161404848098755,0.3716847896575928,0.37026557326316833,0.36513787508010864,0.35892775654792786,0.35840389132499695,0.3595273196697235,0.3531833589076996,0.35391858220100403,0.35338905453681946,0.35848987102508545,0.3494814932346344,0.36102718114852905,0.3514111638069153,0.35229527950286865,0.3561897575855255,0.34891214966773987,0.34483692049980164,0.34310126304626465,0.3495938181877136,0.35479655861854553,0.35478919744491577,0.3409992456436157,0.33970338106155396,0.3482706546783447,0.3517704904079437,0.3489445447921753,0.34233418107032776,0.33518311381340027,0.34089595079421997,0.34279605746269226,0.34422165155410767,0.3370651602745056,0.33880165219306946,0.3443620800971985,0.3342812657356262,0.3328203856945038,0.34290146827697754,0.34166014194488525,0.3387482762336731,0.337255597114563,0.33760353922843933,0.3249557912349701,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 347       
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 348       
=================================================================
Total params: 695
Trainable params: 695
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 347
Trainable params: 347
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 348
Trainable params: 348
Non-trainable params: 0
_________________________________________________________________
