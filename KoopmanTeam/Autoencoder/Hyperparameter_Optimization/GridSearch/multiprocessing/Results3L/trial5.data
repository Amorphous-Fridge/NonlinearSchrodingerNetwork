2021-06-26
loss,4.057248115539551,2.0227582454681396,2.157158613204956,2.006110429763794,1.5610867738723755,1.60068678855896,2.291030168533325,1.9741977453231812,2.3980491161346436,2.1296095848083496,2.318969964981079,1.7141075134277344,1.7794380187988281,1.7493274211883545,1.9086378812789917,1.7575451135635376,1.6050235033035278,1.5765295028686523,1.3442469835281372,2.0922629833221436,1.387495994567871,1.9615229368209839,1.3992336988449097,1.2452901601791382,1.2484880685806274,1.3973089456558228,1.1182295083999634,1.3280971050262451,0.9139488935470581,1.3664085865020752,0.8371725678443909,1.3445782661437988,1.0121922492980957,0.8682578802108765,0.8269491791725159,1.2027355432510376,1.054751992225647,1.6891177892684937,1.324009656906128,0.8229599595069885,0.8429745435714722,1.0418113470077515,0.9609584212303162,1.0587807893753052,0.8207489848136902,0.7144962549209595,0.9859627485275269,1.2268434762954712,0.9680322408676147,1.0560029745101929,0.6703826189041138,0.8003116846084595,0.6271217465400696,0.7712752819061279,0.8988174200057983,0.5144778490066528,0.5576007962226868,0.915961742401123,0.9983579516410828,0.7526077032089233,0.6245002150535583,0.8460462093353271,1.006517767906189,1.0125812292099,1.0131466388702393,0.7162401080131531,0.7528612017631531,0.9853801131248474,0.876163125038147,0.8149927258491516,0.6667222380638123,0.8228625655174255,0.9546329379081726,0.7590506076812744,1.2507870197296143,0.9694595336914062,1.0439674854278564,0.9829468727111816,0.9254916906356812,0.6904827356338501,0.9063614010810852,0.9854863882064819,0.9938845634460449,0.9998550415039062,0.887249767780304,0.642750084400177,1.1326723098754883,0.9407781362533569,0.9395239949226379,0.6706265807151794,0.6975135207176208,0.649474024772644,0.6903114318847656,0.9011445045471191,0.7656484246253967,0.9332757592201233,0.747734785079956,0.8646138906478882,0.6460021138191223,0.6208420395851135,
mse,0.27798745036125183,0.21475404500961304,0.18879011273384094,0.16827841103076935,0.17262449860572815,0.17599621415138245,0.17046529054641724,0.15554727613925934,0.15518121421337128,0.16551214456558228,0.19943848252296448,0.17880868911743164,0.15532474219799042,0.1582995057106018,0.14643654227256775,0.14092935621738434,0.12628252804279327,0.11824482679367065,0.0966147780418396,0.07758427411317825,0.06799302250146866,0.06740541756153107,0.06757665425539017,0.05397867038846016,0.049478646367788315,0.04996030032634735,0.04614579305052757,0.042087867856025696,0.039302755147218704,0.03699149191379547,0.0435168631374836,0.03889066353440285,0.038173604756593704,0.035176776349544525,0.033110111951828,0.03387483209371567,0.03610212728381157,0.04035911709070206,0.03934793546795845,0.03557300195097923,0.034872476011514664,0.035492852330207825,0.03690754249691963,0.03555498272180557,0.03579697757959366,0.03627995774149895,0.03720775619149208,0.0392734594643116,0.03502868488430977,0.03637166693806648,0.0359652079641819,0.0351029597222805,0.03602083399891853,0.035929933190345764,0.0372188575565815,0.03566213697195053,0.0361330546438694,0.03632831200957298,0.03749054670333862,0.03924314305186272,0.037524063140153885,0.037959080189466476,0.0378587432205677,0.03818344697356224,0.039433449506759644,0.03841254115104675,0.03826802596449852,0.03854728490114212,0.03973616659641266,0.040060464292764664,0.0387575663626194,0.03742600232362747,0.04011540114879608,0.03946176543831825,0.04118666797876358,0.03802419453859329,0.039510857313871384,0.04100147634744644,0.0411515086889267,0.03914591670036316,0.037836238741874695,0.03895144537091255,0.03925776109099388,0.04045844450592995,0.04236066713929176,0.041719622910022736,0.040809255093336105,0.03964307904243469,0.03874920681118965,0.03868674859404564,0.04273604229092598,0.040919214487075806,0.03899885714054108,0.03960702568292618,0.039645031094551086,0.04161396622657776,0.039776191115379333,0.040699683129787445,0.03970504552125931,0.03937145695090294,
mae,0.413600355386734,0.34153857827186584,0.30430445075035095,0.2866367995738983,0.2805260419845581,0.2792034149169922,0.27456429600715637,0.2625415325164795,0.26189395785331726,0.26705124974250793,0.28167474269866943,0.27142468094825745,0.25580599904060364,0.25454336404800415,0.24602358043193817,0.24208511412143707,0.23046569526195526,0.22272439301013947,0.20450612902641296,0.19663122296333313,0.1837669014930725,0.18031010031700134,0.18152141571044922,0.1638725996017456,0.15736185014247894,0.15617716312408447,0.15484076738357544,0.14664441347122192,0.1441991925239563,0.13929995894432068,0.15588994324207306,0.1445273905992508,0.1373683512210846,0.13176028430461884,0.12976516783237457,0.1294015496969223,0.1309300661087036,0.1442364603281021,0.14405249059200287,0.1297171711921692,0.1289762407541275,0.12845177948474884,0.13025513291358948,0.12857621908187866,0.1299601048231125,0.12793129682540894,0.13229462504386902,0.1376158595085144,0.12677691876888275,0.12843352556228638,0.12636131048202515,0.12888498604297638,0.1290620118379593,0.12907838821411133,0.1321234256029129,0.12743891775608063,0.12875568866729736,0.12912675738334656,0.1303236335515976,0.13234984874725342,0.12926419079303741,0.130840003490448,0.13381126523017883,0.12919016182422638,0.13573209941387177,0.1323128193616867,0.13042035698890686,0.13067469000816345,0.1340567171573639,0.14058417081832886,0.1288084089756012,0.12880797684192657,0.13552948832511902,0.13373097777366638,0.13937006890773773,0.13397520780563354,0.13415515422821045,0.13657772541046143,0.13747887313365936,0.12903837859630585,0.12932144105434418,0.1306954175233841,0.13004636764526367,0.13756665587425232,0.1411137580871582,0.14037954807281494,0.13819018006324768,0.1348728984594345,0.12959153950214386,0.1312875896692276,0.13785934448242188,0.13130775094032288,0.12982632219791412,0.13158904016017914,0.13758184015750885,0.134231835603714,0.13055570423603058,0.13700410723686218,0.12970250844955444,0.1286749392747879,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1715      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1716      
=================================================================
Total params: 3,431
Trainable params: 3,431
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 1,715
Trainable params: 1,715
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 1,716
Trainable params: 1,716
Non-trainable params: 0
_________________________________________________________________
