2021-06-26
loss,4.798585414886475,2.881272792816162,3.9153945446014404,3.894226312637329,1.7384533882141113,2.0950608253479004,2.6024508476257324,2.2405152320861816,1.6172397136688232,1.6082473993301392,1.6365532875061035,1.1599164009094238,1.115744709968567,1.9813950061798096,1.6080363988876343,1.7272595167160034,1.7904890775680542,2.352670669555664,2.217622756958008,1.5006364583969116,1.7456254959106445,1.838191270828247,2.839050054550171,1.659206748008728,1.290625810623169,1.9548394680023193,1.7647407054901123,1.6252728700637817,1.3705776929855347,2.0778439044952393,1.5058366060256958,0.9609920382499695,1.0473182201385498,1.106276035308838,1.1106363534927368,1.2157695293426514,1.1314564943313599,1.025773048400879,0.7683168053627014,0.6953974366188049,0.5306113362312317,0.7105907201766968,1.379988193511963,0.9689008593559265,0.9151023626327515,0.6614339351654053,0.6592791080474854,0.8894376158714294,1.1448155641555786,0.9734147787094116,0.6897727847099304,0.8420398235321045,0.7453084588050842,0.8020815253257751,0.9235432147979736,0.8969748020172119,1.1195107698440552,1.2785732746124268,0.8847463726997375,0.6882827281951904,0.6806096434593201,0.995759129524231,0.825111448764801,0.7540889978408813,0.7404540777206421,0.5513654947280884,0.4881640374660492,0.5407531261444092,0.5270716547966003,0.5401555895805359,0.5734243988990784,0.6850995421409607,0.5440526008605957,0.604836642742157,0.5472071766853333,1.0569031238555908,0.9364285469055176,0.9109219908714294,1.3212425708770752,0.5954269170761108,0.544524073600769,0.5172763466835022,0.5481801629066467,0.5029955506324768,0.5882559418678284,0.6541764140129089,0.698119044303894,0.6820472478866577,0.6423960328102112,0.8896251916885376,0.5608944892883301,0.377731591463089,0.906568169593811,0.9235287308692932,0.6053640246391296,0.6168158650398254,0.5974706411361694,0.7821153402328491,0.6946651935577393,1.0181480646133423,
mse,0.3677913546562195,0.3931570053100586,0.32743871212005615,0.4245874285697937,0.3858785927295685,0.3969111144542694,0.36997997760772705,0.3736325204372406,0.39749839901924133,0.392173171043396,0.4217921197414398,0.3918229341506958,0.38593098521232605,0.4119502305984497,0.3997454047203064,0.40100234746932983,0.399667888879776,0.3906095027923584,0.3848281800746918,0.3953004777431488,0.4050087034702301,0.4141361713409424,0.4828120768070221,0.4032019376754761,0.409974604845047,0.4051996171474457,0.3949553966522217,0.4061323404312134,0.39857548475265503,0.39140334725379944,0.37130236625671387,0.37002503871917725,0.37753579020500183,0.3498600125312805,0.36258360743522644,0.3753860890865326,0.38393133878707886,0.3747599422931671,0.38376566767692566,0.3640282154083252,0.3671216070652008,0.3745812177658081,0.3857753872871399,0.3893246054649353,0.37786078453063965,0.3688730001449585,0.3522622585296631,0.38684001564979553,0.3688206970691681,0.37230631709098816,0.37998509407043457,0.36073216795921326,0.376690149307251,0.37775203585624695,0.3812229633331299,0.381368488073349,0.4059652090072632,0.41687583923339844,0.40884390473365784,0.3883802890777588,0.38436463475227356,0.3882907032966614,0.3757952153682709,0.37626755237579346,0.37407928705215454,0.3709949254989624,0.36505627632141113,0.36726540327072144,0.35667937994003296,0.3623217046260834,0.36473122239112854,0.3575954735279083,0.36102795600891113,0.35653358697891235,0.35017094016075134,0.35557642579078674,0.36101195216178894,0.3575415015220642,0.3865320086479187,0.36852914094924927,0.36674144864082336,0.3510826826095581,0.35370784997940063,0.34802642464637756,0.3522883653640747,0.3586423397064209,0.3601316213607788,0.3559194803237915,0.34915387630462646,0.3419114351272583,0.3630374073982239,0.345445454120636,0.3418123722076416,0.3546293377876282,0.3349660634994507,0.3588294982910156,0.3502126634120941,0.36051619052886963,0.36634406447410583,0.3533693552017212,
mae,0.4592580497264862,0.44552937150001526,0.39448052644729614,0.44264572858810425,0.4249541163444519,0.4284815490245819,0.4187060594558716,0.40931305289268494,0.4220530688762665,0.40838032960891724,0.4239872992038727,0.40878504514694214,0.40015122294425964,0.4262145757675171,0.41013216972351074,0.41513943672180176,0.41025111079216003,0.4095582067966461,0.42655277252197266,0.4209079444408417,0.4167563319206238,0.4148285686969757,0.47244080901145935,0.422056645154953,0.4241654574871063,0.4128846824169159,0.4049057066440582,0.4078802764415741,0.4002001881599426,0.40227076411247253,0.37503689527511597,0.3715604841709137,0.3709700107574463,0.34522515535354614,0.3557188808917999,0.37539443373680115,0.376128226518631,0.36501941084861755,0.3723985552787781,0.3570350706577301,0.3577364981174469,0.36191681027412415,0.37834641337394714,0.3892386257648468,0.3692798614501953,0.3558710217475891,0.3449777662754059,0.38744860887527466,0.37371310591697693,0.37194547057151794,0.3674978017807007,0.35164105892181396,0.3655000627040863,0.3638923764228821,0.3729686737060547,0.3727180063724518,0.40610313415527344,0.425735741853714,0.4066540598869324,0.3785319924354553,0.375265508890152,0.38269999623298645,0.3666500449180603,0.3667813539505005,0.36529305577278137,0.361553430557251,0.3518417477607727,0.35049858689308167,0.34414127469062805,0.3484232425689697,0.3485828638076782,0.34667813777923584,0.3490430414676666,0.3429557681083679,0.33470630645751953,0.3496800363063812,0.3635315001010895,0.35008201003074646,0.391276091337204,0.36007389426231384,0.354170024394989,0.33888500928878784,0.3377871811389923,0.3341813385486603,0.3358956277370453,0.34483811259269714,0.3535018265247345,0.3412574827671051,0.33330562710762024,0.33065661787986755,0.35067492723464966,0.33028796315193176,0.33220231533050537,0.34752678871154785,0.34116867184638977,0.35253357887268066,0.3359375,0.3521616458892822,0.3547195494174957,0.34988540410995483,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6483      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6484      
=================================================================
Total params: 12,967
Trainable params: 12,967
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 6,483
Trainable params: 6,483
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 6,484
Trainable params: 6,484
Non-trainable params: 0
_________________________________________________________________
