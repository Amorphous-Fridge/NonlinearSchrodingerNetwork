2021-06-26
loss,6.239142894744873,3.3403215408325195,2.188727378845215,2.939995050430298,2.3018691539764404,2.7451672554016113,2.1033599376678467,2.9526455402374268,2.2291712760925293,2.470369577407837,2.846346855163574,1.8389239311218262,2.17297625541687,1.7566757202148438,1.6950831413269043,1.480950117111206,1.9120726585388184,1.6164480447769165,2.494138479232788,1.744990587234497,1.7189626693725586,1.5531219244003296,1.8531800508499146,1.8476790189743042,1.6027854681015015,2.0452065467834473,1.6906901597976685,1.6726279258728027,1.9694503545761108,1.4725234508514404,2.410048246383667,2.7881240844726562,1.7769370079040527,1.4192917346954346,1.807096242904663,1.7449042797088623,2.0387015342712402,1.4986011981964111,1.3761863708496094,1.177632451057434,1.3876146078109741,1.9770874977111816,1.6133666038513184,1.2231569290161133,1.1968668699264526,1.1854395866394043,1.0835522413253784,1.2954058647155762,1.456374168395996,1.480168342590332,1.8586866855621338,2.2546095848083496,1.6816531419754028,1.84076726436615,1.7911350727081299,1.3922913074493408,1.4013464450836182,1.7072339057922363,1.5508010387420654,1.3965624570846558,1.256662368774414,1.6095198392868042,1.1553561687469482,1.367159366607666,1.3018629550933838,1.5441316366195679,1.6972682476043701,1.268144965171814,1.5366287231445312,1.8032035827636719,1.6414391994476318,1.4142417907714844,1.3132861852645874,1.520058035850525,1.3408398628234863,1.1540799140930176,1.1331725120544434,1.6538089513778687,1.2854046821594238,1.2130275964736938,1.520193338394165,1.3061740398406982,1.1872559785842896,1.141872763633728,1.1755777597427368,1.368257999420166,1.2866387367248535,1.2964307069778442,1.8729230165481567,1.2869236469268799,1.392655611038208,1.3635462522506714,1.4635891914367676,1.3561010360717773,1.820191502571106,1.0129337310791016,1.0615220069885254,1.159402847290039,1.130333662033081,1.152152180671692,
mse,0.6344599723815918,0.574935793876648,0.4937305152416229,0.48330679535865784,0.4649094045162201,0.4619337320327759,0.4535030126571655,0.44875577092170715,0.42120876908302307,0.40204235911369324,0.4272543787956238,0.4222643971443176,0.42939215898513794,0.4136931896209717,0.387908011674881,0.3909173309803009,0.419752836227417,0.3856278955936432,0.3919278085231781,0.3691719174385071,0.3732587397098541,0.3789653778076172,0.3669811487197876,0.3757599890232086,0.3756476938724518,0.3860119879245758,0.388383686542511,0.3461022973060608,0.3740881681442261,0.37919503450393677,0.3584486246109009,0.2387213557958603,0.34390419721603394,0.34240344166755676,0.35603827238082886,0.3418169915676117,0.3685601055622101,0.33355942368507385,0.35955965518951416,0.317134827375412,0.3355255424976349,0.3465512990951538,0.36582157015800476,0.35813140869140625,0.3539269268512726,0.33827435970306396,0.35931161046028137,0.338267058134079,0.3409821391105652,0.3643985688686371,0.3610725402832031,0.2938537001609802,0.3401104807853699,0.35672706365585327,0.3522619903087616,0.3376678228378296,0.3473978042602539,0.34865057468414307,0.3508048355579376,0.3588663339614868,0.342568963766098,0.33467766642570496,0.32445552945137024,0.24512813985347748,0.29441940784454346,0.317326158285141,0.3192204236984253,0.32048043608665466,0.31792381405830383,0.33720606565475464,0.3430100679397583,0.36142298579216003,0.31487661600112915,0.3144609332084656,0.278827428817749,0.3010408580303192,0.27013134956359863,0.301291823387146,0.3267407715320587,0.2945685386657715,0.29767873883247375,0.3042505979537964,0.2977709174156189,0.3052816390991211,0.3163391053676605,0.31590011715888977,0.3332165777683258,0.29910793900489807,0.30687832832336426,0.29269352555274963,0.3163973093032837,0.2811298072338104,0.28218337893486023,0.30706286430358887,0.326203316450119,0.30343097448349,0.2608364224433899,0.2817586660385132,0.2877541780471802,0.29065823554992676,
mae,0.6344496607780457,0.5705612301826477,0.5147712230682373,0.5024210810661316,0.49023520946502686,0.48663654923439026,0.477298378944397,0.4721193313598633,0.45375296473503113,0.4344632625579834,0.44946300983428955,0.44560661911964417,0.4434363842010498,0.43567657470703125,0.41483843326568604,0.4127969443798065,0.42833638191223145,0.4083992838859558,0.4190099239349365,0.3877136707305908,0.4011361002922058,0.40058964490890503,0.39270561933517456,0.3981068432331085,0.40211978554725647,0.40470898151397705,0.4048113524913788,0.38401567935943604,0.3921207785606384,0.3980807363986969,0.4022856652736664,0.3265562057495117,0.3727196753025055,0.3672872483730316,0.37769031524658203,0.3704044818878174,0.3840891718864441,0.360640287399292,0.37555643916130066,0.34689244627952576,0.3610757887363434,0.3709943890571594,0.3846563994884491,0.381038635969162,0.373920738697052,0.36436015367507935,0.376728892326355,0.3609370291233063,0.3643963634967804,0.38420191407203674,0.38024982810020447,0.34311607480049133,0.3629084825515747,0.3742438554763794,0.3741767108440399,0.3615564703941345,0.3661929965019226,0.3681594729423523,0.3725251853466034,0.3764590322971344,0.3599611222743988,0.35970330238342285,0.355325311422348,0.3089262843132019,0.32893630862236023,0.3394522964954376,0.34533119201660156,0.3396325409412384,0.34042564034461975,0.356810599565506,0.3592350482940674,0.3704819083213806,0.33906951546669006,0.34015122056007385,0.3201523721218109,0.3268893361091614,0.31081151962280273,0.3281453847885132,0.3476189374923706,0.3315274715423584,0.33389854431152344,0.3351132869720459,0.32891029119491577,0.33528003096580505,0.33923161029815674,0.34617674350738525,0.350300669670105,0.33007073402404785,0.3377149999141693,0.32750117778778076,0.3407125771045685,0.32539981603622437,0.32061779499053955,0.33629852533340454,0.3548259735107422,0.3433440327644348,0.31605246663093567,0.3206484317779541,0.3195735216140747,0.31947630643844604,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3363      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3364      
=================================================================
Total params: 6,727
Trainable params: 6,727
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 3,363
Trainable params: 3,363
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 3,364
Trainable params: 3,364
Non-trainable params: 0
_________________________________________________________________
