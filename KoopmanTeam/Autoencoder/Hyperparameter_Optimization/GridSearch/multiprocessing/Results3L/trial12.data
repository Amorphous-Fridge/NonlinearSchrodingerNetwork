2021-06-26
loss,4.387885093688965,2.691760778427124,2.4253132343292236,2.462476968765259,3.324883460998535,1.8373064994812012,1.9365283250808716,2.335087299346924,2.3615593910217285,1.7185242176055908,1.795302391052246,1.5301913022994995,2.2993884086608887,2.4717323780059814,2.2657790184020996,1.326532006263733,1.4024436473846436,1.214180588722229,1.3708527088165283,1.7155828475952148,1.8587405681610107,1.513764500617981,1.2988646030426025,1.938420057296753,2.0485825538635254,1.135075330734253,1.551999807357788,1.1964130401611328,0.9620176553726196,1.177934169769287,1.5680625438690186,1.1041080951690674,1.2125260829925537,0.9706396460533142,0.7947213053703308,1.2569411993026733,1.1145339012145996,0.930097758769989,0.661255419254303,1.0517624616622925,1.5561398267745972,1.1011470556259155,0.6662008762359619,0.8141271471977234,0.6339005827903748,0.6869450211524963,0.4920039474964142,0.6484067440032959,0.69040846824646,0.6047905087471008,0.5279282331466675,1.0571171045303345,0.8369135856628418,0.6449226140975952,0.4669783413410187,0.5218059420585632,0.597359299659729,0.9386892914772034,0.8971573710441589,0.7399784326553345,0.7107101678848267,0.42882195115089417,0.4688706696033478,0.581220269203186,0.6713173389434814,0.5323590636253357,0.407522976398468,0.4697832763195038,0.40365222096443176,0.38503289222717285,0.791006326675415,0.5886245965957642,0.4825803339481354,0.6494103074073792,0.5807799100875854,0.4790925979614258,0.4596747159957886,0.43733879923820496,0.3942953050136566,0.5364526510238647,0.7285749316215515,0.5554155111312866,0.5144065618515015,0.4166790246963501,0.461940735578537,0.37730908393859863,0.6661909222602844,0.7199049592018127,1.1409668922424316,0.5829033255577087,0.4630841016769409,0.4901667535305023,0.468237966299057,0.47528186440467834,0.6123080253601074,0.35112786293029785,0.5368633270263672,0.4853464365005493,0.3772749602794647,0.5364148616790771,
mse,0.3879823386669159,0.4159371554851532,0.3701295852661133,0.42202532291412354,0.4430539608001709,0.3822081685066223,0.413107693195343,0.3904275894165039,0.4153995215892792,0.3565259873867035,0.33036789298057556,0.35731711983680725,0.3587758243083954,0.3929777443408966,0.33366912603378296,0.31745752692222595,0.2731020450592041,0.2959483861923218,0.2624898850917816,0.26555100083351135,0.29812923073768616,0.26474729180336,0.2261832058429718,0.22470176219940186,0.224107563495636,0.2343958467245102,0.22684001922607422,0.2058500498533249,0.1784881353378296,0.2001132220029831,0.18938256800174713,0.15943826735019684,0.1549559235572815,0.13338442146778107,0.11453208327293396,0.12595683336257935,0.13909834623336792,0.1128566712141037,0.09980222582817078,0.09294042736291885,0.10540632903575897,0.11111040413379669,0.09884316474199295,0.09703415632247925,0.08854734152555466,0.08895029872655869,0.08322546631097794,0.08301234245300293,0.0810464397072792,0.08779927343130112,0.08233428001403809,0.08848442137241364,0.08774127066135406,0.09360785782337189,0.08452251553535461,0.08157362043857574,0.07011635601520538,0.0846681222319603,0.08513783663511276,0.07621592283248901,0.07747824490070343,0.07644644379615784,0.07110239565372467,0.07596714794635773,0.08036953955888748,0.07834341377019882,0.07273143529891968,0.07172772288322449,0.06388742476701736,0.06154458224773407,0.08146996796131134,0.08045250922441483,0.08684403449296951,0.07493618875741959,0.08707236498594284,0.07653626054525375,0.07305554300546646,0.06799258291721344,0.06524476408958435,0.0726303681731224,0.07779299467802048,0.07472924888134003,0.065985769033432,0.07286718487739563,0.07148192077875137,0.06950147449970245,0.07331036031246185,0.06620520353317261,0.08250630646944046,0.07894086837768555,0.07426870614290237,0.07154348492622375,0.06902947276830673,0.07084191590547562,0.07441558688879013,0.07250948250293732,0.06665562838315964,0.06849182397127151,0.06666159629821777,0.06525532156229019,
mae,0.43694058060646057,0.4443777799606323,0.41297802329063416,0.44133830070495605,0.4713694751262665,0.41780829429626465,0.4363362491130829,0.42235904932022095,0.43715009093284607,0.4039848744869232,0.3889714479446411,0.4019572138786316,0.39783424139022827,0.4213586747646332,0.3843221962451935,0.3693825602531433,0.35119688510894775,0.3579941987991333,0.34271445870399475,0.3319060504436493,0.36253681778907776,0.33851733803749084,0.3210617005825043,0.31699249148368835,0.3106236755847931,0.32028719782829285,0.3172902762889862,0.3040442168712616,0.2877991795539856,0.29486772418022156,0.2942642867565155,0.29036852717399597,0.26855164766311646,0.26902899146080017,0.2563748061656952,0.2639123797416687,0.27310821413993835,0.2568577229976654,0.25102129578590393,0.24328790605068207,0.2602633237838745,0.26126381754875183,0.2526105046272278,0.25200074911117554,0.24492554366588593,0.24689845740795135,0.2406296283006668,0.2430323362350464,0.23771539330482483,0.25118589401245117,0.23783840239048004,0.24817873537540436,0.24428267776966095,0.2563735842704773,0.24421222507953644,0.2411070317029953,0.21974711120128632,0.2401898056268692,0.24283728003501892,0.22833651304244995,0.2308371663093567,0.231883704662323,0.22487516701221466,0.23214565217494965,0.23850364983081818,0.2354862093925476,0.2262433022260666,0.2254885882139206,0.21299846470355988,0.20839358866214752,0.24037699401378632,0.2326156198978424,0.24788691103458405,0.22866682708263397,0.24738824367523193,0.23156753182411194,0.22897270321846008,0.22195486724376678,0.21620714664459229,0.22556687891483307,0.2342703491449356,0.2289537638425827,0.2140287458896637,0.22850286960601807,0.22328944504261017,0.22240306437015533,0.22724029421806335,0.21249599754810333,0.23888184130191803,0.23501664400100708,0.22916710376739502,0.2264452874660492,0.22306136786937714,0.22272111475467682,0.22743406891822815,0.22666728496551514,0.2151331901550293,0.21848128736019135,0.2174302339553833,0.2163146734237671,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5419      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5420      
=================================================================
Total params: 10,839
Trainable params: 10,839
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 5,419
Trainable params: 5,419
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 5,420
Trainable params: 5,420
Non-trainable params: 0
_________________________________________________________________
