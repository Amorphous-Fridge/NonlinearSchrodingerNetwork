2021-06-25
loss,6.594531059265137,2.934338092803955,3.344926118850708,2.727433204650879,2.3523342609405518,2.913763999938965,1.7080426216125488,1.6182641983032227,1.9077296257019043,2.603184223175049,2.113987922668457,3.2897391319274902,3.054544687271118,2.009835958480835,1.4062572717666626,2.7194817066192627,1.786962866783142,1.552384614944458,1.3205662965774536,2.265855550765991,2.08107590675354,1.5598689317703247,1.6336326599121094,0.7531707882881165,1.5758297443389893,0.9511258602142334,1.0481822490692139,1.5116761922836304,1.359372615814209,0.7078585028648376,1.0122708082199097,0.8265931010246277,1.1876592636108398,1.0029559135437012,1.7308578491210938,1.1778240203857422,0.8278849720954895,0.6390839219093323,0.8109926581382751,1.178634762763977,1.166887879371643,0.8843019604682922,0.8012562394142151,0.9438030123710632,0.9503062963485718,0.7395849823951721,0.6772310137748718,0.9566172957420349,0.6907461285591125,0.7590503692626953,0.7484967112541199,0.5520029664039612,0.7686431407928467,0.9658018350601196,0.8315595984458923,0.6201051473617554,0.9188564419746399,0.8261927962303162,0.9434129595756531,0.6633949875831604,0.5566814541816711,0.520512580871582,0.7053810358047485,0.6990727782249451,0.5377622246742249,0.6131089925765991,0.7003254890441895,0.6801828145980835,0.5316203236579895,0.4826900362968445,0.5163785815238953,0.5763102173805237,0.5619404315948486,0.5077061653137207,0.4353765845298767,0.629106879234314,0.6248247623443604,0.699052631855011,0.8244483470916748,0.6627471446990967,0.543129563331604,0.8614569902420044,2.056879997253418,0.8921732306480408,0.897592306137085,0.6887096166610718,0.47784674167633057,0.48970428109169006,0.4724232852458954,0.42909568548202515,0.4658452272415161,0.4501758813858032,0.4907257854938507,0.731813371181488,0.5477465987205505,0.5226430296897888,0.6451046466827393,0.5956186056137085,0.5044310688972473,0.4640778601169586,
mse,0.6380375027656555,0.6122353672981262,0.6263650059700012,0.6280237436294556,0.6131969690322876,0.6452622413635254,0.6485938429832458,0.6521284580230713,0.6385999917984009,0.6599222421646118,0.662361204624176,0.5713071227073669,0.6003275513648987,0.6439920663833618,0.6403462886810303,0.6031435132026672,0.641671359539032,0.6311556100845337,0.6622640490531921,0.6359264254570007,0.6532450318336487,0.6431910991668701,0.6434817314147949,0.6257233619689941,0.645464301109314,0.6859274506568909,0.6776340007781982,0.5531754493713379,0.573814332485199,0.6309486627578735,0.6307685971260071,0.6301203370094299,0.6339840292930603,0.6435326337814331,0.6059821844100952,0.6089338064193726,0.633094072341919,0.6340669393539429,0.621590793132782,0.5851166248321533,0.5590036511421204,0.6099995374679565,0.6257806420326233,0.6311621069908142,0.6337262392044067,0.6306476593017578,0.6352154016494751,0.6304407715797424,0.6318531632423401,0.6221727132797241,0.6195036768913269,0.6231266856193542,0.6114780902862549,0.5923680663108826,0.6044328212738037,0.6109932661056519,0.6059761643409729,0.6010222434997559,0.6045084595680237,0.604982316493988,0.6017186045646667,0.5938186049461365,0.5957534909248352,0.6009911298751831,0.5991817712783813,0.6015167832374573,0.5974804162979126,0.585588276386261,0.5905254483222961,0.5886637568473816,0.5908435583114624,0.5956177711486816,0.5914663076400757,0.5855840444564819,0.5846896171569824,0.5875862240791321,0.5919731855392456,0.5973920226097107,0.5939154028892517,0.590391218662262,0.5937396883964539,0.5970380902290344,0.6265655159950256,0.5537188649177551,0.526179313659668,0.5113265514373779,0.5155684947967529,0.5151569247245789,0.5115963816642761,0.5126436352729797,0.512709379196167,0.5191294550895691,0.5248754620552063,0.5294755697250366,0.5401673316955566,0.550122082233429,0.5542377233505249,0.5646553635597229,0.5621907114982605,0.5621658563613892,
mae,0.6109784841537476,0.5899258255958557,0.6007260680198669,0.6048214435577393,0.5907301902770996,0.6189506649971008,0.6205474138259888,0.6242882609367371,0.6126464605331421,0.6318871974945068,0.6318776607513428,0.5698807239532471,0.5779463052749634,0.6190031170845032,0.6122334003448486,0.5863286852836609,0.6175158023834229,0.6062923073768616,0.6391811966896057,0.6164049506187439,0.6261599063873291,0.6143175363540649,0.6160815954208374,0.5996761322021484,0.6193698644638062,0.6637799143791199,0.6522769927978516,0.5484520792961121,0.5539038181304932,0.6040027737617493,0.6058788895606995,0.6042160391807556,0.6100322604179382,0.6180282235145569,0.5863285064697266,0.5829931497573853,0.6066915988922119,0.6077036261558533,0.5994263887405396,0.5736675262451172,0.5470448136329651,0.5861518979072571,0.599895715713501,0.6056392192840576,0.6086238026618958,0.6055324673652649,0.6115577816963196,0.6059374809265137,0.6084460616111755,0.5973385572433472,0.596261203289032,0.6009712219238281,0.5896689891815186,0.5723258852958679,0.5846943855285645,0.589750349521637,0.5862738490104675,0.5843285918235779,0.584158718585968,0.582952082157135,0.5821574926376343,0.5758641362190247,0.5766152739524841,0.5816299915313721,0.5804777145385742,0.582252562046051,0.5788500905036926,0.567727267742157,0.5725019574165344,0.5705634951591492,0.5722659826278687,0.576295793056488,0.5734916925430298,0.5667044520378113,0.5657945871353149,0.5675773620605469,0.5727059841156006,0.5771538615226746,0.5729672908782959,0.5706176161766052,0.5736836791038513,0.5824089646339417,0.6100416779518127,0.5384906530380249,0.5152662992477417,0.5027751922607422,0.5042935609817505,0.5036959648132324,0.501301109790802,0.5025103688240051,0.5022643804550171,0.5082927942276001,0.5128154158592224,0.5161299705505371,0.5262210369110107,0.5355795621871948,0.5393224954605103,0.5495392084121704,0.5475811958312988,0.5474947094917297,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 4354      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 4356      
=================================================================
Total params: 8,710
Trainable params: 8,710
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 4,354
Trainable params: 4,354
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 4,356
Trainable params: 4,356
Non-trainable params: 0
_________________________________________________________________
