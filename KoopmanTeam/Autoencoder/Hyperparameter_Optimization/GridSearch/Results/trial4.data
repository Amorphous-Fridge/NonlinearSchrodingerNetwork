2021-06-25
loss,7.63020133972168,3.2555811405181885,1.552174687385559,2.3097593784332275,2.027974843978882,1.925845742225647,2.3368473052978516,2.399456024169922,1.3779946565628052,1.6425528526306152,1.0884850025177002,1.044472336769104,1.2204327583312988,1.243282437324524,1.355218768119812,1.0220181941986084,0.9338642358779907,1.111923098564148,1.324143409729004,1.9041492938995361,1.5562586784362793,1.1913528442382812,0.953532338142395,0.8535447120666504,0.9941002130508423,0.6397005319595337,0.784627377986908,0.6453582048416138,0.8058424592018127,0.5775759220123291,0.6266502141952515,0.5916497707366943,0.8854522705078125,0.8074632883071899,0.5162769556045532,0.7205742001533508,0.9897685050964355,2.5113747119903564,1.0352282524108887,0.5162918567657471,0.6194246411323547,0.796424925327301,0.6510884761810303,0.7151947021484375,0.5979940891265869,0.6003345251083374,0.59700608253479,0.9331274628639221,0.701437771320343,0.6636884808540344,0.792611837387085,0.7127526998519897,0.6869836449623108,0.6470945477485657,0.9135688543319702,0.748474657535553,0.736836850643158,0.6572145819664001,0.6820555925369263,0.42887404561042786,0.4338008463382721,0.5054351687431335,0.50544673204422,0.6073598265647888,0.6513128876686096,0.6735475063323975,0.5594478845596313,0.3887840509414673,0.7930113077163696,0.4906280040740967,0.8568416833877563,0.7457377910614014,0.7743127346038818,0.7454343438148499,0.7521413564682007,0.6246749758720398,0.5832653641700745,0.7125086784362793,0.8690013289451599,0.7732164859771729,0.5610607266426086,0.7827259302139282,0.9880403876304626,0.790205180644989,0.8622641563415527,0.5376452803611755,0.5566513538360596,0.5363147854804993,0.5240138173103333,0.4093124270439148,0.6349358558654785,0.5126970410346985,0.6593775153160095,0.535189151763916,0.5610811114311218,0.7950965762138367,0.5871466398239136,0.6074378490447998,0.48228374123573303,0.6318877935409546,
mse,0.6173818707466125,0.598491907119751,0.6107560396194458,0.592698335647583,0.6093313097953796,0.5941882133483887,0.5953046083450317,0.5769774317741394,0.6005570888519287,0.6047852635383606,0.5914507508277893,0.5576180815696716,0.5694561004638672,0.5905861258506775,0.5824594497680664,0.5950415730476379,0.5814799070358276,0.5701001882553101,0.5053967237472534,0.5364052057266235,0.5767054557800293,0.5801805257797241,0.5790922045707703,0.5704372525215149,0.5691624283790588,0.5521658658981323,0.5551168918609619,0.5610436797142029,0.5631959438323975,0.5623990893363953,0.5595748424530029,0.5608305931091309,0.5687941908836365,0.5675745606422424,0.5542358160018921,0.5419957041740417,0.5329662561416626,0.49925553798675537,0.5256103277206421,0.5262653827667236,0.5296398997306824,0.5422254800796509,0.5434826016426086,0.5385751128196716,0.5445584058761597,0.5477893948554993,0.5546770095825195,0.5386341214179993,0.5319187641143799,0.5455833077430725,0.555022120475769,0.5668420791625977,0.564061164855957,0.5635954737663269,0.5709118843078613,0.5640078783035278,0.5537195801734924,0.5589798092842102,0.5606662631034851,0.5577208995819092,0.5541352033615112,0.5527674555778503,0.5609883666038513,0.559084415435791,0.5586411952972412,0.5535581707954407,0.5616500973701477,0.5508045554161072,0.5509173274040222,0.5273455381393433,0.5351810455322266,0.5532849431037903,0.5667138695716858,0.5556278824806213,0.5574747920036316,0.563538134098053,0.5462667942047119,0.5487368702888489,0.5564371943473816,0.563585638999939,0.559852659702301,0.5589922070503235,0.5511682033538818,0.5425638556480408,0.5458195209503174,0.5541753172874451,0.553421676158905,0.5533128976821899,0.5634444952011108,0.5680056214332581,0.569507360458374,0.5712677240371704,0.5668126940727234,0.5598568320274353,0.5622953176498413,0.5584586262702942,0.5661700963973999,0.5700170993804932,0.569973349571228,0.5507789850234985,
mae,0.6044499278068542,0.5640143752098083,0.5727169513702393,0.5588959455490112,0.5740451216697693,0.561470627784729,0.562539279460907,0.5565979480743408,0.5698691010475159,0.5733655691146851,0.561973512172699,0.5398918390274048,0.5421227812767029,0.561119794845581,0.5571923851966858,0.5678790211677551,0.5555738210678101,0.5487163066864014,0.5228685140609741,0.5260919332504272,0.5576508045196533,0.5593429803848267,0.5589420199394226,0.5518704652786255,0.5509471297264099,0.5365490913391113,0.538544774055481,0.5431482195854187,0.5453993678092957,0.5459819436073303,0.5426220893859863,0.5443883538246155,0.5492708683013916,0.5482609272003174,0.5384288430213928,0.5275743007659912,0.5232129096984863,0.5211122632026672,0.5182026624679565,0.5157230496406555,0.5174535512924194,0.5270727276802063,0.5291840434074402,0.5255782008171082,0.5307917594909668,0.5327817797660828,0.5392497181892395,0.525474488735199,0.5203279852867126,0.5315091609954834,0.5399113297462463,0.5501768589019775,0.5466333627700806,0.5476833581924438,0.5535875558853149,0.5475413799285889,0.537913978099823,0.5438845753669739,0.5453822016716003,0.5428376197814941,0.5384034514427185,0.5372710227966309,0.5439640879631042,0.542304277420044,0.5408084988594055,0.5380508899688721,0.5456151962280273,0.535075843334198,0.5397610664367676,0.5157198905944824,0.5243551135063171,0.5378358364105225,0.5483133792877197,0.5398045182228088,0.5413719415664673,0.5458528399467468,0.5313639640808105,0.5320310592651367,0.5393717288970947,0.5470213890075684,0.5423147678375244,0.5473110675811768,0.5431495308876038,0.5292472839355469,0.5319350957870483,0.5384878516197205,0.5372515916824341,0.5376685857772827,0.5457110404968262,0.550439178943634,0.5530145168304443,0.5530811548233032,0.5489521622657776,0.5434373617172241,0.545225203037262,0.5408583879470825,0.547048807144165,0.5548396110534668,0.5546848177909851,0.5388837456703186,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 4418      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 4420      
=================================================================
Total params: 8,838
Trainable params: 8,838
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 66        
=================================================================
Total params: 4,418
Trainable params: 4,418
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                96        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 4,420
Trainable params: 4,420
Non-trainable params: 0
_________________________________________________________________
