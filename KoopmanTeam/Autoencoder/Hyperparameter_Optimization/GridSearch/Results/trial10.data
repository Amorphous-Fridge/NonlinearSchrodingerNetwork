2021-06-25
loss,9.211915016174316,4.124303817749023,3.005974769592285,1.9190258979797363,2.1780173778533936,2.8739707469940186,2.120785713195801,1.9110805988311768,1.2715380191802979,1.4299812316894531,2.1563663482666016,1.0124998092651367,0.8640555739402771,1.2720401287078857,1.2274158000946045,1.2422094345092773,0.9111689925193787,0.7697358727455139,0.624596357345581,0.8127058148384094,0.7386291027069092,0.8893347978591919,0.8312900066375732,1.1436882019042969,0.8739615082740784,0.7974551320075989,0.7258113622665405,0.88396155834198,1.1346206665039062,1.4416142702102661,0.9224526286125183,0.9146831035614014,0.7321005463600159,0.80254065990448,0.9814232587814331,0.7460476756095886,0.7440831065177917,0.6755353808403015,0.6244699358940125,0.7021351456642151,1.168542742729187,0.9590194225311279,0.6673880219459534,0.5966220498085022,1.0223058462142944,0.724773108959198,0.7438018321990967,0.8171874284744263,0.6713659763336182,0.6030351519584656,0.6821945309638977,0.6794378161430359,1.0095428228378296,0.6747025847434998,0.7134608626365662,0.5827311873435974,0.6435103416442871,1.2417480945587158,0.7570268511772156,0.6677333116531372,0.6246663928031921,0.6529113054275513,0.60235595703125,0.6861279010772705,0.6471797227859497,0.5535640120506287,0.5189244747161865,0.5167532563209534,0.701073169708252,1.3854938745498657,0.8053273558616638,0.7115761637687683,0.7047238349914551,0.8316907286643982,0.6772741079330444,0.796773374080658,0.6483203768730164,0.6247766017913818,0.6542043089866638,0.5876880884170532,0.6579118371009827,0.7840260863304138,0.5388789176940918,0.5523597598075867,0.6526799201965332,0.6207619309425354,0.5753755569458008,0.6458150744438171,0.4971708655357361,0.5164797306060791,0.515328586101532,0.7419469952583313,0.7179682850837708,0.6916748285293579,0.5966053009033203,0.7599717974662781,0.7774035930633545,0.5654283761978149,0.6952887773513794,0.6726205348968506,
mse,0.6794940233230591,0.612368106842041,0.5513647794723511,0.49480998516082764,0.4951937794685364,0.5731052756309509,0.5755507946014404,0.5405981540679932,0.5225270390510559,0.482033371925354,0.5013177990913391,0.5058854222297668,0.49356043338775635,0.5022909641265869,0.5042620897293091,0.5205457806587219,0.5154127478599548,0.5145857334136963,0.5139066576957703,0.5162805914878845,0.5291779041290283,0.5327722430229187,0.5407195091247559,0.5545290112495422,0.5537107586860657,0.5544637441635132,0.5581676363945007,0.5587621331214905,0.5648153424263,0.5715637803077698,0.5696222186088562,0.5798270106315613,0.5775043368339539,0.5752020478248596,0.5759969353675842,0.5652753710746765,0.5740254521369934,0.5682355761528015,0.5705664157867432,0.57061767578125,0.5723240971565247,0.5715082287788391,0.5735210180282593,0.5754459500312805,0.5781818628311157,0.5690870881080627,0.5675451159477234,0.5705739855766296,0.5703539848327637,0.5772641897201538,0.5783937573432922,0.5764039754867554,0.5733490586280823,0.5689176321029663,0.5739753246307373,0.5784927606582642,0.5749773979187012,0.5803918838500977,0.5706978440284729,0.5670933723449707,0.5669053196907043,0.5645988583564758,0.5666940808296204,0.5696074962615967,0.5666685700416565,0.567380428314209,0.5527874827384949,0.5558623671531677,0.5554921627044678,0.575031578540802,0.5860268473625183,0.5833387970924377,0.5815982818603516,0.5797946453094482,0.5812941193580627,0.5690198540687561,0.5671099424362183,0.5687171816825867,0.5798956155776978,0.5767306685447693,0.5760551691055298,0.5781410336494446,0.584516704082489,0.5666787028312683,0.5699903964996338,0.5771963000297546,0.5746507048606873,0.5700747966766357,0.573880672454834,0.5759031176567078,0.5656525492668152,0.5689549446105957,0.5849181413650513,0.5834701061248779,0.5790157318115234,0.5780889987945557,0.580114483833313,0.5790048837661743,0.5787238478660583,0.5826318860054016,
mae,0.6951304078102112,0.6747190952301025,0.6048461198806763,0.5356659293174744,0.5302562117576599,0.5861104130744934,0.5780820250511169,0.5459165573120117,0.5256888270378113,0.490025132894516,0.49753111600875854,0.50200355052948,0.48798081278800964,0.49469760060310364,0.49457982182502747,0.5099620223045349,0.505302369594574,0.5041001439094543,0.5039690136909485,0.5066045522689819,0.516732394695282,0.5202872157096863,0.5279148817062378,0.5378890037536621,0.5390762686729431,0.5388933420181274,0.541658878326416,0.5443306565284729,0.5471899509429932,0.553636372089386,0.5515568256378174,0.5623852014541626,0.5605044364929199,0.5572257041931152,0.5600945949554443,0.5497574806213379,0.5548362135887146,0.550830602645874,0.5549329519271851,0.5533283352851868,0.5556678771972656,0.553422749042511,0.5539154410362244,0.5566646456718445,0.5594923496246338,0.550287127494812,0.5504816174507141,0.5518209338188171,0.5529940128326416,0.5579793453216553,0.5599687695503235,0.5563077330589294,0.5565307140350342,0.5512909889221191,0.5553719997406006,0.5588072538375854,0.5548245310783386,0.562341570854187,0.554175615310669,0.5486860871315002,0.5498673915863037,0.5479620099067688,0.5479875802993774,0.5506881475448608,0.5504510998725891,0.5556581020355225,0.5389547944068909,0.5374854803085327,0.5379629731178284,0.553511381149292,0.566530704498291,0.5665817856788635,0.5613362789154053,0.5595902800559998,0.5615798830986023,0.5514077544212341,0.5502120852470398,0.5516882538795471,0.561802089214325,0.5615788102149963,0.5591083765029907,0.5598602890968323,0.5630181431770325,0.5479385852813721,0.552201509475708,0.5580807328224182,0.5556038022041321,0.5533074140548706,0.5569397211074829,0.5572465062141418,0.5470914244651794,0.5499271154403687,0.5644007325172424,0.5627610087394714,0.5597420334815979,0.5589351654052734,0.5610604286193848,0.5588110089302063,0.5600361227989197,0.5638952851295471,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 6402      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6404      
=================================================================
Total params: 12,806
Trainable params: 12,806
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 6,402
Trainable params: 6,402
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 6,404
Trainable params: 6,404
Non-trainable params: 0
_________________________________________________________________
