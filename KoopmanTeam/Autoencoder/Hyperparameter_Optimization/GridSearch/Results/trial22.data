2021-06-25
loss,13.869195938110352,5.151805400848389,6.783963680267334,4.315422534942627,4.641256332397461,3.0622081756591797,3.20751953125,2.0460779666900635,1.9236323833465576,2.13411545753479,1.1018729209899902,1.0700832605361938,1.1673269271850586,1.2145746946334839,0.9016548991203308,1.1662019491195679,1.0981866121292114,0.9077214002609253,0.939612865447998,1.8018969297409058,1.6832351684570312,1.3706103563308716,0.9902425408363342,0.7572850584983826,0.8204362392425537,1.3437739610671997,1.2089847326278687,0.7841817736625671,1.0229586362838745,1.0447381734848022,0.8356329202651978,0.7407047748565674,0.7488201856613159,0.7434887886047363,0.6852928996086121,0.6993939876556396,0.9103676676750183,0.9986879825592041,1.8391364812850952,1.3037467002868652,0.8777680993080139,0.7708119750022888,0.7598525285720825,0.9665457010269165,0.6158128976821899,1.2355724573135376,0.8879942893981934,0.8325541615486145,0.8105359077453613,1.547285795211792,1.4201087951660156,0.7927373647689819,0.6209926009178162,0.6441941857337952,0.5362710356712341,0.487592875957489,0.571927547454834,0.712796151638031,1.3876063823699951,0.8671362996101379,0.757343053817749,0.7728897929191589,0.6288963556289673,0.6592715978622437,0.8315115571022034,0.7995610237121582,0.7256548404693604,0.7997202277183533,0.6584978699684143,0.645202100276947,0.6159612536430359,0.5173913836479187,0.4712979793548584,1.0048149824142456,0.6982839107513428,0.8228446841239929,0.6174588203430176,0.7041739821434021,0.6050297617912292,0.5685644149780273,0.5027404427528381,0.8196192979812622,1.3175288438796997,1.2630910873413086,0.8691285848617554,0.6798995733261108,0.49125802516937256,0.5580199360847473,0.8761218786239624,0.5258914828300476,0.4817894697189331,0.5840046405792236,0.6825112700462341,0.5587642192840576,0.5731002688407898,0.5560057163238525,0.7174223065376282,0.5349471569061279,0.5344300270080566,0.544877290725708,
mse,0.7372496724128723,0.5955032110214233,0.5033847093582153,0.5568972826004028,0.5270313024520874,0.6348883509635925,0.5368166565895081,0.5255415439605713,0.5310866832733154,0.5532019138336182,0.5399327278137207,0.5464271903038025,0.5647320747375488,0.5710996985435486,0.5712729692459106,0.572252631187439,0.581814706325531,0.568527102470398,0.5774931311607361,0.5853233337402344,0.5680809020996094,0.5397294759750366,0.5595114827156067,0.5632568597793579,0.5708812475204468,0.5612728595733643,0.5618144869804382,0.583528995513916,0.5852403044700623,0.5843752026557922,0.5701671838760376,0.5691298842430115,0.5771462917327881,0.577487587928772,0.5838830471038818,0.5849323272705078,0.5927274227142334,0.5983876585960388,0.5976371169090271,0.6024008989334106,0.5945374965667725,0.5875351428985596,0.5820001363754272,0.5864771008491516,0.5898084044456482,0.5919925570487976,0.599765956401825,0.5825051665306091,0.5921931266784668,0.5894381999969482,0.5511984825134277,0.5619775652885437,0.5635507106781006,0.5718576908111572,0.5782358646392822,0.5758562684059143,0.5760464668273926,0.5671117901802063,0.5572616457939148,0.5792170166969299,0.5818791389465332,0.5802709460258484,0.5813808441162109,0.578392744064331,0.5802198052406311,0.5827818512916565,0.5883171558380127,0.5880875587463379,0.5859786868095398,0.5816792845726013,0.5785142183303833,0.576271653175354,0.5830457210540771,0.5842145085334778,0.5969207286834717,0.578791618347168,0.5639345645904541,0.5687121748924255,0.5709332227706909,0.5680503249168396,0.5698409080505371,0.5774729251861572,0.5589886903762817,0.5445655584335327,0.5532494187355042,0.5593442320823669,0.5629323720932007,0.5584855079650879,0.5697588920593262,0.5774239897727966,0.572155237197876,0.5700584650039673,0.5624246597290039,0.5619239807128906,0.5656586289405823,0.5691290497779846,0.5739725232124329,0.5731326937675476,0.5752434730529785,0.5777820348739624,
mae,0.7082121968269348,0.6386066675186157,0.5612154006958008,0.5786437392234802,0.560778796672821,0.6097458004951477,0.531685471534729,0.5194299817085266,0.5241933465003967,0.5475412607192993,0.5266917943954468,0.5321650505065918,0.5482667684555054,0.5550708174705505,0.5538429021835327,0.5561748743057251,0.5633703470230103,0.5509375929832458,0.5604425668716431,0.5694663524627686,0.5571094751358032,0.5345905423164368,0.5465582013130188,0.5480718016624451,0.5536749362945557,0.5489561557769775,0.5444760918617249,0.5639824867248535,0.5647861361503601,0.5674021244049072,0.5546027421951294,0.552503228187561,0.5591442584991455,0.5587500929832458,0.5636547207832336,0.5642788410186768,0.5731832385063171,0.5782351493835449,0.5761367678642273,0.5814726948738098,0.5748975872993469,0.5690059065818787,0.5631852746009827,0.5665488243103027,0.5709553956985474,0.5705991983413696,0.5793008208274841,0.5636409521102905,0.5721492767333984,0.5732807517051697,0.5434489846229553,0.5464228987693787,0.5474123358726501,0.5541852116584778,0.558950662612915,0.5579149723052979,0.558042585849762,0.5514047145843506,0.5391696691513062,0.5586345195770264,0.564539909362793,0.5611221194267273,0.5632197856903076,0.5642307996749878,0.5618078708648682,0.5634459853172302,0.5697944760322571,0.5720652937889099,0.5659894943237305,0.5612804293632507,0.560451865196228,0.5569277405738831,0.563236653804779,0.5670928955078125,0.5731725096702576,0.5600569844245911,0.5457381010055542,0.5490244030952454,0.5532597303390503,0.5491834282875061,0.5519436001777649,0.5597759485244751,0.5506351590156555,0.5385466814041138,0.5391409397125244,0.5431204438209534,0.544894278049469,0.5412235260009766,0.5511607527732849,0.5589845180511475,0.5551590919494629,0.5556338429450989,0.5493057370185852,0.5467637777328491,0.5479306578636169,0.5492001175880432,0.5537577867507935,0.5529149770736694,0.5569168925285339,0.5571045875549316,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 27154     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 27156     
=================================================================
Total params: 54,310
Trainable params: 54,310
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 130       
=================================================================
Total params: 27,154
Trainable params: 27,154
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                192       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 27,156
Trainable params: 27,156
Non-trainable params: 0
_________________________________________________________________
