2021-06-25
loss,6.129915237426758,4.489589214324951,2.8188107013702393,2.5896706581115723,3.09035587310791,2.5776844024658203,2.013392686843872,2.5832974910736084,1.7886675596237183,2.0641515254974365,2.4467623233795166,2.3475637435913086,2.038546562194824,2.359386444091797,1.9111006259918213,2.047590970993042,1.3601552248001099,1.463571310043335,4.976919174194336,5.804971694946289,3.261441707611084,2.215374231338501,3.858415126800537,1.6715582609176636,3.35459566116333,1.574062466621399,1.2249928712844849,1.5821053981781006,1.2745521068572998,1.4484152793884277,1.0368787050247192,1.7316641807556152,1.209043025970459,1.2376688718795776,0.9471024870872498,1.6324495077133179,1.2408287525177002,0.9434332847595215,0.8847976922988892,1.7926743030548096,0.9452918767929077,0.8531644940376282,0.8701643347740173,1.0220248699188232,0.8865646123886108,0.854702889919281,0.6821198463439941,0.7753197550773621,0.7181944847106934,0.6911901235580444,0.833931028842926,0.6667404770851135,0.6348841786384583,1.017314076423645,0.941020667552948,0.8135076761245728,0.9794253706932068,1.1014121770858765,0.836046576499939,0.75690758228302,0.8668967485427856,0.6058118939399719,0.7169379591941833,0.7182824611663818,0.8786070942878723,0.7163820862770081,0.768922746181488,1.0067968368530273,0.765807569026947,0.4758128225803375,0.3902178704738617,0.6549335718154907,0.7139372825622559,0.4850130081176758,0.5340694785118103,0.5729146599769592,0.7360138893127441,0.7680732011795044,0.7146671414375305,0.890952467918396,0.6287630200386047,0.5638114213943481,0.7899234294891357,0.536175549030304,0.4441121220588684,0.4678691625595093,0.6107223629951477,0.5140435695648193,0.5801436901092529,0.5441905856132507,0.46139442920684814,0.6480312347412109,0.9215957522392273,0.7502449154853821,0.7360825538635254,0.6832433938980103,0.6524374485015869,0.5121448040008545,1.0173923969268799,0.9646594524383545,
mse,0.2739710211753845,0.3217606842517853,0.3008210361003876,0.24557174742221832,0.23182374238967896,0.21631263196468353,0.1925516128540039,0.18414050340652466,0.18564549088478088,0.1599804311990738,0.18921484053134918,0.16133926808834076,0.15265166759490967,0.18637798726558685,0.1911318600177765,0.17872434854507446,0.17539814114570618,0.16895170509815216,0.19419090449810028,0.22192323207855225,0.17986994981765747,0.1130155622959137,0.09129850566387177,0.08490623533725739,0.08328689634799957,0.0969388484954834,0.11006804555654526,0.10128480941057205,0.09670145809650421,0.08453712612390518,0.08576676994562149,0.08869560062885284,0.08797072619199753,0.08806899935007095,0.07267738878726959,0.0772831067442894,0.06837537884712219,0.07895796000957489,0.07369038462638855,0.07113177329301834,0.06773366779088974,0.05436316132545471,0.04730058088898659,0.049448732286691666,0.046656541526317596,0.043228160589933395,0.04300994053483009,0.04218735173344612,0.04074354097247124,0.042412951588630676,0.0411103256046772,0.042169176042079926,0.040579188615083694,0.042326994240283966,0.04126922786235809,0.03912610188126564,0.03932132571935654,0.03974112123250961,0.03950590267777443,0.03669211268424988,0.03676917031407356,0.035453323274850845,0.03491552546620369,0.037885233759880066,0.03791163116693497,0.03879960626363754,0.03971818834543228,0.03857964649796486,0.03634743392467499,0.03652701899409294,0.03494596108794212,0.03666872903704643,0.035928960889577866,0.036447543650865555,0.03457830473780632,0.034172121435403824,0.035359084606170654,0.035098735243082047,0.03736408054828644,0.0384230799973011,0.035846222192049026,0.0351773239672184,0.03674973547458649,0.03280334174633026,0.033665359020233154,0.03375869616866112,0.03423692286014557,0.03489195927977562,0.035227078944444656,0.034186623990535736,0.03401542082428932,0.035492267459630966,0.0356239452958107,0.03779730200767517,0.037079159170389175,0.03500142693519592,0.03684790059924126,0.03611874207854271,0.038291819393634796,0.03727615252137184,
mae,0.4178592562675476,0.46998175978660583,0.43903377652168274,0.3823045790195465,0.3576306998729706,0.33431193232536316,0.3081844449043274,0.30582132935523987,0.294575572013855,0.2623137831687927,0.28848326206207275,0.270963191986084,0.2561303377151489,0.28552693128585815,0.28733742237091064,0.27860769629478455,0.2739233076572418,0.26965874433517456,0.3272562026977539,0.3757738769054413,0.34503287076950073,0.26860448718070984,0.24755436182022095,0.2336631417274475,0.2190818041563034,0.23271070420742035,0.2314148098230362,0.22402356564998627,0.22348356246948242,0.21248938143253326,0.2120376080274582,0.21359314024448395,0.2119840681552887,0.20748983323574066,0.20141081511974335,0.20205695927143097,0.19366781413555145,0.20506685972213745,0.19937826693058014,0.19743287563323975,0.19262033700942993,0.182204470038414,0.16861437261104584,0.16998694837093353,0.16678011417388916,0.1615690290927887,0.16025269031524658,0.15732289850711823,0.15560844540596008,0.15874622762203217,0.15524572134017944,0.15738730132579803,0.15500397980213165,0.15775835514068604,0.15607470273971558,0.1519857794046402,0.15211430191993713,0.15297256410121918,0.15132227540016174,0.14589117467403412,0.14560438692569733,0.1463717818260193,0.1431417018175125,0.14743410050868988,0.14800286293029785,0.15104295313358307,0.15161271393299103,0.1488719880580902,0.14404016733169556,0.14402247965335846,0.14210562407970428,0.14372684061527252,0.14207130670547485,0.14462602138519287,0.14013127982616425,0.1394066959619522,0.13918213546276093,0.1394488364458084,0.1452624797821045,0.14600175619125366,0.14077749848365784,0.14006537199020386,0.14210814237594604,0.13471010327339172,0.13623285293579102,0.13534985482692719,0.1379586160182953,0.13929887115955353,0.13890546560287476,0.13714361190795898,0.13645830750465393,0.14117079973220825,0.14078116416931152,0.14524929225444794,0.1410985141992569,0.13849863409996033,0.14188417792320251,0.14041076600551605,0.14750516414642334,0.14502117037773132,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 3346      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3348      
=================================================================
Total params: 6,694
Trainable params: 6,694
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 3,346
Trainable params: 3,346
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 3,348
Trainable params: 3,348
Non-trainable params: 0
_________________________________________________________________
