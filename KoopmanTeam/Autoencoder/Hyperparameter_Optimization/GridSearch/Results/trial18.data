2021-06-25
loss,10.152828216552734,3.5227842330932617,1.7701804637908936,1.4708564281463623,2.0109193325042725,1.327040433883667,1.3121964931488037,1.8755602836608887,1.5261348485946655,3.486220359802246,5.8610310554504395,8.245987892150879,3.228261709213257,5.295130729675293,1.5406230688095093,1.0754616260528564,1.1402831077575684,0.983933687210083,1.2183728218078613,1.1147392988204956,1.0643061399459839,0.8290697336196899,0.9269202947616577,0.7583321928977966,1.3453688621520996,0.8441470265388489,0.7884175181388855,1.3343985080718994,1.7915769815444946,2.5272433757781982,1.265620470046997,0.6632937788963318,0.607323944568634,0.6193059086799622,1.0671086311340332,0.953481137752533,1.0873808860778809,1.0605608224868774,0.9438225626945496,0.8059289455413818,0.6787864565849304,0.7181863188743591,0.742353081703186,0.7588818073272705,0.789044976234436,1.2953583002090454,1.2683212757110596,1.066314458847046,0.7574317455291748,0.7323598265647888,0.7057121396064758,0.784472644329071,0.6681352257728577,0.591478705406189,0.6628515720367432,0.5913326144218445,0.5791161060333252,0.6887643337249756,0.7154191732406616,1.4337915182113647,1.0466642379760742,0.9743881821632385,0.7494572997093201,0.6995130777359009,0.8188428282737732,0.7460480332374573,0.9752513766288757,0.696462094783783,0.7815112471580505,0.6524109840393066,0.5597243309020996,0.6175937652587891,0.5933035016059875,0.6378020644187927,0.867501974105835,1.2898401021957397,0.757377028465271,0.623063862323761,0.7439736723899841,0.8232683539390564,0.8109927177429199,0.7837859988212585,0.8252607583999634,0.4556044340133667,0.47507038712501526,0.796949028968811,0.9094745516777039,0.7339603304862976,0.5749807953834534,0.7302263379096985,0.7408983707427979,0.6339995861053467,0.6258440613746643,0.5968413352966309,0.7377616167068481,0.7179517149925232,0.7158163189888,1.023926854133606,0.6582906246185303,0.823695957660675,
mse,0.5414751172065735,0.5511776208877563,0.5525513291358948,0.5516197681427002,0.549048900604248,0.5775189399719238,0.5625597238540649,0.5710093975067139,0.585166335105896,0.6033498644828796,0.6319068670272827,0.6902929544448853,0.6965526342391968,0.6815891265869141,0.7086864709854126,0.6995388269424438,0.6964048743247986,0.6916438937187195,0.6835260987281799,0.687009334564209,0.6900948286056519,0.6827626824378967,0.6781374216079712,0.6825356483459473,0.6817389726638794,0.6787092685699463,0.6829267740249634,0.6822094917297363,0.654472827911377,0.6644966006278992,0.676684558391571,0.6805912256240845,0.6821330189704895,0.6845144033432007,0.6854910254478455,0.686598002910614,0.6971988677978516,0.7015644907951355,0.697580873966217,0.6985836029052734,0.6986625790596008,0.6992000341415405,0.6952170729637146,0.7003585696220398,0.7103607058525085,0.6994880437850952,0.7085884213447571,0.695264458656311,0.7081342339515686,0.7076758742332458,0.7128020524978638,0.7110262513160706,0.6906388998031616,0.6991820335388184,0.7021206021308899,0.7083265781402588,0.7076830267906189,0.7097588181495667,0.7069356441497803,0.6782076358795166,0.687743067741394,0.7055367231369019,0.7093710899353027,0.7073246240615845,0.7087972164154053,0.7081300616264343,0.7156643867492676,0.7175253033638,0.7109287977218628,0.7135688066482544,0.7102985382080078,0.7066998481750488,0.7089756727218628,0.7132617235183716,0.7212209105491638,0.7204166650772095,0.7135767936706543,0.7135867476463318,0.7161314487457275,0.7162224650382996,0.7195208072662354,0.7183266282081604,0.7224774956703186,0.7149541974067688,0.6992732286453247,0.6894991993904114,0.7159441113471985,0.7175012826919556,0.7132139801979065,0.7133170366287231,0.7227306962013245,0.7250365614891052,0.7212463617324829,0.7147840857505798,0.7170730829238892,0.709689736366272,0.723747193813324,0.7139192223548889,0.7128041982650757,0.715862512588501,
mae,0.5871990323066711,0.573154091835022,0.5634161829948425,0.5452558994293213,0.5356659293174744,0.5576780438423157,0.5466877222061157,0.5536021590232849,0.5627168416976929,0.5874107480049133,0.6071521639823914,0.6782932877540588,0.6711877584457397,0.6347821950912476,0.6769508123397827,0.6703460216522217,0.6668403148651123,0.6576284766197205,0.6505751609802246,0.6534292697906494,0.6571313738822937,0.6507898569107056,0.6490240693092346,0.6525217294692993,0.6531796455383301,0.6499674320220947,0.6575323343276978,0.6511918902397156,0.6218388080596924,0.6206578016281128,0.6426642537117004,0.6473042964935303,0.6472511291503906,0.6499086618423462,0.6492514610290527,0.6552889943122864,0.6605590581893921,0.6614679098129272,0.6578599810600281,0.6581236124038696,0.6578088402748108,0.6559022665023804,0.6499903798103333,0.6562396883964539,0.6566753387451172,0.6510396003723145,0.6571655869483948,0.6524228453636169,0.6556093096733093,0.6583805084228516,0.6641125679016113,0.6644300222396851,0.6445965766906738,0.6505668759346008,0.6510859131813049,0.6555436849594116,0.6578658819198608,0.656375527381897,0.6559500694274902,0.6448854804039001,0.6462061405181885,0.6553791761398315,0.6574257612228394,0.655924916267395,0.6554668545722961,0.655113160610199,0.6599739789962769,0.6681357622146606,0.6606425642967224,0.6600425243377686,0.6580671072006226,0.6602876782417297,0.6590449810028076,0.6658473014831543,0.669989824295044,0.6647817492485046,0.6631752252578735,0.658210277557373,0.6619802117347717,0.6648856997489929,0.6653030514717102,0.6671730279922485,0.6705193519592285,0.671551525592804,0.6590960025787354,0.655796229839325,0.6722112894058228,0.6717756390571594,0.6648343801498413,0.6678965091705322,0.6667883396148682,0.6700659990310669,0.6672683954238892,0.6659008860588074,0.6670902967453003,0.6600621938705444,0.6666656732559204,0.663550615310669,0.6658418774604797,0.6672380566596985,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 20866     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 20868     
=================================================================
Total params: 41,734
Trainable params: 41,734
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 20,866
Trainable params: 20,866
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 20,868
Trainable params: 20,868
Non-trainable params: 0
_________________________________________________________________
