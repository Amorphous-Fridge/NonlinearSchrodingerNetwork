2021-06-25
loss,6.226278305053711,3.4034476280212402,2.282379150390625,2.972630023956299,2.0664472579956055,3.3515655994415283,1.321319580078125,2.3093738555908203,1.3719651699066162,1.58412504196167,1.0474497079849243,0.8168617486953735,1.7480839490890503,0.891710638999939,0.9031168222427368,1.100620150566101,1.1643840074539185,0.7308409810066223,0.7795405387878418,1.0266073942184448,0.8173750042915344,0.7888301610946655,0.7768780589103699,0.7319148778915405,0.7110269665718079,0.7099841833114624,0.926842451095581,1.1663422584533691,1.5624371767044067,1.5083670616149902,0.9129236340522766,0.7736023664474487,0.6473819017410278,0.7864646911621094,0.6209967732429504,1.0428037643432617,0.9491464495658875,0.9144052267074585,0.9400689601898193,0.7710419297218323,0.8626754879951477,0.6939308047294617,0.8468165397644043,0.7024470567703247,0.6216719150543213,0.9919828772544861,0.7919006943702698,0.6199281215667725,0.7379330992698669,0.5587267279624939,0.4423917531967163,0.5840439796447754,0.6813852787017822,0.9586366415023804,0.5875846147537231,0.7713306546211243,0.7383463382720947,0.5997629165649414,0.5338341593742371,0.6223872900009155,0.653744637966156,0.5507152080535889,0.4657835364341736,0.5074387788772583,0.9694266319274902,0.651017963886261,0.5827264189720154,0.5407480001449585,0.5224722027778625,0.8515757918357849,0.7645818591117859,0.7202936410903931,0.8522328734397888,0.6511070728302002,0.5093691349029541,0.764922022819519,0.6105431914329529,0.551435112953186,0.5025598406791687,0.5859377384185791,0.7252925038337708,1.8472511768341064,8.945793151855469,3.2122750282287598,1.657427191734314,1.8047294616699219,1.2018370628356934,0.9199709892272949,0.7188295125961304,0.6773664355278015,0.6810411810874939,0.5602098703384399,0.5833348035812378,0.584892988204956,0.8586180210113525,0.7682163119316101,0.6681913137435913,0.5098242163658142,0.7068696618080139,0.7947272658348083,
mse,0.5278809070587158,0.5406410098075867,0.5698368549346924,0.48132559657096863,0.45113250613212585,0.5139657258987427,0.5404026508331299,0.5601619482040405,0.5760486721992493,0.5802449584007263,0.5789430141448975,0.566719651222229,0.5651775598526001,0.5726772546768188,0.5804394483566284,0.5751893520355225,0.592094898223877,0.5933601260185242,0.5769457221031189,0.5773170590400696,0.582109272480011,0.5745426416397095,0.5830495357513428,0.5842002630233765,0.5814256072044373,0.5839571952819824,0.5894008874893188,0.6049960255622864,0.5702101588249207,0.5935494899749756,0.6126230359077454,0.6066319346427917,0.6063171029090881,0.6044117212295532,0.5998122096061707,0.5928640961647034,0.5967451930046082,0.6038200259208679,0.6077533960342407,0.5926639437675476,0.5938799977302551,0.6007842421531677,0.5987430214881897,0.5925832986831665,0.5891390442848206,0.5951033234596252,0.6036895513534546,0.6051077842712402,0.6035836935043335,0.6008145809173584,0.5984925627708435,0.6013513803482056,0.6010765433311462,0.6001182794570923,0.5895114541053772,0.5899562239646912,0.5877847671508789,0.5827679634094238,0.5858582258224487,0.5890251398086548,0.5936928987503052,0.5956619381904602,0.5923641324043274,0.5898227095603943,0.5924885869026184,0.6039423942565918,0.6013143062591553,0.6001174449920654,0.6005235314369202,0.5691367387771606,0.5774389505386353,0.5878174304962158,0.5946605801582336,0.593029260635376,0.5950855016708374,0.5955371260643005,0.6006238460540771,0.5980539321899414,0.5944368839263916,0.5874172449111938,0.5959516763687134,0.6057776212692261,0.5299553871154785,0.5603485107421875,0.563915491104126,0.5412692427635193,0.4804360270500183,0.47293469309806824,0.4883175194263458,0.49802589416503906,0.5017318725585938,0.502783477306366,0.5032455921173096,0.4971385896205902,0.5078884959220886,0.5133588314056396,0.5180652141571045,0.5149382948875427,0.5077862739562988,0.5231814384460449,
mae,0.5540660619735718,0.5535482168197632,0.5691608190536499,0.5181413888931274,0.4852887690067291,0.5223344564437866,0.5332115292549133,0.5488253235816956,0.5618002414703369,0.5643376111984253,0.5654585957527161,0.5518217086791992,0.5523686408996582,0.5590585470199585,0.5649755001068115,0.5600376725196838,0.5707321763038635,0.5739039182662964,0.5661782026290894,0.5595636367797852,0.5625411868095398,0.5560269355773926,0.5647679567337036,0.5652175545692444,0.5615732669830322,0.5643203854560852,0.5700889825820923,0.5862917304039001,0.5570222735404968,0.5743816494941711,0.5887420177459717,0.5845606327056885,0.5850850343704224,0.5841018557548523,0.5799611806869507,0.5721595883369446,0.5778090357780457,0.5845726132392883,0.5877202749252319,0.5732861757278442,0.5742981433868408,0.5805422067642212,0.5779315829277039,0.5701979994773865,0.5714361667633057,0.5762819051742554,0.5846261978149414,0.5854363441467285,0.5828590989112854,0.5821183323860168,0.5794702172279358,0.5811542868614197,0.5803630352020264,0.5796170234680176,0.570395290851593,0.5735910534858704,0.5689447522163391,0.5610896944999695,0.5667859315872192,0.5698978304862976,0.5738540887832642,0.5761566162109375,0.5725631713867188,0.5708353519439697,0.5718209743499756,0.5826961398124695,0.5800694823265076,0.5800331234931946,0.5815243124961853,0.5532266497612,0.5589153170585632,0.5685617923736572,0.573905885219574,0.5722101330757141,0.5743784308433533,0.5745757818222046,0.5784611105918884,0.5767608284950256,0.5724086165428162,0.5680953860282898,0.5765470862388611,0.5929944515228271,0.5747398734092712,0.5529028177261353,0.5670503377914429,0.5549240112304688,0.5149571895599365,0.5003526210784912,0.506473183631897,0.5119547843933105,0.5128517150878906,0.5156866312026978,0.5123192071914673,0.5023456811904907,0.5118203163146973,0.5159927606582642,0.5167164206504822,0.5092064142227173,0.504800021648407,0.5133387446403503,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 6482      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6484      
=================================================================
Total params: 12,966
Trainable params: 12,966
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 6,482
Trainable params: 6,482
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 6,484
Trainable params: 6,484
Non-trainable params: 0
_________________________________________________________________
