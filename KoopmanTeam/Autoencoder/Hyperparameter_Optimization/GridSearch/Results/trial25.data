2021-06-25
loss,8.203490257263184,6.204047679901123,3.0376498699188232,4.2497239112854,3.272815227508545,2.5358824729919434,2.105219841003418,2.6279144287109375,2.067499876022339,2.055372953414917,2.4845170974731445,2.936812400817871,2.399751901626587,1.7594130039215088,2.31660795211792,1.6232233047485352,1.6895272731781006,1.5369006395339966,1.8941913843154907,1.399346947669983,1.533747911453247,1.390630841255188,1.2774803638458252,1.6113392114639282,1.3838281631469727,1.5301764011383057,1.5293054580688477,1.7343019247055054,1.3318272829055786,1.1494804620742798,0.9431613087654114,1.4686799049377441,1.7772811651229858,0.9483255743980408,1.1345170736312866,1.148680329322815,1.0429837703704834,1.0023188591003418,0.9669880867004395,0.7773275971412659,0.5953818559646606,1.422387957572937,0.7280027270317078,0.5939851999282837,0.710376501083374,0.5872287154197693,1.0533647537231445,0.944907546043396,0.6079827547073364,0.5130066871643066,0.8664979338645935,0.728165864944458,0.8341186046600342,0.7800695300102234,0.5795923471450806,0.5998358130455017,0.5711860060691833,0.546575129032135,0.6333781480789185,0.7779837846755981,0.8618943691253662,0.9366708993911743,0.7227668166160583,1.3743401765823364,0.625062882900238,0.5924912691116333,0.5466046929359436,0.7564618587493896,0.598665714263916,0.6370784640312195,0.5210875272750854,0.5216162204742432,0.5325420498847961,0.5304834246635437,0.5890111327171326,0.8224716186523438,0.427704393863678,0.7046551704406738,0.7370969653129578,0.7311649918556213,0.5491427779197693,0.556797444820404,0.5426098108291626,0.5259740948677063,0.6368247866630554,1.022404432296753,0.6602003574371338,0.5428354740142822,0.5942731499671936,0.5738534927368164,0.584644615650177,0.5264879465103149,0.7019885182380676,0.6938694715499878,0.5351619720458984,0.49235209822654724,0.6237704753875732,0.5721853375434875,0.6980398297309875,0.4857214391231537,
mse,0.5046141147613525,0.4654393792152405,0.5120382905006409,0.5124843120574951,0.485082745552063,0.5282182097434998,0.5722585320472717,0.5736366510391235,0.5673722624778748,0.5844079852104187,0.598604679107666,0.5513812899589539,0.5048388838768005,0.554029107093811,0.5699394345283508,0.5592115521430969,0.5348090529441833,0.5542256236076355,0.5511621236801147,0.5462653636932373,0.5014856457710266,0.48628178238868713,0.47649821639060974,0.4716211259365082,0.500899612903595,0.4770594835281372,0.46951183676719666,0.4653373658657074,0.47106051445007324,0.44788098335266113,0.4460589289665222,0.42681530117988586,0.3862283229827881,0.43136584758758545,0.4244827330112457,0.42190536856651306,0.4152599275112152,0.4255143702030182,0.4132671058177948,0.4119996130466461,0.4133671820163727,0.413960337638855,0.4024229943752289,0.40080955624580383,0.40806350111961365,0.4112468957901001,0.4101109206676483,0.40756484866142273,0.41304951906204224,0.4172816872596741,0.420438677072525,0.40730151534080505,0.42397332191467285,0.4297579824924469,0.4256194829940796,0.4261115789413452,0.42772284150123596,0.4313095211982727,0.4191814363002777,0.4197743535041809,0.4312513768672943,0.43747156858444214,0.42938849329948425,0.4361436367034912,0.4617933928966522,0.44206559658050537,0.44399821758270264,0.4454782009124756,0.4473026394844055,0.45245856046676636,0.45264118909835815,0.4432786703109741,0.45627322793006897,0.45563551783561707,0.4519341289997101,0.45115044713020325,0.4567175805568695,0.4502895772457123,0.46108028292655945,0.46564629673957825,0.45766064524650574,0.46218037605285645,0.46388545632362366,0.45969244837760925,0.4620192050933838,0.46947768330574036,0.4673074781894684,0.4659186601638794,0.4780457019805908,0.46359896659851074,0.4519200921058655,0.466511070728302,0.4606929421424866,0.45911774039268494,0.45576098561286926,0.464344322681427,0.4737292230129242,0.4657902419567108,0.46958887577056885,0.47446078062057495,
mae,0.5697144865989685,0.5185570120811462,0.5324118733406067,0.5265892744064331,0.5145049691200256,0.5373565554618835,0.5669262409210205,0.5609778761863708,0.5527575016021729,0.5634805560112,0.5788447856903076,0.5411850810050964,0.5029251575469971,0.5431310534477234,0.5510632991790771,0.5383187532424927,0.5212587118148804,0.5338203310966492,0.5338807106018066,0.530887246131897,0.5091046094894409,0.4959745407104492,0.48927098512649536,0.4860400855541229,0.5176936388015747,0.49395477771759033,0.4844597280025482,0.4833262264728546,0.48212382197380066,0.46107006072998047,0.4595685303211212,0.4510537385940552,0.4341438412666321,0.44948849081993103,0.4418081045150757,0.43667179346084595,0.43216297030448914,0.4367735981941223,0.42870062589645386,0.4175313711166382,0.42060521245002747,0.434444785118103,0.41030600666999817,0.40384379029273987,0.41207897663116455,0.41360437870025635,0.42024844884872437,0.4245713949203491,0.41022127866744995,0.40911582112312317,0.41434264183044434,0.4005112051963806,0.41653957962989807,0.4249168038368225,0.41707760095596313,0.41781365871429443,0.4185613691806793,0.42156994342803955,0.4132072329521179,0.4214206337928772,0.43562081456184387,0.43908238410949707,0.4292393624782562,0.44429147243499756,0.4528355896472931,0.4339471757411957,0.4373086094856262,0.4365216791629791,0.4400097727775574,0.44473540782928467,0.4440772235393524,0.43727654218673706,0.44788098335266113,0.4451134502887726,0.4491121768951416,0.4416532516479492,0.4491816461086273,0.44460582733154297,0.4504191279411316,0.4555012881755829,0.44642889499664307,0.4520151913166046,0.4529721736907959,0.4482499361038208,0.4504753053188324,0.4669499099254608,0.46151623129844666,0.4583369791507721,0.4706646203994751,0.4540046453475952,0.4463275969028473,0.4535062313079834,0.4550260603427887,0.45568156242370605,0.45087987184524536,0.45840463042259216,0.46174079179763794,0.4553496241569519,0.4585259258747101,0.46341925859451294,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 21010     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 21012     
=================================================================
Total params: 42,022
Trainable params: 42,022
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 130       
=================================================================
Total params: 21,010
Trainable params: 21,010
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                192       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 21,012
Trainable params: 21,012
Non-trainable params: 0
_________________________________________________________________
