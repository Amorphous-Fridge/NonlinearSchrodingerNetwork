2021-06-25
loss,13.662240982055664,6.52072286605835,6.746853828430176,5.608025550842285,4.175356864929199,4.8282623291015625,5.039990425109863,4.905948638916016,5.432614803314209,5.150977611541748,2.872462511062622,3.374769926071167,2.519535779953003,1.6431711912155151,2.885915517807007,1.913875937461853,1.8309146165847778,2.6164960861206055,3.229504346847534,2.1526172161102295,2.1241626739501953,4.448770046234131,2.751762628555298,1.958181619644165,0.9969438910484314,0.8323700428009033,1.3297243118286133,1.4505006074905396,0.9400985240936279,1.112087368965149,0.89975905418396,0.6749733090400696,0.7147849798202515,0.8068394660949707,1.151410698890686,1.103009819984436,1.6995112895965576,2.2781946659088135,1.413732886314392,1.0422168970108032,0.7259165048599243,0.8807944655418396,1.4022105932235718,1.0238662958145142,1.384507656097412,1.8382666110992432,1.207842230796814,1.1772483587265015,1.213442325592041,0.8589972853660583,0.6872563362121582,0.9431650638580322,1.2496932744979858,0.8551453351974487,0.9766843318939209,1.2325290441513062,0.7269090414047241,0.7330158948898315,1.0405545234680176,1.0111653804779053,1.1832852363586426,1.2364941835403442,0.8425467610359192,0.7822589874267578,0.676137387752533,0.8558815121650696,0.8823245763778687,0.7245844006538391,0.7246809601783752,0.9102739691734314,0.7349091172218323,0.9559683799743652,0.8243913054466248,0.6958876848220825,0.644355833530426,0.7783254384994507,0.925651490688324,0.640839695930481,0.904681384563446,0.7547618746757507,0.7019454836845398,0.6141427755355835,0.6175447106361389,0.6809330582618713,0.7412145137786865,0.6217871308326721,0.5694248080253601,0.7668766975402832,1.2893770933151245,1.045453667640686,0.6782925128936768,0.7635506391525269,0.5673647522926331,0.7843213081359863,0.6170616149902344,1.1973917484283447,1.1444792747497559,0.7574909329414368,0.6189517378807068,0.7440643310546875,
mse,0.5183901786804199,0.5805523991584778,0.580514669418335,0.5904643535614014,0.6496126651763916,0.5925148129463196,0.5970078110694885,0.6547146439552307,0.6504324078559875,0.7030983567237854,0.6083576083183289,0.6017934679985046,0.5293546915054321,0.5721256136894226,0.5643178820610046,0.5884210467338562,0.6291726231575012,0.6415088772773743,0.6506723165512085,0.573378324508667,0.6123448610305786,0.4475564658641815,0.46277710795402527,0.5852189660072327,0.5896320939064026,0.5908567309379578,0.5933708548545837,0.6023420095443726,0.6207728385925293,0.6236751675605774,0.6172549724578857,0.60597825050354,0.6073638200759888,0.5987294316291809,0.6147032380104065,0.6070538759231567,0.5795333385467529,0.6022436618804932,0.6188634634017944,0.6253475546836853,0.6189859509468079,0.6184298992156982,0.5872215628623962,0.605016827583313,0.6247976422309875,0.6250964403152466,0.6264244914054871,0.6042003035545349,0.6249163746833801,0.6257804036140442,0.6241231560707092,0.6296618580818176,0.6258150339126587,0.6260812878608704,0.6163826584815979,0.6309959888458252,0.5998263359069824,0.6060951352119446,0.606269896030426,0.6235045790672302,0.6301177144050598,0.625932514667511,0.6194557547569275,0.6205074787139893,0.6124587059020996,0.6014899611473083,0.6130844950675964,0.5984729528427124,0.6209605932235718,0.6332169771194458,0.6261451244354248,0.6265226602554321,0.6141523122787476,0.6233932971954346,0.6196938157081604,0.6126497387886047,0.6195244789123535,0.6181890964508057,0.6113640069961548,0.60760897397995,0.6164209246635437,0.6226466298103333,0.619555652141571,0.6149837970733643,0.6215503215789795,0.6191071271896362,0.6074597835540771,0.6203342080116272,0.594328761100769,0.6197671294212341,0.624521017074585,0.6164273619651794,0.6113524436950684,0.6142511963844299,0.6284856796264648,0.5905123353004456,0.5616024136543274,0.6001213192939758,0.5894975066184998,0.5861197113990784,
mae,0.5580753684043884,0.5750175714492798,0.5811506509780884,0.5778591632843018,0.6134384870529175,0.5693157911300659,0.5795663595199585,0.6526049971580505,0.6449058651924133,0.6941207051277161,0.5928813815116882,0.5883668065071106,0.5158628225326538,0.5540512204170227,0.5513484477996826,0.5707269906997681,0.6071218848228455,0.6343415975570679,0.6312620639801025,0.5578482151031494,0.5884708166122437,0.5105177164077759,0.4923619329929352,0.5681430697441101,0.5672788023948669,0.5692096948623657,0.5740920901298523,0.5795003771781921,0.5983527302742004,0.6008996367454529,0.595196008682251,0.5840286612510681,0.5856738090515137,0.576958417892456,0.5933801531791687,0.5854589939117432,0.5655531883239746,0.5807562470436096,0.5976063013076782,0.6022606492042542,0.5974936485290527,0.5960667133331299,0.5694584846496582,0.5853855013847351,0.599570631980896,0.6048405170440674,0.6020469069480896,0.5818853974342346,0.6011070609092712,0.5990618467330933,0.6003484129905701,0.6063517332077026,0.6024258136749268,0.6008288264274597,0.5941469073295593,0.6067191958427429,0.5820759534835815,0.582564115524292,0.5833279490470886,0.5995191335678101,0.6046851277351379,0.600570559501648,0.5939009189605713,0.5975134372711182,0.5903196930885315,0.5803210735321045,0.592814564704895,0.5753173232078552,0.5943774580955505,0.6044877171516418,0.6023106575012207,0.6035645008087158,0.589542806148529,0.5983433127403259,0.597375214099884,0.5896145105361938,0.5954777002334595,0.5968108177185059,0.5881502032279968,0.5849528312683105,0.5925233960151672,0.6005701422691345,0.5955495834350586,0.5919463634490967,0.5981992483139038,0.5952953100204468,0.5847674012184143,0.5979878306388855,0.5734350681304932,0.5956073999404907,0.601240873336792,0.5940287113189697,0.5890981554985046,0.5919754505157471,0.6066141128540039,0.5774592757225037,0.5499899387359619,0.5795766711235046,0.5686609745025635,0.5653176307678223,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 22962     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 22964     
=================================================================
Total params: 45,926
Trainable params: 45,926
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 66        
=================================================================
Total params: 22,962
Trainable params: 22,962
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                96        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 22,964
Trainable params: 22,964
Non-trainable params: 0
_________________________________________________________________
