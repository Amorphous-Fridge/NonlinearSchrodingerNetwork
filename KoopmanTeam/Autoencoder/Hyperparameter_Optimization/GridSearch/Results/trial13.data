2021-06-25
loss,6.438325881958008,3.8783719539642334,4.064228057861328,6.905354022979736,3.8856263160705566,2.7830922603607178,3.2136218547821045,1.738836646080017,2.201143264770508,1.8040753602981567,1.9342972040176392,2.0111284255981445,1.6256234645843506,1.5001252889633179,1.7611433267593384,5.213274002075195,6.84407901763916,2.4317572116851807,2.2176408767700195,1.916892647743225,1.4838876724243164,1.971083402633667,1.644025444984436,1.6881288290023804,1.5297759771347046,1.455899953842163,1.529670238494873,1.3447105884552002,1.3261467218399048,1.4470038414001465,1.6071170568466187,1.4068413972854614,1.1678913831710815,1.0315457582473755,1.3181524276733398,0.6998072266578674,0.7164725661277771,0.9205114245414734,0.6299728155136108,0.9663330912590027,0.7367189526557922,0.6758665442466736,1.0197722911834717,0.8169457316398621,0.6357578039169312,0.6388351321220398,0.648349404335022,1.0203185081481934,1.0992188453674316,0.5400309562683105,0.6301857233047485,0.5806624293327332,0.5425412058830261,0.5711292624473572,0.6133499145507812,0.6333125233650208,0.5716168880462646,0.6324827075004578,0.6000214219093323,0.5466362237930298,0.5548544526100159,0.5774571895599365,0.5318340063095093,0.5292222499847412,0.5845641493797302,0.5608203411102295,0.5540905594825745,0.5502315759658813,0.9527162909507751,1.3227859735488892,0.8598003387451172,0.54485684633255,0.5407407283782959,0.8193600177764893,0.5066644549369812,0.7840206623077393,0.819600522518158,0.5004206299781799,0.4910839796066284,0.6301137804985046,0.6135713458061218,0.46950623393058777,0.5404956340789795,0.44550323486328125,0.8009393215179443,0.628576397895813,0.7181500196456909,0.8097934722900391,0.5757861137390137,0.4711998403072357,0.52254319190979,0.531445324420929,0.4853089153766632,0.5900920629501343,0.4187295436859131,0.3755433261394501,0.37702006101608276,0.37241530418395996,0.42941814661026,0.4017736315727234,
mse,0.5671046376228333,0.5178332328796387,0.4956713914871216,0.5043171048164368,0.3971833288669586,0.43851637840270996,0.41214025020599365,0.4106937348842621,0.3766707181930542,0.3887999653816223,0.37159889936447144,0.4027164876461029,0.39335623383522034,0.3840169906616211,0.38838130235671997,0.3276834785938263,0.2159729152917862,0.2500980496406555,0.2858298718929291,0.28758856654167175,0.278262734413147,0.292228102684021,0.3190660774707794,0.3140832781791687,0.30994513630867004,0.32857757806777954,0.32524436712265015,0.347619891166687,0.35286930203437805,0.3590684235095978,0.3683505952358246,0.39278361201286316,0.3927605450153351,0.3909863233566284,0.4004933834075928,0.4143565893173218,0.4256012737751007,0.4245014190673828,0.43414074182510376,0.4352501332759857,0.44807785749435425,0.4514155089855194,0.45434555411338806,0.46012669801712036,0.46243205666542053,0.46833422780036926,0.46731090545654297,0.4622909426689148,0.48229682445526123,0.48131850361824036,0.4802631735801697,0.49321189522743225,0.4931790828704834,0.5029236674308777,0.5043507218360901,0.5075517892837524,0.509685754776001,0.5155571699142456,0.512633204460144,0.5131314992904663,0.5207656621932983,0.5224425792694092,0.5253636837005615,0.5313398241996765,0.5315231680870056,0.5362169146537781,0.5352748036384583,0.5347131490707397,0.5373940467834473,0.5360828042030334,0.5486221313476562,0.5492896437644958,0.5402496457099915,0.5416734218597412,0.5514758825302124,0.5479881167411804,0.5568676590919495,0.5594737529754639,0.5599238276481628,0.5576037764549255,0.5639882683753967,0.564314603805542,0.5675384402275085,0.5646824836730957,0.571418821811676,0.568992018699646,0.5657557845115662,0.5679932236671448,0.5709245800971985,0.5706439018249512,0.5728235244750977,0.5720542669296265,0.5636332035064697,0.5606187582015991,0.5586279034614563,0.5596636533737183,0.5627943277359009,0.5646445751190186,0.5660039782524109,0.5618162751197815,
mae,0.6293632984161377,0.5775696635246277,0.5357818007469177,0.5361964106559753,0.45514559745788574,0.4673880338668823,0.4482184648513794,0.4304751455783844,0.40162765979766846,0.4045717120170593,0.3908795416355133,0.4074171185493469,0.401382714509964,0.3932342827320099,0.39099594950675964,0.3855743110179901,0.3332732319831848,0.3348401188850403,0.3476113975048065,0.3456934988498688,0.3344557285308838,0.337253212928772,0.3574584126472473,0.3583785593509674,0.3472460210323334,0.36160799860954285,0.3659038543701172,0.38156166672706604,0.38371285796165466,0.3889003098011017,0.39094457030296326,0.41714560985565186,0.41285187005996704,0.409282922744751,0.41425400972366333,0.4260300099849701,0.43290138244628906,0.4298465847969055,0.43512558937072754,0.4329943060874939,0.44123023748397827,0.44039905071258545,0.44609421491622925,0.447830468416214,0.4485531747341156,0.4560815691947937,0.4530785083770752,0.46139660477638245,0.4728567898273468,0.46884116530418396,0.46967244148254395,0.47977420687675476,0.4826093018054962,0.4892957806587219,0.49119362235069275,0.49406853318214417,0.4960722029209137,0.5012289881706238,0.49913519620895386,0.4997986853122711,0.5086004734039307,0.5091220736503601,0.5131632089614868,0.5176218152046204,0.517865002155304,0.5223069190979004,0.5221558213233948,0.5219027400016785,0.5245862007141113,0.523942768573761,0.5326063632965088,0.5344439744949341,0.5265904664993286,0.5270416140556335,0.5346286296844482,0.5319939851760864,0.5398520231246948,0.5437808632850647,0.542981743812561,0.5414663553237915,0.5466358065605164,0.5483964681625366,0.5491710901260376,0.5473161935806274,0.5530035495758057,0.5490798354148865,0.5472223162651062,0.5500133037567139,0.5545993447303772,0.5543211102485657,0.5546285510063171,0.5531578063964844,0.5469035506248474,0.5443494915962219,0.5424830913543701,0.5442252159118652,0.5450537204742432,0.5478505492210388,0.5476160645484924,0.5455005764961243,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 12770     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 12772     
=================================================================
Total params: 25,542
Trainable params: 25,542
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 130       
=================================================================
Total params: 12,770
Trainable params: 12,770
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                192       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 12,772
Trainable params: 12,772
Non-trainable params: 0
_________________________________________________________________
