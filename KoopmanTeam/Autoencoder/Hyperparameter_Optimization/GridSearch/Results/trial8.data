2021-06-25
loss,4.811321258544922,2.766874074935913,2.4224517345428467,2.059443712234497,2.396413803100586,1.918672800064087,1.6802047491073608,2.4844706058502197,2.892693281173706,1.781497597694397,1.8104324340820312,1.8447222709655762,1.9273866415023804,1.4073125123977661,1.606033444404602,2.0047860145568848,1.8365538120269775,1.603202223777771,1.8108189105987549,1.6921383142471313,1.774843454360962,1.4573464393615723,2.15856671333313,1.313576102256775,1.8288073539733887,2.9409055709838867,1.449011206626892,1.596657156944275,1.2926008701324463,1.4111725091934204,1.30366849899292,1.0948199033737183,1.188889741897583,0.9977280497550964,1.2846397161483765,1.258143663406372,0.9146639108657837,1.2644274234771729,1.0592080354690552,1.0023704767227173,0.7961112856864929,0.6821338534355164,0.7000116109848022,0.7961711883544922,0.7419843077659607,0.9549146890640259,0.9964632987976074,0.8085654377937317,0.7678577303886414,0.8117023706436157,0.5539868474006653,0.9731065630912781,0.8541871905326843,0.7506405115127563,0.7814304828643799,1.1094094514846802,0.8131232261657715,0.6959803104400635,0.6231396794319153,0.798083484172821,0.9459852576255798,0.8342745304107666,0.9094751477241516,0.7733140587806702,0.7692130208015442,0.914206862449646,0.7419736385345459,0.7606591582298279,0.6464508175849915,0.8107253313064575,0.6235969662666321,0.6895171403884888,1.0356825590133667,0.9950346946716309,1.267237901687622,0.8654330372810364,0.6647975444793701,0.7898271679878235,0.7718226909637451,0.7150707840919495,0.7789332866668701,0.8421850800514221,0.5978578925132751,0.7112806439399719,0.7451449632644653,0.5682970881462097,0.5876369476318359,0.6218728423118591,0.5667173862457275,0.6134220361709595,0.5224025845527649,0.6282477974891663,0.7430711984634399,0.6895256042480469,0.5987269282341003,0.8099563121795654,0.7845743298530579,0.4501405358314514,0.6059409976005554,0.6790443658828735,
mse,0.49451977014541626,0.39303553104400635,0.3505258858203888,0.38617488741874695,0.3346482515335083,0.3795584440231323,0.30206751823425293,0.2870176434516907,0.34969577193260193,0.33309391140937805,0.31857794523239136,0.29949846863746643,0.2753378748893738,0.2905300259590149,0.29372215270996094,0.276888906955719,0.27727848291397095,0.2699948847293854,0.21817582845687866,0.22620344161987305,0.20173051953315735,0.1946527659893036,0.1993781477212906,0.22320456802845,0.14757972955703735,0.13955096900463104,0.16115693747997284,0.12890107929706573,0.12266936898231506,0.13440658152103424,0.11598677933216095,0.08895459026098251,0.07828063517808914,0.07376688718795776,0.06322070956230164,0.06343363970518112,0.051293469965457916,0.046433039009571075,0.04156488925218582,0.036208268254995346,0.033430371433496475,0.03188369423151016,0.03289720416069031,0.0319548137485981,0.029155196622014046,0.030454814434051514,0.03222024068236351,0.03450063243508339,0.02932603843510151,0.030494235455989838,0.033156611025333405,0.030663007870316505,0.031444400548934937,0.031836628913879395,0.031912609934806824,0.034084852784872055,0.034604161977767944,0.03127175197005272,0.031013494357466698,0.03257415443658829,0.03231970965862274,0.033856023102998734,0.033581387251615524,0.03201795369386673,0.0317852608859539,0.03409355878829956,0.033333297818899155,0.03421935811638832,0.031141670420765877,0.03254637122154236,0.031949881464242935,0.03754457086324692,0.05315922200679779,0.04102468863129616,0.04278341680765152,0.03891770541667938,0.03651813045144081,0.035515446215867996,0.036446910351514816,0.03604807332158089,0.03582695871591568,0.03725024312734604,0.036410365253686905,0.03510676324367523,0.03583810105919838,0.038350895047187805,0.037236303091049194,0.03752976283431053,0.03624160587787628,0.03633764386177063,0.03505948930978775,0.034379228949546814,0.034472957253456116,0.03348865360021591,0.0320630744099617,0.03256761655211449,0.032810360193252563,0.032914381474256516,0.030458390712738037,0.030680017545819283,
mae,0.5516287088394165,0.45153579115867615,0.4082978069782257,0.4193514287471771,0.38433510065078735,0.4025473892688751,0.3638228476047516,0.3453928828239441,0.38699474930763245,0.3720502555370331,0.3598857820034027,0.34339654445648193,0.3315173387527466,0.33059537410736084,0.3282462954521179,0.32109302282333374,0.31791970133781433,0.30800333619117737,0.28707173466682434,0.2843957841396332,0.270011842250824,0.2706368565559387,0.2831418514251709,0.2764742970466614,0.2819659113883972,0.26490432024002075,0.2431582659482956,0.22943097352981567,0.22705049812793732,0.22261673212051392,0.2108672559261322,0.19994546473026276,0.18528270721435547,0.17721058428287506,0.16871747374534607,0.16320250928401947,0.153374582529068,0.14858373999595642,0.142084538936615,0.1380845308303833,0.13244794309139252,0.13007479906082153,0.13307936489582062,0.1309107542037964,0.12482012808322906,0.12919822335243225,0.13182663917541504,0.1387804001569748,0.12537796795368195,0.12883660197257996,0.13638736307621002,0.12983904778957367,0.1315087378025055,0.13275642693042755,0.13372796773910522,0.1399354487657547,0.1398351788520813,0.13076449930667877,0.13043095171451569,0.13363152742385864,0.13443028926849365,0.1370449662208557,0.13537731766700745,0.1316373348236084,0.13276705145835876,0.13787700235843658,0.13652360439300537,0.14233830571174622,0.1316995471715927,0.13197965919971466,0.13102871179580688,0.14303378760814667,0.17967067658901215,0.15525086224079132,0.16172672808170319,0.14973899722099304,0.141365647315979,0.1383156180381775,0.14158904552459717,0.14010939002037048,0.13918200135231018,0.14212419092655182,0.13966801762580872,0.1364651322364807,0.1366804540157318,0.14230966567993164,0.13914993405342102,0.13988684117794037,0.13898442685604095,0.13955165445804596,0.13465726375579834,0.13341407477855682,0.13541214168071747,0.13049893081188202,0.1283341944217682,0.12783841788768768,0.12981320917606354,0.130295529961586,0.12423835694789886,0.1233234703540802,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 2242      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2244      
=================================================================
Total params: 4,486
Trainable params: 4,486
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 2,242
Trainable params: 2,242
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 2,244
Trainable params: 2,244
Non-trainable params: 0
_________________________________________________________________
