2021-06-25
loss,7.44681453704834,5.234653949737549,5.611898899078369,3.005312919616699,2.88394832611084,3.829338788986206,2.738983392715454,3.980820417404175,3.1559250354766846,2.6396172046661377,1.9513403177261353,3.4116814136505127,3.748129367828369,2.886108160018921,2.6454553604125977,1.5149062871932983,1.7496188879013062,1.8453410863876343,1.6190142631530762,1.4744248390197754,1.5501381158828735,1.056401014328003,1.2720494270324707,1.1644631624221802,1.50754976272583,2.0699100494384766,0.8419586420059204,1.8817458152770996,3.636687994003296,1.7040666341781616,0.883251965045929,1.0122491121292114,0.9009966850280762,0.8554983735084534,1.1583582162857056,0.811896800994873,0.6602306365966797,0.5691872835159302,0.7750913500785828,0.906907856464386,0.7930749654769897,0.5346247553825378,0.5915140509605408,0.6152077913284302,0.5898623466491699,0.582141101360321,0.6418380737304688,0.7990107536315918,0.8114202618598938,0.7043682932853699,0.6391987800598145,0.5916484594345093,0.796959400177002,0.8090767860412598,0.8789730668067932,0.7430943250656128,0.8620215654373169,0.688737154006958,0.6185714602470398,0.4893260896205902,0.6389006972312927,0.8530428409576416,0.6135372519493103,0.726732075214386,0.7173221111297607,0.6743626594543457,0.6056177020072937,0.5121667385101318,0.497437983751297,0.5066922307014465,0.5641034841537476,0.5871550440788269,0.5232191681861877,0.47769901156425476,0.5499279499053955,0.8096502423286438,0.7074658870697021,0.4066585302352905,0.4119478464126587,0.44531071186065674,0.4317457973957062,0.3877679407596588,0.6282313466072083,0.6051456332206726,0.6852365732192993,0.5323145389556885,0.5830623507499695,0.5461678504943848,0.7809763550758362,0.7633061408996582,0.5344887971878052,0.710669994354248,0.6152169704437256,0.5726126432418823,0.4481845796108246,0.623030960559845,0.5877432823181152,0.8386871814727783,0.5889009237289429,0.683228075504303,
mse,0.6684277057647705,0.6844643354415894,0.6028332710266113,0.5674378871917725,0.5947901010513306,0.584089457988739,0.5115865468978882,0.5519603490829468,0.5975936651229858,0.5618123412132263,0.5807444453239441,0.5409669876098633,0.5598198175430298,0.6677122712135315,0.6616394519805908,0.6648591756820679,0.648906409740448,0.6227067708969116,0.6229360699653625,0.6422755718231201,0.593453586101532,0.5912863612174988,0.6030685901641846,0.6062090992927551,0.6202553510665894,0.5736585855484009,0.5954219698905945,0.6194061040878296,0.6111257672309875,0.6203104257583618,0.6095943450927734,0.612663745880127,0.6188905239105225,0.5683578252792358,0.5846726298332214,0.5906326174736023,0.5907556414604187,0.5855403542518616,0.5866565108299255,0.5830920934677124,0.5918976068496704,0.5804365277290344,0.5775934457778931,0.580834150314331,0.5845955014228821,0.585130512714386,0.5912215709686279,0.5939080715179443,0.5838202834129333,0.5717376470565796,0.5633319616317749,0.566737949848175,0.5698885917663574,0.5740241408348083,0.5629540085792542,0.5833985805511475,0.591212809085846,0.5814640522003174,0.5847280621528625,0.59031742811203,0.5959500074386597,0.601193368434906,0.5998912453651428,0.578569233417511,0.5838621258735657,0.5889933705329895,0.5950006246566772,0.5941796898841858,0.5923672318458557,0.5948425531387329,0.5938586592674255,0.5918787717819214,0.5940020084381104,0.5968402028083801,0.5969443917274475,0.5952115654945374,0.5979312062263489,0.6035524010658264,0.5999677777290344,0.5968460440635681,0.5987375974655151,0.5916293859481812,0.5939701199531555,0.5939735770225525,0.5986701846122742,0.5922953486442566,0.5916731357574463,0.5958787798881531,0.5915026664733887,0.606399416923523,0.5981964468955994,0.5862377285957336,0.5927163362503052,0.6035539507865906,0.6049976944923401,0.6028357148170471,0.6042129397392273,0.6062484979629517,0.5844146609306335,0.5806032419204712,
mae,0.6507709622383118,0.6771883964538574,0.6015152931213379,0.5720913410186768,0.5843207240104675,0.5934439897537231,0.5066714882850647,0.5468604564666748,0.5860497951507568,0.6058889627456665,0.6133561134338379,0.5630530118942261,0.5797349810600281,0.6554971933364868,0.6519979238510132,0.6418759822845459,0.6124821305274963,0.5941570401191711,0.5934690833091736,0.606391191482544,0.5798400640487671,0.5794656276702881,0.5845033526420593,0.5869807004928589,0.6041512489318848,0.5664674043655396,0.5762978792190552,0.6010518074035645,0.6033506393432617,0.597646951675415,0.5861213803291321,0.5870760083198547,0.5972967147827148,0.5491458773612976,0.5649171471595764,0.5692749619483948,0.5704607963562012,0.5646368265151978,0.5659124255180359,0.5650522112846375,0.5718914270401001,0.5610382556915283,0.5600792169570923,0.5609063506126404,0.5640001893043518,0.5667569041252136,0.5718947052955627,0.5733960270881653,0.5644019842147827,0.5511161684989929,0.5441515445709229,0.5458518862724304,0.5510378479957581,0.5552899241447449,0.5465468764305115,0.5633909106254578,0.5727611780166626,0.5635916590690613,0.5678896307945251,0.5714596509933472,0.5763716697692871,0.5796658396720886,0.5813857913017273,0.5608007311820984,0.5636956095695496,0.5677838325500488,0.5764142870903015,0.5756080150604248,0.5733078122138977,0.5742766261100769,0.5742570757865906,0.5690625905990601,0.5722649097442627,0.5766295790672302,0.5768584609031677,0.5749824643135071,0.5775550603866577,0.58284592628479,0.5799062848091125,0.5753746032714844,0.578426718711853,0.5704099535942078,0.5741719603538513,0.5739218592643738,0.5768239498138428,0.5722278952598572,0.570101797580719,0.5751854181289673,0.5707437992095947,0.5846781730651855,0.5755071043968201,0.5662662982940674,0.5709460973739624,0.5837630033493042,0.5841360688209534,0.5828635692596436,0.5847809314727783,0.5841562747955322,0.5647413730621338,0.5612141489982605,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 8578      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8580      
=================================================================
Total params: 17,158
Trainable params: 17,158
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 66        
=================================================================
Total params: 8,578
Trainable params: 8,578
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                96        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 8,580
Trainable params: 8,580
Non-trainable params: 0
_________________________________________________________________
