2021-06-25
loss,10.07234001159668,4.301166534423828,2.6914212703704834,1.732021689414978,1.6220470666885376,2.0589990615844727,2.4924893379211426,2.0075643062591553,1.6235275268554688,1.667568325996399,2.1398911476135254,1.09246826171875,1.3936740159988403,1.1037272214889526,0.7677802443504333,1.3725262880325317,0.8947151303291321,1.1569308042526245,1.3157905340194702,0.9634866118431091,1.0249139070510864,1.1916297674179077,0.884401261806488,1.3013360500335693,0.912244975566864,1.0375289916992188,0.8247320055961609,1.0686471462249756,0.9246019124984741,0.713425874710083,1.2816046476364136,1.2307783365249634,0.6933042407035828,0.6961554884910583,0.5899465084075928,0.5374109148979187,0.9676604270935059,0.784386157989502,0.6536469459533691,0.8854224681854248,0.777997612953186,1.068608283996582,0.8031601905822754,0.6655831336975098,0.7489327788352966,0.5471103191375732,0.5357978343963623,0.8263832330703735,0.7501226663589478,0.6720384359359741,0.851102352142334,1.140994906425476,0.777876615524292,1.1027592420578003,0.8411281704902649,0.7458596229553223,0.8293704986572266,0.6639649868011475,0.7781606316566467,0.7260127067565918,0.6940628886222839,0.7829368710517883,0.6944615244865417,0.7912469506263733,0.5994575619697571,0.5882409811019897,0.7369818687438965,1.101688027381897,0.6724795699119568,0.5150684118270874,0.5752544403076172,0.5241250395774841,0.48021578788757324,0.6819406151771545,0.6052203178405762,0.7882264852523804,0.7419558763504028,0.676767885684967,0.5256686210632324,0.5338737964630127,0.5082280039787292,0.978165864944458,0.569840133190155,0.5210341811180115,0.6127241253852844,0.5550669431686401,0.765913188457489,0.5198323130607605,0.5505366921424866,0.5116561651229858,0.5257141590118408,0.5258074402809143,0.5135144591331482,0.7274682521820068,0.6652303338050842,0.709770143032074,0.7394409775733948,0.5527773499488831,0.4548277258872986,0.636059045791626,
mse,0.3778068423271179,0.4894726574420929,0.4878228008747101,0.4887649118900299,0.4975447952747345,0.501453697681427,0.4972449541091919,0.48009732365608215,0.49591419100761414,0.5334764719009399,0.5328178405761719,0.5264886021614075,0.5365723967552185,0.5421717166900635,0.5395497679710388,0.5418412685394287,0.5553491115570068,0.5490900278091431,0.5501744747161865,0.55057692527771,0.5489156246185303,0.5294256210327148,0.5332821607589722,0.5301993489265442,0.5384450554847717,0.5490247011184692,0.5441763401031494,0.5450291633605957,0.5433040857315063,0.5347570180892944,0.5241544246673584,0.5354733467102051,0.5441867709159851,0.5263010859489441,0.5171793103218079,0.5277530550956726,0.5303906798362732,0.5462671518325806,0.5447645783424377,0.5325886607170105,0.5157040953636169,0.5268550515174866,0.5376971960067749,0.536907434463501,0.5346998572349548,0.5288133025169373,0.524411678314209,0.5320616364479065,0.5323349833488464,0.5338490605354309,0.5342243313789368,0.5135015249252319,0.5287420153617859,0.5337343811988831,0.5195921659469604,0.5303933620452881,0.5368214845657349,0.5377299785614014,0.5287301540374756,0.5258889198303223,0.5319075584411621,0.5296130180358887,0.5228891968727112,0.5282564759254456,0.540768563747406,0.5398392677307129,0.5318654775619507,0.5228067636489868,0.5379451513290405,0.5362680554389954,0.5377094745635986,0.5390861630439758,0.5401197075843811,0.5375681519508362,0.5405672788619995,0.5444079041481018,0.5375367999076843,0.5389864444732666,0.5409507155418396,0.5380439162254333,0.5355936288833618,0.5409431457519531,0.535807192325592,0.5340604782104492,0.5351346731185913,0.5349527597427368,0.541647732257843,0.5408814549446106,0.5418177247047424,0.5399712920188904,0.5410736203193665,0.5359533429145813,0.5396891832351685,0.5179389715194702,0.5192533135414124,0.5333735346794128,0.5510684847831726,0.5435709357261658,0.5435571670532227,0.5429474115371704,
mae,0.472237229347229,0.49413737654685974,0.49653884768486023,0.48413777351379395,0.4882899522781372,0.49342265725135803,0.5013284087181091,0.49012669920921326,0.4944182336330414,0.5221967101097107,0.5246634483337402,0.5150332450866699,0.5217098593711853,0.5276243686676025,0.5252698063850403,0.5277175903320312,0.5384035706520081,0.5344850420951843,0.5345625877380371,0.5334429144859314,0.5344749689102173,0.5188069343566895,0.5209512114524841,0.5191819667816162,0.5265967845916748,0.534350574016571,0.5295392870903015,0.5325210690498352,0.5327526926994324,0.5237462520599365,0.5148851275444031,0.5233118534088135,0.5323261022567749,0.5164335370063782,0.5073457360267639,0.5169868469238281,0.5192936658859253,0.5338276028633118,0.5323373079299927,0.5225690603256226,0.5092099905014038,0.5169177055358887,0.5227661728858948,0.5232845544815063,0.5230249166488647,0.5191428661346436,0.5161884427070618,0.5198622941970825,0.5197837948799133,0.5236815810203552,0.5235651135444641,0.507055938243866,0.5191420316696167,0.5265951156616211,0.5108358860015869,0.5167370438575745,0.5219482183456421,0.5209141373634338,0.5193972587585449,0.5123372077941895,0.516155481338501,0.5166292786598206,0.5112850069999695,0.5175634622573853,0.5241280198097229,0.5238990187644958,0.516038715839386,0.5130881667137146,0.524665117263794,0.521568238735199,0.522731363773346,0.5214884281158447,0.5257359743118286,0.5206764340400696,0.5234571695327759,0.5284289717674255,0.5211847424507141,0.5229356288909912,0.5248605608940125,0.5198403000831604,0.5202252864837646,0.5254709124565125,0.5184658765792847,0.5181367993354797,0.5194525718688965,0.5184249877929688,0.5248624682426453,0.5260757207870483,0.5259712338447571,0.5254734754562378,0.5259414911270142,0.5213744640350342,0.5255208015441895,0.5116427540779114,0.5089121460914612,0.5208536982536316,0.5352784991264343,0.5254795551300049,0.5263465046882629,0.527076005935669,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 7474      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 7476      
=================================================================
Total params: 14,950
Trainable params: 14,950
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 66        
=================================================================
Total params: 7,474
Trainable params: 7,474
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                96        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 7,476
Trainable params: 7,476
Non-trainable params: 0
_________________________________________________________________
