2021-06-25
loss,6.638024806976318,3.353609085083008,5.353597640991211,6.014591217041016,4.7848591804504395,3.3948581218719482,2.516633987426758,2.075026035308838,2.1184096336364746,4.0850701332092285,2.746443748474121,2.4638559818267822,2.295703887939453,2.4217498302459717,1.643812656402588,3.093446969985962,2.4967620372772217,1.6331322193145752,2.4829344749450684,2.211733341217041,2.0270581245422363,1.6267390251159668,2.4780757427215576,2.095454454421997,2.265070915222168,1.988365650177002,2.2098569869995117,2.0236008167266846,2.0335941314697266,2.043555974960327,2.0671863555908203,1.9404641389846802,1.9608490467071533,1.4382940530776978,1.523579716682434,1.371468186378479,1.490917682647705,1.8642566204071045,1.6977951526641846,1.5891271829605103,1.4057868719100952,1.3535821437835693,1.7300111055374146,2.0455143451690674,1.402598261833191,1.4720765352249146,0.9716551899909973,1.0384571552276611,1.125375747680664,0.9396858811378479,0.958057701587677,0.8322032690048218,1.1358709335327148,1.2342257499694824,1.0640873908996582,0.7407044768333435,1.1200308799743652,0.9341071248054504,0.7048523426055908,0.7092056274414062,1.1913695335388184,0.8296415209770203,0.9896231293678284,0.6247715950012207,0.7343572974205017,1.022998332977295,0.6322486996650696,0.6615205407142639,0.8788883686065674,0.8939629197120667,0.8502604961395264,1.0578457117080688,0.6724509596824646,0.7061010003089905,0.6486705541610718,0.6054496169090271,0.6469061374664307,0.5552119016647339,0.7297620177268982,0.4392507076263428,0.48072823882102966,0.6904876232147217,0.7390013933181763,0.6736578941345215,0.5771302580833435,0.9228689670562744,0.4612214267253876,0.7208912372589111,0.5951278209686279,0.6170689463615417,1.0301593542099,0.5042043328285217,0.6983898878097534,0.6622239947319031,0.6296743154525757,0.7102693319320679,0.9403407573699951,1.1890743970870972,0.7114782929420471,0.5971375107765198,
mse,0.2036990225315094,0.2201816737651825,0.2727621793746948,0.32149043679237366,0.3270614743232727,0.3248356580734253,0.3270367681980133,0.3305491507053375,0.32609328627586365,0.34994637966156006,0.3231927454471588,0.3362365663051605,0.33494818210601807,0.34013116359710693,0.3323103189468384,0.30584901571273804,0.2975025475025177,0.2827831208705902,0.3073233366012573,0.29347458481788635,0.2915290296077728,0.2732681930065155,0.2531455457210541,0.28158634901046753,0.2957768142223358,0.2821413278579712,0.3010949194431305,0.28598156571388245,0.28121262788772583,0.2509540021419525,0.24052517116069794,0.25534650683403015,0.25082167983055115,0.22017334401607513,0.22001585364341736,0.22471483051776886,0.21291793882846832,0.20327997207641602,0.1736629456281662,0.150216743350029,0.14223280549049377,0.1500178426504135,0.11047134548425674,0.11338271200656891,0.08360912650823593,0.06943116337060928,0.06824827194213867,0.06566452980041504,0.062260761857032776,0.062208596616983414,0.05609220638871193,0.054156675934791565,0.0580308735370636,0.061072174459695816,0.05305915325880051,0.053447574377059937,0.052184805274009705,0.05199955403804779,0.04425431415438652,0.043964046984910965,0.04663820564746857,0.04389204829931259,0.04613777622580528,0.04119366034865379,0.043008580803871155,0.04429127648472786,0.043334487825632095,0.042399581521749496,0.044340018182992935,0.044064637273550034,0.04505114629864693,0.053432565182447433,0.04396126791834831,0.042645759880542755,0.042227305471897125,0.0413074716925621,0.04256104305386543,0.04238981381058693,0.041225191205739975,0.04129405319690704,0.04056090489029884,0.04185378924012184,0.042467206716537476,0.042808279395103455,0.039385803043842316,0.04050835594534874,0.042691897600889206,0.041943103075027466,0.04134861007332802,0.041124433279037476,0.04391765594482422,0.040754057466983795,0.04010728374123573,0.04062100499868393,0.03926213085651398,0.041026387363672256,0.04467887803912163,0.043579522520303726,0.042859043926000595,0.04271472990512848,
mae,0.3496741056442261,0.3474788963794708,0.37666207551956177,0.40173473954200745,0.4010772407054901,0.4006781280040741,0.39741194248199463,0.4017539322376251,0.40304139256477356,0.4211878180503845,0.39548012614250183,0.4100365936756134,0.4074689745903015,0.40716609358787537,0.40964367985725403,0.38908177614212036,0.3785013258457184,0.36675184965133667,0.3845617175102234,0.37271374464035034,0.3734052777290344,0.3586896061897278,0.3466046154499054,0.3691917359828949,0.3715112805366516,0.3611413240432739,0.37279945611953735,0.36369088292121887,0.3599652051925659,0.3432794511318207,0.3304736018180847,0.3414275646209717,0.3360714316368103,0.32629454135894775,0.31640860438346863,0.3202248811721802,0.3066832423210144,0.31237319111824036,0.2869836688041687,0.26950111985206604,0.2636707127094269,0.26579365134239197,0.2490205019712448,0.24834665656089783,0.21112237870693207,0.19970466196537018,0.19851145148277283,0.2000369131565094,0.19622229039669037,0.19899986684322357,0.18956223130226135,0.18609458208084106,0.1937127262353897,0.19871246814727783,0.17952901124954224,0.18401117622852325,0.18201038241386414,0.1847819834947586,0.17192260921001434,0.17208333313465118,0.17664772272109985,0.1715380698442459,0.17415006458759308,0.16272103786468506,0.16773930191993713,0.17090988159179688,0.16972923278808594,0.16722293198108673,0.17191003262996674,0.1714557707309723,0.17264749109745026,0.19152741134166718,0.16967247426509857,0.1666043996810913,0.16467426717281342,0.16098923981189728,0.16454344987869263,0.16471876204013824,0.1591210961341858,0.15989384055137634,0.15749138593673706,0.16219381988048553,0.1633279025554657,0.16458043456077576,0.15534603595733643,0.1566098928451538,0.16414503753185272,0.16215866804122925,0.16163721680641174,0.16050665080547333,0.16660772264003754,0.1558249145746231,0.15696404874324799,0.15777377784252167,0.1531146764755249,0.15983770787715912,0.16719059646129608,0.16104160249233246,0.16252557933330536,0.1634131371974945,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 8578      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8580      
=================================================================
Total params: 17,158
Trainable params: 17,158
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 66        
=================================================================
Total params: 8,578
Trainable params: 8,578
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                96        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 8,580
Trainable params: 8,580
Non-trainable params: 0
_________________________________________________________________
