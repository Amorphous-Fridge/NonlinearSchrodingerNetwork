2021-06-25
loss,10.811285018920898,6.107755184173584,3.2059803009033203,2.825355291366577,4.460529327392578,5.115554332733154,2.8324825763702393,2.332160472869873,3.4417197704315186,4.834691047668457,3.099850654602051,4.058795928955078,2.6644327640533447,2.4740772247314453,1.747554898262024,2.025862455368042,2.5855095386505127,2.696620225906372,2.1040291786193848,2.2732656002044678,2.4119205474853516,2.1129415035247803,2.729067802429199,2.1985971927642822,2.597824811935425,2.227559804916382,2.3965654373168945,2.5457756519317627,1.7022818326950073,1.702060580253601,2.315530776977539,1.9651085138320923,2.066558599472046,1.997448444366455,2.5440332889556885,2.2684671878814697,1.9762409925460815,2.592101812362671,2.1266233921051025,2.2329633235931396,2.676537275314331,1.877189040184021,1.5787558555603027,1.7776867151260376,1.9758011102676392,1.7495454549789429,2.188990354537964,1.7334986925125122,2.3278920650482178,2.6928048133850098,2.295958995819092,2.100597381591797,1.8448469638824463,1.8590333461761475,2.101776361465454,2.100980758666992,1.4926743507385254,1.797660231590271,1.8058241605758667,2.001178503036499,1.707474708557129,1.3263609409332275,2.3533530235290527,2.1468610763549805,1.835906982421875,1.406632423400879,1.5417616367340088,1.641576886177063,1.264894962310791,1.3140720129013062,2.380429744720459,1.7462174892425537,1.4870986938476562,1.4491705894470215,1.6499683856964111,1.4256634712219238,1.8528071641921997,1.314620852470398,1.7605034112930298,1.6309176683425903,1.5511174201965332,1.4215298891067505,1.257151484489441,1.567734718322754,1.7846237421035767,1.3696953058242798,1.5868935585021973,1.9630717039108276,1.857425332069397,1.6934943199157715,1.6112216711044312,1.4860584735870361,1.8786725997924805,1.8356318473815918,2.015608787536621,1.5340863466262817,1.4428361654281616,1.7254220247268677,1.4272027015686035,1.8065452575683594,
mse,0.6309822201728821,0.48928502202033997,0.5378464460372925,0.5575430989265442,0.4782816171646118,0.5422463417053223,0.5223818421363831,0.5197957158088684,0.537163257598877,0.530491054058075,0.5066158175468445,0.5287482738494873,0.5087166428565979,0.5458071827888489,0.5109274387359619,0.5233084559440613,0.5247318148612976,0.5170273184776306,0.5074275135993958,0.5148173570632935,0.5146670341491699,0.5216983556747437,0.49261826276779175,0.4944688379764557,0.4927405118942261,0.4949202239513397,0.49141061305999756,0.47791290283203125,0.47645896673202515,0.4569140672683716,0.4634760320186615,0.44792965054512024,0.4653509855270386,0.4635186493396759,0.46038612723350525,0.43927571177482605,0.45712053775787354,0.4456902742385864,0.44245997071266174,0.43946605920791626,0.42999720573425293,0.43400251865386963,0.44230175018310547,0.3858592212200165,0.41479700803756714,0.3995961844921112,0.42083001136779785,0.41445213556289673,0.4147660732269287,0.42002755403518677,0.427051305770874,0.4195919930934906,0.3957604467868805,0.3997889459133148,0.3789171874523163,0.4068482518196106,0.3857509195804596,0.4130171835422516,0.3499731719493866,0.34179428219795227,0.3676488399505615,0.3740547299385071,0.3818507790565491,0.38078975677490234,0.3800501525402069,0.370510458946228,0.3669132590293884,0.3416447937488556,0.3740611672401428,0.35155826807022095,0.3567465841770172,0.3778480589389801,0.3527245819568634,0.35256630182266235,0.3697670102119446,0.35848140716552734,0.36919230222702026,0.36123770475387573,0.36073780059814453,0.3342256546020508,0.31754109263420105,0.30996865034103394,0.29807332158088684,0.2930929958820343,0.2830207347869873,0.29154282808303833,0.2686472237110138,0.29579854011535645,0.31986817717552185,0.31618595123291016,0.3057938516139984,0.31395310163497925,0.32482829689979553,0.2947835922241211,0.29284894466400146,0.30652064085006714,0.295968234539032,0.29418545961380005,0.29970940947532654,0.2998714745044708,
mae,0.6120241284370422,0.47803211212158203,0.5075668096542358,0.5277610421180725,0.4650130569934845,0.5051926970481873,0.48367878794670105,0.49092909693717957,0.5069248080253601,0.49814391136169434,0.47695815563201904,0.49154582619667053,0.4763352870941162,0.5043660998344421,0.4791884124279022,0.4864300489425659,0.4903908669948578,0.48769253492355347,0.47700369358062744,0.4766674041748047,0.48028865456581116,0.484041303396225,0.4623135030269623,0.46562620997428894,0.4604732394218445,0.46453025937080383,0.45927855372428894,0.45004427433013916,0.4438210427761078,0.4292689561843872,0.43690231442451477,0.42643892765045166,0.43557941913604736,0.4356901943683624,0.4351242184638977,0.42054492235183716,0.4301321506500244,0.42447608709335327,0.4234981834888458,0.41435253620147705,0.4083825349807739,0.4101499915122986,0.41117867827415466,0.3839089870452881,0.39196956157684326,0.38342365622520447,0.39690130949020386,0.3927629888057709,0.3947259783744812,0.39776161313056946,0.4085375964641571,0.39407461881637573,0.37863749265670776,0.38005948066711426,0.3648815453052521,0.38377511501312256,0.3693915605545044,0.4156475365161896,0.36353638768196106,0.34212249517440796,0.350880891084671,0.35339680314064026,0.3597213327884674,0.36287152767181396,0.3598156273365021,0.3543225824832916,0.3500942885875702,0.33714091777801514,0.35198456048965454,0.34884577989578247,0.3513738214969635,0.36396652460098267,0.34181147813796997,0.3356465995311737,0.3474394679069519,0.3425031304359436,0.34842178225517273,0.34666773676872253,0.34351304173469543,0.3259078860282898,0.3130795359611511,0.30879470705986023,0.2988266944885254,0.29602348804473877,0.2846432328224182,0.29223161935806274,0.27514591813087463,0.29580581188201904,0.3325164020061493,0.3163381516933441,0.3018161654472351,0.3088015615940094,0.3306964039802551,0.30410948395729065,0.2962339222431183,0.30003511905670166,0.2963030934333801,0.2911919355392456,0.29496029019355774,0.29493314027786255,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 17026     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17028     
=================================================================
Total params: 34,054
Trainable params: 34,054
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 130       
=================================================================
Total params: 17,026
Trainable params: 17,026
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                192       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 17,028
Trainable params: 17,028
Non-trainable params: 0
_________________________________________________________________
