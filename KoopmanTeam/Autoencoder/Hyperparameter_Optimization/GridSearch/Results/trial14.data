2021-06-25
loss,7.654947280883789,4.418424129486084,2.9402520656585693,2.490139961242676,3.240957260131836,2.580744743347168,2.2320640087127686,2.788355827331543,2.532867670059204,2.8264758586883545,1.8008110523223877,2.6645684242248535,2.1201579570770264,1.5492663383483887,2.7029428482055664,2.288309097290039,1.8599799871444702,1.6722830533981323,1.745428204536438,1.6193650960922241,1.9914509057998657,1.21481192111969,0.9501641988754272,1.0001931190490723,0.9939890503883362,0.9024671316146851,0.8527839779853821,0.8463159799575806,0.8230917453765869,0.8137773275375366,0.7883226275444031,0.8284512162208557,0.8363059759140015,0.8267527222633362,0.8924098014831543,0.8899955749511719,0.8061085343360901,0.8044111132621765,1.3303380012512207,0.8526191115379333,0.829267144203186,1.1999213695526123,1.002198338508606,1.1832892894744873,0.9488157033920288,0.6443990468978882,0.7074096202850342,0.669853687286377,0.7447071671485901,0.9862131476402283,0.8210582733154297,0.9070473313331604,0.9652096629142761,1.0631496906280518,1.1171090602874756,0.9295207262039185,0.737417995929718,0.9601154327392578,1.0483289957046509,1.2706609964370728,1.016467809677124,0.933758020401001,0.6827439665794373,0.7900123596191406,0.9233633279800415,0.8388922214508057,0.5959662795066833,0.7367936968803406,0.6708064079284668,0.6096510887145996,0.6518851518630981,0.5663809180259705,0.5985984206199646,0.561103880405426,0.7383532524108887,0.7655081152915955,0.8785889148712158,0.969383716583252,0.6664862632751465,0.7379009127616882,0.7957128882408142,0.7942826747894287,0.6935874819755554,0.8333190083503723,0.5710965991020203,0.5771278142929077,0.5406061410903931,0.5761480927467346,0.659614086151123,0.6076797246932983,0.6475636959075928,0.4924846589565277,0.6314618587493896,0.7290256023406982,0.6536837220191956,0.9457570910453796,0.7446131706237793,0.882822573184967,1.1302216053009033,0.8670618534088135,
mse,0.6787803769111633,0.5956159234046936,0.5156948566436768,0.5034481287002563,0.5028812885284424,0.46820446848869324,0.473178505897522,0.4432827830314636,0.36557385325431824,0.41426217555999756,0.4101898968219757,0.4234808385372162,0.42225292325019836,0.4302722215652466,0.4111822545528412,0.4237838685512543,0.40460535883903503,0.42114144563674927,0.431893914937973,0.43408024311065674,0.4408585727214813,0.4491252601146698,0.4390050768852234,0.4309571087360382,0.4319632053375244,0.42143744230270386,0.4232906401157379,0.41840100288391113,0.4116339385509491,0.40388816595077515,0.41035327315330505,0.4047664403915405,0.40990597009658813,0.4062332808971405,0.41089126467704773,0.41150963306427,0.41107189655303955,0.40203791856765747,0.4115169644355774,0.40411707758903503,0.399118036031723,0.4065883755683899,0.412508100271225,0.4168430268764496,0.4146406650543213,0.415569543838501,0.4041599631309509,0.4003976583480835,0.40435871481895447,0.4113333523273468,0.41419175267219543,0.41292840242385864,0.4222303330898285,0.4109821319580078,0.42929190397262573,0.41148829460144043,0.42091795802116394,0.41605663299560547,0.3959813714027405,0.40459007024765015,0.4261619448661804,0.4210655689239502,0.41988319158554077,0.42375248670578003,0.42609500885009766,0.4283420145511627,0.4382815957069397,0.4231642782688141,0.4196685552597046,0.42353320121765137,0.42286133766174316,0.4205538034439087,0.416594535112381,0.4123649597167969,0.41816550493240356,0.42746514081954956,0.43883445858955383,0.45622503757476807,0.43912258744239807,0.43050625920295715,0.43484923243522644,0.42492467164993286,0.43175944685935974,0.4363628625869751,0.4379807710647583,0.429433673620224,0.42326781153678894,0.4192613661289215,0.42625728249549866,0.42569369077682495,0.42358478903770447,0.411734938621521,0.4185139834880829,0.42085525393486023,0.42643359303474426,0.4286985695362091,0.4378022253513336,0.4395606219768524,0.42412030696868896,0.44149571657180786,
mae,0.639533519744873,0.5588112473487854,0.49339190125465393,0.48186245560646057,0.4753415286540985,0.4438224136829376,0.4472430348396301,0.4311369061470032,0.38821709156036377,0.40885013341903687,0.4003286361694336,0.4083439111709595,0.41589781641960144,0.4215361773967743,0.4093972444534302,0.41748401522636414,0.40386298298835754,0.4111599028110504,0.4261903762817383,0.4262715280056,0.4342265725135803,0.4404086172580719,0.4353426694869995,0.4285290837287903,0.4283875524997711,0.4225917160511017,0.42202144861221313,0.41529110074043274,0.40829265117645264,0.4042709767818451,0.40669751167297363,0.40292757749557495,0.40838512778282166,0.4028538167476654,0.4064362645149231,0.40694695711135864,0.4075081944465637,0.40117862820625305,0.41925203800201416,0.40301966667175293,0.39943528175354004,0.4048841893672943,0.4101928472518921,0.414067804813385,0.41258230805397034,0.4090394973754883,0.39810818433761597,0.3977470099925995,0.39838141202926636,0.40355339646339417,0.409297913312912,0.40920689702033997,0.4268304705619812,0.4089127480983734,0.42639973759651184,0.4122691750526428,0.41280806064605713,0.4119189977645874,0.42250311374664307,0.40848690271377563,0.42290541529655457,0.41882047057151794,0.4130454957485199,0.4180074632167816,0.4205959737300873,0.4227057695388794,0.4272717535495758,0.41674572229385376,0.41421782970428467,0.4158589541912079,0.41620659828186035,0.4107198417186737,0.4099915027618408,0.40494486689567566,0.4081312417984009,0.4181514382362366,0.4266693592071533,0.4424096643924713,0.42696842551231384,0.4188167452812195,0.4236204922199249,0.41599559783935547,0.4245017170906067,0.4252673387527466,0.4240330457687378,0.4199705421924591,0.4115913510322571,0.4109143912792206,0.41699331998825073,0.41499632596969604,0.4154796898365021,0.4058808982372284,0.4094786047935486,0.4104944169521332,0.4161025583744049,0.41941776871681213,0.4249235987663269,0.4350602328777313,0.432516872882843,0.44272536039352417,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 7506      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 7508      
=================================================================
Total params: 15,014
Trainable params: 15,014
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 7,506
Trainable params: 7,506
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 7,508
Trainable params: 7,508
Non-trainable params: 0
_________________________________________________________________
