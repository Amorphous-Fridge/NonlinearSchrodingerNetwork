2021-06-26
loss,1.5375171899795532,0.3381820023059845,0.30961981415748596,0.2957204580307007,0.2483263462781906,0.20555612444877625,0.13778606057167053,0.10700590908527374,0.09633035957813263,0.0717998594045639,0.07932549715042114,0.06441543251276016,0.08660945296287537,0.06205017864704132,0.058255478739738464,0.05822782963514328,0.053104616701602936,0.05223967880010605,0.06643401831388474,0.0451073944568634,0.03890955075621605,0.04211689159274101,0.04574193060398102,0.04915959760546684,0.058843132108449936,0.04725084453821182,0.045835770666599274,0.044316116720438004,0.04568229243159294,0.04301527887582779,0.0437009334564209,0.041157010942697525,0.03549946844577789,0.029402028769254684,0.037931982427835464,0.04100411757826805,0.040065836161375046,0.04112837463617325,0.03615553677082062,0.03238331153988838,0.039015188813209534,0.04102974012494087,0.03645148128271103,0.04036504775285721,0.033184610307216644,0.033115774393081665,0.037668630480766296,0.036425694823265076,0.03297993913292885,0.027891356498003006,0.0388740673661232,0.035174477845430374,0.035036567598581314,0.03494974970817566,0.034053415060043335,0.032601937651634216,0.028561845421791077,0.033055782318115234,0.03440598398447037,0.02927197888493538,0.02621358074247837,0.03056204505264759,0.031034044921398163,0.029232874512672424,0.020214641466736794,0.02936437912285328,0.033063631504774094,0.032921042293310165,0.0275737214833498,0.03285470977425575,0.03097209520637989,0.02821996621787548,0.02602931298315525,0.03191406652331352,0.029200471937656403,0.02907990850508213,0.031959161162376404,0.029613032937049866,0.030478868633508682,0.02861838787794113,0.029382776468992233,0.026534833014011383,0.031991228461265564,0.02638566680252552,0.028490176424384117,0.023981662467122078,0.024089062586426735,0.02790023386478424,0.026502501219511032,0.026501597836613655,0.022277317941188812,0.025405392050743103,0.025280645117163658,0.027623474597930908,0.02542116492986679,0.025137705728411674,0.027196737006306648,0.02715460956096649,0.024612750858068466,0.02990434132516384,
mse,0.8342218995094299,0.0339001901447773,0.028994586318731308,0.026531873270869255,0.0197505634278059,0.013200881890952587,0.005684034898877144,0.003566189669072628,0.0027949728537350893,0.0015681092627346516,0.0018542425241321325,0.001268531777895987,0.002177140209823847,0.001145129557698965,0.0010356699349358678,0.0010303924791514874,0.0008575439569540322,0.0008239894523285329,0.001259089563973248,0.0006141650374047458,0.00045352260349318385,0.0005317110917530954,0.0006530877435579896,0.000758799840696156,0.0009794882498681545,0.0006492299726232886,0.0005975891253910959,0.0005791686708107591,0.0006110641988925636,0.0005359933129511774,0.0005394186009652913,0.0004978811484761536,0.00038424174999818206,0.0002606233465485275,0.00044007570249959826,0.00048270318075083196,0.00046941492473706603,0.0004846446099691093,0.00039373256731778383,0.0003158587496727705,0.00043701782124117017,0.0004909398267045617,0.00039394275518134236,0.00047831516712903976,0.00032149755861610174,0.0003212257579434663,0.00041522542596794665,0.00037057415465824306,0.0003173404838889837,0.00023547327145934105,0.00044166360748931766,0.0003607223625294864,0.00035665251198224723,0.0003633974411059171,0.00033850170439109206,0.0002991145593114197,0.00023667649656999856,0.0003123753413092345,0.00034234521444886923,0.0002518269175197929,0.00020716700237244368,0.00027592797414399683,0.0002783733361866325,0.0002678768942132592,0.00012180421617813408,0.0002475121000315994,0.0003214302414562553,0.00030418456299230456,0.00022406103380490094,0.0003141427878290415,0.00027401361148804426,0.00022966925462242216,0.00020305415091570467,0.00029588857432827353,0.0002491131308488548,0.0002565904287621379,0.00029552410705946386,0.0002538665139582008,0.00028107219259254634,0.0002482098061591387,0.00025214129709638655,0.00020250031957402825,0.00028992819716222584,0.00020385021343827248,0.00023603328736498952,0.00016832310939207673,0.0001739638828439638,0.00022995258041191846,0.00020369001140352339,0.0002158804563805461,0.00015151001571211964,0.00019022708875127137,0.00018670244025997818,0.0002232578699477017,0.0001939145295182243,0.000189456797670573,0.00022159551735967398,0.0002265218208776787,0.00017574451339896768,0.00025621920940466225,
mae,0.6225975155830383,0.14069195091724396,0.12770554423332214,0.12464281171560287,0.1047988310456276,0.08799125999212265,0.05868004262447357,0.04570833593606949,0.04098190367221832,0.030523570254445076,0.03308833763003349,0.027415165677666664,0.03683622553944588,0.026335053145885468,0.024517236277461052,0.024805786088109016,0.02236233651638031,0.022060684859752655,0.027563398703932762,0.01912495866417885,0.01626521907746792,0.017908494919538498,0.019555991515517235,0.020747579634189606,0.024106627330183983,0.019893275573849678,0.019520070403814316,0.018771620467305183,0.019018804654479027,0.01752680353820324,0.018231019377708435,0.01766236498951912,0.015198905020952225,0.012353291735053062,0.016055021435022354,0.01740412786602974,0.017245857045054436,0.017717286944389343,0.015041372738778591,0.01363055594265461,0.016697458922863007,0.01729503832757473,0.015360125340521336,0.016590513288974762,0.014017406851053238,0.013862223364412785,0.016054976731538773,0.01573745161294937,0.013939381577074528,0.011575567536056042,0.01624998264014721,0.014756500720977783,0.015042648650705814,0.014473387971520424,0.014370033517479897,0.013680797070264816,0.011998738162219524,0.013950621709227562,0.014205693267285824,0.012400051578879356,0.011031638830900192,0.013039925135672092,0.013248381204903126,0.01229754090309143,0.008500199764966965,0.012408855371177197,0.013766949065029621,0.013806446455419064,0.011668849736452103,0.013913997448980808,0.013232921250164509,0.011595828458666801,0.010908544063568115,0.01337390672415495,0.012134481221437454,0.012452551163733006,0.01330761518329382,0.012583192437887192,0.012971068732440472,0.012005566619336605,0.01216868031769991,0.01121549867093563,0.013279982842504978,0.011222434230148792,0.012173347175121307,0.01028177049010992,0.010230937972664833,0.0117869321256876,0.011136939749121666,0.011380601674318314,0.009370695799589157,0.010794936679303646,0.010652809403836727,0.01168949156999588,0.01059820968657732,0.010457401163876057,0.01141858845949173,0.011736718006432056,0.010545113123953342,0.012809098698198795,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 203795    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 203796    
=================================================================
Total params: 407,591
Trainable params: 407,591
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 203,795
Trainable params: 203,795
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 203,796
Trainable params: 203,796
Non-trainable params: 0
_________________________________________________________________
