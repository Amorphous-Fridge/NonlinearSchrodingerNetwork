2021-06-26
loss,0.5590564608573914,0.17732243239879608,0.08932505548000336,0.08081592619419098,0.06990651041269302,0.061552248895168304,0.05628332123160362,0.052427738904953,0.05043363571166992,0.0585571713745594,0.05520420894026756,0.06257398426532745,0.0497661828994751,0.05096045881509781,0.0651782676577568,0.05330881103873253,0.05787095054984093,0.08139148354530334,0.07229530066251755,0.06734886020421982,0.061999835073947906,0.058698080480098724,0.05068624019622803,0.041486334055662155,0.045539941638708115,0.05593768134713173,0.05470883473753929,0.05089426040649414,0.045466747134923935,0.03647563233971596,0.04132292419672012,0.0493144653737545,0.04255754500627518,0.03662585839629173,0.03328385949134827,0.030572999268770218,0.04535922408103943,0.04773319140076637,0.04515684023499489,0.04279407486319542,0.03911397233605385,0.03387896344065666,0.035245396196842194,0.042363014072179794,0.040495481342077255,0.03840300440788269,0.03555243834853172,0.031141281127929688,0.028245260939002037,0.026184944435954094,0.0277058407664299,0.025816289708018303,0.02482254058122635,0.028023624792695045,0.04257294163107872,0.03868860751390457,0.03721976280212402,0.03519730642437935,0.03407802805304527,0.03200843185186386,0.029631180688738823,0.027614539489150047,0.02829233556985855,0.0345618836581707,0.03173509240150452,0.026589104905724525,0.03071247786283493,0.03195207193493843,0.03026888519525528,0.02823837287724018,0.026220576837658882,0.024172797799110413,0.02236199378967285,0.021320901811122894,0.02054682932794094,0.01975470408797264,0.027135439217090607,0.032309021800756454,0.03191017732024193,0.030291814357042313,0.02887139469385147,0.027592800557613373,0.02612832374870777,0.024255746975541115,0.023151295259594917,0.024190448224544525,0.028088467195630074,0.028309866786003113,0.02693089097738266,0.025837218388915062,0.02348550409078598,0.02344391867518425,0.02276371233165264,0.023447958752512932,0.023403696715831757,0.021265923976898193,0.019691046327352524,0.021581001579761505,0.022929031401872635,0.021247781813144684,
mse,0.15242640674114227,0.010155660100281239,0.0023283804766833782,0.0018578378949314356,0.0013599388767033815,0.001065703108906746,0.0009002092410810292,0.000792352482676506,0.0007342890021391213,0.0010278737172484398,0.0009160842746496201,0.0011796028120443225,0.0006926040514372289,0.0007991505553945899,0.00125416973605752,0.0007793227559886873,0.0010220545809715986,0.0018998929299414158,0.0015435874229297042,0.0013350100489333272,0.0011149944039061666,0.0009954158449545503,0.0007237348472699523,0.0004932988667860627,0.0006004805327393115,0.0008765408420003951,0.0008436691714450717,0.0007336901617236435,0.0005797096528112888,0.0003720202948898077,0.0004928396083414555,0.0006941111641936004,0.0005156230763532221,0.00037298069219104946,0.00031313992803916335,0.00026915513444691896,0.0006046534399501979,0.0006422136793844402,0.0005803395761176944,0.0005167769850231707,0.0004276941472198814,0.000321058469126001,0.0003723999543581158,0.0005019013769924641,0.0004577629151754081,0.0004092157760169357,0.00034521802444942296,0.0002689232351258397,0.00022134935716167092,0.00019458046881482005,0.00021867408941034228,0.000186100514838472,0.00017028968431986868,0.00023405924730468541,0.000506255601067096,0.0004189061000943184,0.0003858113195747137,0.00034815125400200486,0.00032813032157719135,0.0002861354441847652,0.00024507567286491394,0.00021757223294116557,0.00023258996952790767,0.0003261598467361182,0.00027423491701483727,0.0002001214597839862,0.000264449481619522,0.00027889921329915524,0.00024993010447360575,0.00021821787231601775,0.0001903316588141024,0.0001610974286450073,0.00013876189768780023,0.00012688132119365036,0.00011782228102674708,0.0001106355048250407,0.00021127864602021873,0.0002917571400757879,0.00027935495018027723,0.00025319671840406954,0.00022923422511667013,0.0002106578031089157,0.00018826265295501798,0.0001643829164095223,0.00015110181993804872,0.00017928757006302476,0.00022024402278475463,0.00021707857376895845,0.00019856318249367177,0.00018522462050896138,0.0001568435545777902,0.00015271356096491218,0.0001489635615143925,0.00015728115977253765,0.00015387896564789116,0.0001265824248548597,0.00010995750926667824,0.00013384339399635792,0.0001427424285793677,0.00012810889165848494,
mae,0.23861177265644073,0.07514271885156631,0.03835520148277283,0.034557949751615524,0.030376922339200974,0.02669995091855526,0.024439312517642975,0.022604389116168022,0.02160937525331974,0.025238754227757454,0.023829393088817596,0.026854166761040688,0.021489083766937256,0.02194131910800934,0.02807251736521721,0.022928016260266304,0.02458018995821476,0.03561685234308243,0.031732019037008286,0.029666263610124588,0.027340862900018692,0.02585209533572197,0.022318251430988312,0.017537567764520645,0.01946943812072277,0.02469514310359955,0.024113990366458893,0.022490933537483215,0.019800463691353798,0.015384330414235592,0.017503736540675163,0.02192646451294422,0.01839025691151619,0.015664100646972656,0.01403492409735918,0.01279005128890276,0.019698718562722206,0.021001821383833885,0.019894100725650787,0.018903743475675583,0.017365535721182823,0.014562636613845825,0.01494433544576168,0.018600303679704666,0.018017686903476715,0.01709902100265026,0.015347745269536972,0.012914481572806835,0.012094220146536827,0.01125418022274971,0.011928333900868893,0.01124497875571251,0.010774653404951096,0.012036117725074291,0.018719637766480446,0.017033757641911507,0.016366006806492805,0.015465790405869484,0.01502561941742897,0.014039874076843262,0.012617994099855423,0.011874730698764324,0.012281086295843124,0.014919809997081757,0.01367635652422905,0.010973946191370487,0.013159669935703278,0.014138954691588879,0.013455932028591633,0.012277346104383469,0.011530463583767414,0.010659235529601574,0.009808585047721863,0.009332173503935337,0.008991002105176449,0.008488483726978302,0.011633007787168026,0.014169003814458847,0.014039207249879837,0.013363420963287354,0.012701356783509254,0.011983687058091164,0.011111749336123466,0.010113383643329144,0.009794098325073719,0.010326718911528587,0.011932827532291412,0.012172593735158443,0.0117668891325593,0.01130181085318327,0.010066725313663483,0.009785542264580727,0.009672454558312893,0.00989627931267023,0.009754575788974762,0.008512360975146294,0.00830839667469263,0.009191089309751987,0.009847364388406277,0.009075410664081573,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 18283     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 18284     
=================================================================
Total params: 36,567
Trainable params: 36,567
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 18,283
Trainable params: 18,283
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 18,284
Trainable params: 18,284
Non-trainable params: 0
_________________________________________________________________
