2021-06-26
loss,1.0986409187316895,0.24791021645069122,0.17908279597759247,0.11130550503730774,0.09092411398887634,0.09430095553398132,0.09345035254955292,0.07765451073646545,0.07986234128475189,0.07634240388870239,0.06681209802627563,0.06296347826719284,0.04835382476449013,0.05139293149113655,0.06175622344017029,0.053439732640981674,0.05337044224143028,0.050750747323036194,0.05451751872897148,0.043264083564281464,0.03791666403412819,0.05124563351273537,0.0535367950797081,0.0432635098695755,0.04606596380472183,0.047320857644081116,0.03494018688797951,0.03568021208047867,0.03899843990802765,0.03983333706855774,0.04195791855454445,0.03532243147492409,0.03883839771151543,0.034412872046232224,0.03845713660120964,0.032948996871709824,0.024552932009100914,0.0318397656083107,0.037117522209882736,0.03156667947769165,0.0291733480989933,0.0333818756043911,0.03383171558380127,0.03136284649372101,0.03425880894064903,0.03157705068588257,0.027911808341741562,0.03176436573266983,0.029794247820973396,0.030808812007308006,0.029690589755773544,0.027730483561754227,0.02988600917160511,0.0329330675303936,0.02793959155678749,0.02469516359269619,0.026642924174666405,0.023569149896502495,0.029671967029571533,0.02661961503326893,0.02673746831715107,0.027193492278456688,0.02746407501399517,0.027316592633724213,0.026173295453190804,0.026203589513897896,0.023282082751393318,0.028767574578523636,0.026304328814148903,0.02586808241903782,0.025502994656562805,0.025966215878725052,0.02341565676033497,0.024104543030261993,0.024443138390779495,0.02384570986032486,0.02413131482899189,0.020909328013658524,0.02190817892551422,0.025933444499969482,0.02381034381687641,0.021771559491753578,0.024269532412290573,0.024500418454408646,0.0213681198656559,0.022935068234801292,0.02028632164001465,0.021167105063796043,0.02304605208337307,0.020128803327679634,0.020262209698557854,0.022394265979528427,0.02143455669283867,0.024970363825559616,0.021652065217494965,0.018858401104807854,0.01873854734003544,0.022463519126176834,0.020276987925171852,0.016574718058109283,
mse,0.4613772928714752,0.01998128741979599,0.00985662080347538,0.0038575220387429,0.002482454990968108,0.002605448942631483,0.002634734846651554,0.0018685151590034366,0.0019886058289557695,0.0018678000196814537,0.0013489560224115849,0.0012330168392509222,0.0007029373664408922,0.0008016456849873066,0.0011867238208651543,0.0008601383888162673,0.0008786956313997507,0.0007974666077643633,0.0009099527960643172,0.0005860129604116082,0.0004370506212580949,0.0007800859166309237,0.000846012553665787,0.0005715113948099315,0.0006182586657814682,0.0006427820771932602,0.0003929991216864437,0.00039275726885534823,0.0004604979185387492,0.0004910784773528576,0.0005198628059588373,0.000377730350010097,0.000455267756478861,0.0003521250910125673,0.0004291982913855463,0.00035398409818299115,0.00019114668248221278,0.00030056413379497826,0.00041016380419023335,0.0002956089156214148,0.0002570247452240437,0.00032307804212905467,0.0003459332510828972,0.00030627165688201785,0.0003342890995554626,0.00029944058042019606,0.00023243790201377124,0.00029230210930109024,0.00026006673579104245,0.0002753675216808915,0.00025675527285784483,0.00023081214749254286,0.00026987347519025207,0.0003022027958650142,0.00022471895499620587,0.00018294135225005448,0.0002051256742561236,0.00016742906882427633,0.00025454798014834523,0.00021424631995614618,0.00020972097991034389,0.00022118803462944925,0.00022351526422426105,0.0002219672896899283,0.00020147468603681773,0.0002014712808886543,0.0001577903312863782,0.00024149211822077632,0.00019884173525497317,0.00019020507170353085,0.0001947069977177307,0.0001938603090820834,0.00016085105016827583,0.00016924231022130698,0.00017257418949157,0.0001664045121287927,0.00017142495198640972,0.00012977961159776896,0.00014025589916855097,0.00019097713811788708,0.00016158013022504747,0.00013828273222316056,0.00016684530419297516,0.0001731661759549752,0.00013330041838344187,0.00014686203212477267,0.0001204560321639292,0.00013196140935178846,0.00015238701598718762,0.00011610110232140869,0.00011960812116740271,0.00014291091065388173,0.00013520913489628583,0.00017371293506585062,0.00013479428889695555,0.00010543058306211606,0.00010493348236195743,0.00014313642168417573,0.00011804928362835199,8.279506437247619e-05,
mae,0.465346097946167,0.10575295239686966,0.07571665942668915,0.04740379750728607,0.03879762068390846,0.040086910128593445,0.03948930278420448,0.03344889357686043,0.034094274044036865,0.03281475603580475,0.0289207324385643,0.026948126032948494,0.02074684388935566,0.021889138966798782,0.026333607733249664,0.022758977487683296,0.022664852440357208,0.021993231028318405,0.023125112056732178,0.018439562991261482,0.016314931213855743,0.02216912806034088,0.023432563990354538,0.018897581845521927,0.020022545009851456,0.019680935889482498,0.014937316998839378,0.015249431133270264,0.01688811369240284,0.017082454636693,0.017825907096266747,0.015059157274663448,0.01674540713429451,0.014885886572301388,0.016502395272254944,0.014142895117402077,0.010390876792371273,0.013517235405743122,0.01584504544734955,0.013456065207719803,0.01233949139714241,0.014058126136660576,0.014588623307645321,0.013224329799413681,0.01452248077839613,0.013547083362936974,0.01181122101843357,0.013791949488222599,0.012709095142781734,0.012961491011083126,0.012770610861480236,0.011826875619590282,0.012636524625122547,0.014198613353073597,0.012276842258870602,0.010445956140756607,0.011390406638383865,0.010059221647679806,0.012888971716165543,0.01133199967443943,0.011300564743578434,0.011515552178025246,0.01168655976653099,0.011872027069330215,0.01129315234720707,0.011245673522353172,0.009816009551286697,0.01205714326351881,0.011320706456899643,0.011097447015345097,0.010963639244437218,0.01088195201009512,0.009906084276735783,0.010389220900833607,0.010422641411423683,0.010210935957729816,0.010063955560326576,0.008806033991277218,0.00925567839294672,0.010914542712271214,0.010111488401889801,0.009282419458031654,0.010202053003013134,0.01018441841006279,0.009082641452550888,0.009951126761734486,0.008681024424731731,0.00898342952132225,0.009730302728712559,0.008652779273688793,0.008772876113653183,0.00964900478720665,0.009094680659472942,0.010112902149558067,0.00921441987156868,0.007873628288507462,0.007972230203449726,0.009859111160039902,0.008634937927126884,0.0070265354588627815,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 135019    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 135020    
=================================================================
Total params: 270,039
Trainable params: 270,039
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 135,019
Trainable params: 135,019
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 135,020
Trainable params: 135,020
Non-trainable params: 0
_________________________________________________________________
