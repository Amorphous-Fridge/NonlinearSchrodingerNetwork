2021-06-26
loss,1.4826512336730957,0.36606472730636597,0.3063836991786957,0.25821179151535034,0.2485056072473526,0.2282126396894455,0.2538483738899231,0.22723853588104248,0.21776893734931946,0.2091100811958313,0.171922504901886,0.14282305538654327,0.16690310835838318,0.12487556785345078,0.09584306925535202,0.08412019908428192,0.0884346291422844,0.07690093666315079,0.09020978212356567,0.07224226742982864,0.06572116911411285,0.06647510826587677,0.057964663952589035,0.050881754606962204,0.052882421761751175,0.05439572408795357,0.04972616210579872,0.056012216955423355,0.04909970611333847,0.055374566465616226,0.044191665947437286,0.048559561371803284,0.04236369580030441,0.043831657618284225,0.04372059926390648,0.043068353086709976,0.03794487938284874,0.039751335978507996,0.03543977439403534,0.03913455829024315,0.04211704805493355,0.034330103546381,0.04083312675356865,0.0378682017326355,0.03645341470837593,0.029338212683796883,0.035827022045850754,0.03759387135505676,0.03181084990501404,0.033020325005054474,0.03586385399103165,0.034830838441848755,0.031046228483319283,0.0313601978123188,0.03387971967458725,0.03487701714038849,0.032774485647678375,0.029943855479359627,0.030593276023864746,0.03292284160852432,0.029926327988505363,0.030723709613084793,0.028157303109765053,0.030291546136140823,0.032784171402454376,0.028160246089100838,0.02845587208867073,0.030778711661696434,0.028365524485707283,0.025617729872465134,0.028160706162452698,0.02813071757555008,0.029273178428411484,0.028410909697413445,0.02662615105509758,0.024459686130285263,0.02789631299674511,0.026164792478084564,0.028703246265649796,0.026158036664128304,0.025280941277742386,0.024310290813446045,0.025275539606809616,0.025737633928656578,0.02602366916835308,0.025561463087797165,0.026120580732822418,0.02579314075410366,0.02972862496972084,0.0255520511418581,0.025403719395399094,0.025301175191998482,0.021290456876158714,0.02150014601647854,0.026599764823913574,0.023793203756213188,0.026368863880634308,0.02670874074101448,0.025361472740769386,0.022705834358930588,
mse,1.0098363161087036,0.039659783244132996,0.02852209284901619,0.021356448531150818,0.020190466195344925,0.017344476655125618,0.021510165184736252,0.017729973420500755,0.01659245789051056,0.015412827953696251,0.010108891874551773,0.006141528487205505,0.008126651868224144,0.004489741753786802,0.0026505482383072376,0.002081159967929125,0.0022802914027124643,0.0017172376392409205,0.0023474267218261957,0.001522840466350317,0.0012430893257260323,0.00128121895249933,0.0009757659863680601,0.0008045033900998533,0.0008109868504106998,0.0008431845926679671,0.0007290313369594514,0.0008870873716659844,0.0007011458510532975,0.0008640963351354003,0.0005707651725970209,0.0006540330359712243,0.0005218572332523763,0.0005537164397537708,0.000552337325643748,0.0005316705792210996,0.00042344286339357495,0.0004485783283598721,0.0003677290224004537,0.0004423799109645188,0.0005030481843277812,0.0003415748360566795,0.0004741860320791602,0.0004125174891669303,0.0003754275676328689,0.0002581127919256687,0.000364305597031489,0.0003966280200984329,0.000297125632641837,0.000318301550578326,0.00037328858161345124,0.0003362975548952818,0.0002788786659948528,0.0002795068430714309,0.00032407481921836734,0.0003472183016128838,0.00031032750848680735,0.00025843700859695673,0.00026299874298274517,0.00030962779419496655,0.0002567236952017993,0.0002658117446117103,0.00022742892906535417,0.00026749944663606584,0.00030195998260751367,0.00022377647110261023,0.00022966359392739832,0.00027137319557368755,0.000226592572289519,0.00019504380179569125,0.00022927112877368927,0.00021460436983034015,0.0002473230706527829,0.00023107895685825497,0.00020923270494677126,0.00017768882389646024,0.0002237192529719323,0.00019810086814686656,0.0002343942760489881,0.00019463710486888885,0.00019097403855994344,0.0001722707529552281,0.00017953789210878313,0.00019120570505037904,0.00019735565001610667,0.0001864036312326789,0.00019517855253070593,0.00019489876285661012,0.00024339769151993096,0.00018664445087779313,0.00018302688840776682,0.00019091473950538784,0.00013914736337028444,0.00013938396295998245,0.00020473796757869422,0.00016672807396389544,0.00019949402485508472,0.00020771891286130995,0.00018712067685555667,0.0001517479249741882,
mae,0.6164749264717102,0.1614672988653183,0.13343721628189087,0.11185396462678909,0.10767530649900436,0.0973023921251297,0.10740819573402405,0.09777795523405075,0.09163764864206314,0.087669238448143,0.07353717088699341,0.06075871363282204,0.07206442207098007,0.05357511341571808,0.040741726756095886,0.035537317395210266,0.0374833345413208,0.03277624025940895,0.0379224568605423,0.03087679110467434,0.027860252186655998,0.027712393552064896,0.024825729429721832,0.021702274680137634,0.022832129150629044,0.023312339559197426,0.02142805978655815,0.024379203096032143,0.02127983048558235,0.023323338478803635,0.019016969949007034,0.02112123928964138,0.018142685294151306,0.018951978534460068,0.018534434959292412,0.01876087486743927,0.01617260091006756,0.01684681884944439,0.015118032693862915,0.0165876392275095,0.01773666776716709,0.014590298756957054,0.017626527696847916,0.016368443146348,0.015405560843646526,0.01252518780529499,0.01521263923496008,0.01615208573639393,0.013624928891658783,0.014167463406920433,0.014999969862401485,0.014705413952469826,0.013125701807439327,0.01340477541089058,0.014342724345624447,0.014659889042377472,0.014007543213665485,0.012772411108016968,0.012945328839123249,0.013818012550473213,0.012851277366280556,0.01324382796883583,0.011971444822847843,0.01293756254017353,0.014093808829784393,0.011917423456907272,0.012112921103835106,0.01311720721423626,0.01213117316365242,0.010937762446701527,0.011848174035549164,0.0119487214833498,0.012534928508102894,0.011982150375843048,0.011239306069910526,0.010313203558325768,0.011810434982180595,0.011300001293420792,0.012148363515734673,0.011187087744474411,0.010721414349973202,0.010327266529202461,0.01066239271312952,0.01086329109966755,0.010961659252643585,0.010879447683691978,0.011181119829416275,0.011103508062660694,0.012861273251473904,0.010794583708047867,0.0107661671936512,0.010759294033050537,0.008997847326099873,0.00916384533047676,0.011421846225857735,0.010192811489105225,0.011309751309454441,0.011464825831353664,0.010841332376003265,0.009621514938771725,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 275667    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 275668    
=================================================================
Total params: 551,335
Trainable params: 551,335
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 275,667
Trainable params: 275,667
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 275,668
Trainable params: 275,668
Non-trainable params: 0
_________________________________________________________________
