2021-06-26
loss,0.7249107360839844,0.2573026716709137,0.24369759857654572,0.237605020403862,0.23111699521541595,0.22050514817237854,0.1921108067035675,0.18255534768104553,0.16707850992679596,0.11869509518146515,0.11481498926877975,0.09420210868120193,0.1008772924542427,0.0864529013633728,0.09273240715265274,0.0692315548658371,0.05776569992303848,0.0559685081243515,0.06042243912816048,0.06427384167909622,0.056629400700330734,0.050532951951026917,0.061590470373630524,0.05800740420818329,0.052058830857276917,0.052701760083436966,0.04705454036593437,0.04243643209338188,0.04580959677696228,0.045476630330085754,0.0449073351919651,0.04464738070964813,0.04221979156136513,0.04190203174948692,0.04131152108311653,0.041060153394937515,0.03592691943049431,0.040750112384557724,0.03630754351615906,0.03279583528637886,0.029203906655311584,0.03204010799527168,0.03829774633049965,0.04257545992732048,0.03507427126169205,0.030951952561736107,0.03328026831150055,0.036723390221595764,0.031200816854834557,0.03343178331851959,0.0351700484752655,0.03497985005378723,0.02974824607372284,0.028966939076781273,0.02793526090681553,0.030475899577140808,0.029419779777526855,0.029944822192192078,0.02907337248325348,0.028441844508051872,0.028752760961651802,0.03153511881828308,0.029277406632900238,0.027387820184230804,0.029120445251464844,0.030210696160793304,0.027131760492920876,0.024571383371949196,0.024087009951472282,0.029384849593043327,0.025286488234996796,0.02634572982788086,0.026442954316735268,0.023570546880364418,0.026408137753605843,0.02623513713479042,0.025015709921717644,0.023532047867774963,0.023483866825699806,0.024683857336640358,0.02441822923719883,0.02425980381667614,0.022010590881109238,0.02268110029399395,0.01998191699385643,0.01646285131573677,0.02100510522723198,0.02435126155614853,0.02479366585612297,0.02384243905544281,0.025407789275050163,0.022850409150123596,0.021039990708231926,0.023321211338043213,0.021045343950390816,0.022437067702412605,0.020755194127559662,0.019031887874007225,0.018776899203658104,0.021141545847058296,
mse,0.24363525211811066,0.02109578438103199,0.019625891000032425,0.018931522965431213,0.018077852204442024,0.016486262902617455,0.011301407590508461,0.009653113782405853,0.00890224240720272,0.004208040423691273,0.003734919708222151,0.0025607997085899115,0.00283009628765285,0.0021842780988663435,0.002393740462139249,0.0013875998556613922,0.0009445085888728499,0.0008901616092771292,0.0010399670572951436,0.001198305282741785,0.0008811812149360776,0.0007135375053621829,0.0010652897180989385,0.0009448687196709216,0.0007734203245490789,0.0008037700317800045,0.0006158838514238596,0.0005136123509146273,0.0005880854441784322,0.0005838966462761164,0.0005812398158013821,0.00056993099860847,0.0005169279174879193,0.00048620704910717905,0.0004908714909106493,0.0005001944955438375,0.0003625846584327519,0.0004647155583370477,0.00037039548624306917,0.00030500232242047787,0.00024761277018114924,0.00029407429974526167,0.00040956161683425307,0.0005145945469848812,0.00034932789276354015,0.00027371905161999166,0.00031432785908691585,0.0003781079431064427,0.00026963918935507536,0.00031166416010819376,0.0003458359860815108,0.00034071903792209923,0.00024858812685124576,0.00023625430185347795,0.00022781238658353686,0.00026386845274828374,0.00023994526418391615,0.0002523372240830213,0.00024024838057812303,0.000230850899242796,0.00023161149874795228,0.000280112522887066,0.00024252432922367007,0.00020886048150714487,0.00023754235007800162,0.00025160968652926385,0.00020117151143494993,0.00016633888299111277,0.000164568773470819,0.00023775013687554747,0.00018022941367235035,0.00019129384600091726,0.00019573568715713918,0.00015719851944595575,0.0001915873435791582,0.00019880618492607027,0.00017495607607997954,0.00015752841136418283,0.00015899351274129003,0.00016834944835864007,0.00016690947813913226,0.00016236508963629603,0.00013711434439755976,0.00014331849524751306,0.00011582738079596311,8.138240082189441e-05,0.00012879414134658873,0.00016691035125404596,0.0001719340798445046,0.00016143164248205721,0.00018531944078858942,0.00014602590817958117,0.00012644409434869885,0.00015888205962255597,0.00012416589015629143,0.00014284247299656272,0.00012402681750245392,0.00010461918282089755,0.00010131845920113847,0.0001278539712075144,
mae,0.31334352493286133,0.11251949518918991,0.10841240733861923,0.10567446053028107,0.1025075688958168,0.09638112783432007,0.08165358752012253,0.07811437547206879,0.07061074674129486,0.049910079687833786,0.04850730299949646,0.03988591954112053,0.04331577941775322,0.03622838854789734,0.03984277695417404,0.030045704916119576,0.02449415996670723,0.023594573140144348,0.02574925497174263,0.027092553675174713,0.024191390722990036,0.021641578525304794,0.026194298639893532,0.024727623909711838,0.021794598549604416,0.02292635291814804,0.01996523328125477,0.018088804557919502,0.019373292103409767,0.019636886194348335,0.01940111070871353,0.019426999613642693,0.01811080053448677,0.017889482900500298,0.017856694757938385,0.01725638657808304,0.015108143910765648,0.01812087744474411,0.015529567375779152,0.01378563605248928,0.012295913882553577,0.013781704008579254,0.01643703319132328,0.01868455857038498,0.015156703069806099,0.013250232674181461,0.014009344391524792,0.01567651890218258,0.013205046765506268,0.014254570938646793,0.015167256817221642,0.015114978887140751,0.012752844952046871,0.012228358536958694,0.011858734302222729,0.013058450073003769,0.012534941546618938,0.012870832346379757,0.012287111021578312,0.011935539543628693,0.01219242438673973,0.013426688499748707,0.012448430061340332,0.01156107522547245,0.012435894459486008,0.01283959113061428,0.011592821218073368,0.010492700152099133,0.010102441534399986,0.012655625119805336,0.010789414867758751,0.01127607747912407,0.011511672288179398,0.009983235970139503,0.011004723608493805,0.01110072247684002,0.010554703883826733,0.010178548283874989,0.009992378763854504,0.010488922707736492,0.010501052252948284,0.010531996376812458,0.009234989993274212,0.009605946950614452,0.008369398303329945,0.00699326628819108,0.008890154771506786,0.01040039025247097,0.010503893718123436,0.010019414126873016,0.010885458439588547,0.009677904658019543,0.008949082344770432,0.010107054375112057,0.00885876826941967,0.009515016339719296,0.008765364065766335,0.008064968511462212,0.007947126403450966,0.009003598242998123,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 72419     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 72420     
=================================================================
Total params: 144,839
Trainable params: 144,839
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 72,419
Trainable params: 72,419
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 72,420
Trainable params: 72,420
Non-trainable params: 0
_________________________________________________________________
