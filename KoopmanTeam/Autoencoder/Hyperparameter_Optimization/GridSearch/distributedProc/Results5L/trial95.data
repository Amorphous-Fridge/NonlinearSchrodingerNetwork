2021-06-26
loss,1.085375428199768,0.19938308000564575,0.1436687409877777,0.11362245678901672,0.1050458550453186,0.08802250027656555,0.07197750359773636,0.06638762354850769,0.056271497160196304,0.06046989560127258,0.052867207676172256,0.043823618441820145,0.04597296193242073,0.05520614609122276,0.044967010617256165,0.04751541465520859,0.03874650597572327,0.04366402328014374,0.038950785994529724,0.03624159097671509,0.031436268240213394,0.03427291288971901,0.03671513497829437,0.03216996043920517,0.031069625169038773,0.027470113709568977,0.03007424809038639,0.03150540217757225,0.028203463181853294,0.02626482956111431,0.032596055418252945,0.030519001185894012,0.02929176390171051,0.026808081194758415,0.029206551611423492,0.022220797836780548,0.019784146919846535,0.021351845934987068,0.027518104761838913,0.024063237011432648,0.02246316708624363,0.023803317919373512,0.024098314344882965,0.0228025633841753,0.024916166439652443,0.022762756794691086,0.024166304618120193,0.021547669544816017,0.02330143004655838,0.022571664303541183,0.02195318043231964,0.020348725840449333,0.0200534388422966,0.02069520391523838,0.02303503267467022,0.02333167940378189,0.021493935957551003,0.020228903740644455,0.018261102959513664,0.019972793757915497,0.02070571482181549,0.019279692322015762,0.01861860603094101,0.019627941772341728,0.01984313130378723,0.020203806459903717,0.019916707649827003,0.018960939720273018,0.01915103569626808,0.01860036887228489,0.019413456320762634,0.018507033586502075,0.019473396241664886,0.017597267404198647,0.016484487801790237,0.01871289499104023,0.018529348075389862,0.017668597400188446,0.018043052405118942,0.015280790627002716,0.017129259184002876,0.015417421236634254,0.01797328144311905,0.01981034129858017,0.017354058101773262,0.015686646103858948,0.01895398646593094,0.018629565834999084,0.017791572958230972,0.017827846109867096,0.018467895686626434,0.017933428287506104,0.017884274944663048,0.01729719340801239,0.016283638775348663,0.015853509306907654,0.01605989784002304,0.017101958394050598,0.0168630201369524,0.015988409519195557,
mse,0.5491740703582764,0.0117514468729496,0.005967176053673029,0.0037893184926360846,0.003243927378207445,0.0023362799547612667,0.001554363640025258,0.0012723159743472934,0.0009561111219227314,0.0010929120471701026,0.0008302926435135305,0.0005780255305580795,0.00064562022453174,0.0009009723435156047,0.0006031753728166223,0.0006895402329973876,0.0004494266177061945,0.000552582205273211,0.00044168243766762316,0.0003886124468408525,0.0002891188196372241,0.0003477199061308056,0.00039120321162045,0.0003040095034521073,0.00028354482492432,0.000219905428821221,0.00027017458342015743,0.0002884484420064837,0.00023641009465791285,0.00020476897771004587,0.0002982946753036231,0.0002679380704648793,0.0002400108496658504,0.0002201459719799459,0.00023996089294087142,0.00014677419676445425,0.00011502153211040422,0.00013713000225834548,0.000215713691432029,0.00016612712352070957,0.00014537147944793105,0.00016478208999615163,0.00017007207497954369,0.00015308264119084924,0.00017338371253572404,0.00014804776583332568,0.00016746929031796753,0.0001358269655611366,0.00015461798466276377,0.00014448552974499762,0.00013652557390742004,0.0001189831382362172,0.00011589295900193974,0.00012413687363732606,0.00014848551654722542,0.0001503077073721215,0.0001291451189899817,0.00011629326036199927,9.780256368685514e-05,0.0001167156733572483,0.00012017666449537501,0.00010840042523341253,0.00010103057866217569,0.00011172266385983676,0.00011472834012238309,0.00011685506615322083,0.00011378540511941537,0.00010458430188009515,0.00010659763938747346,0.00010042178473668173,0.00010886993550229818,9.920145384967327e-05,0.00010868555546039715,9.189629054162651e-05,8.154192619258538e-05,0.00010197984374826774,9.92359418887645e-05,9.233195305569097e-05,9.541848703520373e-05,7.059016934363171e-05,8.770518616074696e-05,7.124705007299781e-05,9.363304707221687e-05,0.00011058110976591706,8.689356036484241e-05,7.403202471323311e-05,0.00010466744424775243,0.0001015633752103895,9.201972716255113e-05,9.191655408358201e-05,9.771722397999838e-05,9.410498023498803e-05,9.099376620724797e-05,8.671224350109696e-05,7.856800220906734e-05,7.501077925553545e-05,7.661111885681748e-05,8.722809434402734e-05,8.582572627346963e-05,7.575777999591082e-05,
mae,0.450835257768631,0.08415040373802185,0.061032138764858246,0.04898447543382645,0.04453984275460243,0.03761262819170952,0.03076600469648838,0.028006797656416893,0.023982198908925056,0.025905663147568703,0.02248145081102848,0.018544239923357964,0.01980733685195446,0.02362784370779991,0.019183553755283356,0.0199641864746809,0.01651717722415924,0.01859436184167862,0.016424236819148064,0.015343992970883846,0.013273080810904503,0.014556732960045338,0.01558701042085886,0.013670122250914574,0.013094883412122726,0.011602967046201229,0.012805541977286339,0.013474651612341404,0.011948764324188232,0.011196199804544449,0.013737495057284832,0.01295525673776865,0.01256913784891367,0.011319916695356369,0.012420248240232468,0.009455747902393341,0.008353006094694138,0.009059609845280647,0.011864053085446358,0.010166028514504433,0.009525069035589695,0.010225368663668633,0.010279800742864609,0.009764343500137329,0.01070463191717863,0.009739057160913944,0.010301441885530949,0.009058552794158459,0.009882570244371891,0.009738734923303127,0.009300973266363144,0.008630170486867428,0.008529096841812134,0.00875960011035204,0.009755285456776619,0.009923569858074188,0.009185069240629673,0.008510507643222809,0.007797200232744217,0.00834682211279869,0.00877904798835516,0.008226223289966583,0.007842457853257656,0.008303647860884666,0.008323172107338905,0.008580873720347881,0.00842746626585722,0.008106966502964497,0.00818152166903019,0.007927272468805313,0.008239848539233208,0.00787007063627243,0.008369605988264084,0.007498407270759344,0.007013702765107155,0.007972164079546928,0.00796541664749384,0.00756441056728363,0.007648972328752279,0.0065221404656767845,0.007282499689608812,0.006565283518284559,0.007550013717263937,0.008555143140256405,0.007376482710242271,0.006644143257290125,0.008039658889174461,0.007871103473007679,0.007480739150196314,0.007546010427176952,0.007772869896143675,0.007630284409970045,0.00760892266407609,0.007282672915607691,0.0068579441867768764,0.006721134763211012,0.006805419921875,0.0073263817466795444,0.007100211456418037,0.0066537437960505486,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 144579    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 144580    
=================================================================
Total params: 289,159
Trainable params: 289,159
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 144,579
Trainable params: 144,579
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 144,580
Trainable params: 144,580
Non-trainable params: 0
_________________________________________________________________
