2021-06-26
loss,0.6881687641143799,0.2663131356239319,0.1948268711566925,0.13833577930927277,0.14149051904678345,0.10624038428068161,0.10319657623767853,0.0927431508898735,0.07618570327758789,0.08267160505056381,0.08946007490158081,0.06963054090738297,0.07054195553064346,0.071288101375103,0.05574512109160423,0.05159284546971321,0.06081703305244446,0.047879066318273544,0.04833097383379936,0.04718463495373726,0.043761029839515686,0.04658529907464981,0.042051270604133606,0.03856278955936432,0.038144420832395554,0.03299456089735031,0.037489935755729675,0.035636577755212784,0.0352168083190918,0.03422834351658821,0.032529737800359726,0.030816156417131424,0.028651006519794464,0.02842443250119686,0.028036588802933693,0.03165554255247116,0.02880650758743286,0.025462906807661057,0.026271231472492218,0.028645921498537064,0.024601450189948082,0.022961871698498726,0.02014031819999218,0.030010800808668137,0.02601500041782856,0.021347468718886375,0.021557895466685295,0.02258971519768238,0.024990899488329887,0.023058170452713966,0.023941151797771454,0.02502240613102913,0.023789025843143463,0.025529539212584496,0.022313550114631653,0.020204994827508926,0.021407771855592728,0.02251114323735237,0.022674180567264557,0.02355787716805935,0.019906239584088326,0.021592916920781136,0.020594440400600433,0.01932888850569725,0.02178267203271389,0.022554336115717888,0.020758381113409996,0.017091602087020874,0.020574059337377548,0.022303888574242592,0.020970972254872322,0.02008800022304058,0.020761359483003616,0.020144937559962273,0.01846442185342312,0.017579210922122,0.02163250744342804,0.02034986950457096,0.019442683085799217,0.019309476017951965,0.019224863499403,0.018536023795604706,0.01630331017076969,0.017727240920066833,0.018002448603510857,0.019679289311170578,0.020556427538394928,0.018042076379060745,0.019314631819725037,0.01871529407799244,0.01987549476325512,0.018395734950900078,0.017966322600841522,0.016173915937542915,0.016104644164443016,0.017487498000264168,0.02034740522503853,0.01884080469608307,0.018167225643992424,0.018435994163155556,
mse,0.21570686995983124,0.02236158773303032,0.011635098606348038,0.005458794999867678,0.006174000911414623,0.003358294954523444,0.0031964373774826527,0.00241932668723166,0.0016378579894080758,0.001977809239178896,0.002300481079146266,0.001382181653752923,0.0014052421320229769,0.001408840878866613,0.0008889622986316681,0.0007802753243595362,0.001030687359161675,0.0006512175314128399,0.0006458137067966163,0.0006204720702953637,0.0005322590004652739,0.0006057780119590461,0.0004807257791981101,0.00042301806388422847,0.00041455039172433317,0.00031294231303036213,0.00041043394594453275,0.00035563454730436206,0.0003524094063322991,0.0003255228220950812,0.0002897449885495007,0.00026833018637262285,0.0002309752017026767,0.00022928780526854098,0.0002203836920671165,0.0002815491461660713,0.00022980727953836322,0.00018025454482994974,0.00019481370691210032,0.00022974316379986703,0.00017120108532253653,0.00014908454613760114,0.00012094555131625384,0.0002567546034697443,0.00019262100977357477,0.00013563725224230438,0.00013789042714051902,0.00014674634439870715,0.0001731322699924931,0.00014928015298210084,0.00016246330051217228,0.00017326889792457223,0.00016631963080726564,0.00018293324683327228,0.0001405823859386146,0.00011740816989913583,0.00013548578135669231,0.00014472779002971947,0.00014721813204232603,0.00015474698739126325,0.00011433343752287328,0.00013251019117888063,0.00011960919800912961,0.00010801232565427199,0.00013859615137334913,0.00014319358160719275,0.00012318664812482893,8.919736137613654e-05,0.00012172684364486486,0.00013971872976981103,0.0001266722974833101,0.00011474739585537463,0.00012429941853042692,0.00011711809202097356,9.93634675978683e-05,9.20424863579683e-05,0.00013287297042552382,0.00011705067299772054,0.00010905673843808472,0.00010892382852034643,0.0001062283554347232,0.00010007696255343035,8.018690277822316e-05,9.303393017034978e-05,9.490770025877282e-05,0.00011120404815301299,0.00011799703497672454,9.559968748362735e-05,0.0001073866369551979,0.00010177283547818661,0.00011253939737798646,9.638172923587263e-05,9.159170440398157e-05,7.567983266199008e-05,7.848405948607251e-05,8.998675184557214e-05,0.00012050483201164752,0.00010141201346414164,9.643330122344196e-05,0.00010034030128736049,
mae,0.2893163859844208,0.11744453758001328,0.08381836861371994,0.059431031346321106,0.0606294721364975,0.04523209482431412,0.04418221861124039,0.039613064378499985,0.03250063583254814,0.03485230728983879,0.038101378828287125,0.030035536736249924,0.030266376212239265,0.031244948506355286,0.024018988013267517,0.021964799612760544,0.026303477585315704,0.020084798336029053,0.02086767740547657,0.02053723856806755,0.018564553931355476,0.020304962992668152,0.018243860453367233,0.016573844477534294,0.01622639037668705,0.014057070948183537,0.015962032601237297,0.015306792221963406,0.015567958354949951,0.014613104984164238,0.013957977294921875,0.013216388411819935,0.01213223859667778,0.012134728021919727,0.011767396703362465,0.013318258337676525,0.01241808570921421,0.010907675139605999,0.011094745248556137,0.012412339448928833,0.010483542457222939,0.009871862828731537,0.008534245193004608,0.012821848504245281,0.0109040392562747,0.009062446653842926,0.009250794537365437,0.009506120346486568,0.0104539655148983,0.009694451466202736,0.010111632756888866,0.01073890645056963,0.01019317377358675,0.01106060016900301,0.00940271932631731,0.008460868149995804,0.009207651019096375,0.009388795122504234,0.00965510867536068,0.010295859538018703,0.008450076915323734,0.009105909615755081,0.008619680069386959,0.008146155625581741,0.009226140566170216,0.009649509564042091,0.008694810792803764,0.007333558984100819,0.008714134804904461,0.009475190192461014,0.008914384990930557,0.008677775040268898,0.0088340500369668,0.008536878041923046,0.007837532088160515,0.007464289665222168,0.009245933033525944,0.00854733306914568,0.008255704306066036,0.008190713822841644,0.008178097195923328,0.007875705137848854,0.006921085063368082,0.00742389215156436,0.007665278390049934,0.008482041768729687,0.008872260339558125,0.007777367252856493,0.008245992474257946,0.007885820232331753,0.00832909345626831,0.007841700688004494,0.007600496988743544,0.006838309578597546,0.006885843351483345,0.0073464009910821915,0.008864733390510082,0.008036109618842602,0.007702304515987635,0.007898787036538124,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 78755     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 78756     
=================================================================
Total params: 157,511
Trainable params: 157,511
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 78,755
Trainable params: 78,755
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 78,756
Trainable params: 78,756
Non-trainable params: 0
_________________________________________________________________
