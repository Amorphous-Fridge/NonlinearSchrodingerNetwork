2021-06-26
loss,0.530968427658081,0.32242947816848755,0.2560311257839203,0.1966187059879303,0.15266534686088562,0.12555314600467682,0.11602135002613068,0.10481774061918259,0.08700020611286163,0.07909226417541504,0.0714154839515686,0.05663955584168434,0.05857241526246071,0.061084166169166565,0.05388186126947403,0.061773281544446945,0.042026959359645844,0.044559627771377563,0.04138033464550972,0.04118826240301132,0.049047425389289856,0.04161937162280083,0.042285457253456116,0.04429321736097336,0.04381202533841133,0.0406964011490345,0.03372799977660179,0.03537501394748688,0.03059171698987484,0.03577546030282974,0.03789874538779259,0.03415852040052414,0.033556025475263596,0.03358881175518036,0.03415566682815552,0.030421461910009384,0.026997767388820648,0.020509907975792885,0.02698727324604988,0.03336508572101593,0.027818826958537102,0.027514906600117683,0.029280824586749077,0.02880684658885002,0.02973261848092079,0.025062648579478264,0.02384948916733265,0.02652791701257229,0.024565601721405983,0.024018902331590652,0.025135435163974762,0.027442678809165955,0.023521561175584793,0.022220689803361893,0.026763729751110077,0.024927763268351555,0.022721195593476295,0.024689922109246254,0.0261661559343338,0.02277185395359993,0.02105696126818657,0.026425106450915337,0.02350710891187191,0.02246042713522911,0.02365449257194996,0.02104014717042446,0.019239794462919235,0.022959377616643906,0.022566303610801697,0.021159375086426735,0.020482776686549187,0.02304132655262947,0.02274431474506855,0.020761780440807343,0.019193604588508606,0.02164919301867485,0.023927723988890648,0.020919032394886017,0.017342817038297653,0.017813147976994514,0.019676895812153816,0.020262975245714188,0.021579589694738388,0.02072947286069393,0.018800359219312668,0.0168126430362463,0.01822180300951004,0.021349625661969185,0.021418506279587746,0.018934819847345352,0.022468658164143562,0.019056782126426697,0.021630186587572098,0.020154090598225594,0.018116697669029236,0.02007686160504818,0.02007424086332321,0.01925765350461006,0.016751699149608612,0.017839962616562843,
mse,0.11082597821950912,0.03165122866630554,0.02137839049100876,0.012247005477547646,0.007099019829183817,0.00466556241735816,0.0037639152724295855,0.003140360116958618,0.002250221325084567,0.0017173863016068935,0.00140182685572654,0.0009358709212392569,0.0010292584775015712,0.0010717265540733933,0.0008066002046689391,0.0010447211097925901,0.000521618640050292,0.0005589356878772378,0.00048801061348058283,0.0004908346454612911,0.0006937445723451674,0.0005002880934625864,0.00050885952077806,0.0005401675007306039,0.0005234181298874319,0.0004602093540597707,0.000325031578540802,0.00035137866507284343,0.000264541944488883,0.00036958351847715676,0.0003938964509870857,0.00032961886608973145,0.00031490184483118355,0.0003172628639731556,0.0003253004397265613,0.0002571997756604105,0.00020790367852896452,0.00012593105202540755,0.00021341757383197546,0.00030600829632021487,0.0002190374070778489,0.00021543196635320783,0.00024062389275059104,0.00023730992688797414,0.00024529604706913233,0.00018054009706247598,0.00016237849195022136,0.00019495982269290835,0.0001704147143755108,0.00016613196930848062,0.00017831212608143687,0.00020705329370684922,0.00015690189320594072,0.0001444109802832827,0.0002114444359904155,0.00017494089843239635,0.00014456709322985262,0.00017173154628835618,0.00019471552514005452,0.0001454171142540872,0.00012564781354740262,0.0001935889886226505,0.0001548604341223836,0.0001452782889828086,0.00015525269554927945,0.00012374836660455912,0.00010673712677089497,0.00015432987129315734,0.00014143400767352432,0.00012784366845153272,0.00012187647371320054,0.00015232250734698027,0.00014412259042728692,0.00012004329619230703,0.00010595517233014107,0.00013081337965559214,0.00015766640717629343,0.00012482897727750242,8.946811431087554e-05,9.351801418233663e-05,0.00011146211181767285,0.00011440047092037275,0.00013047757965978235,0.00012051642988808453,0.00010340697917854413,8.317439642269164e-05,9.919879084918648e-05,0.00012721717939712107,0.00012567982776090503,0.00010130173177458346,0.00014193564129527658,0.00010388910595793277,0.00012884935131296515,0.00011269240349065512,9.628806583350524e-05,0.00011636885756161064,0.00011140997230540961,0.0001061537186615169,8.30843418953009e-05,9.254743054043502e-05,
mae,0.22897586226463318,0.1406869888305664,0.11476743966341019,0.08548784255981445,0.06464369595050812,0.05410773679614067,0.04987121745944023,0.04511570930480957,0.037010904401540756,0.03369733691215515,0.03093118406832218,0.024427713826298714,0.025295257568359375,0.025631045922636986,0.02300109714269638,0.027021195739507675,0.017893606796860695,0.018958810716867447,0.01725078374147415,0.017202654853463173,0.020771436393260956,0.017828363925218582,0.018057039007544518,0.01868169568479061,0.018746932968497276,0.01725744642317295,0.014434106647968292,0.014898075722157955,0.013025261461734772,0.015297804027795792,0.016307028010487556,0.014408014714717865,0.014303014613687992,0.014379228465259075,0.014541685581207275,0.013189595192670822,0.011543932370841503,0.008818880654871464,0.011413189582526684,0.014452023431658745,0.011728018522262573,0.011923986487090588,0.012345732189714909,0.01243618130683899,0.012873847037553787,0.010730857960879803,0.010042732581496239,0.01102936640381813,0.010324019007384777,0.010245919227600098,0.010594313964247704,0.01164216548204422,0.009875072166323662,0.009391028434038162,0.011510730721056461,0.01054937019944191,0.009647740982472897,0.010485081933438778,0.01122068241238594,0.009593278169631958,0.009006587788462639,0.011370600201189518,0.01002996601164341,0.009503968060016632,0.009969071485102177,0.008957664482295513,0.00791836902499199,0.00978039763867855,0.00950166117399931,0.009047560393810272,0.008765347301959991,0.009720760397613049,0.009626239538192749,0.008936003781855106,0.008144695311784744,0.009210070595145226,0.010165090672671795,0.008856195025146008,0.007344484329223633,0.0075632017105817795,0.008375562727451324,0.008658057078719139,0.009220235049724579,0.008734211325645447,0.007797498721629381,0.007075699511915445,0.007733621634542942,0.009107674472033978,0.009139076806604862,0.00804750993847847,0.00954438466578722,0.008038705214858055,0.009057247079908848,0.00821091327816248,0.007382804527878761,0.008664158172905445,0.00851178914308548,0.008220884017646313,0.007151662837713957,0.007620471064001322,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 70563     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 70564     
=================================================================
Total params: 141,127
Trainable params: 141,127
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 70,563
Trainable params: 70,563
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 70,564
Trainable params: 70,564
Non-trainable params: 0
_________________________________________________________________
