2021-06-26
loss,0.513969898223877,0.2447592169046402,0.12820611894130707,0.07350527495145798,0.059527862817049026,0.05272681266069412,0.04876650497317314,0.04518161341547966,0.04253599792718887,0.040135182440280914,0.03847326710820198,0.03699153661727905,0.03545742481946945,0.03424550220370293,0.033031102269887924,0.03193095326423645,0.031079519540071487,0.0301706250756979,0.02973731979727745,0.02893684059381485,0.028338996693491936,0.028109664097428322,0.027437804266810417,0.027076246216893196,0.02659154124557972,0.02611180953681469,0.026101388037204742,0.02559712901711464,0.02511955052614212,0.024931706488132477,0.024754347279667854,0.02423848584294319,0.02438553050160408,0.023867251351475716,0.023644056171178818,0.02344118058681488,0.02309657633304596,0.022982187569141388,0.02272363379597664,0.022541405633091927,0.022382080554962158,0.022193187847733498,0.022118031978607178,0.022122854366898537,0.02183806151151657,0.021586177870631218,0.021303066983819008,0.021318651735782623,0.021167900413274765,0.02095102332532406,0.0209682397544384,0.02074398845434189,0.020717334002256393,0.02044844627380371,0.020172670483589172,0.020295750349760056,0.02006082609295845,0.020068936049938202,0.02004442736506462,0.019778955727815628,0.01980026811361313,0.019640084356069565,0.019519180059432983,0.019493943080306053,0.019176693633198738,0.0192584078758955,0.019250063225626945,0.01900375634431839,0.01905578188598156,0.01885415054857731,0.018765278160572052,0.018825268372893333,0.01871819980442524,0.018597716465592384,0.01846221834421158,0.018515462055802345,0.018399523571133614,0.018293915316462517,0.01828780211508274,0.017971832305192947,0.018143966794013977,0.01793074607849121,0.017956599593162537,0.01791238971054554,0.017693303525447845,0.017648303881287575,0.017655013129115105,0.017786487936973572,0.017428290098905563,0.017630137503147125,0.017332836985588074,0.017587972804903984,0.01744319312274456,0.017487945035099983,0.017366372048854828,0.017174672335386276,0.0171283520758152,0.016945255920290947,0.017120692878961563,0.016913792118430138,
mse,0.09825144708156586,0.01997005194425583,0.005757843144237995,0.001797456992790103,0.001205446314997971,0.0009524096385575831,0.0008120766142383218,0.0006958607700653374,0.0006161315832287073,0.000544905080460012,0.0004983412218280137,0.00045452360063791275,0.0004153824702370912,0.0003870885702781379,0.0003560623445082456,0.00033154376433230937,0.00031085999216884375,0.0002916214580181986,0.00027915227110497653,0.00026542178238742054,0.0002541012072470039,0.0002456834481563419,0.00023302269983105361,0.00022530168644152582,0.00021752137399744242,0.00020917743677273393,0.00020642344316001981,0.00019849895033985376,0.0001905304379761219,0.00018721302330959588,0.00018519052537158132,0.00017569205374456942,0.00017657458374742419,0.00016816882998682559,0.00016493018483743072,0.00016213447088375688,0.000157559072249569,0.0001554791087983176,0.00015153044660110027,0.0001500829093856737,0.00014646706404164433,0.00014512418420054018,0.0001430721313226968,0.00014282934716902673,0.00013861502520740032,0.00013609185407403857,0.00013205624418333173,0.00013157310604583472,0.00013000142644159496,0.00012742364197038114,0.00012755449279211462,0.0001249872730113566,0.00012497355055529624,0.00012160542246419936,0.00011762952635763213,0.0001193770658574067,0.00011672158871078864,0.00011631980305537581,0.00011602687300182879,0.00011318207543808967,0.00011365165846655145,0.0001113086545956321,0.00010984587424900383,0.0001096414853236638,0.00010605721035972238,0.00010674870281945914,0.00010672718053683639,0.00010377206490375102,0.00010430670226924121,0.00010215936345048249,0.00010157809447264299,0.00010167506843572482,0.00010070601274492219,9.980201139114797e-05,9.756253712112084e-05,9.833372314460576e-05,9.754643542692065e-05,9.61391197051853e-05,9.604620572645217e-05,9.334176866104826e-05,9.407568722963333e-05,9.211857104673982e-05,9.28101217141375e-05,9.200578642776236e-05,9.039331052917987e-05,8.913265628507361e-05,8.961718413047493e-05,9.008124470710754e-05,8.6915613792371e-05,8.88647700776346e-05,8.609698852524161e-05,8.86356647242792e-05,8.716173761058599e-05,8.724728832021356e-05,8.617697312729433e-05,8.458523370791227e-05,8.431247260887176e-05,8.203499601222575e-05,8.358938794117421e-05,8.179226279025897e-05,
mae,0.22076524794101715,0.10384499281644821,0.054834164679050446,0.0309268981218338,0.0251217819750309,0.022166695445775986,0.020564548671245575,0.01906251348555088,0.01798003539443016,0.01688452437520027,0.016213782131671906,0.015607994049787521,0.014963556081056595,0.014388849958777428,0.013934326358139515,0.013430140912532806,0.013106081634759903,0.012649277225136757,0.012528927065432072,0.012265515513718128,0.011921525001525879,0.011841491796076298,0.011634049005806446,0.011424072086811066,0.011267531663179398,0.010995591059327126,0.010988668538630009,0.010698561556637287,0.010669630020856857,0.01046364288777113,0.010364831425249577,0.01017844956368208,0.010299566201865673,0.010110603645443916,0.009911042638123035,0.009859029203653336,0.009793093428015709,0.009654432535171509,0.009598215110599995,0.009502691216766834,0.009448349475860596,0.009280205704271793,0.009298949502408504,0.009289000183343887,0.009130958467721939,0.009083217941224575,0.009021883830428123,0.008924354799091816,0.008813478983938694,0.008834696374833584,0.008836881257593632,0.008755705319344997,0.008649992756545544,0.008491627871990204,0.008501637727022171,0.008441523648798466,0.008473998866975307,0.008431339636445045,0.008318059146404266,0.008414057083427906,0.00827140174806118,0.008281651884317398,0.008185877464711666,0.00822594203054905,0.008079957216978073,0.008121930062770844,0.008099082857370377,0.007978733628988266,0.008002753369510174,0.00788846705108881,0.00794030912220478,0.007890247739851475,0.007841421291232109,0.00777759263291955,0.007722056936472654,0.00778893893584609,0.0077737122774124146,0.007693960797041655,0.0077221328392624855,0.007609857711941004,0.007662227842956781,0.007621088996529579,0.007559043820947409,0.007579884026199579,0.007461393252015114,0.007492041680961847,0.00747710419818759,0.0074197473004460335,0.00733910221606493,0.007327058352530003,0.007285373751074076,0.007394098676741123,0.00734492763876915,0.007371595129370689,0.007248913869261742,0.007221502717584372,0.007123814430087805,0.007145393639802933,0.0072186230681836605,0.007147952914237976,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3643      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3644      
=================================================================
Total params: 7,287
Trainable params: 7,287
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 3,643
Trainable params: 3,643
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 3,644
Trainable params: 3,644
Non-trainable params: 0
_________________________________________________________________
