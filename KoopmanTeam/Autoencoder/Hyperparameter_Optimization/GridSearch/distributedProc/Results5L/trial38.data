2021-06-26
loss,0.5672895312309265,0.25033968687057495,0.24199862778186798,0.23557089269161224,0.22594887018203735,0.23881086707115173,0.21970565617084503,0.17618697881698608,0.15325304865837097,0.11488711088895798,0.10301344841718674,0.10739673674106598,0.09366271644830704,0.07209227234125137,0.09629642218351364,0.07482599467039108,0.06985200941562653,0.08280029147863388,0.08460955321788788,0.06794486194849014,0.05194868892431259,0.055012594908475876,0.06954719871282578,0.06445731967687607,0.055745672434568405,0.044727277010679245,0.03784310817718506,0.04677416756749153,0.053776487708091736,0.051329102367162704,0.04694269225001335,0.03969264402985573,0.04610447585582733,0.047702301293611526,0.04839402064681053,0.04479793459177017,0.03839586302638054,0.03354779630899429,0.04195027053356171,0.035312775522470474,0.0335446298122406,0.030421623960137367,0.028035901486873627,0.024574406445026398,0.028875524178147316,0.0406363308429718,0.03472865745425224,0.04122680798172951,0.03359465301036835,0.027867386117577553,0.02910238690674305,0.029557740315794945,0.031360041350126266,0.034993112087249756,0.031462185084819794,0.03382541611790657,0.03846566379070282,0.0338045172393322,0.0332290381193161,0.030470428988337517,0.02960509993135929,0.028719767928123474,0.02625250816345215,0.028686199337244034,0.029345054179430008,0.02714214101433754,0.03354765102267265,0.029616357758641243,0.02667327970266342,0.022741658613085747,0.020247891545295715,0.02568027935922146,0.027806514874100685,0.022688226774334908,0.02562783472239971,0.029421815648674965,0.026874570176005363,0.024461990222334862,0.02992515079677105,0.0276686642318964,0.024528488516807556,0.02513672597706318,0.0246112197637558,0.025124995037913322,0.022257866337895393,0.025727758184075356,0.02816062420606613,0.023546524345874786,0.0237294789403677,0.02630167454481125,0.024356387555599213,0.020776672288775444,0.01791844516992569,0.01608998328447342,0.015955548733472824,0.023871012032032013,0.02215033769607544,0.022065849974751472,0.021224411204457283,0.022712377831339836,
mse,0.17598840594291687,0.020627237856388092,0.019845424219965935,0.01911940798163414,0.017696181312203407,0.018936486914753914,0.0160516444593668,0.009562955237925053,0.007111134007573128,0.0038539862725883722,0.0030901909340173006,0.003578193485736847,0.00276951608248055,0.0016033495776355267,0.0027450991328805685,0.0017056147335097194,0.0014874020125716925,0.0019719870761036873,0.002009616233408451,0.001371336868032813,0.0007929306593723595,0.0009035455295816064,0.001379825291223824,0.0011683224001899362,0.0009182366775348783,0.00062986696138978,0.0004533619503490627,0.0006673635798506439,0.0008470019674859941,0.0007552389870397747,0.0006308596348389983,0.0004669785557780415,0.0006034100078977644,0.0006376094534061849,0.0006595185259357095,0.00056638871319592,0.0004347037465777248,0.0003360593691468239,0.0005026666913181543,0.0003647072007879615,0.00032817895407788455,0.00027358203078620136,0.00023706538195256144,0.00018356606597080827,0.00024962201132439077,0.00045810043229721487,0.0003537740558385849,0.00048607063945382833,0.00031939957989379764,0.00023452931782230735,0.00024979302543215454,0.0002461220428813249,0.00028423586627468467,0.0003417817933950573,0.0002830727898981422,0.0003397640830371529,0.0004126573621761054,0.0003213598974980414,0.00030487842741422355,0.0002624666958581656,0.0002501192793715745,0.0002369489666307345,0.000199087371584028,0.00023622803564649075,0.00024372573534492403,0.0002114459639415145,0.00030670291744172573,0.00024263262457679957,0.0002011332253459841,0.0001475366880185902,0.00011953339708270505,0.00019764993339776993,0.00021893229859415442,0.00014755610027350485,0.0001933191088028252,0.00023961096303537488,0.00020759979088325053,0.00017074083734769374,0.00025122310034930706,0.00021283345995470881,0.00017294319695793092,0.0001868621475296095,0.000171880325069651,0.0001763167674653232,0.00014422606909647584,0.00019063748186454177,0.00021685795218218118,0.00016023116768337786,0.00016093236627057195,0.00019702754798345268,0.00016720470739528537,0.0001228214823640883,9.708049037726596e-05,7.860095502110198e-05,7.551302405772731e-05,0.00016000786854419857,0.00013939046766608953,0.00013973104069009423,0.00013438062160275877,0.00014489608292933553,
mae,0.24278581142425537,0.10705157369375229,0.10587188601493835,0.10550646483898163,0.10310284793376923,0.10130766779184341,0.09398763626813889,0.07529018074274063,0.06489402800798416,0.048907071352005005,0.04345818608999252,0.04457486793398857,0.040073513984680176,0.030595336109399796,0.04003283381462097,0.032087817788124084,0.02949291653931141,0.035314299166202545,0.03623480349779129,0.029044313356280327,0.021723931655287743,0.02313181944191456,0.02963276393711567,0.027162594720721245,0.024360163137316704,0.0190600398927927,0.01602991484105587,0.019845152273774147,0.02271147258579731,0.022266600281000137,0.01954611949622631,0.016638092696666718,0.019779348745942116,0.020666899159550667,0.02095765806734562,0.01905236952006817,0.017080411314964294,0.014211281202733517,0.017779625952243805,0.014864577911794186,0.014089175499975681,0.012771007604897022,0.011923768557608128,0.010518384166061878,0.012131201103329659,0.01823411136865616,0.015203343704342842,0.018045006319880486,0.01413745153695345,0.011617150157690048,0.012126457877457142,0.012417035177350044,0.013251960277557373,0.015453508123755455,0.014254237525165081,0.014687564224004745,0.017309583723545074,0.014832858927547932,0.014836817979812622,0.01342059951275587,0.012466618791222572,0.012163061648607254,0.010817409493029118,0.01215302012860775,0.012366327457129955,0.011512038297951221,0.014544090256094933,0.012901414185762405,0.011514646001160145,0.009510690346360207,0.00866108201444149,0.011196587234735489,0.011222558096051216,0.00946809072047472,0.010700207203626633,0.012659171596169472,0.011240780353546143,0.010221820324659348,0.012788498774170876,0.011830031871795654,0.01037549041211605,0.01041411142796278,0.010236258618533611,0.01009420771151781,0.009455586783587933,0.011078335344791412,0.011820622719824314,0.01010327972471714,0.010033544152975082,0.011439243331551552,0.009810212068259716,0.008525963872671127,0.0075566451996564865,0.0068778591230511665,0.006742594763636589,0.010168793611228466,0.009383541531860828,0.009209997951984406,0.009124127216637135,0.009606201201677322,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 51211     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 51212     
=================================================================
Total params: 102,423
Trainable params: 102,423
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 51,211
Trainable params: 51,211
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 51,212
Trainable params: 51,212
Non-trainable params: 0
_________________________________________________________________
