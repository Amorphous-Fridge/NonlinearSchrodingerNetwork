2021-06-26
loss,0.3956172466278076,0.14989334344863892,0.09555908292531967,0.10491939634084702,0.08530814200639725,0.0831073597073555,0.0964694395661354,0.08590631186962128,0.06861943751573563,0.08228037506341934,0.07207581400871277,0.06599687784910202,0.06682883203029633,0.05934376269578934,0.044914860278367996,0.053544722497463226,0.05358292907476425,0.05428865924477577,0.04973999410867691,0.04833836108446121,0.04846809804439545,0.044969864189624786,0.04718717187643051,0.042329005897045135,0.04437275230884552,0.04111522063612938,0.039069537073373795,0.04379557445645332,0.03029017709195614,0.030909549444913864,0.04069298133254051,0.03906877711415291,0.03492681682109833,0.027038300409913063,0.028792034834623337,0.04133055359125137,0.03406510129570961,0.03917068615555763,0.03326280042529106,0.03285892680287361,0.03762802109122276,0.03488847613334656,0.03079688735306263,0.027118459343910217,0.02493317425251007,0.022116944193840027,0.030327780172228813,0.03585244342684746,0.03406260162591934,0.03228886052966118,0.028684673830866814,0.031403813511133194,0.03360305726528168,0.03210875391960144,0.03025049716234207,0.0266768429428339,0.023925619199872017,0.023178210482001305,0.027633916586637497,0.03239314258098602,0.028805511072278023,0.027884136885404587,0.029038522392511368,0.025302674621343613,0.022159315645694733,0.02529369853436947,0.026872223243117332,0.02690907195210457,0.02614475041627884,0.025644389912486076,0.020976772531867027,0.017357079312205315,0.015734784305095673,0.016377953812479973,0.01633281446993351,0.019192280247807503,0.02655988745391369,0.02652454562485218,0.026449870318174362,0.026797505095601082,0.026279358193278313,0.023749224841594696,0.021350232884287834,0.020263899117708206,0.019259344786405563,0.017135269939899445,0.022059880197048187,0.026599569246172905,0.023348195478320122,0.021625421941280365,0.024193011224269867,0.023431003093719482,0.022669343277812004,0.024928303435444832,0.024167578667402267,0.02204933948814869,0.0204763300716877,0.0191545020788908,0.016341546550393105,0.013489153236150742,
mse,0.086469367146492,0.007114038337022066,0.002810556208714843,0.0032481560483574867,0.0021135597489774227,0.002059962134808302,0.003008460160344839,0.0022553333546966314,0.0014671367825940251,0.002054681070148945,0.0015047612832859159,0.0012714255135506392,0.0013228656025603414,0.0010154738556593657,0.0005942515563219786,0.0008612621459178627,0.0008425580454058945,0.0008511953637935221,0.0007536012562923133,0.0006966638611629605,0.0006993346032686532,0.0005822109524160624,0.0006507904035970569,0.0005203637992963195,0.0005713793798349798,0.000512307567987591,0.0004490335413720459,0.0005469199386425316,0.0002846017014235258,0.000316826713969931,0.00046974842553026974,0.00044724586769007146,0.00035297509748488665,0.00022558959608431906,0.00025564845418557525,0.00048550820793025196,0.0003452711971476674,0.0004393551789689809,0.0003276023780927062,0.00031141459476202726,0.00040837840060703456,0.00034505664370954037,0.0002698481548577547,0.00021267641568556428,0.00018488710338715464,0.00015202240319922566,0.0002993116795551032,0.00036195488064549863,0.0003313406486995518,0.0003001389850396663,0.00023503322154283524,0.00028921524062752724,0.00032245874172076583,0.00029242245364002883,0.0002575013495516032,0.00020461890380829573,0.0001688921038294211,0.00015817668463569134,0.00021741425734944642,0.00030223472276702523,0.0002401697274763137,0.00022594259644392878,0.00023920941748656332,0.00018032373918686062,0.0001441870554117486,0.00019432311819400638,0.0002103746373904869,0.00020677786960732192,0.00020070628670509905,0.00018874643137678504,0.00013505082461051643,9.579102334100753e-05,7.393766281893477e-05,8.280616020783782e-05,8.012980106286705e-05,0.00011476078361738473,0.00019809036166407168,0.0001989616866922006,0.00020113479695282876,0.0002050308685284108,0.00019959201745223254,0.00015721771342214197,0.000128069834318012,0.0001175762081402354,0.00011386835831217468,9.28204899537377e-05,0.000150808526086621,0.0001993810583371669,0.00015243186498992145,0.0001358143927063793,0.00016916124150156975,0.0001559031952638179,0.00014401016233023256,0.00018003469449467957,0.00016529437561985105,0.00013780973677057773,0.00012033985694870353,0.00010765760816866532,8.37120387586765e-05,5.45931288797874e-05,
mae,0.16923636198043823,0.06558611989021301,0.041078101843595505,0.04507216811180115,0.03662554547190666,0.035649623721838,0.04254883900284767,0.037544041872024536,0.0297908503562212,0.03610756993293762,0.03141378238797188,0.028755147010087967,0.029502857476472855,0.02578437142074108,0.019318485632538795,0.023425938561558723,0.02343977428972721,0.023744964972138405,0.021981844678521156,0.020766284316778183,0.021329130977392197,0.01941656693816185,0.020612504333257675,0.01840750128030777,0.019150076434016228,0.01809670403599739,0.016942834481596947,0.019300073385238647,0.01312444731593132,0.013413870707154274,0.017589924857020378,0.01706884056329727,0.014997662045061588,0.011544955894351006,0.012340289540588856,0.018180495128035545,0.014692265540361404,0.017108319327235222,0.014540859498083591,0.014103650115430355,0.016486769542098045,0.015214172191917896,0.013299504294991493,0.011467578820884228,0.010559898801147938,0.00943599734455347,0.013085552491247654,0.01567305251955986,0.014837123453617096,0.014129586517810822,0.012518154457211494,0.013565183617174625,0.014995642937719822,0.014236070215702057,0.013136152178049088,0.01132727600634098,0.00993077177554369,0.009831119328737259,0.011802440509200096,0.014264128170907497,0.012564757838845253,0.012147821485996246,0.012604760937392712,0.010999500751495361,0.00953162182122469,0.010935037396848202,0.011656085029244423,0.01172441616654396,0.011335939168930054,0.010902597568929195,0.008991527371108532,0.007492425385862589,0.006831618957221508,0.007078924216330051,0.006977719720453024,0.008278858847916126,0.01156982034444809,0.011380141600966454,0.011625734157860279,0.011740345507860184,0.011598528362810612,0.010144888423383236,0.009141013957560062,0.008625144138932228,0.00823221169412136,0.007414873223751783,0.009514185599982738,0.011219706386327744,0.009916914626955986,0.009090250357985497,0.010356813669204712,0.010187821462750435,0.009892717935144901,0.010981369763612747,0.010524561628699303,0.009479258209466934,0.00891159102320671,0.008245260454714298,0.00701176980510354,0.005843943916261196,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25595     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25596     
=================================================================
Total params: 51,191
Trainable params: 51,191
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 25,595
Trainable params: 25,595
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 25,596
Trainable params: 25,596
Non-trainable params: 0
_________________________________________________________________
