2021-06-26
loss,0.9895885586738586,0.25005051493644714,0.24256671965122223,0.23410305380821228,0.22749412059783936,0.22016407549381256,0.21891412138938904,0.20773443579673767,0.19954758882522583,0.1845603585243225,0.20288342237472534,0.11726436018943787,0.13771051168441772,0.12150374054908752,0.11967073380947113,0.09061934798955917,0.0904046818614006,0.08718516677618027,0.08661720156669617,0.07804165780544281,0.0807652398943901,0.05528563633561134,0.061810608953237534,0.059131279587745667,0.06445010006427765,0.058212704956531525,0.06124342605471611,0.05857323482632637,0.046720314770936966,0.050741177052259445,0.05521249771118164,0.05856924504041672,0.05057157948613167,0.04735106974840164,0.041434284299612045,0.044701676815748215,0.04431179165840149,0.047686412930488586,0.03780372440814972,0.039494894444942474,0.046844929456710815,0.04156083986163139,0.04334232956171036,0.04273596405982971,0.038474153727293015,0.0360218770802021,0.04043978080153465,0.03179808333516121,0.03185495734214783,0.04056686908006668,0.03747725859284401,0.034092310816049576,0.038492850959300995,0.039326585829257965,0.03629304841160774,0.03379448875784874,0.032003793865442276,0.033361002802848816,0.027630649507045746,0.03626490756869316,0.033349841833114624,0.03307012841105461,0.03505832329392433,0.02823152393102646,0.031267162412405014,0.031677283346652985,0.03241631016135216,0.03212293982505798,0.03049543872475624,0.02897542528808117,0.03172820061445236,0.029609227553009987,0.02786886878311634,0.026404965668916702,0.026981450617313385,0.026440486311912537,0.030090969055891037,0.02901134081184864,0.02999064512550831,0.024452462792396545,0.02578256092965603,0.028778282925486565,0.028736554086208344,0.029988134279847145,0.02738136239349842,0.024525223299860954,0.024744044989347458,0.025476619601249695,0.025304924696683884,0.028725089505314827,0.026208793744444847,0.02360636740922928,0.026056375354528427,0.02571856789290905,0.022393666207790375,0.023939955979585648,0.02596728503704071,0.024779200553894043,0.02817656844854355,0.024500276893377304,
mse,0.4827396869659424,0.02071389928460121,0.019769424572587013,0.018601752817630768,0.017595773562788963,0.016540123149752617,0.016152983531355858,0.014824521727859974,0.013636976480484009,0.010995196178555489,0.012708918191492558,0.004076446406543255,0.005680595524609089,0.004426928702741861,0.004188543185591698,0.002345280721783638,0.002355244942009449,0.0021967426873743534,0.002127463696524501,0.0018083065515384078,0.0018971136305481195,0.0009205573005601764,0.0010893269209191203,0.0009969121310859919,0.0011761602945625782,0.0010193296475335956,0.0010915165767073631,0.0009592447895556688,0.00061312026809901,0.0007239487022161484,0.0008951992494985461,0.0009553317213431001,0.000713384011760354,0.0006606720271520317,0.0004927736008539796,0.0005578300915658474,0.0005511374911293387,0.0006409725756384432,0.00041355646681040525,0.00046049547381699085,0.000622695020865649,0.00047305799671448767,0.0005154493846930563,0.0004940612125210464,0.0004275325045455247,0.00037554375012405217,0.00045147613855078816,0.0002844854025170207,0.0002896058140322566,0.00046914166887290776,0.0003878988209180534,0.00032017845660448074,0.0004058444465044886,0.0004196955997031182,0.0003629884449765086,0.0003237746423110366,0.0002824168186634779,0.0003062201722059399,0.00021793499763589352,0.0003731522592715919,0.0003194144810549915,0.0003047357895411551,0.0003378276014700532,0.00022052675194572657,0.0002788183919619769,0.000281597109278664,0.0002956970129162073,0.0002882849657908082,0.00025692672352306545,0.0002283373469254002,0.0002881999535020441,0.000243373287958093,0.00021098715660627931,0.00018935397383756936,0.00020193829550407827,0.00019642020924948156,0.00025179795920848846,0.00023576598323415965,0.00024698389461264014,0.00016777697601355612,0.00019181740935891867,0.0002291674172738567,0.0002380404039286077,0.0002449050371069461,0.00020664861949626356,0.0001669063203735277,0.00017754668078850955,0.00018195812299381942,0.00018175801960751414,0.00022853702830616385,0.00018691711011342704,0.00015671733126509935,0.0001933802996063605,0.00018063437892124057,0.000137678041937761,0.00016173644689843059,0.00018911501683760434,0.00017090946494136006,0.00022058672038838267,0.00016841285105329007,
mae,0.4321541488170624,0.10672657936811447,0.10832954198122025,0.1072717010974884,0.10344968736171722,0.0987764373421669,0.0958901196718216,0.08975695818662643,0.0849774107336998,0.07913465797901154,0.0862833708524704,0.04960165172815323,0.05934150144457817,0.050819989293813705,0.05067746341228485,0.03832787647843361,0.038452789187431335,0.037627678364515305,0.03681166097521782,0.03358318656682968,0.03456913307309151,0.023437809199094772,0.026537612080574036,0.025237195193767548,0.02775593474507332,0.024713730439543724,0.02592855878174305,0.024731582030653954,0.01973893493413925,0.021771810948848724,0.023634053766727448,0.0237836055457592,0.021778836846351624,0.019904380664229393,0.0174856036901474,0.018989406526088715,0.018540747463703156,0.020543888211250305,0.016382018104195595,0.016550250351428986,0.01997879333794117,0.017968514934182167,0.018154796212911606,0.01759294420480728,0.016303203999996185,0.015218015760183334,0.017805296927690506,0.01380937173962593,0.013553380966186523,0.01682616025209427,0.015966273844242096,0.014354021288454533,0.016470441594719887,0.01651689223945141,0.015480744652450085,0.014206557534635067,0.013382104225456715,0.014370889402925968,0.01179297361522913,0.014989685267210007,0.014144599437713623,0.014191332273185253,0.015039240010082722,0.012262937612831593,0.013331498950719833,0.013695772737264633,0.013731002807617188,0.013650831766426563,0.013487998396158218,0.01267952285706997,0.013169798068702221,0.012643788941204548,0.011995773762464523,0.01107816956937313,0.011377361603081226,0.011377368122339249,0.012673350982367992,0.012382984161376953,0.012909331358969212,0.01056375727057457,0.010803724639117718,0.012148572131991386,0.012200521305203438,0.0121576813980937,0.01166053768247366,0.010464382357895374,0.010590535588562489,0.010865076445043087,0.010680004023015499,0.011932074092328548,0.011140300892293453,0.010197725147008896,0.011375653557479382,0.011381344869732857,0.009389812126755714,0.010094883851706982,0.011027761735022068,0.010599706321954727,0.012243940494954586,0.010609087534248829,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 72403     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 72404     
=================================================================
Total params: 144,807
Trainable params: 144,807
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 72,403
Trainable params: 72,403
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 72,404
Trainable params: 72,404
Non-trainable params: 0
_________________________________________________________________
