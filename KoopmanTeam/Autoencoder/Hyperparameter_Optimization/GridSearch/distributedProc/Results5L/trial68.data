2021-06-26
loss,0.4766070246696472,0.23554092645645142,0.23122894763946533,0.22558294236660004,0.20243453979492188,0.13242082297801971,0.11264979094266891,0.0842919573187828,0.07886962592601776,0.07783547043800354,0.07088712602853775,0.07249626517295837,0.05774030089378357,0.052794117480516434,0.065230593085289,0.061247359961271286,0.05522501468658447,0.05678544193506241,0.03777989000082016,0.038176145404577255,0.04053029417991638,0.05305599048733711,0.042640239000320435,0.03467640280723572,0.04377499595284462,0.04809872806072235,0.04348147287964821,0.03382375091314316,0.03770669549703598,0.034971512854099274,0.03956705704331398,0.038181062787771225,0.03538178279995918,0.03303469344973564,0.029951469972729683,0.039384353905916214,0.033363476395606995,0.029314495623111725,0.026667263358831406,0.03085634484887123,0.028457216918468475,0.02780671790242195,0.029541702941060066,0.029461834579706192,0.026261480525135994,0.0262659452855587,0.030130678787827492,0.028152547776699066,0.02189275063574314,0.01823744736611843,0.02819954603910446,0.027570875361561775,0.02854260429739952,0.028734741732478142,0.02815129980444908,0.027033323422074318,0.024993564933538437,0.02526262030005455,0.02415468730032444,0.02441841922700405,0.022797195240855217,0.0223062913864851,0.020942458882927895,0.02481038309633732,0.020703928545117378,0.02578219398856163,0.027270715683698654,0.024653682485222816,0.02208424173295498,0.02520543523132801,0.02336016111075878,0.020889732986688614,0.01954207569360733,0.020576367154717445,0.02556043304502964,0.023862767964601517,0.021605322137475014,0.02371373400092125,0.023929519578814507,0.020949840545654297,0.02343113347887993,0.020206786692142487,0.020556502044200897,0.020250685513019562,0.01883324608206749,0.018782809376716614,0.021408701315522194,0.021991698071360588,0.02247852273285389,0.020939821377396584,0.020006228238344193,0.019293947145342827,0.021382905542850494,0.022437548264861107,0.021185534074902534,0.01916949450969696,0.01909036748111248,0.022601734846830368,0.020327460020780563,0.017364460974931717,
mse,0.11576131731271744,0.019421126693487167,0.01897021010518074,0.018148308619856834,0.013666318729519844,0.005349027458578348,0.0036584564950317144,0.0020504321437329054,0.0018624903168529272,0.0017480659298598766,0.0015039416030049324,0.0015347037697210908,0.000966202758718282,0.0008036515791900456,0.0012654034653678536,0.0010593193583190441,0.00087354815332219,0.000932788650970906,0.0004404377832543105,0.00044015911407768726,0.0004763707402162254,0.0007944638491608202,0.0005279278848320246,0.00034177530324086547,0.0005493474891409278,0.0006592170684598386,0.0005495591321960092,0.0003333429922349751,0.0004095190088264644,0.0003582166973501444,0.0004589275922626257,0.0004063272208441049,0.0003626790130510926,0.000313244410790503,0.0002640182210598141,0.00043118110625073314,0.0003144671500194818,0.0002514293300919235,0.00021020877466071397,0.0002752109430730343,0.00023324898211285472,0.00022792995150666684,0.000248170894337818,0.0002449813764542341,0.00019989539578091353,0.00020279374439269304,0.0002586449554655701,0.00022630680177826434,0.00014451217430178076,0.00010149985610041767,0.00022348936181515455,0.00021527452918235213,0.0002304798981640488,0.00023262744070962071,0.00022628376609645784,0.00020958516688551754,0.00017792153812479228,0.00018291163723915815,0.0001659681147430092,0.00016736432735342532,0.0001474784512538463,0.00014168425695970654,0.00012488020001910627,0.00018262903904542327,0.00012680297368206084,0.00018522044410929084,0.0002081133279716596,0.00017003562243189663,0.00014304128126241267,0.00017833556921686977,0.00015288841677829623,0.00012650369899347425,0.00011286446533631533,0.00012227401020936668,0.00018451770301908255,0.00016118660278152674,0.0001307152269873768,0.0001621098053874448,0.0001594061468495056,0.00012488426000345498,0.0001539352088002488,0.00011910498869838193,0.00012142505147494376,0.00011424222611822188,0.00010058269981527701,0.00010320288129150867,0.0001304186589550227,0.00013558538921643049,0.0001430876145604998,0.0001246420870302245,0.00011171313963131979,0.00010599414963508025,0.00013049837434664369,0.0001435998419765383,0.00012417462130542845,0.00010584639676380903,0.00010707695037126541,0.00014158700651023537,0.00011675489804474637,8.908422023523599e-05,
mae,0.20395545661449432,0.09527576714754105,0.09535197168588638,0.09858223795890808,0.08797387778759003,0.05664131045341492,0.04803677648305893,0.03574100136756897,0.03312533348798752,0.03345299884676933,0.03073340468108654,0.030504142865538597,0.024875156581401825,0.02227652072906494,0.027911823242902756,0.026383914053440094,0.023574771359562874,0.024708980694413185,0.01611201837658882,0.016319945454597473,0.017133072018623352,0.02258867584168911,0.01845955103635788,0.0152592733502388,0.018421949818730354,0.02041587606072426,0.019010132178664207,0.014171459712088108,0.015930436551570892,0.015048403292894363,0.016829267144203186,0.016216941177845,0.015356507152318954,0.014268548227846622,0.012994695454835892,0.017507949844002724,0.015236792154610157,0.012452474795281887,0.01091891247779131,0.01330912858247757,0.012133849784731865,0.01174523588269949,0.012531301006674767,0.012439637444913387,0.010969898663461208,0.011171450838446617,0.012704852037131786,0.011957339011132717,0.009208200499415398,0.007768403273075819,0.01198336947709322,0.0116434870287776,0.012218963354825974,0.01219386700540781,0.01165674440562725,0.01157874334603548,0.010691050440073013,0.010601998306810856,0.010255005210638046,0.010216054506599903,0.009422901086509228,0.009543994441628456,0.008849377743899822,0.010602337308228016,0.0087912417948246,0.010910684242844582,0.011498122476041317,0.01090409979224205,0.009263327345252037,0.010575725696980953,0.009909240528941154,0.009023215621709824,0.008466128259897232,0.00871059950441122,0.010721543803811073,0.010044414550065994,0.00933351181447506,0.010132518596947193,0.00986451841890812,0.00879308208823204,0.009957164525985718,0.008690225891768932,0.008754793554544449,0.008589964359998703,0.007968239486217499,0.007935276255011559,0.009099666960537434,0.009530909359455109,0.009614008478820324,0.008974996395409107,0.008331254124641418,0.008088608272373676,0.009204135276377201,0.009696547873318195,0.008889271877706051,0.008046519011259079,0.008028515614569187,0.009458476677536964,0.008702265098690987,0.007415343075990677,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 51443     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 51444     
=================================================================
Total params: 102,887
Trainable params: 102,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 51,443
Trainable params: 51,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 51,444
Trainable params: 51,444
Non-trainable params: 0
_________________________________________________________________
