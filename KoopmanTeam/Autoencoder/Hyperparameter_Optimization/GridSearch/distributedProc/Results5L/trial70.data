2021-06-26
loss,1.949367642402649,0.2696794271469116,0.14248815178871155,0.13166449964046478,0.12175223231315613,0.08495613187551498,0.08358034491539001,0.09537346661090851,0.09238363057374954,0.07389532029628754,0.05766231566667557,0.05245634540915489,0.04710014909505844,0.049358759075403214,0.05596380680799484,0.04285300150513649,0.064296193420887,0.06789597123861313,0.0456966869533062,0.04801766574382782,0.04364338889718056,0.04032355174422264,0.05569029226899147,0.06295618414878845,0.055987950414419174,0.04153871908783913,0.03501013666391373,0.0392620675265789,0.04804958775639534,0.05294056236743927,0.04570117965340614,0.03804376721382141,0.03345486521720886,0.03833375126123428,0.05075100436806679,0.045165225863456726,0.040454767644405365,0.03313852474093437,0.028924621641635895,0.027536623179912567,0.034157346934080124,0.03867267444729805,0.04213376343250275,0.041573163121938705,0.036315180361270905,0.03241945803165436,0.03505904600024223,0.03863416612148285,0.03564088046550751,0.031601596623659134,0.02740113064646721,0.03711092844605446,0.03303776681423187,0.028415219858288765,0.029466448351740837,0.036354128271341324,0.03252790868282318,0.029721563681960106,0.027645785361528397,0.02538977563381195,0.0271193478256464,0.03455111384391785,0.033388327807188034,0.02812131494283676,0.029293416067957878,0.03105670027434826,0.030022749677300453,0.02677115984261036,0.024313485249876976,0.022533610463142395,0.021391509100794792,0.020267194136977196,0.022393692284822464,0.02773534320294857,0.024778900668025017,0.021475356072187424,0.020275048911571503,0.023322639986872673,0.02832172065973282,0.03476398065686226,0.03210124745965004,0.027767987921833992,0.028245635330677032,0.030034620314836502,0.0283178873360157,0.0254528671503067,0.02590588480234146,0.027498260140419006,0.023337170481681824,0.020791925489902496,0.02157972753047943,0.02529623731970787,0.023803958669304848,0.021838845685124397,0.025537915527820587,0.028379226103425026,0.02772793546319008,0.02618149109184742,0.022216210141777992,0.019796347245573997,
mse,1.0483814477920532,0.023390622809529305,0.006350094452500343,0.00559275085106492,0.004832589067518711,0.0022018104791641235,0.002166585298255086,0.0027740830555558205,0.0025325024034827948,0.0016196921933442354,0.0009310132008977234,0.0007775033009238541,0.0006419369601644576,0.0007279655546881258,0.0009690385195426643,0.0005456534563563764,0.0012471787631511688,0.001352416118606925,0.0006220778450369835,0.0006479129078797996,0.0005267719971016049,0.000457005575299263,0.0009367315215058625,0.0011048153974115849,0.0008820335497148335,0.0005075090448372066,0.0003582195204216987,0.0004488784761633724,0.0006740216049365699,0.0007768287323415279,0.0005875800852663815,0.00040398715646006167,0.00031328696059063077,0.0004331430827733129,0.0007151882164180279,0.0005705574294552207,0.00047252062358893454,0.0003237289492972195,0.0002479703398421407,0.00022731267381459475,0.00033437417005188763,0.0004274487728253007,0.0004989171284250915,0.0004814373387489468,0.00038057463825680315,0.00030206760857254267,0.00035256275441497564,0.0004135437775403261,0.00035661537549458444,0.00028572697192430496,0.00021829846082255244,0.0003771680349018425,0.0003077819710597396,0.00023646284535061568,0.0002473930362612009,0.00037319958209991455,0.0002957696851808578,0.0002461447147652507,0.00021687409025616944,0.0001885695819510147,0.0002120232820743695,0.0003351450723130256,0.00031033175764605403,0.0002301288186572492,0.00024486795882694423,0.0002731993154156953,0.00024862855207175016,0.00019678853277582675,0.00016365466581191868,0.00014410947915166616,0.0001308237697230652,0.0001182061096187681,0.00015379919204860926,0.000227496144361794,0.00018251492292620242,0.00013636180665344,0.00011968445323873311,0.00015978369629010558,0.00023380370112136006,0.00034833859535865486,0.0002894351491704583,0.00022375774278771132,0.00022777376580052078,0.00025170587468892336,0.00022602675016969442,0.0001841928606154397,0.0001904742675833404,0.00021074058895464987,0.00015525858907494694,0.00012313424667809159,0.00013982471136841923,0.0001796000578906387,0.0001604565477464348,0.00013416029105428606,0.00019590381998568773,0.00022901030024513602,0.00021360557002481073,0.0001904892415041104,0.00013760017463937402,0.00011175189865753055,
mae,0.6751244068145752,0.11385355144739151,0.05969388037919998,0.05508480221033096,0.053619708865880966,0.03590688854455948,0.034666962921619415,0.041059885174036026,0.03999753296375275,0.030372824519872665,0.02301332727074623,0.022637011483311653,0.020817041397094727,0.021247370168566704,0.02376924455165863,0.018444811925292015,0.02799210511147976,0.030185997486114502,0.019420064985752106,0.019635245203971863,0.017422104254364967,0.016602538526058197,0.024163328111171722,0.027919316664338112,0.0250835157930851,0.017866671085357666,0.015003289096057415,0.016759755089879036,0.020713379606604576,0.023449789732694626,0.01979532465338707,0.01589108631014824,0.014241611585021019,0.016174331307411194,0.022253837436437607,0.019983775913715363,0.017824284732341766,0.013649366796016693,0.012299587950110435,0.011615617200732231,0.014375556260347366,0.016501471400260925,0.018278727307915688,0.018199637532234192,0.01564454287290573,0.013788286596536636,0.015016002580523491,0.016789408400654793,0.015675317496061325,0.013722130097448826,0.011742431670427322,0.016199447214603424,0.014819014817476273,0.012153854593634605,0.012719700112938881,0.015703905373811722,0.013819228857755661,0.012253575026988983,0.011796382255852222,0.010823671706020832,0.011496302671730518,0.014617446810007095,0.014411683194339275,0.01150808297097683,0.01242811232805252,0.013289452530443668,0.013022252358496189,0.011417505331337452,0.01034129410982132,0.00971951149404049,0.009254558943212032,0.008611815981566906,0.009539786726236343,0.011604306288063526,0.010183073580265045,0.009083222597837448,0.0085915457457304,0.0099667152389884,0.01211933046579361,0.01521178800612688,0.013925991952419281,0.011574446223676205,0.011960371397435665,0.012872358784079552,0.012158876284956932,0.010611343197524548,0.011139153502881527,0.012282747775316238,0.009927175007760525,0.008638289757072926,0.009199422784149647,0.0108240507543087,0.009998711757361889,0.00934804417192936,0.01084108091890812,0.012111394666135311,0.011906759813427925,0.011402084492146969,0.009419621899724007,0.008526630699634552,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 67275     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 67276     
=================================================================
Total params: 134,551
Trainable params: 134,551
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 67,275
Trainable params: 67,275
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 67,276
Trainable params: 67,276
Non-trainable params: 0
_________________________________________________________________
