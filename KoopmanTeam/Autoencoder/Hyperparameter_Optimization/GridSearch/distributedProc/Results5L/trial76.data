2021-06-26
loss,0.6678743958473206,0.23793120682239532,0.22067268192768097,0.194711834192276,0.14134709537029266,0.10552920401096344,0.12026121467351913,0.09672556072473526,0.07061491161584854,0.0934920608997345,0.0600464791059494,0.0714285597205162,0.059403277933597565,0.07537136226892471,0.060798048973083496,0.05729139223694801,0.0506817065179348,0.04443884268403053,0.05581708997488022,0.03521415591239929,0.04583698883652687,0.03965247794985771,0.04675457626581192,0.04765457287430763,0.052039336413145065,0.043512776494026184,0.03765052556991577,0.04094042629003525,0.037598446011543274,0.031814031302928925,0.035672567784786224,0.04476211220026016,0.034883007407188416,0.04005593806505203,0.035539742559194565,0.032143380492925644,0.038492124527692795,0.035703644156455994,0.034671105444431305,0.027906913310289383,0.03214229643344879,0.03596505522727966,0.03260303661227226,0.02862725406885147,0.023741867393255234,0.027351444587111473,0.031111834570765495,0.03003540448844433,0.031918421387672424,0.030270585790276527,0.03118784725666046,0.029140206053853035,0.025565514340996742,0.0261990949511528,0.029847504571080208,0.030646279454231262,0.026441378518939018,0.022308649495244026,0.021025262773036957,0.021707048639655113,0.027216853573918343,0.026712240651249886,0.023910189047455788,0.023887908086180687,0.022222504019737244,0.022912995889782906,0.019550619646906853,0.022030726075172424,0.025135859847068787,0.02882426790893078,0.02763615921139717,0.027565574273467064,0.025309434160590172,0.021668292582035065,0.021925238892436028,0.02572164312005043,0.023047957569360733,0.026443112641572952,0.024978728964924812,0.023174619302153587,0.02205563336610794,0.023419808596372604,0.023955712094902992,0.022306246683001518,0.021549683064222336,0.023177290335297585,0.02264820784330368,0.023917045444250107,0.024388350546360016,0.024916965514421463,0.021548934280872345,0.02172461338341236,0.022453179582953453,0.01989605836570263,0.019996674731373787,0.02068501152098179,0.019727742299437523,0.02070174738764763,0.01886916719377041,0.01717131957411766,
mse,0.21545477211475372,0.019183725118637085,0.016944272443652153,0.012059309519827366,0.0058624292723834515,0.0032535046339035034,0.00420454703271389,0.002876096870750189,0.0014932173071429133,0.0025021356996148825,0.0011035283096134663,0.0014524348080158234,0.0010408584494143724,0.0016054160660132766,0.0010368364164605737,0.0009840414859354496,0.0007483547669835389,0.0006128591485321522,0.0008863484254106879,0.00038153136847540736,0.0005921509000472724,0.0004639468970708549,0.0006059103761799634,0.0006586582749150693,0.0007630211184732616,0.0005430551245808601,0.00040504225762560964,0.0004851437115576118,0.00039739019121043384,0.0002850921591743827,0.00039275214658118784,0.000548560346942395,0.0003600645868573338,0.0004693487426266074,0.0003500382590573281,0.00029823751538060606,0.00041022300138138235,0.0003562317870091647,0.0003374134248588234,0.0002273887803312391,0.0002965655585285276,0.00036259900662116706,0.00029930786695331335,0.00023080437676981091,0.00016940050409175456,0.00022934639127925038,0.0002750288404058665,0.0002533032966312021,0.000283999863313511,0.00024990533711388707,0.00027094705728814006,0.00024145426868926734,0.00018770599854178727,0.00019336777040734887,0.00024873990332707763,0.000254963495535776,0.00019220579997636378,0.00014516084047500044,0.00013175429194234312,0.0001435040176147595,0.00021778423979412764,0.0001924479875015095,0.00015807690215297043,0.00015632447320967913,0.00013944675447419286,0.00015820244152564555,0.00011380951764294878,0.00014359944907482713,0.0001822296908358112,0.00023978081298992038,0.00021767242287751287,0.00020933483028784394,0.00017846286937128752,0.0001371025136904791,0.0001424404908902943,0.00018319986702408642,0.00014793185982853174,0.0001957814092747867,0.0001740392908686772,0.00015401057316921651,0.00013636902440339327,0.00015720419469289482,0.0001683656155364588,0.00014290498802438378,0.0001310814404860139,0.00015233976591844112,0.0001428265095455572,0.00016322646115440875,0.0001673694496275857,0.00017092697089537978,0.00013376408605836332,0.00013494234008248895,0.00014003910473547876,0.00011494106001919135,0.0001164678469649516,0.00011980546696577221,0.00011243528570048511,0.00011835529585368931,0.00010033501894213259,8.492416964145377e-05,
mae,0.28352680802345276,0.10128727555274963,0.09296861290931702,0.08328130841255188,0.06088876351714134,0.045700084418058395,0.05053360015153885,0.0423244908452034,0.03009583242237568,0.04081510379910469,0.025618698447942734,0.030473140999674797,0.02556370198726654,0.032529596239328384,0.026303036138415337,0.024693669751286507,0.022115128114819527,0.019145524129271507,0.024065373465418816,0.01502515934407711,0.01944657973945141,0.01682870090007782,0.020044956356287003,0.020595567300915718,0.02282073348760605,0.01917949505150318,0.015979889780282974,0.01746787503361702,0.015880240127444267,0.013388030230998993,0.01519928127527237,0.019559688866138458,0.014906257390975952,0.017360053956508636,0.01508465688675642,0.013660093769431114,0.0167952012270689,0.015546159818768501,0.01494121178984642,0.011832798831164837,0.013750439509749413,0.015640664845705032,0.014212952926754951,0.011928443796932697,0.010040433146059513,0.011779287829995155,0.013310793787240982,0.012856303714215755,0.01368281152099371,0.012814291752874851,0.013259789906442165,0.01255909726023674,0.010847196914255619,0.01130213774740696,0.01258808746933937,0.013018789701163769,0.011360500007867813,0.00963604636490345,0.008945244364440441,0.009208359755575657,0.011546023190021515,0.011468449607491493,0.010032917372882366,0.010060140863060951,0.009468553587794304,0.009667622856795788,0.008357816375792027,0.009275143966078758,0.01036008633673191,0.012487523257732391,0.01183023676276207,0.011852715164422989,0.010637955740094185,0.008969875983893871,0.00925488118082285,0.011059539392590523,0.009909313172101974,0.011350763030350208,0.010872104205191135,0.009716685861349106,0.009414974600076675,0.01007615216076374,0.01014274824410677,0.009514590725302696,0.009174452163279057,0.010048056952655315,0.009664973244071007,0.010175837203860283,0.01029900461435318,0.011103114113211632,0.009174240753054619,0.009297680109739304,0.009522957727313042,0.008293299935758114,0.00851317960768938,0.008685131557285786,0.008400828577578068,0.009021210484206676,0.008216370828449726,0.007259971462190151,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 69459     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 69460     
=================================================================
Total params: 138,919
Trainable params: 138,919
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 69,459
Trainable params: 69,459
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 69,460
Trainable params: 69,460
Non-trainable params: 0
_________________________________________________________________
