2021-06-26
loss,1.1357817649841309,0.25186607241630554,0.23132380843162537,0.22313819825649261,0.21238647401332855,0.2058839648962021,0.19806887209415436,0.1829422414302826,0.16470718383789062,0.15195640921592712,0.11490693688392639,0.09701095521450043,0.08688998222351074,0.07897190749645233,0.0729341059923172,0.08108976483345032,0.06467757374048233,0.045225463807582855,0.05193425342440605,0.0588851161301136,0.045617636293172836,0.05070381239056587,0.048317715525627136,0.04895499348640442,0.04569794237613678,0.04611094295978546,0.041821036487817764,0.03981532156467438,0.03534460812807083,0.03835047781467438,0.035207558423280716,0.03584932163357735,0.03532828390598297,0.03304300457239151,0.02903488092124462,0.028809605166316032,0.0349368155002594,0.030964260920882225,0.03139710798859596,0.02868400327861309,0.03008917160332203,0.028757307678461075,0.02307160198688507,0.021684756502509117,0.020335786044597626,0.022448882460594177,0.02982284314930439,0.026010120287537575,0.020586203783750534,0.0299048013985157,0.02603682316839695,0.02551191858947277,0.024648839607834816,0.026764653623104095,0.023714808747172356,0.021869653835892677,0.023873748257756233,0.02446618489921093,0.0239217858761549,0.02303338795900345,0.020605487748980522,0.018024694174528122,0.021121811121702194,0.02310565486550331,0.02591942623257637,0.023675663396716118,0.021694887429475784,0.02201448753476143,0.021892590448260307,0.022339222952723503,0.021215002983808517,0.021295402199029922,0.019178418442606926,0.01982870325446129,0.01882450468838215,0.02252049930393696,0.0208013653755188,0.02297607623040676,0.021337486803531647,0.020260795950889587,0.02106657437980175,0.021217936649918556,0.020741797983646393,0.01892426796257496,0.01758020743727684,0.019407635554671288,0.019743291661143303,0.021812811493873596,0.019123844802379608,0.017302915453910828,0.015890756621956825,0.018024606630206108,0.019178356975317,0.018814800307154655,0.018615281209349632,0.020623179152607918,0.019542330875992775,0.017778458073735237,0.015298672020435333,0.01758601702749729,
mse,0.5636063814163208,0.020903559401631355,0.018579401075839996,0.017563851550221443,0.016063598915934563,0.015011042356491089,0.013619739562273026,0.011030077002942562,0.008113853633403778,0.006730742286890745,0.00383559288457036,0.002661903155967593,0.0022077865432947874,0.0018637583125382662,0.0015501469606533647,0.0018893080996349454,0.0012655826285481453,0.0006001252913847566,0.0007583564729429781,0.0009939062874764204,0.0006052114185877144,0.0007217638194561005,0.000658845470752567,0.0006688888533972204,0.0005815753247588873,0.0005929041071794927,0.0004919873317703605,0.00044186413288116455,0.00035323805059306324,0.00040373008232563734,0.00034300985862500966,0.0003553053247742355,0.00034954221337102354,0.0003058865258935839,0.00023188447812572122,0.00023285593488253653,0.00033946114126592875,0.00026987004093825817,0.0002703486243262887,0.00023801319184713066,0.00025515182642266154,0.00022947111574467272,0.0001526761770946905,0.00013826947542838752,0.00012140478065703064,0.0001491956354584545,0.0002448818413540721,0.00018747025751508772,0.00012429311755113304,0.00025350876967422664,0.0001887743128463626,0.00017856823978945613,0.00017184499301947653,0.000198468187591061,0.00015673240704927593,0.00013686816964764148,0.00016019551549106836,0.00016876528388820589,0.00016316086112055928,0.0001447617687517777,0.000119307245768141,9.469089127378538e-05,0.0001394330320181325,0.00015448337944690138,0.00018623817595653236,0.00015539154992438853,0.00012948269431944937,0.00013865556684322655,0.00013430495164357126,0.0001397213345626369,0.0001291729131480679,0.00012873145169578493,0.00010562798706814647,0.00011137014371342957,0.0001035496752592735,0.0001401107874698937,0.00012169694673502818,0.00014903298870194703,0.0001271825603907928,0.00011697189620463178,0.0001231808855663985,0.00012645154492929578,0.00012042646267218515,0.0001023758013616316,8.984475425677374e-05,0.00010756909614428878,0.00011066570004913956,0.00013227391173131764,0.00010293691593687981,8.626088674645871e-05,7.540443766629323e-05,9.444486204301938e-05,0.0001019836709019728,0.00010124107939191163,9.947219950845465e-05,0.00012050160876242444,0.0001079672874766402,9.042688907356933e-05,6.937223224667832e-05,9.134120045928285e-05,
mae,0.43298229575157166,0.10814108699560165,0.1048542782664299,0.10209304839372635,0.0958997905254364,0.09098077565431595,0.08549657464027405,0.07811414450407028,0.06968031078577042,0.06382454931735992,0.04824976623058319,0.041136641055345535,0.03725777193903923,0.03381818160414696,0.031191252171993256,0.03419287130236626,0.027821974828839302,0.019323445856571198,0.02194359339773655,0.02577604539692402,0.019378969445824623,0.02185298129916191,0.020760638639330864,0.021092185750603676,0.019536161795258522,0.019789639860391617,0.018211640417575836,0.017010802403092384,0.015133509412407875,0.01635526865720749,0.014720415696501732,0.015363730490207672,0.015064399689435959,0.013949427753686905,0.012445819564163685,0.012452326714992523,0.01512064691632986,0.013389093801379204,0.0133047541603446,0.012135174125432968,0.012943442910909653,0.012309047393500805,0.00976896844804287,0.009170692414045334,0.00862448662519455,0.009550390765070915,0.01267422828823328,0.011321022175252438,0.00877542607486248,0.012933996506035328,0.01086159236729145,0.010863206349313259,0.01030921470373869,0.01155101414769888,0.010110970586538315,0.009266185574233532,0.010134820826351643,0.010565671138465405,0.010215125977993011,0.00948528666049242,0.008588647469878197,0.0076115308329463005,0.009041383862495422,0.009824137203395367,0.011374900117516518,0.010028240270912647,0.009041955694556236,0.00918788556009531,0.009182647801935673,0.0094996253028512,0.00901185255497694,0.00895212683826685,0.0080820731818676,0.008400103077292442,0.007885274477303028,0.009616491384804249,0.008786138147115707,0.009975495748221874,0.009125578217208385,0.008668291382491589,0.009010497480630875,0.00916996132582426,0.008887697011232376,0.0080473143607378,0.007421476300805807,0.00825056154280901,0.008373105898499489,0.009296036325395107,0.008214714005589485,0.0072406274266541,0.0066767591051757336,0.007693629711866379,0.008208095096051693,0.008067315444350243,0.007875642739236355,0.008830948732793331,0.008288886398077011,0.007547140587121248,0.006496814079582691,0.007386274170130491,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 105443    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 105444    
=================================================================
Total params: 210,887
Trainable params: 210,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 105,443
Trainable params: 105,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 105,444
Trainable params: 105,444
Non-trainable params: 0
_________________________________________________________________
