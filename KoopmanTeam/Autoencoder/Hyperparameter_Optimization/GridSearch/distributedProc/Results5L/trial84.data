2021-06-26
loss,1.2660255432128906,0.3696441650390625,0.3635029196739197,0.35978931188583374,0.35893669724464417,0.3566189110279083,0.3514840602874756,0.3518895208835602,0.34889644384384155,0.34737223386764526,0.3473297953605652,0.337683767080307,0.34605664014816284,0.3053034245967865,0.23792943358421326,0.23060725629329681,0.22563152015209198,0.21084651350975037,0.20621410012245178,0.1462227702140808,0.11452507227659225,0.09647583961486816,0.07699567824602127,0.07011335343122482,0.06292948126792908,0.05680973455309868,0.06445953249931335,0.06862054020166397,0.06036406382918358,0.05940762534737587,0.04317020997405052,0.03770007938146591,0.039414066821336746,0.03684866428375244,0.050829313695430756,0.045586708933115005,0.03855422884225845,0.03478451445698738,0.030152689665555954,0.042344700545072556,0.04058103263378143,0.03634351119399071,0.03861115872859955,0.032792769372463226,0.031446803361177444,0.03523830696940422,0.03201191872358322,0.029284510761499405,0.028516823425889015,0.03069773130118847,0.029312778264284134,0.035210803151130676,0.03234893083572388,0.024897804483771324,0.02800816483795643,0.028955573216080666,0.02983296662569046,0.03195105493068695,0.02915395423769951,0.02788231149315834,0.02546854317188263,0.024097567424178123,0.025129597634077072,0.029709987342357635,0.02165895141661167,0.03068544901907444,0.031155813485383987,0.028631541877985,0.023135919123888016,0.024177158251404762,0.022007400169968605,0.029470358043909073,0.02709331549704075,0.024123581126332283,0.024242322891950607,0.024496404454112053,0.028897183015942574,0.025872930884361267,0.024510584771633148,0.02063559740781784,0.023948905989527702,0.027808232232928276,0.02364509366452694,0.021362612023949623,0.02184215374290943,0.024476202204823494,0.02628147602081299,0.02166294865310192,0.02090015448629856,0.022685423493385315,0.02287742681801319,0.02364467829465866,0.02573227323591709,0.024214472621679306,0.022534530609846115,0.023935746401548386,0.0215303897857666,0.017212912440299988,0.019107753410935402,0.02154422551393509,
mse,0.8089174628257751,0.04019211232662201,0.03898979350924492,0.038367174565792084,0.03828044235706329,0.03784719854593277,0.037064146250486374,0.03700938820838928,0.03645811229944229,0.03606962785124779,0.035825490951538086,0.034105800092220306,0.03520451486110687,0.028551047667860985,0.019275173544883728,0.01829329878091812,0.01729748211801052,0.014559095725417137,0.013392854481935501,0.006524106487631798,0.0038959423545747995,0.0028705885633826256,0.001746328896842897,0.001449340139515698,0.0012199095217511058,0.0009464958566240966,0.0012273344909772277,0.001349767786450684,0.0010953996097669005,0.0009953351691365242,0.00054406956769526,0.00042030573240481317,0.00048100625281222165,0.0004046992980875075,0.0007698169210925698,0.0005985335446894169,0.00044188767788000405,0.000360554491635412,0.00027899217093363404,0.0005284054204821587,0.0004607427108567208,0.0003779353282880038,0.00042675159056670964,0.0003217115590814501,0.00029169057961553335,0.00036259100306779146,0.0003006779297720641,0.00024933545500971377,0.00024347992439288646,0.0002707997045945376,0.00025028243544511497,0.0003531634865794331,0.000299976411042735,0.00018595339497551322,0.00022848138178233057,0.0002435439091641456,0.0002583867753855884,0.0002895107609219849,0.00025010693934746087,0.0002297535538673401,0.0001931571023305878,0.00017560251581016928,0.0001836661685956642,0.00026029019500128925,0.00014186857151798904,0.00027529068756848574,0.0002727738756220788,0.00023541026166640222,0.00016111190780065954,0.00017026346176862717,0.00014846208796370775,0.00024383369600400329,0.00021342599939089268,0.00017228297656401992,0.0001720110885798931,0.00017870728333946317,0.000232610254897736,0.00019314985547680408,0.00017386706895194948,0.00012848600454162806,0.00016822553880047053,0.00021831544290762395,0.00015920893929433078,0.0001376291475025937,0.00014194984396453947,0.00017321403720416129,0.0001961410162039101,0.0001383388153044507,0.00013364215556066483,0.00015189284749794751,0.00015412559150718153,0.00016302181757055223,0.00018777517834678292,0.00016865733778104186,0.00014960627595428377,0.00016567356942687184,0.0001350431120954454,9.02684114407748e-05,0.00010913155711023137,0.0001345706987194717,
mae,0.5620695948600769,0.16214336454868317,0.1591191291809082,0.15748922526836395,0.1570882648229599,0.15513019263744354,0.15232115983963013,0.15181440114974976,0.15034203231334686,0.15006957948207855,0.14971745014190674,0.1453259438276291,0.14812633395195007,0.1320604532957077,0.10686396807432175,0.10474241524934769,0.10052923113107681,0.09104068577289581,0.0883660688996315,0.06242699548602104,0.04827524721622467,0.0409015417098999,0.03253977373242378,0.029848478734493256,0.026823675259947777,0.024106862023472786,0.027528252452611923,0.02958507277071476,0.02605403959751129,0.0252554789185524,0.01807401329278946,0.016049178317189217,0.016745440661907196,0.015652762725949287,0.02122848480939865,0.019445225596427917,0.016519198194146156,0.014870182611048222,0.012842437252402306,0.018274597823619843,0.01714181900024414,0.015334542840719223,0.016663089394569397,0.014220692217350006,0.01347558293491602,0.014920966699719429,0.01365114375948906,0.012437455356121063,0.012248623184859753,0.013106930069625378,0.012467842549085617,0.015081256628036499,0.014035996980965137,0.010633748956024647,0.01188071258366108,0.01238905917853117,0.012821085751056671,0.013815398328006268,0.0122848404571414,0.012020583264529705,0.010860718786716461,0.010278222151100636,0.01048591360449791,0.012524780817329884,0.00909725297242403,0.012919378466904163,0.013458408415317535,0.012384049594402313,0.009841366671025753,0.010323025286197662,0.00940586719661951,0.01235270593315363,0.011636820621788502,0.01042796578258276,0.010389265604317188,0.010404317639768124,0.012549174949526787,0.011028443463146687,0.010455574840307236,0.008812070824205875,0.010189649648964405,0.012004551477730274,0.010083938017487526,0.009108513593673706,0.009302356280386448,0.01043088547885418,0.011294112540781498,0.009178526699543,0.008994115516543388,0.00955252442508936,0.009684514254331589,0.01003569271415472,0.011058945208787918,0.010352611541748047,0.009579152800142765,0.010353511199355125,0.009122958406805992,0.007271334063261747,0.008165527135133743,0.009163317270576954,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 200651    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 200652    
=================================================================
Total params: 401,303
Trainable params: 401,303
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 200,651
Trainable params: 200,651
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 200,652
Trainable params: 200,652
Non-trainable params: 0
_________________________________________________________________
