2021-06-26
loss,1.1137301921844482,0.3697730302810669,0.32688018679618835,0.28498345613479614,0.2591378390789032,0.2381574958562851,0.22374920547008514,0.2206784188747406,0.257819265127182,0.21853747963905334,0.15184199810028076,0.14609937369823456,0.09875041991472244,0.11117348074913025,0.10167986154556274,0.08621054887771606,0.09579339623451233,0.07717683166265488,0.06866085529327393,0.07521876692771912,0.06607570499181747,0.07061582803726196,0.06100616604089737,0.0672517791390419,0.05505063384771347,0.052673134952783585,0.05597541853785515,0.04754232242703438,0.04184964299201965,0.04015613719820976,0.04412834346294403,0.05076909437775612,0.04252086579799652,0.046151865273714066,0.039959050714969635,0.038825441151857376,0.035918883979320526,0.0358906090259552,0.034903623163700104,0.032644812017679214,0.039601314812898636,0.03876706212759018,0.03802613914012909,0.03582964092493057,0.03142460808157921,0.0349450558423996,0.031367529183626175,0.030168645083904266,0.031187066808342934,0.03373825177550316,0.030971884727478027,0.024742022156715393,0.025383030995726585,0.0301157645881176,0.030911760404706,0.025623001158237457,0.029090121388435364,0.02871660515666008,0.029525337740778923,0.026783639565110207,0.027105651795864105,0.0223452877253294,0.024978911504149437,0.02566801756620407,0.027667906135320663,0.02557171881198883,0.02542513608932495,0.02585691027343273,0.025523116812109947,0.025502050295472145,0.02248024381697178,0.025175657123327255,0.02332291379570961,0.025159139186143875,0.023939087986946106,0.022664641961455345,0.02585631050169468,0.025094423443078995,0.02098073437809944,0.020852157846093178,0.02161497436463833,0.024311259388923645,0.02598021738231182,0.022496920078992844,0.021767793223261833,0.02309701405465603,0.021114228293299675,0.019577065482735634,0.02287377417087555,0.021275531500577927,0.023092135787010193,0.021974120289087296,0.021781228482723236,0.0219613928347826,0.021926667541265488,0.022565342485904694,0.020606549456715584,0.021060490980744362,0.020599711686372757,0.021193265914916992,
mse,0.5872239470481873,0.03962564095854759,0.03133508190512657,0.02455824427306652,0.02104591578245163,0.01835356466472149,0.016421813517808914,0.015883205458521843,0.020829005166888237,0.014566322788596153,0.006701560225337744,0.006295409053564072,0.002812993712723255,0.003752690739929676,0.0030068843625485897,0.0021103343460708857,0.002596562262624502,0.0016974126920104027,0.0013771397061645985,0.0016063663642853498,0.001222996972501278,0.0013893981231376529,0.0011050249449908733,0.0012968245428055525,0.0008875166531652212,0.0008337574545294046,0.0008785780519247055,0.0006354504730552435,0.0004998000804334879,0.00046793455840088427,0.0005615422269329429,0.0007292985101230443,0.0005106056341901422,0.0005872436449863017,0.0004434535512700677,0.00042020995169878006,0.00035554866190068424,0.0003635484026744962,0.00033532336237840354,0.00030112502281554043,0.0004405714280437678,0.0004316291306167841,0.0004083740641362965,0.000359031226253137,0.0002829590521287173,0.00034791152575053275,0.0002760908682830632,0.0002569983771536499,0.00027354704798199236,0.00031790268258191645,0.0002676040166988969,0.00017845019465312362,0.00018709305732045323,0.0002563023008406162,0.00026614355738274753,0.00019293419609311968,0.00024585321079939604,0.00023142162535805255,0.0002505410520825535,0.00020383404626045376,0.00020545949519146234,0.00014653611287940294,0.00018205685773864388,0.00018950719095300883,0.00021361905965022743,0.00018637871835380793,0.00018921626906376332,0.0001872772118076682,0.00019122356025036424,0.00018317090871278197,0.0001432342396583408,0.00018048667698167264,0.00016085366951301694,0.00018161657499149442,0.00016476286691613495,0.00014691753312945366,0.0001853091671364382,0.00017557181126903743,0.00012908235657960176,0.00013075859169475734,0.00013485988893080503,0.00016703532310202718,0.0001881247735582292,0.00014452246250584722,0.00013447186211124063,0.0001545336126582697,0.00012846053868997842,0.00011297600576654077,0.0001456194877391681,0.0001313835964538157,0.00015059817815199494,0.00013811477401759475,0.0001342647592537105,0.00013544618559535593,0.00013846108049619943,0.00014342361828312278,0.00012267591955605894,0.00012821237032767385,0.00012230353604536504,0.00012723820691462606,
mae,0.48376768827438354,0.15991224348545074,0.14020904898643494,0.12345991283655167,0.11164045333862305,0.10144945979118347,0.09579123556613922,0.09511867165565491,0.11219919472932816,0.09292034059762955,0.06478837132453918,0.060775548219680786,0.0416409969329834,0.0470132976770401,0.04437863454222679,0.036463599652051926,0.04062986746430397,0.03254374861717224,0.02940896339714527,0.03139252960681915,0.0278426855802536,0.030433468520641327,0.026374774053692818,0.029368963092565536,0.023371592164039612,0.022390859201550484,0.02394661121070385,0.01996602676808834,0.017755288630723953,0.01694134622812271,0.018700679764151573,0.021838700398802757,0.01826717145740986,0.019806208088994026,0.017032485455274582,0.016609353944659233,0.015344333834946156,0.015435921959578991,0.014767603017389774,0.01361019629985094,0.017024977132678032,0.016860732808709145,0.016641927883028984,0.015179384499788284,0.013318373821675777,0.01462588645517826,0.013127736747264862,0.01287956815212965,0.013352363370358944,0.014529116451740265,0.013356795534491539,0.010448968037962914,0.01075830589979887,0.01270118448883295,0.013123737648129463,0.010893415659666061,0.012556659989058971,0.01221286877989769,0.012553593143820763,0.011224783957004547,0.011456375941634178,0.009481295011937618,0.010700148530304432,0.010917054489254951,0.011871668510138988,0.01069035567343235,0.010841301642358303,0.010993611998856068,0.011072126217186451,0.010868273675441742,0.009641231968998909,0.010583997704088688,0.009988394565880299,0.010798590257763863,0.010149492882192135,0.009502856992185116,0.011025832034647465,0.010953502729535103,0.008909972384572029,0.008845610544085503,0.009147495962679386,0.010275354608893394,0.011100922711193562,0.009489716030657291,0.00926804170012474,0.009913689456880093,0.008973808959126472,0.008315000683069229,0.009677024558186531,0.0091231819242239,0.009877435863018036,0.009455454535782337,0.009141414426267147,0.009294957853853703,0.009372464381158352,0.009590838104486465,0.009023490361869335,0.008802928030490875,0.008722340688109398,0.00894833728671074,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 210083    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 210084    
=================================================================
Total params: 420,167
Trainable params: 420,167
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 210,083
Trainable params: 210,083
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 210,084
Trainable params: 210,084
Non-trainable params: 0
_________________________________________________________________
