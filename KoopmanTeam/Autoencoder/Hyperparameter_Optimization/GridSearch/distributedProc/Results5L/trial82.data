2021-06-26
loss,1.3097212314605713,0.4016285240650177,0.3548542261123657,0.35172009468078613,0.3512454628944397,0.35190626978874207,0.2549285292625427,0.23800045251846313,0.23471353948116302,0.2326621115207672,0.23106931149959564,0.23907877504825592,0.20916055142879486,0.13573212921619415,0.11510647088289261,0.10016649216413498,0.09623731672763824,0.08318766951560974,0.06826231628656387,0.0708170011639595,0.07708185911178589,0.07038571685552597,0.06949000060558319,0.06699127703905106,0.05272475257515907,0.05175895616412163,0.05589676275849342,0.04913587495684624,0.04386546090245247,0.05042806640267372,0.04510287940502167,0.042118340730667114,0.04929055646061897,0.051904842257499695,0.04771057143807411,0.050192974507808685,0.04113852605223656,0.036813925951719284,0.03827768191695213,0.045080628246068954,0.047523535788059235,0.040433138608932495,0.03643639385700226,0.03744583949446678,0.036128442734479904,0.03090822510421276,0.026932820677757263,0.027863282710313797,0.03598032891750336,0.037402763962745667,0.04411198943853378,0.04227010905742645,0.03784172609448433,0.037706855684518814,0.03834359720349312,0.040343355387449265,0.03815404698252678,0.0308219101279974,0.03239981457591057,0.027349069714546204,0.03253747150301933,0.03531991317868233,0.029711904004216194,0.030892662703990936,0.031573355197906494,0.03116496093571186,0.03534668684005737,0.03256198763847351,0.03222723305225372,0.03344463184475899,0.03348008170723915,0.032683566212654114,0.030739925801753998,0.024053582921624184,0.027886338531970978,0.02959561161696911,0.028114737942814827,0.02899087220430374,0.02765515260398388,0.03245602920651436,0.03027077205479145,0.025180339813232422,0.02564268372952938,0.02835971862077713,0.030940569937229156,0.029267027974128723,0.029438646510243416,0.025413714349269867,0.02743634767830372,0.024442356079816818,0.025641798973083496,0.02657346799969673,0.028909094631671906,0.029170570895075798,0.02580072730779648,0.027991237118840218,0.026812581345438957,0.024257736280560493,0.024373764172196388,0.024745313450694084,
mse,0.7045045495033264,0.046984877437353134,0.03757994994521141,0.037103425711393356,0.03679991140961647,0.03649082034826279,0.021560415625572205,0.019703296944499016,0.019416283816099167,0.019206278026103973,0.01880163699388504,0.018213124945759773,0.013616079464554787,0.005997868720442057,0.0039879740215837955,0.0031913211569190025,0.003052783664315939,0.002140437252819538,0.001500564394518733,0.0015494966646656394,0.0017801180947571993,0.001528933527879417,0.0014398051425814629,0.0013506165705621243,0.0008429758017882705,0.0008096351521089673,0.0009695299668237567,0.0007454000879079103,0.0006076446734368801,0.0007711226353421807,0.0006140218465588987,0.0005521756247617304,0.000730145548004657,0.0008225491619668901,0.0006841083522886038,0.0007442568894475698,0.0005221202736720443,0.00041572953341528773,0.00046657296479679644,0.0006208207341842353,0.0006565909134224057,0.0004974169423803687,0.00040391588117927313,0.0004124896368011832,0.0003964361676480621,0.00029766318039037287,0.00023266964126378298,0.00024208761169575155,0.0004009965341538191,0.00041751895332708955,0.0005738213076256216,0.0005235201679170132,0.00043043112964369357,0.00041731857345439494,0.0004440742777660489,0.0004670355701819062,0.0004220016999170184,0.00030092697124928236,0.0003137458406854421,0.00023361534113064408,0.0003100658068433404,0.0003775154473260045,0.00026818917831405997,0.0002903509302996099,0.0002943293657153845,0.0002961528953164816,0.00037033879198133945,0.00031356673571281135,0.00031056368607096374,0.00033564880141057074,0.00032992794876918197,0.000319425918860361,0.0002779297938104719,0.00017817251500673592,0.0002434908237773925,0.00026787747628986835,0.00024100398877635598,0.00024985679192468524,0.00023168037296272814,0.0003044890472665429,0.00027032397338189185,0.00019555198377929628,0.000200316499103792,0.0002398699871264398,0.00028177714557386935,0.0002556490944698453,0.0002528635668568313,0.00019748328486457467,0.00022541327052749693,0.0001814729330362752,0.00019621018145699054,0.00021095553529448807,0.00024465646129101515,0.0002496732631698251,0.00019890963449142873,0.00023123629216570407,0.00021474588720593601,0.0001775887212716043,0.00018093590915668756,0.0001814159331843257,
mae,0.5825952887535095,0.1733228713274002,0.15383005142211914,0.15321828424930573,0.15362758934497833,0.15119200944900513,0.11365727335214615,0.10741038620471954,0.1065448597073555,0.1058628186583519,0.10498128831386566,0.10431773960590363,0.08924691379070282,0.057395391166210175,0.0492330938577652,0.04285752773284912,0.041044630110263824,0.036006245762109756,0.029388384893536568,0.030090639367699623,0.03324553743004799,0.030058536678552628,0.029733430594205856,0.028811275959014893,0.022570159286260605,0.02192535810172558,0.023930266499519348,0.021228211000561714,0.01875404641032219,0.02160388045012951,0.019214710220694542,0.017916785553097725,0.021244514733552933,0.022547993808984756,0.020655889064073563,0.021525360643863678,0.01783774048089981,0.01571711339056492,0.016484441235661507,0.019606852903962135,0.020681651309132576,0.017496878281235695,0.015538327395915985,0.015793031081557274,0.01553363911807537,0.013274764642119408,0.01154994685202837,0.011858323588967323,0.015491110272705555,0.016072776168584824,0.01885296404361725,0.017994070425629616,0.016517825424671173,0.0162759181112051,0.016483915969729424,0.017438868060708046,0.016501346603035927,0.013268250040709972,0.013961486518383026,0.011637858115136623,0.013871326111257076,0.015349643304944038,0.012696522288024426,0.01325687300413847,0.013573812320828438,0.01356352586299181,0.015449441969394684,0.01411303412169218,0.013551798649132252,0.01453645434230566,0.014735251665115356,0.014769149012863636,0.013333153910934925,0.010182684287428856,0.011797253042459488,0.01293522585183382,0.012050759978592396,0.012652411125600338,0.011883161030709743,0.014394539408385754,0.013214622624218464,0.010610077530145645,0.010939202271401882,0.01215799804776907,0.013442021794617176,0.01277746632695198,0.013022125698626041,0.010913223959505558,0.011609970591962337,0.010364850983023643,0.011037108488380909,0.011401839554309845,0.01239125058054924,0.012726869434118271,0.011224525049328804,0.012005873024463654,0.011724751442670822,0.010444862768054008,0.010586538352072239,0.010722082108259201,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 133963    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 133964    
=================================================================
Total params: 267,927
Trainable params: 267,927
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 133,963
Trainable params: 133,963
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 133,964
Trainable params: 133,964
Non-trainable params: 0
_________________________________________________________________
