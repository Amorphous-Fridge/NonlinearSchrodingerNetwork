2021-06-26
loss,0.47506001591682434,0.22887521982192993,0.21484093368053436,0.2041483372449875,0.19218438863754272,0.17938867211341858,0.1649816632270813,0.1501132994890213,0.09763966500759125,0.07699912786483765,0.0706181526184082,0.08301596343517303,0.06739635765552521,0.05830033868551254,0.06692467629909515,0.06634178012609482,0.06706693023443222,0.06129016354680061,0.05271158739924431,0.049687352031469345,0.048279065638780594,0.05952543765306473,0.05515211075544357,0.0498209223151207,0.04725489765405655,0.040004197508096695,0.034482453018426895,0.030893923714756966,0.029533592984080315,0.043012771755456924,0.04564817249774933,0.0378740094602108,0.035376228392124176,0.0332508310675621,0.032239243388175964,0.034873008728027344,0.02962464839220047,0.035765014588832855,0.04031870514154434,0.03653428703546524,0.03504718840122223,0.03304503485560417,0.03218585625290871,0.027632009238004684,0.02516225166618824,0.02359028160572052,0.022949345409870148,0.022639190778136253,0.02819889597594738,0.033524952828884125,0.03216858580708504,0.03185150772333145,0.027836952358484268,0.02941679023206234,0.029943600296974182,0.027716241776943207,0.0248341653496027,0.02451658807694912,0.02753346413373947,0.028316162526607513,0.02501221001148224,0.022778036072850227,0.020537767559289932,0.01870395801961422,0.01803109608590603,0.018737059086561203,0.022776374593377113,0.023143084719777107,0.023942220956087112,0.026079677045345306,0.028297634795308113,0.023989398032426834,0.024832945317029953,0.021236881613731384,0.024799682199954987,0.022855598479509354,0.017953254282474518,0.01623326726257801,0.018171418458223343,0.017955580726265907,0.02484976500272751,0.023631999269127846,0.020361842587590218,0.018424589186906815,0.022716792300343513,0.02554965764284134,0.021632103249430656,0.022580649703741074,0.02438150905072689,0.02113218978047371,0.018938301131129265,0.018076561391353607,0.015354436822235584,0.019046830013394356,0.023535404354333878,0.024255137890577316,0.022582771256566048,0.019580906257033348,0.01985812932252884,0.02274792641401291,
mse,0.08715265244245529,0.018284093588590622,0.01620933972299099,0.014483749866485596,0.012820303440093994,0.010503126308321953,0.008299330249428749,0.007052124943584204,0.0030243152286857367,0.0018060468137264252,0.001535978284664452,0.002023303182795644,0.0013445720542222261,0.0010050996206700802,0.0013853136915713549,0.0012729368172585964,0.001295394729822874,0.0010875375010073185,0.0007967236451804638,0.0007125838892534375,0.0006612956058233976,0.0009920942829921842,0.0008589003118686378,0.0007083158125169575,0.000634154595900327,0.0004555291961878538,0.0003372739301994443,0.0002719923504628241,0.0002564253518357873,0.0005383385578170419,0.0005872753099538386,0.00039829249726608396,0.00035437330370768905,0.00031172914896160364,0.0002894253411795944,0.00034745351877063513,0.00026437919586896896,0.00037943501956760883,0.00047275834367610514,0.00037667289143428206,0.00035619191476143897,0.00030960069852881134,0.0002885666617657989,0.00021640799241140485,0.0001800407626433298,0.0001612000778550282,0.00015185089432634413,0.00015496164269279689,0.00023414053430315107,0.0003251484304200858,0.00029609655030071735,0.0002874964557122439,0.00022146999253891408,0.0002413112233625725,0.00025149440625682473,0.00021271005971357226,0.00017722869233693928,0.00017257705621886998,0.00022527707915287465,0.00022288280888460577,0.0001761841558618471,0.00015022496518213302,0.00012379969120956957,0.00010650749027263373,9.94311340036802e-05,0.00010764591570477933,0.0001563557452755049,0.00015889668429736048,0.0001642370771151036,0.00019526746473275125,0.00022804137552157044,0.00016277661779895425,0.00017823470989242196,0.0001368372468277812,0.00017805324750952423,0.00015065637126099318,9.794457582756877e-05,8.1696554843802e-05,0.00010287384793628007,0.00010036479943664744,0.000177631140104495,0.0001562672550790012,0.00011970478226430714,0.00010271404607919976,0.00015213334700092673,0.00017959251999855042,0.00013409204257186502,0.0001473986339988187,0.00016729586059227586,0.00012438616249710321,0.00010177060175919905,9.767220035428181e-05,7.070434367051348e-05,0.000111383807961829,0.000155575035023503,0.00016877661983016878,0.0001443654764443636,0.0001098994689527899,0.00011154607636854053,0.00014408992137759924,
mae,0.20488637685775757,0.10506150126457214,0.09447503089904785,0.08688811212778091,0.0831368938088417,0.07755939662456512,0.06953061372041702,0.06228070706129074,0.040889523923397064,0.03247220441699028,0.029452405869960785,0.03535090759396553,0.028534704819321632,0.024605488404631615,0.02800283394753933,0.028239011764526367,0.028101691976189613,0.02572844736278057,0.022426670417189598,0.020913923159241676,0.020661618560552597,0.025142474099993706,0.02317945286631584,0.02072129026055336,0.019957100972533226,0.016776876524090767,0.014597740024328232,0.013071534223854542,0.012533106841146946,0.018288493156433105,0.019219879060983658,0.016370678320527077,0.015412361361086369,0.014234528876841068,0.01377122849225998,0.01433406863361597,0.012379390187561512,0.014907808043062687,0.016481978818774223,0.015286531299352646,0.014383727684617043,0.01386177446693182,0.013413568958640099,0.011405556462705135,0.010313279926776886,0.009810271672904491,0.009526851586997509,0.009653453715145588,0.011934671550989151,0.013902273029088974,0.01335324626415968,0.013003101572394371,0.011628040112555027,0.012704416178166866,0.012559072114527225,0.01184901874512434,0.010348145850002766,0.010351833887398243,0.011126121506094933,0.012121476233005524,0.010406971909105778,0.009629344567656517,0.008711185306310654,0.007996339350938797,0.0075501371175050735,0.00796341523528099,0.009652111679315567,0.009845772758126259,0.010153071023523808,0.01094506960362196,0.01168821007013321,0.01040554791688919,0.010458008386194706,0.0088120736181736,0.01024435181170702,0.009635813534259796,0.007602288853377104,0.006882691290229559,0.007713576778769493,0.007567752618342638,0.010377811267971992,0.009820004925131798,0.00858286116272211,0.007768157869577408,0.00942283496260643,0.011010655201971531,0.009252343326807022,0.009385739453136921,0.010229233652353287,0.008918298408389091,0.0077427043579518795,0.0076528252102434635,0.006480916868895292,0.008168784901499748,0.01000188197940588,0.009908744134008884,0.00921359658241272,0.008296916261315346,0.008325858041644096,0.009661924093961716,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34227     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34228     
=================================================================
Total params: 68,455
Trainable params: 68,455
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 34,227
Trainable params: 34,227
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 34,228
Trainable params: 34,228
Non-trainable params: 0
_________________________________________________________________
