2021-06-26
loss,2.723644971847534,2.2114391326904297,2.203939914703369,2.2028281688690186,2.2054283618927,2.2040510177612305,2.202890396118164,2.204231023788452,2.203967809677124,2.204010248184204,2.204514265060425,2.204921245574951,2.2040393352508545,2.2048580646514893,2.2040610313415527,2.2039575576782227,2.2045376300811768,2.2039239406585693,2.1269707679748535,0.5051791667938232,0.21737828850746155,0.20418499410152435,0.13773870468139648,0.11253124475479126,0.0940147340297699,0.08512518554925919,0.08193685859441757,0.07176955044269562,0.07172209769487381,0.059730347245931625,0.05617784336209297,0.05695981904864311,0.04514133930206299,0.040711697190999985,0.0416066013276577,0.05397684499621391,0.04922103509306908,0.041253961622714996,0.04090498015284538,0.03755511716008186,0.03223863244056702,0.029854798689484596,0.037443190813064575,0.03294197469949722,0.029062069952487946,0.035645391792058945,0.03769048675894737,0.035138532519340515,0.040751323103904724,0.036401115357875824,0.03553229570388794,0.03573918715119362,0.03384069353342056,0.03219598904252052,0.03588009998202324,0.0306569654494524,0.03130820393562317,0.030780434608459473,0.03190835565328598,0.03158107027411461,0.023824084550142288,0.02990240417420864,0.029292099177837372,0.031189225614070892,0.034523025155067444,0.02989005297422409,0.030826617032289505,0.028612956404685974,0.027604684233665466,0.025185609236359596,0.029151039198040962,0.02841773070394993,0.02488095313310623,0.030828535556793213,0.03187175095081329,0.027850160375237465,0.022558389231562614,0.024867059662938118,0.031504902988672256,0.027387438341975212,0.024342117831110954,0.02212890237569809,0.026357846334576607,0.02955923229455948,0.026941249147057533,0.023499907925724983,0.023297592997550964,0.031019192188978195,0.028688544407486916,0.02705373801290989,0.024460678920149803,0.02863118425011635,0.024136874824762344,0.023893460631370544,0.027453456073999405,0.02695780247449875,0.02533937618136406,0.02632659673690796,0.028954794630408287,0.025298750028014183,
mse,1.9732095003128052,1.2364038228988647,1.2283592224121094,1.2272026538848877,1.2300376892089844,1.228527307510376,1.2272051572799683,1.2287081480026245,1.2284380197525024,1.228429913520813,1.2290334701538086,1.229444146156311,1.2284550666809082,1.2294265031814575,1.228520393371582,1.2284326553344727,1.2290750741958618,1.2283451557159424,1.1777069568634033,0.10630066692829132,0.0166610237210989,0.014989061281085014,0.005708475597202778,0.0036334365140646696,0.002576063387095928,0.0022771451622247696,0.0019054749282076955,0.0014877187786623836,0.0014439963269978762,0.0009956173598766327,0.0009057772695086896,0.0009095401037484407,0.000585180358029902,0.0004999467637389898,0.0005025600548833609,0.000799827859736979,0.0006747935549356043,0.0004947192501276731,0.0004716368275694549,0.00039708096301183105,0.0002914778597187251,0.0002698719035834074,0.0004125195846427232,0.00031053050770424306,0.00024116852728184313,0.00035018115886487067,0.00039734202437102795,0.0003388913464732468,0.0004901906359009445,0.000384162412956357,0.0003669234283734113,0.00036028670729137957,0.00031221818062476814,0.0003105759678874165,0.00036673538852483034,0.00026196337421424687,0.00027002760907635093,0.00027674759621731937,0.00029029525467194617,0.0002810138976201415,0.0001662776485318318,0.00024720755754970014,0.00024052684602793306,0.0002837716892827302,0.00033432114287279546,0.0002555514802224934,0.0002687984670046717,0.00022583357349503785,0.00021510479564312845,0.00017727876547724009,0.00024899226264096797,0.0002251381811220199,0.000176870686118491,0.000269972049864009,0.0002818912616930902,0.00021767598809674382,0.00014760250633116812,0.00017628978821448982,0.00027598574524745345,0.0002129060449078679,0.00016758650599513203,0.00014194913092069328,0.0001902982621686533,0.0002455895591992885,0.00019607989815995097,0.00015501683810725808,0.0001560041418997571,0.00027585518546402454,0.0002306425740243867,0.00019900983897969127,0.00016709275951143354,0.00023208066704683006,0.00015777563385199755,0.0001628585159778595,0.00021188726532272995,0.00020431153825484216,0.00017830876458901912,0.0001963887334568426,0.0002307881077285856,0.00018413389625493437,
mae,1.0660288333892822,0.6194252371788025,0.6003807187080383,0.5979282855987549,0.5977275967597961,0.5963394045829773,0.5951066017150879,0.5948992371559143,0.59433513879776,0.5936962366104126,0.593691885471344,0.5933915972709656,0.5926182270050049,0.5927370190620422,0.5922395586967468,0.5920788049697876,0.5923727750778198,0.5932419300079346,0.6631608009338379,0.20852649211883545,0.10088246315717697,0.08999467641115189,0.05775640904903412,0.04800380766391754,0.040220919996500015,0.035312581807374954,0.03466806560754776,0.02984098345041275,0.029733214527368546,0.024555588141083717,0.023789389058947563,0.02362918108701706,0.019190676510334015,0.01753212697803974,0.017772987484931946,0.022130781784653664,0.0197838693857193,0.016701621934771538,0.01720524951815605,0.016194548457860947,0.013766421936452389,0.012564110569655895,0.015887998044490814,0.013757108710706234,0.012341232039034367,0.014712555333971977,0.015895148739218712,0.0152744697406888,0.016588613390922546,0.014864333905279636,0.014918601140379906,0.014458895660936832,0.014452822506427765,0.013340581208467484,0.014332043938338757,0.013067185878753662,0.013202770613133907,0.012833037413656712,0.013258125633001328,0.01324236299842596,0.010091135278344154,0.012926534749567509,0.012632089667022228,0.01273472048342228,0.013095499016344547,0.012403198517858982,0.01265918742865324,0.01244506798684597,0.011705663055181503,0.01069959532469511,0.01173988077789545,0.012217042036354542,0.01040093693882227,0.012687410227954388,0.012219119817018509,0.011839261278510094,0.009571180678904057,0.010596531443297863,0.012962038628757,0.011669274419546127,0.010195969603955746,0.009432743303477764,0.011175215244293213,0.012145573273301125,0.011841481551527977,0.009931662119925022,0.009852645918726921,0.012432302348315716,0.011539522558450699,0.01130836270749569,0.010806419886648655,0.011588206514716148,0.01052896399050951,0.010230118408799171,0.011331289075314999,0.011320323683321476,0.010575886815786362,0.011080894619226456,0.011573204770684242,0.009906304068863392,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 210083    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 210084    
=================================================================
Total params: 420,167
Trainable params: 420,167
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 210,083
Trainable params: 210,083
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 210,084
Trainable params: 210,084
Non-trainable params: 0
_________________________________________________________________
