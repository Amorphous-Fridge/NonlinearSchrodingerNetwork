2021-06-26
loss,0.4589836001396179,0.24755404889583588,0.22591868042945862,0.19857020676136017,0.11527334153652191,0.06467993557453156,0.05063146725296974,0.04485613480210304,0.041563402861356735,0.038978856056928635,0.03759610652923584,0.035831429064273834,0.03423840180039406,0.033716585487127304,0.052632641047239304,0.035623203963041306,0.03315111994743347,0.05573585629463196,0.04821261391043663,0.04272323474287987,0.03582952916622162,0.03456798940896988,0.04156872257590294,0.04942339286208153,0.04764006659388542,0.042818643152713776,0.039479225873947144,0.03516475111246109,0.0313715934753418,0.027081593871116638,0.024682290852069855,0.0240839384496212,0.023914773017168045,0.03283875063061714,0.03972430154681206,0.02811787649989128,0.024094365537166595,0.025397609919309616,0.022020356729626656,0.021267762407660484,0.027054481208324432,0.031885500997304916,0.03315914049744606,0.03680146113038063,0.03629935905337334,0.033985234797000885,0.032132234424352646,0.030594265088438988,0.028976093977689743,0.027415575459599495,0.025700358673930168,0.02378125488758087,0.02229136787354946,0.022271785885095596,0.021331971511244774,0.021792078390717506,0.02326919138431549,0.029500393196940422,0.030888760462403297,0.030010472983121872,0.028170494362711906,0.030534543097019196,0.029182564467191696,0.035120245069265366,0.03183812275528908,0.029751144349575043,0.028459832072257996,0.0272829532623291,0.026411890983581543,0.02550756186246872,0.024404073134064674,0.02338833175599575,0.022536981850862503,0.02198769897222519,0.021499361842870712,0.02097088284790516,0.020513780415058136,0.019922232255339622,0.018916940316557884,0.017416121438145638,0.024536533281207085,0.03130107372999191,0.02819410152733326,0.02663341723382473,0.025462837889790535,0.024663085117936134,0.02390664629638195,0.023315981030464172,0.022573553025722504,0.02179058827459812,0.02116919308900833,0.020543169230222702,0.020072918385267258,0.01970580406486988,0.02379540167748928,0.031013362109661102,0.0293061975389719,0.025082485750317574,0.022612841799855232,0.02049020119011402,
mse,0.08020546287298203,0.020829584449529648,0.018352873623371124,0.01406094990670681,0.004054405726492405,0.0012395341182127595,0.0007464500376954675,0.0005829494912177324,0.0004997444339096546,0.0004385060165077448,0.0004043435328640044,0.0003701535752043128,0.0003460829029791057,0.00032916435156948864,0.0008625930640846491,0.0003941832110285759,0.0003384824958629906,0.0008677550358697772,0.0006371565395966172,0.0005170293152332306,0.0003779974940698594,0.0003523152263369411,0.000497662287671119,0.0007060321513563395,0.0006329278694465756,0.0005125200259499252,0.0004362684558145702,0.0003475891426205635,0.0002806532138492912,0.00021325927809812129,0.00017938643577508628,0.00017046135326381773,0.00016759436402935535,0.00032272006501443684,0.00046704744454473257,0.00024678136105649173,0.0001756015990395099,0.00020209567446727306,0.0001424825459253043,0.00013400021998677403,0.00022105708194430918,0.000298949918942526,0.0003315235662739724,0.0003856693219859153,0.0003680204099509865,0.0003171754360664636,0.0002834799524862319,0.00025801663286983967,0.00023369098198600113,0.00021100927551742643,0.00018628069665282965,0.00016264186706393957,0.00014378289051819593,0.0001460431085433811,0.00013221020344644785,0.00013944045349489897,0.00016638317902106792,0.0002577667182777077,0.0002720891498029232,0.0002620963496156037,0.0002306611422682181,0.0002612349344417453,0.0002473039785400033,0.0003496505378279835,0.00028633922920562327,0.00024937145644798875,0.0002278694009874016,0.00020951083570253104,0.00019667731248773634,0.0001837736926972866,0.0001664882875047624,0.000153551489347592,0.00014428359281737357,0.0001377567241434008,0.0001320717710768804,0.00012584189244080335,0.00012095458077965304,0.00011493886995594949,0.00010547618148848414,8.877213258529082e-05,0.00018381541303824633,0.0002762454969342798,0.0002229076490039006,0.00019748249906115234,0.0001815610594348982,0.00016906527162063867,0.00016005955694708973,0.00015077306306920946,0.0001411781122442335,0.0001315144618274644,0.00012475272524170578,0.00011748004908440635,0.00011250661918893456,0.00010897452739300206,0.00016385348862968385,0.00028032547561451793,0.00023881453671492636,0.00017855987243819982,0.00014462988474406302,0.00011774006998166442,
mae,0.20149698853492737,0.1113775223493576,0.1015559509396553,0.08438701927661896,0.04965498298406601,0.02774544432759285,0.021924974396824837,0.019169991835951805,0.017967235296964645,0.01675126887857914,0.01606500893831253,0.015404238365590572,0.014650187455117702,0.014472045004367828,0.022142231464385986,0.015014958567917347,0.014159547165036201,0.02426845394074917,0.021712737157940865,0.019167888909578323,0.015482824295759201,0.014508552849292755,0.01783672533929348,0.021203186362981796,0.02118206024169922,0.019320059567689896,0.017916807904839516,0.014712917618453503,0.0131455697119236,0.011541337706148624,0.010443087667226791,0.010120365768671036,0.010187814012169838,0.01378688495606184,0.016920294612646103,0.012007313780486584,0.010337370447814465,0.010710992850363255,0.009475715458393097,0.00908795278519392,0.011565059423446655,0.013662564568221569,0.014231139793992043,0.015757186338305473,0.016398398205637932,0.015365327708423138,0.01451628003269434,0.013662668876349926,0.012377782724797726,0.011387759819626808,0.010781589895486832,0.01016649603843689,0.009453567676246166,0.009386247955262661,0.009162302128970623,0.009257350116968155,0.00998891331255436,0.01210725586861372,0.01272665522992611,0.012669986113905907,0.012034798040986061,0.01368777733296156,0.012988368049263954,0.015421781688928604,0.013886502012610435,0.013029003515839577,0.01251278631389141,0.01198815368115902,0.011605702340602875,0.011413419619202614,0.010614410974085331,0.009878947399556637,0.009475707076489925,0.009252076037228107,0.009030698798596859,0.008837354369461536,0.008647291921079159,0.00849603209644556,0.008118530735373497,0.0074112326838076115,0.010500210337340832,0.013228021562099457,0.012152459472417831,0.011554202996194363,0.011083077639341354,0.010797441937029362,0.010457228869199753,0.01009153202176094,0.009747788310050964,0.009351912885904312,0.008973565883934498,0.008627213537693024,0.008384925313293934,0.008266748860478401,0.01016175001859665,0.012928563170135021,0.012065034359693527,0.010123626329004765,0.009335058741271496,0.008645858615636826,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9259      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9260      
=================================================================
Total params: 18,519
Trainable params: 18,519
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 9,259
Trainable params: 9,259
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 9,260
Trainable params: 9,260
Non-trainable params: 0
_________________________________________________________________
