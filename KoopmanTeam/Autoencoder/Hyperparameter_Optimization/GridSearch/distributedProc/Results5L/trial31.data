2021-06-26
loss,0.6503824591636658,0.2353978008031845,0.2253718376159668,0.1910088211297989,0.16414481401443481,0.09018649160861969,0.08346778899431229,0.07117187231779099,0.060005903244018555,0.053602710366249084,0.0630272924900055,0.05972665175795555,0.08913052827119827,0.07579728215932846,0.060497477650642395,0.048854850232601166,0.05506115406751633,0.0626002848148346,0.0658298134803772,0.058371320366859436,0.04215758666396141,0.0368998758494854,0.04542536661028862,0.03852551430463791,0.05746511369943619,0.05376436188817024,0.04522122070193291,0.04799899458885193,0.04659058526158333,0.03838275745511055,0.03363160789012909,0.030536524951457977,0.02995586208999157,0.030326679348945618,0.038160983473062515,0.047896482050418854,0.03945222124457359,0.03747003152966499,0.04163546860218048,0.03586303070187569,0.03974924981594086,0.03069642372429371,0.02065971866250038,0.020564794540405273,0.020430993288755417,0.02034066990017891,0.020124759525060654,0.020235782489180565,0.019938385114073753,0.019802767783403397,0.02883879840373993,0.027479438111186028,0.027215948328375816,0.0330488458275795,0.036670997738838196,0.031781092286109924,0.03045562654733658,0.02939685620367527,0.030800804495811462,0.031373728066682816,0.028910350054502487,0.025256352499127388,0.024695565924048424,0.029520858079195023,0.03293714299798012,0.027784746140241623,0.02457817643880844,0.02815672568976879,0.029785189777612686,0.02655150182545185,0.029127070680260658,0.029017481952905655,0.0253136083483696,0.021593382582068443,0.02398480847477913,0.023490695282816887,0.022167988121509552,0.0212116576731205,0.020178349688649178,0.019410185515880585,0.019038129597902298,0.017287056893110275,0.01971372403204441,0.028483856469392776,0.030275531113147736,0.027419989928603172,0.0249861478805542,0.025851521641016006,0.024711880832910538,0.02687326818704605,0.024531012400984764,0.021387919783592224,0.01935366541147232,0.018218521028757095,0.017801558598876,0.01584329642355442,0.01745259389281273,0.024771247059106827,0.027026714757084846,0.024834711104631424,
mse,0.19227710366249084,0.019701333716511726,0.018371962010860443,0.01250021904706955,0.008236370980739594,0.002453028690069914,0.0021356346551328897,0.0014738604659214616,0.0010328951757401228,0.0008272225968539715,0.0011774837039411068,0.0010570911690592766,0.0023109468165785074,0.0016551229637116194,0.0010745194740593433,0.0007118672947399318,0.0008691969560459256,0.0011597914854064584,0.0012387948809191585,0.0009796456433832645,0.0005173605168238282,0.0003939281450584531,0.0005940991686657071,0.0004314668185543269,0.0009349073516204953,0.0008090921328403056,0.0005961841088719666,0.0006485317717306316,0.0006015439867042005,0.00041433595470152795,0.00031779875280335546,0.0002588668139651418,0.00026330436230637133,0.0002675308787729591,0.00043763217399828136,0.0006508087390102446,0.0004558752989396453,0.00039544832543469965,0.0004865916562266648,0.0003706528223119676,0.00044384514330886304,0.00027777350624091923,0.00012469812645576894,0.00012201492791064084,0.00011939971591345966,0.00011783497757278383,0.00011566816829144955,0.00011572341463761404,0.00011391538282623515,0.00011200601875316352,0.00023614540987182409,0.00021132134133949876,0.00021162979828659445,0.0003139204054605216,0.00037882252945564687,0.0002824107650667429,0.00026285849162377417,0.00024519345606677234,0.00026959829847328365,0.00028246594592928886,0.00023936631623655558,0.0001824367354856804,0.00018681892834138125,0.00024999500601552427,0.0003025455225724727,0.00021276535699144006,0.00017306426889263093,0.00023291500110644847,0.00024876833776943386,0.00020663096802309155,0.0002360550279263407,0.0002331421128474176,0.00018120119057130069,0.0001394214341416955,0.0001624656142666936,0.00015396215894725174,0.00013986538397148252,0.00012668427370954305,0.00011532809730852023,0.0001114646001951769,0.00010944533278234303,8.848235302139074e-05,0.00011644984624581411,0.00023476664500776678,0.0002568654017522931,0.00021246513642836362,0.000180538569111377,0.00019483774667605758,0.00017216768173966557,0.00019970329594798386,0.00016959106142167002,0.000129764957819134,0.00010757370910141617,9.708341531222686e-05,9.352175402455032e-05,7.786529749864712e-05,9.4206327048596e-05,0.0001822259509935975,0.00020159769337624311,0.0001735696423565969,
mae,0.278616338968277,0.10302779823541641,0.09978920221328735,0.082162044942379,0.07200207561254501,0.03877920284867287,0.035876788198947906,0.0308329239487648,0.026290960609912872,0.023404181003570557,0.026539580896496773,0.025618402287364006,0.03939713537693024,0.033331435173749924,0.026109855622053146,0.02088269777595997,0.02325141243636608,0.02698870748281479,0.029283665120601654,0.02597724460065365,0.01781996339559555,0.015623966231942177,0.01975822262465954,0.01653977483510971,0.025319429114460945,0.023897914215922356,0.019554516300559044,0.021062705665826797,0.020783133804798126,0.01636640727519989,0.0144851915538311,0.013260040432214737,0.012821720913052559,0.012743561528623104,0.016333268955349922,0.02101326733827591,0.017243273556232452,0.01625354401767254,0.0181884728372097,0.015431045554578304,0.017479674890637398,0.013231318444013596,0.008882187306880951,0.008933387696743011,0.008933773264288902,0.008871825411915779,0.008622287772595882,0.00883033499121666,0.008695068769156933,0.008637603372335434,0.012077191844582558,0.01152151357382536,0.011500955559313297,0.014113640412688255,0.015811530873179436,0.013708161190152168,0.013120237737894058,0.01243559643626213,0.013238465413451195,0.013327918015420437,0.012324551120400429,0.010540158487856388,0.010576026514172554,0.012695662677288055,0.014317958615720272,0.011569763533771038,0.010241776704788208,0.012219934724271297,0.012937823310494423,0.011488097719848156,0.012794805690646172,0.012832021340727806,0.010708843357861042,0.009000680409371853,0.009911680594086647,0.009847802110016346,0.009548489935696125,0.009193295612931252,0.008781966753304005,0.008388590067625046,0.008156592026352882,0.007435558829456568,0.00846452172845602,0.012282383628189564,0.013345545157790184,0.01195734366774559,0.010875544510781765,0.011165124364197254,0.010546122677624226,0.011824092827737331,0.010446084663271904,0.009136084467172623,0.00820455327630043,0.007632544729858637,0.0075772725977003574,0.006744127720594406,0.007416454143822193,0.010760732926428318,0.011930390261113644,0.010897379368543625,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25771     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25772     
=================================================================
Total params: 51,543
Trainable params: 51,543
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 25,771
Trainable params: 25,771
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 25,772
Trainable params: 25,772
Non-trainable params: 0
_________________________________________________________________
