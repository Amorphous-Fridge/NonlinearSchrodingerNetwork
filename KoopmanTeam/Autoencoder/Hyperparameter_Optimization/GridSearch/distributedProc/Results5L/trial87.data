2021-06-26
loss,2.3680124282836914,2.2287943363189697,2.2222282886505127,2.221102714538574,2.221461772918701,2.221079111099243,2.2210757732391357,2.2220842838287354,2.2212815284729004,2.2204506397247314,2.2202773094177246,2.2193329334259033,2.2201523780822754,2.220172166824341,2.218264102935791,2.217589855194092,2.2355167865753174,2.2300617694854736,2.2219483852386475,2.2209508419036865,2.2205753326416016,2.2215077877044678,2.2204620838165283,2.219055414199829,2.2189784049987793,2.2174887657165527,2.215886116027832,2.2110135555267334,2.209575891494751,2.2104547023773193,2.204064130783081,2.2037105560302734,2.201094627380371,2.2038567066192627,2.1995725631713867,2.200310707092285,2.2010011672973633,2.2006218433380127,2.2000913619995117,2.2004058361053467,2.200655937194824,2.201117753982544,2.2000625133514404,2.2002439498901367,2.200222969055176,2.200551748275757,2.200568199157715,2.201228618621826,2.1996254920959473,2.2009501457214355,2.200312614440918,2.2009193897247314,2.2004406452178955,2.201643705368042,2.1997811794281006,2.201230764389038,2.200869083404541,2.2374982833862305,2.3149259090423584,0.6118250489234924,0.35304224491119385,0.33671608567237854,0.329500287771225,0.32026782631874084,0.313007116317749,0.3060533404350281,0.29904797673225403,0.3029736280441284,0.2541406750679016,0.19637590646743774,0.17275775969028473,0.1531151682138443,0.12440165877342224,0.09729497879743576,0.08395513892173767,0.07734398543834686,0.06457977741956711,0.058678340166807175,0.06262901425361633,0.056270696222782135,0.0586654432117939,0.051909189671278,0.05524822324514389,0.04962153360247612,0.040946438908576965,0.045909009873867035,0.03991715982556343,0.0511656291782856,0.031527020037174225,0.039449650794267654,0.04167550057172775,0.04226100817322731,0.04210326075553894,0.03612488880753517,0.041796229779720306,0.034887004643678665,0.04483386129140854,0.03763474151492119,0.03890438377857208,0.041270267218351364,
mse,1.4359300136566162,1.2550938129425049,1.2481067180633545,1.2468385696411133,1.2472364902496338,1.246770977973938,1.2467817068099976,1.24796724319458,1.2469944953918457,1.2461535930633545,1.2458879947662354,1.2448577880859375,1.2458596229553223,1.245807409286499,1.2437198162078857,1.2429924011230469,1.2635629177093506,1.256720781326294,1.247717022895813,1.2466319799423218,1.2462425231933594,1.247310996055603,1.2461358308792114,1.244603157043457,1.244559645652771,1.2429537773132324,1.2412056922912598,1.2359247207641602,1.2344950437545776,1.2354326248168945,1.2285202741622925,1.2280611991882324,1.2250611782073975,1.227932095527649,1.223219633102417,1.2240785360336304,1.2248735427856445,1.2243525981903076,1.2238011360168457,1.2240841388702393,1.224442720413208,1.2249301671981812,1.2238000631332397,1.2239830493927002,1.2239865064620972,1.2242913246154785,1.2243403196334839,1.2250291109085083,1.2233343124389648,1.2247281074523926,1.224019169807434,1.224717140197754,1.224135160446167,1.225541114807129,1.2234933376312256,1.2250624895095825,1.2247169017791748,1.2677757740020752,1.359190821647644,0.14722973108291626,0.03740142285823822,0.034417230635881424,0.03259604424238205,0.03082866035401821,0.02959800884127617,0.028558410704135895,0.027435598894953728,0.02784215472638607,0.020391739904880524,0.012934600003063679,0.009953582659363747,0.0073615266010165215,0.004651213996112347,0.002801391528919339,0.0021287337876856327,0.0018623281503096223,0.0012350021861493587,0.0010094098979607224,0.0011630493681877851,0.0009294156916439533,0.000989247695542872,0.0008309746044687927,0.0008928143070079386,0.0007081694202497602,0.0004976654308848083,0.00062713393708691,0.0004729646898340434,0.000798409862909466,0.0003075483546126634,0.00047494680620729923,0.0004955761833116412,0.0005338425980880857,0.0005028214072808623,0.0003906860074494034,0.0005395936314016581,0.00036804541014134884,0.0005907820886932313,0.0004118327342439443,0.0004377463483251631,0.00048564589815214276,
mae,0.8221639394760132,0.6745810508728027,0.6533685326576233,0.6533147692680359,0.6536695957183838,0.6531308889389038,0.6519549489021301,0.6544016003608704,0.6521254181861877,0.6531338691711426,0.6536009311676025,0.6525810360908508,0.6515224575996399,0.6531184315681458,0.6478399634361267,0.6463986039161682,0.6921377778053284,0.6770310401916504,0.6577718257904053,0.654833197593689,0.6543682813644409,0.6539685130119324,0.6527297496795654,0.650434672832489,0.6468156576156616,0.6442919373512268,0.6398871541023254,0.627846360206604,0.6208620071411133,0.6197983026504517,0.5966870784759521,0.5906586647033691,0.57735276222229,0.5867102146148682,0.5610535144805908,0.5647118091583252,0.5669106841087341,0.5602848529815674,0.5666362047195435,0.5660578012466431,0.5629183053970337,0.5669723749160767,0.5673419237136841,0.5589649677276611,0.564684271812439,0.5646646022796631,0.5636704564094543,0.5734149813652039,0.5595008134841919,0.566972017288208,0.5607535243034363,0.5632362961769104,0.5652220845222473,0.5735471844673157,0.5585016012191772,0.5585149526596069,0.5638002753257751,0.6191232204437256,0.7786927819252014,0.25455614924430847,0.1555173397064209,0.145293727517128,0.14079947769641876,0.13675735890865326,0.13362078368663788,0.1308932900428772,0.12828822433948517,0.1290571689605713,0.10918430238962173,0.08489474654197693,0.07457070052623749,0.06570123136043549,0.052568282932043076,0.04114837199449539,0.035590220242738724,0.03252003341913223,0.027364568784832954,0.024623531848192215,0.02638947032392025,0.023598944768309593,0.024640195071697235,0.02211267314851284,0.02277074009180069,0.021294014528393745,0.017070794478058815,0.019361291080713272,0.01660492643713951,0.021291101351380348,0.013320347294211388,0.01664123311638832,0.017733998596668243,0.01776275597512722,0.017793437466025352,0.015179294161498547,0.017331989482045174,0.014553197659552097,0.01895299181342125,0.01598467491567135,0.01640215888619423,0.01727747730910778,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 136083    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 136084    
=================================================================
Total params: 272,167
Trainable params: 272,167
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 136,083
Trainable params: 136,083
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 136,084
Trainable params: 136,084
Non-trainable params: 0
_________________________________________________________________
