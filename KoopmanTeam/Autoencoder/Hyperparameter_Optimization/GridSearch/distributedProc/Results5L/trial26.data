2021-06-26
loss,0.3706406354904175,0.21241898834705353,0.11134406924247742,0.07500956207513809,0.05809246376156807,0.052726611495018005,0.04814927652478218,0.04481147229671478,0.04221515357494354,0.04035201668739319,0.03860848397016525,0.037364695221185684,0.036127444356679916,0.03461948782205582,0.03442179411649704,0.03275930508971214,0.03185805305838585,0.032091427594423294,0.03099311888217926,0.030188867822289467,0.02917090617120266,0.029365750029683113,0.028813747689127922,0.028170865029096603,0.02797054313123226,0.027431251481175423,0.027089333161711693,0.02667120471596718,0.026480820029973984,0.02615455910563469,0.025688553228974342,0.0255616195499897,0.025468695908784866,0.02487090788781643,0.024940915405750275,0.024506835266947746,0.024668503552675247,0.02405630610883236,0.023864032700657845,0.02399648353457451,0.023561764508485794,0.02349003776907921,0.023221638053655624,0.02288394421339035,0.024473436176776886,0.03534894436597824,0.025299072265625,0.022719401866197586,0.022279128432273865,0.022177021950483322,0.02195136621594429,0.02181931957602501,0.02162420190870762,0.02122541517019272,0.021533777937293053,0.021286845207214355,0.02107817679643631,0.02118109166622162,0.020791860297322273,0.02072823978960514,0.020739473402500153,0.020682796835899353,0.02044404298067093,0.02044355310499668,0.020450938493013382,0.01990596391260624,0.020355699583888054,0.019846254959702492,0.020018665120005608,0.025072598829865456,0.03250305727124214,0.03228447586297989,0.03365281596779823,0.031082330271601677,0.027364442124962807,0.024800311774015427,0.023618629202246666,0.02271907962858677,0.022006625309586525,0.02197991870343685,0.022113433107733727,0.02171567641198635,0.02121470496058464,0.020495576784014702,0.019865024834871292,0.019350312650203705,0.019299093633890152,0.01879330724477768,0.018867718055844307,0.018398188054561615,0.01839246228337288,0.01841944269835949,0.017809638753533363,0.017941681668162346,0.01773061417043209,0.017632106319069862,0.01764415204524994,0.017408806830644608,0.017608240246772766,0.017307620495557785,
mse,0.04752366989850998,0.015098866075277328,0.0039261579513549805,0.00175031169783324,0.0010884796502068639,0.0008878974476829171,0.000736778776627034,0.0006286776624619961,0.0005496768280863762,0.0004952225717715919,0.00044938898645341396,0.0004180277173873037,0.00039311673026531935,0.0003629733982961625,0.0003525455540511757,0.00032247122726403177,0.00030540459556505084,0.0003078387235291302,0.00028591693262569606,0.00027350703021511436,0.0002542504807934165,0.0002578666608314961,0.0002493854844942689,0.00023588398471474648,0.00023335765581578016,0.00022369256475940347,0.00021848894539289176,0.0002126874605892226,0.00020860273798462003,0.00020295908325351775,0.0001975598861463368,0.00019562923989724368,0.0001918629859574139,0.00018221211212221533,0.00018497703422326595,0.00017898112128023058,0.00017972596106119454,0.0001700224238447845,0.00016816526476759464,0.00016886972298379987,0.00016284942103084177,0.00016223419515881687,0.0001579166273586452,0.00015388330211862922,0.00019069477275479585,0.0003770546754822135,0.00019786485063377768,0.0001528232969576493,0.00014607423509005457,0.00014454883057624102,0.00014194754476193339,0.00013860785111319274,0.00013671447231899947,0.00013356479757931083,0.00013540372310671955,0.00013264562585391104,0.00012990784307476133,0.00013109011342749,0.00012568316014949232,0.0001243260339833796,0.00012529888772405684,0.00012418345431797206,0.00012154348223702982,0.00012156221055192873,0.00012167503882665187,0.00011793692829087377,0.00012032294034725055,0.00011444138363003731,0.00011877498764079064,0.00019907692330889404,0.0003050579398404807,0.0003035066765733063,0.00031861383467912674,0.00028082297649234533,0.00021014762751292437,0.00017457902140449733,0.00016017298912629485,0.00014926808944437653,0.00014031564933247864,0.00014111195923760533,0.0001416136947227642,0.000136647344334051,0.00013071336434222758,0.00012143531785113737,0.000115050861495547,0.00010853543062694371,0.00010811341780936345,0.00010249311162624508,0.00010357846622355282,9.833259537117556e-05,9.862386650638655e-05,9.870322537608445e-05,9.276263153878972e-05,9.343100100522861e-05,9.13789845071733e-05,9.024386963574216e-05,9.038769348990172e-05,8.831496234051883e-05,9.012153168441728e-05,8.702914055902511e-05,
mae,0.16021671891212463,0.08650045096874237,0.047451578080654144,0.03191138803958893,0.024803632870316505,0.02253073640167713,0.020655682310461998,0.019214197993278503,0.018122153356671333,0.017332283779978752,0.01660871133208275,0.016018113121390343,0.015572551637887955,0.014778439886868,0.014886736869812012,0.014086023904383183,0.01369776576757431,0.013872588984668255,0.013384287245571613,0.013083897531032562,0.012647781521081924,0.012743678875267506,0.012479791417717934,0.012142429128289223,0.012008853256702423,0.01178194023668766,0.011732267215847969,0.011557905934751034,0.011400415562093258,0.011381339281797409,0.011088665574789047,0.011024922132492065,0.011027422733604908,0.010704334825277328,0.010653567500412464,0.010583923198282719,0.010705871507525444,0.010403703898191452,0.010264208540320396,0.010406102985143661,0.010231651365756989,0.01014410238713026,0.009996290318667889,0.009794820100069046,0.010634814389050007,0.015092287212610245,0.010893136262893677,0.00981032382696867,0.009597396478056908,0.009520011954009533,0.00948572251945734,0.009337546303868294,0.009278964251279831,0.00910735223442316,0.009309041313827038,0.00912835169583559,0.009094019420444965,0.009199094027280807,0.008883107453584671,0.00889610219746828,0.008890652097761631,0.00894195307046175,0.008816384710371494,0.008771097287535667,0.008789238519966602,0.008549949154257774,0.008820516988635063,0.008557537570595741,0.008669579401612282,0.010843890719115734,0.013674730435013771,0.01354056317359209,0.014506345614790916,0.012996708042919636,0.011911753565073013,0.010847189463675022,0.010274129919707775,0.009844271466135979,0.009533662348985672,0.009455305524170399,0.00952355656772852,0.009369811974465847,0.009253707714378834,0.008949141018092632,0.008625243790447712,0.008469811640679836,0.008423171937465668,0.008213662542402744,0.008200905285775661,0.008041794411838055,0.007983645424246788,0.007990148849785328,0.007757636718451977,0.007693697698414326,0.007545312866568565,0.007612317334860563,0.007613924331963062,0.0075151813216507435,0.007642040029168129,0.007374480366706848,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8811      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8812      
=================================================================
Total params: 17,623
Trainable params: 17,623
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 8,811
Trainable params: 8,811
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 8,812
Trainable params: 8,812
Non-trainable params: 0
_________________________________________________________________
