2021-06-26
loss,2.8148653507232666,0.49341881275177,0.3636263310909271,0.35082507133483887,0.36094528436660767,0.34272101521492004,0.2519667446613312,0.22061842679977417,0.21705234050750732,0.1985161453485489,0.1920871138572693,0.17796021699905396,0.1762481927871704,0.17154884338378906,0.16287857294082642,0.16023515164852142,0.158950537443161,0.15497605502605438,0.17639905214309692,0.1470915675163269,0.1275925487279892,0.1227763444185257,0.12030103802680969,0.11309193819761276,0.08436404913663864,0.09463487565517426,0.08640602231025696,0.09212370961904526,0.08150233328342438,0.07959423214197159,0.07038155943155289,0.07061173766851425,0.060610298067331314,0.053316760808229446,0.049789752811193466,0.05989423766732216,0.04957827553153038,0.05789961293339729,0.051198773086071014,0.051734890788793564,0.052563343197107315,0.05177915096282959,0.05230816826224327,0.04836355149745941,0.041834257543087006,0.04794638603925705,0.0484791025519371,0.04101775214076042,0.037186149507761,0.036063555628061295,0.04193316772580147,0.03795362636446953,0.040585268288850784,0.040412869304418564,0.044810909777879715,0.0414678156375885,0.039153940975666046,0.0404343456029892,0.04071829840540886,0.036600399762392044,0.035841409116983414,0.03361419215798378,0.037478722631931305,0.037791162729263306,0.03259410336613655,0.033934012055397034,0.0374743789434433,0.035045843571424484,0.03427112475037575,0.03209540992975235,0.03181583061814308,0.03430764749646187,0.040347203612327576,0.03428993001580238,0.03569618985056877,0.03183300420641899,0.030943291261792183,0.035109102725982666,0.038458142429590225,0.032482393085956573,0.031404126435518265,0.0380718819797039,0.0395020917057991,0.030802099034190178,0.03279078006744385,0.0333869494497776,0.03476635366678238,0.03122197464108467,0.03216318413615227,0.030699830502271652,0.032078035175800323,0.03280416503548622,0.03167380020022392,0.030994834378361702,0.027764858677983284,0.03838518634438515,0.033936165273189545,0.030405648052692413,0.031212471425533295,0.02604515291750431,
mse,2.3226985931396484,0.07693851739168167,0.0393371544778347,0.03718657046556473,0.03935867175459862,0.03734147176146507,0.020232276991009712,0.016352331265807152,0.01542158517986536,0.013054536655545235,0.012188559398055077,0.010792115703225136,0.010499277152121067,0.009919298812747002,0.009186927229166031,0.008828665129840374,0.008683891035616398,0.008202139288187027,0.009826529771089554,0.006512252613902092,0.004847247619181871,0.004548743367195129,0.0042122541926801205,0.0036728032864630222,0.0020365023519843817,0.0025947235990315676,0.002114582806825638,0.0024084672331809998,0.0019045504741370678,0.001778364647179842,0.0013913973234593868,0.0014112764038145542,0.001049961312673986,0.0008034337079152465,0.0007442621281370521,0.0010194112546741962,0.000688866653945297,0.0009497443097643554,0.0007366774952970445,0.000750019564293325,0.0007871424313634634,0.0007603564881719649,0.0007662592688575387,0.0006532231927849352,0.0004905686364509165,0.000631049508228898,0.0006469046929851174,0.0004639258258976042,0.0003783447318710387,0.0003731854958459735,0.00047625930164940655,0.00040157162584364414,0.00046660529915243387,0.0004519742215052247,0.0005528173060156405,0.00047280456055887043,0.00042856697109527886,0.00045975190005265176,0.0004717323463410139,0.00037484386120922863,0.00036440425901673734,0.0003226253029424697,0.0003982809139415622,0.0003826408355962485,0.00029823524528183043,0.0003217621415387839,0.00039732418372295797,0.0003444077738095075,0.0003229167778044939,0.0002954145602416247,0.0003024176985491067,0.0003297851944807917,0.00045309975394047797,0.0003309227467980236,0.0003576946328394115,0.00028646003920584917,0.00028283873689360917,0.0003557763993740082,0.00040975131560117006,0.000295554957119748,0.0002863794506993145,0.0004153353802394122,0.0004232425126247108,0.0002743236836977303,0.0003057591675315052,0.0003136493032798171,0.0003323458950035274,0.0002783156814984977,0.0002925223088823259,0.00026752683334052563,0.0002850272285286337,0.00029973412165418267,0.00028877679142169654,0.0002643930783960968,0.00022554317547474056,0.0004017671453766525,0.0003159487678203732,0.00026193418307229877,0.0002678299497347325,0.00019553329912014306,
mae,1.1297943592071533,0.21219348907470703,0.1604723334312439,0.1559106707572937,0.15726374089717865,0.14916931092739105,0.10970128327608109,0.09505261480808258,0.09401298314332962,0.08533565700054169,0.08275029063224792,0.07715942710638046,0.07571706175804138,0.07362077385187149,0.07013202458620071,0.06880056113004684,0.06821361184120178,0.06666911393404007,0.07526038587093353,0.06246265396475792,0.05345432460308075,0.052263084799051285,0.05091019719839096,0.048176538199186325,0.0358722098171711,0.03959818184375763,0.036383431404829025,0.03914554789662361,0.03485902398824692,0.03490196168422699,0.029535576701164246,0.029077379032969475,0.02562449872493744,0.02272910811007023,0.020675063133239746,0.02503262273967266,0.02072421833872795,0.024373872205615044,0.021171022206544876,0.02088048681616783,0.022412702441215515,0.022263605147600174,0.021957598626613617,0.020819909870624542,0.017641855403780937,0.020090611651539803,0.02075970359146595,0.01736990176141262,0.015285435132682323,0.015039381571114063,0.018143106251955032,0.01604522578418255,0.017188386991620064,0.017206871882081032,0.019092721864581108,0.01761362887918949,0.016641730442643166,0.01708001084625721,0.017704416066408157,0.015761462971568108,0.015125629492104053,0.014091091230511665,0.01601676270365715,0.01676342636346817,0.014387533999979496,0.014378436841070652,0.015869159251451492,0.014894656836986542,0.014720604754984379,0.013541204854846,0.013472765684127808,0.014462517574429512,0.01725047081708908,0.01453393418341875,0.015093795023858547,0.013106711208820343,0.013487548567354679,0.014879033900797367,0.016129719093441963,0.013554097153246403,0.013207793235778809,0.01634487695991993,0.016966955736279488,0.013115567155182362,0.014020473696291447,0.014140906743705273,0.014792353846132755,0.01334184966981411,0.01338461134582758,0.013150773011147976,0.01337341871112585,0.013790981844067574,0.013502213172614574,0.013280564919114113,0.011894584633409977,0.016359608620405197,0.014031064696609974,0.012933127582073212,0.013114994391798973,0.010907220654189587,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 313155    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 313156    
=================================================================
Total params: 626,311
Trainable params: 626,311
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 313,155
Trainable params: 313,155
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 313,156
Trainable params: 313,156
Non-trainable params: 0
_________________________________________________________________
