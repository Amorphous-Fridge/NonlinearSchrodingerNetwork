2021-06-26
loss,2.359466791152954,2.222285270690918,2.2218236923217773,2.2220184803009033,2.2211968898773193,2.220883846282959,2.227428436279297,2.214290142059326,2.211376905441284,2.204644203186035,2.203270435333252,2.1930902004241943,0.8623678684234619,0.24786479771137238,0.24694553017616272,0.20926696062088013,0.1862034648656845,0.17039762437343597,0.13737669587135315,0.10945108532905579,0.08768673986196518,0.08468051254749298,0.09193353354930878,0.0672200545668602,0.06558486819267273,0.06969713419675827,0.05948623642325401,0.07060778886079788,0.059434954077005386,0.04550864174962044,0.058644913136959076,0.04592857509851456,0.03975681588053703,0.0441012866795063,0.04847883805632591,0.03758403658866882,0.0369751900434494,0.031279586255550385,0.03257466107606888,0.03868158161640167,0.03592979162931442,0.042636092752218246,0.04192619025707245,0.036453019827604294,0.03163658082485199,0.02817211113870144,0.034203626215457916,0.028936676681041718,0.0333973728120327,0.037317484617233276,0.03298602253198624,0.030667565762996674,0.03200355917215347,0.028187014162540436,0.02721123769879341,0.026606176048517227,0.031919196248054504,0.0291998740285635,0.03132862597703934,0.029924586415290833,0.029897337779402733,0.03172818571329117,0.029726542532444,0.026927616447210312,0.02388937957584858,0.026370400562882423,0.024022893980145454,0.0268396083265543,0.0277565810829401,0.028297679498791695,0.027016375213861465,0.023754136636853218,0.026234524324536324,0.029166828840970993,0.02735844999551773,0.028148209676146507,0.022721871733665466,0.0229953620582819,0.02496500313282013,0.02505217120051384,0.024149028584361076,0.023374300450086594,0.021748797968029976,0.027009429410099983,0.025557920336723328,0.025301041081547737,0.02180725894868374,0.024712126702070236,0.021645931527018547,0.0229409858584404,0.02176838554441929,0.0239003524184227,0.026143813505768776,0.026454703882336617,0.02215615287423134,0.021182052791118622,0.022128166630864143,0.022600533440709114,0.02307460829615593,0.020390747115015984,
mse,1.4259893894195557,1.248083233833313,1.2476511001586914,1.2478015422821045,1.246863603591919,1.2465766668319702,1.2536946535110474,1.2393040657043457,1.2364501953125,1.229153037071228,1.2275506258010864,1.2166759967803955,0.2866854667663574,0.02039167657494545,0.020233288407325745,0.015410985797643661,0.012458894401788712,0.009323731996119022,0.005803931970149279,0.003722215536981821,0.0024213395081460476,0.0022524124942719936,0.002528998302295804,0.0013093159068375826,0.0012328127631917596,0.001443461631424725,0.0010251507628709078,0.001429015421308577,0.0009753280319273472,0.0005877248477190733,0.0009995168074965477,0.0005984095041640103,0.00045204118941910565,0.0005611784872598946,0.0006590831326320767,0.00041997269727289677,0.0003824226150754839,0.00028559277416206896,0.0003270376182626933,0.00043114341679029167,0.00036317631020210683,0.0005158550920896232,0.0004882466746494174,0.0003736289218068123,0.00028154169558547437,0.0002331795112695545,0.00032650536741130054,0.0002446928119752556,0.0003280620730947703,0.0003826458123512566,0.0003082403272856027,0.0002719717740546912,0.0002852347388397902,0.00022235421056393534,0.00021218702022451907,0.00020553583453875035,0.0002870173193514347,0.0002412030880805105,0.00027247017715126276,0.00025315163657069206,0.00025744206504896283,0.0002785188262350857,0.0002448243321850896,0.000197947199922055,0.00017140615091193467,0.00019822607282549143,0.00016852919361554086,0.00020467181457206607,0.0002132332301698625,0.00022416697174776345,0.0002028449234785512,0.0001601636759005487,0.00019475205044727772,0.00023632844386156648,0.00020644972391892225,0.00021931393712293357,0.00014924394781701267,0.0001509680732851848,0.00017555816157255322,0.00017435311747249216,0.00016662562848068774,0.000153927510837093,0.00013884520740248263,0.00021247776749078184,0.00018221254867967218,0.00018033134983852506,0.0001380478497594595,0.00017217652930412441,0.00013460262562148273,0.00014850342995487154,0.00013874629803467542,0.0001597494847374037,0.00019237131346017122,0.00019292773504275829,0.00013975737965665758,0.00012849047197960317,0.0001387326919939369,0.00014705053763464093,0.00014867704885546118,0.00012169676483608782,
mae,0.8222163319587708,0.6569019556045532,0.6548119187355042,0.6546777486801147,0.6545037627220154,0.6539027690887451,0.6679680347442627,0.6250766515731812,0.6255364418029785,0.5983800888061523,0.5961114764213562,0.6052878499031067,0.3659857213497162,0.10602429509162903,0.10547777265310287,0.09134398400783539,0.08160562813282013,0.07306162267923355,0.05805669724941254,0.046359833329916,0.03723162040114403,0.035785917192697525,0.03924066200852394,0.0286046601831913,0.027828684076666832,0.02947389893233776,0.024797752499580383,0.03073577955365181,0.024701716378331184,0.01880631037056446,0.02419498935341835,0.018727784976363182,0.017003970220685005,0.018333032727241516,0.020724106580018997,0.015554200857877731,0.0160916056483984,0.01347821019589901,0.013887226581573486,0.01642441563308239,0.015283452346920967,0.01824845001101494,0.017500808462500572,0.015189395286142826,0.013645933009684086,0.01196163147687912,0.014345395378768444,0.012343614362180233,0.014139865525066853,0.016041092574596405,0.013880137354135513,0.013185334391891956,0.013073218986392021,0.011935177259147167,0.011579529382288456,0.011152347549796104,0.013599293306469917,0.012604224495589733,0.013035216368734837,0.0129059087485075,0.01260546687990427,0.013628409244120121,0.013014126569032669,0.011120736598968506,0.010164854116737843,0.011364441365003586,0.010239804163575172,0.011346107348799706,0.012001939117908478,0.011749752797186375,0.011696018278598785,0.010110832750797272,0.011050567962229252,0.012316621840000153,0.011703554540872574,0.011939405463635921,0.009572288021445274,0.009742578491568565,0.010515596717596054,0.010451571084558964,0.010275550186634064,0.010065295733511448,0.009206089191138744,0.01154102198779583,0.010922573506832123,0.010692805051803589,0.009297582320868969,0.01017114520072937,0.00919756293296814,0.009909036569297314,0.009164436720311642,0.009867246262729168,0.011033525690436363,0.011313538998365402,0.009327615611255169,0.00894206017255783,0.009283722378313541,0.009636766277253628,0.009730867110192776,0.008584636263549328,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 138195    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 138196    
=================================================================
Total params: 276,391
Trainable params: 276,391
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 138,195
Trainable params: 138,195
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 138,196
Trainable params: 138,196
Non-trainable params: 0
_________________________________________________________________
