2021-06-26
loss,0.5353677868843079,0.2603788673877716,0.23690147697925568,0.22953741252422333,0.2229841649532318,0.21595114469528198,0.21189452707767487,0.20606116950511932,0.19994384050369263,0.19628150761127472,0.18929119408130646,0.1867178976535797,0.18316805362701416,0.18100742995738983,0.17310161888599396,0.1678427755832672,0.16298000514507294,0.15273137390613556,0.13698752224445343,0.1290564388036728,0.13241420686244965,0.11376318335533142,0.10698363184928894,0.0695803090929985,0.07335507124662399,0.08526961505413055,0.07298003882169724,0.06426491588354111,0.05735671892762184,0.0687381774187088,0.06567169725894928,0.04961850494146347,0.04896843433380127,0.058068178594112396,0.05405620485544205,0.050474416464567184,0.04799613356590271,0.03999440744519234,0.05117151886224747,0.044078197330236435,0.041001081466674805,0.0429680310189724,0.03792523220181465,0.042189039289951324,0.036050859838724136,0.03726327791810036,0.0352829284965992,0.04165833815932274,0.03783971443772316,0.03352293744683266,0.03211028501391411,0.0359121598303318,0.03572077676653862,0.03286335617303848,0.03071027249097824,0.03544522449374199,0.029153916984796524,0.030182642862200737,0.032271530479192734,0.03105876035988331,0.030972925946116447,0.031170399859547615,0.028483921661973,0.02568301372230053,0.025531813502311707,0.028209807351231575,0.029063355177640915,0.028023524209856987,0.025034187361598015,0.024007637053728104,0.0272720605134964,0.031493403017520905,0.027017978951334953,0.02787875197827816,0.026960339397192,0.023265432566404343,0.023936323821544647,0.023287333548069,0.02330598048865795,0.023522691801190376,0.02488439343869686,0.025233177468180656,0.02632163092494011,0.024277925491333008,0.025344228371977806,0.02444104105234146,0.020589051768183708,0.019555967301130295,0.023727895691990852,0.024645747616887093,0.02308080904185772,0.02297160215675831,0.023138772696256638,0.021432900801301003,0.020600682124495506,0.023007528856396675,0.02176233008503914,0.02048499509692192,0.021414615213871002,0.01982126571238041,
mse,0.12006577849388123,0.02202293649315834,0.019075578078627586,0.01785881817340851,0.0168998334556818,0.01593644544482231,0.01522592268884182,0.014520250260829926,0.013730053789913654,0.013139006681740284,0.012335839681327343,0.011957241222262383,0.011497481726109982,0.011188484728336334,0.010366290807723999,0.009739226661622524,0.008816203102469444,0.007396968547254801,0.005728927440941334,0.004924843553453684,0.005111551843583584,0.0037087351083755493,0.0034117165487259626,0.0013952655717730522,0.0015705175464972854,0.002080996986478567,0.001491786795668304,0.0011569332564249635,0.0009497968712821603,0.0013464209623634815,0.0012057691346853971,0.0007040986674837768,0.0007029591361060739,0.0009398273541592062,0.0008258023299276829,0.0007145582349039614,0.0006401227437891066,0.0004752036475110799,0.0007358670700341463,0.0005395439802668989,0.0004694468807429075,0.0005175358965061605,0.0004014592559542507,0.0005086432211101055,0.00037466653157025576,0.000387807609513402,0.0003576878225430846,0.0004894773010164499,0.0003996969317086041,0.00030922991572879255,0.0002933342766482383,0.00035733997356146574,0.00035278016002848744,0.000300443556625396,0.0002666630898602307,0.00035354637657292187,0.00024675941676832736,0.0002554337552282959,0.0002907683956436813,0.0002655287098605186,0.00027227026293985546,0.0002716252638492733,0.00022829597583040595,0.00018927572818938643,0.0001853662688517943,0.0002272907440783456,0.0002376001502852887,0.0002172199310734868,0.00017989156185649335,0.00016533443704247475,0.0002090186026180163,0.0002752837026491761,0.00020425465481821448,0.0002212981489719823,0.00020292846602387726,0.00015251434524543583,0.0001658022083574906,0.00015419353439938277,0.00015329144662246108,0.00015585495566483587,0.00017213723913300782,0.00018058378191199154,0.0001930205471580848,0.00016720901476219296,0.00018098192231263965,0.00016818864969536662,0.00012330865138210356,0.00011403535609133542,0.00015538920706603676,0.00016740744467824697,0.00014899751113262028,0.0001466533140046522,0.00014764752995688468,0.0001288057246711105,0.0001244747545570135,0.00014916974760126323,0.00013245423906482756,0.00011864710540976375,0.00013136166671756655,0.00011255896970396861,
mae,0.23132114112377167,0.1105121448636055,0.10653091222047806,0.1043912023305893,0.10007745027542114,0.09569337218999863,0.09238338470458984,0.0889778807759285,0.08590351790189743,0.08382865786552429,0.08050990849733353,0.0793379470705986,0.07792486995458603,0.07696413993835449,0.07374697923660278,0.07144135236740112,0.06906989961862564,0.06437888741493225,0.05792579799890518,0.054924607276916504,0.05640385299921036,0.04807629436254501,0.04509517550468445,0.029512370005249977,0.031199688091874123,0.036878395825624466,0.03105609491467476,0.027287056669592857,0.02427803911268711,0.029310159385204315,0.028176909312605858,0.021536750718951225,0.020687244832515717,0.024643313139677048,0.023299288004636765,0.02132885903120041,0.020612521097064018,0.016969695687294006,0.022211339324712753,0.019053302705287933,0.017456721514463425,0.01873164065182209,0.01624912954866886,0.01837955228984356,0.015486047603189945,0.015832412987947464,0.015078685246407986,0.018217969685792923,0.01654324121773243,0.014069508761167526,0.013614910654723644,0.015183431096374989,0.015165824443101883,0.013990415260195732,0.013116789981722832,0.01520567201077938,0.0124456025660038,0.01286684162914753,0.013580381870269775,0.013046704232692719,0.013019713573157787,0.013361749239265919,0.012214486487209797,0.011005423963069916,0.010967518202960491,0.01201334223151207,0.012206469662487507,0.011995010077953339,0.010603067465126514,0.010255265049636364,0.011498609557747841,0.013643648475408554,0.011418179608881474,0.01203518733382225,0.011589251458644867,0.009825076907873154,0.01014040969312191,0.009899259544909,0.009837835095822811,0.009902450256049633,0.010568015277385712,0.01066706795245409,0.01119308266788721,0.010312939062714577,0.01084638386964798,0.010287893936038017,0.008658383972942829,0.008349107578396797,0.010045566596090794,0.0105277169495821,0.009763393551111221,0.009793363511562347,0.009786737151443958,0.009189696051180363,0.008790787309408188,0.00961624551564455,0.009231135249137878,0.008550475351512432,0.00896168127655983,0.008452328853309155,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 56035     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 56036     
=================================================================
Total params: 112,071
Trainable params: 112,071
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 56,035
Trainable params: 56,035
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 56,036
Trainable params: 56,036
Non-trainable params: 0
_________________________________________________________________
