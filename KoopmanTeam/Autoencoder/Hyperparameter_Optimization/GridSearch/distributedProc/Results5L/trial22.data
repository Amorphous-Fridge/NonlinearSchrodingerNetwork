2021-06-26
loss,0.3665936589241028,0.14520637691020966,0.09771090745925903,0.0910690575838089,0.07993262261152267,0.0704629123210907,0.07507245242595673,0.0938967913389206,0.07028231769800186,0.06531641632318497,0.056575216352939606,0.06475602090358734,0.04856573045253754,0.05791715532541275,0.07418836653232574,0.05700647458434105,0.05278951674699783,0.03855587914586067,0.046838629990816116,0.05759487673640251,0.05904754251241684,0.056871674954891205,0.05514906346797943,0.05507553741335869,0.05125316604971886,0.04602466896176338,0.04232696443796158,0.057277608662843704,0.054588910192251205,0.04561574384570122,0.0445617139339447,0.04590490832924843,0.03873509541153908,0.03410540893673897,0.04682795703411102,0.04352928698062897,0.039099160581827164,0.03625135123729706,0.0339169055223465,0.03212251141667366,0.04064171761274338,0.04578835889697075,0.04172637313604355,0.0336010605096817,0.03213698789477348,0.028733029961586,0.02690276876091957,0.031291455030441284,0.034988343715667725,0.031983815133571625,0.0338519886136055,0.03932885825634003,0.035079848021268845,0.033579304814338684,0.03353775665163994,0.03705484792590141,0.035282596945762634,0.031496111303567886,0.02808547578752041,0.026761632412672043,0.025255313143134117,0.022119546309113503,0.03164717182517052,0.03353932499885559,0.03129202499985695,0.032417017966508865,0.03166273981332779,0.029081957414746284,0.027215396985411644,0.026223307475447655,0.030024299398064613,0.029366273432970047,0.03136371076107025,0.027144193649291992,0.029528364539146423,0.025851894170045853,0.023656504228711128,0.02180669829249382,0.025203602388501167,0.030816109851002693,0.02610357105731964,0.026214048266410828,0.02640008181333542,0.027664655819535255,0.025903183966875076,0.024618089199066162,0.023739976808428764,0.02277236431837082,0.02212296985089779,0.023212986066937447,0.02606414258480072,0.023829780519008636,0.021872667595744133,0.022376783192157745,0.022988729178905487,0.019106363877654076,0.022179612889885902,0.027825677767395973,0.027111198753118515,0.024266542866826057,
mse,0.059209857136011124,0.006225278601050377,0.0029645899776369333,0.002447216073051095,0.0018567262450233102,0.0014808601699769497,0.0016894463915377855,0.002476837718859315,0.0014147129841148853,0.0012694484321400523,0.0009287248831242323,0.0013084583915770054,0.0006648970302194357,0.0009754390921443701,0.0015203916700556874,0.0009599316981621087,0.0008315545273944736,0.0004115266783628613,0.0006412444054149091,0.0010069082491099834,0.0009777417872101068,0.0009137970046140254,0.000867083203047514,0.0008402853272855282,0.0007178226369433105,0.000581278232857585,0.0005002761026844382,0.000959655037149787,0.0008179282303899527,0.000585556379519403,0.000550737779121846,0.0005778163904324174,0.00043240428203716874,0.0003283380065113306,0.0006037508137524128,0.0005205644411034882,0.0004143078112974763,0.000360079895472154,0.0003197331679984927,0.00029422316583804786,0.00046012617531232536,0.0005778964841738343,0.0004804641066584736,0.0003297845250926912,0.00029054327751509845,0.00023573522048536688,0.0002067599561996758,0.0002872610930353403,0.00035294180270284414,0.0002904046268668026,0.00033528299536556005,0.00041867978870868683,0.0003419907297939062,0.0003146787057630718,0.000316565710818395,0.0003880061558447778,0.00034454662818461657,0.0002713199064601213,0.00021856855892110616,0.0002016091748373583,0.00017994528752751648,0.00014248734805732965,0.00029632251244038343,0.00030589158996008337,0.0002772382867988199,0.00028914600261487067,0.0002699000760912895,0.0002300655032740906,0.0002047918242169544,0.00019661184342112392,0.0002502817951608449,0.0002416345087112859,0.00026817453908734024,0.00021168695820961148,0.00024107503122650087,0.0001919646019814536,0.00015740570961497724,0.00013612519251182675,0.00018030517094302922,0.00026140979025512934,0.0001913681480800733,0.00019005208741873503,0.00019643548876047134,0.00020597311959136277,0.00018117022409569472,0.00016559155483264476,0.00015342871483881027,0.00014109416224528104,0.00013419135939329863,0.0001616232912056148,0.00018782500410452485,0.0001555439957883209,0.00013504811795428395,0.0001442379434593022,0.00014701455074828118,0.00010719528654590249,0.0001413881400367245,0.00021010305499657989,0.0001993606420001015,0.00016027066158130765,
mae,0.15780197083950043,0.06171092018485069,0.0415986031293869,0.038776252418756485,0.03350716829299927,0.03043019026517868,0.032209254801273346,0.04012976214289665,0.02950913831591606,0.02808632142841816,0.024567609652876854,0.02808305434882641,0.020659951493144035,0.024454398080706596,0.03099840134382248,0.024228312075138092,0.022565823048353195,0.017039626836776733,0.019688980653882027,0.024270953610539436,0.02547905594110489,0.024936547502875328,0.023591039702296257,0.023426862433552742,0.02051527053117752,0.01834016665816307,0.017670344561338425,0.024759214371442795,0.023137954995036125,0.01930762082338333,0.01890057511627674,0.019917558878660202,0.01675201766192913,0.014983312226831913,0.02025160938501358,0.017914090305566788,0.01603546552360058,0.015489567071199417,0.014830167405307293,0.013633094727993011,0.017253093421459198,0.02011941932141781,0.018732523545622826,0.01469955313950777,0.013803534209728241,0.012427173554897308,0.01148714404553175,0.013476639054715633,0.014845223166048527,0.013748347759246826,0.014508935622870922,0.017317891120910645,0.015311178751289845,0.01437266357243061,0.014177931472659111,0.015310286544263363,0.014794986695051193,0.014056065119802952,0.012430638074874878,0.011820896528661251,0.010644146241247654,0.0092002609744668,0.013641536235809326,0.014889482408761978,0.01343589648604393,0.013928708620369434,0.012896215543150902,0.01178944855928421,0.011278178542852402,0.011209815740585327,0.012757820077240467,0.012464604340493679,0.01314644142985344,0.011355327442288399,0.0127183236181736,0.011303910054266453,0.010091868229210377,0.009204949252307415,0.010696250945329666,0.013020088896155357,0.010765389539301395,0.010881735011935234,0.010923156514763832,0.011465644463896751,0.011086945421993732,0.010839671827852726,0.010494599118828773,0.01009816862642765,0.009757285937666893,0.009957419708371162,0.010988452471792698,0.010061284527182579,0.009263546206057072,0.009558628313243389,0.009537782520055771,0.008113348856568336,0.009462406858801842,0.011915263719856739,0.01200175192207098,0.01052556186914444,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 18835     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 18836     
=================================================================
Total params: 37,671
Trainable params: 37,671
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 18,835
Trainable params: 18,835
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 18,836
Trainable params: 18,836
Non-trainable params: 0
_________________________________________________________________
