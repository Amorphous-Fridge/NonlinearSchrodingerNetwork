2021-06-26
loss,0.5531437397003174,0.24742567539215088,0.23369650542736053,0.2062831073999405,0.15951409935951233,0.1336458921432495,0.12566635012626648,0.08301056921482086,0.060207974165678024,0.09030557423830032,0.07908794283866882,0.07370234280824661,0.08469138294458389,0.08013017475605011,0.0625184029340744,0.053258251398801804,0.0579582080245018,0.06988021731376648,0.0585768036544323,0.055856600403785706,0.050138335675001144,0.056578993797302246,0.044144950807094574,0.04052172601222992,0.03671344742178917,0.04689084365963936,0.052158474922180176,0.03998410329222679,0.047456517815589905,0.0574408583343029,0.04998888075351715,0.04303659498691559,0.03239157050848007,0.032019831240177155,0.04046276956796646,0.0358826145529747,0.04022291675209999,0.039542604237794876,0.043876390904188156,0.042199742048978806,0.036982692778110504,0.041992273181676865,0.03416169807314873,0.02892492525279522,0.02729964256286621,0.025944162160158157,0.02410036511719227,0.03070739656686783,0.03559717908501625,0.03347017243504524,0.03824710473418236,0.03469312563538551,0.03177184239029884,0.029604682698845863,0.028589995577931404,0.025773195549845695,0.024569211527705193,0.024427680298686028,0.02703178860247135,0.03157883137464523,0.03331108018755913,0.034243904054164886,0.035339824855327606,0.031897369772195816,0.025935852900147438,0.03247787058353424,0.02752874046564102,0.025375351309776306,0.023980390280485153,0.022754738107323647,0.021693220362067223,0.021058596670627594,0.022010043263435364,0.026274658739566803,0.025532184168696404,0.028593847528100014,0.028983185067772865,0.026850663125514984,0.023810191079974174,0.021744471043348312,0.020250501111149788,0.01881295070052147,0.016840478405356407,0.01651621051132679,0.015591484494507313,0.015579759143292904,0.015093221329152584,0.015038751065731049,0.014867573045194149,0.014583910815417767,0.014675664715468884,0.014620867557823658,0.014488372020423412,0.014286215417087078,0.014422081410884857,0.014181026257574558,0.014182990416884422,0.014057022519409657,0.013928801752626896,0.013925398699939251,
mse,0.14695023000240326,0.020352454856038094,0.018475733697414398,0.013370021246373653,0.007244959473609924,0.005052791442722082,0.004435344133526087,0.0021316849160939455,0.0010180152021348476,0.002452262444421649,0.0017860810039564967,0.0015773650957271457,0.002021802356466651,0.0017814823659136891,0.001132612582296133,0.0008572040242142975,0.0010047534015029669,0.0013924321392551064,0.0009690563310869038,0.0008713401039130986,0.000721561664249748,0.0008852679748088121,0.0005473662167787552,0.000463024596683681,0.0003965844225604087,0.0006375344237312675,0.0007699150592088699,0.00046006133197806776,0.0006464880425482988,0.0009463798487558961,0.0006933463155291975,0.0005373625899665058,0.0003142761706840247,0.0003054138214793056,0.0004592802724801004,0.00036555391852743924,0.0004588534648064524,0.0004502995579969138,0.0005360583309084177,0.0004902888322249055,0.0003812548238784075,0.0004956835764460266,0.00032476059277541935,0.00023681257152929902,0.00021224803640507162,0.00019425558275543153,0.00017191523511428386,0.0002802844101097435,0.0003486408677417785,0.00031491060508415103,0.00040248659206554294,0.00033287727274000645,0.0002790094295050949,0.00024510384537279606,0.00022742743021808565,0.0001896242465591058,0.00017110492626670748,0.00017354745068587363,0.00020853402384091169,0.000287604023469612,0.00031148569541983306,0.0003373882209416479,0.00035793811548501253,0.00028280942933633924,0.00019442455959506333,0.0002947273023892194,0.0002111555659212172,0.00017889178707264364,0.00016036987653933465,0.0001460396160837263,0.00013382534962147474,0.00012570184480864555,0.0001401714835083112,0.00020843511447310448,0.00019188746227882802,0.0002296050952281803,0.00023646884073968977,0.00020098258391954005,0.0001612943015061319,0.00013431352272164077,0.00011658832227112725,0.00010557725181570277,8.191973029170185e-05,7.632326742168516e-05,6.808256875956431e-05,6.80592711432837e-05,6.394876982085407e-05,6.326523725874722e-05,6.217624468263239e-05,5.968518598820083e-05,6.11644281889312e-05,5.9820224123541266e-05,5.899557800148614e-05,5.760394560638815e-05,5.770897041657008e-05,5.623236211249605e-05,5.627925202134065e-05,5.530806811293587e-05,5.4267100495053455e-05,5.431934187072329e-05,
mae,0.2385091334581375,0.11301502585411072,0.10783781856298447,0.08865141868591309,0.06821944564580917,0.05703889951109886,0.05352809280157089,0.03439706563949585,0.025545131415128708,0.03804970160126686,0.03342486545443535,0.031317662447690964,0.03700219467282295,0.033789943903684616,0.026345573365688324,0.02298026718199253,0.02481490932404995,0.03028804250061512,0.024623915553092957,0.024453701451420784,0.021296177059412003,0.02405758947134018,0.019262446090579033,0.017312971875071526,0.01569472998380661,0.019880186766386032,0.022451743483543396,0.01695401407778263,0.020257150754332542,0.02439788170158863,0.021440517157316208,0.018292613327503204,0.013650315813720226,0.013618383556604385,0.01746954955160618,0.015632370486855507,0.017219843342900276,0.01671832613646984,0.018792834132909775,0.017901116982102394,0.015734929591417313,0.018242591992020607,0.014524752274155617,0.01216907612979412,0.011408934369683266,0.010989140719175339,0.010249440558254719,0.012922975234687328,0.015483140014111996,0.014411632902920246,0.016459105536341667,0.015136458911001682,0.013333149254322052,0.012424295768141747,0.012115653604269028,0.011015440337359905,0.010466475039720535,0.010398536920547485,0.011578756384551525,0.013401677832007408,0.014109966345131397,0.014861810952425003,0.015105107799172401,0.013498017564415932,0.010987584479153156,0.013581953011453152,0.011899961158633232,0.011089613661170006,0.010347199626266956,0.009649423882365227,0.009191826917231083,0.00896891113370657,0.009308584034442902,0.011281116865575314,0.010872780345380306,0.012395492754876614,0.012236488983035088,0.011094036512076855,0.009988205507397652,0.008924475871026516,0.008340854197740555,0.008036592975258827,0.007193689234554768,0.007147369906306267,0.00674412539228797,0.006688179913908243,0.00649231905117631,0.006463376339524984,0.006315526552498341,0.006259537767618895,0.006303052883595228,0.006237134803086519,0.006184689234942198,0.00610558083280921,0.006155896000564098,0.0060191829688847065,0.006068539805710316,0.005982220638543367,0.005884115118533373,0.005934291053563356,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34251     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34252     
=================================================================
Total params: 68,503
Trainable params: 68,503
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 34,251
Trainable params: 34,251
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 34,252
Trainable params: 34,252
Non-trainable params: 0
_________________________________________________________________
