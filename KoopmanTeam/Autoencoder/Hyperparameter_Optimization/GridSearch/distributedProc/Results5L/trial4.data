2021-06-26
loss,0.41264379024505615,0.20664289593696594,0.12269387394189835,0.08110451698303223,0.06506650894880295,0.05732659250497818,0.05347665771842003,0.06582176685333252,0.060914959758520126,0.07008176296949387,0.0579756498336792,0.06916499137878418,0.07121452689170837,0.05996205285191536,0.0538899265229702,0.04761272296309471,0.043678294867277145,0.04136814549565315,0.04076410457491875,0.036331187933683395,0.03512365743517876,0.034797754138708115,0.03331926465034485,0.0330844409763813,0.03229375183582306,0.03191781044006348,0.03142978996038437,0.031138412654399872,0.030884819105267525,0.030410198494791985,0.029971037060022354,0.029369855299592018,0.029516376554965973,0.04451453313231468,0.04831615835428238,0.045676589012145996,0.03800564631819725,0.04484077915549278,0.04020397365093231,0.03631919249892235,0.03400920331478119,0.032515257596969604,0.032437022775411606,0.04507157951593399,0.043150048702955246,0.03941529989242554,0.033864185214042664,0.046998415142297745,0.04541396722197533,0.04577519744634628,0.04348547011613846,0.039375897496938705,0.03700539842247963,0.0368957594037056,0.03994513303041458,0.0322924368083477,0.029437148943543434,0.02787121757864952,0.026901358738541603,0.02613295614719391,0.025507710874080658,0.026998987421393394,0.03970486298203468,0.03564566746354103,0.033363260328769684,0.030925504863262177,0.02940034680068493,0.03997178375720978,0.0322125069797039,0.04215991497039795,0.042109083384275436,0.036556538194417953,0.03328082337975502,0.031477805227041245,0.029571300372481346,0.027386879548430443,0.025545479729771614,0.02440340258181095,0.023260442540049553,0.021891050040721893,0.020940378308296204,0.020292427390813828,0.020066412165760994,0.019924426451325417,0.019762448966503143,0.019682472571730614,0.01955539546906948,0.019407309591770172,0.019417058676481247,0.019228827208280563,0.019122561439871788,0.019091574475169182,0.019027583301067352,0.01883600279688835,0.018397042527794838,0.018899613991379738,0.018773183226585388,0.01861395500600338,0.01847725547850132,0.018609939143061638,
mse,0.06826131045818329,0.015462960116565228,0.004872928373515606,0.002022304804995656,0.0013113453751429915,0.0010285783791914582,0.0008936838712543249,0.0013111799489706755,0.0010894291335716844,0.001407923293299973,0.0009877710836008191,0.0014319006586447358,0.0014445625711232424,0.0010715146781876683,0.0008499335963279009,0.0006640054052695632,0.0005786787369288504,0.0005168698262423277,0.0004924964741803706,0.0004012579738628119,0.0003781417617574334,0.0003617789479903877,0.00033074262319132686,0.0003225927066523582,0.00030981088639236987,0.00030035627423785627,0.00029110966715961695,0.0002848781587090343,0.00027909231721423566,0.0002719793701544404,0.00026242711464874446,0.00025582703528925776,0.00025803883909247816,0.0007702188449911773,0.0006918036960996687,0.0006009445060044527,0.0004227368044666946,0.0005723300855606794,0.00044257703120820224,0.00036472323699854314,0.00032390785054303706,0.00030570817762054503,0.00030044023878872395,0.0005908652674406767,0.0005387753481045365,0.0004470784915611148,0.00032713223481550813,0.0007139058434404433,0.0005827917484566569,0.0005933044594712555,0.0005359599599614739,0.0004465585807338357,0.0004073989111930132,0.00039387293509207666,0.0004686393076553941,0.0002956539101433009,0.00024455535458400846,0.0002227556105935946,0.00020799582125619054,0.00019602602696977556,0.00018760641978587955,0.00021326002024579793,0.0004468754632398486,0.00037067223456688225,0.00030559522565454245,0.0002644143532961607,0.0002451901964377612,0.00045746960677206516,0.00031668110750615597,0.0005106311873532832,0.0004953724564984441,0.0003779551771003753,0.0003157778410241008,0.00028044049395248294,0.00024834537180140615,0.00021235518215689808,0.0001854553702287376,0.0001717561244731769,0.00015612061542924494,0.00013757454871665686,0.00012643310765270144,0.00011979034752584994,0.0001163334381999448,0.00011421503586461768,0.00011298766185063869,0.0001113093676394783,0.00010987355199176818,0.00010847219527931884,0.00010808747174451128,0.00010595718049444258,0.00010518839553697035,0.00010475525778019801,0.00010319132707081735,0.00010088405542774126,9.711881284601986e-05,0.00010201115946983919,0.0001000639604171738,9.842666622716933e-05,9.679658978711814e-05,9.838660480454564e-05,
mae,0.17661048471927643,0.08811953663825989,0.05177844688296318,0.03414474427700043,0.027482884004712105,0.024302832782268524,0.02261362038552761,0.028104806318879128,0.026081476360559464,0.02908944897353649,0.024246666580438614,0.029442355036735535,0.02980046719312668,0.024405980482697487,0.021774444729089737,0.02025197446346283,0.01863998733460903,0.017698056995868683,0.017356984317302704,0.015331437811255455,0.014876498840749264,0.014779641292989254,0.014128562994301319,0.014157958328723907,0.013692988082766533,0.013560817576944828,0.013463827781379223,0.013191399164497852,0.013071597553789616,0.012873542495071888,0.012687313370406628,0.012418474070727825,0.012561006471514702,0.018067246302962303,0.020055925473570824,0.019543353468179703,0.016128720715641975,0.01924085058271885,0.016705580055713654,0.014727563597261906,0.013839645311236382,0.01366278063505888,0.013769229874014854,0.01886727660894394,0.018637903034687042,0.016669876873493195,0.014756405726075172,0.02035571075975895,0.01922975853085518,0.01964389719069004,0.0196139644831419,0.017416883260011673,0.016054341569542885,0.015710588544607162,0.01697806641459465,0.013589108362793922,0.01251919474452734,0.011933032423257828,0.011563071981072426,0.01125161163508892,0.010791681706905365,0.011507570743560791,0.01688840240240097,0.015065979212522507,0.014949619770050049,0.013908492401242256,0.01286635734140873,0.017068715766072273,0.013830282725393772,0.018553195521235466,0.017464088276028633,0.015906594693660736,0.014930922538042068,0.013846505433321,0.012500971555709839,0.011769012548029423,0.011153756640851498,0.010523354634642601,0.010052709840238094,0.009420170448720455,0.008930309675633907,0.008697929792106152,0.008535726927220821,0.00852107722312212,0.008525935001671314,0.008406327106058598,0.008359573781490326,0.008359109051525593,0.008384021930396557,0.008270157501101494,0.008161108009517193,0.00812679622322321,0.008181705139577389,0.008120203390717506,0.007831872440874577,0.007898866198956966,0.00797707587480545,0.007936039939522743,0.007841524668037891,0.007900952361524105,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 4811      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 4812      
=================================================================
Total params: 9,623
Trainable params: 9,623
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 4,811
Trainable params: 4,811
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 4,812
Trainable params: 4,812
Non-trainable params: 0
_________________________________________________________________
