2021-06-26
loss,0.38318562507629395,0.12663310766220093,0.10486733168363571,0.07389053702354431,0.05708671733736992,0.06026998907327652,0.057775672525167465,0.05305870994925499,0.05185653269290924,0.048085276037454605,0.06330366432666779,0.07566609233617783,0.06098107248544693,0.05435679852962494,0.04480273649096489,0.03966203331947327,0.039266716688871384,0.06038013845682144,0.05532291531562805,0.049669671803712845,0.04666352644562721,0.03639296814799309,0.028780359774827957,0.028350746259093285,0.02669791504740715,0.02598908357322216,0.025874324142932892,0.025169918313622475,0.024957427754998207,0.02462177537381649,0.024737991392612457,0.02385137975215912,0.02374950423836708,0.024032985791563988,0.03401320055127144,0.04035681113600731,0.03617297112941742,0.03819717466831207,0.038322776556015015,0.03464282676577568,0.034976452589035034,0.03821058198809624,0.03595137596130371,0.02873140387237072,0.020702145993709564,0.020315788686275482,0.01993931084871292,0.0195607990026474,0.019803106784820557,0.019420353695750237,0.019368695095181465,0.01941242627799511,0.01904890313744545,0.0193235632032156,0.019080551341176033,0.018933545798063278,0.019126078113913536,0.018876392394304276,0.021417122334241867,0.03220662474632263,0.031800542026758194,0.030153242871165276,0.026753749698400497,0.023877913132309914,0.03300277516245842,0.030499089509248734,0.03098025545477867,0.030480574816465378,0.026204220950603485,0.023605892434716225,0.01764877699315548,0.017131740227341652,0.01724412478506565,0.01694566011428833,0.016841797158122063,0.0167473703622818,0.016502244397997856,0.01681545563042164,0.016590286046266556,0.016556138172745705,0.016410615295171738,0.016134265810251236,0.01629367098212242,0.016103239730000496,0.016378486528992653,0.02709433063864708,0.026317041367292404,0.026997141540050507,0.025289520621299744,0.026366708800196648,0.027748215943574905,0.02638094499707222,0.023630186915397644,0.021828066557645798,0.02573457546532154,0.025646021589636803,0.02490457333624363,0.025128906592726707,0.022735491394996643,0.02132187783718109,
mse,0.08827142417430878,0.004559831693768501,0.00319714960642159,0.001580996671691537,0.0009489938383921981,0.0010815553832799196,0.0009462664020247757,0.0007991061429493129,0.0007835958385840058,0.0006499537266790867,0.0011476711370050907,0.0016015390865504742,0.0010769356740638614,0.0008638399885967374,0.0005677074077539146,0.00044147760490886867,0.00043957974412478507,0.0010462399804964662,0.0008615803672000766,0.0007061474025249481,0.00063159572891891,0.0004019276821054518,0.00024570131790824234,0.00023310391406994313,0.00020722593762911856,0.00019571540178731084,0.00019357148266863078,0.00018215829913970083,0.00018012337386608124,0.0001730594231048599,0.00017454242333769798,0.00016525416867807508,0.00016644423885736614,0.00017290108371526003,0.00034667932777665555,0.00047218057443387806,0.00036787649150937796,0.00041798510937951505,0.0004280572466086596,0.00033972066012211144,0.0003381069691386074,0.0004272675432730466,0.00036860123509541154,0.000241929737967439,0.0001275687973247841,0.00011974546214332804,0.00011486417497508228,0.00011068067396990955,0.00011261895997449756,0.00010765670594992116,0.0001071375299943611,0.00010635428043315187,0.00010522322554606944,0.00010650531476130709,0.00010390317038400099,0.0001026726167765446,0.00010503942030481994,0.00010309202480129898,0.00013890094123780727,0.00029301378526724875,0.0002810434380080551,0.00025182359968312085,0.00020760275947395712,0.00017156220565084368,0.0003172912693116814,0.00025896343868225813,0.0002759740746114403,0.00025970517890527844,0.00019226571021135896,0.00015960658492986113,9.444249735679477e-05,8.538199472241104e-05,8.572049409849569e-05,8.241994510171935e-05,8.111080387607217e-05,8.108190377242863e-05,7.911609282018617e-05,8.20511850179173e-05,7.914975140010938e-05,7.779953011777252e-05,7.63996722525917e-05,7.507485861424357e-05,7.719652057858184e-05,7.45086363167502e-05,7.771943637635559e-05,0.0002092740178341046,0.00018978689331561327,0.00020719658641610295,0.00018344790441915393,0.00019936209719162434,0.00021752271277364343,0.00019682008132804185,0.0001628621539566666,0.0001399613101966679,0.00019372868700884283,0.00018667595577426255,0.00017422519158571959,0.0001726440677884966,0.00014430933515541255,0.00012950465315952897,
mae,0.1664070338010788,0.05407638102769852,0.04410869628190994,0.031064219772815704,0.024290461093187332,0.025883791968226433,0.024371087551116943,0.02225583605468273,0.022060157731175423,0.020287565886974335,0.02727840654551983,0.032735876739025116,0.02601877599954605,0.02321305312216282,0.01910397596657276,0.016732022166252136,0.016589956358075142,0.02586553804576397,0.02346363291144371,0.02112782746553421,0.020094480365514755,0.015667840838432312,0.012324986048042774,0.01202250923961401,0.011259743943810463,0.011035275645554066,0.010914243757724762,0.010700548999011517,0.01054334081709385,0.010508549399673939,0.0103534534573555,0.010138791985809803,0.010181098245084286,0.01021028496325016,0.014561184681952,0.01727120764553547,0.015486462041735649,0.016403190791606903,0.016132084652781487,0.01488832850009203,0.014916866086423397,0.01630907505750656,0.015447334386408329,0.012096001766622066,0.008821763098239899,0.008572852239012718,0.008393905125558376,0.008320137858390808,0.008364798501133919,0.008239165879786015,0.008172210305929184,0.008253033272922039,0.008036736398935318,0.00821622833609581,0.008185253478586674,0.008054601028561592,0.008164774626493454,0.008025981485843658,0.009174845181405544,0.013800757937133312,0.013513742946088314,0.012994376011192799,0.011624790728092194,0.010038051754236221,0.01400743331760168,0.012922105379402637,0.013410691171884537,0.013235325925052166,0.01117630209773779,0.010141003876924515,0.007506073918193579,0.007304016966372728,0.00721080182120204,0.007122040260583162,0.007034262642264366,0.0070838467217981815,0.006998521275818348,0.007158839609473944,0.006961770821362734,0.007022216450423002,0.006907345727086067,0.006961208768188953,0.006886878050863743,0.006876287516206503,0.006936336867511272,0.011608373373746872,0.010991794057190418,0.011642166413366795,0.010952973738312721,0.011229620315134525,0.011904638260602951,0.01145346648991108,0.010101140476763248,0.009266143664717674,0.010840659961104393,0.010924900881946087,0.010582184419035912,0.010628986172378063,0.009557228535413742,0.009056173264980316,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17579     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17580     
=================================================================
Total params: 35,159
Trainable params: 35,159
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 17,579
Trainable params: 17,579
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 17,580
Trainable params: 17,580
Non-trainable params: 0
_________________________________________________________________
