2021-06-26
loss,3.6539270877838135,2.7568089962005615,1.489099144935608,0.27896127104759216,0.2135302722454071,0.13864420354366302,0.1257478892803192,0.10612085461616516,0.0896083414554596,0.09279853850603104,0.08669579774141312,0.08821548521518707,0.07981255650520325,0.06698941439390182,0.07666432112455368,0.06387536227703094,0.05203664302825928,0.048572197556495667,0.052783265709877014,0.06075908616185188,0.052118729799985886,0.054512955248355865,0.045964524149894714,0.04814241826534271,0.05466355383396149,0.04810398444533348,0.04823077842593193,0.047149594873189926,0.04397425800561905,0.03557474911212921,0.04303407296538353,0.04232585057616234,0.046288035809993744,0.038891199976205826,0.042791999876499176,0.04287394508719444,0.033474747091531754,0.033660467714071274,0.03402740880846977,0.03739297762513161,0.03562374413013458,0.036955639719963074,0.03259943798184395,0.031385086476802826,0.03235189616680145,0.04279472678899765,0.03615117445588112,0.03513769432902336,0.03957017511129379,0.03037850372493267,0.037422001361846924,0.03187071904540062,0.0359477624297142,0.031715892255306244,0.034766241908073425,0.028040854260325432,0.029084237292408943,0.031786683946847916,0.034023843705654144,0.029847504571080208,0.03138573095202446,0.029426181688904762,0.03140763193368912,0.02962782420217991,0.0301984790712595,0.025796514004468918,0.02563357912003994,0.0262227114289999,0.029151998460292816,0.02582622319459915,0.025585126131772995,0.0289777684956789,0.029611729085445404,0.028906244784593582,0.027493109926581383,0.02777182310819626,0.02566576935350895,0.027052337303757668,0.02828320674598217,0.02738068997859955,0.02648775279521942,0.023635609075427055,0.025777675211429596,0.02475598081946373,0.024601103737950325,0.019545255228877068,0.02638082765042782,0.02438770979642868,0.02509392239153385,0.026652054861187935,0.02328864112496376,0.021686160936951637,0.02107299491763115,0.02645634487271309,0.020917588844895363,0.02227078005671501,0.025792554020881653,0.021840715780854225,0.020165199413895607,0.023174168542027473,
mse,3.400716781616211,1.96156644821167,0.7359177470207214,0.0236913301050663,0.013138341717422009,0.005572502501308918,0.0046656313352286816,0.0032501351088285446,0.002316636499017477,0.002469221130013466,0.0021472980733960867,0.00227823993191123,0.001853400026448071,0.0012761835241690278,0.0016623171977698803,0.001136341947130859,0.0007838012534193695,0.0006763504934497178,0.0008289636461995542,0.0010223975405097008,0.0007683760486543179,0.0008503275457769632,0.0005898460512980819,0.0006610470009036362,0.0008399360813200474,0.0006866210023872554,0.0006618225597776473,0.0006371223134920001,0.0005480043473653495,0.00036739095230586827,0.0005172692472115159,0.0005036222282797098,0.0006032913224771619,0.0004213213105686009,0.0005044955178163946,0.0005217131110839546,0.0003147974202875048,0.0003252993046771735,0.0003370890626683831,0.0003932445542886853,0.00034983150544576347,0.0003861350123770535,0.00030629668617621064,0.0002812998427543789,0.00029062910471111536,0.0005180591833777726,0.00036360492231324315,0.00035276287235319614,0.00043516469304449856,0.0002667001390364021,0.0003880257427226752,0.00028957362519577146,0.00036837049992755055,0.0002836534404195845,0.0003347374440636486,0.00023111209156922996,0.000241379500948824,0.0002885286812670529,0.0003313621273264289,0.0002523661532904953,0.0002694065042305738,0.00024954392574727535,0.0002803030947688967,0.00024708290584385395,0.0002601322194095701,0.00019371729285921901,0.00018828386964742094,0.00020099227549508214,0.0002370693109696731,0.00019140230142511427,0.000188394493306987,0.00023773653083480895,0.0002478673995938152,0.00023935154604259878,0.0002129390777554363,0.00021986098727211356,0.0001860337652033195,0.00021088928042445332,0.00022615208581555635,0.0002116405958076939,0.00020061447867192328,0.00016226558363996446,0.00018585467478260398,0.00017486588330939412,0.00017677206778898835,0.00011466600699350238,0.00020003216923214495,0.0001679921115282923,0.00017832571757026017,0.00020520899852272123,0.00015554639685433358,0.00013674153888132423,0.0001288344501517713,0.00019614549819380045,0.00013099421630613506,0.00014591531362384558,0.00018318327784072608,0.00013718298578169197,0.00012272399908397347,0.0001527616404928267,
mae,1.625146508216858,1.0273488759994507,0.45684516429901123,0.1172606348991394,0.09159724414348602,0.05892333388328552,0.054509736597537994,0.04594574123620987,0.03876134008169174,0.04009911045432091,0.03633779659867287,0.03670832887291908,0.032780133187770844,0.02770661562681198,0.03257274255156517,0.026588067412376404,0.02172408252954483,0.020597539842128754,0.022064276039600372,0.02624625898897648,0.02185058407485485,0.02308599278330803,0.019640302285552025,0.020398151129484177,0.02321777492761612,0.02015921287238598,0.020350521430373192,0.020035648718476295,0.01813063584268093,0.015000266022980213,0.018487799912691116,0.01795330084860325,0.019965069368481636,0.016269661486148834,0.018189478665590286,0.018158817663788795,0.014162813313305378,0.014183765277266502,0.014383938163518906,0.015719052404165268,0.014825334772467613,0.01570792868733406,0.013969311490654945,0.013157968409359455,0.013796845450997353,0.01810845173895359,0.015607215464115143,0.01511477306485176,0.017197858542203903,0.012705300934612751,0.016112977638840675,0.013479170389473438,0.015488112345337868,0.013493946753442287,0.014996379613876343,0.011809379793703556,0.012321769259870052,0.0139293959364295,0.014494883827865124,0.012728624045848846,0.013118471950292587,0.012168508023023605,0.01339971087872982,0.012225260958075523,0.012786367908120155,0.011025257408618927,0.010935154743492603,0.011195963248610497,0.012572974897921085,0.01088394969701767,0.010710801929235458,0.012593566440045834,0.012989874929189682,0.012515638954937458,0.011828551068902016,0.011929968371987343,0.010941225104033947,0.011649023741483688,0.012089530006051064,0.011683735996484756,0.011357604525983334,0.010180498473346233,0.010891535319387913,0.010476401075720787,0.010507423430681229,0.00824087392538786,0.011168918572366238,0.010331051424145699,0.010622051544487476,0.01138819195330143,0.010024011135101318,0.009154842235147953,0.009013178758323193,0.011310679838061333,0.00897037610411644,0.009400752373039722,0.011017589829862118,0.009338315576314926,0.008694845251739025,0.009910188615322113,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 222659    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 222660    
=================================================================
Total params: 445,319
Trainable params: 445,319
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 222,659
Trainable params: 222,659
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 222,660
Trainable params: 222,660
Non-trainable params: 0
_________________________________________________________________
