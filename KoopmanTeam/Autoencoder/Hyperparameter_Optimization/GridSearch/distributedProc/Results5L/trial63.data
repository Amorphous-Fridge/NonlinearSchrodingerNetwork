2021-06-26
loss,0.4044962227344513,0.19642168283462524,0.12935906648635864,0.10375721752643585,0.09181591123342514,0.07333248108625412,0.059193529188632965,0.06729680299758911,0.05078529193997383,0.06859800964593887,0.059147242456674576,0.05523727461695671,0.04432206228375435,0.04350036010146141,0.04364444315433502,0.04303286224603653,0.03213042765855789,0.030472587794065475,0.029421601444482803,0.04292285069823265,0.04301173985004425,0.04503413662314415,0.04521317780017853,0.04208507388830185,0.03955737128853798,0.03798956796526909,0.033218882977962494,0.03244016319513321,0.035972606390714645,0.035899568349123,0.04248867183923721,0.03596504032611847,0.03246045857667923,0.03183763474225998,0.026979707181453705,0.02215566486120224,0.024796295911073685,0.027393244206905365,0.0363745354115963,0.03461890295147896,0.030571606010198593,0.02693318761885166,0.02521757036447525,0.023449284955859184,0.022859161719679832,0.022277824580669403,0.02155156061053276,0.01969955675303936,0.018754106014966965,0.018127936869859695,0.017524316906929016,0.01727990061044693,0.01693449728190899,0.016798196360468864,0.01668267883360386,0.016573410481214523,0.016447491943836212,0.016270622611045837,0.016253354027867317,0.01620909757912159,0.016028722748160362,0.0159927848726511,0.015758881345391273,0.015790395438671112,0.015618674457073212,0.015522480942308903,0.015421215444803238,0.015523779205977917,0.015400763601064682,0.023115087300539017,0.026147237047553062,0.023861706256866455,0.025279931724071503,0.026629529893398285,0.023074770346283913,0.022567346692085266,0.023373791947960854,0.02125026471912861,0.019398394972085953,0.020577430725097656,0.02196199633181095,0.020058808848261833,0.0249306783080101,0.024018514901399612,0.023906365036964417,0.022456850856542587,0.022587765008211136,0.020300786942243576,0.02390550635755062,0.021981818601489067,0.02036958932876587,0.021657634526491165,0.0189504474401474,0.019661176949739456,0.0179399773478508,0.017159078270196915,0.016299594193696976,0.015191533602774143,0.014683200046420097,0.019706562161445618,
mse,0.06692028045654297,0.012634191662073135,0.004943372216075659,0.003163879504427314,0.002403393853455782,0.0015659126220270991,0.001006656908430159,0.0012873475207015872,0.000751303683500737,0.0013786834897473454,0.001010465552099049,0.0008519156253896654,0.000567923067137599,0.0005423165857791901,0.0005455527571029961,0.0005495587829500437,0.00029663092573173344,0.00026030067238025367,0.0002509349142201245,0.0005398510256782174,0.000521216366905719,0.0005808364949189126,0.0005659603630192578,0.0005051426705904305,0.0004416202718857676,0.0003994996950495988,0.0003077307192143053,0.0003079467569477856,0.0003677721251733601,0.00037599224015139043,0.0005127561744302511,0.0003617638722062111,0.000292362121399492,0.0003111054829787463,0.00021312030730769038,0.000147602244396694,0.00018265187100041658,0.0002169272629544139,0.0003741656255442649,0.0003399987181182951,0.000261916866293177,0.00020234794646967202,0.00018077529966831207,0.00015720812371000648,0.00014880781236570328,0.00014359068882185966,0.00013293034862726927,0.00011121673742309213,9.879602293949574e-05,9.217835759045556e-05,8.553736552130431e-05,8.38054038467817e-05,8.053897909121588e-05,7.903524965513498e-05,7.846611697459593e-05,7.690105121582747e-05,7.57476082071662e-05,7.503103552153334e-05,7.437687600031495e-05,7.269216439453885e-05,7.241647108457983e-05,7.124346302589402e-05,6.976992153795436e-05,6.958909216336906e-05,6.820190174039453e-05,6.69359287712723e-05,6.697844946756959e-05,6.76257986924611e-05,6.809803744545206e-05,0.000158717404701747,0.00019499020709190518,0.00015913879906293005,0.0001801949692890048,0.00019501450879033655,0.0001513078314019367,0.00014507451851386577,0.0001518851931905374,0.0001291841472266242,0.00010975026816595346,0.00012355211947578937,0.00013442279305309057,0.00011600417929003015,0.00017432549793738872,0.0001636040396988392,0.0001567011931911111,0.00014064033166505396,0.0001414628786733374,0.00011796325270552188,0.00015913514653220773,0.00013534349272958934,0.00011863237159559503,0.00013139157090336084,0.00010534585453569889,0.0001062166629708372,8.977877587312832e-05,8.278237510239705e-05,7.642831042176113e-05,6.86044804751873e-05,6.728293374180794e-05,0.00011279973114142194,
mae,0.16934314370155334,0.08381141722202301,0.055008139461278915,0.044053640216588974,0.038903072476387024,0.030894707888364792,0.024848373606801033,0.028247859328985214,0.021322086453437805,0.028821147978305817,0.025115283206105232,0.022647490724921227,0.018544957041740417,0.018437771126627922,0.018264299258589745,0.018215138465166092,0.013670341111719608,0.013044600374996662,0.012356888502836227,0.01837945729494095,0.01830514706671238,0.019220124930143356,0.018945686519145966,0.017857229337096214,0.016610560938715935,0.016123909503221512,0.014571547508239746,0.013846931047737598,0.014699751511216164,0.015098104253411293,0.018218128010630608,0.0151087436825037,0.01361223217099905,0.01331157237291336,0.011419108137488365,0.00939639750868082,0.010462016798555851,0.011554623953998089,0.015749894082546234,0.014954538084566593,0.013055272400379181,0.011879730969667435,0.010921170935034752,0.010051128454506397,0.009688914753496647,0.009465816430747509,0.009127238765358925,0.008430357091128826,0.008150054141879082,0.007862844504415989,0.00756662804633379,0.007448902819305658,0.007197706028819084,0.0071609956212341785,0.007118308451026678,0.007105776574462652,0.006906898692250252,0.006935414858162403,0.0068631465546786785,0.006825510412454605,0.006733493879437447,0.006828569807112217,0.006664113607257605,0.00663793133571744,0.006623105611652136,0.0066079203970730305,0.006524971686303616,0.006600435357540846,0.006535801105201244,0.009782303124666214,0.01111077144742012,0.01023025531321764,0.01062694564461708,0.011315378360450268,0.00986512005329132,0.009516078978776932,0.009717756882309914,0.009166819974780083,0.008243761956691742,0.008799021132290363,0.009457234293222427,0.00849161297082901,0.010591646656394005,0.010072407312691212,0.010053209029138088,0.009460452944040298,0.009402301162481308,0.008499633520841599,0.009923122823238373,0.009381117299199104,0.008777309209108353,0.009174068458378315,0.008038729429244995,0.008493601344525814,0.007566126529127359,0.0073320819064974785,0.006923917680978775,0.006474063266068697,0.006328894291073084,0.008410713635385036,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 33931     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 33932     
=================================================================
Total params: 67,863
Trainable params: 67,863
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 33,931
Trainable params: 33,931
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 33,932
Trainable params: 33,932
Non-trainable params: 0
_________________________________________________________________
