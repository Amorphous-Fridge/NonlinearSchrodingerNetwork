2021-06-26
loss,0.9040691256523132,0.4902113080024719,0.3926319181919098,0.3939327001571655,0.27728602290153503,0.24921266734600067,0.21666431427001953,0.16898207366466522,0.10947868973016739,0.0959911122918129,0.09052138030529022,0.08891548961400986,0.07945865392684937,0.08240680396556854,0.07314760237932205,0.07472681999206543,0.06312016397714615,0.05470224842429161,0.05095146596431732,0.04929950088262558,0.04683394357562065,0.051284074783325195,0.046552423387765884,0.04217517748475075,0.03787082061171532,0.05240190401673317,0.04223630577325821,0.03895382583141327,0.04125487431883812,0.04158606380224228,0.03146784380078316,0.03307783231139183,0.04082527011632919,0.034797780215740204,0.03759593144059181,0.037544358521699905,0.03386424109339714,0.028743617236614227,0.034312330186367035,0.029182039201259613,0.02848866395652294,0.025909798219799995,0.03475526347756386,0.030764998868107796,0.03558359667658806,0.03236563503742218,0.031153207644820213,0.029963325709104538,0.03051229938864708,0.030802913010120392,0.02904622256755829,0.027515240013599396,0.02591630257666111,0.027852220460772514,0.02556203305721283,0.02723662555217743,0.031102575361728668,0.026901543140411377,0.024429159238934517,0.02276402711868286,0.02703317441046238,0.027179958298802376,0.027971096336841583,0.026362700387835503,0.026649242267012596,0.026332277804613113,0.026112718507647514,0.026063410565257072,0.02479420229792595,0.024299509823322296,0.02575119584798813,0.02302459441125393,0.025919657200574875,0.022820131853222847,0.024152744561433792,0.023531876504421234,0.026597144082188606,0.026021329686045647,0.023332839831709862,0.02277553081512451,0.020856782793998718,0.022224633023142815,0.021297141909599304,0.021761581301689148,0.021874139085412025,0.021901914849877357,0.01796886883676052,0.021081065759062767,0.024111399427056313,0.024488015100359917,0.022448252886533737,0.020086755976080894,0.017975617200136185,0.02222847379744053,0.024210650473833084,0.020695915445685387,0.022122062742710114,0.020262528210878372,0.020955801010131836,0.021647239103913307,
mse,0.3016056418418884,0.06953072547912598,0.04380756989121437,0.0457768440246582,0.02392861433327198,0.019625980406999588,0.0144392941147089,0.008706378750503063,0.00343539216555655,0.002694386290386319,0.0025574981700628996,0.0023100306279957294,0.001804846222512424,0.002061224775388837,0.0015396710950881243,0.001633183564990759,0.001112289377488196,0.0008590224897488952,0.0007726316689513624,0.0007027678657323122,0.0006453152163885534,0.0007618405506946146,0.0006030170479789376,0.000495320069603622,0.00042640985338948667,0.0007796160643920302,0.000510857964400202,0.0004402106278575957,0.0004856265732087195,0.0004995620111003518,0.00029341146000660956,0.000323054613545537,0.000465017365058884,0.0003484927583485842,0.00041374005377292633,0.0004001680063083768,0.0003297214861959219,0.0002461534459143877,0.00034293546923436224,0.0002424547274131328,0.00023009564029052854,0.00019806399359367788,0.0003542466147337109,0.0002743363147601485,0.0003609570558182895,0.0003024199395440519,0.0002791978185996413,0.00025257389643229544,0.0002744611701928079,0.00026778195751830935,0.00023924265406094491,0.00021664121595676988,0.00019552888988982886,0.00022381468443199992,0.00019361285376362503,0.00020997131650801748,0.00028068124083802104,0.00021890306379646063,0.0001753567485138774,0.00015698086644988507,0.00021231082791928202,0.00021614431170746684,0.00022666488075628877,0.0002010493044508621,0.00020654351101256907,0.0001968966971617192,0.00019869048264808953,0.00019186096324119717,0.00018065172480419278,0.00017430138541385531,0.00019589027215261012,0.00015339202946051955,0.00018888017802964896,0.00015045434702187777,0.00016637152293697,0.00016139533545356244,0.00020060967653989792,0.00018928000645246357,0.00015639093180652708,0.0001506517583038658,0.00012788760068360716,0.00014348639524541795,0.00013470872363541275,0.00014255091082304716,0.0001378608722006902,0.00013818981824442744,9.836936078500003e-05,0.00012742061517201364,0.00016288631013594568,0.00017344528168905526,0.00014353283040691167,0.00011656605784082785,9.889488865155727e-05,0.00014257041038945317,0.0001688557822490111,0.00012242393859196454,0.00014174125681165606,0.000120912904094439,0.00012740692181978375,0.00013446366938296705,
mae,0.3871580958366394,0.2136923372745514,0.1711915135383606,0.17002199590206146,0.12257248163223267,0.10843890905380249,0.09226372838020325,0.07231183350086212,0.046984557062387466,0.04154009371995926,0.0389714278280735,0.038711126893758774,0.03418666124343872,0.03454384207725525,0.030531587079167366,0.03249134123325348,0.026245353743433952,0.02346322126686573,0.0217756275087595,0.021169133484363556,0.019912058487534523,0.022212574258446693,0.01995876617729664,0.017771070823073387,0.015959275886416435,0.02249276079237461,0.018047671765089035,0.016752973198890686,0.01740960031747818,0.017722947522997856,0.013405567035079002,0.013944989070296288,0.01724885404109955,0.01488767471164465,0.016217947006225586,0.01589999347925186,0.014477994292974472,0.012226120568811893,0.014281566254794598,0.01237926259636879,0.012286770157516003,0.010898241773247719,0.015003069303929806,0.012810653075575829,0.0154552161693573,0.013867964968085289,0.01341346837580204,0.012622027657926083,0.012988325208425522,0.013119922019541264,0.012213856913149357,0.01165897399187088,0.011050604283809662,0.011786038987338543,0.010663691908121109,0.01137915812432766,0.013331765308976173,0.011544513516128063,0.010346251539885998,0.009615770541131496,0.01134598720818758,0.011503535322844982,0.012077594175934792,0.01118497271090746,0.011260759085416794,0.011283048428595066,0.011269696056842804,0.011018362827599049,0.010563330724835396,0.010356124490499496,0.010925433598458767,0.009841522201895714,0.011034978553652763,0.009595466777682304,0.010281195864081383,0.009970122016966343,0.01137838326394558,0.011395568028092384,0.01000823825597763,0.009641568176448345,0.008866144344210625,0.009421269409358501,0.009095963090658188,0.009275347925722599,0.009323876351118088,0.009348214603960514,0.007699493784457445,0.00887165404856205,0.010438935831189156,0.01065817940980196,0.009383213706314564,0.008428922854363918,0.007530272006988525,0.009478306397795677,0.010460474528372288,0.008808021433651447,0.009339387528598309,0.008628176525235176,0.009005307219922543,0.009183383546769619,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 271507    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 271508    
=================================================================
Total params: 543,015
Trainable params: 543,015
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 271,507
Trainable params: 271,507
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 271,508
Trainable params: 271,508
Non-trainable params: 0
_________________________________________________________________
