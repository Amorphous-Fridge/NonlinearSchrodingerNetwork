2021-06-26
loss,0.36970603466033936,0.11807283759117126,0.07750649005174637,0.06931552290916443,0.07627538591623306,0.06819342821836472,0.06703266501426697,0.0704982802271843,0.08362902700901031,0.06993304938077927,0.07561380416154861,0.08395583182573318,0.07072457671165466,0.06040997430682182,0.05432794988155365,0.0501752644777298,0.04484336078166962,0.05207475274801254,0.05220174789428711,0.048872824758291245,0.059293657541275024,0.04834652319550514,0.04352053627371788,0.04059514030814171,0.03858095034956932,0.054244328290224075,0.05415172502398491,0.05342184007167816,0.043316300958395004,0.03871122747659683,0.035734035074710846,0.04893970489501953,0.05323774367570877,0.04413891211152077,0.03631642088294029,0.034871283918619156,0.03423959016799927,0.032585106790065765,0.03651519864797592,0.04849042370915413,0.043756041675806046,0.04252033680677414,0.03854159265756607,0.027866587042808533,0.02304195426404476,0.022426757961511612,0.022174347192049026,0.021969864144921303,0.02163868211209774,0.021630899980664253,0.021469371393322945,0.0212068110704422,0.02114684320986271,0.02091873250901699,0.02090759575366974,0.0206703320145607,0.020495615899562836,0.020465528592467308,0.020423967391252518,0.020954662933945656,0.032871730625629425,0.034306179732084274,0.03168170526623726,0.03400605171918869,0.0245546605437994,0.025754863396286964,0.03285485506057739,0.033877842128276825,0.029935216531157494,0.02689482644200325,0.02976800687611103,0.03285013511776924,0.033690281212329865,0.029452377930283546,0.02522393688559532,0.026317665353417397,0.03268241137266159,0.03081165812909603,0.027537420392036438,0.025980114936828613,0.023673463612794876,0.028883831575512886,0.025907782837748528,0.02760731428861618,0.02764993906021118,0.02679211087524891,0.023607486858963966,0.02493196912109852,0.028373217210173607,0.026406068354845047,0.024595022201538086,0.02360006980597973,0.022675052285194397,0.021695313975214958,0.02332484722137451,0.024870116263628006,0.025525236502289772,0.03010299615561962,0.02764619141817093,0.025812610983848572,
mse,0.05593365803360939,0.004754199180752039,0.0017790519632399082,0.001451017684303224,0.0017017130739986897,0.0013468689285218716,0.0012693987227976322,0.001506494591012597,0.001979917986318469,0.001374551560729742,0.0017033180920407176,0.001966455951333046,0.0013787884963676333,0.0010344075271859765,0.0008430242305621505,0.0007258713012561202,0.0005789033602923155,0.0008153512608259916,0.0007948203128762543,0.0007119503570720553,0.0009966621873900294,0.0006586196250282228,0.0005310056149028242,0.0004655351513065398,0.00042465515434741974,0.0008524029981344938,0.0008481025579385459,0.0007978552603162825,0.00054480618564412,0.00042418710654601455,0.00036972801899537444,0.0006761671393178403,0.0007784658810123801,0.0005428731674328446,0.0003797866520471871,0.0003505281638354063,0.0003350373008288443,0.00031050751567818224,0.0003792784991674125,0.0006398531841114163,0.0005405379924923182,0.0005043703713454306,0.0004158059018664062,0.00023752350534778088,0.00015429167251568288,0.00014186272164806724,0.0001381317269988358,0.00013506770483218133,0.0001333537802565843,0.00013042149657849222,0.00012760395475197583,0.00012498190335463732,0.000123557576444,0.0001217337412526831,0.00012022945156786591,0.00011810340220108628,0.00011683712364174426,0.00011771314166253433,0.00011497261584736407,0.00012919100117869675,0.00030903329025022686,0.00032805383671075106,0.0002834409533534199,0.00031177562777884305,0.00017822740483097732,0.00019088400586042553,0.00030961583252064884,0.00031474229763261974,0.00024395849322900176,0.0002043133572442457,0.0002515886735636741,0.00029661544249393046,0.00030935031827539206,0.0002495610387995839,0.00018543338228482753,0.00019764866738114506,0.00029228595667518675,0.0002582209708634764,0.0002113691152771935,0.00019001090549863875,0.0001620144466869533,0.00023786199744790792,0.00018933005048893392,0.00021718423522543162,0.00021013038349337876,0.00020077220688108355,0.0001636634551687166,0.00017476761422585696,0.00022534506570082158,0.00018929102225229144,0.00016636679356452078,0.00015405866724904627,0.00014326415839605033,0.00013539072824642062,0.00015704831457696855,0.00017146462050732225,0.00018368106975685805,0.00025129030109383166,0.00020905332348775119,0.00018383389397058636,
mae,0.15856996178627014,0.05047239363193512,0.033087968826293945,0.029617877677083015,0.03256800398230553,0.029116692021489143,0.028283212333917618,0.030422357842326164,0.03676441311836243,0.030543575063347816,0.03278271108865738,0.03730671480298042,0.03169582039117813,0.024445831775665283,0.021917272359132767,0.020443720743060112,0.018698260188102722,0.022243557497859,0.022005224600434303,0.020756792277097702,0.025872206315398216,0.0206129290163517,0.01852571591734886,0.017338866367936134,0.016510356217622757,0.023364895954728127,0.02334052510559559,0.023824622854590416,0.01874520443379879,0.01618455909192562,0.01523070689290762,0.021226679906249046,0.02279670536518097,0.01979023776948452,0.01512825582176447,0.014609472826123238,0.014258777722716331,0.013773714192211628,0.015382596291601658,0.020633036270737648,0.01865709386765957,0.01838047057390213,0.016843605786561966,0.011790193617343903,0.009788580238819122,0.009446749463677406,0.009259369224309921,0.009406501427292824,0.00916178897023201,0.009311921894550323,0.009021349251270294,0.009097832255065441,0.00900191068649292,0.008940502069890499,0.008868865668773651,0.008704813197255135,0.008822585456073284,0.008679721504449844,0.008890957571566105,0.008913183584809303,0.014118864201009274,0.014497057534754276,0.01358901895582676,0.014328905381262302,0.010325226001441479,0.010656236670911312,0.013978617265820503,0.013995642773807049,0.012484525330364704,0.011335086077451706,0.012757216580212116,0.014222928322851658,0.014555380679666996,0.012612143531441689,0.010615143924951553,0.010624242015182972,0.013772084377706051,0.013410176150500774,0.01221921481192112,0.011050425469875336,0.010039519518613815,0.012436795979738235,0.010867313481867313,0.011756295338273048,0.011699170805513859,0.011251444928348064,0.010015872307121754,0.010699069127440453,0.012210340239107609,0.010991150513291359,0.010278509929776192,0.010029378347098827,0.009749666787683964,0.00934319943189621,0.009852715767920017,0.010295468382537365,0.010677985846996307,0.012833335436880589,0.011998189613223076,0.011566686443984509,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 14195     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 14196     
=================================================================
Total params: 28,391
Trainable params: 28,391
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 14,195
Trainable params: 14,195
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 14,196
Trainable params: 14,196
Non-trainable params: 0
_________________________________________________________________
