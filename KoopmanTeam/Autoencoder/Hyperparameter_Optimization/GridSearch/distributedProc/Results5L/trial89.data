2021-06-26
loss,0.9371041655540466,0.4022858738899231,0.38275980949401855,0.37252578139305115,0.3574713468551636,0.31117814779281616,0.26162075996398926,0.24550117552280426,0.2332799881696701,0.2256641834974289,0.21867458522319794,0.20246179401874542,0.19688723981380463,0.211649551987648,0.16266950964927673,0.11827345937490463,0.12146804481744766,0.12295365333557129,0.08276434242725372,0.096075639128685,0.08185461908578873,0.07651936262845993,0.06494883447885513,0.06371422111988068,0.06362209469079971,0.053237032145261765,0.053207941353321075,0.051318928599357605,0.046028491109609604,0.04996708407998085,0.046542197465896606,0.05406050756573677,0.05094783008098602,0.049881838262081146,0.04498675465583801,0.04900774359703064,0.03783336281776428,0.038122329860925674,0.0330866277217865,0.04379262775182724,0.04194597899913788,0.04094165936112404,0.03846120834350586,0.03310560807585716,0.02992389164865017,0.038369134068489075,0.03642614558339119,0.03293566405773163,0.03852338343858719,0.03390854224562645,0.030776483938097954,0.03126342222094536,0.03276063874363899,0.03074064664542675,0.03289640694856644,0.029848743230104446,0.025487985461950302,0.0296719241887331,0.03134763613343239,0.028840666636824608,0.030842294916510582,0.025939367711544037,0.02456352859735489,0.02982933446764946,0.029494082555174828,0.026130277663469315,0.028700949624180794,0.029058951884508133,0.026021545752882957,0.02799925021827221,0.02512495219707489,0.02629133313894272,0.02817855030298233,0.025461433455348015,0.02286624349653721,0.025503918528556824,0.023447522893548012,0.02327125519514084,0.02460298128426075,0.02366359531879425,0.02833138406276703,0.02402658946812153,0.022446293383836746,0.023615991696715355,0.02206205390393734,0.024254102259874344,0.02247960865497589,0.025347664952278137,0.02226404845714569,0.019826767966151237,0.022527705878019333,0.02395135723054409,0.026595206931233406,0.021793734282255173,0.022552737966179848,0.022390414029359818,0.021761862561106682,0.019391991198062897,0.01945500448346138,0.022904396057128906,
mse,0.38945528864860535,0.046078551560640335,0.04209868982434273,0.04023662209510803,0.03719639778137207,0.029469233006238937,0.02168363146483898,0.01944967359304428,0.017926868051290512,0.017090139910578728,0.015948878601193428,0.013905933126807213,0.012798434123396873,0.014465179294347763,0.008035925216972828,0.004168896470218897,0.004414499271661043,0.004287945106625557,0.0020544929429888725,0.002723042154684663,0.0019478854956105351,0.0017389400163665414,0.0012373505160212517,0.0011499084066599607,0.001135584432631731,0.000811501347925514,0.0008354767924174666,0.0007681303541176021,0.0006067696958780289,0.0006938503938727081,0.0006212019361555576,0.0008290351834148169,0.0007287914049811661,0.0006860440480522811,0.0005775531171821058,0.0006681995000690222,0.0004148618900217116,0.00042069877963513136,0.0003155931772198528,0.0005499207763932645,0.0004914334858767688,0.00047962128883227706,0.0004135102790314704,0.00031888578087091446,0.0002694852009881288,0.0004124593979213387,0.0003726462018676102,0.00030250896816141903,0.00041340210009366274,0.00031798414420336485,0.00026596864336170256,0.00027436247910372913,0.00030666496604681015,0.00026565129519440234,0.00030054544913582504,0.0002517255488783121,0.00019424666243139654,0.00024482456501573324,0.00027822863194160163,0.00023390473506879061,0.00026587306638248265,0.0001888802507892251,0.00017621512233745307,0.0002502778370399028,0.00023744269856251776,0.0001947489072335884,0.0002336970210308209,0.00023796244931872934,0.00019167602295055985,0.0002190153900301084,0.00018194332369603217,0.0001918539055623114,0.00022416395950131118,0.00018223196093458682,0.00015009618073236197,0.00018301860836800188,0.00015699049981776625,0.00015786400763317943,0.0001719394640531391,0.00016516930190846324,0.00022365165932569653,0.00016367343778256327,0.00014657022256869823,0.00015825680748093873,0.00014113054203335196,0.00016667578893247992,0.00014482549158856273,0.00017895144992507994,0.0001377462613163516,0.00011828535207314417,0.0001466840476496145,0.00016374005645047873,0.00019912321295123547,0.00013618828961625695,0.00014692415425088257,0.0001447351969545707,0.0001332468236796558,0.0001094770705094561,0.00011351282591931522,0.0001497517223469913,
mae,0.4149032235145569,0.17553597688674927,0.1668747365474701,0.16248875856399536,0.15559855103492737,0.1350320726633072,0.11539461463689804,0.10676922649145126,0.10012736916542053,0.09552408009767532,0.0927930474281311,0.08568014204502106,0.08386436104774475,0.09002378582954407,0.06889473646879196,0.05042802914977074,0.05193597450852394,0.05227591097354889,0.03522615507245064,0.03935058042407036,0.034851547330617905,0.03241701051592827,0.02753492072224617,0.026862675324082375,0.02664186991751194,0.022485844790935516,0.022508248686790466,0.02194494940340519,0.019406963139772415,0.02118627354502678,0.019760973751544952,0.022754404693841934,0.021708378568291664,0.021305959671735764,0.01905801333487034,0.02113342098891735,0.015490743331611156,0.016299914568662643,0.013888174667954445,0.01844315603375435,0.017675405368208885,0.017330503091216087,0.016513917595148087,0.014138035476207733,0.012657860293984413,0.015976082533597946,0.015608498826622963,0.013956321403384209,0.01635533757507801,0.014395534060895443,0.012935071252286434,0.013335254974663258,0.01385543029755354,0.01313374750316143,0.014194500632584095,0.012857211753726006,0.010905884206295013,0.012640428729355335,0.01325635239481926,0.012071759440004826,0.01308831013739109,0.010637093335390091,0.010410758666694164,0.012724202126264572,0.012565413489937782,0.011117561720311642,0.012316732667386532,0.0122701870277524,0.010866576805710793,0.0115888062864542,0.010668857954442501,0.010957407765090466,0.011973807588219643,0.01090655941516161,0.009616564959287643,0.010838914662599564,0.009915809147059917,0.009929915890097618,0.010768868029117584,0.01009528897702694,0.012102162465453148,0.01019211020320654,0.009609834291040897,0.009925205260515213,0.009275988675653934,0.01013367809355259,0.0095328688621521,0.0107169970870018,0.009389099664986134,0.008345436304807663,0.00949756521731615,0.010138035751879215,0.011662326753139496,0.009380390867590904,0.009497418068349361,0.009648756124079227,0.009188259020447731,0.008135580457746983,0.008192731067538261,0.009730033576488495,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 203795    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 203796    
=================================================================
Total params: 407,591
Trainable params: 407,591
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 203,795
Trainable params: 203,795
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 203,796
Trainable params: 203,796
Non-trainable params: 0
_________________________________________________________________
