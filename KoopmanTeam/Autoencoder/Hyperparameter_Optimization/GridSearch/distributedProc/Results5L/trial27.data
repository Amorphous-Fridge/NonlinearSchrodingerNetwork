2021-06-26
loss,0.3720167577266693,0.19340747594833374,0.08821901679039001,0.06133906915783882,0.05602247267961502,0.04411506652832031,0.041059546172618866,0.038616396486759186,0.04853639006614685,0.05417407676577568,0.048541292548179626,0.03258878365159035,0.027881188318133354,0.028846951201558113,0.027451515197753906,0.026301827281713486,0.026474814862012863,0.02551399916410446,0.025031842291355133,0.02440638840198517,0.023719845339655876,0.02320653200149536,0.02283472754061222,0.02247757650911808,0.021734261885285378,0.021600447595119476,0.021477777510881424,0.02634838968515396,0.030974578112363815,0.0323600135743618,0.03466452285647392,0.030764389783143997,0.03202002868056297,0.028424622491002083,0.019046349450945854,0.01802734285593033,0.017609354108572006,0.017319845035672188,0.01726682111620903,0.017278261482715607,0.017126766964793205,0.017195366322994232,0.017003560438752174,0.016704313457012177,0.01681561954319477,0.016671348363161087,0.016679590567946434,0.016585292294621468,0.016472067683935165,0.016369592398405075,0.016193103045225143,0.016141030937433243,0.01606637053191662,0.015971357002854347,0.01593237742781639,0.015764879062771797,0.01571275293827057,0.015540177002549171,0.015418300405144691,0.015506519004702568,0.01525590755045414,0.015319977886974812,0.01528820302337408,0.015163492411375046,0.015074606984853745,0.014942892827093601,0.01484158355742693,0.014715743251144886,0.014730194583535194,0.014759239740669727,0.01459421031177044,0.014505386352539062,0.014491729438304901,0.01451190561056137,0.014365831390023232,0.014339473098516464,0.014349482022225857,0.014141874387860298,0.014150619506835938,0.01407648529857397,0.013967751525342464,0.013986194506287575,0.013909592293202877,0.013759536668658257,0.013866269960999489,0.013651188462972641,0.01373677235096693,0.013659339398145676,0.013501436449587345,0.013516701757907867,0.013531621545553207,0.013544038869440556,0.013372784480452538,0.013325636275112629,0.013346748426556587,0.013343194499611855,0.013258865103125572,0.013060415163636208,0.013144765049219131,0.013024603016674519,
mse,0.055284932255744934,0.013476861640810966,0.0023964629508554935,0.0011746544623747468,0.0009349478641524911,0.0005808838177472353,0.0004944754764437675,0.0004378921876195818,0.000695207214448601,0.0008544056909158826,0.0006822337745688856,0.0003205268585588783,0.00023309077369049191,0.0002467575541231781,0.0002195119159296155,0.00020235119154676795,0.00020815414609387517,0.00019089473062194884,0.00018293764151167125,0.00017356325406581163,0.0001634829241083935,0.0001566331775393337,0.00015345608699135482,0.00014643459871876985,0.00013761415902990848,0.00013483746442943811,0.000136160000693053,0.00021895140525884926,0.0002805257390718907,0.0003039943694602698,0.00034418117138557136,0.0002771704748738557,0.00029436961631290615,0.00023621012223884463,0.00010869037214433774,9.558312012813985e-05,9.080999734578654e-05,8.804621029412374e-05,8.690071263117716e-05,8.681636245455593e-05,8.520722622051835e-05,8.545372838852927e-05,8.338436600752175e-05,8.156496187439188e-05,8.210489613702521e-05,8.141236321534961e-05,8.055561920627952e-05,8.014005288714543e-05,7.84967269282788e-05,7.728898344794288e-05,7.611451292177662e-05,7.639941031811759e-05,7.480136264348403e-05,7.39727693144232e-05,7.409744284814224e-05,7.264724263222888e-05,7.114088657544926e-05,7.00311065884307e-05,6.911260425113142e-05,7.018906035227701e-05,6.73502727295272e-05,6.82623649481684e-05,6.698034121654928e-05,6.652120646322146e-05,6.532553379656747e-05,6.439663411583751e-05,6.389457848854363e-05,6.243817188078538e-05,6.283528637140989e-05,6.306657451204956e-05,6.128315726527944e-05,6.11713549005799e-05,6.107755325501785e-05,6.056261190678924e-05,6.027329800417647e-05,5.9918034821748734e-05,5.9633377532009035e-05,5.776064790552482e-05,5.81418389629107e-05,5.701862755813636e-05,5.6140535889426246e-05,5.680620233761147e-05,5.581895311479457e-05,5.5179320042952895e-05,5.562694786931388e-05,5.444192356662825e-05,5.464744754135609e-05,5.456990038510412e-05,5.3331001254264265e-05,5.271425470709801e-05,5.2725001296494156e-05,5.319330011843704e-05,5.176100239623338e-05,5.131781654199585e-05,5.169215000933036e-05,5.168459756532684e-05,5.086987584945746e-05,4.9413130909670144e-05,4.974356488673948e-05,4.947749403072521e-05,
mae,0.15805038809776306,0.07756728678941727,0.03678199276328087,0.025385640561580658,0.02320859022438526,0.018369868397712708,0.017100654542446136,0.016164207831025124,0.020177878439426422,0.022478634491562843,0.019864026457071304,0.01359906792640686,0.011668792925775051,0.012024393305182457,0.011320650577545166,0.010965067893266678,0.011060328222811222,0.010679044760763645,0.010517929680645466,0.010210167616605759,0.009945324622094631,0.009733139537274837,0.009551499038934708,0.009349566884338856,0.00907172728329897,0.009042466059327126,0.009021155536174774,0.011086302809417248,0.013075754977762699,0.013637328520417213,0.014445421285927296,0.012878566980361938,0.013275827281177044,0.011619490571320057,0.00800977274775505,0.007519501261413097,0.00733500299975276,0.00720958411693573,0.007240112405270338,0.007204845547676086,0.007201578468084335,0.007207775488495827,0.00710851326584816,0.007034044712781906,0.007038513198494911,0.007018071599304676,0.006984400562942028,0.006982850842177868,0.006906353402882814,0.006861576810479164,0.006786355283111334,0.006737553980201483,0.006732172332704067,0.0067041111178696156,0.0066699255257844925,0.006615203805267811,0.006584921386092901,0.006520600523799658,0.006508599501103163,0.006501604802906513,0.006455694325268269,0.006418743170797825,0.006402075756341219,0.0063567268662154675,0.006297094281762838,0.006277980748564005,0.006245298311114311,0.006094830110669136,0.006193394772708416,0.006192248314619064,0.006093357224017382,0.006109409499913454,0.006111689377576113,0.006062808446586132,0.006021501030772924,0.0060290563851594925,0.006022794172167778,0.0059380196034908295,0.005936503876000643,0.005967265926301479,0.0058621810749173164,0.0058634621091187,0.005822354461997747,0.005777248181402683,0.005801809020340443,0.005695615895092487,0.0057914974167943,0.005720878019928932,0.0056653679348528385,0.005707316566258669,0.005725167226046324,0.005683863069862127,0.0056028347462415695,0.00561889773234725,0.005585271865129471,0.005589723587036133,0.005578238517045975,0.005476734600961208,0.005492693744599819,0.005470131523907185,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 13051     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 13052     
=================================================================
Total params: 26,103
Trainable params: 26,103
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 13,051
Trainable params: 13,051
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 13,052
Trainable params: 13,052
Non-trainable params: 0
_________________________________________________________________
