2021-06-26
loss,0.656039834022522,0.3015068769454956,0.2653138041496277,0.2495516985654831,0.2369161993265152,0.23347711563110352,0.23311983048915863,0.22560158371925354,0.19156481325626373,0.13252854347229004,0.13082677125930786,0.09533390402793884,0.08462564647197723,0.08655889332294464,0.05967552214860916,0.07615477591753006,0.05431082844734192,0.053250752389431,0.060481395572423935,0.05221298336982727,0.04886813461780548,0.05682366341352463,0.04605035483837128,0.04304103925824165,0.045234084129333496,0.03978882357478142,0.04939370974898338,0.0431380458176136,0.03733673691749573,0.03371335193514824,0.04198442026972771,0.029035920277237892,0.03715132549405098,0.034080322831869125,0.03853629529476166,0.041919056326150894,0.030740467831492424,0.03805272653698921,0.03957391530275345,0.03738465905189514,0.031151192262768745,0.03449449688196182,0.03261158615350723,0.029478559270501137,0.029572052881121635,0.03232746943831444,0.03266254812479019,0.03778073936700821,0.03465402498841286,0.03299839422106743,0.03017287328839302,0.02870277687907219,0.031333912163972855,0.03162567317485809,0.027863960713148117,0.026949720457196236,0.030543329194188118,0.029235130175948143,0.03098009154200554,0.02658643014729023,0.02472653239965439,0.030384989455342293,0.02744908630847931,0.03159834444522858,0.027329592034220695,0.026567600667476654,0.025161029770970345,0.026047654449939728,0.02762392908334732,0.023412831127643585,0.02600955218076706,0.028498707339167595,0.027949409559369087,0.02482645772397518,0.029530838131904602,0.024344060570001602,0.02491704933345318,0.0245694350451231,0.024181419983506203,0.023002272471785545,0.026952669024467468,0.02600698731839657,0.022920679301023483,0.023639440536499023,0.024330513551831245,0.023396886885166168,0.02752099186182022,0.026838863268494606,0.023389006033539772,0.020247526466846466,0.019014494493603706,0.022439701482653618,0.025472573935985565,0.024531951174139977,0.021648645401000977,0.022693634033203125,0.021245285868644714,0.023150639608502388,0.023395564407110214,0.0235122200101614,
mse,0.1797483116388321,0.027912849560379982,0.022585147991776466,0.020705724135041237,0.01950553059577942,0.01908976025879383,0.018905645236372948,0.017990093678236008,0.012602325528860092,0.005522577092051506,0.005119851790368557,0.0025866113137453794,0.0020461641252040863,0.0021770379971712828,0.001158813713118434,0.001641828683204949,0.0008628262439742684,0.0008113490766845644,0.001060758950188756,0.0007831063703633845,0.000681268225889653,0.0009230024879798293,0.0006006356561556458,0.000531959580257535,0.0006008405471220613,0.0004544104740489274,0.0007018472533673048,0.0005315399612300098,0.0003997336025349796,0.0003362107672728598,0.000503657094668597,0.0002555097744334489,0.00038710545049980283,0.00032860354986041784,0.00042526013567112386,0.0004888479015789926,0.00027418616809882224,0.00040331686614081264,0.00043276819633319974,0.00038902810774743557,0.0002790183061733842,0.00034007735666818917,0.0003033131069969386,0.0002551197540014982,0.0002506529272068292,0.00029102948610670865,0.0003034162800759077,0.0003937639994546771,0.00033749014255590737,0.0003022078308276832,0.00025557843036949635,0.00023335596779361367,0.0002765602548606694,0.0002810807782225311,0.00022479923791252077,0.00021164288045838475,0.00025786174228414893,0.00024325847334694117,0.00026649778010323644,0.00019713629444595426,0.00017491707694716752,0.00025876107974909246,0.0002161436714231968,0.0002782978699542582,0.0002114980889018625,0.00019966984109487385,0.00018000164709519595,0.00019502876966726035,0.00020983316062483937,0.0001558077201480046,0.00019440252799540758,0.00022711117344442755,0.00021804700372740626,0.0001787907094694674,0.00024024362210184336,0.00016875356959644705,0.00017751503037288785,0.00017290408140979707,0.0001649176119826734,0.00014933546481188387,0.0002059210673905909,0.0001893651351565495,0.0001474411110393703,0.00016229256289079785,0.00016579622752033174,0.00015815401275176555,0.0002127865154761821,0.0002017103834077716,0.00015188389807008207,0.00011871652532136068,0.00011036505020456389,0.00014946541341487318,0.00018491789523977786,0.00016606831923127174,0.0001342933246633038,0.00014537351671606302,0.00013533732271753252,0.00015369485481642187,0.00015919056022539735,0.0001550927700009197,
mae,0.28234022855758667,0.13056646287441254,0.11220519989728928,0.1053958311676979,0.09832260757684708,0.09678556770086288,0.09534329175949097,0.09515121579170227,0.0822085365653038,0.056187354028224945,0.054159220308065414,0.03982897475361824,0.03563692420721054,0.0355713926255703,0.0250842422246933,0.032267965376377106,0.023243799805641174,0.02260279841721058,0.025478553026914597,0.02174200303852558,0.020541273057460785,0.02387695014476776,0.019168822094798088,0.018252437934279442,0.018910294398665428,0.01673193648457527,0.020439593121409416,0.017938809469342232,0.015864664688706398,0.014197333715856075,0.017938876524567604,0.01242164894938469,0.015709221363067627,0.014440754428505898,0.016202788800001144,0.017573395743966103,0.012786333449184895,0.015995969995856285,0.017209002748131752,0.016143161803483963,0.013269386254251003,0.014481824822723866,0.01389012299478054,0.012391862459480762,0.012252207845449448,0.01363774761557579,0.013476320542395115,0.015967082232236862,0.014974662102758884,0.013481582514941692,0.013083565980196,0.011947345919907093,0.013215051963925362,0.013656857423484325,0.011720426380634308,0.011394425295293331,0.012399304658174515,0.012500646524131298,0.01324542984366417,0.011368832550942898,0.010362928733229637,0.012902663089334965,0.01182325929403305,0.013562357053160667,0.011607997119426727,0.01130367536097765,0.010597839020192623,0.011008871719241142,0.01184785645455122,0.009899784810841084,0.010857406072318554,0.011945480480790138,0.01182476058602333,0.010630806908011436,0.012045469135046005,0.010256235487759113,0.010659282095730305,0.0103761563077569,0.010144034400582314,0.009621663950383663,0.011685128323733807,0.011415920220315456,0.010035227984189987,0.010048052296042442,0.010330059565603733,0.009990070946514606,0.01179494708776474,0.010860254988074303,0.01000833511352539,0.008430320769548416,0.007983346469700336,0.009476132690906525,0.010548276826739311,0.01030647847801447,0.009389838203787804,0.00968498270958662,0.008877161890268326,0.009946358390152454,0.00995122455060482,0.010055298916995525,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 135027    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 135028    
=================================================================
Total params: 270,055
Trainable params: 270,055
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 135,027
Trainable params: 135,027
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 135,028
Trainable params: 135,028
Non-trainable params: 0
_________________________________________________________________
