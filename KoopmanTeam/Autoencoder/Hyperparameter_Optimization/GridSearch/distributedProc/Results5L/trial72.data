2021-06-26
loss,0.5764179825782776,0.2287004142999649,0.20202071964740753,0.1594701111316681,0.09874138981103897,0.11479458957910538,0.09143931418657303,0.11005306988954544,0.09211066365242004,0.08503029495477676,0.0787685289978981,0.07731331139802933,0.0743161141872406,0.05714084580540657,0.060170747339725494,0.06830040365457535,0.06193095073103905,0.059728898108005524,0.05454052612185478,0.05852636322379112,0.0585261769592762,0.04607515409588814,0.043469734489917755,0.05278167128562927,0.05001720041036606,0.047471847385168076,0.040520764887332916,0.040573712438344955,0.045329149812459946,0.050272755324840546,0.04254705831408501,0.041853319853544235,0.03621894493699074,0.037455152720212936,0.04287320002913475,0.04258625954389572,0.035015448927879333,0.029691480100154877,0.030796373263001442,0.031480882316827774,0.040706634521484375,0.03581709787249565,0.03551255166530609,0.03746417164802551,0.03913700208067894,0.033916834741830826,0.03306528553366661,0.03137936070561409,0.03908667713403702,0.03491968661546707,0.0336456336081028,0.03204133361577988,0.029293138533830643,0.027019191533327103,0.027367250993847847,0.03477388620376587,0.029861001297831535,0.03214909881353378,0.02944038063287735,0.029551556333899498,0.025907309725880623,0.02961338497698307,0.03187958896160126,0.026322072371840477,0.0276784710586071,0.02581907995045185,0.026973633095622063,0.02627345360815525,0.03029799647629261,0.02725222334265709,0.02579856663942337,0.026636779308319092,0.027420757338404655,0.026066854596138,0.026604365557432175,0.023917803540825844,0.025323204696178436,0.026620788499712944,0.02382412739098072,0.020736584439873695,0.017402492463588715,0.018765879794955254,0.02287728525698185,0.023296179249882698,0.022668106481432915,0.029260840266942978,0.025174055248498917,0.02448708936572075,0.02563082054257393,0.02525116503238678,0.0240559671074152,0.022540640085935593,0.021321943029761314,0.022054873406887054,0.024589212611317635,0.02400912530720234,0.02301671914756298,0.023352129384875298,0.02372690662741661,0.020384609699249268,
mse,0.1596439927816391,0.017472952604293823,0.012282726354897022,0.00754763837903738,0.002970894332975149,0.0037320596165955067,0.002386257750913501,0.003563838079571724,0.0024505939800292253,0.0021210303530097008,0.0017945669824257493,0.0017831420991569757,0.0016003840137273073,0.0009216055041179061,0.001051151193678379,0.0013304677559062839,0.001079820329323411,0.0010317254345864058,0.0008614355465397239,0.0009839560370892286,0.0009688665741123259,0.000632353825494647,0.0005487088346853852,0.0007939870120026171,0.0007131429156288505,0.0006368724280036986,0.00046062536421231925,0.00047157693188637495,0.0005855172639712691,0.0007192377815954387,0.0005203854525461793,0.0005035610520280898,0.0003730404132511467,0.0004129633598495275,0.0005199689185246825,0.0005095020169392228,0.00036323911626823246,0.0002612289390526712,0.00027583641349337995,0.0002877074875868857,0.00047145452117547393,0.00036599289160221815,0.0003618891933001578,0.0003943666524719447,0.00043736171210184693,0.0003224682295694947,0.00030580232851207256,0.0002819187648128718,0.0004256606043782085,0.00034600048093125224,0.00031601102091372013,0.00029498329968191683,0.00024690022110007703,0.00020856567425653338,0.0002166997583117336,0.0003363695868756622,0.00025319657288491726,0.00029234032263047993,0.00024110589583870023,0.00024081990704871714,0.00019176903879269958,0.00025438322336412966,0.0002880195388570428,0.00019676145166158676,0.00021951903181616217,0.00019313747179694474,0.00021039559214841574,0.00019480613991618156,0.00025832123355939984,0.00021382590057328343,0.0001940775546245277,0.00020379577472340316,0.00021293776808306575,0.00019548300770111382,0.00020127125026192516,0.00016329213394783437,0.00017970615590456873,0.00020010584557894617,0.00016108076670207083,0.0001279571879422292,9.30719543248415e-05,0.0001074868268915452,0.00014812391600571573,0.00015497174172196537,0.00015165242075454444,0.0002407784922979772,0.00017594177916180342,0.0001732275850372389,0.000184451651875861,0.00018301245290786028,0.00016766850603744388,0.00014401949010789394,0.00013299137935973704,0.00014009671576786786,0.00016979381325654685,0.0001627008750801906,0.00014761716010980308,0.00015629510744474828,0.00015946291387081146,0.00012493529357016087,
mae,0.25006094574928284,0.0953347235918045,0.08687298744916916,0.0680663138628006,0.04172082990407944,0.04854967072606087,0.03823092207312584,0.04808409512042999,0.039438992738723755,0.037340402603149414,0.03354690223932266,0.033524636179208755,0.03181568533182144,0.02398988977074623,0.025851737707853317,0.029209457337856293,0.026145100593566895,0.025316700339317322,0.023161306977272034,0.024884182959794998,0.025021018460392952,0.01936264894902706,0.01820925995707512,0.02287791296839714,0.022010445594787598,0.020064575597643852,0.017094064503908157,0.01702582649886608,0.01929745264351368,0.021655922755599022,0.018267808482050896,0.01773247867822647,0.01532738097012043,0.015775788575410843,0.018489381298422813,0.01828206703066826,0.014431560412049294,0.012537133879959583,0.013041403144598007,0.013464449904859066,0.017337294295430183,0.015425474382936954,0.014977831393480301,0.01573987677693367,0.016948914155364037,0.014153280295431614,0.014096057042479515,0.013218095526099205,0.017005126923322678,0.015139274299144745,0.014178644865751266,0.013602783903479576,0.012327093631029129,0.011503167450428009,0.01166732981801033,0.01462144497781992,0.012734906747937202,0.013706166297197342,0.012527283281087875,0.012471492402255535,0.010874411091208458,0.012578022666275501,0.01382175087928772,0.01117037609219551,0.011783814057707787,0.010772358626127243,0.01142042875289917,0.010954000055789948,0.013078571297228336,0.011768089607357979,0.010881718248128891,0.011345796287059784,0.011676767840981483,0.010929593816399574,0.011173977516591549,0.01019463874399662,0.010790053755044937,0.011333458125591278,0.009839678183197975,0.008746430277824402,0.007400758098810911,0.008074870333075523,0.009900248609483242,0.009954247623682022,0.009620975703001022,0.012564555741846561,0.010748577304184437,0.010430723428726196,0.011099903844296932,0.010713046416640282,0.010147693566977978,0.009716817177832127,0.009042792022228241,0.009320434182882309,0.010432732291519642,0.010352215729653835,0.009740340523421764,0.010024436749517918,0.010213254950940609,0.008702106773853302,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 100619    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 100620    
=================================================================
Total params: 201,239
Trainable params: 201,239
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 100,619
Trainable params: 100,619
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 100,620
Trainable params: 100,620
Non-trainable params: 0
_________________________________________________________________
