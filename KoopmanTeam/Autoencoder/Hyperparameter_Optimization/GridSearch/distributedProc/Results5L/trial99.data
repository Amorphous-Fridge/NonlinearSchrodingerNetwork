2021-06-26
loss,0.8928535580635071,0.35756930708885193,0.36634981632232666,0.27589502930641174,0.2491503208875656,0.2297147512435913,0.2190287709236145,0.2070266753435135,0.24666206538677216,0.1516677886247635,0.14728693664073944,0.12863922119140625,0.11896703392267227,0.10363789647817612,0.08551494777202606,0.09836146235466003,0.07096877694129944,0.06693289428949356,0.06632711738348007,0.07342589646577835,0.05201110243797302,0.04535891115665436,0.055656980723142624,0.060176774859428406,0.05125238746404648,0.0614330917596817,0.06062217801809311,0.05380212888121605,0.04630391299724579,0.04711843654513359,0.04494756832718849,0.03557306155562401,0.04124040529131889,0.04324531927704811,0.05073617771267891,0.04017282649874687,0.041285060346126556,0.04197380691766739,0.041744980961084366,0.03826478123664856,0.03849323093891144,0.03375980257987976,0.03495081514120102,0.037683747708797455,0.04007503017783165,0.03608431667089462,0.03488953039050102,0.03584660217165947,0.03475044295191765,0.03388659656047821,0.03408288210630417,0.0357196219265461,0.033254049718379974,0.026147516444325447,0.029931461438536644,0.03067777305841446,0.03131798654794693,0.034700606018304825,0.03222279250621796,0.033045802265405655,0.030031083151698112,0.028907161206007004,0.02216632291674614,0.024608666077256203,0.03130091354250908,0.026321280747652054,0.029332585632801056,0.028855834156274796,0.025945832952857018,0.02966799959540367,0.02627911977469921,0.029913177713751793,0.025716770440340042,0.028027456253767014,0.025460591539740562,0.027111709117889404,0.028239138424396515,0.028811870142817497,0.024711277335882187,0.022863147780299187,0.02495560422539711,0.028236204758286476,0.026662884280085564,0.025704341009259224,0.026899728924036026,0.023635046556591988,0.022769760340452194,0.027125239372253418,0.023989887908101082,0.023935632780194283,0.02173622138798237,0.020877061411738396,0.02610606513917446,0.025478122755885124,0.024802448228001595,0.024978909641504288,0.02358224429190159,0.02390246093273163,0.02228846587240696,0.02621862106025219,
mse,0.3265252411365509,0.03845769539475441,0.04221586138010025,0.023551011458039284,0.019829437136650085,0.01730557717382908,0.015954159200191498,0.013953588902950287,0.019686641171574593,0.006888838484883308,0.006445648148655891,0.004780914634466171,0.004003416746854782,0.002952128415927291,0.0021023412700742483,0.0027888237964361906,0.0014653302496299148,0.0012897949200123549,0.001321416930295527,0.0015296192141249776,0.0007873638533055782,0.0005993407685309649,0.0009005628526210785,0.0010155714116990566,0.0007642922573722899,0.0010580401867628098,0.0010366400238126516,0.0008193330722860992,0.0006071925745345652,0.0006200562929734588,0.0005653301486745477,0.0003630671708378941,0.0004911677679046988,0.0005338823539204895,0.0007166477153077722,0.0004509365535341203,0.00048148646601475775,0.0004924105596728623,0.0004987423308193684,0.0004053644079249352,0.0004008061077911407,0.00032712408574298024,0.00034147186670452356,0.00040312152123078704,0.00046912857214920223,0.00037540486664511263,0.0003544415521901101,0.00036349560832604766,0.0003374517254997045,0.00032208606717176735,0.000328446039929986,0.0003711713070515543,0.00031391496304422617,0.00019974053429905325,0.00026430777506902814,0.0002696524315979332,0.0002796124026644975,0.00033417492522858083,0.0002931966446340084,0.0003069466620218009,0.0002591415250208229,0.00023835021420381963,0.00014592237130273134,0.00018775869102682918,0.0002745711535681039,0.0002055168733932078,0.00024498195853084326,0.00023239769507199526,0.00019139958021696657,0.0002531758800614625,0.00019975659961346537,0.0002547496114857495,0.00019140752556268126,0.00022108662233222276,0.00018579686002340168,0.00020654012041632086,0.00022480131883639842,0.00022672954946756363,0.00017326578381471336,0.00015154438733588904,0.0001807330409064889,0.00023005445837043226,0.00020010286243632436,0.0001914859312819317,0.00021068747446406633,0.00016068345576059073,0.00015042746963445097,0.00021615545847453177,0.00016516551841050386,0.00016318999405484647,0.00013584857515525073,0.00013415048306342214,0.00019112773588858545,0.0001810261601349339,0.00017283862689509988,0.00017519632820039988,0.00015595796867273748,0.00016251836495939642,0.00014312719576992095,0.0001933398307301104,
mae,0.3799896240234375,0.15593469142913818,0.1589992493391037,0.11947983503341675,0.1066274642944336,0.09617070853710175,0.09248572587966919,0.08831228315830231,0.10356580466032028,0.06353799253702164,0.06236639991402626,0.054804425686597824,0.05010151490569115,0.04392285272479057,0.03634133189916611,0.042218804359436035,0.029980070888996124,0.028701387345790863,0.028672320768237114,0.029704241082072258,0.02169991284608841,0.01924447901546955,0.02340118959546089,0.02458030916750431,0.021084697917103767,0.02590734325349331,0.02641947753727436,0.023164384067058563,0.019704997539520264,0.019763167947530746,0.018376030027866364,0.01496618241071701,0.01745319366455078,0.01817697286605835,0.022142283618450165,0.016990888863801956,0.017459811642766,0.017233652994036674,0.017512399703264236,0.01602376438677311,0.016108324751257896,0.014309590682387352,0.014854772947728634,0.01628507301211357,0.017205314710736275,0.015296462923288345,0.015076360665261745,0.015084866434335709,0.014750063419342041,0.013941955752670765,0.014694481156766415,0.014944230206310749,0.013697237707674503,0.011010675691068172,0.0128263458609581,0.012953992001712322,0.013432208448648453,0.014807002618908882,0.013715348206460476,0.014077876694500446,0.012482918798923492,0.012098990380764008,0.009401213377714157,0.010357523337006569,0.013417469337582588,0.011187924072146416,0.012532973662018776,0.012110981158912182,0.011045407503843307,0.012527912855148315,0.010934152640402317,0.01261773332953453,0.01079854927957058,0.011607903055846691,0.01068594679236412,0.011434603482484818,0.012149911373853683,0.012418944388628006,0.010508662089705467,0.009705238044261932,0.01041769701987505,0.012083458714187145,0.011185962706804276,0.01099269650876522,0.011598820798099041,0.010018800385296345,0.009631270542740822,0.01156019326299429,0.010026498697698116,0.00997255090624094,0.009027693420648575,0.008883556351065636,0.01097745168954134,0.010833373293280602,0.010608043521642685,0.01051761582493782,0.00980442762374878,0.010189304128289223,0.009525351226329803,0.011288365349173546,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 267339    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 267340    
=================================================================
Total params: 534,679
Trainable params: 534,679
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 267,339
Trainable params: 267,339
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 267,340
Trainable params: 267,340
Non-trainable params: 0
_________________________________________________________________
