2021-06-26
loss,2.354487895965576,1.492628574371338,0.4093681573867798,0.2847745418548584,0.26828524470329285,0.25644004344940186,0.24560989439487457,0.24341636896133423,0.24325069785118103,0.23955345153808594,0.23875801265239716,0.23567606508731842,0.2338695079088211,0.22894300520420074,0.22687877714633942,0.22432661056518555,0.22141245007514954,0.21600030362606049,0.21734380722045898,0.21293658018112183,0.21040628850460052,0.21021905541419983,0.2041577696800232,0.2054181843996048,0.19883857667446136,0.20240376889705658,0.19516803324222565,0.19696101546287537,0.19293762743473053,0.19835476577281952,0.18071432411670685,0.1550830751657486,0.16085289418697357,0.13228288292884827,0.1338903158903122,0.11366545408964157,0.11377069354057312,0.09921284019947052,0.08714403957128525,0.07351119816303253,0.06554609537124634,0.07186833769083023,0.07423632591962814,0.06903395056724548,0.076671302318573,0.0692981630563736,0.061143115162849426,0.05293303355574608,0.06497202068567276,0.06187527999281883,0.06145891174674034,0.05587327480316162,0.04498320445418358,0.046349383890628815,0.048807233572006226,0.051689062267541885,0.04718930646777153,0.06748462468385696,0.05572264641523361,0.04688367247581482,0.05115007236599922,0.04412267357110977,0.04405256360769272,0.04542180895805359,0.043615613132715225,0.04176768288016319,0.04607285559177399,0.041114501655101776,0.042551130056381226,0.044666796922683716,0.04596414417028427,0.0380978025496006,0.04036465287208557,0.03796549141407013,0.03063736855983734,0.03083709441125393,0.040345449000597,0.04044868424534798,0.03932097926735878,0.034287188202142715,0.03500581532716751,0.03327658027410507,0.029363902285695076,0.03733731433749199,0.0355774387717247,0.03551021218299866,0.03695280849933624,0.03585001081228256,0.03149358555674553,0.030116355046629906,0.033017348498106,0.031873319298028946,0.03506043180823326,0.031983181834220886,0.028170406818389893,0.030479678884148598,0.035061173141002655,0.0327351838350296,0.03184514120221138,0.034966789186000824,
mse,1.4595108032226562,0.6298635601997375,0.05051083490252495,0.025491826236248016,0.02305632084608078,0.021716900169849396,0.02043226920068264,0.020129069685935974,0.02010183595120907,0.019678154960274696,0.019558705389499664,0.019075920805335045,0.018626168370246887,0.01803363300859928,0.01761060394346714,0.017291653901338577,0.01701991632580757,0.016466835513710976,0.01647167280316353,0.01604858785867691,0.015673674643039703,0.015575265511870384,0.014953600242733955,0.014918932691216469,0.014216841198503971,0.014412293210625648,0.013645139522850513,0.013576168566942215,0.012838730588555336,0.013008199632167816,0.010727700777351856,0.00790378637611866,0.008308137767016888,0.005521812476217747,0.005444845650345087,0.00397728756070137,0.003970571793615818,0.0029392926953732967,0.002234354382380843,0.0016091434517875314,0.0012767630396410823,0.0014904179843142629,0.00169035152066499,0.001388941309414804,0.00175107317045331,0.0014538236428052187,0.0011479223612695932,0.0008780009229667485,0.001249978318810463,0.0010923143709078431,0.001156348385848105,0.0009113724809139967,0.0006012220401316881,0.000641524966340512,0.0006825090385973454,0.0007544373511336744,0.0006485660560429096,0.0012687135022133589,0.0008641250315122306,0.0006333102937787771,0.0007490443531423807,0.0005532419891096652,0.0005510547198355198,0.0006077663856558502,0.0005689459503628314,0.0005134634557180107,0.0006072601536288857,0.0004888840485364199,0.000517683569341898,0.0005585621111094952,0.0006012716912664473,0.0004212198837194592,0.000467701320303604,0.00041655992390587926,0.00028468162054196,0.0002764943928923458,0.000477417663205415,0.0004598704108502716,0.000434237445006147,0.00034698002855293453,0.00035890136496163905,0.0003189193375874311,0.0002536487299948931,0.0003987327218055725,0.00037320799310691655,0.0003622666117735207,0.0003840494027826935,0.00036198896123096347,0.00028841837774962187,0.0002673098642844707,0.0003088786033913493,0.0002965988533105701,0.0003504170454107225,0.0003014783433172852,0.00024328719882760197,0.0002934155927505344,0.0003608665138017386,0.00030929528293199837,0.00028974120505154133,0.0003533739363774657,
mae,0.8866206407546997,0.5700650215148926,0.17426079511642456,0.12079846113920212,0.11450988799333572,0.10748913884162903,0.10236582905054092,0.10133248567581177,0.10057980567216873,0.098931223154068,0.09890547394752502,0.09814453125,0.09881128370761871,0.09686467796564102,0.0962030217051506,0.09509355574846268,0.09370242804288864,0.090898297727108,0.09259885549545288,0.09011418372392654,0.08896922320127487,0.08900539577007294,0.08636218309402466,0.08718714863061905,0.0846116840839386,0.08643278479576111,0.08361463248729706,0.0843178927898407,0.08258979022502899,0.08501669764518738,0.07735520601272583,0.06621773540973663,0.06855250149965286,0.0555272214114666,0.05636695399880409,0.04839884862303734,0.04855741560459137,0.042394790798425674,0.03673846647143364,0.031208710744976997,0.027786757797002792,0.030486678704619408,0.031705763190984726,0.02895674668252468,0.03222234547138214,0.02920476719737053,0.025837741792201996,0.022571375593543053,0.027278808876872063,0.026320254430174828,0.026534929871559143,0.023466475307941437,0.018812164664268494,0.019482016563415527,0.02059331163764,0.022002389654517174,0.020005278289318085,0.029450617730617523,0.024125082418322563,0.019346758723258972,0.02185882069170475,0.018638068810105324,0.018942106515169144,0.019361263141036034,0.018492359668016434,0.018009407445788383,0.019056471064686775,0.01741541177034378,0.01824053004384041,0.01880374550819397,0.019937949255108833,0.016694175079464912,0.017056165263056755,0.016222044825553894,0.013081583194434643,0.013055766932666302,0.017117591574788094,0.016833925619721413,0.017131751403212547,0.014696641825139523,0.015098541975021362,0.014110066927969456,0.012677758932113647,0.015606321394443512,0.015126458369195461,0.01514689065515995,0.015444347634911537,0.015329629182815552,0.013411978259682655,0.01283655408769846,0.01403761189430952,0.013591980561614037,0.014853861182928085,0.013904568739235401,0.012123072519898415,0.013068901374936104,0.015209207311272621,0.014126581139862537,0.013380203396081924,0.014527933672070503,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 200651    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 200652    
=================================================================
Total params: 401,303
Trainable params: 401,303
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 200,651
Trainable params: 200,651
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 200,652
Trainable params: 200,652
Non-trainable params: 0
_________________________________________________________________
