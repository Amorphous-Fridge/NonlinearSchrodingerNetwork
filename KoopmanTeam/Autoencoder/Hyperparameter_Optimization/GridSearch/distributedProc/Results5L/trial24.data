2021-06-26
loss,0.5033857226371765,0.1673160046339035,0.09850829094648361,0.10867355018854141,0.08889099210500717,0.1003188043832779,0.09193386137485504,0.07087203115224838,0.0750238373875618,0.09198668599128723,0.09641163051128387,0.06516915559768677,0.07203306257724762,0.05584222823381424,0.07560452818870544,0.06954622268676758,0.056318845599889755,0.05029847100377083,0.07055112719535828,0.058246999979019165,0.05554927513003349,0.0636988952755928,0.04241674020886421,0.04972358047962189,0.05302273854613304,0.050853416323661804,0.049094606190919876,0.04904291778802872,0.04337569698691368,0.045825690031051636,0.05132220312952995,0.047218240797519684,0.043260712176561356,0.03710643947124481,0.03716323524713516,0.04329600930213928,0.038503147661685944,0.03575637936592102,0.04768485203385353,0.044069867581129074,0.03692439943552017,0.03363960608839989,0.03460964560508728,0.03735756501555443,0.03252424672245979,0.03935777768492699,0.03612840548157692,0.03724666312336922,0.038371458649635315,0.036382049322128296,0.03069998510181904,0.034004293382167816,0.030444486066699028,0.02843560464680195,0.03914833441376686,0.03143522888422012,0.031762488186359406,0.035463448613882065,0.029719891026616096,0.027947040274739265,0.025976315140724182,0.02591550350189209,0.03452296927571297,0.029301617294549942,0.02761545404791832,0.025890808552503586,0.024738429114222527,0.02269965223968029,0.019719520583748817,0.01934623159468174,0.020073723047971725,0.02828332595527172,0.03155308589339256,0.032291147857904434,0.027262933552265167,0.024865977466106415,0.024285398423671722,0.02659709006547928,0.026198096573352814,0.030638182535767555,0.025167612358927727,0.025120370090007782,0.02757343277335167,0.027689501643180847,0.024674903601408005,0.02631242759525776,0.027490034699440002,0.02477998659014702,0.02266935631632805,0.02132573164999485,0.02018132619559765,0.019420916214585304,0.01858656108379364,0.020391441881656647,0.022708458825945854,0.023785818368196487,0.020415132865309715,0.020542806014418602,0.022066406905651093,0.024751486256718636,
mse,0.13050146400928497,0.008646208792924881,0.0027295202016830444,0.003566701663658023,0.0022072161082178354,0.0029976877849549055,0.002517157234251499,0.001508592627942562,0.0015730608720332384,0.002393401460722089,0.0027357435319572687,0.0012810603948310018,0.0014811728615313768,0.0009133745916187763,0.0016029353719204664,0.0013550781877711415,0.0009040521690621972,0.0007518704514950514,0.001382452086545527,0.0009879348799586296,0.0008854405605234206,0.0011311797425150871,0.0005461025284603238,0.000744593096897006,0.0007871879497542977,0.0007489108247682452,0.0006849921774119139,0.0006631492869928479,0.0005367901758290827,0.0006043002940714359,0.0007562626851722598,0.000615486700553447,0.0005187323549762368,0.0003796309174504131,0.0003893473476637155,0.0005123910959810019,0.0004060958744958043,0.00037842142046429217,0.0006531499093398452,0.0005368045531213284,0.0003763402928598225,0.00031979731284081936,0.00036207112134434283,0.0003825975290965289,0.00031590444268658757,0.00042091147042810917,0.0003666808770503849,0.00038321438478305936,0.00040842025191523135,0.0003709620505105704,0.0002614970435388386,0.00031911738915368915,0.00025659077800810337,0.00023548133322037756,0.0004271346260793507,0.0002813110768329352,0.0002816667838487774,0.00034668963053263724,0.00024307802959810942,0.00021683423256035894,0.00019088668341282755,0.00019428222731221467,0.00033195153810083866,0.00023332373530138284,0.0002089587796945125,0.00018484352040104568,0.00016803362814243883,0.00014990945055615157,0.00011117104440927505,0.00010746574844233692,0.00011987790639977902,0.00023335615696851164,0.0002842351095750928,0.0002967609907500446,0.00020874889742117375,0.00017440550436731428,0.00016292369400616735,0.00020402943482622504,0.00018677841580938548,0.0002667245571501553,0.0001870304549811408,0.00017614442913327366,0.00021514973195735365,0.00021299481159076095,0.00016809186490718275,0.00019147670536767691,0.00020642131858039647,0.0001685395691310987,0.00014153600204735994,0.00012548925587907434,0.00011331005953252316,0.00010476431634742767,9.624652739148587e-05,0.00012166611122665927,0.00014673956320621073,0.00015768141020089388,0.00011845742119476199,0.00011950163025176153,0.00013754601241089404,0.00017138289695139974,
mae,0.21417377889156342,0.06878751516342163,0.042249422520399094,0.0458899550139904,0.03768559545278549,0.04258445277810097,0.03950347751379013,0.03024766966700554,0.03147123008966446,0.03843959420919418,0.04159713163971901,0.026180436834692955,0.030014358460903168,0.02371395193040371,0.03210250288248062,0.029817743226885796,0.023701278492808342,0.021329078823328018,0.02997589111328125,0.024546677246689796,0.02355938032269478,0.0269376989454031,0.01824152283370495,0.02093510329723358,0.0227236058562994,0.02140428125858307,0.020888501778244972,0.021373163908720016,0.018291374668478966,0.019548630341887474,0.022024376317858696,0.01985730603337288,0.01849742792546749,0.015029425732791424,0.01521071046590805,0.018492694944143295,0.016669781878590584,0.01491261925548315,0.01949215680360794,0.018262967467308044,0.01590796746313572,0.014173598028719425,0.014766230247914791,0.01590861566364765,0.013630278408527374,0.01669086515903473,0.015331237576901913,0.015922747552394867,0.016458194702863693,0.01574145257472992,0.012838455848395824,0.014789419248700142,0.013146945275366306,0.012049201875925064,0.01659252494573593,0.013245628215372562,0.013787638396024704,0.015075640752911568,0.012683434411883354,0.011163127608597279,0.010478636249899864,0.010733707807958126,0.014484954066574574,0.012684420682489872,0.012105622328817844,0.011443521827459335,0.010717754252254963,0.009622238576412201,0.008315461687743664,0.008047787472605705,0.00845180545002222,0.011951632797718048,0.013297216966748238,0.013533879071474075,0.011731470003724098,0.010687469504773617,0.010383239947259426,0.011193398386240005,0.011324354447424412,0.01327449455857277,0.010590387508273125,0.010588807985186577,0.011593390256166458,0.011583404615521431,0.010589809156954288,0.01104146521538496,0.011667346581816673,0.01048214640468359,0.009706896729767323,0.008927569724619389,0.008572790771722794,0.00829748623073101,0.007974524050951004,0.008728817105293274,0.009519445709884167,0.010040667839348316,0.008704542182385921,0.008759480901062489,0.009350697509944439,0.010600508190691471,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 19939     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 19940     
=================================================================
Total params: 39,879
Trainable params: 39,879
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 19,939
Trainable params: 19,939
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 19,940
Trainable params: 19,940
Non-trainable params: 0
_________________________________________________________________
