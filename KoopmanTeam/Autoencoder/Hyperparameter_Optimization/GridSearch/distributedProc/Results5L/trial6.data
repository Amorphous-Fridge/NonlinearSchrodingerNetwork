2021-06-26
loss,0.3527010381221771,0.11148276925086975,0.0695713609457016,0.05561496317386627,0.04922241345047951,0.04441092535853386,0.04081731662154198,0.03878965973854065,0.03717764467000961,0.035635557025671005,0.03448810428380966,0.033338725566864014,0.03293844312429428,0.0317523255944252,0.03128362074494362,0.03081003949046135,0.03022036701440811,0.02952170930802822,0.02904527634382248,0.028551630675792694,0.02832867205142975,0.02777368761599064,0.02746100351214409,0.02724391222000122,0.026787428185343742,0.026492955163121223,0.02645973488688469,0.026126574724912643,0.025804409757256508,0.02548331581056118,0.02527919039130211,0.025258848443627357,0.024701610207557678,0.024629753082990646,0.024475140497088432,0.024261046200990677,0.024145327508449554,0.023875107988715172,0.02358921617269516,0.02344045229256153,0.023469049483537674,0.02311944216489792,0.023037170991301537,0.02273677848279476,0.022567143663764,0.022408518940210342,0.022538505494594574,0.022384515032172203,0.02212238870561123,0.023261170834302902,0.030312430113554,0.0371735654771328,0.03434145823121071,0.03226153552532196,0.030822552740573883,0.02958085387945175,0.028704356402158737,0.027442429214715958,0.025045372545719147,0.03844117745757103,0.03686859831213951,0.03372859209775925,0.0320020355284214,0.030238714069128036,0.029306601732969284,0.027999453246593475,0.02896002121269703,0.04237612336874008,0.040743570774793625,0.03805955499410629,0.035930756479501724,0.03460310399532318,0.03316715732216835,0.0318865142762661,0.030473332852125168,0.029014648869633675,0.027309773489832878,0.02465200424194336,0.026329724118113518,0.03237856924533844,0.03060637228190899,0.02924266830086708,0.02794809639453888,0.026837678626179695,0.026016831398010254,0.025268735364079475,0.024707762524485588,0.031074291095137596,0.03185950219631195,0.029329365119338036,0.027977457270026207,0.026902703568339348,0.0259077325463295,0.03692561015486717,0.03477129340171814,0.032534629106521606,0.03104260191321373,0.029656799510121346,0.02784314565360546,0.026442034170031548,
mse,0.05623053014278412,0.004404612351208925,0.0016438632737845182,0.0010540313087403774,0.0008223365293815732,0.000656859774608165,0.0005530316266231239,0.0004898472689092159,0.0004410679975990206,0.000401635275920853,0.0003727194562088698,0.0003493532130960375,0.00033580110175535083,0.0003125685325358063,0.0003009024658240378,0.0002897145168390125,0.00027755097835324705,0.00026487387367524207,0.00025584944523870945,0.00024791533360257745,0.00024197598395403475,0.00023281612084247172,0.00022621219977736473,0.0002240901958430186,0.0002146075275959447,0.0002100719721056521,0.00020745687652379274,0.000202752067707479,0.00019714361405931413,0.00019193472689948976,0.00018965308845508844,0.0001899469643831253,0.00018088544311467558,0.0001790876849554479,0.0001759636215865612,0.0001730806689010933,0.00017096041119657457,0.00016709273040760309,0.00016286336176563054,0.00016016354493331164,0.00016000840696506202,0.0001556071947561577,0.00015405142039526254,0.00015043735038489103,0.00014841755910310894,0.00014620744332205504,0.00014737674791831523,0.0001448910916224122,0.0001419896725565195,0.0001567472208989784,0.00028565002139657736,0.0003853682428598404,0.0003254628099966794,0.0002886008005589247,0.0002629636146593839,0.00024315129849128425,0.00022940858616493642,0.00020615491666831076,0.0001781511673470959,0.00041102839168161154,0.00038104495615698397,0.00031768259941600263,0.00028316155658103526,0.00025535313761793077,0.0002401377132628113,0.00022041604097466916,0.0002463938435539603,0.000506836746353656,0.00045252422569319606,0.0003991331032011658,0.00035896722692996264,0.00033499428536742926,0.00030798683292232454,0.000285759917460382,0.0002617503050714731,0.00023782554490026087,0.0002119904529536143,0.00017392750305589288,0.00021110639499966055,0.0002912291092798114,0.00025707200984470546,0.00023540381516795605,0.0002162161108572036,0.00020086484437342733,0.00018899916904047132,0.00017924226995091885,0.00017199123976752162,0.00029732263647019863,0.00027616420993581414,0.00023581837012898177,0.00021574970742221922,0.00019992337911389768,0.0001864604710135609,0.0004022213688585907,0.00033556376001797616,0.00029510344029404223,0.0002703229256439954,0.0002472500200383365,0.0002177315909648314,0.00019407420768402517,
mae,0.14925414323806763,0.048130787909030914,0.029370971024036407,0.02361927181482315,0.02080117166042328,0.018848296254873276,0.0173319261521101,0.016503851860761642,0.015722012147307396,0.015135586261749268,0.014671261422336102,0.014092104509472847,0.013902460224926472,0.013359138742089272,0.013253326527774334,0.013174888677895069,0.012765140272676945,0.012461317703127861,0.012285787612199783,0.012189202010631561,0.011987847276031971,0.011757651343941689,0.011625099927186966,0.011642553843557835,0.011342245154082775,0.011225439608097076,0.011167981661856174,0.011017270386219025,0.010829034261405468,0.010888762772083282,0.01074785552918911,0.01084793172776699,0.010511349886655807,0.010628256015479565,0.010286159813404083,0.010397810488939285,0.010192410089075565,0.010304155759513378,0.009947999380528927,0.009998796507716179,0.01002598274499178,0.009869089350104332,0.009948321618139744,0.009828107431530952,0.009496636688709259,0.009603254497051239,0.009515983983874321,0.009314420633018017,0.009610856883227825,0.009818574413657188,0.012905903160572052,0.016079697757959366,0.014924390241503716,0.014049782417714596,0.013350801542401314,0.012871857732534409,0.012454804033041,0.012100514955818653,0.010491689667105675,0.015742158517241478,0.016604982316493988,0.015218897722661495,0.01443669106811285,0.01362853404134512,0.013227205723524094,0.012596970424056053,0.0126486299559474,0.01837543398141861,0.018611140549182892,0.017683623358607292,0.016636552289128304,0.016029449179768562,0.015365933999419212,0.014537428505718708,0.012959527783095837,0.011033408343791962,0.010302389040589333,0.010640103369951248,0.011001511476933956,0.014007584191858768,0.0136138666421175,0.012974443845450878,0.01254878006875515,0.012161964550614357,0.01170082576572895,0.011411572806537151,0.011016521602869034,0.012885362841188908,0.013528554700314999,0.012480596080422401,0.012073502875864506,0.01139843836426735,0.010377470403909683,0.015679681673645973,0.014328666031360626,0.013590400107204914,0.012895201332867146,0.012037872336804867,0.010696714743971825,0.010636775754392147,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5107      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5108      
=================================================================
Total params: 10,215
Trainable params: 10,215
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 5,107
Trainable params: 5,107
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 5,108
Trainable params: 5,108
Non-trainable params: 0
_________________________________________________________________
