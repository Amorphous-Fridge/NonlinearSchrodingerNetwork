2021-06-26
loss,0.6089844703674316,0.22639629244804382,0.12359180301427841,0.10040733218193054,0.11931421607732773,0.10407204926013947,0.08798939734697342,0.08642718940973282,0.08281761407852173,0.1064370721578598,0.08759253472089767,0.07178817689418793,0.046301182359457016,0.055736053735017776,0.060205526649951935,0.06341561675071716,0.06928557902574539,0.05781154707074165,0.05736134946346283,0.05751274526119232,0.052415523678064346,0.044615648686885834,0.04934755712747574,0.04691601172089577,0.040673766285181046,0.03816907852888107,0.041843220591545105,0.049783434718847275,0.043650273233652115,0.035459890961647034,0.041118741035461426,0.04391670599579811,0.042187463492155075,0.03628110513091087,0.02997630648314953,0.03371042385697365,0.03006826899945736,0.039979398250579834,0.037025753408670425,0.03066089004278183,0.034316834062337875,0.03058738447725773,0.02712419256567955,0.035944756120443344,0.03560340031981468,0.029953012242913246,0.031706176698207855,0.02955235168337822,0.029696686193346977,0.025291789323091507,0.028373971581459045,0.029186027124524117,0.026421280577778816,0.026107337325811386,0.03168077766895294,0.02985014021396637,0.024830084294080734,0.022402947768568993,0.02145097404718399,0.02494732290506363,0.030196690931916237,0.02716279774904251,0.024251095950603485,0.02626027911901474,0.023351825773715973,0.02309228666126728,0.026221657171845436,0.027869515120983124,0.025304540991783142,0.022248659282922745,0.024268021807074547,0.021326381713151932,0.02057330682873726,0.021888650953769684,0.022434938699007034,0.024229008704423904,0.021309128031134605,0.020528294146060944,0.018516356125473976,0.021873734891414642,0.020758068189024925,0.019034765660762787,0.01782033033668995,0.016800763085484505,0.015275047160685062,0.016977133229374886,0.023672105744481087,0.0240781232714653,0.020443372428417206,0.021760983392596245,0.020839117467403412,0.02001967467367649,0.019739393144845963,0.01996278576552868,0.02067275531589985,0.018800286576151848,0.016923021525144577,0.017601987347006798,0.019132070243358612,0.01918352209031582,
mse,0.16459675133228302,0.01581527665257454,0.004306444898247719,0.002937082899734378,0.004273849539458752,0.003051329869776964,0.0021937338169664145,0.0021718312054872513,0.0019351998344063759,0.003241253085434437,0.0021834038197994232,0.0014650137163698673,0.0006230709841474891,0.0009025631006807089,0.0010138077195733786,0.0011633835965767503,0.0013610431924462318,0.0009755010833032429,0.0009138070163317025,0.0009270449518226087,0.0008230465464293957,0.0005768830305896699,0.0006875778781250119,0.0006105270003899932,0.00045680865878239274,0.00041728225187398493,0.0005200985469855368,0.0006887823110446334,0.0005403805989772081,0.00035523693077266216,0.00047431205166503787,0.0005428578006103635,0.0005001424578949809,0.0003686724230647087,0.0002646135108079761,0.0003185716341249645,0.00026228008209727705,0.00045527893234975636,0.0003846484760288149,0.00026983197312802076,0.0003352327039465308,0.0002672424307093024,0.00022144775721244514,0.00036673847353085876,0.00036839983658865094,0.00025297122192569077,0.00028432434191927314,0.0002485414734110236,0.00024931447114795446,0.0001904327073134482,0.00023221578157972544,0.00023594308004248887,0.00019462151976767927,0.00019338811398483813,0.0002826364943757653,0.00025108351837843657,0.00017248504445888102,0.00014079741958994418,0.00013033764844294637,0.00018529959197621793,0.00025880520115606487,0.00020734559802804142,0.00016599864466115832,0.00019123304809909314,0.00015235577302519232,0.00015276116027962416,0.00019559783686418086,0.00022246423759497702,0.00017832584853749722,0.0001394563150824979,0.000166357567650266,0.00012900898582302034,0.0001245276362169534,0.0001388339005643502,0.00014347302203532308,0.00016532612789887935,0.000129472347907722,0.00012214721937198192,0.00010074835154227912,0.0001339952868875116,0.00011900794925168157,0.0001046175675583072,9.183386282529682e-05,8.149631321430206e-05,6.933680560905486e-05,8.699043974047527e-05,0.0001566608843859285,0.00016037712339311838,0.00011624868784565479,0.00013079203199595213,0.00012182486534584314,0.00011280522448942065,0.00010929490235866979,0.00011238811566727236,0.0001191986448247917,9.931511885952204e-05,8.351146971108392e-05,8.929004980018362e-05,0.00010257557005388662,0.00010160475358134136,
mae,0.26154983043670654,0.09695076942443848,0.05284858122467995,0.04195130988955498,0.05158288776874542,0.044518690556287766,0.03788164258003235,0.03664558008313179,0.03569190576672554,0.045772600919008255,0.038834456354379654,0.030171707272529602,0.019553689286112785,0.02371743507683277,0.02578136883676052,0.02710498869419098,0.030600417405366898,0.024814018979668617,0.024451198056340218,0.024216243997216225,0.022312629967927933,0.018938381224870682,0.02066809870302677,0.020255226641893387,0.016995888203382492,0.0161299929022789,0.01773248426616192,0.02155403420329094,0.01854895055294037,0.015060407109558582,0.017536059021949768,0.019211534410715103,0.01820344291627407,0.015719065442681313,0.012704883702099323,0.014267602004110813,0.01278754509985447,0.017070965841412544,0.015830937772989273,0.013274198397994041,0.014670134522020817,0.01311329286545515,0.011708450503647327,0.015445590019226074,0.015387573279440403,0.012806489132344723,0.013733277097344398,0.012517612427473068,0.012382781133055687,0.010693936608731747,0.012013656087219715,0.012586282566189766,0.011253713630139828,0.010958824306726456,0.013600527308881283,0.012888486497104168,0.010418375954031944,0.009536199271678925,0.0091164018958807,0.010515310801565647,0.013114276342093945,0.011698218993842602,0.01018383540213108,0.011127623729407787,0.009771916083991528,0.009869399480521679,0.011455826461315155,0.012337998487055302,0.011059189215302467,0.009500622749328613,0.010494199581444263,0.009187333285808563,0.008719019591808319,0.009336266666650772,0.00958931352943182,0.010397766716778278,0.008966703899204731,0.008610183373093605,0.007893361151218414,0.009447482414543629,0.008890180848538876,0.008149669505655766,0.00745135173201561,0.006992707960307598,0.006466941442340612,0.007250126451253891,0.010184931568801403,0.010193591006100178,0.008772004395723343,0.0094232726842165,0.008875773288309574,0.008493945002555847,0.008352908305823803,0.008472149260342121,0.008824324235320091,0.008151994086802006,0.007266974542289972,0.007632642984390259,0.0082100760191679,0.008211452513933182,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 52819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 52820     
=================================================================
Total params: 105,639
Trainable params: 105,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 52,819
Trainable params: 52,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 52,820
Trainable params: 52,820
Non-trainable params: 0
_________________________________________________________________
