2021-06-26
loss,0.40221908688545227,0.1612962931394577,0.08748902380466461,0.07480563968420029,0.06422573328018188,0.06214228272438049,0.07814152538776398,0.06825065612792969,0.05666496604681015,0.050945963710546494,0.06553905457258224,0.07442095875740051,0.06318024545907974,0.03743018954992294,0.033573638647794724,0.0561971478164196,0.04914799705147743,0.04337086156010628,0.038268450647592545,0.039273276925086975,0.05741084739565849,0.049124568700790405,0.04489405080676079,0.04626389965415001,0.04421061649918556,0.03963053598999977,0.046665143221616745,0.04134390503168106,0.03946155682206154,0.04173656925559044,0.03938569128513336,0.04015683755278587,0.04014858230948448,0.03561089187860489,0.03447393700480461,0.0358332134783268,0.035390134900808334,0.036526020616292953,0.038153745234012604,0.03517135977745056,0.03252368047833443,0.03796638548374176,0.0338459350168705,0.03089999407529831,0.03010181151330471,0.03138313814997673,0.02940116822719574,0.028125301003456116,0.026997964829206467,0.02535353973507881,0.03801498934626579,0.034023210406303406,0.03165619820356369,0.03035825677216053,0.033869773149490356,0.0327598862349987,0.02939591370522976,0.027950599789619446,0.02996034547686577,0.027587346732616425,0.028889477252960205,0.028763066977262497,0.02406373992562294,0.027571965008974075,0.03108513168990612,0.0281987264752388,0.025844592601060867,0.024035222828388214,0.023268168792128563,0.021794836968183517,0.02049335278570652,0.028914885595440865,0.026934944093227386,0.027670573443174362,0.030156994238495827,0.02587985061109066,0.022591078653931618,0.0210006982088089,0.019197728484869003,0.017063651233911514,0.016657771542668343,0.016091827303171158,0.015484397299587727,0.015189088881015778,0.015035487711429596,0.015089770779013634,0.014886823482811451,0.014743910171091557,0.014615468680858612,0.014882206916809082,0.014669802971184254,0.014802627265453339,0.014665360562503338,0.014579943381249905,0.014601880684494972,0.014587568119168282,0.014625710435211658,0.014415450394153595,0.01446869969367981,0.014415111392736435,
mse,0.06489146500825882,0.009736319072544575,0.0023514486383646727,0.001731542986817658,0.0012408857000991702,0.0011578110279515386,0.0017782502109184861,0.0014153808588162065,0.0009186557144857943,0.0007889909902587533,0.0012445274041965604,0.001579901436343789,0.0011836225166916847,0.0004187188169453293,0.0003363689174875617,0.0008905304130166769,0.000677672796882689,0.0005267574451863766,0.00042950105853378773,0.00048101210268214345,0.000950510730035603,0.0006860108114778996,0.0005753078148700297,0.000609228853136301,0.0005455490900203586,0.0004514915926847607,0.0006113618146628141,0.0004916489706374705,0.00044602359412238,0.0004896955215372145,0.00044236189569346607,0.00046494961134158075,0.0004507322737481445,0.0003519634192343801,0.0003468267386779189,0.0003640217473730445,0.00035867159022018313,0.00037811638321727514,0.0004074092139489949,0.00034334175870753825,0.00030403619166463614,0.00039961456786841154,0.00031676344224251807,0.0002786935947369784,0.0002620830200612545,0.0002704717044252902,0.0002398621872998774,0.0002207498619100079,0.0002031544572673738,0.000183954878593795,0.00042883961577899754,0.000333870091708377,0.0002817249915096909,0.0002554925449658185,0.0003197673649992794,0.00030140450689941645,0.000245046365307644,0.0002253551356261596,0.0002542894217185676,0.00021217083849478513,0.0002345380198676139,0.00023056674399413168,0.00016648882592562586,0.00022006775543559343,0.0002673036069609225,0.00022142654052004218,0.0001830737164709717,0.00015906518092378974,0.00014890114834997803,0.00013223283167462796,0.00012038459681207314,0.0002315547171747312,0.00020472398318815976,0.0002172012027585879,0.0002538036205805838,0.0001863984507508576,0.00014162690786179155,0.00012441951548680663,0.00010543189273448661,8.929910109145567e-05,8.186294871848077e-05,7.314804679481313e-05,6.774433131795377e-05,6.519369344459847e-05,6.395452510332689e-05,6.487055361503735e-05,6.290888995863497e-05,6.18785634287633e-05,6.131814006948844e-05,6.229157588677481e-05,6.073380063753575e-05,6.128951645223424e-05,6.000584835419431e-05,5.933850843575783e-05,6.0026948631275445e-05,6.050569572835229e-05,5.9790439991047606e-05,5.862519174115732e-05,5.881455581402406e-05,5.85777779633645e-05,
mae,0.16977740824222565,0.07157591730356216,0.03678051382303238,0.031104927882552147,0.02710515819489956,0.0263367909938097,0.032785769551992416,0.02824755385518074,0.02332201413810253,0.021180840209126472,0.027299292385578156,0.03067174181342125,0.025513114407658577,0.015682734549045563,0.014255821704864502,0.024204431101679802,0.021311402320861816,0.01875179074704647,0.016406334936618805,0.016627179458737373,0.0230336282402277,0.0204990915954113,0.018944745883345604,0.019448837265372276,0.019155869260430336,0.016769498586654663,0.019521404057741165,0.017108747735619545,0.016732878983020782,0.0175827294588089,0.016994550824165344,0.017149675637483597,0.01630220375955105,0.015444384887814522,0.014521610923111439,0.015000968240201473,0.014980018138885498,0.015390533953905106,0.015886088833212852,0.014589079655706882,0.0140232490375638,0.015417256392538548,0.013978071510791779,0.013037499040365219,0.0129492012783885,0.012870642356574535,0.011561982333660126,0.011242806911468506,0.010967270471155643,0.010646730661392212,0.014871593564748764,0.01362767443060875,0.013103505596518517,0.012747910805046558,0.014102947898209095,0.013513065874576569,0.01133586186915636,0.011559898033738136,0.012521817348897457,0.011863773688673973,0.011980270966887474,0.012133524753153324,0.01026167068630457,0.011425470001995564,0.011968608014285564,0.011549800634384155,0.011201947927474976,0.010454267263412476,0.01013683807104826,0.009377051144838333,0.00882239080965519,0.012396836653351784,0.011458532884716988,0.011917446739971638,0.011949324980378151,0.011013243347406387,0.009639979340136051,0.00896268617361784,0.008272589184343815,0.007098358124494553,0.006887038238346577,0.006435187067836523,0.006321621593087912,0.006356016267091036,0.006368318106979132,0.0063477372750639915,0.006316129118204117,0.006200569681823254,0.006156661547720432,0.006141567602753639,0.006229181308299303,0.006285265553742647,0.0062886751256883144,0.0061958543956279755,0.006150202360004187,0.006224110722541809,0.006162732373923063,0.006089865695685148,0.006131741218268871,0.006109445821493864,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 13355     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 13356     
=================================================================
Total params: 26,711
Trainable params: 26,711
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 13,355
Trainable params: 13,355
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 13,356
Trainable params: 13,356
Non-trainable params: 0
_________________________________________________________________
