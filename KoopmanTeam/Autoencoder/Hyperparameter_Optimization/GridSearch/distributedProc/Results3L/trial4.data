2021-06-26
loss,0.5013952851295471,0.23520927131175995,0.16171087324619293,0.06984545290470123,0.050018683075904846,0.04004886746406555,0.03550276532769203,0.03265824913978577,0.030749425292015076,0.02870853990316391,0.027681631967425346,0.026601461693644524,0.02561577595770359,0.024696435779333115,0.023911843076348305,0.023665141314268112,0.022722311317920685,0.022109000012278557,0.02161330170929432,0.0212098415941,0.020807072520256042,0.0203744824975729,0.019987158477306366,0.019749712198972702,0.019276291131973267,0.01908586546778679,0.018967846408486366,0.018756303936243057,0.018195703625679016,0.018085666000843048,0.017850294709205627,0.017877155914902687,0.017577022314071655,0.017291251569986343,0.017332695424556732,0.017019636929035187,0.016807543113827705,0.016873378306627274,0.016590731218457222,0.016467249020934105,0.016245190054178238,0.01640225015580654,0.016020001843571663,0.01589752547442913,0.01588912308216095,0.015840379521250725,0.015730641782283783,0.0154793132096529,0.01545326504856348,0.015255575068295002,0.015280910767614841,0.015197651460766792,0.015111599117517471,0.01484324224293232,0.014942927286028862,0.014860782772302628,0.014871836639940739,0.014665025286376476,0.014459027908742428,0.014551549218595028,0.014428101480007172,0.014256393536925316,0.014294887892901897,0.014275350607931614,0.014053677208721638,0.014111123979091644,0.01402123924344778,0.013989398255944252,0.01384324673563242,0.013917024247348309,0.013744411058723927,0.01374264806509018,0.013603610917925835,0.013627796433866024,0.013540918938815594,0.013496761210262775,0.013441993854939938,0.0133749321103096,0.013345323503017426,0.013286789879202843,0.013241524808108807,0.013279307633638382,0.01313652005046606,0.013133461587131023,0.013085663318634033,0.013040960766375065,0.013013966381549835,0.012918435037136078,0.012940002605319023,0.012805700302124023,0.012752963230013847,0.012808602303266525,0.012751679867506027,0.012741846963763237,0.012681999243795872,0.012671935372054577,0.012697424739599228,0.01258845441043377,0.012514241971075535,0.012461293488740921,
mse,0.10891556739807129,0.018974458798766136,0.009686999022960663,0.0017329290276393294,0.0009097456932067871,0.000599440885707736,0.0004605258582159877,0.0003875157271977514,0.0003396333777345717,0.000296197016723454,0.000272228877292946,0.00025108546833507717,0.00022978098422754556,0.00021480290160980076,0.00019989965949207544,0.00019377352145966142,0.00017781328642740846,0.00016826203500386328,0.00015944703773129731,0.00015365297440439463,0.00014688182272948325,0.000140517033287324,0.00013553474855143577,0.00013107316044624895,0.0001241761347046122,0.00012025211617583409,0.00011926051956834272,0.00011598027049330994,0.00010948118870146573,0.00010778617433970794,0.00010389911039965227,0.00010506010585231707,0.00010044619557447731,9.777659579413012e-05,9.760187094798312e-05,9.370030602440238e-05,9.211950964527205e-05,9.162810601992533e-05,8.885615534381941e-05,8.747264655539766e-05,8.456413343083113e-05,8.591398363932967e-05,8.197296119760722e-05,8.034206985030323e-05,8.027163130464032e-05,7.956873741932213e-05,7.854032446630299e-05,7.580108649563044e-05,7.579163502668962e-05,7.384842319879681e-05,7.374149572569877e-05,7.26836733520031e-05,7.132420432753861e-05,6.978682358749211e-05,7.009725959505886e-05,6.890037911944091e-05,6.912321987329051e-05,6.742368714185432e-05,6.522228795802221e-05,6.627343827858567e-05,6.494492117781192e-05,6.341884727589786e-05,6.34528259979561e-05,6.328731251414865e-05,6.114232382969931e-05,6.13782467553392e-05,6.082345134927891e-05,6.0352609580149874e-05,5.8914170949719846e-05,5.976524334982969e-05,5.820807200507261e-05,5.802851228509098e-05,5.7125009334413335e-05,5.728115502279252e-05,5.651930041494779e-05,5.5626529501751065e-05,5.543287261389196e-05,5.469381721923128e-05,5.4719075706088915e-05,5.390409933170304e-05,5.3477957408176735e-05,5.382186282076873e-05,5.24148199474439e-05,5.259145109448582e-05,5.2168488764436916e-05,5.2032504754606634e-05,5.1429080485831946e-05,5.05240386701189e-05,5.097900429973379e-05,4.9841302825370803e-05,4.9281810788670555e-05,4.943604290019721e-05,4.916836405755021e-05,4.936901677865535e-05,4.879198604612611e-05,4.848291791859083e-05,4.86196659039706e-05,4.7809564421186224e-05,4.731973240268417e-05,4.676039679907262e-05,
mae,0.21341362595558167,0.10265883803367615,0.07148582488298416,0.029593857005238533,0.021290559321641922,0.01692180521786213,0.014928694814443588,0.013744180090725422,0.012923947535455227,0.012095022015273571,0.01168825477361679,0.01123057957738638,0.010842573828995228,0.010442167520523071,0.010124754160642624,0.010048281401395798,0.009644191712141037,0.009402407333254814,0.009205284528434277,0.009011971764266491,0.008813001215457916,0.008670476265251637,0.008463982492685318,0.008392779156565666,0.00820069294422865,0.008127131499350071,0.008072374388575554,0.007953344844281673,0.007752353325486183,0.007652526721358299,0.007582284975796938,0.0075977034866809845,0.0074773854576051235,0.00732365483418107,0.007386432960629463,0.007220500148832798,0.007096628658473492,0.007194059435278177,0.007046222221106291,0.006981140933930874,0.006896109785884619,0.006977646145969629,0.006802499759942293,0.0067672161385416985,0.006733528338372707,0.006707947235554457,0.006676612421870232,0.00657349219545722,0.00657301302999258,0.0064739566296339035,0.006459382362663746,0.006462701130658388,0.006425438914448023,0.00636912090703845,0.006347056478261948,0.006306135561317205,0.006295742001384497,0.006188425235450268,0.006133248098194599,0.0061553162522614,0.006116623990237713,0.006084258668124676,0.006060274317860603,0.00605540769174695,0.00600455654785037,0.005987657234072685,0.005947886500507593,0.0059213959611952305,0.005900967866182327,0.005891221109777689,0.005825727712363005,0.005843637976795435,0.005804155021905899,0.005784341599792242,0.005774167366325855,0.005729645024985075,0.005715154577046633,0.0056992326863110065,0.00563541054725647,0.005646734032779932,0.005649011116474867,0.005629006773233414,0.005564913619309664,0.0055715953931212425,0.005579950753599405,0.005519251339137554,0.005571931134909391,0.005510933231562376,0.005464276764541864,0.00544344587251544,0.005462185945361853,0.005450814962387085,0.005401995964348316,0.0053864442743361,0.005409770179539919,0.005418126471340656,0.005387646611779928,0.005343744531273842,0.0053217727690935135,0.005301628261804581,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1203      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1204      
=================================================================
Total params: 2,407
Trainable params: 2,407
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 1,203
Trainable params: 1,203
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 1,204
Trainable params: 1,204
Non-trainable params: 0
_________________________________________________________________
