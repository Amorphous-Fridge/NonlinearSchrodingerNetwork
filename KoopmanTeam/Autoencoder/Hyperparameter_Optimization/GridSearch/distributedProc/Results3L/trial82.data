2021-06-26
loss,0.5999034643173218,0.10488572716712952,0.09512785822153091,0.08055970817804337,0.08047468960285187,0.06724957376718521,0.06891763210296631,0.05567367002367973,0.05058916658163071,0.03922966867685318,0.048541635274887085,0.042437586933374405,0.04008900746703148,0.04350779578089714,0.04102698713541031,0.03082536719739437,0.03626088798046112,0.03414962813258171,0.03356456384062767,0.0365213006734848,0.03082669898867607,0.027742834761738777,0.023486213758587837,0.02842237986624241,0.026720253750681877,0.024952121078968048,0.028373485431075096,0.030590806156396866,0.026073642075061798,0.0258066076785326,0.02685394138097763,0.025234343484044075,0.025101613253355026,0.023083874955773354,0.02160700410604477,0.02058110013604164,0.020210471004247665,0.022708678618073463,0.02071124128997326,0.021126698702573776,0.020283591002225876,0.021283507347106934,0.02084672637283802,0.019738694652915,0.01907503791153431,0.01938057504594326,0.020210443064570427,0.01752760261297226,0.017800642177462578,0.01445041410624981,0.016904912889003754,0.019184382632374763,0.017537500709295273,0.019716406241059303,0.018030870705842972,0.015625953674316406,0.0135794123634696,0.01607135497033596,0.01631624810397625,0.016439011320471764,0.016587983816862106,0.015362734906375408,0.01742536760866642,0.01735120452940464,0.016132652759552002,0.01592801697552204,0.015530828386545181,0.016687488183379173,0.017637766897678375,0.015129974111914635,0.01288970373570919,0.013666127808392048,0.01637878641486168,0.016091015189886093,0.01550261303782463,0.014466998167335987,0.01648620143532753,0.015162991359829903,0.013728508725762367,0.015597973950207233,0.01571851409971714,0.014616232365369797,0.013755670748651028,0.01583879068493843,0.014963933266699314,0.015016365796327591,0.01457541435956955,0.012903090566396713,0.012369164265692234,0.012890866957604885,0.013343160040676594,0.01439324114471674,0.015185948461294174,0.014046290889382362,0.01347370259463787,0.013789232820272446,0.012992341071367264,0.011045311577618122,0.01459065917879343,0.014798872172832489,
mse,0.19370612502098083,0.003565892344340682,0.002683657919988036,0.0020257446449249983,0.0019834667909890413,0.0013343350728973746,0.0014002058887854218,0.0008877605432644486,0.0007313836831599474,0.000459367292933166,0.0007002343190833926,0.0005273305578157306,0.0004663120489567518,0.0005403707036748528,0.00048791736480779946,0.000294078461593017,0.0003797398239839822,0.0003389591001905501,0.00033160127350129187,0.000373558810679242,0.0002653964329510927,0.00022864289348945022,0.00016816251445561647,0.0002368015266256407,0.000205708944122307,0.00018570154497865587,0.00023265255731530488,0.00025943017681129277,0.00019476846500765532,0.00019284799054730684,0.00020761342602781951,0.00018645537784323096,0.00018331575847696513,0.0001536862546345219,0.00013615874922834337,0.0001256717077922076,0.00012021265865769237,0.00015085641643963754,0.0001250828499905765,0.00012825019075535238,0.00012036136467941105,0.00012993960990570486,0.00012343729031272233,0.00011326593084959313,0.00010643540736055002,0.0001081688969861716,0.00011453608749434352,9.033308015204966e-05,9.445898467674851e-05,6.388151814462617e-05,8.753963629715145e-05,0.00010407494119135663,9.017343836603686e-05,0.00011134647502331063,9.264980326406658e-05,7.36223955755122e-05,5.6934648455353454e-05,7.832119445083663e-05,7.82987117418088e-05,8.041379624046385e-05,7.959925278555602e-05,6.995033618295565e-05,8.842022361932322e-05,8.608195639681071e-05,7.728238415438682e-05,7.349161751335487e-05,7.148189615691081e-05,8.06941679911688e-05,8.747740503167734e-05,6.655183824477717e-05,5.180325752007775e-05,5.819923535455018e-05,7.656260277144611e-05,7.484845264116302e-05,7.041326898615807e-05,6.292725447565317e-05,7.700015703449026e-05,6.799513357691467e-05,5.720806439057924e-05,6.97212090017274e-05,7.129546429496258e-05,6.320861575659364e-05,5.722523565054871e-05,7.462946086889133e-05,6.583919457625598e-05,6.510830280603841e-05,6.100505925132893e-05,5.061766569269821e-05,4.7769597586011514e-05,5.1748062105616555e-05,5.43052883585915e-05,6.100206155679189e-05,6.52551680104807e-05,5.7674693380249664e-05,5.5142932978924364e-05,5.7868430303642526e-05,5.1142062147846445e-05,3.838386692223139e-05,6.0940561525058e-05,6.322398985503241e-05,
mae,0.25942176580429077,0.04365804046392441,0.0405062660574913,0.03474896028637886,0.03376339375972748,0.028697652742266655,0.029080158099532127,0.023824205622076988,0.021497787907719612,0.016645781695842743,0.020927613601088524,0.018260793760418892,0.016995934769511223,0.01863165944814682,0.017485613003373146,0.013033655472099781,0.015460019931197166,0.014492086134850979,0.01436569169163704,0.015341509133577347,0.01301631797105074,0.01180059090256691,0.010054176673293114,0.011996456421911716,0.011397751979529858,0.010551943443715572,0.012037987820804119,0.013209916651248932,0.011039339005947113,0.010909203439950943,0.01147819310426712,0.010757055133581161,0.010648960247635841,0.009745772927999496,0.0091543672606349,0.008732497692108154,0.008577371947467327,0.009727993980050087,0.0088227279484272,0.008963492698967457,0.00856380257755518,0.008983423002064228,0.008797953836619854,0.008404758758842945,0.008056165650486946,0.008247650228440762,0.008623878471553326,0.007553464733064175,0.007561851758509874,0.006108089815825224,0.0071365018375217915,0.0080683259293437,0.007367587648332119,0.008362351916730404,0.007676216773688793,0.006708226632326841,0.00573996314778924,0.006786660756915808,0.006879367399960756,0.0069765062071383,0.00706087052822113,0.006575935985893011,0.0074342829175293446,0.00740145705640316,0.0067281341180205345,0.006746991071850061,0.006633797660470009,0.007077609188854694,0.0074901278130710125,0.0064902896992862225,0.005546773783862591,0.005822259932756424,0.006920828018337488,0.006803020369261503,0.006463912315666676,0.00607002479955554,0.006962838117033243,0.006444227881729603,0.005779627710580826,0.0066678160801529884,0.0065595353953540325,0.006222348660230637,0.0058999089524149895,0.0067337797954678535,0.006234725937247276,0.006389651447534561,0.006172193679958582,0.005501620005816221,0.005291411187499762,0.005448290146887302,0.005736884661018848,0.006080636754631996,0.006355734076350927,0.005938029382377863,0.005695878062397242,0.005897621624171734,0.005546868313103914,0.004629729315638542,0.00622599059715867,0.006329283118247986,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 99715     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 99716     
=================================================================
Total params: 199,431
Trainable params: 199,431
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 99,715
Trainable params: 99,715
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 99,716
Trainable params: 99,716
Non-trainable params: 0
_________________________________________________________________
