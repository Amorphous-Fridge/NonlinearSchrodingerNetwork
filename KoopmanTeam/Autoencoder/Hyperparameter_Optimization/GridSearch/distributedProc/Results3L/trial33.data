2021-06-26
loss,0.33322808146476746,0.08842086046934128,0.05479610338807106,0.046472951769828796,0.04307816922664642,0.041455645114183426,0.039016421884298325,0.045431867241859436,0.04616129770874977,0.04001544043421745,0.03269943594932556,0.029179412871599197,0.029911281540989876,0.04125351831316948,0.0386648066341877,0.041801776736974716,0.040507711470127106,0.04014122113585472,0.03376847878098488,0.04013892635703087,0.03666778281331062,0.03159370273351669,0.031192559748888016,0.03553729131817818,0.0363522432744503,0.03131554275751114,0.03653401508927345,0.031617797911167145,0.029107393696904182,0.02707391045987606,0.026146573945879936,0.033104442059993744,0.03270523622632027,0.024150414392352104,0.021333305165171623,0.018511738628149033,0.01784484088420868,0.01745467446744442,0.017169881612062454,0.017105523496866226,0.01685321517288685,0.016780881211161613,0.016782209277153015,0.016501005738973618,0.0164932943880558,0.016298120841383934,0.016325348988175392,0.01620248146355152,0.016024375334382057,0.015946874395012856,0.01581091247498989,0.015790309756994247,0.015631020069122314,0.015535478480160236,0.015374964103102684,0.015312016941606998,0.015252186916768551,0.015265759080648422,0.015095628798007965,0.014978313818573952,0.014978217892348766,0.014735852368175983,0.014794031158089638,0.014721580781042576,0.01454851496964693,0.014521616511046886,0.014455931261181831,0.0144761111587286,0.014337875880300999,0.014200281351804733,0.014119677245616913,0.014020188711583614,0.013994780369102955,0.013908610679209232,0.013822103850543499,0.013749564997851849,0.013678605668246746,0.01362940575927496,0.013545245863497257,0.013574075885117054,0.013399966061115265,0.020567964762449265,0.02302783913910389,0.022425100207328796,0.022727282717823982,0.02057916484773159,0.019941680133342743,0.021970655769109726,0.022938327863812447,0.021341698244214058,0.0203825943171978,0.021302837878465652,0.021781625226140022,0.020288141444325447,0.01910058967769146,0.020045481622219086,0.021080978214740753,0.020424282178282738,0.019256068393588066,0.01832943595945835,
mse,0.04541118070483208,0.0026530222967267036,0.000958475167863071,0.000659775163512677,0.0005552824586629868,0.0005152066587470472,0.00045435153879225254,0.0006129711982794106,0.0006274261977523565,0.0004671210190281272,0.0003138253523502499,0.00025183483376167715,0.0002626097993925214,0.0005110526690259576,0.00042629518429748714,0.0005030400352552533,0.0004858850734308362,0.0004664717707782984,0.00033002521377056837,0.0004596291109919548,0.00038087941356934607,0.0002895691432058811,0.00028473202837631106,0.00035935110645368695,0.0003744390851352364,0.00027703866362571716,0.00038427411345764995,0.0002846893621608615,0.00024202419444918633,0.00021102592290844768,0.00019885347865056247,0.00031034532003104687,0.0003064519842155278,0.00017579318955540657,0.0001362050825264305,0.00010107679554494098,9.039309225045145e-05,8.672710828250274e-05,8.376221376238391e-05,8.329068077728152e-05,8.078465180005878e-05,7.975949120009318e-05,7.96069361967966e-05,7.718404231127352e-05,7.664037548238412e-05,7.507635018555447e-05,7.515692414017394e-05,7.370746607193723e-05,7.141734386095777e-05,7.129816367523745e-05,7.122628448996693e-05,7.064109377097338e-05,6.848468910902739e-05,6.749348540324718e-05,6.683406536467373e-05,6.630885764025152e-05,6.553383718710393e-05,6.580117042176425e-05,6.433402450056747e-05,6.258821667870507e-05,6.287969154072925e-05,6.131635745987296e-05,6.171187123982236e-05,6.214066524989903e-05,6.0648322687484324e-05,6.0954414948355407e-05,5.815673648612574e-05,5.915877773077227e-05,5.7377066696062684e-05,5.642941323458217e-05,5.672711267834529e-05,5.530176349566318e-05,5.469184907269664e-05,5.40820365131367e-05,5.3908115660306066e-05,5.326802784111351e-05,5.2840987336821854e-05,5.2317860536277294e-05,5.208613947615959e-05,5.2601964853238314e-05,5.057740054326132e-05,0.0001301563752349466,0.0001515317417215556,0.00014428085705731064,0.0001422265631845221,0.00012696761405095458,0.00011793443991336972,0.00013789664080832154,0.00014498794917017221,0.00012833075015805662,0.00011930461914744228,0.0001339949667453766,0.00013224288704805076,0.00011833946336992085,0.00010588744044071063,0.00011193176032975316,0.00012367947783786803,0.00011693324631778523,0.00010568933794274926,9.645616955822334e-05,
mae,0.14316684007644653,0.03695806860923767,0.022849448025226593,0.01931869424879551,0.018078500404953957,0.017542535439133644,0.01656685210764408,0.01925032213330269,0.018787739798426628,0.016817394644021988,0.013867106288671494,0.01231552753597498,0.012590144760906696,0.017352469265460968,0.016346458345651627,0.017641110345721245,0.01724180579185486,0.017006484791636467,0.014119850471615791,0.01695353351533413,0.01580781489610672,0.013105112127959728,0.01309613510966301,0.01516342256218195,0.015558454208076,0.01361861452460289,0.015649423003196716,0.01349750254303217,0.012659359723329544,0.011615143157541752,0.011125240474939346,0.013745968230068684,0.013423729687929153,0.010140039958059788,0.009144462645053864,0.007735488936305046,0.0074927848763763905,0.007331616710871458,0.007232788018882275,0.007143373601138592,0.0070825726725161076,0.0070090522058308125,0.007155884988605976,0.006946956738829613,0.006966971792280674,0.006881100591272116,0.006837248802185059,0.006855141371488571,0.006808102130889893,0.006744544953107834,0.006592865101993084,0.006623223423957825,0.00665002828463912,0.006560878828167915,0.006425310391932726,0.0064374967478215694,0.0065249609760940075,0.006432217545807362,0.006349139381200075,0.006391320843249559,0.006328968796879053,0.006217101123183966,0.006235611625015736,0.006185181904584169,0.006221439223736525,0.006147438194602728,0.006183583755046129,0.0060812002047896385,0.006096808705478907,0.006042820401489735,0.005925923120230436,0.005893026478588581,0.005950430408120155,0.005890409927815199,0.00583774084225297,0.00583864189684391,0.005674462299793959,0.005785857327282429,0.005718736443668604,0.00569418678060174,0.005640221294015646,0.008768358267843723,0.009554808959364891,0.009537018835544586,0.00956485141068697,0.008602499030530453,0.008396368473768234,0.009257545694708824,0.00963586661964655,0.008952846750617027,0.008491861633956432,0.00912514328956604,0.009309825487434864,0.00852577481418848,0.008187869563698769,0.008471749722957611,0.008940557949244976,0.008622962050139904,0.008160565048456192,0.007896941155195236,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 18987     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 18988     
=================================================================
Total params: 37,975
Trainable params: 37,975
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 18,987
Trainable params: 18,987
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 18,988
Trainable params: 18,988
Non-trainable params: 0
_________________________________________________________________
