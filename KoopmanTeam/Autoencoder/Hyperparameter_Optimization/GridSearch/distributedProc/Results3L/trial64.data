2021-06-26
loss,0.3493460416793823,0.11338503658771515,0.09272737801074982,0.08210569620132446,0.07354481518268585,0.07613639533519745,0.07198622077703476,0.056342579424381256,0.04965090751647949,0.043367572128772736,0.05172598734498024,0.05368086323142052,0.05078567937016487,0.0512281209230423,0.040188055485486984,0.03651578724384308,0.03578777238726616,0.03474273532629013,0.04518091678619385,0.04057072103023529,0.04202837869524956,0.035041771829128265,0.03136000409722328,0.033294349908828735,0.035944268107414246,0.035474710166454315,0.032505735754966736,0.036794304847717285,0.030402453616261482,0.029072657227516174,0.03498893603682518,0.035560861229896545,0.030808808282017708,0.030600694939494133,0.032472603023052216,0.029248390346765518,0.02717430330812931,0.026404500007629395,0.03052438795566559,0.027656586840748787,0.026801051571965218,0.031139865517616272,0.028444891795516014,0.026663046330213547,0.025420572608709335,0.025780821219086647,0.02557200752198696,0.024813594296574593,0.022846190258860588,0.02210024558007717,0.018778081983327866,0.021638311445713043,0.02704564295709133,0.027058178558945656,0.0241447314620018,0.022414634004235268,0.02084372192621231,0.0195232592523098,0.01850767992436886,0.021984243765473366,0.0241532064974308,0.023526206612586975,0.024967055767774582,0.02365383692085743,0.02398981899023056,0.02066005952656269,0.020934930071234703,0.023595940321683884,0.02277783676981926,0.021859807893633842,0.022070495411753654,0.02089700847864151,0.021870367228984833,0.02138502150774002,0.01906782016158104,0.017159052193164825,0.016022372990846634,0.01478552259504795,0.015561134554445744,0.018072552978992462,0.021954147145152092,0.019942672923207283,0.02072357013821602,0.01790277287364006,0.015511821955442429,0.01950223743915558,0.017505984753370285,0.01756889373064041,0.015169225633144379,0.018818141892552376,0.019370265305042267,0.020596208050847054,0.02007697895169258,0.02074919268488884,0.018040072172880173,0.017507167533040047,0.015307178720831871,0.012953492812812328,0.01207160484045744,0.01119788084179163,
mse,0.04657302424311638,0.004083773121237755,0.0025009738747030497,0.002014386933296919,0.001534227398224175,0.0016229088651016355,0.0014432986499741673,0.0009236538899131119,0.0007064884412102401,0.0005444775451906025,0.0007723327726125717,0.0008234241395257413,0.0007122365641407669,0.0007525627152062953,0.0004767577338498086,0.00038781811599619687,0.000374552357243374,0.000368142849765718,0.0005919104442000389,0.0004658796242438257,0.0005035497015342116,0.0003451963420957327,0.00028245968860574067,0.00033795664785429835,0.0003747287264559418,0.0003593354776967317,0.0003045550256501883,0.00040013340185396373,0.0002696996962185949,0.0002511779312044382,0.00035643280716612935,0.00035865046083927155,0.0002741493808571249,0.00026920082746073604,0.00029564977739937603,0.0002473193744663149,0.00022045055811759084,0.0002111310459440574,0.000266151299001649,0.0002203747135354206,0.00021073110110592097,0.00027757760835811496,0.00023404443345498294,0.0002044581633526832,0.0001886671525426209,0.00019280225387774408,0.00018904957687482238,0.00017132709035649896,0.00014869154256302863,0.0001398852764395997,0.00010619068780215457,0.00014263241610024124,0.00020894143381156027,0.00020583753939718008,0.0001674179802648723,0.00014237398863770068,0.00012577182496897876,0.00011110160266980529,0.00010366644710302353,0.0001463786029489711,0.00017413827299606055,0.0001591245672898367,0.0001735099940560758,0.00015946417988743633,0.00016304507153108716,0.00012752409384120256,0.00012805062578991055,0.00016014702850952744,0.0001463355147279799,0.00013916735770180821,0.00013647829473484308,0.00012313161278143525,0.0001378755405312404,0.00013063105870969594,0.00010453996947035193,8.776420872891322e-05,7.649884355487302e-05,6.558761378983036e-05,7.543615356553346e-05,9.871770453173667e-05,0.00013398323790170252,0.00011421413364587352,0.0001216333475895226,9.631038847146556e-05,7.400214963126928e-05,0.00011101795098511502,9.164926450466737e-05,9.179603512166068e-05,7.075535540934652e-05,0.00010251150524709374,0.00010452858987264335,0.00011989314953098074,0.00011384023673599586,0.00012066416093148291,9.120777394855395e-05,8.978931873571128e-05,7.165088027250022e-05,5.315750968293287e-05,4.4272281229496e-05,3.712644684128463e-05,
mae,0.15062688291072845,0.04851899668574333,0.0395192950963974,0.03558116778731346,0.031528424471616745,0.03254599869251251,0.031434543430805206,0.024399705231189728,0.021370558068156242,0.01849871315062046,0.02211597189307213,0.022894825786352158,0.02165708690881729,0.02218405157327652,0.017251934856176376,0.015649523586034775,0.015332648530602455,0.014828532002866268,0.01947779580950737,0.017351791262626648,0.018109917640686035,0.015388020314276218,0.013492508791387081,0.014265217818319798,0.015409269370138645,0.0150271225720644,0.013821860775351524,0.015798265114426613,0.012892859056591988,0.012574107386171818,0.015050913207232952,0.015325527638196945,0.013255921192467213,0.013074295595288277,0.013956733047962189,0.012670005671679974,0.011592991650104523,0.011173635721206665,0.0129522904753685,0.01119260210543871,0.011479416862130165,0.013458723202347755,0.012495404109358788,0.011700727045536041,0.01091307308524847,0.010867549106478691,0.010951702482998371,0.010710966773331165,0.009809554554522038,0.009446204639971256,0.008005000650882721,0.009176110848784447,0.011587194167077541,0.0116684315726161,0.010182028636336327,0.009449955075979233,0.00886253546923399,0.008414407260715961,0.007932361215353012,0.009327693842351437,0.010238131508231163,0.009808719158172607,0.010502598248422146,0.010015744715929031,0.010314333252608776,0.008753996342420578,0.008929542265832424,0.01009364239871502,0.00974547304213047,0.00929479394108057,0.00977033656090498,0.009023886173963547,0.009393367916345596,0.009068395011126995,0.007944783195853233,0.007372748106718063,0.006866435520350933,0.0063360268250107765,0.006602163892239332,0.0076706288382411,0.009304549545049667,0.00842963345348835,0.008945200592279434,0.007792044430971146,0.006601231638342142,0.008234945125877857,0.0074357884004712105,0.0075265769846737385,0.006423240527510643,0.007994499057531357,0.008374680764973164,0.008659291081130505,0.008480649441480637,0.008860674686729908,0.007704842835664749,0.007403695024549961,0.00654838141053915,0.005493117496371269,0.005146007519215345,0.00478137843310833,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 41811     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 41812     
=================================================================
Total params: 83,623
Trainable params: 83,623
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 41,811
Trainable params: 41,811
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 41,812
Trainable params: 41,812
Non-trainable params: 0
_________________________________________________________________
