2021-06-26
loss,0.37356317043304443,0.10192637145519257,0.055901311337947845,0.04042376950383186,0.0346580445766449,0.03184475377202034,0.029908079653978348,0.02817331999540329,0.026973655447363853,0.02589820884168148,0.02496054209768772,0.02413683943450451,0.02357230894267559,0.02314244769513607,0.02269245870411396,0.022206950932741165,0.021750647574663162,0.021396750584244728,0.021247180178761482,0.020823178812861443,0.02050652913749218,0.020204516127705574,0.01996936835348606,0.019875213503837585,0.01963115856051445,0.0193304605782032,0.019243715330958366,0.018959110602736473,0.018890906125307083,0.018687665462493896,0.01853848434984684,0.018364686518907547,0.01828065700829029,0.018082575872540474,0.017903663218021393,0.017818694934248924,0.01777772605419159,0.017573218792676926,0.01754416525363922,0.01737385056912899,0.017295924946665764,0.017193729057908058,0.016860278323292732,0.017018796876072884,0.01684277132153511,0.016741085797548294,0.01660298742353916,0.016597546637058258,0.016428813338279724,0.016423406079411507,0.016319356858730316,0.02162839099764824,0.027126643806695938,0.021097056567668915,0.02798124961555004,0.023374969139695168,0.021617701277136803,0.02034129947423935,0.019293630495667458,0.018939629197120667,0.018095048144459724,0.021473517641425133,0.028638748452067375,0.025747248902916908,0.023639218881726265,0.022251920774579048,0.021197743713855743,0.020339906215667725,0.019650623202323914,0.01913558319211006,0.018734542652964592,0.03226820006966591,0.028238875791430473,0.02555996924638748,0.024160079658031464,0.022986438125371933,0.022138044238090515,0.021470051258802414,0.02087687887251377,0.02866748347878456,0.03216348960995674,0.029191486537456512,0.02720082737505436,0.025855455547571182,0.024794964119791985,0.02382322959601879,0.022762665525078773,0.021778807044029236,0.020592696964740753,0.01960328035056591,0.01884600892663002,0.018299736082553864,0.017804229632019997,0.017390167340636253,0.016992079094052315,0.01666080206632614,0.016414618119597435,0.016147177666425705,0.015907907858490944,0.01573311723768711,
mse,0.06069149076938629,0.0037923501804471016,0.001015790388919413,0.000504548370372504,0.00036038554389961064,0.00029860626091249287,0.00026028789579868317,0.0002287762181367725,0.00020805098756682128,0.00019135813636239618,0.00017701537581160665,0.0001654547668294981,0.00015762400289531797,0.000151626649312675,0.00014565915626008064,0.0001387102820444852,0.0001334798289462924,0.00012935593258589506,0.00012663948291447014,0.00012218324991408736,0.00011815025209216401,0.00011434547923272476,0.00011160344001837075,0.00011067480954807252,0.00010773433314170688,0.00010458016186021268,0.00010326607298338786,0.00010059261694550514,9.962403419194743e-05,9.724814299261197e-05,9.565216168994084e-05,9.418933041160926e-05,9.286607382819057e-05,9.134893480222672e-05,8.898328815121204e-05,8.825911208987236e-05,8.78045175340958e-05,8.566029282519594e-05,8.541857823729515e-05,8.393079770030454e-05,8.249781967606395e-05,8.174498361768201e-05,7.89146579336375e-05,8.026203431654721e-05,7.835454016458243e-05,7.764804468024522e-05,7.600786193506792e-05,7.596465002279729e-05,7.455878949258476e-05,7.459703920176253e-05,7.351352542173117e-05,0.000172857879078947,0.00023933844931889325,0.00014781257777940482,0.0002284046495333314,0.00015343660197686404,0.00013235399092081934,0.00011695381544996053,0.00010627962910803035,0.00010253044456476346,9.334888454759493e-05,0.0001422805362381041,0.00022691652702633291,0.00018283806275576353,0.00015428934420924634,0.00013626272266265005,0.00012334634084254503,0.00011352004366926849,0.0001063247473211959,0.00010099264181917533,9.716876957099885e-05,0.00030270247953012586,0.00021737698989454657,0.00017798820044845343,0.00015928935317788273,0.000144580626511015,0.0001349330850644037,0.0001274141250178218,0.00012169581168564036,0.0002480443217791617,0.00028379837749525905,0.00023324762878473848,0.00020380858040880412,0.00018369837198406458,0.00016848661471158266,0.0001558502990519628,0.00014223525067791343,0.00012932672689203173,0.00011608420027187094,0.00010606057912809774,9.809991024667397e-05,9.26192951737903e-05,8.800294017419219e-05,8.427146531175822e-05,8.045794675126672e-05,7.751698285574093e-05,7.542496314272285e-05,7.303016900550574e-05,7.077317422954366e-05,6.894056423334405e-05,
mae,0.16031035780906677,0.04282832145690918,0.02340746857225895,0.01705842651426792,0.014665942639112473,0.013577831909060478,0.01279227714985609,0.012047533877193928,0.011542069725692272,0.011155163869261742,0.010655815713107586,0.010392806492745876,0.010144666768610477,0.009937146678566933,0.009809241630136967,0.009593215771019459,0.009374957531690598,0.009223336353898048,0.009096432477235794,0.008974862284958363,0.008780783042311668,0.00855251681059599,0.008522294461727142,0.008565772324800491,0.00835749227553606,0.008180027827620506,0.008319752290844917,0.008135984651744366,0.007995727472007275,0.008061499334871769,0.007923256605863571,0.007800198160111904,0.007800090126693249,0.007696198765188456,0.007700966205447912,0.007629103492945433,0.007511490024626255,0.007533568888902664,0.007512872107326984,0.007392963394522667,0.007382567506283522,0.007347856182605028,0.0071672601625323296,0.007319379597902298,0.007131853606551886,0.007181169465184212,0.007058215327560902,0.007150253746658564,0.006963278632611036,0.007037265691906214,0.0069588953629136086,0.009121173992753029,0.012019965797662735,0.008820301853120327,0.012211507186293602,0.010552534833550453,0.009907061234116554,0.009262879379093647,0.008626680821180344,0.008396677672863007,0.007952255196869373,0.009262369014322758,0.011982443742454052,0.011082768440246582,0.010259474627673626,0.009647049941122532,0.00921199843287468,0.008849677629768848,0.008586814627051353,0.008236557245254517,0.007970710285007954,0.013175994157791138,0.011325049214065075,0.010342627763748169,0.009804810397326946,0.00938362069427967,0.009082682430744171,0.008829096332192421,0.008623825386166573,0.012296270579099655,0.013929210603237152,0.012748181819915771,0.011966773308813572,0.011467554606497288,0.011042110621929169,0.01056606788188219,0.009600060991942883,0.009278777986764908,0.009078835137188435,0.008577440865337849,0.008153866045176983,0.007867605425417423,0.007598060183227062,0.007386305835098028,0.007174158468842506,0.007024448364973068,0.0069153220392763615,0.006744109559804201,0.006681808270514011,0.006594485603272915,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 4451      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 4452      
=================================================================
Total params: 8,903
Trainable params: 8,903
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 4,451
Trainable params: 4,451
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 4,452
Trainable params: 4,452
Non-trainable params: 0
_________________________________________________________________
