2021-06-26
loss,0.36816707253456116,0.11047816276550293,0.0745498389005661,0.07982861250638962,0.06051572412252426,0.054796501994132996,0.06374133378267288,0.05164254829287529,0.048996374011039734,0.04665656387805939,0.03787790611386299,0.03613008186221123,0.04680454358458519,0.04229043051600456,0.04450402408838272,0.038140032440423965,0.03560206666588783,0.03398057073354721,0.03591914474964142,0.04028836265206337,0.03210042417049408,0.03196650743484497,0.030752278864383698,0.02836419828236103,0.030418625101447105,0.033893223851919174,0.0315224714577198,0.03005434200167656,0.03195999190211296,0.02830498479306698,0.024258604273200035,0.021600371226668358,0.022799057886004448,0.02771085686981678,0.027129950001835823,0.025645321235060692,0.024645300582051277,0.026283415034413338,0.024086756631731987,0.021651998162269592,0.021553397178649902,0.022869283333420753,0.021801427006721497,0.024023404344916344,0.022692620754241943,0.019567808136343956,0.0158615093678236,0.01692110113799572,0.018549619242548943,0.019738325849175453,0.017551712691783905,0.020119979977607727,0.020244592800736427,0.020473750308156013,0.015708208084106445,0.016841918230056763,0.01938479021191597,0.01718425191938877,0.017453832551836967,0.01752215065062046,0.0193528663367033,0.017462486401200294,0.016326552256941795,0.01473270170390606,0.018850645050406456,0.017474330961704254,0.015619460493326187,0.014413628727197647,0.013427912257611752,0.01605360023677349,0.01859237253665924,0.016615333035588264,0.016756447032094002,0.01571935974061489,0.015286006033420563,0.01544858142733574,0.01611923798918724,0.014613292180001736,0.014880720525979996,0.016446778550744057,0.015838854014873505,0.013662817887961864,0.011755687184631824,0.015020756982266903,0.01565159298479557,0.014935385435819626,0.015482865273952484,0.015068717300891876,0.014571620151400566,0.011818354949355125,0.011702951043844223,0.012242961674928665,0.01253923773765564,0.0151923643425107,0.015174773521721363,0.014271175488829613,0.01507163792848587,0.014139455743134022,0.01297664362937212,0.01228190865367651,
mse,0.058423686772584915,0.0037929266691207886,0.0016270405612885952,0.0018517100252211094,0.00106392044108361,0.000872490112669766,0.0011645047925412655,0.0007882036734372377,0.0007185106514953077,0.0006650810828432441,0.00042141630547121167,0.000386698025977239,0.0006423605955205858,0.000535321538336575,0.0005626544007100165,0.0004141032986808568,0.0003767444286495447,0.0003473937977105379,0.0003814356168732047,0.00047920236829668283,0.00030315181356854737,0.0003040641313418746,0.00028028973611071706,0.0002456192742101848,0.00027114266413263977,0.0003383895382285118,0.0002874171477742493,0.000260142725892365,0.00028432009276002645,0.0002335801545996219,0.00017739302711561322,0.0001440451160306111,0.00016045261872932315,0.0002198501897510141,0.0002088958426611498,0.00018820827244780958,0.00017601765284780413,0.0001980547676794231,0.0001658606925047934,0.0001372374244965613,0.00013708211190532893,0.00015514480764977634,0.00013904162915423512,0.0001616385707166046,0.00014215681585483253,0.00011638970318017527,7.583721890114248e-05,8.746676030568779e-05,0.00010467982792761177,0.00011563683074200526,9.25244385143742e-05,0.00011810396972578019,0.00011948490282520652,0.00011733344581443816,7.561758684460074e-05,8.58481289469637e-05,0.00010857438610401005,8.773653098614886e-05,9.050682274391875e-05,9.031152148963884e-05,0.00010378050501458347,8.842664101393893e-05,7.950825965963304e-05,6.4918800489977e-05,9.993650019168854e-05,8.657697617309168e-05,7.239289698190987e-05,6.14736054558307e-05,5.3555399063043296e-05,7.745949551463127e-05,9.650707215769216e-05,7.764290785416961e-05,8.090306801022962e-05,7.112133607733995e-05,6.832470535300672e-05,6.848234625067562e-05,7.466138777090237e-05,6.463735189754516e-05,6.423950981115922e-05,7.66418015700765e-05,7.08499428583309e-05,5.4133190133143216e-05,4.2680432670749724e-05,6.577153544640169e-05,6.899207073729485e-05,6.398384721251205e-05,6.898633000673726e-05,6.431557994801551e-05,6.186028622323647e-05,4.266817632014863e-05,4.253039514878765e-05,4.6331035264302045e-05,4.802961848326959e-05,6.802533607697114e-05,6.494907574960962e-05,5.819228317704983e-05,6.46083353785798e-05,5.6528617278672755e-05,4.751451706397347e-05,4.28011771873571e-05,
mae,0.15652413666248322,0.04773970693349838,0.03165990859270096,0.033960506319999695,0.025886209681630135,0.02322557009756565,0.027473261579871178,0.021796518936753273,0.02068900503218174,0.01992395892739296,0.01595539040863514,0.015285330824553967,0.019904309883713722,0.017997244372963905,0.01896604336798191,0.016238905489444733,0.015060833655297756,0.014439859427511692,0.015250164084136486,0.017293166369199753,0.013777084648609161,0.013516158796846867,0.013080059550702572,0.012156974524259567,0.012789013795554638,0.01428076159209013,0.013522165827453136,0.012785693630576134,0.013517342507839203,0.011674049310386181,0.010393824428319931,0.009183354675769806,0.009665405377745628,0.011823082342743874,0.011526325717568398,0.010854068212211132,0.010517588816583157,0.011332148686051369,0.0102711021900177,0.009160738438367844,0.009103918448090553,0.009635750204324722,0.009224584326148033,0.010178519412875175,0.009589985944330692,0.0082017220556736,0.006790732964873314,0.007253437768667936,0.007984228432178497,0.008338731713593006,0.007409979589283466,0.008491155691444874,0.008658284321427345,0.008611755445599556,0.0067211478017270565,0.007054930552840233,0.008164617232978344,0.0072800288908183575,0.007437158841639757,0.007452466990798712,0.008231163956224918,0.007384850177913904,0.006959909573197365,0.006227681413292885,0.00782427005469799,0.007446832489222288,0.006654274649918079,0.006175785791128874,0.005722113884985447,0.006809311918914318,0.007911724038422108,0.0070317769423127174,0.0070686643011868,0.006556681357324123,0.00651088310405612,0.00647928100079298,0.006855489686131477,0.00623718136921525,0.006296181585639715,0.006975517142564058,0.006729738786816597,0.005790633615106344,0.004908564500510693,0.006378035061061382,0.006661046762019396,0.0062553416937589645,0.006544053088873625,0.006395614705979824,0.00610263692215085,0.005001870449632406,0.004910638555884361,0.005097844172269106,0.005258238408714533,0.006461247801780701,0.006463116966187954,0.006100911647081375,0.006419761572033167,0.006018697749823332,0.005530314054340124,0.0052388496696949005,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 66627     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 66628     
=================================================================
Total params: 133,255
Trainable params: 133,255
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 66,627
Trainable params: 66,627
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 66,628
Trainable params: 66,628
Non-trainable params: 0
_________________________________________________________________
