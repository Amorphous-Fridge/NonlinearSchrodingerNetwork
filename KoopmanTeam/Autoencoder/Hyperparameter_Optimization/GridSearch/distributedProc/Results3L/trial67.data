2021-06-26
loss,0.309666246175766,0.20284253358840942,0.10184556245803833,0.06563833355903625,0.049158744513988495,0.04523519054055214,0.04984799399971962,0.03645063191652298,0.04152153804898262,0.03577880933880806,0.03252230957150459,0.03554203733801842,0.03360708802938461,0.03133609518408775,0.035007089376449585,0.04403252527117729,0.03897230699658394,0.033952582627534866,0.030986638739705086,0.03223595768213272,0.028624705970287323,0.024043671786785126,0.027692439034581184,0.03526519238948822,0.027404196560382843,0.02428240142762661,0.022840678691864014,0.030893972143530846,0.0325850211083889,0.028790395706892014,0.02653173916041851,0.024391554296016693,0.023393791168928146,0.024478156119585037,0.018981916829943657,0.021369021385908127,0.026339614763855934,0.022563261911273003,0.02093253843486309,0.019758624956011772,0.01853545382618904,0.02120426669716835,0.027120351791381836,0.026232708245515823,0.02726193144917488,0.026823997497558594,0.024034537374973297,0.02227969653904438,0.0208295751363039,0.019652778282761574,0.01853790134191513,0.017649730667471886,0.01671934314072132,0.023866398259997368,0.026136038824915886,0.020024418830871582,0.020303724333643913,0.019625140354037285,0.021837914362549782,0.020754048600792885,0.01949300430715084,0.01841258816421032,0.016760723665356636,0.016043854877352715,0.016376662999391556,0.01630348525941372,0.01613771542906761,0.017853308469057083,0.024531055241823196,0.020973922684788704,0.019516143947839737,0.01829659380018711,0.01981041394174099,0.020920509472489357,0.019409291446208954,0.018173081800341606,0.016766510903835297,0.015856178477406502,0.014843047596514225,0.013686138205230236,0.012996478006243706,0.012823540717363358,0.012806101702153683,0.013390419073402882,0.021246902644634247,0.018807008862495422,0.017500484362244606,0.016781603917479515,0.01677674800157547,0.020094843581318855,0.01761993207037449,0.016073836013674736,0.016611434519290924,0.016803747043013573,0.015691855922341347,0.019262932240962982,0.017374061048030853,0.016575081273913383,0.015794653445482254,0.0151496771723032,
mse,0.03346168249845505,0.014988438226282597,0.003246433101594448,0.0012949907686561346,0.0007100885850377381,0.0006049785297363997,0.0007222486310638487,0.00039270296110771596,0.0005092984647490084,0.0003821936552412808,0.00030917246476747096,0.0003672762250062078,0.0003204375971108675,0.0002809858415275812,0.0003615928872022778,0.0005492294440045953,0.0004260416026227176,0.00033326642005704343,0.0002794990432448685,0.0003040001611225307,0.00023526119184680283,0.00016801842139102519,0.00023775955196470022,0.000352817471139133,0.00020957620290573686,0.00016415066784247756,0.00014866524725221097,0.0002769622369669378,0.00029913533944636583,0.00023351656273007393,0.0002080085687339306,0.00017420659423805773,0.00015853147488087416,0.0001755881676217541,0.00010484606900718063,0.00014037203800398856,0.0001896416797535494,0.0001415237202309072,0.0001226755848620087,0.00010878354078158736,9.901080193230882e-05,0.00013693432265426964,0.00021121236204635352,0.00019140444055665284,0.00020959801622666419,0.000204745345399715,0.0001660301786614582,0.00014009747246745974,0.00012276986672077328,0.00010948664566967636,9.925301128532737e-05,8.98513535503298e-05,8.109241025522351e-05,0.00016525032697245479,0.00019090289424639195,0.00011794139572884887,0.0001197878664243035,0.00011032127076759934,0.00013312543160282075,0.00012062712630722672,0.00010607997683109716,9.479027357883751e-05,8.007628639461473e-05,7.374543201876804e-05,8.045243885135278e-05,8.024254930205643e-05,7.668870239285752e-05,9.568680980009958e-05,0.00016421360487584025,0.0001247706386493519,0.0001098205175367184,9.723813127493486e-05,0.00011264581553405151,0.0001224211446242407,0.00010598688095342368,9.169353143079206e-05,7.833207200746983e-05,7.087134872563183e-05,6.322458648355678e-05,5.5558892199769616e-05,5.090679042041302e-05,5.100806083646603e-05,4.9066467909142375e-05,5.433975820778869e-05,0.00012656931357923895,0.0001023130607791245,8.576057734899223e-05,8.045533468248323e-05,8.005635027075186e-05,0.00011095006630057469,8.673858246766031e-05,7.322321471292526e-05,8.033067570067942e-05,7.917353650555015e-05,7.069107959978282e-05,0.00010330352961318567,8.462352707283571e-05,7.735659164609388e-05,7.184846617747098e-05,6.597257015528157e-05,
mae,0.13036105036735535,0.08609365671873093,0.04323362186551094,0.028093744069337845,0.02057243511080742,0.019006459042429924,0.021285567432641983,0.015480585396289825,0.017615022137761116,0.015306390821933746,0.013807607814669609,0.014960012398660183,0.014343446120619774,0.013486661948263645,0.014769217930734158,0.01852891407907009,0.016710314899683,0.014633194543421268,0.013235729187726974,0.01361815258860588,0.012143629603087902,0.010250840336084366,0.011794453486800194,0.014985834248363972,0.011476259678602219,0.01024311687797308,0.009729609824717045,0.013359134085476398,0.013554301112890244,0.012286546640098095,0.011189291253685951,0.010280993767082691,0.00992796290665865,0.010459650307893753,0.008050155825912952,0.009182167239487171,0.011346213519573212,0.009214391931891441,0.008670981973409653,0.00818259920924902,0.00793822854757309,0.009011099115014076,0.011324289254844189,0.01111498475074768,0.011507106944918633,0.0113699771463871,0.010191158391535282,0.009500081650912762,0.008680414408445358,0.00806675385683775,0.007576220668852329,0.007380843162536621,0.00711415708065033,0.01015474833548069,0.011013256385922432,0.008514910005033016,0.008575361222028732,0.008300709538161755,0.009254369884729385,0.008542516268789768,0.007909703068435192,0.007419506087899208,0.0071245525032281876,0.006909885909408331,0.006979588884860277,0.006941727828234434,0.006942691281437874,0.007516246289014816,0.010394948534667492,0.008804012089967728,0.008275655098259449,0.00770658440887928,0.008328696712851524,0.008715799078345299,0.00810835137963295,0.007843424566090107,0.007236866746097803,0.006817526649683714,0.006378074176609516,0.005893287248909473,0.005620617885142565,0.005468625575304031,0.005417427979409695,0.005684927571564913,0.009121282026171684,0.00806512963026762,0.007597178686410189,0.007278142962604761,0.007104366552084684,0.008445505984127522,0.007487106136977673,0.006923293694853783,0.007074345368891954,0.007194297853857279,0.006702833343297243,0.00806291215121746,0.007463349029421806,0.007144074887037277,0.00677343737334013,0.006444865372031927,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 21187     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 21188     
=================================================================
Total params: 42,375
Trainable params: 42,375
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 21,187
Trainable params: 21,187
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 21,188
Trainable params: 21,188
Non-trainable params: 0
_________________________________________________________________
