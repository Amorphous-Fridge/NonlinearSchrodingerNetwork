2021-06-26
loss,0.3237644135951996,0.06497937440872192,0.04954420402646065,0.04336369410157204,0.03939617797732353,0.03927294909954071,0.04723002761602402,0.04232820123434067,0.0387372225522995,0.052660856395959854,0.04152321815490723,0.03706737607717514,0.03297805041074753,0.03897407650947571,0.040337152779102325,0.054811447858810425,0.04702897369861603,0.03731155768036842,0.03515932336449623,0.032014161348342896,0.03660941869020462,0.04637087509036064,0.03561804071068764,0.02436010353267193,0.02317517250776291,0.022447118535637856,0.022047458216547966,0.02164674922823906,0.021476641297340393,0.021459851413965225,0.02103627473115921,0.020920107141137123,0.02101760357618332,0.020664487034082413,0.020488688722252846,0.02198435738682747,0.03268543630838394,0.03196706995368004,0.03764800354838371,0.03413854539394379,0.030057668685913086,0.0272409375756979,0.03042329102754593,0.031355854123830795,0.028111636638641357,0.026230495423078537,0.02375413477420807,0.021782150492072105,0.021338116377592087,0.025372013449668884,0.03477666154503822,0.03352973610162735,0.03192562237381935,0.029575921595096588,0.02382594347000122,0.025616716593503952,0.029835129156708717,0.02834298461675644,0.026464447379112244,0.030071042478084564,0.027508992701768875,0.02532343380153179,0.02373071387410164,0.024918019771575928,0.026508376002311707,0.025909407064318657,0.02366049215197563,0.02212737500667572,0.02112363837659359,0.0209826547652483,0.022443709895014763,0.024000123143196106,0.022568251937627792,0.026358306407928467,0.026045696809887886,0.024279186502099037,0.023049447685480118,0.021635793149471283,0.02098964899778366,0.020207248628139496,0.018346332013607025,0.018141301348805428,0.021566646173596382,0.02169695310294628,0.02040698006749153,0.02092968486249447,0.021320173516869545,0.02512732893228531,0.023252271115779877,0.021945759654045105,0.020677683874964714,0.01968645304441452,0.018854398280382156,0.018188757821917534,0.017349913716316223,0.02037089504301548,0.02092103287577629,0.01930895633995533,0.01838521659374237,0.021195992827415466,
mse,0.054691821336746216,0.001350477454252541,0.0007553884643130004,0.0005479026003740728,0.0004443639481905848,0.00046409328933805227,0.0006427241605706513,0.000501168193295598,0.00042566834599711,0.0007791580283083022,0.0004750820517074317,0.0003827830369118601,0.0003201993531547487,0.000425778329372406,0.00048420627717860043,0.0008857580833137035,0.000623280939180404,0.0003959810419473797,0.0003406900796107948,0.00029328695381991565,0.0003977961605414748,0.0006030127988196909,0.00036551884841173887,0.00017684152408037335,0.00015464986790902913,0.00014465147978626192,0.00013897533062845469,0.0001349367230432108,0.0001352460531052202,0.00013086591206956655,0.00012955580314155668,0.00012786990555468947,0.00012507106293924153,0.00012011399667244405,0.00011861047096317634,0.0001482329098507762,0.00030421733390539885,0.00028672345797531307,0.00039393716724589467,0.00032831833232194185,0.0002491020713932812,0.00020923676493111998,0.00026269175577908754,0.00026734909624792635,0.00021915337129030377,0.00019030430121347308,0.00016202426922973245,0.00013996406050864607,0.00013437059533316642,0.0001847415551310405,0.00034056376898661256,0.0003147911629639566,0.0002868963638320565,0.00024578592274338007,0.0001669823977863416,0.00019170535961166024,0.00024754696642048657,0.0002226555661763996,0.00020465560373850167,0.0002464994031470269,0.00021321894018910825,0.00018455713870935142,0.00015964717022143304,0.00017529394244775176,0.00019753344531636685,0.00018890868523158133,0.0001546860148664564,0.00013950647553429008,0.00012590560072567314,0.00012746488209813833,0.00014345931413117796,0.00015594791329931468,0.0001448483089916408,0.000196667795535177,0.0001896306494018063,0.0001655251398915425,0.00014892453327775002,0.00013490325363818556,0.00012667427654378116,0.00011637988791335374,9.714349289424717e-05,9.599411714589223e-05,0.00012918267748318613,0.0001308321370743215,0.00011699972674250603,0.00012473251263145357,0.00012798374518752098,0.00017594918608665466,0.00015014597738627344,0.00013429531827569008,0.00011912244372069836,0.00010855033906409517,0.00010158627264900133,9.258838690584525e-05,8.508867904311046e-05,0.0001170455216197297,0.00012124333443352953,0.00010325341281713918,9.423462324775755e-05,0.00012804384459741414,
mae,0.13554799556732178,0.027668090537190437,0.021032705903053284,0.018482353538274765,0.01697050780057907,0.01677856408059597,0.019887512549757957,0.01771245151758194,0.016379067674279213,0.02219517156481743,0.017258675768971443,0.015909720212221146,0.014163748361170292,0.016382036730647087,0.016974352300167084,0.023333407938480377,0.020573081448674202,0.015615515410900116,0.014817854389548302,0.013754729181528091,0.015729578211903572,0.020496198907494545,0.015285580419003963,0.010433278977870941,0.010075904428958893,0.009812843054533005,0.009594653733074665,0.009307898581027985,0.009254942648112774,0.009249698370695114,0.00914694182574749,0.008982478640973568,0.009105795994400978,0.008877325803041458,0.008777766488492489,0.009494101628661156,0.013547753915190697,0.013439907692372799,0.01623339205980301,0.013984279707074165,0.01255878247320652,0.011800763197243214,0.013266989961266518,0.013772283680737019,0.012399980798363686,0.011425257660448551,0.010346150025725365,0.009518667124211788,0.008950455114245415,0.010753349401056767,0.014839529991149902,0.014614097774028778,0.014098530635237694,0.012411300092935562,0.010275686159729958,0.01093752309679985,0.012883709743618965,0.011676022782921791,0.011072683148086071,0.0130003048107028,0.01185867190361023,0.010667284950613976,0.010167231783270836,0.010582753457129002,0.01150062121450901,0.011072455905377865,0.009804905392229557,0.009483144618570805,0.009028874337673187,0.008931395597755909,0.009595957584679127,0.010101164691150188,0.009581368416547775,0.011309215798974037,0.011627726256847382,0.010890090838074684,0.010164315812289715,0.009372829459607601,0.008968440815806389,0.008578372187912464,0.007856260985136032,0.007684424519538879,0.009210478514432907,0.009113302454352379,0.008785503916442394,0.008870532736182213,0.009085958823561668,0.010847646743059158,0.010197669267654419,0.009664488025009632,0.008669305592775345,0.007881663739681244,0.007527255453169346,0.00730131845921278,0.007170998025685549,0.008511408232152462,0.008659830316901207,0.00822110753506422,0.007746904622763395,0.009046399965882301,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 10755     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 10756     
=================================================================
Total params: 21,511
Trainable params: 21,511
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 10,755
Trainable params: 10,755
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 10,756
Trainable params: 10,756
Non-trainable params: 0
_________________________________________________________________
