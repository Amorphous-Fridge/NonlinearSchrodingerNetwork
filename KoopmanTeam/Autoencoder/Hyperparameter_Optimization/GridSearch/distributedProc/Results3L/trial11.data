2021-06-26
loss,0.527220606803894,0.1849856972694397,0.07246249169111252,0.05047965049743652,0.04193074256181717,0.03693181648850441,0.033377908170223236,0.03105597011744976,0.02936268411576748,0.028149079531431198,0.026792483404278755,0.025687523186206818,0.025182927027344704,0.024276020005345345,0.02360823005437851,0.023019185289740562,0.022402076050639153,0.02206697314977646,0.0216281246393919,0.02118467167019844,0.020831873640418053,0.020395338535308838,0.020172467455267906,0.019918836653232574,0.019817151129245758,0.01940280944108963,0.019047332927584648,0.01899300329387188,0.018691783770918846,0.01853087916970253,0.01826593279838562,0.018208399415016174,0.018000133335590363,0.017900817096233368,0.017648331820964813,0.017660804092884064,0.017367620021104813,0.017462188377976418,0.017230037599802017,0.01706971414387226,0.0168951116502285,0.01697530783712864,0.016832591965794563,0.01663176342844963,0.016510456800460815,0.016300229355692863,0.01645951345562935,0.016286775469779968,0.016205722466111183,0.016058873385190964,0.015985392034053802,0.01591876894235611,0.01590225286781788,0.015818260610103607,0.015558239072561264,0.01565036177635193,0.015471355058252811,0.015444224700331688,0.01525930967181921,0.01536482572555542,0.015252373181283474,0.015189643949270248,0.015136421658098698,0.015062767080962658,0.014921574853360653,0.014893941581249237,0.01482702512294054,0.014748631976544857,0.014674085192382336,0.01461311336606741,0.01458325982093811,0.014651764184236526,0.014463275671005249,0.014505264349281788,0.01433601975440979,0.014342838898301125,0.014314316213130951,0.014178600162267685,0.014111573807895184,0.014105062931776047,0.01411600224673748,0.014066064730286598,0.013968309387564659,0.013923509046435356,0.01390813011676073,0.013870220631361008,0.013848227448761463,0.013892881572246552,0.0137525275349617,0.013678177259862423,0.01372856181114912,0.013656334951519966,0.013634308241307735,0.013674819841980934,0.013463295996189117,0.013550217263400555,0.013467036187648773,0.013444524258375168,0.013352504000067711,0.013385581783950329,
mse,0.11576059460639954,0.012284130789339542,0.001958827953785658,0.000912291172426194,0.0006135755684226751,0.0004692152142524719,0.0003768008609768003,0.00032071713940240443,0.00028210823074914515,0.00025600410299375653,0.0002297103637829423,0.00021078891586512327,0.00019989479915238917,0.0001849639811553061,0.0001732311793603003,0.0001644640724407509,0.00015447207260876894,0.00014960354019422084,0.00014262368495110422,0.00013656917144544423,0.00013251922791823745,0.0001256961259059608,0.00012214732123538852,0.0001196209923364222,0.0001178954989882186,0.00011316216841805726,0.00010851965635083616,0.00010748547356342897,0.00010439144534757361,0.00010282713628839701,9.915846749208868e-05,9.905017941491678e-05,9.614198643248528e-05,9.471375233260915e-05,9.182622306980193e-05,9.213464363710955e-05,8.907664596335962e-05,9.03289983398281e-05,8.764475933276117e-05,8.608258212916553e-05,8.360783249372616e-05,8.500709373038262e-05,8.33589001558721e-05,8.129116758937016e-05,7.996229396667331e-05,7.779674342600629e-05,7.969310536282137e-05,7.727297634119168e-05,7.685364107601345e-05,7.552310125902295e-05,7.443711365340278e-05,7.389138045255095e-05,7.37564405426383e-05,7.278149132616818e-05,7.016045856289566e-05,7.131556048989296e-05,6.96080969646573e-05,6.897426646901295e-05,6.748525629518554e-05,6.838075205450878e-05,6.729719461873174e-05,6.703522376483306e-05,6.63366517983377e-05,6.559838220709935e-05,6.44625979475677e-05,6.378230318659917e-05,6.35795877315104e-05,6.26194741926156e-05,6.191364809637889e-05,6.126563675934449e-05,6.10907154623419e-05,6.150330591481179e-05,6.005181421642192e-05,6.041873348294757e-05,5.890753891435452e-05,5.883575795451179e-05,5.889958993066102e-05,5.759371560998261e-05,5.694566425518133e-05,5.68981995456852e-05,5.7050969189731404e-05,5.669236270477995e-05,5.5570340919075534e-05,5.5423734011128545e-05,5.4952608479652554e-05,5.498902828549035e-05,5.460835018311627e-05,5.4829506552778184e-05,5.382474046200514e-05,5.311306085786782e-05,5.363225136534311e-05,5.307138417265378e-05,5.2798441174672917e-05,5.316441092872992e-05,5.116962711326778e-05,5.2102142944931984e-05,5.137749030836858e-05,5.1426468417048454e-05,5.065380173618905e-05,5.090371269034222e-05,
mae,0.230197474360466,0.0793759822845459,0.030848920345306396,0.021458733826875687,0.017856301739811897,0.015668407082557678,0.014158960431814194,0.013190244324505329,0.012466361746191978,0.011936665512621403,0.01136062853038311,0.01093607023358345,0.010735380463302135,0.010372631251811981,0.010063683614134789,0.009840083308517933,0.009574887342751026,0.009365817531943321,0.009257089346647263,0.008999010547995567,0.008953699842095375,0.00865891482681036,0.008627009578049183,0.00848456285893917,0.008477301336824894,0.008253414183855057,0.008141394704580307,0.008116841316223145,0.007978012785315514,0.00793261919170618,0.00771323312073946,0.007726460229605436,0.007652939762920141,0.0075707207433879375,0.007507251109927893,0.0075256675481796265,0.007414733991026878,0.0074809156358242035,0.0073025221936404705,0.007203932385891676,0.0071889543905854225,0.007303985767066479,0.007184457033872604,0.007118644192814827,0.007047806400805712,0.006893911864608526,0.007026580162346363,0.006973233073949814,0.006955491378903389,0.006851396057754755,0.00679447315633297,0.006799560040235519,0.0067687672562897205,0.006687368266284466,0.006584912072867155,0.006703486666083336,0.00653506675735116,0.006567990407347679,0.006476094946265221,0.006508922204375267,0.0065145487897098064,0.006492725573480129,0.006464019417762756,0.006410843692719936,0.0063431779853999615,0.0062095047906041145,0.0063652158714830875,0.006208186037838459,0.006274488754570484,0.006241719238460064,0.0061784363351762295,0.006230349652469158,0.006111939437687397,0.0061784000135958195,0.0061369226314127445,0.006060800049453974,0.006089136470109224,0.006067582871764898,0.006022225134074688,0.006004904396831989,0.005995773244649172,0.005959822330623865,0.005951504688709974,0.005947014782577753,0.005870917346328497,0.005919105838984251,0.005921223666518927,0.005903048440814018,0.005843560677021742,0.005766610614955425,0.005758500657975674,0.00581455510109663,0.005778293590992689,0.005769412964582443,0.005796126089990139,0.005731395445764065,0.005736976861953735,0.00573536055162549,0.005686527583748102,0.005653433967381716,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2819      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2820      
=================================================================
Total params: 5,639
Trainable params: 5,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 2,819
Trainable params: 2,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 2,820
Trainable params: 2,820
Non-trainable params: 0
_________________________________________________________________
