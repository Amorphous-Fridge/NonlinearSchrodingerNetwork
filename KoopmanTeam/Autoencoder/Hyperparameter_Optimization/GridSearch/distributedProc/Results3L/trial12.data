2021-06-26
loss,0.4257647693157196,0.19236308336257935,0.09650219976902008,0.0560547299683094,0.044352561235427856,0.04076686501502991,0.037747159600257874,0.03472161293029785,0.03239070996642113,0.03099670633673668,0.02998174913227558,0.028755435720086098,0.02798943780362606,0.027340123429894447,0.026710398495197296,0.026154890656471252,0.02540641464293003,0.02503749169409275,0.024640673771500587,0.024337293580174446,0.023895826190710068,0.023409325629472733,0.023388201370835304,0.023015720769762993,0.022518454119563103,0.022365299984812737,0.022153418511152267,0.0217108353972435,0.021533265709877014,0.021315565332770348,0.021129870787262917,0.021012641489505768,0.020754072815179825,0.020502619445323944,0.02060665376484394,0.020285671576857567,0.020061077550053596,0.020037665963172913,0.019803976640105247,0.019570989534258842,0.019545096904039383,0.019508540630340576,0.01929662562906742,0.019174491986632347,0.019026072695851326,0.0189497247338295,0.018877647817134857,0.018738510087132454,0.018590595573186874,0.01842893287539482,0.018434692174196243,0.018260829150676727,0.018202967941761017,0.018122516572475433,0.01797921396791935,0.017847111448645592,0.01787698082625866,0.01774744689464569,0.01761838048696518,0.01758550852537155,0.017450708895921707,0.017321277409791946,0.017298534512519836,0.017263513058423996,0.017169026657938957,0.017004014924168587,0.016983333975076675,0.016912681981921196,0.016821224242448807,0.016775408759713173,0.01667827181518078,0.016617342829704285,0.016519315540790558,0.016444077715277672,0.01642141118645668,0.01638278178870678,0.016246946528553963,0.01617484726011753,0.016136623919010162,0.016083357855677605,0.016029642894864082,0.015994064509868622,0.015924934297800064,0.015833644196391106,0.015833336859941483,0.01572287827730179,0.015747783705592155,0.015621439553797245,0.015573649667203426,0.015590258873999119,0.015497897751629353,0.015507351607084274,0.015448302961885929,0.015400511212646961,0.015440200455486774,0.015228219330310822,0.015282703563570976,0.015248246490955353,0.015203953720629215,0.015078986994922161,
mse,0.07997211813926697,0.0131717249751091,0.0032254913821816444,0.001057242276147008,0.0006349161849357188,0.0005277132731862366,0.00044000931666232646,0.0003697098873089999,0.0003208051493857056,0.00029325144714675844,0.0002759243652690202,0.0002511758648324758,0.0002373919851379469,0.00022458637249656022,0.0002127459883922711,0.00020341126946732402,0.00019214136409573257,0.0001851396227721125,0.000178858419531025,0.0001733521930873394,0.00016770520596764982,0.00016182938998099416,0.00015966137289069593,0.00015399341646116227,0.00014753102732356638,0.0001444519148208201,0.0001413212885381654,0.00013572594616562128,0.000133047578856349,0.00013041008787695318,0.0001278161653317511,0.00012657571642193943,0.00012314434570726007,0.00012036904081469402,0.00012046362098772079,0.00011750137491617352,0.00011445904965512455,0.00011478059604996815,0.00011141713912365958,0.000109161737782415,0.000108228501630947,0.00010784142068587244,0.00010522984666749835,0.0001038807604345493,0.00010250900959363207,0.00010127556743100286,0.00010145523265236989,9.9223580036778e-05,9.744035196490586e-05,9.560408216202632e-05,9.587005479261279e-05,9.445387695450336e-05,9.351236803922802e-05,9.238602797267959e-05,9.053763642441481e-05,8.97831778274849e-05,8.959070692071691e-05,8.864302799338475e-05,8.67051348905079e-05,8.676883589942008e-05,8.529920160071924e-05,8.397759665967897e-05,8.346363756572828e-05,8.357074693776667e-05,8.218699804274365e-05,8.086252637440339e-05,8.07117685326375e-05,7.997721695574e-05,7.940934301586822e-05,7.855646981624886e-05,7.748528150841594e-05,7.698187982896343e-05,7.650691259186715e-05,7.544949039584026e-05,7.536130578955635e-05,7.471466233255342e-05,7.338278373936191e-05,7.28854865883477e-05,7.246973109431565e-05,7.235092925839126e-05,7.184361311374232e-05,7.123497198335826e-05,7.031343557173386e-05,6.975822907406837e-05,6.958733138162643e-05,6.869221397209913e-05,6.891084922244772e-05,6.797187961637974e-05,6.790576298953965e-05,6.703552207909524e-05,6.709078297717497e-05,6.704711995553225e-05,6.662697705905885e-05,6.587437383132055e-05,6.616550672333688e-05,6.39183126622811e-05,6.497240246972069e-05,6.50347355986014e-05,6.386348104570061e-05,6.265998672461137e-05,
mae,0.18115253746509552,0.0833096131682396,0.04085800051689148,0.023771414533257484,0.01875019632279873,0.017184557393193245,0.016064278781414032,0.014687414281070232,0.013756262138485909,0.013110336847603321,0.012663216330111027,0.012164532206952572,0.011839384213089943,0.011615555733442307,0.011335275135934353,0.011015895754098892,0.010789514519274235,0.010586075484752655,0.010387223213911057,0.010359728708863258,0.010222453624010086,0.009902065619826317,0.009885200299322605,0.009746761061251163,0.009691989049315453,0.009473965503275394,0.009299066849052906,0.009181206114590168,0.009030726738274097,0.009113715961575508,0.008993919938802719,0.008949793875217438,0.008768776431679726,0.00871973391622305,0.00875556468963623,0.00868567731231451,0.008478722535073757,0.008435097523033619,0.00850659515708685,0.008344369940459728,0.008302789181470871,0.008322540670633316,0.008162948302924633,0.008107217028737068,0.007920363917946815,0.008097099140286446,0.007955403067171574,0.008006922900676727,0.007892976514995098,0.007830947637557983,0.007870038971304893,0.007734482176601887,0.007738408632576466,0.007667947560548782,0.007705367170274258,0.007542788982391357,0.007517446763813496,0.007471668533980846,0.007472136523574591,0.007504324894398451,0.0074440790340304375,0.007416092325001955,0.007422651629894972,0.0073972102254629135,0.0072590988129377365,0.007323313970118761,0.00723454961553216,0.007181850261986256,0.00713002122938633,0.007043116260319948,0.007110506296157837,0.007188701070845127,0.006909560412168503,0.0070425523445010185,0.0069330912083387375,0.007026533596217632,0.006958455312997103,0.006842872127890587,0.006793453823775053,0.006880934815853834,0.006827794946730137,0.0066774990409612656,0.006714759394526482,0.006674494128674269,0.0067625390365719795,0.006636708974838257,0.006742873229086399,0.006652546115219593,0.006562603171914816,0.00664174510166049,0.006545082200318575,0.006630815099924803,0.006588359363377094,0.0065401471219956875,0.006503288634121418,0.006469167303293943,0.006513630971312523,0.0064316121861338615,0.006367859430611134,0.006444370839744806,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3363      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3364      
=================================================================
Total params: 6,727
Trainable params: 6,727
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 3,363
Trainable params: 3,363
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 3,364
Trainable params: 3,364
Non-trainable params: 0
_________________________________________________________________
