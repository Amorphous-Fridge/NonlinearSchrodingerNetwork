2021-06-26
loss,0.2993101179599762,0.07513228803873062,0.06354013830423355,0.054714102298021317,0.052138376981019974,0.04301943629980087,0.045328736305236816,0.040693677961826324,0.03935901075601578,0.04467858001589775,0.03649085760116577,0.038205236196517944,0.035900283604860306,0.03414257615804672,0.029756106436252594,0.037288848310709,0.03521064668893814,0.03723864629864693,0.03382468596100807,0.03171965852379799,0.030836882069706917,0.02360205166041851,0.02796556055545807,0.03131239488720894,0.030148396268486977,0.029983721673488617,0.023844532668590546,0.02160417102277279,0.02152019925415516,0.025660762563347816,0.02698761411011219,0.029770033434033394,0.028409667313098907,0.025393642485141754,0.024591755121946335,0.023602385073900223,0.020001906901597977,0.021522600203752518,0.021074024960398674,0.023834289982914925,0.022685399278998375,0.019687889143824577,0.017751552164554596,0.018591245636343956,0.018763910979032516,0.0221145860850811,0.022655699402093887,0.020367877557873726,0.020702507346868515,0.024135254323482513,0.02049863524734974,0.019731910899281502,0.022093968465924263,0.019230792298913002,0.01738639548420906,0.015833599492907524,0.014798673801124096,0.014207498170435429,0.01449785940349102,0.014697600156068802,0.015416682697832584,0.016860617324709892,0.023040002211928368,0.0203656405210495,0.019902562722563744,0.01918167434632778,0.017862925305962563,0.017039714381098747,0.01815132237970829,0.01704629324376583,0.01632365770637989,0.01595977135002613,0.015352700836956501,0.014940784312784672,0.01694173365831375,0.01998589187860489,0.016750531271100044,0.015732256695628166,0.015150933526456356,0.014010689221322536,0.014954974874854088,0.01361921988427639,0.012083773501217365,0.013637334108352661,0.01676279865205288,0.015038643032312393,0.01637955568730831,0.015230756253004074,0.016649354249238968,0.014871486462652683,0.013083222322165966,0.01381018478423357,0.013302629813551903,0.014507808722555637,0.015084730461239815,0.014077694155275822,0.013812584802508354,0.012411355972290039,0.012972556054592133,0.012034256011247635,
mse,0.04076468572020531,0.0017552853096276522,0.0011744840303435922,0.0008705681539140642,0.0007931303698569536,0.0005641890456900001,0.0005990188801661134,0.00047355747665278614,0.00045229497482068837,0.0006041938904672861,0.0003897598653566092,0.0004236348031554371,0.00037845197948627174,0.000338561600074172,0.0002563648740760982,0.0003977251471951604,0.00036727171391248703,0.0004081900406163186,0.0003348069731146097,0.0002936584933195263,0.00027617820887826383,0.00016803914331831038,0.00023427596897818148,0.0002847093273885548,0.0002589984214864671,0.0002554527309257537,0.00017085872241295874,0.0001405633956892416,0.000138280083774589,0.0001898512855404988,0.00020704598864540458,0.00025112388539128006,0.00023050818708725274,0.00018858218390960246,0.00017704088531900197,0.0001581588585395366,0.0001186785739264451,0.00013555142504628748,0.00013001890329178423,0.0001615539804333821,0.00014403561362996697,0.0001130895470851101,9.40099052968435e-05,0.00010087223927257583,0.0001044579767039977,0.00014271341206040233,0.00014352815924212337,0.00011970465129707009,0.00012144116772105917,0.0001663111906964332,0.0001199479156639427,0.00010959793871734291,0.0001390246907249093,0.00010326055053155869,8.744553633732721e-05,7.386320066871122e-05,6.544167990796268e-05,5.995652099954896e-05,6.301428948063403e-05,6.421930447686464e-05,7.031313725747168e-05,8.379338396480307e-05,0.00014974559599068016,0.00011918772361241281,0.00011158265988342464,0.0001036324756569229,9.237988706445321e-05,8.414631884079427e-05,9.261295781470835e-05,8.293933933600783e-05,7.661573908990249e-05,7.302740414161235e-05,6.836167449364439e-05,6.532911356771365e-05,8.198436262318864e-05,0.00011072558118030429,8.335799793712795e-05,7.173697667894885e-05,6.698023207718506e-05,5.8197943872073665e-05,6.586143717868254e-05,5.533800504053943e-05,4.618628736352548e-05,5.4984840971883386e-05,7.813893898855895e-05,6.411200592992827e-05,7.537486817454919e-05,6.652423326158896e-05,7.914118759799749e-05,6.403610314009711e-05,5.196635902393609e-05,5.670263271895237e-05,5.3018975449958816e-05,6.020705768605694e-05,6.456187111325562e-05,5.761036663898267e-05,5.476207297760993e-05,4.612584234564565e-05,4.9623544327914715e-05,4.360328603070229e-05,
mae,0.12967461347579956,0.03197291120886803,0.02676629275083542,0.02322130836546421,0.022000033408403397,0.01825294829905033,0.019186971709132195,0.017438525334000587,0.01681656390428543,0.018773183226585388,0.015428855083882809,0.01631590537726879,0.015271710231900215,0.0144997863098979,0.012717886827886105,0.01587758958339691,0.014799713157117367,0.015854177996516228,0.014270758256316185,0.013450571335852146,0.012983410619199276,0.010045936331152916,0.011717233806848526,0.01323398482054472,0.012890978716313839,0.012631489895284176,0.01016442570835352,0.009224094450473785,0.009118936955928802,0.010889612138271332,0.011518522165715694,0.012701214291155338,0.012077153660356998,0.010841085575520992,0.010417490266263485,0.009981735609471798,0.008529523387551308,0.009110606275498867,0.008912981487810612,0.010024425573647022,0.009590333327651024,0.00835044402629137,0.007481397595256567,0.007936399430036545,0.007882226258516312,0.009369121864438057,0.009517846629023552,0.008601086214184761,0.008733725175261497,0.010059683583676815,0.008743397891521454,0.008355937898159027,0.009294440038502216,0.008218168281018734,0.00747982133179903,0.006699956022202969,0.00629100576043129,0.006005289498716593,0.006177909206598997,0.006282234564423561,0.006565221585333347,0.00713601429015398,0.009670629166066647,0.00859195925295353,0.008410054259002209,0.008107242174446583,0.007625581230968237,0.007250431925058365,0.007624315097928047,0.00709046283736825,0.006781293544918299,0.006622727960348129,0.006442029029130936,0.006332105956971645,0.007171463221311569,0.00828306470066309,0.006999141536653042,0.006677174940705299,0.006441022735089064,0.00594223802909255,0.0063436697237193584,0.005724747199565172,0.0051445444114506245,0.005741617642343044,0.00712626613676548,0.006307227071374655,0.006872132886201143,0.006437935866415501,0.006931710056960583,0.006232675164937973,0.005620616488158703,0.005899500101804733,0.005635565146803856,0.0061692227609455585,0.0064153121784329414,0.006026980467140675,0.005879217758774757,0.005258587189018726,0.005474531091749668,0.005124690942466259,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 41987     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 41988     
=================================================================
Total params: 83,975
Trainable params: 83,975
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 41,987
Trainable params: 41,987
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 41,988
Trainable params: 41,988
Non-trainable params: 0
_________________________________________________________________
