2021-06-26
loss,0.3709106147289276,0.10990668088197708,0.0665275976061821,0.07660401612520218,0.06424148380756378,0.05569696053862572,0.04828338325023651,0.04304998740553856,0.03919468820095062,0.04726098105311394,0.04442620649933815,0.03680886700749397,0.05141836777329445,0.042104143649339676,0.03590593487024307,0.03999501094222069,0.045506611466407776,0.037730053067207336,0.034357503056526184,0.03261849656701088,0.04294056445360184,0.045254990458488464,0.04249567911028862,0.03881215676665306,0.03238178417086601,0.02882489375770092,0.02658556029200554,0.025284407660365105,0.02495172806084156,0.02338576875627041,0.030460111796855927,0.027574386447668076,0.03480919823050499,0.03454863652586937,0.033765118569135666,0.034253984689712524,0.030350875109434128,0.026361169293522835,0.02414540760219097,0.023025356233119965,0.021941475570201874,0.021349044516682625,0.021247630938887596,0.021307075396180153,0.020743820816278458,0.03327266499400139,0.032174836844205856,0.02886311523616314,0.025860732421278954,0.0236800629645586,0.0220193974673748,0.020894426852464676,0.020227903500199318,0.01957671344280243,0.019164444878697395,0.01837015524506569,0.01714400202035904,0.016316283494234085,0.015747804194688797,0.015217305161058903,0.015003779903054237,0.01768355444073677,0.023810820654034615,0.02198641002178192,0.024041220545768738,0.022182999178767204,0.020907944068312645,0.019809681922197342,0.01903255097568035,0.018418854102492332,0.017997266724705696,0.017611436545848846,0.017342519015073776,0.01703094318509102,0.025455038994550705,0.02534356527030468,0.02311716228723526,0.021213244646787643,0.020170733332633972,0.01898816041648388,0.018422532826662064,0.017186852172017097,0.017424024641513824,0.015118763782083988,0.018055317923426628,0.0172328669577837,0.01640043407678604,0.018259894102811813,0.019960716366767883,0.016997236758470535,0.01705404929816723,0.017951639369130135,0.016935329884290695,0.01628863625228405,0.015710080042481422,0.015215247869491577,0.014845593832433224,0.01450209878385067,0.014107546769082546,0.013814473524689674,
mse,0.04872541502118111,0.0040383548475801945,0.0014084689319133759,0.0018689082935452461,0.0012156498851254582,0.0009092374239116907,0.0006895143305882812,0.0005569243221543729,0.00045921572018414736,0.0006625997484661639,0.0005665728240273893,0.0004099177895113826,0.000761185132432729,0.0005084092263132334,0.0003616365429479629,0.0004896912141703069,0.0006211845320649445,0.00039704516530036926,0.00033382343826815486,0.00030272931326180696,0.0005739262560382485,0.000585560395848006,0.0005162089364603162,0.0004323513130657375,0.0002973765949718654,0.00023805268574506044,0.00020805266103707254,0.0001918421476148069,0.0001871344429673627,0.00016745446191634983,0.00026643046294339,0.00021944874606560916,0.0003605078672990203,0.00034729926846921444,0.0003239127981942147,0.0003305064747110009,0.0002563999150879681,0.0001961018133442849,0.00016655349463690072,0.0001516818447271362,0.00013855235010851175,0.00013162754476070404,0.000133653316879645,0.00013133980974089354,0.0001246660976903513,0.0003234796167816967,0.00028866910724900663,0.00023405866522807628,0.000190403065062128,0.0001616426307009533,0.00014108476170804352,0.00012695389159489423,0.00011914486822206527,0.00011201884626643732,0.00010774248221423477,0.00010138464858755469,8.528473699698225e-05,7.706656469963491e-05,7.213471690192819e-05,6.773442146368325e-05,6.684770050924271e-05,9.587140084477141e-05,0.00016287746257148683,0.00013917317846789956,0.00016255414811894298,0.00014192797243595123,0.000125791848404333,0.0001134572084993124,0.00010433347779326141,9.810373012442142e-05,9.374098590342328e-05,8.944364526541904e-05,8.73688404681161e-05,8.666502253618091e-05,0.00018787143926601857,0.00017699020099826157,0.00014948956959415227,0.00012685992987826467,0.00011419672227930278,0.00010232874774374068,9.60344186751172e-05,8.778113260632381e-05,8.746075764065608e-05,7.010511762928218e-05,9.489954391028732e-05,8.301660272991285e-05,7.655553781660274e-05,9.774868522072211e-05,0.00011560024722712114,8.280801557702944e-05,8.551519567845389e-05,9.045197657542303e-05,8.220432937378064e-05,7.656099478481337e-05,7.194693898782134e-05,6.770521576981992e-05,6.479138392023742e-05,6.162773934192955e-05,5.840098310727626e-05,5.5471191444667056e-05,
mae,0.15792930126190186,0.04573622718453407,0.028485296294093132,0.032517123967409134,0.027348235249519348,0.02362086810171604,0.020583169534802437,0.018306154757738113,0.016873836517333984,0.02005499042570591,0.018782570958137512,0.01589667983353138,0.021825967356562614,0.017718806862831116,0.01566307246685028,0.01702873967587948,0.019701184704899788,0.016764706000685692,0.015197786502540112,0.014214086346328259,0.0185672789812088,0.019342131912708282,0.018596937879920006,0.016853099688887596,0.01407295186072588,0.012592277489602566,0.011150460690259933,0.01045030727982521,0.010326330550014973,0.009857425466179848,0.01274559274315834,0.011982075870037079,0.014992274343967438,0.014945294708013535,0.014549548737704754,0.015090268105268478,0.013211322017014027,0.0108113968744874,0.010138357058167458,0.009606290608644485,0.009184980764985085,0.009080450050532818,0.00906318984925747,0.009094338864088058,0.008919385261833668,0.014378471300005913,0.014081128872931004,0.012402676045894623,0.010678946040570736,0.00941123254597187,0.008826496079564095,0.008423478342592716,0.008228723891079426,0.007997340522706509,0.007816994562745094,0.007708496414124966,0.007351061329245567,0.007061851676553488,0.0068069021217525005,0.006561580114066601,0.006475129164755344,0.0074600111693143845,0.010094396770000458,0.009288499131798744,0.009950673207640648,0.00917833298444748,0.008639841340482235,0.008178077638149261,0.007885763421654701,0.007686568424105644,0.007548059802502394,0.007410301361232996,0.007347355596721172,0.00721336854621768,0.010918987914919853,0.010876999236643314,0.009933860041201115,0.008814428001642227,0.008137172088027,0.007643135264515877,0.007432665675878525,0.007132589817047119,0.007503053639084101,0.006496678572148085,0.007695862557739019,0.0074599916115403175,0.007051020860671997,0.007767802570015192,0.008572222664952278,0.007190781645476818,0.007274793926626444,0.007614261005073786,0.007225352339446545,0.006959699559956789,0.006701905280351639,0.006428735796362162,0.00623471662402153,0.006113048177212477,0.006005566567182541,0.005987224169075489,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 19043     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 19044     
=================================================================
Total params: 38,087
Trainable params: 38,087
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 19,043
Trainable params: 19,043
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 19,044
Trainable params: 19,044
Non-trainable params: 0
_________________________________________________________________
