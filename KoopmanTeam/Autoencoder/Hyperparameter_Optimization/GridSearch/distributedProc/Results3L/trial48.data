2021-06-26
loss,0.3481336534023285,0.09094776213169098,0.06746026873588562,0.0505041778087616,0.052443668246269226,0.061427369713783264,0.05463031679391861,0.055440496653318405,0.05215734988451004,0.03996558114886284,0.03356819599866867,0.030262090265750885,0.0300062894821167,0.028949234634637833,0.036173731088638306,0.03281264379620552,0.0405539833009243,0.03599889576435089,0.03766200691461563,0.03224863484501839,0.029540471732616425,0.026939254254102707,0.027683110907673836,0.026341522112488747,0.02654532715678215,0.02860260009765625,0.02592664770781994,0.028528526425361633,0.027915671467781067,0.024535244330763817,0.022734971717000008,0.02127450704574585,0.02071753330528736,0.022464189678430557,0.02655658684670925,0.024700872600078583,0.02295236848294735,0.024530325084924698,0.021285466849803925,0.01882673054933548,0.016946446150541306,0.018553204834461212,0.01670096628367901,0.017971184104681015,0.01751573197543621,0.02315279096364975,0.024036848917603493,0.021722037345170975,0.02202160656452179,0.021458474919199944,0.019322961568832397,0.017300477251410484,0.01500358060002327,0.015457469038665295,0.017457177862524986,0.02148103155195713,0.02020697109401226,0.017677918076515198,0.018853262066841125,0.019149281084537506,0.018393028527498245,0.017356840893626213,0.018658671528100967,0.016299409791827202,0.013776288367807865,0.015982719138264656,0.017858777195215225,0.016958532854914665,0.01579916663467884,0.015068430453538895,0.0139844361692667,0.012506005354225636,0.01693055033683777,0.01815941371023655,0.016803622245788574,0.015905819833278656,0.016741178929805756,0.016154596582055092,0.016752934083342552,0.015733512118458748,0.014233730733394623,0.013325035572052002,0.01203915011137724,0.014971358701586723,0.017959486693143845,0.01567942462861538,0.014544394798576832,0.0134343933314085,0.012099282816052437,0.013526832684874535,0.015310604125261307,0.015110774897038937,0.014516184106469154,0.013375554233789444,0.01391745824366808,0.014664039947092533,0.014502029865980148,0.013423161581158638,0.011458358727395535,0.01097511500120163,
mse,0.05362192168831825,0.0026097779627889395,0.0013412998523563147,0.0007304862374439836,0.0008057893719524145,0.0011317274766042829,0.000868699629791081,0.0008939390536397696,0.000804161187261343,0.00044946465641260147,0.0003249704896006733,0.000269848620519042,0.00026413454907014966,0.00024325455888174474,0.00038319575833156705,0.0003201510407961905,0.0004778351285494864,0.000368178152712062,0.00039961456786841154,0.0002973561058752239,0.0002464735589455813,0.00021322615793906152,0.00022119921050034463,0.00020078860688954592,0.0002093439397867769,0.00023250607773661613,0.00019230821635574102,0.00022841212921775877,0.00022111974249128252,0.0001724663161439821,0.00014591541548725218,0.00013138864596839994,0.00012876692926511168,0.00015098114090505987,0.0001957119966391474,0.0001701291330391541,0.00015331606846302748,0.00017190097423736006,0.00012678118946496397,0.00010458071483299136,8.679437451064587e-05,0.00010351837408961728,8.282823546323925e-05,9.517051512375474e-05,9.249040158465505e-05,0.0001511671580374241,0.00016087567200884223,0.0001328742946498096,0.00013752779341302812,0.00013077547191642225,0.0001085445546777919,8.98283688002266e-05,6.96417992003262e-05,7.161307439673692e-05,9.119024616666138e-05,0.00012998079182580113,0.00011462366819614545,9.093410335481167e-05,0.00010094408935401589,0.0001038503905874677,9.701280941953883e-05,8.72039599926211e-05,9.7725132945925e-05,7.783658656990156e-05,5.903765486436896e-05,7.775262201903388e-05,9.076466812985018e-05,7.968598220031708e-05,7.029018888715655e-05,6.413859955500811e-05,5.648978185490705e-05,4.6880082663847134e-05,8.485926082357764e-05,9.11444440134801e-05,8.006684220163152e-05,7.333004759857431e-05,8.059568790486082e-05,7.691186328884214e-05,7.939908391563222e-05,7.042392826406285e-05,6.0578244301723316e-05,5.3395386203192174e-05,4.41565498476848e-05,6.52819435345009e-05,8.920776599552482e-05,7.118281064322218e-05,6.051106538507156e-05,5.2373387006809935e-05,4.3931257096119225e-05,5.5318734666798264e-05,6.847054464742541e-05,6.463387398980558e-05,5.8484663895796984e-05,5.149248681846075e-05,5.704623617930338e-05,6.186503742355853e-05,6.125046638771892e-05,5.378810237743892e-05,4.043594890390523e-05,3.80934689019341e-05,
mae,0.15113654732704163,0.038798052817583084,0.028804488480091095,0.021586759015917778,0.022485576570034027,0.02641175501048565,0.023387856781482697,0.024020081385970116,0.022141950204968452,0.01693114824593067,0.014349105767905712,0.012894525192677975,0.012824339792132378,0.012278885580599308,0.015387987717986107,0.014072591438889503,0.01740446500480175,0.015419316478073597,0.016163639724254608,0.013953378424048424,0.012443887069821358,0.011564685963094234,0.011862164363265038,0.011199908331036568,0.011422807350754738,0.012343782931566238,0.011113184504210949,0.012121596373617649,0.011755663901567459,0.010515243746340275,0.00960534904152155,0.008998110890388489,0.008879226632416248,0.00944661907851696,0.011228113435208797,0.010577516630291939,0.0096827307716012,0.010533916763961315,0.009026157669723034,0.007843531668186188,0.0072022611275315285,0.007955703884363174,0.007109916768968105,0.007535847369581461,0.00742611987516284,0.009789980947971344,0.010416421107947826,0.009243585169315338,0.009418332949280739,0.009182699024677277,0.008183091878890991,0.007406603544950485,0.006380004808306694,0.0065175374038517475,0.007410138845443726,0.009204400703310966,0.008578229695558548,0.007433044724166393,0.008002624846994877,0.008215120993554592,0.007844253443181515,0.007342472206801176,0.007967811077833176,0.006822444964200258,0.005869151558727026,0.006833216641098261,0.007615987677127123,0.0071335239335894585,0.006531484890729189,0.006220464129000902,0.0058775488287210464,0.005326139274984598,0.007284298539161682,0.0077157169580459595,0.007100930903106928,0.006729113403707743,0.0071127284318208694,0.006863293703645468,0.00714800413697958,0.006697037722915411,0.006098862271755934,0.005673771724104881,0.005113181658089161,0.006342413369566202,0.007715174462646246,0.006635008379817009,0.005954184103757143,0.005626356694847345,0.005082379560917616,0.005734002683311701,0.006549453362822533,0.006422051228582859,0.006221135146915913,0.005728886928409338,0.00597203616052866,0.006209376268088818,0.0061877453699707985,0.005759993102401495,0.004881783854216337,0.004712129011750221,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 33603     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 33604     
=================================================================
Total params: 67,207
Trainable params: 67,207
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 33,603
Trainable params: 33,603
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 33,604
Trainable params: 33,604
Non-trainable params: 0
_________________________________________________________________
