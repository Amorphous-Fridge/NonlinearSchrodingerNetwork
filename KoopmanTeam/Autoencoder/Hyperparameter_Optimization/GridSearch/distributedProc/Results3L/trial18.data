2021-06-26
loss,0.5000525116920471,0.21996952593326569,0.09282050281763077,0.05949893593788147,0.05265966057777405,0.0474507138133049,0.04340623319149017,0.04037217050790787,0.03714320808649063,0.0356588177382946,0.03455248847603798,0.0327928327023983,0.03222854435443878,0.03125813975930214,0.03060021623969078,0.02993854507803917,0.029277319088578224,0.028548767790198326,0.02819634974002838,0.02768941968679428,0.02717650681734085,0.026738189160823822,0.02629467286169529,0.025938022881746292,0.025512181222438812,0.025068460032343864,0.02483006753027439,0.024475472047924995,0.024237237870693207,0.023856569081544876,0.02358785644173622,0.023112313821911812,0.023180337622761726,0.022620227187871933,0.022435113787651062,0.022193560376763344,0.022024132311344147,0.02175421640276909,0.02159315161406994,0.0213442612439394,0.021097801625728607,0.020747344940900803,0.020758073776960373,0.020578904077410698,0.020405516028404236,0.020224176347255707,0.020079748705029488,0.019902072846889496,0.019725598394870758,0.01953992061316967,0.019324010238051414,0.019305577501654625,0.019092753529548645,0.01906920224428177,0.018865378573536873,0.018747173249721527,0.01866777054965496,0.018552519381046295,0.01825823448598385,0.01835024356842041,0.01812574826180935,0.018129175528883934,0.01794362999498844,0.017811955884099007,0.01779075898230076,0.01764504238963127,0.017625518143177032,0.017479024827480316,0.017503805458545685,0.01729130558669567,0.017269229516386986,0.017143087461590767,0.017048317939043045,0.017035972326993942,0.016991646960377693,0.016906332224607468,0.01683967188000679,0.016610341146588326,0.016746006906032562,0.016494182869791985,0.016588322818279266,0.016358228400349617,0.0164223350584507,0.01635967753827572,0.016303442418575287,0.016195127740502357,0.016202064231038094,0.016002967953681946,0.016012849286198616,0.016032416373491287,0.015919754281640053,0.01591467298567295,0.015797795727849007,0.0158215444535017,0.015661602839827538,0.015692753717303276,0.01550214271992445,0.01556611992418766,0.015514951199293137,0.015461537055671215,
mse,0.11348045617341995,0.016848422586917877,0.003285015467554331,0.0012932264944538474,0.0009836271638050675,0.0007926854304969311,0.0006659038481302559,0.0005738029722124338,0.0004891392309218645,0.00044208989129401743,0.000404317892389372,0.0003690053417813033,0.0003513881820254028,0.00032678793650120497,0.00031316830427385867,0.0002957842079922557,0.0002800028305500746,0.00026520018582232296,0.0002597715938463807,0.00024511758238077164,0.00023624672030564398,0.00022761251602787524,0.0002181533200200647,0.00021081902377773076,0.000204069830942899,0.00019567804702091962,0.00019125525432173163,0.00018545115017332137,0.00018083371105603874,0.00017429633589927107,0.00016949613927863538,0.00016290888015646487,0.00016186965513043106,0.0001558381918584928,0.00015214951417874545,0.0001482211664551869,0.00014640793961007148,0.00014138713595457375,0.00013926067913416773,0.00013586286513600498,0.00013296636461745948,0.00012852858344558626,0.00012731111200992018,0.00012576926383189857,0.00012299224908929318,0.0001203093197545968,0.00011855450429720804,0.00011679951421683654,0.00011451805039541796,0.0001115909981308505,0.00010915385792031884,0.00010907487012445927,0.00010646428563632071,0.0001063055606209673,0.00010323560127289966,0.00010216770897386596,0.00010117416240973398,0.00010051601566374302,9.659251372795552e-05,9.782709093997255e-05,9.50374233070761e-05,9.531500836601481e-05,9.338834934169427e-05,9.168841643258929e-05,9.152218990493566e-05,8.995005919132382e-05,8.986863394966349e-05,8.853805047692731e-05,8.861537207849324e-05,8.659378363518044e-05,8.598323620390147e-05,8.492983033647761e-05,8.363422239199281e-05,8.386861736653373e-05,8.343775698449463e-05,8.228174556279555e-05,8.180787699529901e-05,7.882955833338201e-05,8.075145888142288e-05,7.802057371009141e-05,7.946488767629489e-05,7.733676466159523e-05,7.730492507107556e-05,7.70497863413766e-05,7.654724322492257e-05,7.527684647357091e-05,7.528551941504702e-05,7.3351948230993e-05,7.360251038335264e-05,7.352353713940829e-05,7.249349437188357e-05,7.267294859047979e-05,7.103390817064792e-05,7.224048749776557e-05,7.005335646681488e-05,7.082386582624167e-05,6.875118560856208e-05,6.923814362380654e-05,6.910443335073069e-05,6.847266922704875e-05,
mae,0.2146160900592804,0.0946279838681221,0.03930782154202461,0.02521548420190811,0.022366266697645187,0.020205924287438393,0.018541090190410614,0.01725839450955391,0.01590532250702381,0.01526176929473877,0.014847972430288792,0.014083202928304672,0.013810652308166027,0.0134135652333498,0.013097738847136497,0.012852871790528297,0.012567373923957348,0.012228736653923988,0.012042650952935219,0.011890696361660957,0.011659316718578339,0.011481452733278275,0.01129884459078312,0.011138363741338253,0.010954340919852257,0.010815314948558807,0.010638898238539696,0.010399994440376759,0.010427669622004032,0.01014897134155035,0.010178612545132637,0.009890034794807434,0.009999200701713562,0.009738163091242313,0.009652628563344479,0.009565354324877262,0.009536637924611568,0.009353702887892723,0.009233024902641773,0.009203570894896984,0.008987930603325367,0.008907295763492584,0.008922391571104527,0.008736909367144108,0.008759615942835808,0.008721194230020046,0.008607201278209686,0.008580819703638554,0.008481843397021294,0.008344581350684166,0.00822929572314024,0.008297629654407501,0.008216377347707748,0.008169243112206459,0.008180256932973862,0.007971958257257938,0.007994035258889198,0.0079826470464468,0.007862234488129616,0.007923122495412827,0.007728789933025837,0.00773425679653883,0.00774360541254282,0.007661621086299419,0.007651307620108128,0.007523142267018557,0.007456379942595959,0.0075677852146327496,0.007566728163510561,0.007310233078896999,0.007433930411934853,0.007454659324139357,0.007232095114886761,0.007335620932281017,0.007320569362491369,0.007339447271078825,0.0073446547612547874,0.007124041207134724,0.0071613662876188755,0.007008316460996866,0.007133083418011665,0.007025537081062794,0.007020252291113138,0.006983761675655842,0.007111257407814264,0.006841861642897129,0.00692103011533618,0.006774728186428547,0.006863968446850777,0.006914533209055662,0.006792839150875807,0.006888743489980698,0.006781657226383686,0.006847182288765907,0.006780647672712803,0.006775943096727133,0.0066480934619903564,0.0067157079465687275,0.0066215479746460915,0.006684750784188509,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3315      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3316      
=================================================================
Total params: 6,631
Trainable params: 6,631
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 3,315
Trainable params: 3,315
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 3,316
Trainable params: 3,316
Non-trainable params: 0
_________________________________________________________________
