2021-06-26
loss,0.4002506732940674,0.2289590686559677,0.1820947825908661,0.10502788424491882,0.0614871084690094,0.052954792976379395,0.04542161151766777,0.04177604243159294,0.038808539509773254,0.0364905409514904,0.03473082557320595,0.033660974353551865,0.03206567093729973,0.03091736137866974,0.030240120366215706,0.02928176335990429,0.028404900804162025,0.027823906391859055,0.027258215472102165,0.02674679271876812,0.026179209351539612,0.025722026824951172,0.025370512157678604,0.024819133803248405,0.024504927918314934,0.024135995656251907,0.02376708574593067,0.02365974336862564,0.023302273824810982,0.022848060354590416,0.022562893107533455,0.022425450384616852,0.022128291428089142,0.02201242186129093,0.021573839709162712,0.02139921672642231,0.033277105540037155,0.032218530774116516,0.032468266785144806,0.03497881069779396,0.03723764419555664,0.03306024894118309,0.020073847845196724,0.020079579204320908,0.0195777527987957,0.01945243775844574,0.019445940852165222,0.019395554438233376,0.019221436232328415,0.019177788868546486,0.018942467868328094,0.01893622800707817,0.01884746178984642,0.018599949777126312,0.018675483763217926,0.018558109179139137,0.01847514882683754,0.018327288329601288,0.018212495371699333,0.018160495907068253,0.01813647337257862,0.018059834837913513,0.018011370673775673,0.018021436408162117,0.01789875701069832,0.017778970301151276,0.01749638095498085,0.017655031755566597,0.017662255093455315,0.01739358715713024,0.017338423058390617,0.01732480339705944,0.017061373218894005,0.017229724675416946,0.017061764374375343,0.01689258962869644,0.0167929045855999,0.016784142702817917,0.0166765209287405,0.016626037657260895,0.016627425327897072,0.01651887409389019,0.016430826857686043,0.01632492057979107,0.01610196754336357,0.01702497899532318,0.027632279321551323,0.028486380353569984,0.024794120341539383,0.0230479147285223,0.021824155002832413,0.020890654996037483,0.020196758210659027,0.02105504460632801,0.02939092181622982,0.026602018624544144,0.02499563619494438,0.02362271398305893,0.02275208942592144,0.022095823660492897,
mse,0.06528371572494507,0.018488310277462006,0.012012229301035404,0.003495218697935343,0.0012829086044803262,0.0009418808040209115,0.000682396232150495,0.0005716425366699696,0.0004864244838245213,0.0004298662533983588,0.00038361185579560697,0.0003566727682482451,0.00032285493216477334,0.00029994890792295337,0.0002820405352395028,0.0002637635625433177,0.00024711014702916145,0.00023603418958373368,0.00022520842321682721,0.0002158882125513628,0.00020631148072425276,0.0001987246359931305,0.00019195754430256784,0.0001839408214436844,0.0001767135108821094,0.00017165113240480423,0.00016632374899927527,0.00016353324463125318,0.0001588141603861004,0.00015239710046444088,0.00014879147056490183,0.00014669338997919112,0.00014293912681750953,0.0001403986825607717,0.00013596996723208576,0.0001410656695952639,0.00033661670750007033,0.0002974256931338459,0.00029922512476332486,0.00035387914977036417,0.00038969540037214756,0.0003126023802906275,0.00012535885616671294,0.00011836674093501642,0.00011235591227887198,0.00011063800775445998,0.00011000616359524429,0.00010862819181056693,0.00010656370432116091,0.00010570506856311113,0.00010311900405213237,0.00010307735647074878,0.00010185012797592208,9.953004337148741e-05,0.00010084000678034499,9.846303873928264e-05,9.729140583658591e-05,9.58816526690498e-05,9.654608584241942e-05,9.462321031605825e-05,9.356233931612223e-05,9.404128650203347e-05,9.528073132969439e-05,9.26744905882515e-05,9.069222869584337e-05,8.942303975345567e-05,9.02213723747991e-05,8.924982830649242e-05,8.816567424219102e-05,8.558190165786073e-05,8.67207781993784e-05,8.599382999818772e-05,8.438461372861639e-05,8.36792096379213e-05,8.237900328822434e-05,8.115301170619205e-05,8.12683065305464e-05,8.065413567237556e-05,7.924568490125239e-05,7.845249638194218e-05,7.79917900217697e-05,7.67520468798466e-05,7.639456453034654e-05,7.566306157968938e-05,7.849527173675597e-05,8.828342106426135e-05,0.0002313859004061669,0.0002349178830627352,0.00017413026944268495,0.00014945217117201537,0.00013465779193211347,0.0001246954343514517,0.00011673076369334012,0.00013139379734639078,0.0002412752219242975,0.0001944658870343119,0.00017347493849229068,0.00015565294597763568,0.00014561564603354782,0.00013744187890551984,
mae,0.1680261194705963,0.09453340619802475,0.075944684445858,0.043970655649900436,0.025830253958702087,0.022356322035193443,0.01912291720509529,0.0176681037992239,0.016393279656767845,0.01545810792595148,0.014704675413668156,0.014276571571826935,0.013571999035775661,0.013064893893897533,0.012805516831576824,0.012305294163525105,0.011992096900939941,0.011752758175134659,0.01149832271039486,0.01129903830587864,0.011052641086280346,0.01083303615450859,0.01080151554197073,0.010512040928006172,0.010493176989257336,0.010259158909320831,0.010009685531258583,0.009954825975000858,0.009817677550017834,0.009760608896613121,0.009535598568618298,0.009494143538177013,0.009321838617324829,0.00938910897821188,0.009149333462119102,0.009069369174540043,0.014358571730554104,0.01414457242935896,0.014154681004583836,0.01481518242508173,0.01594545692205429,0.014004448428750038,0.008483749814331532,0.008562372997403145,0.008325506001710892,0.008247881196439266,0.008241124451160431,0.008274417370557785,0.008178354240953922,0.008120566606521606,0.008099137805402279,0.008004358038306236,0.008045798167586327,0.007950207218527794,0.007959704846143723,0.00783783569931984,0.007776922080665827,0.007830713875591755,0.0077460468746721745,0.007748854346573353,0.007651897147297859,0.007683885749429464,0.007575448602437973,0.007600058801472187,0.007680930662900209,0.007556740660220385,0.0074192238971591,0.007488984614610672,0.0075437156483531,0.0074066580273211,0.00728727737441659,0.007395974360406399,0.007267781067639589,0.007245801854878664,0.0072221700102090836,0.00711178220808506,0.007113696541637182,0.007090198341757059,0.0070493160746991634,0.007076077628880739,0.007055280264467001,0.006966710556298494,0.006999756209552288,0.006961456965655088,0.006866951007395983,0.0072059063240885735,0.011893289163708687,0.012447815388441086,0.011151083745062351,0.010317090898752213,0.009786239825189114,0.009336108341813087,0.0090156439691782,0.009145519696176052,0.012677112594246864,0.011598826386034489,0.01087628211826086,0.010244200006127357,0.00983721949160099,0.009539198130369186,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 4427      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 4428      
=================================================================
Total params: 8,855
Trainable params: 8,855
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 4,427
Trainable params: 4,427
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 4,428
Trainable params: 4,428
Non-trainable params: 0
_________________________________________________________________
