2021-06-26
loss,0.312374472618103,0.21845543384552002,0.15745629370212555,0.09103116393089294,0.09755777567625046,0.0817873403429985,0.06456317752599716,0.056405067443847656,0.04718708619475365,0.055122848600149155,0.06220681965351105,0.06809832900762558,0.06302771717309952,0.05227028205990791,0.044259872287511826,0.04338297247886658,0.041034866124391556,0.047096382826566696,0.04077234864234924,0.03778085485100746,0.043701305985450745,0.047475650906562805,0.0440935418009758,0.03554564714431763,0.04139231517910957,0.04202786460518837,0.03930607810616493,0.034830763936042786,0.038127198815345764,0.04014492407441139,0.031802672892808914,0.027849256992340088,0.032348621636629105,0.036692049354314804,0.03314701095223427,0.029400968924164772,0.03699447214603424,0.033391792327165604,0.029069796204566956,0.027777763083577156,0.028187289834022522,0.03199680149555206,0.033862531185150146,0.03056986629962921,0.02893698215484619,0.027020150795578957,0.02504650317132473,0.02915002591907978,0.027364399284124374,0.023850519210100174,0.017789775505661964,0.016911037266254425,0.016717547550797462,0.01686147041618824,0.027510887011885643,0.02622574009001255,0.025602400302886963,0.029566727578639984,0.02587052807211876,0.028057700023055077,0.025151144713163376,0.024438919499516487,0.02662045508623123,0.023755347356200218,0.02234501577913761,0.021686015650629997,0.02056187577545643,0.023239340633153915,0.0218668133020401,0.021124504506587982,0.020239699631929398,0.020269546657800674,0.0243814866989851,0.024019461125135422,0.023672543466091156,0.02654244937002659,0.02430136129260063,0.021775051951408386,0.022022681310772896,0.01824825443327427,0.016208594664931297,0.015566476620733738,0.017711101099848747,0.021019192412495613,0.021856026723980904,0.02343844808638096,0.024709457531571388,0.02213519625365734,0.021027754992246628,0.02050110325217247,0.021088816225528717,0.02184602990746498,0.02113356441259384,0.021492864936590195,0.019632162526249886,0.019277432933449745,0.021556749939918518,0.021497515961527824,0.021628351882100105,0.01981145516037941,
mse,0.03630002215504646,0.01742740347981453,0.008003626950085163,0.0025250976905226707,0.0028271314222365618,0.00195837183855474,0.0012414635857567191,0.0009410484926775098,0.0006685060798190534,0.0009121968760155141,0.0011260471073910594,0.0013585917185992002,0.001129251904785633,0.0008039757376536727,0.0005681859911419451,0.0005510725313797593,0.00048664677888154984,0.0006290879682637751,0.00047742840251885355,0.000415672519011423,0.0005691340193152428,0.000654558592941612,0.0005681401817128062,0.0003645653778221458,0.0005142611335031688,0.0005131755024194717,0.00043033892870880663,0.00035467854468151927,0.00041723091271705925,0.0004628213064279407,0.00029662298038601875,0.00023666392371524125,0.0002997043775394559,0.0003872475354000926,0.00031135513563640416,0.0002521117276046425,0.0003820077399723232,0.0003111270198132843,0.0002518340479582548,0.00022449478274211287,0.00023524441348854452,0.00028975342866033316,0.00032091783941723406,0.0002670431276783347,0.00023777458409313112,0.00020970289187971503,0.00018505181651562452,0.0002435218048049137,0.00021516354172490537,0.000168651356943883,9.700905502540991e-05,8.48959170980379e-05,8.388719288632274e-05,8.601797162555158e-05,0.00022103781520854682,0.00020032664178870618,0.0001916635810630396,0.0002480173425283283,0.00019199054804630578,0.0002210001985076815,0.0001814687275327742,0.00017361949721816927,0.0001983194233616814,0.00016187125584110618,0.00014766142703592777,0.00014425907284021378,0.0001279491261811927,0.0001540759694762528,0.00013764537288807333,0.00012908378266729414,0.00011935079237446189,0.0001230187772307545,0.00017283398483414203,0.00016664070426486433,0.00016689731273800135,0.00020656915148720145,0.0001709982316242531,0.00013597501674667,0.00013995783228892833,0.00010732252121670172,8.448628796031699e-05,7.629268657183275e-05,9.816150850383565e-05,0.0001268443593289703,0.00013667967868968844,0.00015648077533114702,0.0001711882505333051,0.0001379893656121567,0.00012650032294914126,0.00012068389332853258,0.00012811640044674277,0.00013556664634961635,0.00012994525604881346,0.00013520587526727468,0.00011017413635272533,0.00010746597399702296,0.00013104785466566682,0.00013255819794721901,0.000133251553052105,0.00011127135076094419,
mae,0.13352376222610474,0.10137458145618439,0.06744822859764099,0.039094191044569016,0.04237763583660126,0.03509484604001045,0.027751218527555466,0.024034662172198296,0.020241547375917435,0.02373383566737175,0.026316259056329727,0.029589354991912842,0.02738042175769806,0.02243722975254059,0.018876299262046814,0.018641911447048187,0.017356516793370247,0.02009752206504345,0.017719287425279617,0.016151435673236847,0.018749462440609932,0.020572379231452942,0.019088810309767723,0.014874354936182499,0.017665527760982513,0.01793474331498146,0.0169947762042284,0.015208268538117409,0.016219688579440117,0.01721484214067459,0.013633332215249538,0.011801495216786861,0.013931064866483212,0.015923654660582542,0.013884452171623707,0.012430055998265743,0.01570751518011093,0.014314659871160984,0.012230046093463898,0.011742275208234787,0.012025033123791218,0.013809463009238243,0.014416365884244442,0.013257469981908798,0.012446146458387375,0.01125248521566391,0.010540765710175037,0.012386235408484936,0.011669342406094074,0.010312672704458237,0.007624214980751276,0.007316991686820984,0.0071526276879012585,0.00722637539729476,0.01181863434612751,0.01095194835215807,0.01085369661450386,0.012640092521905899,0.011071901768445969,0.012112238444387913,0.010808013379573822,0.01040710136294365,0.011235177516937256,0.009864099323749542,0.009567614644765854,0.009281150996685028,0.008820442482829094,0.00967133417725563,0.008834765292704105,0.008612923324108124,0.008253010921180248,0.008456957526504993,0.010087510570883751,0.010073891840875149,0.010107802227139473,0.011218487285077572,0.010213339701294899,0.009187083691358566,0.0092419208958745,0.0077772303484380245,0.006971263326704502,0.006643715314567089,0.007555521558970213,0.00885797943919897,0.009229499846696854,0.010047334246337414,0.01047034002840519,0.009241735562682152,0.008820941671729088,0.008886385709047318,0.00899494532495737,0.009402725845575333,0.008930375799536705,0.009198445826768875,0.00847540982067585,0.008347724564373493,0.00920743029564619,0.009150460362434387,0.009326697327196598,0.008290664292871952,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 21163     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 21164     
=================================================================
Total params: 42,327
Trainable params: 42,327
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 21,163
Trainable params: 21,163
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 21,164
Trainable params: 21,164
Non-trainable params: 0
_________________________________________________________________
