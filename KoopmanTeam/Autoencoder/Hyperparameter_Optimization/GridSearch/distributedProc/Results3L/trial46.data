2021-06-26
loss,0.29146474599838257,0.07264717668294907,0.05272083729505539,0.06043444201350212,0.048504315316677094,0.04588291794061661,0.041520167142152786,0.03749067708849907,0.05276437848806381,0.04799245670437813,0.05401034280657768,0.04452131688594818,0.0375184528529644,0.029626624658703804,0.027760667726397514,0.029364226385951042,0.04337301850318909,0.036734141409397125,0.04190509021282196,0.03558006137609482,0.03298262506723404,0.030680455267429352,0.02756374515593052,0.02460099384188652,0.022456370294094086,0.022229136899113655,0.021528882905840874,0.02101161889731884,0.027189716696739197,0.034275904297828674,0.02926238626241684,0.029524102807044983,0.03337064012885094,0.031250063329935074,0.030258875340223312,0.026085948571562767,0.022715404629707336,0.02297661267220974,0.028092259541153908,0.025527723133563995,0.028628533706068993,0.029207449406385422,0.024920139461755753,0.024016091600060463,0.025854578241705894,0.02372507005929947,0.022409943863749504,0.02149108238518238,0.015260514803230762,0.014959681779146194,0.01442655548453331,0.014082249253988266,0.014000252820551395,0.013870504684746265,0.013726076111197472,0.013801558874547482,0.013767069205641747,0.013724868185818195,0.013640280812978745,0.013432478532195091,0.013559413142502308,0.013404017314314842,0.013367476873099804,0.01339978538453579,0.013191192410886288,0.013212699443101883,0.013089640997350216,0.01298527792096138,0.013096642680466175,0.012873806990683079,0.01277759950608015,0.012883329764008522,0.012727027758955956,0.012697377242147923,0.012579021044075489,0.012466060929000378,0.01246927585452795,0.012403962202370167,0.01235082745552063,0.01223815232515335,0.012273874133825302,0.012182976119220257,0.01211190689355135,0.01205550879240036,0.011973435059189796,0.011950752697885036,0.01181606762111187,0.01184803992509842,0.011851733550429344,0.01178180705755949,0.014354373328387737,0.020172500982880592,0.019059685990214348,0.018741264939308167,0.019111156463623047,0.018664972856640816,0.0201423317193985,0.019878452643752098,0.017675546929240227,0.016123460605740547,
mse,0.0367572158575058,0.0016672140918672085,0.000849059724714607,0.0011490281904116273,0.0006681614904664457,0.0005913028726354241,0.0004899355699308217,0.00040620475192554295,0.0008304249495267868,0.0006735667702741921,0.0008322767680510879,0.0005668946541845798,0.0004254058003425598,0.0002557000261731446,0.0002237827720819041,0.0002527741016820073,0.0005603039171546698,0.0003830604546237737,0.0005025966675020754,0.0003518316661939025,0.00030415746732614934,0.0002631777024362236,0.00021757616195827723,0.0001735708792693913,0.00014607308548875153,0.00014511763583868742,0.00013438117457553744,0.00012667405826505274,0.00021876780374441296,0.00033065039315260947,0.0002426544378977269,0.00024485858739353716,0.0003123167552985251,0.0002720568736549467,0.00025743935839273036,0.0001885042729554698,0.00014972528151702136,0.00015312839241232723,0.0002198438160121441,0.00018253002781420946,0.00023579230764880776,0.0002359434583922848,0.00017320897313766181,0.00016304019663948566,0.00018248781270813197,0.00015647975669708103,0.00013956973270978779,0.00013106824189890176,6.639998173341155e-05,6.260538066271693e-05,5.844730549142696e-05,5.559972851187922e-05,5.472819248097949e-05,5.444680937216617e-05,5.273622082313523e-05,5.3302883316064253e-05,5.241472172201611e-05,5.2021332521690056e-05,5.164685717318207e-05,5.023808262194507e-05,5.111161226523109e-05,4.977016578777693e-05,4.963089668308385e-05,5.018127922085114e-05,4.790233288076706e-05,4.8547768528806046e-05,4.776762216351926e-05,4.697398253483698e-05,4.714598981081508e-05,4.5908018364571035e-05,4.575657658278942e-05,4.560771049000323e-05,4.475374225876294e-05,4.471183638088405e-05,4.362485196907073e-05,4.3092426494695246e-05,4.336070196586661e-05,4.25234466092661e-05,4.193350105197169e-05,4.173384149908088e-05,4.161821198067628e-05,4.081394581589848e-05,4.09886815759819e-05,4.078216807101853e-05,3.958769957534969e-05,3.944189302274026e-05,3.9177946746349335e-05,3.985450166510418e-05,3.9087779441615567e-05,3.934146661777049e-05,6.592834688490257e-05,0.00011860929225804284,0.00010223451681667939,0.00010019589535659179,0.00010059391206596047,9.898692223941907e-05,0.0001118272339226678,0.00010622706031426787,8.891033212421462e-05,7.656177331227809e-05,
mae,0.12318666279315948,0.031032448634505272,0.02260778471827507,0.02586468495428562,0.02052813582122326,0.01931961439549923,0.01760082319378853,0.01608220487833023,0.02308894693851471,0.02088608592748642,0.023294806480407715,0.019180262461304665,0.01615876704454422,0.01294687669724226,0.0118324626237154,0.01260913535952568,0.01858658157289028,0.01579134166240692,0.018126793205738068,0.015257146209478378,0.014283979311585426,0.013524254783987999,0.011992068029940128,0.010640782304108143,0.009634966030716896,0.00959505420178175,0.009233254939317703,0.009039384312927723,0.01152827963232994,0.014337245374917984,0.012466603890061378,0.01252286322414875,0.014460559003055096,0.013369964435696602,0.013210887089371681,0.01105374377220869,0.00964475516229868,0.009699566289782524,0.012164762243628502,0.011091193184256554,0.012188118882477283,0.012635966762900352,0.01065589115023613,0.010194790549576283,0.010831616818904877,0.010019090957939625,0.00962028931826353,0.009227676317095757,0.006572766229510307,0.006498596165329218,0.00624648854136467,0.0060478998348116875,0.006009840872138739,0.005966927390545607,0.005843717604875565,0.005860026925802231,0.005830723792314529,0.005821102764457464,0.00582098588347435,0.0057026054710149765,0.00569202471524477,0.005688914097845554,0.005639732349663973,0.005682994145900011,0.005593119189143181,0.005567314103245735,0.0055855922400951385,0.00551091181114316,0.005521091166883707,0.005485400557518005,0.00542791560292244,0.005482333246618509,0.005384745076298714,0.005390571430325508,0.005337427370250225,0.005265418905764818,0.005266332067549229,0.005259424448013306,0.005241840612143278,0.005195861682295799,0.005186200141906738,0.005163363181054592,0.005151514895260334,0.005130840465426445,0.005076025612652302,0.005071674473583698,0.0049859206192195415,0.005016788840293884,0.005076442379504442,0.004949646070599556,0.006079785991460085,0.008612100034952164,0.008107063360512257,0.007946805097162724,0.00810314156115055,0.007914605550467968,0.00873053539544344,0.008677185513079166,0.007632994558662176,0.006804532837122679,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 21123     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 21124     
=================================================================
Total params: 42,247
Trainable params: 42,247
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 21,123
Trainable params: 21,123
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 21,124
Trainable params: 21,124
Non-trainable params: 0
_________________________________________________________________
