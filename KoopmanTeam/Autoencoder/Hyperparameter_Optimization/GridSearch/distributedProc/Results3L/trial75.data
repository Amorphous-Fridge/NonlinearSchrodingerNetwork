2021-06-26
loss,0.3762844204902649,0.10817530006170273,0.07787805795669556,0.06830883771181107,0.06214889883995056,0.0739561915397644,0.06206056475639343,0.06126111000776291,0.051496472209692,0.04831729829311371,0.04160003364086151,0.04547547921538353,0.04611741006374359,0.03736400231719017,0.029622292146086693,0.030957259237766266,0.03506794571876526,0.04043539613485336,0.035965122282505035,0.03908578306436539,0.03564994037151337,0.03414037823677063,0.03454631567001343,0.03186478838324547,0.028167376294732094,0.028757475316524506,0.03253353014588356,0.030022235587239265,0.029606947675347328,0.03016771376132965,0.025325104594230652,0.022795122116804123,0.026650477200746536,0.02562117390334606,0.030095627531409264,0.027395449578762054,0.027393555268645287,0.021786076948046684,0.022248337045311928,0.023725368082523346,0.019508587196469307,0.01563449576497078,0.01834854856133461,0.023598341271281242,0.019579021260142326,0.023733915761113167,0.020830566063523293,0.020260902121663094,0.021977201104164124,0.023117758333683014,0.019970260560512543,0.019699720665812492,0.022135378792881966,0.017799295485019684,0.017863698303699493,0.02039409801363945,0.02063572220504284,0.019657397642731667,0.017169706523418427,0.0153035344555974,0.014153276570141315,0.01942477375268936,0.021041620522737503,0.018489651381969452,0.01623808592557907,0.018828539177775383,0.016225581988692284,0.013837311416864395,0.01673746667802334,0.01823204942047596,0.017440127208828926,0.017878182232379913,0.015338074415922165,0.014230838045477867,0.013862297870218754,0.013562233187258244,0.013153357431292534,0.015151742845773697,0.019149040803313255,0.018139082938432693,0.01766175962984562,0.015036379918456078,0.01489560678601265,0.01580178365111351,0.014810013584792614,0.016184600070118904,0.01491940300911665,0.013281288556754589,0.013353451155126095,0.014897462911903858,0.01578553393483162,0.015552043914794922,0.014345892705023289,0.013482808135449886,0.012628256343305111,0.013915070332586765,0.013044659979641438,0.014420839957892895,0.015293625183403492,0.014762609265744686,
mse,0.05209222435951233,0.004185148514807224,0.0017739426111802459,0.0013533788733184338,0.001172339078038931,0.0015682001831009984,0.0011408064747229218,0.001066270051524043,0.0007892381981946528,0.000687650463078171,0.0005118303233757615,0.0006039941217750311,0.0006178792682476342,0.00040185690158978105,0.00025522391661070287,0.0002934257499873638,0.0003725071146618575,0.0004644503933377564,0.0003886832273565233,0.00043376683606766164,0.0003642576630227268,0.0003455393889453262,0.0003528314409777522,0.00030389137100428343,0.00023321322805713862,0.0002511795028112829,0.00031421773019246757,0.000265534152276814,0.00025160040240734816,0.00026510690804570913,0.00019266940944362432,0.00015949844964779913,0.00020440405933186412,0.00019879006140399724,0.0002591228985693306,0.0002133213129127398,0.000220411442569457,0.00014502700651064515,0.0001434056757716462,0.0001617991947568953,0.00011604119936237112,7.281903526745737e-05,0.00010347761417506263,0.00016195506032090634,0.00011562286817934364,0.00016282612341456115,0.00013220225810073316,0.00012100285675842315,0.00013915634190198034,0.00015021600120235234,0.0001170254108728841,0.00011598777928156778,0.00014227064093574882,9.747516014613211e-05,9.532319381833076e-05,0.00011978508700849488,0.00012515339767560363,0.0001091974409064278,8.847090066410601e-05,7.069437560858205e-05,6.091512841521762e-05,0.00010903063230216503,0.00012464009341783822,9.910488734021783e-05,7.853407441871241e-05,0.00010343983740312979,7.99221161287278e-05,5.9397956647444516e-05,8.625227201264352e-05,9.506088827038184e-05,8.860642265062779e-05,9.009846689878032e-05,6.834058149252087e-05,6.305213901214302e-05,5.933177817496471e-05,5.699293615180068e-05,5.348562262952328e-05,6.817394023528323e-05,0.00010731193469837308,9.14713746169582e-05,8.980609709396958e-05,6.576455052709207e-05,6.563641363754869e-05,7.103956158971414e-05,6.418221892090514e-05,7.419829489663243e-05,6.40628786641173e-05,5.376544868340716e-05,5.4665961215505376e-05,6.578789179911837e-05,7.111163722584024e-05,6.743743870174512e-05,5.9464342484716326e-05,5.124154995428398e-05,4.6472348913084716e-05,5.7223216572310776e-05,5.0374834245303646e-05,6.101604594732635e-05,6.598958134418353e-05,6.259047222556546e-05,
mae,0.16111087799072266,0.045072827488183975,0.03294645622372627,0.029031407088041306,0.02623080089688301,0.03190620616078377,0.026270151138305664,0.025989430025219917,0.021882789209485054,0.020767178386449814,0.01751066744327545,0.019241897389292717,0.01963871531188488,0.015916340053081512,0.012502028606832027,0.013208954595029354,0.01480878610163927,0.017144395038485527,0.015335743315517902,0.01664198562502861,0.015059318393468857,0.014478248544037342,0.014606395736336708,0.013625217601656914,0.012046044692397118,0.01217079907655716,0.013907316140830517,0.012859893962740898,0.01254562009125948,0.012929271906614304,0.01079392060637474,0.00965642835944891,0.011374065652489662,0.011016316711902618,0.012884519062936306,0.011665585450828075,0.01163419708609581,0.009275036863982677,0.009471604600548744,0.010065333917737007,0.008274063467979431,0.006637582555413246,0.007780652027577162,0.009965677745640278,0.008328994736075401,0.009960578754544258,0.00873502902686596,0.008654549717903137,0.009332816116511822,0.009769972413778305,0.008536187000572681,0.00842222198843956,0.009446836076676846,0.007495294790714979,0.007600958459079266,0.008651990443468094,0.008839095011353493,0.008353077806532383,0.007364206947386265,0.006555786356329918,0.005963865667581558,0.008304637856781483,0.008914495818316936,0.00781532283872366,0.0068673985078930855,0.008018764667212963,0.006879652850329876,0.005819142330437899,0.0070759328082203865,0.007743371184915304,0.007446519564837217,0.0075058601796627045,0.00645377766340971,0.005995109677314758,0.0058645461685955524,0.005778601858764887,0.0055449772626161575,0.0064399647526443005,0.008164376951754093,0.00767641793936491,0.00754947355017066,0.006352465599775314,0.006336497608572245,0.006582461763173342,0.00625627813860774,0.006780937779694796,0.006325279362499714,0.005644429940730333,0.005619006231427193,0.006320786662399769,0.0066363816149532795,0.0065136621706187725,0.00603282218798995,0.005607511382550001,0.005314771085977554,0.0059044379740953445,0.005514089949429035,0.00616171769797802,0.006505268160253763,0.006215124856680632,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 50115     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 50116     
=================================================================
Total params: 100,231
Trainable params: 100,231
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 50,115
Trainable params: 50,115
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 50,116
Trainable params: 50,116
Non-trainable params: 0
_________________________________________________________________
