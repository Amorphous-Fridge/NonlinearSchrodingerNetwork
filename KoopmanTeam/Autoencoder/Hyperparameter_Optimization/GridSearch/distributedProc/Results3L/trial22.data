2021-06-26
loss,0.3385670483112335,0.09095419198274612,0.05520329996943474,0.04364558681845665,0.03753844276070595,0.033850617706775665,0.03168099373579025,0.03108906000852585,0.02921869233250618,0.028133757412433624,0.027178559452295303,0.026338916271924973,0.025613723322749138,0.02521585486829281,0.024638064205646515,0.024013513699173927,0.023543307557702065,0.023088151589035988,0.022696292027831078,0.02260080724954605,0.0221632719039917,0.021770954132080078,0.02162882499396801,0.021204251796007156,0.021147428080439568,0.02088538371026516,0.020656809210777283,0.02057737298309803,0.020334625616669655,0.01999419927597046,0.01984279789030552,0.019846543669700623,0.01955566555261612,0.019321907311677933,0.01917163096368313,0.018938293680548668,0.018817970529198647,0.01870161108672619,0.018698396161198616,0.01836901716887951,0.01833462342619896,0.018101941794157028,0.018096687272191048,0.017968541011214256,0.017672423273324966,0.017634805291891098,0.01758088916540146,0.017530297860503197,0.01743450202047825,0.017206791788339615,0.017180563881993294,0.017028065398335457,0.016962386667728424,0.016964931041002274,0.016786634922027588,0.016733717173337936,0.01649913564324379,0.016555001959204674,0.016440274193882942,0.01640983857214451,0.016309743747115135,0.016198808327317238,0.01615237072110176,0.016066575422883034,0.01596645824611187,0.015882175415754318,0.01586916670203209,0.01576814614236355,0.015706738457083702,0.015606170520186424,0.015593279153108597,0.015469405800104141,0.015532375313341618,0.01537646446377039,0.01532782893627882,0.015300849452614784,0.015221690759062767,0.015202159062027931,0.015073285438120365,0.015047031454741955,0.015088120475411415,0.014931677840650082,0.014944731257855892,0.01484222523868084,0.014777754433453083,0.014758237637579441,0.014662173576653004,0.014637274667620659,0.014541455544531345,0.014630675315856934,0.01446322537958622,0.014529949054121971,0.014497574418783188,0.014348668046295643,0.014297962188720703,0.014248006045818329,0.014263235032558441,0.014175010845065117,0.014145820401608944,0.014173443429172039,
mse,0.04341207817196846,0.0030810395255684853,0.0010205595754086971,0.0006173749570734799,0.0004479752096813172,0.00036265526432543993,0.00032175518572330475,0.0002932693751063198,0.00025877615553326905,0.00023742338817100972,0.00022213436022866517,0.00020837545162066817,0.00019570555014070123,0.00018956624262500554,0.00018100788292940706,0.0001717201666906476,0.0001644006697461009,0.0001576757786097005,0.00015148130478337407,0.0001500866492278874,0.00014500002725981176,0.00013824552297592163,0.00013573099568020552,0.00013087027764413506,0.00012990430695936084,0.00012672336015384644,0.00012445647735148668,0.00012292101746425033,0.0001199741309392266,0.00011552354408195242,0.00011411020386731252,0.00011275317228864878,0.0001106658746721223,0.00010725292668212205,0.00010540819494053721,0.00010265988385071978,0.00010169295273954049,0.00010049609409179538,9.965704521164298e-05,9.63738639256917e-05,9.538608719594777e-05,9.326587314717472e-05,9.283656254410744e-05,9.170980774797499e-05,8.826756675262004e-05,8.810550207272172e-05,8.778030314715579e-05,8.731061825528741e-05,8.588705532019958e-05,8.33556114230305e-05,8.373369200853631e-05,8.204437472159043e-05,8.133002847898751e-05,8.121477731037885e-05,7.961583469295874e-05,7.88242177804932e-05,7.657161768293008e-05,7.753682439215481e-05,7.560922676930204e-05,7.598304364364594e-05,7.471913704648614e-05,7.401548646157607e-05,7.252461364259943e-05,7.258178084157407e-05,7.199017272796482e-05,7.104145333869383e-05,7.110773731255904e-05,6.971718539716676e-05,6.890182703500614e-05,6.82511308696121e-05,6.786137237213552e-05,6.711194873787463e-05,6.73803297104314e-05,6.633566226810217e-05,6.564408977283165e-05,6.523007323266938e-05,6.461432349169627e-05,6.472420500358567e-05,6.430633220588788e-05,6.347997259581462e-05,6.327226583380252e-05,6.205793033586815e-05,6.255644257180393e-05,6.142711936263368e-05,6.0841473896289244e-05,6.074055272620171e-05,5.979415072943084e-05,5.989807687001303e-05,5.929309918428771e-05,5.9109050198458135e-05,5.832264287164435e-05,5.8681216614786536e-05,5.826189953950234e-05,5.739337211707607e-05,5.685333235305734e-05,5.626652273349464e-05,5.655644054058939e-05,5.5979056924115866e-05,5.555590178119019e-05,5.5799166148062795e-05,
mae,0.14799432456493378,0.038775376975536346,0.023413358256220818,0.01849883422255516,0.015832697972655296,0.014316374436020851,0.013514790683984756,0.012996559962630272,0.012340325862169266,0.011860119178891182,0.011426222510635853,0.011139282956719398,0.010824106633663177,0.01075142901390791,0.010392340831458569,0.010193542577326298,0.009952392429113388,0.009786311537027359,0.009622306562960148,0.009479425847530365,0.009371507912874222,0.009338531643152237,0.009091131389141083,0.008840227499604225,0.009030751883983612,0.008845703676342964,0.008765976876020432,0.008736171759665012,0.008611289784312248,0.008530021645128727,0.00854202825576067,0.008458067663013935,0.008319486863911152,0.008174832910299301,0.008200329728424549,0.008120129816234112,0.007955562323331833,0.007857066579163074,0.007918096147477627,0.007897796109318733,0.007787302136421204,0.007662856485694647,0.007568085100501776,0.0077766613103449345,0.007419992703944445,0.007550508249551058,0.0074083576910197735,0.0074607087299227715,0.007398365531116724,0.00722807040438056,0.007176070008426905,0.007188111077994108,0.007113713771104813,0.00727381044998765,0.007072295993566513,0.007139899302273989,0.007041626609861851,0.007135242223739624,0.007014813367277384,0.006987881846725941,0.006951909512281418,0.0068290624767541885,0.00682167150080204,0.006802648771554232,0.006787712685763836,0.006701923441141844,0.0067857312969863415,0.006722959224134684,0.006538780406117439,0.006630063056945801,0.0066518825478851795,0.0065116314217448235,0.006608914118260145,0.006668064743280411,0.006601303815841675,0.0065414784476161,0.006408474408090115,0.006377252750098705,0.0063676731660962105,0.006375058088451624,0.006373957265168428,0.006344297435134649,0.006502674426883459,0.006396481767296791,0.006164824590086937,0.006366610061377287,0.006169885862618685,0.006229545455425978,0.006216049659997225,0.0062340907752513885,0.006000680383294821,0.006265996489673853,0.006270034704357386,0.006130864843726158,0.005947483703494072,0.006013702135533094,0.0060214330442249775,0.006080555729568005,0.005953497719019651,0.0060460567474365234,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5443      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5444      
=================================================================
Total params: 10,887
Trainable params: 10,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 5,443
Trainable params: 5,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 5,444
Trainable params: 5,444
Non-trainable params: 0
_________________________________________________________________
