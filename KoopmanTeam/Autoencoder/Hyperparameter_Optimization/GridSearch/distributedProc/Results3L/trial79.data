2021-06-26
loss,0.350148469209671,0.0984606146812439,0.06931993365287781,0.05654517561197281,0.04897674173116684,0.042176660150289536,0.04134694114327431,0.034708037972450256,0.0412573479115963,0.035234905779361725,0.039955511689186096,0.03880218416452408,0.03826680779457092,0.02732415497303009,0.024156784638762474,0.023783907294273376,0.034509576857089996,0.03680964186787605,0.029710562899708748,0.022971970960497856,0.02327432483434677,0.026351768523454666,0.03355792909860611,0.03144342452287674,0.026959586888551712,0.025098111480474472,0.024083897471427917,0.027198530733585358,0.028149070218205452,0.02355477772653103,0.018347393721342087,0.018060268834233284,0.020312821492552757,0.02425568178296089,0.02849356085062027,0.0261071864515543,0.020587751641869545,0.020787011831998825,0.02241102047264576,0.024483375251293182,0.02374061569571495,0.02442588098347187,0.025475777685642242,0.021887117996811867,0.02009515091776848,0.02175910770893097,0.023315029218792915,0.019573425874114037,0.018977683037519455,0.017679523676633835,0.019748279824852943,0.02146480791270733,0.020297767594456673,0.019092539325356483,0.020163467153906822,0.018055537715554237,0.017526952549815178,0.01905670017004013,0.01787213608622551,0.016829418018460274,0.015900369733572006,0.014819538220763206,0.017639584839344025,0.020701754838228226,0.01811302825808525,0.01683555170893669,0.01649283617734909,0.02042490430176258,0.020367925986647606,0.017126576974987984,0.01776491105556488,0.01636369153857231,0.015363994985818863,0.014624548144638538,0.01710077002644539,0.015913458541035652,0.01649636961519718,0.017624055966734886,0.01615178771317005,0.014998452737927437,0.014701888896524906,0.017116330564022064,0.01690063066780567,0.015611449256539345,0.014667540788650513,0.013616385869681835,0.013478338718414307,0.015722956508398056,0.01712389476597309,0.01567658595740795,0.015019506216049194,0.013495255261659622,0.012705886736512184,0.013161864131689072,0.014594794251024723,0.01773526519536972,0.017963675782084465,0.016226399689912796,0.014102590270340443,0.014156725257635117,
mse,0.056970033794641495,0.002993888920173049,0.0014214100083336234,0.0009189166012220085,0.0007321320008486509,0.0005248620873317122,0.0005088775069452822,0.0003565441584214568,0.0004834348219446838,0.00037758462713100016,0.00046354802907444537,0.0004282646987121552,0.0004218464018777013,0.00022337297559715807,0.00018272263696417212,0.00017017469508573413,0.00033564071054570377,0.0003786985471379012,0.00024770875461399555,0.00016287242760881782,0.00016169929585885257,0.00020211456285323948,0.0003191002761013806,0.0002816389605868608,0.00020857485651504248,0.00018762605031952262,0.00016735107055865228,0.00022715251543559134,0.0002318556944373995,0.000168439801200293,0.00010264362208545208,9.762119589140639e-05,0.0001237187098013237,0.00016426235379185528,0.00022522345534525812,0.0002023275737883523,0.0001262671430595219,0.00012862532457802445,0.00014515970542561263,0.00016618553490843624,0.00016131496522575617,0.0001681208668742329,0.00018445095338393003,0.0001374950079480186,0.00012058169522788376,0.00013237984967418015,0.0001541102974442765,0.00011319512850604951,0.00010696137906052172,9.444848546991125e-05,0.00011156812979606912,0.00012892074300907552,0.00011474985512904823,0.00010642920824466273,0.00011334269220242277,9.273718751501292e-05,9.121213952312246e-05,0.00010180054232478142,9.024418977787718e-05,8.179095311788842e-05,7.423356146318838e-05,6.524494529003277e-05,9.22552208066918e-05,0.00011728584649972618,8.99410733836703e-05,8.05008239694871e-05,7.929580169729888e-05,0.00011823219392681494,0.00012011383660137653,8.475698268739507e-05,8.79204017110169e-05,7.484682282665744e-05,6.670685252174735e-05,6.287309224717319e-05,8.653534314362332e-05,7.452947465935722e-05,7.946581899886951e-05,8.659706509206444e-05,7.431984704453498e-05,6.641206709900871e-05,6.704005500068888e-05,8.399755461141467e-05,7.916201138868928e-05,6.828501500422135e-05,6.279444642132148e-05,5.609213258139789e-05,5.5748791055520996e-05,7.26954749552533e-05,8.298607281176373e-05,6.979725731071085e-05,6.443786696763709e-05,5.5560758482897654e-05,5.0303409807384014e-05,5.299820986692794e-05,6.173715519253165e-05,8.738575706956908e-05,9.374619548907503e-05,7.46579171391204e-05,5.982124639558606e-05,5.7885619753506035e-05,
mae,0.14941096305847168,0.04179815202951431,0.02957424893975258,0.02444213628768921,0.02068323642015457,0.01807328499853611,0.01734675094485283,0.014849493280053139,0.01747116632759571,0.014978376217186451,0.016749681904911995,0.01646810956299305,0.01610981673002243,0.011619452387094498,0.010288932360708714,0.010118387639522552,0.014676489867269993,0.01543440856039524,0.012480478733778,0.009659253992140293,0.009950104169547558,0.011223879642784595,0.014319568872451782,0.013161834329366684,0.011404821649193764,0.010681948624551296,0.010272448882460594,0.01120915450155735,0.011924096383154392,0.009932591579854488,0.00780884874984622,0.007610321044921875,0.008556442335247993,0.010279135778546333,0.012074533849954605,0.01097019761800766,0.008777616545557976,0.008817006833851337,0.009665075689554214,0.01044290792196989,0.01005912572145462,0.01021693553775549,0.010589014738798141,0.009234310127794743,0.008537755347788334,0.009310110472142696,0.00984403770416975,0.008208475075662136,0.008075921796262264,0.007553058210760355,0.008315261453390121,0.009006908163428307,0.008575018495321274,0.008106973953545094,0.008492641150951385,0.007764420472085476,0.007506280671805143,0.008086169138550758,0.007680250331759453,0.007211389485746622,0.0068490211851894855,0.006389021873474121,0.007447791285812855,0.008722559548914433,0.007791944779455662,0.0073438240215182304,0.0070303515531122684,0.008534527383744717,0.008428787812590599,0.007244298234581947,0.007574230898171663,0.006953878328204155,0.006488618440926075,0.006058901082724333,0.0072747631929814816,0.006855600979179144,0.0070100463926792145,0.007470276206731796,0.006847315933555365,0.006433658767491579,0.0061661177314817905,0.007285283412784338,0.007199749816209078,0.006682266015559435,0.006342447362840176,0.005813133902847767,0.005691621918231249,0.006770483683794737,0.0071132248267531395,0.006608199328184128,0.006354214623570442,0.005770674906671047,0.005398914683610201,0.005563691258430481,0.006239619106054306,0.007482137065380812,0.007569998037070036,0.006898968014866114,0.005974069703370333,0.005942963529378176,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 70819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 70820     
=================================================================
Total params: 141,639
Trainable params: 141,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 70,819
Trainable params: 70,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 70,820
Trainable params: 70,820
Non-trainable params: 0
_________________________________________________________________
