2021-06-26
loss,0.4559255540370941,0.24727711081504822,0.21831203997135162,0.1849818229675293,0.07555366307497025,0.043127384036779404,0.033818319439888,0.030647560954093933,0.02806897647678852,0.026954811066389084,0.02588108368217945,0.02469240128993988,0.02385747991502285,0.023336799815297127,0.023371469229459763,0.0228213332593441,0.022103341296315193,0.021699698641896248,0.021379156038165092,0.021076511591672897,0.020435810089111328,0.020453358069062233,0.019984949380159378,0.019976451992988586,0.019476596266031265,0.019453775137662888,0.019429152831435204,0.018971240147948265,0.018535083159804344,0.018811121582984924,0.018404319882392883,0.01837092824280262,0.0179681908339262,0.01775563508272171,0.017709976062178612,0.017471667379140854,0.017246434465050697,0.01723853498697281,0.016979658976197243,0.01693623512983322,0.016843101009726524,0.016836052760481834,0.016547754406929016,0.016560286283493042,0.016550393775105476,0.016446411609649658,0.01607714779675007,0.016177913174033165,0.015831829980015755,0.015633905306458473,0.0158831849694252,0.015643790364265442,0.015450959093868732,0.015399731695652008,0.015386112965643406,0.015362679958343506,0.015249455347657204,0.014994286000728607,0.014956269413232803,0.014914015308022499,0.014875564724206924,0.014759013429284096,0.01467984914779663,0.014559878036379814,0.014429482631385326,0.014523032121360302,0.01433026697486639,0.014380330219864845,0.014211347326636314,0.01422871369868517,0.014168666675686836,0.01393826212733984,0.014169749803841114,0.01395970955491066,0.013931507244706154,0.01374631654471159,0.013821211643517017,0.013687756843864918,0.013541596941649914,0.013701360672712326,0.01368962973356247,0.013433622196316719,0.013591795228421688,0.013430162332952023,0.013389987871050835,0.0133342444896698,0.013434856198728085,0.013221786357462406,0.01321363914757967,0.013155151158571243,0.013130826875567436,0.013163375668227673,0.013024233281612396,0.013133963569998741,0.013083597645163536,0.01291457749903202,0.012923432514071465,0.01289555337280035,0.012874500826001167,0.012687052600085735,
mse,0.06837523728609085,0.021089835092425346,0.017623357474803925,0.012840472161769867,0.002436903538182378,0.0007877567550167441,0.0004808264202438295,0.00039683468639850616,0.000339432037435472,0.00030842656269669533,0.0002775961474981159,0.0002558898995630443,0.00024114992993418127,0.0002288832765771076,0.0002208715450251475,0.00021139951422810555,0.00019785643962677568,0.0001912401057779789,0.00018511594680603594,0.00017829662829171866,0.00016600285016465932,0.0001657727116253227,0.00015846933820284903,0.0001573165354784578,0.00015161317423917353,0.0001484597596572712,0.00014388409908860922,0.00013963542005512863,0.0001345231430605054,0.00013557838974520564,0.00012977894220966846,0.00012980772589799017,0.0001247465261258185,0.00012130357936257496,0.00012129116657888517,0.00011851263116113842,0.00011442165850894526,0.00011377288319636136,0.00011097732203779742,0.00010935919999610633,0.00010915808525169268,0.00010920313070528209,0.00010527796985115856,0.00010354510595789179,0.00010370021482231095,0.00010177170770475641,9.774690261110663e-05,9.976311412174255e-05,9.703308023745194e-05,9.484193287789822e-05,9.503534965915605e-05,9.260403749067336e-05,9.135663276538253e-05,8.958214311860502e-05,9.0767651272472e-05,8.965782762970775e-05,8.899634121917188e-05,8.505014557158574e-05,8.601076842751354e-05,8.496206282870844e-05,8.411010639974847e-05,8.253356645582244e-05,8.171320223482326e-05,8.115269156405702e-05,7.923426892375574e-05,8.054958743741736e-05,7.776913844281808e-05,7.84744115662761e-05,7.632782217115164e-05,7.609048043377697e-05,7.618142990395427e-05,7.416514563374221e-05,7.42397241992876e-05,7.373464904958382e-05,7.331590313697234e-05,7.125175034161657e-05,7.262725557666272e-05,7.128185097826645e-05,6.86499843141064e-05,7.10760141373612e-05,6.994188152020797e-05,6.807185127399862e-05,6.98626899975352e-05,6.743119593011215e-05,6.731844041496515e-05,6.647438567597419e-05,6.750111788278446e-05,6.561296322615817e-05,6.481608579633757e-05,6.50638758088462e-05,6.448593194363639e-05,6.452912202803418e-05,6.291557656368241e-05,6.371616473188624e-05,6.356370431603864e-05,6.203094380907714e-05,6.169668631628156e-05,6.192743603605777e-05,5.9850761317647994e-05,5.977436012472026e-05,
mae,0.1959371566772461,0.11371088027954102,0.10437266528606415,0.083616703748703,0.03149716556072235,0.01801261119544506,0.014249461703002453,0.012917053885757923,0.01189203280955553,0.011423405259847641,0.010938595980405807,0.010453058406710625,0.010111978277564049,0.009918740950524807,0.0099058011546731,0.009677214547991753,0.009344559162855148,0.009185176342725754,0.00906793400645256,0.008904528804123402,0.008679594844579697,0.008659854531288147,0.008463588543236256,0.008422473445534706,0.00822877325117588,0.008242377080023289,0.008165580220520496,0.007989385165274143,0.007885869592428207,0.007940459065139294,0.007791645359247923,0.007749494165182114,0.007652874104678631,0.007531785871833563,0.007480993866920471,0.007374138105660677,0.007316522765904665,0.007309891749173403,0.007216154132038355,0.007165314629673958,0.007181825581938028,0.007115557324141264,0.007038118317723274,0.007039361633360386,0.0069574457593262196,0.00695751653984189,0.006842656061053276,0.006806471385061741,0.006735187955200672,0.006679784040898085,0.006718324031680822,0.0066517977975308895,0.0065215397626161575,0.0065607475116848946,0.006538067478686571,0.006444413680583239,0.006483195815235376,0.006348091177642345,0.006266930606216192,0.006318768952041864,0.006315682083368301,0.006295975297689438,0.00619192561134696,0.006114044692367315,0.006164127495139837,0.006129481364041567,0.006075856275856495,0.00610627606511116,0.006001974456012249,0.005970371887087822,0.00597120588645339,0.005952153354883194,0.005947028286755085,0.005925631616264582,0.005852756090462208,0.005818135570734739,0.005834439303725958,0.005837561562657356,0.005726102739572525,0.005751693621277809,0.005727520678192377,0.005704609677195549,0.005735586863011122,0.005623644683510065,0.00561157101765275,0.005620860960334539,0.005654939915984869,0.005630558356642723,0.005548183806240559,0.005594311282038689,0.005529261659830809,0.0054749902337789536,0.005532951559871435,0.005535926204174757,0.00549528282135725,0.005425991490483284,0.0054431394673883915,0.005442836321890354,0.0054034339264035225,0.00539533793926239,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1163      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1164      
=================================================================
Total params: 2,327
Trainable params: 2,327
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 1,163
Trainable params: 1,163
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 1,164
Trainable params: 1,164
Non-trainable params: 0
_________________________________________________________________
