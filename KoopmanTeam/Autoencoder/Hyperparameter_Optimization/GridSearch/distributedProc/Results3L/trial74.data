2021-06-26
loss,0.3702765703201294,0.13508905470371246,0.07894296944141388,0.07497984170913696,0.045051079243421555,0.03903434798121452,0.04312814772129059,0.04975394159555435,0.055107638239860535,0.04841335862874985,0.04506123438477516,0.03932716324925423,0.04297001659870148,0.04159321263432503,0.035667791962623596,0.03177555650472641,0.03836994618177414,0.041582945734262466,0.03295239061117172,0.028448890894651413,0.025314098224043846,0.028270775452256203,0.036728668957948685,0.032045166939496994,0.03067954070866108,0.03290601074695587,0.031824737787246704,0.02807997725903988,0.025790316984057426,0.023851165547966957,0.02632962167263031,0.02555139549076557,0.021318798884749413,0.023195289075374603,0.030778588727116585,0.030518198385834694,0.02442438341677189,0.0224738959223032,0.02174163982272148,0.020326126366853714,0.023654552176594734,0.023081915453076363,0.020693384110927582,0.019853616133332253,0.02399599738419056,0.019818909466266632,0.02307870239019394,0.022347427904605865,0.024507474154233932,0.022715101018548012,0.023019423708319664,0.024070218205451965,0.024983422830700874,0.023244017735123634,0.021209396421909332,0.019593942910432816,0.01802295632660389,0.016406184062361717,0.016205597668886185,0.02045314945280552,0.017952824011445045,0.015665050595998764,0.014819740317761898,0.016863688826560974,0.016000282019376755,0.019540516659617424,0.022900106385350227,0.020643694326281548,0.01990615762770176,0.02040036953985691,0.018958475440740585,0.018885567784309387,0.01628669537603855,0.015613112598657608,0.014555949717760086,0.014148170128464699,0.016690440475940704,0.01922706887125969,0.0191416684538126,0.019360681995749474,0.01742011122405529,0.016342420130968094,0.016448764130473137,0.02063571661710739,0.020012684166431427,0.018036792054772377,0.015832452103495598,0.013981509953737259,0.013708886690437794,0.01217647921293974,0.013559628278017044,0.01785329543054104,0.01763777993619442,0.016830427572131157,0.016507402062416077,0.01675564795732498,0.01620519906282425,0.016041191294789314,0.016482319682836533,0.016051970422267914,
mse,0.051148921251297,0.005849259439855814,0.0019058698089793324,0.001789306988939643,0.0005894311470910907,0.0004379345919005573,0.0005394576000981033,0.0007207760936580598,0.0008495092624798417,0.0006704828701913357,0.0005869260057806969,0.0004385485081002116,0.0005298383766785264,0.0005240623722784221,0.0003689014120027423,0.0002982968871947378,0.00042112753726541996,0.0004923567175865173,0.0003171233111061156,0.00023812327708583325,0.00018969761731568724,0.0002348777634324506,0.00039196229772642255,0.00029660589643754065,0.00027390551986172795,0.00031222988036461174,0.0002817909116856754,0.00022443542547989637,0.0001883959339465946,0.00016964407404884696,0.00019848094962071627,0.00018179276958107948,0.00013672775821760297,0.00016447318193968385,0.00026577457902021706,0.0002632769464980811,0.00017755087174009532,0.0001461583306081593,0.00013860900071449578,0.00012589257676154375,0.00016713596414774656,0.0001546410785522312,0.00012857929687015712,0.00011939870455535129,0.00016329644131474197,0.00011824403918581083,0.0001511396112618968,0.0001430862321285531,0.0001753397227730602,0.0001503701350884512,0.00014581000141333789,0.0001625157310627401,0.00017410691361874342,0.00015440856805071235,0.00012437536497600377,0.0001083391543943435,9.334177593700588e-05,8.037590305320919e-05,7.987773278728127e-05,0.00012136263831052929,9.50069515965879e-05,7.37044756533578e-05,6.617292092414573e-05,8.388468995690346e-05,7.702127913944423e-05,0.00011865582928294316,0.00014604194439016283,0.00011983399599557742,0.00011571542563615367,0.00011764590453822166,0.00010354051482863724,9.878364653559402e-05,7.817472942406312e-05,7.457975152647123e-05,6.47028791718185e-05,6.034768739482388e-05,8.39044587337412e-05,0.00010337268759030849,0.00010381965694250539,0.00010258763359161094,8.449307642877102e-05,7.6212381827645e-05,8.007694850675762e-05,0.00011995431123068556,0.00011741268099285662,9.350233449367806e-05,7.287590415216982e-05,5.957757093710825e-05,5.739019252359867e-05,4.492006701184437e-05,5.578872878686525e-05,9.115706052398309e-05,8.673041156725958e-05,7.824991917004809e-05,7.73944120737724e-05,8.131378126563504e-05,7.653610373381525e-05,7.260458369273692e-05,7.810781244188547e-05,7.142283720895648e-05,
mae,0.15817368030548096,0.05883141607046127,0.03363274410367012,0.03219957649707794,0.019093316048383713,0.01648102141916752,0.018379412591457367,0.02118886075913906,0.02339952625334263,0.020740315318107605,0.01918858475983143,0.016702735796570778,0.01827430911362171,0.017766978591680527,0.015275249257683754,0.01351100578904152,0.016217024996876717,0.01754259131848812,0.014165349304676056,0.012015091255307198,0.010773880407214165,0.012149007059633732,0.015779808163642883,0.013309120200574398,0.013073095120489597,0.013942764140665531,0.01349631231278181,0.011809727177023888,0.010980521328747272,0.010120502673089504,0.011116775684058666,0.0106595978140831,0.009062991477549076,0.009852401912212372,0.01312289573252201,0.013081153854727745,0.010470235720276833,0.009571611881256104,0.009187843650579453,0.008646760135889053,0.01000918634235859,0.00977968517690897,0.008823845535516739,0.008462782949209213,0.010149532929062843,0.008419589139521122,0.0097397081553936,0.009480664506554604,0.010439890436828136,0.009659897536039352,0.009694624692201614,0.010178719647228718,0.010664059780538082,0.00989130511879921,0.00874431524425745,0.008132659830152988,0.007756756618618965,0.007067576516419649,0.006841757334768772,0.008716050535440445,0.007579077500849962,0.006673475727438927,0.006322694011032581,0.007120177149772644,0.006832954939454794,0.00836370512843132,0.009765389375388622,0.008723837323486805,0.008376078680157661,0.00859606359153986,0.008035928010940552,0.007984879426658154,0.006965124513953924,0.006568768061697483,0.006114107556641102,0.00600851234048605,0.0070740701630711555,0.008134408853948116,0.008073360659182072,0.008088046684861183,0.0072883786633610725,0.00694930600002408,0.007037465460598469,0.008779583498835564,0.008508449420332909,0.007623350713402033,0.006803212221711874,0.005969630554318428,0.005879070609807968,0.005205688998103142,0.005738153588026762,0.0076179830357432365,0.007434619124978781,0.007163119502365589,0.007018005941063166,0.007170768920332193,0.006914097815752029,0.006764426361769438,0.007059033494442701,0.006813921499997377,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 41859     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 41860     
=================================================================
Total params: 83,719
Trainable params: 83,719
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 41,859
Trainable params: 41,859
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 41,860
Trainable params: 41,860
Non-trainable params: 0
_________________________________________________________________
