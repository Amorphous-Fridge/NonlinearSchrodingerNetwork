2021-06-26
loss,0.3339020013809204,0.18975955247879028,0.09141106903553009,0.06698183715343475,0.06908062100410461,0.05755842104554176,0.04605308547616005,0.037542302161455154,0.033589549362659454,0.03105221316218376,0.028752023354172707,0.026240715757012367,0.0245931688696146,0.02306182123720646,0.02203659527003765,0.02168606035411358,0.021029096096754074,0.020405393093824387,0.02043447270989418,0.01973777264356613,0.01933572255074978,0.019109468907117844,0.01870671473443508,0.01830437034368515,0.01818517968058586,0.01792806200683117,0.017624495550990105,0.017409058287739754,0.017297470942139626,0.016953006386756897,0.016858533024787903,0.016581371426582336,0.016528431326150894,0.016307586804032326,0.016156142577528954,0.015949489548802376,0.015868576243519783,0.015651000663638115,0.01564430445432663,0.015527031384408474,0.015164203941822052,0.015294625423848629,0.01519976370036602,0.014909904450178146,0.014955745078623295,0.014782642014324665,0.014691703021526337,0.014606681652367115,0.014468810521066189,0.014265171252191067,0.014416107907891273,0.014249213971197605,0.014214464463293552,0.014113797806203365,0.013925778679549694,0.01395964901894331,0.013814277946949005,0.013792842626571655,0.01358799822628498,0.013614191673696041,0.013499095104634762,0.013399090617895126,0.01347840204834938,0.013152713887393475,0.013377890922129154,0.01324854139238596,0.013058367185294628,0.013040116056799889,0.013020878657698631,0.012884301133453846,0.012837438844144344,0.012910689227283001,0.012734566815197468,0.012645233422517776,0.012604977935552597,0.01264191884547472,0.012646657414734364,0.012472339905798435,0.012392363511025906,0.012468170374631882,0.012378170154988766,0.01232162956148386,0.012262169271707535,0.012301752343773842,0.012086744420230389,0.012085957452654839,0.012052468955516815,0.012154984287917614,0.011875027790665627,0.012392157688736916,0.012265116907656193,0.012214039452373981,0.012003766372799873,0.011942491866648197,0.011831426993012428,0.011839537881314754,0.01926032267510891,0.01917712762951851,0.018330760300159454,0.021262764930725098,
mse,0.043996140360832214,0.013369865715503693,0.002698774915188551,0.001452229917049408,0.0014046634314581752,0.0010202075354754925,0.0006612594588659704,0.0004383385821711272,0.00034724135184660554,0.0002972131478600204,0.0002591230149846524,0.00021824214491061866,0.00018922737217508256,0.00016854748537298292,0.0001535056362627074,0.00014652835670858622,0.00013831919932272285,0.00012870473437942564,0.00012842248543165624,0.00011982132855337113,0.00011504724534461275,0.00011178326531080529,0.00010762766760308295,0.0001021791686071083,0.00010129740257980302,9.777454397408292e-05,9.41285106819123e-05,9.157278691418469e-05,9.035378752741963e-05,8.665992936585099e-05,8.580728172091767e-05,8.291674021165818e-05,8.197357965400442e-05,7.975310290930793e-05,7.820707833161578e-05,7.630276377312839e-05,7.629911851836368e-05,7.38144080969505e-05,7.306050247279927e-05,7.23445336916484e-05,6.997802120167762e-05,6.973925337661058e-05,6.87088759150356e-05,6.582886271644384e-05,6.60910300211981e-05,6.448273779824376e-05,6.442241283366457e-05,6.283797119976953e-05,6.200125790201128e-05,6.133624992799014e-05,6.164072692627087e-05,5.988631892250851e-05,5.9170932217966765e-05,5.8361198171041906e-05,5.680972753907554e-05,5.702592898160219e-05,5.641854659188539e-05,5.591150329564698e-05,5.484937719302252e-05,5.413807593868114e-05,5.291824709274806e-05,5.284864528221078e-05,5.285407314659096e-05,5.13048107677605e-05,5.2046365453861654e-05,5.06858887092676e-05,4.966885899193585e-05,4.973037721356377e-05,4.9411853979108855e-05,4.825172800337896e-05,4.7981524403439835e-05,4.809900565305725e-05,4.711449582828209e-05,4.65822740807198e-05,4.727594568976201e-05,4.6569919504690915e-05,4.648747926694341e-05,4.542811802821234e-05,4.454414010979235e-05,4.465110760065727e-05,4.4108270230935887e-05,4.4388660171534866e-05,4.328618888393976e-05,4.3504573113750666e-05,4.296750921639614e-05,4.258177796145901e-05,4.255474414094351e-05,4.241100396029651e-05,4.146954961470328e-05,4.597292354446836e-05,4.4525833800435066e-05,4.2907744500553235e-05,4.0869126678444445e-05,4.0912120311986655e-05,4.076456025359221e-05,4.165486461715773e-05,0.00010900775669142604,0.00010117618512595072,9.461272566113621e-05,0.00012381133274175227,
mae,0.1413150429725647,0.08278032392263412,0.039719585329294205,0.02891908586025238,0.02941274829208851,0.025033526122570038,0.020046183839440346,0.016246356070041656,0.014184181578457355,0.013079172000288963,0.012189553119242191,0.011189223267138004,0.010499369353055954,0.009857681579887867,0.009398863650858402,0.009209005162119865,0.008966044522821903,0.008672412484884262,0.008739371784031391,0.008418076671659946,0.008239436894655228,0.008150474168360233,0.00800748635083437,0.007761593908071518,0.0077700549736619,0.007647952530533075,0.007452318444848061,0.007428039330989122,0.007385024335235357,0.0071989065036177635,0.007172043435275555,0.0070748357102274895,0.0070878867991268635,0.006908077746629715,0.006869934033602476,0.0067831361666321754,0.006749491207301617,0.006683815736323595,0.0066485027782619,0.006594175472855568,0.006475062575191259,0.006460901349782944,0.006452986504882574,0.0062522864900529385,0.006359000224620104,0.006317491643130779,0.006275352090597153,0.006196004804223776,0.006159603595733643,0.006048045586794615,0.006148606538772583,0.006137318443506956,0.00601648073643446,0.006006909068673849,0.005985081195831299,0.00587011594325304,0.005873087793588638,0.00586287397891283,0.0057589830830693245,0.00576763553544879,0.005772951990365982,0.005639413371682167,0.005775520112365484,0.005548409651964903,0.005693459417670965,0.005662434734404087,0.005510882940143347,0.0055087567307055,0.005554796662181616,0.0054156421683728695,0.005418790504336357,0.005552459508180618,0.005388662219047546,0.005356611218303442,0.00534790987148881,0.0053758216090500355,0.005356477573513985,0.005310086999088526,0.005277542397379875,0.005305486731231213,0.005184338893741369,0.005280244164168835,0.005191182717680931,0.00523935304954648,0.0051004947163164616,0.0051096524111926556,0.00509544787928462,0.005131151527166367,0.005036667454987764,0.005282334517687559,0.005232055205851793,0.005192473530769348,0.00512938667088747,0.0051111457869410515,0.005010990891605616,0.0050133406184613705,0.008193204179406166,0.008608764968812466,0.008019346743822098,0.00880232360213995,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6515      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6516      
=================================================================
Total params: 13,031
Trainable params: 13,031
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 6,515
Trainable params: 6,515
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 6,516
Trainable params: 6,516
Non-trainable params: 0
_________________________________________________________________
