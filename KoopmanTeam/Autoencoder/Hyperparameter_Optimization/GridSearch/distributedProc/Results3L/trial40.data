2021-06-26
loss,0.3091698884963989,0.08306166529655457,0.0457150898873806,0.037688449025154114,0.03641267865896225,0.04953518509864807,0.03655846044421196,0.0330403596162796,0.03649093955755234,0.041718870401382446,0.04580262675881386,0.03770839422941208,0.033157385885715485,0.02390715852379799,0.02240595780313015,0.02190684713423252,0.021548785269260406,0.02111581340432167,0.020963437855243683,0.020724980160593987,0.020303506404161453,0.02036147564649582,0.01986377313733101,0.019728440791368484,0.019334537908434868,0.019147489219903946,0.018979305401444435,0.018910694867372513,0.018475372344255447,0.018458032980561256,0.018366632983088493,0.027418935671448708,0.025303348898887634,0.028270693495869637,0.02878902666270733,0.027400823310017586,0.029688887298107147,0.029118385165929794,0.025009479373693466,0.028158431872725487,0.03039037249982357,0.025560710579156876,0.018578670918941498,0.01667129620909691,0.017352186143398285,0.017695022746920586,0.017079344019293785,0.028398973867297173,0.025054477155208588,0.022457130253314972,0.020959336310625076,0.01992270164191723,0.019159551709890366,0.019685370847582817,0.022546377032995224,0.028847260400652885,0.028354080393910408,0.027662081643939018,0.024498796090483665,0.018551649525761604,0.023237841203808784,0.02612314186990261,0.023582661524415016,0.022254018113017082,0.021552249789237976,0.020534012466669083,0.019501641392707825,0.01862947829067707,0.017742820084095,0.01701877824962139,0.0184718519449234,0.028620943427085876,0.027074268087744713,0.023640193045139313,0.02150637097656727,0.02033238112926483,0.019180595874786377,0.01810416765511036,0.017498865723609924,0.016887612640857697,0.016448311507701874,0.016091642901301384,0.015754016116261482,0.015396583825349808,0.014756309799849987,0.013990575447678566,0.013569418340921402,0.013158193789422512,0.012946524657309055,0.012784029357135296,0.012575536966323853,0.012447449378669262,0.012332487851381302,0.012283473275601864,0.012238437309861183,0.012021304108202457,0.014852529391646385,0.018488798290491104,0.020194226875901222,0.018152890726923943,
mse,0.039166051894426346,0.00236115837469697,0.0006348033202812076,0.0004207732272334397,0.0003942298935726285,0.0007228081813082099,0.0004092467133887112,0.00032779702451080084,0.0004156313952989876,0.0005064334254711866,0.0005996155086904764,0.00041553404298610985,0.0003239046782255173,0.00016907855751924217,0.0001460648054489866,0.00013836275320500135,0.0001333430118393153,0.00012762822734657675,0.000127578794490546,0.00012208941916469485,0.000116678886115551,0.00011668968363665044,0.00011218315921723843,0.000109017790236976,0.00010506027319934219,0.00010364352783653885,0.00010091688454849645,0.00010029730037786067,9.566702647134662e-05,9.555967699270695e-05,9.846637840382755e-05,0.00023222582240123302,0.0001889175910037011,0.0002283947542309761,0.00024292097077704966,0.00021657692559529096,0.0002492790808901191,0.00023628906637895852,0.00017602577281650156,0.0002266335504828021,0.0002619724255055189,0.0001840512122726068,0.00010200342512689531,7.95068044681102e-05,9.069876978173852e-05,9.312648035120219e-05,8.650786912767217e-05,0.00022328822524286807,0.00017862109234556556,0.00014070187171455473,0.0001240262936335057,0.00011274473945377395,0.00010490147542441264,0.00011252680997131392,0.0001518352364655584,0.00023339354083873332,0.00022710194753017277,0.00021155073773115873,0.00016882916679605842,0.0001069824502337724,0.0001588179002283141,0.0001912578009068966,0.00015355295909103006,0.0001394674472976476,0.00013219323591329157,0.00012019388668704778,0.00010858162568183616,9.935857815435156e-05,8.979914855444804e-05,8.248222729889676e-05,0.00010171269968850538,0.00022954755695536733,0.00020893845066893846,0.00015474960673600435,0.00012904155300930142,0.00011664105841191486,0.00010456876043463126,9.330641478300095e-05,8.709957910468802e-05,8.157084812410176e-05,7.754385296721011e-05,7.396887667709962e-05,7.066239777486771e-05,6.763474084436893e-05,6.219481292646378e-05,5.625602352665737e-05,5.1882634579669684e-05,4.8848523874767125e-05,4.7364341298816726e-05,4.6185632527340204e-05,4.46845697297249e-05,4.3819025449920446e-05,4.395919677335769e-05,4.294043901609257e-05,4.238197288941592e-05,4.277170228306204e-05,6.684012623736635e-05,0.00010178553930018097,0.00011668226943584159,9.148108802037314e-05,
mae,0.1313723474740982,0.03516257181763649,0.019254524260759354,0.016117900609970093,0.015385061502456665,0.021286938339471817,0.015508662909269333,0.014085624366998672,0.015596304088830948,0.017716581001877785,0.019419245421886444,0.0160206351429224,0.014027131721377373,0.010165560990571976,0.009502464905381203,0.009342722594738007,0.009130166843533516,0.008979265578091145,0.008952032774686813,0.00891483761370182,0.008602679707109928,0.008608726784586906,0.008435902185738087,0.008373301476240158,0.008316644467413425,0.008187026716768742,0.00812104158103466,0.008097445592284203,0.007943524979054928,0.00782395526766777,0.007784034125506878,0.012318314053118229,0.010924011468887329,0.01192475575953722,0.012133714742958546,0.011500311084091663,0.01240882184356451,0.01232943870127201,0.010886120609939098,0.012040870264172554,0.01305888406932354,0.01081316452473402,0.007768130861222744,0.00710255466401577,0.007452624849975109,0.007450119126588106,0.007214686367660761,0.01214643381536007,0.010726358741521835,0.009441991336643696,0.00873768050223589,0.008313680067658424,0.007949634455144405,0.008312180638313293,0.009616928175091743,0.01234603300690651,0.012185147032141685,0.012025853618979454,0.01082012802362442,0.00797784049063921,0.009967389516532421,0.011190006509423256,0.010223431512713432,0.009748956188559532,0.009520347230136395,0.009031849913299084,0.008547844365239143,0.008108229376375675,0.0075234584510326385,0.007199766114354134,0.007789661176502705,0.01236014999449253,0.011943264864385128,0.01029565092176199,0.009383770637214184,0.00878563430160284,0.008142990991473198,0.00765740592032671,0.007388223893940449,0.0071012903936207294,0.006916035432368517,0.006734208669513464,0.006562774069607258,0.006421465892344713,0.006332330871373415,0.005977343767881393,0.005880736745893955,0.005573592614382505,0.00551116606220603,0.0054430877789855,0.005330576095730066,0.005273285321891308,0.005254795774817467,0.005196316633373499,0.005161992274224758,0.005117213819175959,0.006270574405789375,0.007748420350253582,0.008739214390516281,0.007565234787762165,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 10691     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 10692     
=================================================================
Total params: 21,383
Trainable params: 21,383
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 10,691
Trainable params: 10,691
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 10,692
Trainable params: 10,692
Non-trainable params: 0
_________________________________________________________________
