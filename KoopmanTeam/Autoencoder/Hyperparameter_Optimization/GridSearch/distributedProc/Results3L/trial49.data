2021-06-26
loss,0.35979199409484863,0.09553339332342148,0.10166513174772263,0.06780305504798889,0.059000179171562195,0.04705455154180527,0.05171579867601395,0.04684855043888092,0.037345126271247864,0.03831544518470764,0.04346296191215515,0.033824943006038666,0.0360436886548996,0.03840712457895279,0.04104829207062721,0.03689327836036682,0.03327041119337082,0.030362697318196297,0.02960222400724888,0.028439965099096298,0.02438170462846756,0.030942395329475403,0.03565910458564758,0.030513959005475044,0.03042709268629551,0.028298035264015198,0.022505536675453186,0.02133995294570923,0.023697538301348686,0.02429465763270855,0.02645833231508732,0.026153957471251488,0.027459997683763504,0.02302904799580574,0.024599473923444748,0.025500638410449028,0.023798443377017975,0.020897293463349342,0.020397979766130447,0.01940782368183136,0.019996402785182,0.018190760165452957,0.016426455229520798,0.016544492915272713,0.020239515230059624,0.022754348814487457,0.02121640369296074,0.0212065652012825,0.017900561913847923,0.016597090288996696,0.018982794135808945,0.02153399959206581,0.020666906610131264,0.018034575507044792,0.01779848523437977,0.017394643276929855,0.018880443647503853,0.017894303426146507,0.019076943397521973,0.018523598089814186,0.01758301816880703,0.016454393044114113,0.01385027077049017,0.013535710982978344,0.014673414640128613,0.01523712370544672,0.015179915353655815,0.013486891984939575,0.018492110073566437,0.018898751586675644,0.016453437507152557,0.014124995097517967,0.014605531468987465,0.01382468082010746,0.01487991213798523,0.016446616500616074,0.01669144071638584,0.015641527250409126,0.012798309326171875,0.011834518983960152,0.013735570944845676,0.01303169596940279,0.015674399212002754,0.018007706850767136,0.016894938424229622,0.014394219033420086,0.013434997759759426,0.013007152825593948,0.01204718742519617,0.012659098953008652,0.015541103668510914,0.015654806047677994,0.015453101135790348,0.01530953124165535,0.015266012400388718,0.013919112272560596,0.012908797711133957,0.014624434523284435,0.014891736209392548,0.013967344537377357,
mse,0.05139903724193573,0.0029117888770997524,0.003327620681375265,0.0013350729132071137,0.001029635313898325,0.0006511207902804017,0.0007805649074725807,0.0006272548926062882,0.0004109459987375885,0.00042994803516194224,0.0005584427271969616,0.0003436923725530505,0.0003831599897239357,0.00042556304833851755,0.000500402064062655,0.00038659057463519275,0.00032695994013920426,0.00028060172917321324,0.0002576925908215344,0.00024253102310467511,0.00017869527800939977,0.0002884571731556207,0.00036802649265155196,0.0002714614092838019,0.00025749762426130474,0.00023198068083729595,0.00015488038479816169,0.00013681668497156352,0.00016816725837998092,0.00017158767150249332,0.00020313513232395053,0.00019900481856893748,0.00021639859187416732,0.0001562299730721861,0.00017305616347584873,0.00018386989540886134,0.0001623448042664677,0.0001319212169619277,0.0001220695412484929,0.00011465890565887094,0.00011985793389612809,9.995100845117122e-05,7.97481625340879e-05,8.163764869095758e-05,0.0001236100506503135,0.00014572216605301946,0.00012871516810264438,0.00012678230996243656,9.532352851238102e-05,8.296172745758668e-05,0.0001066990225808695,0.00012960883032064885,0.00012411254283506423,9.484501788392663e-05,9.376604430144653e-05,8.925808651838452e-05,0.00010208892490481958,9.148401295533404e-05,0.00010310333163943142,9.692520688986406e-05,8.904019341571257e-05,7.933195593068376e-05,5.843212784384377e-05,5.502051135408692e-05,6.504347402369604e-05,6.909763760631904e-05,7.000738696660846e-05,5.544378291233443e-05,9.404306183569133e-05,0.0001004726073006168,7.774174446240067e-05,6.009495336911641e-05,6.240356742637232e-05,5.848504224559292e-05,6.60461955703795e-05,7.796481804689392e-05,7.811189425410703e-05,6.88013169565238e-05,4.9518454034114257e-05,4.318180072004907e-05,5.679891910403967e-05,5.1903349230997264e-05,7.192284829216078e-05,9.05546112335287e-05,7.968729187268764e-05,5.984020754112862e-05,5.2461877203313634e-05,5.142705049365759e-05,4.4539508962770924e-05,4.941682345815934e-05,7.098179048625752e-05,6.90783781465143e-05,6.876271072542295e-05,6.535467400681227e-05,6.543668132508174e-05,5.721468187402934e-05,4.9363294237991795e-05,6.052053140592761e-05,6.360962288454175e-05,5.7470169849693775e-05,
mae,0.1544932723045349,0.04079147428274155,0.04343600198626518,0.028742466121912003,0.02526639960706234,0.019900677725672722,0.021731136366724968,0.019920766353607178,0.015889454632997513,0.016332559287548065,0.018513556569814682,0.014510910958051682,0.0154503108933568,0.01611330173909664,0.017584459856152534,0.015493345446884632,0.014204119332134724,0.012875608168542385,0.012615651823580265,0.012057015672326088,0.010514510795474052,0.013142747804522514,0.015363677404820919,0.01304788701236248,0.012945623137056828,0.01200061570852995,0.009524780325591564,0.009043245576322079,0.010047568939626217,0.010251755826175213,0.011212140321731567,0.011109225451946259,0.011578384786844254,0.00975291058421135,0.010370957665145397,0.0107421288266778,0.01014536339789629,0.008859779685735703,0.00872426014393568,0.008249213919043541,0.008484155870974064,0.007764555048197508,0.007015647832304239,0.007035235874354839,0.008500125259160995,0.009635157883167267,0.00903172604739666,0.008898969739675522,0.007598003838211298,0.0070592910051345825,0.007999161258339882,0.009169954806566238,0.008709244430065155,0.0075852395966649055,0.0075905476696789265,0.00733717018738389,0.008052929304540157,0.007509704679250717,0.0081328721717,0.00786307081580162,0.007471503224223852,0.006981578655540943,0.0058780633844435215,0.0056659989058971405,0.006248198915272951,0.006523509044200182,0.006467032246291637,0.0057726590894162655,0.007834875956177711,0.007969427853822708,0.006932190153747797,0.0060109361074864864,0.006162391975522041,0.005840645637363195,0.006301885470747948,0.006932252086699009,0.007054517976939678,0.006544644013047218,0.005450538359582424,0.005010643042623997,0.005847429856657982,0.0055474452674388885,0.006605157628655434,0.007684249430894852,0.007241604384034872,0.006042263470590115,0.005796805024147034,0.005454737693071365,0.005092816427350044,0.005384383723139763,0.006614058744162321,0.006649106275290251,0.006581626366823912,0.006527282763272524,0.006422699894756079,0.005927028134465218,0.005439387634396553,0.006196741480380297,0.006335154641419649,0.005974404979497194,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 50243     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 50244     
=================================================================
Total params: 100,487
Trainable params: 100,487
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 50,243
Trainable params: 50,243
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 50,244
Trainable params: 50,244
Non-trainable params: 0
_________________________________________________________________
