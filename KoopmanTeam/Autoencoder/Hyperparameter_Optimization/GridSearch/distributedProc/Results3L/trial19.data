2021-06-26
loss,0.34645575284957886,0.16395418345928192,0.07026538997888565,0.047105055302381516,0.038357410579919815,0.03290821239352226,0.029826132580637932,0.028141768649220467,0.02655424177646637,0.025508474558591843,0.02446463145315647,0.02375541627407074,0.023063039407134056,0.022634070366621017,0.02229328639805317,0.02174818329513073,0.021260099485516548,0.020906366407871246,0.020461637526750565,0.020170869305729866,0.019729219377040863,0.019459223374724388,0.01927356794476509,0.0189798716455698,0.018687307834625244,0.01845906488597393,0.018329035490751266,0.0180363692343235,0.017792319878935814,0.01777210645377636,0.01733006164431572,0.017340105026960373,0.017108554020524025,0.016949918121099472,0.016976594924926758,0.01661517657339573,0.016643382608890533,0.0163575429469347,0.01634124107658863,0.016077585518360138,0.01608574204146862,0.0159175805747509,0.015846671536564827,0.015755943953990936,0.01567457616329193,0.015528984367847443,0.01553351804614067,0.015238846652209759,0.015232297591865063,0.015194865874946117,0.015110425651073456,0.015025399625301361,0.015028243884444237,0.014892189763486385,0.01477656327188015,0.014726957306265831,0.014616838656365871,0.014586865901947021,0.014309188351035118,0.014496982097625732,0.01439838670194149,0.014437220990657806,0.014337983913719654,0.014233754016458988,0.014229745604097843,0.01407745759934187,0.014102489687502384,0.014140955172479153,0.013969388790428638,0.01386648416519165,0.013918910175561905,0.013784929178655148,0.013776309788227081,0.01366773247718811,0.013674385845661163,0.01358360517770052,0.01354893483221531,0.013532950542867184,0.013782596215605736,0.016268718987703323,0.0239370446652174,0.021877571940422058,0.020519403740763664,0.019510019570589066,0.018765553832054138,0.018267754465341568,0.01769573614001274,0.017009038478136063,0.01498720608651638,0.014087671414017677,0.013794787228107452,0.013610726222395897,0.013449890539050102,0.013369492255151272,0.013328076340258121,0.013181312009692192,0.013114222325384617,0.013012921437621117,0.012914719991385937,0.012988780625164509,
mse,0.04824107140302658,0.010019319131970406,0.001673080725595355,0.0007468266994692385,0.00048085988964885473,0.000347664812579751,0.00028133756131865084,0.00024574261624366045,0.00021739961812272668,0.00019975878240074962,0.00018256356997881085,0.00017054537602234632,0.00016201102698687464,0.00015402403369080275,0.00014907409786246717,0.00014192145317792892,0.00013527725241146982,0.00013040498015470803,0.00012489034270402044,0.00012106903886888176,0.00011573568917810917,0.00011194697435712442,0.00011017915676347911,0.00010608226875774562,0.00010312798258382827,0.00010048859985545278,9.896096889860928e-05,9.570451220497489e-05,9.304146078648046e-05,9.258000500267372e-05,8.886041177902371e-05,8.948068716563284e-05,8.563033043174073e-05,8.392890595132485e-05,8.402541425311938e-05,8.092631469480693e-05,8.061837434070185e-05,7.776160055072978e-05,7.797018770361319e-05,7.529008144047111e-05,7.522188388975337e-05,7.404334610328078e-05,7.326452032430097e-05,7.216029189294204e-05,7.106931298039854e-05,6.942381151020527e-05,6.957165169296786e-05,6.7197295720689e-05,6.733193731633946e-05,6.675106124021113e-05,6.595747981918976e-05,6.479474541265517e-05,6.499495066236705e-05,6.483710603788495e-05,6.265244155656546e-05,6.213479355210438e-05,6.131176633061841e-05,6.139816105132923e-05,5.878045340068638e-05,6.130802648840472e-05,6.061573003535159e-05,5.940904884482734e-05,5.879667878616601e-05,5.81819549552165e-05,5.7730096159502864e-05,5.724494985770434e-05,5.692624472430907e-05,5.707886884920299e-05,5.5608968978049234e-05,5.497109304997139e-05,5.519248225027695e-05,5.412111204350367e-05,5.4082182032288983e-05,5.318595140124671e-05,5.3257099352777004e-05,5.249404421192594e-05,5.233412957750261e-05,5.210721792536788e-05,5.6876346206991e-05,8.544484444428235e-05,0.00015588404494337738,0.00013099130592308939,0.0001169984316220507,0.00010664712317520753,9.930453961715102e-05,9.378568211104721e-05,8.877387153916061e-05,8.399564103456214e-05,6.660726648988202e-05,5.669753591064364e-05,5.482050619320944e-05,5.302657882566564e-05,5.236742435954511e-05,5.156442421139218e-05,5.065480581833981e-05,5.004207923775539e-05,4.957960481988266e-05,4.880458436673507e-05,4.769481165567413e-05,4.8922676796792075e-05,
mae,0.14586031436920166,0.06831040233373642,0.029643815010786057,0.0200998242944479,0.016408629715442657,0.014035896398127079,0.012702025473117828,0.01197178103029728,0.011373912915587425,0.010918238200247288,0.010380608029663563,0.010108721442520618,0.009839046746492386,0.009615907445549965,0.009508105926215649,0.009306090883910656,0.00911928340792656,0.008936146274209023,0.008780144155025482,0.00859089381992817,0.008412868715822697,0.00830348115414381,0.008296569809317589,0.00816367194056511,0.008029225282371044,0.007838431745767593,0.00786901731044054,0.007763240952044725,0.00760955736041069,0.007580197881907225,0.007469949312508106,0.007381030358374119,0.007372566498816013,0.007187774870544672,0.007296402007341385,0.007091608829796314,0.007050808519124985,0.006916180718690157,0.007039456162601709,0.0068970839492976665,0.006841634400188923,0.006781808566302061,0.006779087707400322,0.006717496085911989,0.006616557948291302,0.006462968420237303,0.006602620705962181,0.0064697242341935635,0.006460911128669977,0.006412121467292309,0.006470448337495327,0.0063833571039140224,0.006402980070561171,0.0063609047792851925,0.006301125977188349,0.006384467706084251,0.006163941230624914,0.006229008547961712,0.006063516717404127,0.006166370119899511,0.006201253738254309,0.0062383259646594524,0.006136747542768717,0.006098869256675243,0.00607788423076272,0.005911641754209995,0.006002245005220175,0.006074526347219944,0.005929243750870228,0.0058020357973873615,0.0058655403554439545,0.005824565421789885,0.005903940182179213,0.00580636877566576,0.005851767025887966,0.005780788604170084,0.0057640583254396915,0.0058114975690841675,0.005837407894432545,0.006919693201780319,0.010542276315391064,0.009706912562251091,0.008956868201494217,0.008452028036117554,0.008094025775790215,0.007860741578042507,0.007561592385172844,0.00723761972039938,0.006419882643967867,0.006077301688492298,0.005967467557638884,0.005786306690424681,0.005766658578068018,0.005717849358916283,0.005723143927752972,0.0055970377288758755,0.00566529855132103,0.005575795657932758,0.005483467597514391,0.0055185346864163876,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 4371      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 4372      
=================================================================
Total params: 8,743
Trainable params: 8,743
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 4,371
Trainable params: 4,371
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 4,372
Trainable params: 4,372
Non-trainable params: 0
_________________________________________________________________
