2021-06-26
loss,0.555718183517456,0.25143298506736755,0.1684892773628235,0.12063591927289963,0.08962416648864746,0.06978710740804672,0.059933342039585114,0.06118231266736984,0.04885801300406456,0.04979123920202255,0.04539988562464714,0.044257551431655884,0.042014990001916885,0.03846518695354462,0.0381682850420475,0.0310533307492733,0.03388619050383568,0.029399465769529343,0.02675074338912964,0.0299004465341568,0.030210820958018303,0.028845375403761864,0.030668562278151512,0.02445513941347599,0.026874585077166557,0.0269492007791996,0.023093871772289276,0.021019205451011658,0.0240582674741745,0.02512592077255249,0.02431388944387436,0.02088000997900963,0.021769404411315918,0.023041868582367897,0.021940011531114578,0.021318983286619186,0.0205216221511364,0.020011231303215027,0.02111680433154106,0.01925693452358246,0.019158650189638138,0.017538463696837425,0.01979934610426426,0.020792443305253983,0.018275242298841476,0.016095129773020744,0.018039999529719353,0.020121920853853226,0.01948811486363411,0.018787162378430367,0.020314252004027367,0.01798003911972046,0.016814367845654488,0.017424777150154114,0.01800793968141079,0.01878231018781662,0.019079094752669334,0.01683346927165985,0.015854081138968468,0.01780477724969387,0.01861693523824215,0.017336389049887657,0.016225339844822884,0.01363878883421421,0.014940321445465088,0.017171507701277733,0.016648784279823303,0.018215157091617584,0.01759614795446396,0.01642962545156479,0.017050456255674362,0.014677661471068859,0.015218295156955719,0.014572177082300186,0.016214430332183838,0.01712293177843094,0.016842752695083618,0.016096092760562897,0.015226389281451702,0.014569698832929134,0.012541080825030804,0.014168994501233101,0.013880200684070587,0.01406561117619276,0.01643824391067028,0.015513993799686432,0.015452058054506779,0.014119445346295834,0.013851797208189964,0.014414981938898563,0.016122207045555115,0.014926331117749214,0.012840584851801395,0.015493758954107761,0.015415932983160019,0.01531373243778944,0.01593797653913498,0.015135487541556358,0.01434929296374321,0.011816859245300293,
mse,0.12080138176679611,0.020693019032478333,0.0088953273370862,0.004610397852957249,0.0023958084639161825,0.001518456032499671,0.0010620098328217864,0.0011119242990389466,0.0006963865598663688,0.0007225286681205034,0.0005998187698423862,0.0005696017760783434,0.0005361561779864132,0.0004504611424636096,0.0004464284284040332,0.0002858459483832121,0.00034326405148021877,0.0002590021467767656,0.00021666906832251698,0.0002690656983759254,0.0002654081617947668,0.00024124639458023012,0.0002808311546687037,0.00018066192569676787,0.00021102784376125783,0.00020024603873025626,0.00015721663658041507,0.0001322463940596208,0.0001733848766889423,0.00018081396410707384,0.00016749725909903646,0.0001290198415517807,0.00013854277494829148,0.0001519414217909798,0.00014152280346024781,0.00013068060798104852,0.0001222257997142151,0.00011700328468577936,0.0001277258270420134,0.00010881630441872403,0.00010916347673628479,9.365610458189622e-05,0.00011689335951814428,0.00011869055015267804,9.833716467255726e-05,7.807148358551785e-05,9.739478264236823e-05,0.00011580233694985509,0.00010559358634054661,0.00010181836114497855,0.00011650619126157835,9.496256825514138e-05,8.645630441606045e-05,8.93666292540729e-05,9.58399468800053e-05,0.00010149912122869864,0.00010391692921984941,8.344240632141009e-05,7.731132063781843e-05,9.190323908114806e-05,9.521965694148093e-05,8.616092964075506e-05,7.698970875935629e-05,5.759252599091269e-05,6.922050670254976e-05,8.536599489161745e-05,8.162650919985026e-05,9.402440628036857e-05,9.093288099393249e-05,8.032015466596931e-05,8.321427594637498e-05,6.545688665937632e-05,6.915523408679292e-05,6.370290066115558e-05,7.722464943071827e-05,8.225353667512536e-05,8.19007764221169e-05,7.445470691891387e-05,6.724688864778727e-05,6.423613376682624e-05,4.866957533522509e-05,6.191835564095527e-05,5.878982483409345e-05,5.9461865021148697e-05,7.73312131059356e-05,7.054396701278165e-05,7.048307452350855e-05,5.971404243609868e-05,5.9430043620523065e-05,6.224757817108184e-05,7.684321462875232e-05,6.496968126157299e-05,5.164696995052509e-05,7.007463136687875e-05,6.816525274189189e-05,6.736892100889236e-05,7.243781146826223e-05,6.555014988407493e-05,6.130024848971516e-05,4.41960000898689e-05,
mae,0.2363683134317398,0.11210919171571732,0.07263302803039551,0.050703853368759155,0.03859485685825348,0.02989698387682438,0.02540404535830021,0.025948859751224518,0.020795175805687904,0.021108226850628853,0.01928163319826126,0.018851758912205696,0.01762787625193596,0.016413742676377296,0.016304396092891693,0.013149360194802284,0.014364020898938179,0.012493615038692951,0.011483781039714813,0.012645100243389606,0.012761306017637253,0.01218138262629509,0.012975088320672512,0.010407167486846447,0.011502471752464771,0.01155125629156828,0.009869417175650597,0.00906018540263176,0.0102227246388793,0.010564910247921944,0.010511551983654499,0.008833135478198528,0.009248101152479649,0.00981044489890337,0.009160608984529972,0.008865433745086193,0.008691636845469475,0.008398978039622307,0.008909309282898903,0.00811473187059164,0.008121991530060768,0.007387133780866861,0.008335704915225506,0.008722289465367794,0.0076455771923065186,0.006839157547801733,0.007555946707725525,0.008446442894637585,0.008364837616682053,0.007993284612894058,0.008537408895790577,0.007657013367861509,0.007174577564001083,0.007345709949731827,0.007611571345478296,0.008048836141824722,0.008045321330428123,0.007036241237074137,0.0068002729676663876,0.007596931885927916,0.007898075506091118,0.007456587161868811,0.006950572598725557,0.005771317519247532,0.006316107697784901,0.007198621518909931,0.0070500122383236885,0.007671985775232315,0.007453401573002338,0.0069834040477871895,0.007235036697238684,0.0062266383320093155,0.006429391913115978,0.006185078993439674,0.006893537472933531,0.00727451778948307,0.007125409319996834,0.006763411685824394,0.006379229947924614,0.006127898581326008,0.0051851775497198105,0.005932247266173363,0.0059052444994449615,0.0060171205550432205,0.006970561109483242,0.006591875106096268,0.006517139263451099,0.005950516555458307,0.005913467612117529,0.006156192626804113,0.006808363366872072,0.006343054119497538,0.00554339773952961,0.006429310422390699,0.006516578141599894,0.006478449329733849,0.006710015702992678,0.0063831740990281105,0.006117294542491436,0.005019579082727432,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 132739    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 132740    
=================================================================
Total params: 265,479
Trainable params: 265,479
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 132,739
Trainable params: 132,739
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 132,740
Trainable params: 132,740
Non-trainable params: 0
_________________________________________________________________
