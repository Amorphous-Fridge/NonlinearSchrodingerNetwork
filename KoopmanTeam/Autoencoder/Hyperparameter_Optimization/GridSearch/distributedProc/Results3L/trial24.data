2021-06-26
loss,0.35647374391555786,0.17618365585803986,0.09922055155038834,0.06457332521677017,0.0751904547214508,0.055970560759305954,0.0439295768737793,0.04063451662659645,0.03767119348049164,0.04618934541940689,0.04156799241900444,0.05204448103904724,0.043490853160619736,0.039168260991573334,0.04857778176665306,0.047288231551647186,0.03966328501701355,0.03610321879386902,0.033372748643159866,0.02984165959060192,0.03734217584133148,0.03849785029888153,0.032534390687942505,0.029953138902783394,0.028366900980472565,0.037194158881902695,0.040380313992500305,0.037977434694767,0.03293311968445778,0.028993714600801468,0.028879158198833466,0.03747407719492912,0.03226631134748459,0.029993144795298576,0.028550803661346436,0.027463966980576515,0.02660278230905533,0.02566986158490181,0.024936039000749588,0.024768605828285217,0.03025778755545616,0.030223939567804337,0.03483446687459946,0.028337828814983368,0.029179351404309273,0.022594356909394264,0.02811189740896225,0.02547663450241089,0.023724686354398727,0.02236691303551197,0.02226373739540577,0.021957919001579285,0.03294903412461281,0.03243725746870041,0.028784826397895813,0.026628807187080383,0.02495434693992138,0.021900281310081482,0.020627498626708984,0.025391273200511932,0.023122288286685944,0.021769627928733826,0.020816562697291374,0.020318107679486275,0.027468305081129074,0.031298063695430756,0.027424883097410202,0.025400517508387566,0.024143807590007782,0.023079635575413704,0.021753190085291862,0.020915338769555092,0.02738284133374691,0.026142818853259087,0.024297449737787247,0.022734643891453743,0.021927589550614357,0.02050665207207203,0.02009536325931549,0.02703411504626274,0.024185096845030785,0.02242129109799862,0.02123360149562359,0.020312635228037834,0.019494889304041862,0.018650725483894348,0.02271711826324463,0.022214507684111595,0.019406791776418686,0.01810278743505478,0.01814681477844715,0.017019962891936302,0.017346113920211792,0.018311364576220512,0.021665818989276886,0.02396993339061737,0.017625635489821434,0.022743215784430504,0.02121352031826973,0.020034942775964737,
mse,0.04955639690160751,0.011525975540280342,0.0032476570922881365,0.0013142392272129655,0.0016875636065378785,0.0009617188479751348,0.0005888348678126931,0.0004924319218844175,0.00044005794916301966,0.0006168321124278009,0.0004948613932356238,0.00076303631067276,0.0005249397363513708,0.0004277479602023959,0.0007069201092235744,0.000613885116763413,0.00043920017196796834,0.0003658870991785079,0.0003145595546811819,0.00025585555704310536,0.00042076819227077067,0.00041186180897057056,0.0002931863709818572,0.000249078671913594,0.0002266619703732431,0.00038556690560653806,0.000449605577159673,0.0004023090295959264,0.0003005373873747885,0.00024119917361531407,0.0002431628672638908,0.0003847700427286327,0.0002851093013305217,0.0002495274820830673,0.00022788794012740254,0.00021220662165433168,0.0001993426267290488,0.00018714574980549514,0.0001780041930032894,0.00017430601292289793,0.00026470882585272193,0.00026280159363523126,0.00032351803383789957,0.00022779518621973693,0.00024176454462576658,0.0001543349353596568,0.00021554058184847236,0.00017732854757923633,0.0001551025634398684,0.00014097524399403483,0.00014038920926395804,0.0001366511860396713,0.0003054229018744081,0.0002830766898114234,0.0002250107063446194,0.0001949397410498932,0.0001742183812893927,0.00014078458480071276,0.0001257636904483661,0.00017765355005394667,0.00014602046576328576,0.00013022164057474583,0.00012205966049805284,0.00011827508569695055,0.0002136983093805611,0.00026566439191810787,0.0002052708005066961,0.00017838140774983913,0.0001633237989153713,0.0001503940875409171,0.0001334947592113167,0.00012398287071846426,0.0002086615131702274,0.00018481745792087168,0.00016203278210014105,0.00014326800010167062,0.0001341868337476626,0.00012042068556183949,0.00011779861233662814,0.00019644241547212005,0.00016106000111903995,0.00014083707355894148,0.0001274353708140552,0.00011601176083786413,0.0001071744118235074,9.915070404531434e-05,0.00014539716357830912,0.00013778425636701286,0.00010452936112415045,9.293100447393954e-05,9.462476009503007e-05,8.445798448519781e-05,8.70720759849064e-05,9.697980567580089e-05,0.00013118165952619165,0.00016379181761294603,8.953174256021157e-05,0.00014130120689515024,0.00012318245717324317,0.0001114302795031108,
mae,0.1528264582157135,0.07643463462591171,0.04145719110965729,0.027484502643346786,0.03225697576999664,0.023881301283836365,0.01864493265748024,0.017437104135751724,0.01605062559247017,0.019386624917387962,0.017458628863096237,0.022358262911438942,0.01854030415415764,0.016622919589281082,0.021070711314678192,0.020224202424287796,0.017048902809619904,0.015024641528725624,0.014029516838490963,0.01259677018970251,0.015633128583431244,0.01623603142797947,0.014239140786230564,0.0133596146479249,0.012483278289437294,0.015883272513747215,0.017554715275764465,0.016388725489377975,0.014645936898887157,0.012623743154108524,0.012404138222336769,0.016587818041443825,0.013470670208334923,0.012462515383958817,0.011984982527792454,0.011660022661089897,0.011381699703633785,0.011146806180477142,0.010860861279070377,0.010722282342612743,0.012785025872290134,0.012383180670440197,0.014243942685425282,0.012155821546912193,0.012380238622426987,0.009702270850539207,0.011866932734847069,0.011113051325082779,0.010235636495053768,0.00954202376306057,0.009455972351133823,0.009264703840017319,0.014239735901355743,0.013972374610602856,0.012313536368310452,0.011486148461699486,0.011197400279343128,0.009537921287119389,0.008885970339179039,0.010833466425538063,0.01042970735579729,0.009755090810358524,0.009092134423553944,0.008711669594049454,0.011816396377980709,0.013882346451282501,0.011997450143098831,0.010961310006678104,0.010404982604086399,0.00983267743140459,0.009061324410140514,0.00892029982060194,0.011405332013964653,0.010703098960220814,0.010049923323094845,0.009596996009349823,0.009138352237641811,0.008622124791145325,0.008695709519088268,0.011307811364531517,0.010061334818601608,0.009173188358545303,0.008754175156354904,0.008721878752112389,0.008507583290338516,0.0081742312759161,0.009518047794699669,0.009221895597875118,0.008288612589240074,0.007634582929313183,0.0074937776662409306,0.0071149249561131,0.007244803477078676,0.007630689535290003,0.009199869818985462,0.00994910392910242,0.007508635986596346,0.009707855060696602,0.008793840184807777,0.008118567056953907,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8611      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8612      
=================================================================
Total params: 17,223
Trainable params: 17,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 8,612
Trainable params: 8,612
Non-trainable params: 0
_________________________________________________________________
