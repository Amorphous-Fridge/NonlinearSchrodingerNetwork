2021-06-26
loss,0.3641279637813568,0.12707339227199554,0.05016743019223213,0.03913583233952522,0.03407999128103256,0.03165579214692116,0.029399417340755463,0.02774893492460251,0.026233645156025887,0.025612762197852135,0.024604711681604385,0.023594224825501442,0.023184657096862793,0.02273626998066902,0.02198256552219391,0.02155989408493042,0.02089650370180607,0.020538371056318283,0.020350143313407898,0.019872121512889862,0.01934766210615635,0.019473372027277946,0.01902601309120655,0.01868615113198757,0.018470650538802147,0.018206512555480003,0.017965326085686684,0.017748473212122917,0.0175798162817955,0.01736762747168541,0.01718185283243656,0.0169856995344162,0.016773972660303116,0.016660895198583603,0.016659298911690712,0.016405897215008736,0.016265980899333954,0.016063297167420387,0.015986237674951553,0.01589537225663662,0.015879839658737183,0.01560108084231615,0.015545177273452282,0.015417513437569141,0.015331524424254894,0.015217069536447525,0.015167633071541786,0.01515723206102848,0.015001860447227955,0.014916982501745224,0.014862059615552425,0.014770811423659325,0.01463310606777668,0.014576287008821964,0.014472722075879574,0.01451127603650093,0.01437446940690279,0.014293964020907879,0.014233849011361599,0.014169313944876194,0.014095880091190338,0.014004291035234928,0.013980789110064507,0.013930588960647583,0.013730905950069427,0.013883276842534542,0.013711469247937202,0.013756351545453072,0.013892698101699352,0.013744775205850601,0.01366719976067543,0.0172161515802145,0.02170775830745697,0.021623868495225906,0.024129945784807205,0.022222302854061127,0.021001329645514488,0.020178455859422684,0.019399376586079597,0.018837863579392433,0.01811041124165058,0.017631830647587776,0.016965657472610474,0.014394291676580906,0.014098824001848698,0.013710038736462593,0.013444683514535427,0.01318211667239666,0.013173184357583523,0.012980894185602665,0.012858808040618896,0.012753520160913467,0.012595959939062595,0.012540305033326149,0.012437233701348305,0.012346139177680016,0.012259542010724545,0.012181082740426064,0.012350407429039478,0.012204071506857872,
mse,0.048585858196020126,0.006511568557471037,0.0008480414981022477,0.0005199564038775861,0.0003977648157160729,0.00033724645618349314,0.0002894835197366774,0.0002554068632889539,0.00022830649686511606,0.00021618632308673114,0.00019776649423874915,0.0001815411087591201,0.00017515644140075892,0.00016683590365573764,0.0001565256534377113,0.00014836585614830256,0.00013976685295347124,0.00013590921298600733,0.00013325702457223088,0.0001256305113201961,0.00012040600995533168,0.00011995917884632945,0.00011421903764130548,0.00011112278298242018,0.00010766505874926224,0.00010410646063974127,0.00010215969086857513,9.852429502643645e-05,9.632099681766704e-05,9.370615589432418e-05,9.101010800804943e-05,8.909454481909052e-05,8.680782048031688e-05,8.507302118232474e-05,8.518041431671008e-05,8.249456732301041e-05,8.18598346086219e-05,7.873991853557527e-05,7.731164805591106e-05,7.731420919299126e-05,7.712681690463796e-05,7.426555384881794e-05,7.305182953132316e-05,7.220114639494568e-05,7.312944217119366e-05,7.059233757900074e-05,6.987271626712754e-05,6.904806650709361e-05,6.766125443391502e-05,6.65987390675582e-05,6.726655556121841e-05,6.642424705205485e-05,6.435121758840978e-05,6.431120709748939e-05,6.31119473837316e-05,6.33734161965549e-05,6.180771015351638e-05,6.168227264424786e-05,6.084937558625825e-05,6.005461182212457e-05,5.906829028390348e-05,5.981115100439638e-05,5.863633123226464e-05,5.826265623909421e-05,5.7619101426098496e-05,5.7856133935274556e-05,5.637109643430449e-05,5.645269629894756e-05,6.062187094357796e-05,5.639196024276316e-05,5.5899876315379515e-05,9.496286656940356e-05,0.0001372042461298406,0.00013592799950856715,0.00015882537991274148,0.00013625144492834806,0.00012354158388916403,0.0001146311333286576,0.00010626026778481901,0.00010021781781688333,9.365832374896854e-05,8.874363993527368e-05,8.501421689288691e-05,6.268485594773665e-05,5.855757262906991e-05,5.584426617133431e-05,5.4416559578385204e-05,5.2775478252442554e-05,5.134292950970121e-05,5.067151505500078e-05,4.937816265737638e-05,4.87810029881075e-05,4.816169530386105e-05,4.662872743210755e-05,4.6304339775815606e-05,4.605967478710227e-05,4.5556804252555594e-05,4.529419675236568e-05,4.506425830186345e-05,4.4372613047016785e-05,
mae,0.1542450487613678,0.05426091328263283,0.021273961290717125,0.01653425395488739,0.014456256292760372,0.013423584401607513,0.012483681552112103,0.011799033731222153,0.0111845126375556,0.010877962224185467,0.010523532517254353,0.010066444054245949,0.009913257323205471,0.009700682014226913,0.009387516416609287,0.009127210825681686,0.008875236846506596,0.00873550958931446,0.008713838644325733,0.008461257442831993,0.008252057246863842,0.008289715275168419,0.008098137564957142,0.007998340763151646,0.007868587039411068,0.007703993935137987,0.007616785820573568,0.007568804081529379,0.007438106462359428,0.007399607915431261,0.007294969633221626,0.007199576124548912,0.007126698270440102,0.007001255173236132,0.007070325780659914,0.006962769664824009,0.006872185505926609,0.006855257786810398,0.006815414875745773,0.006714322604238987,0.006755879148840904,0.006664016284048557,0.00660315528512001,0.006573406979441643,0.006520386319607496,0.006438838317990303,0.006418453995138407,0.00637072091922164,0.006377506069839001,0.006282267160713673,0.006300585810095072,0.006276723928749561,0.006186823360621929,0.006162071600556374,0.006164440885186195,0.006153156980872154,0.006128336768597364,0.006111298222094774,0.005969882011413574,0.0060096909292042255,0.00597626157104969,0.006027159281075001,0.0058398498222231865,0.0058687906712293625,0.005865755490958691,0.005800508428364992,0.005843262188136578,0.0058710272423923016,0.00588046433404088,0.005890571046620607,0.005738354288041592,0.00735075818374753,0.00916799996048212,0.009153246879577637,0.010032374411821365,0.009038824588060379,0.008465404622256756,0.008204045705497265,0.00810662005096674,0.007999176159501076,0.0077170575968921185,0.007502071093767881,0.007248721085488796,0.006018228363245726,0.005873134825378656,0.005747356917709112,0.005625458899885416,0.005492126569151878,0.005510625895112753,0.0053957863710820675,0.005338093265891075,0.00529329851269722,0.0052907224744558334,0.0052474867552518845,0.005227035842835903,0.005222582723945379,0.0051613966934382915,0.005173337645828724,0.00511818565428257,0.005054977722465992,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5419      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5420      
=================================================================
Total params: 10,839
Trainable params: 10,839
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 5,419
Trainable params: 5,419
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 5,420
Trainable params: 5,420
Non-trainable params: 0
_________________________________________________________________
