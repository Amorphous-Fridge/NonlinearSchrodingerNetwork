2021-06-26
loss,0.32004204392433167,0.13701730966567993,0.06610773503780365,0.04807903617620468,0.04262809455394745,0.03963557258248329,0.0365823358297348,0.03542276471853256,0.03272606059908867,0.031047657132148743,0.030096936970949173,0.029171200469136238,0.028492456302046776,0.027972839772701263,0.026971526443958282,0.026435095816850662,0.02657320722937584,0.025734975934028625,0.02529744803905487,0.024799644947052002,0.024551009759306908,0.0239542406052351,0.02370835840702057,0.023460624739527702,0.023221278563141823,0.022885236889123917,0.022738542407751083,0.022261979058384895,0.02231995016336441,0.021931692957878113,0.021505022421479225,0.021624071523547173,0.021220801398158073,0.021120524033904076,0.02092163637280464,0.020684294402599335,0.020472757518291473,0.020326055586338043,0.02026299200952053,0.019972680136561394,0.02462155558168888,0.03369264304637909,0.03496823087334633,0.03589821234345436,0.03389115259051323,0.031169559806585312,0.02716410718858242,0.024389762431383133,0.022508027032017708,0.02186470292508602,0.022546803578734398,0.03491509333252907,0.031049225479364395,0.028995078057050705,0.027523953467607498,0.02581147477030754,0.026809317991137505,0.030712205916643143,0.03531791269779205,0.03248637914657593,0.027369627729058266,0.025676868855953217,0.02480762079358101,0.024075999855995178,0.023606181144714355,0.021158309653401375,0.019637752324342728,0.023115692660212517,0.032987575978040695,0.030391206964850426,0.02818416804075241,0.024542944505810738,0.022869694977998734,0.021133143454790115,0.01984063722193241,0.018765944987535477,0.018368327990174294,0.017848288640379906,0.017371775582432747,0.017789166420698166,0.017411701381206512,0.01678478717803955,0.020456133410334587,0.026908831670880318,0.025299815461039543,0.024022212252020836,0.02319725789129734,0.022417740896344185,0.021730193868279457,0.020753368735313416,0.023994553834199905,0.03171764314174652,0.02904602140188217,0.027593141421675682,0.026517121121287346,0.025182392448186874,0.022534828633069992,0.02150367759168148,0.02082732692360878,0.020341387018561363,
mse,0.03901100903749466,0.006841782480478287,0.0014191621448844671,0.0007508088019676507,0.000584365101531148,0.0005061535048298538,0.0004316363192629069,0.0003898107388522476,0.00032873600139282644,0.00029852965963073075,0.00027667221729643643,0.00025802687741816044,0.0002439245581626892,0.00023433704336639494,0.00022035861911717802,0.0002087468164972961,0.00020937783119734377,0.00019654736388474703,0.00018858736439142376,0.0001818523305701092,0.0001798887678887695,0.00016888816026039422,0.0001656635431572795,0.00016010399849619716,0.00015738718502689153,0.00015422933211084455,0.00015183855430223048,0.00014602324517909437,0.00014507357263937593,0.0001397818559780717,0.00013500696513801813,0.00013616419164463878,0.00013050867710262537,0.0001312249805778265,0.00012714242620859295,0.00012406287714838982,0.00012197509204270318,0.00012120673636673018,0.0001183464628411457,0.00011791482393164188,0.0001918697962537408,0.00032085709972307086,0.0003452817618381232,0.00037253519985824823,0.00033231981797143817,0.00028882978949695826,0.0002140990982297808,0.0001736019621603191,0.00014961769920773804,0.00013967067934572697,0.0001560358505230397,0.00035788945388048887,0.0002814204781316221,0.0002502147981431335,0.00023094705829862505,0.00019841277389787138,0.0002129136264557019,0.0002867829753085971,0.00035134173231199384,0.00029981505940668285,0.00022107861877884716,0.00019744430028367788,0.0001852246787166223,0.00017590408970136195,0.00016674227663315833,0.00013527624832931906,0.00011380602518329397,0.0001676163519732654,0.00030975742265582085,0.0002627684152685106,0.00022534724848810583,0.00018114663544110954,0.0001546739076729864,0.00013271077477838844,0.00011705650831572711,0.00010428574023535475,9.848652553046122e-05,9.338794916402549e-05,9.048673382494599e-05,9.215394675265998e-05,8.796717884251848e-05,8.520157280145213e-05,0.00012778842938132584,0.00020976216183044016,0.0001903377124108374,0.00017131739878095686,0.0001602795673534274,0.00014967766765039414,0.00014084423310123384,0.00012521515600383282,0.00017759397451300174,0.00028335480601526797,0.00024080350704025477,0.00021909787028562278,0.0001981327513931319,0.0001799287274479866,0.00014935273793525994,0.00014024385018274188,0.0001313201355515048,0.00012643080845009536,
mae,0.13186916708946228,0.0556471161544323,0.028067460283637047,0.020430732518434525,0.018052585422992706,0.0168173685669899,0.015321653336286545,0.015172886662185192,0.014009672217071056,0.013357765972614288,0.012787963263690472,0.01253336202353239,0.012048006057739258,0.011878004297614098,0.0114054623991251,0.011259065940976143,0.011200533248484135,0.011041556484997272,0.010675634257495403,0.01051189936697483,0.010633575730025768,0.01037162821739912,0.010021520778536797,0.010091598145663738,0.010121447034180164,0.009936354123055935,0.009451385587453842,0.009477376937866211,0.009713157080113888,0.009299838915467262,0.008970645256340504,0.009309419430792332,0.00903992261737585,0.009046670980751514,0.009095556102693081,0.008762567304074764,0.008724835701286793,0.008553645573556423,0.00870175939053297,0.008529516868293285,0.010243657976388931,0.014199402183294296,0.015202700160443783,0.016637979075312614,0.01554117538034916,0.01326203066855669,0.010591454803943634,0.009701268747448921,0.00925795454531908,0.008850568905472755,0.009446319192647934,0.014423353597521782,0.012439575046300888,0.01166598405689001,0.01144866831600666,0.01077297329902649,0.011184921488165855,0.01301285345107317,0.01495314110070467,0.013712655752897263,0.01183371152728796,0.010965812020003796,0.010531682521104813,0.010189145803451538,0.009997809305787086,0.008995618671178818,0.008255661465227604,0.009655020199716091,0.014600818045437336,0.013401567935943604,0.012564510107040405,0.009838143363595009,0.00885262805968523,0.008309146389365196,0.007906673476099968,0.0078008160926401615,0.007749462500214577,0.007536496501415968,0.0074188183061778545,0.007597495336085558,0.007454496808350086,0.007150406949222088,0.008859322406351566,0.011774932034313679,0.011140398681163788,0.010510815307497978,0.010125870816409588,0.009764446876943111,0.009328568354249,0.008729550987482071,0.010481592267751694,0.01457933522760868,0.013385362923145294,0.012705772183835506,0.012286674231290817,0.011333105154335499,0.010033330880105495,0.009682297706604004,0.0093635069206357,0.009169950149953365,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6483      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6484      
=================================================================
Total params: 12,967
Trainable params: 12,967
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 6,483
Trainable params: 6,483
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 6,484
Trainable params: 6,484
Non-trainable params: 0
_________________________________________________________________
