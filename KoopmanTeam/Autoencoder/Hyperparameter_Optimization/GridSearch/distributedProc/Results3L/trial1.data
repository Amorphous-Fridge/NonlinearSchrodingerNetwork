2021-06-26
loss,0.6598750352859497,0.2842998206615448,0.20116151869297028,0.12240771949291229,0.07280902564525604,0.06040491908788681,0.05295545235276222,0.04677778109908104,0.0422169454395771,0.0390297994017601,0.03663675859570503,0.03470151498913765,0.0331055149435997,0.03182688355445862,0.03078627400100231,0.02966291457414627,0.02871728129684925,0.027959361672401428,0.027308786287903786,0.026685407385230064,0.02583627961575985,0.025361016392707825,0.024722134694457054,0.02436463162302971,0.023834967985749245,0.023339638486504555,0.023026153445243835,0.02250184305012226,0.022149469703435898,0.021855304017663002,0.021542446687817574,0.02144390530884266,0.021050037816166878,0.020801084116101265,0.020456384867429733,0.020307037979364395,0.01989271119236946,0.019823042675852776,0.019544415175914764,0.019393833354115486,0.019225619733333588,0.019180631265044212,0.018894901499152184,0.018434515222907066,0.018833912909030914,0.018382348120212555,0.018267527222633362,0.01809372752904892,0.01784874126315117,0.01786637119948864,0.01793533004820347,0.01766206882894039,0.017477842047810555,0.01737920008599758,0.01718687079846859,0.017076902091503143,0.017140934243798256,0.016905969008803368,0.016836604103446007,0.016784844920039177,0.01655976101756096,0.016618195921182632,0.0163938757032156,0.016381101682782173,0.01610623113811016,0.016215777024626732,0.01615706831216812,0.015778478235006332,0.01594809629023075,0.01570630446076393,0.015800483524799347,0.015689916908740997,0.015607442706823349,0.015547361224889755,0.015391349792480469,0.015384967438876629,0.015136233530938625,0.015248065814375877,0.015112334862351418,0.014905397780239582,0.015063983388245106,0.014989962801337242,0.014760506339371204,0.014800271950662136,0.014687377959489822,0.014612490311264992,0.014584695920348167,0.014492359012365341,0.014329008758068085,0.014331073500216007,0.014263694174587727,0.014368155039846897,0.014101679436862469,0.014152836985886097,0.01399189606308937,0.014011628925800323,0.013935135677456856,0.013884433545172215,0.01378113403916359,0.013894417323172092,
mse,0.17329414188861847,0.025314899161458015,0.013829036615788937,0.00536075234413147,0.0019007183145731688,0.0013024047948420048,0.0010033193975687027,0.0007848458481021225,0.0006361053674481809,0.0005416942294687033,0.0004768938815686852,0.0004261126450728625,0.00038768447120673954,0.0003570928529370576,0.0003293118206784129,0.00030511393561027944,0.00028531215502880514,0.00026820757193490863,0.00025351569638587534,0.00024078534625004977,0.00022512509895022959,0.00021580509201157838,0.00020504341227933764,0.00019726649043150246,0.00018852522771339864,0.0001798424927983433,0.0001760193845257163,0.0001666956814005971,0.000161872390890494,0.00015721953241154552,0.00015210028504952788,0.00014992659271229059,0.00014506361912935972,0.00014102377463132143,0.0001363026531180367,0.000134086178150028,0.00012946518836542964,0.0001285570178879425,0.00012398732360452414,0.00012251254520379007,0.00012021927250316367,0.00011893049668287858,0.00011572747462196276,0.0001108047945308499,0.00011353447189321741,0.0001090566220227629,0.00010779686999740079,0.00010520491923671216,0.00010326660412829369,0.00010275502427248284,0.00010262190335197374,9.989712270908058e-05,9.744491399032995e-05,9.701547242002562e-05,9.469432552577928e-05,9.376199886901304e-05,9.312809561379254e-05,9.15781783987768e-05,9.017247793963179e-05,8.967205212684348e-05,8.7300046288874e-05,8.789588900981471e-05,8.504116703988984e-05,8.572415390517563e-05,8.236633584601805e-05,8.350390999112278e-05,8.228190563386306e-05,7.949375867610797e-05,8.046597940847278e-05,7.81638955231756e-05,7.877701864344999e-05,7.789684605086222e-05,7.695573731325567e-05,7.606580038554966e-05,7.487323455279693e-05,7.448688120348379e-05,7.23840348655358e-05,7.307826308533549e-05,7.182455010479316e-05,7.022549107205123e-05,7.146356074372306e-05,7.067904516588897e-05,6.876054249005392e-05,6.89150983816944e-05,6.792542262701318e-05,6.739579839631915e-05,6.684843538096175e-05,6.59679135424085e-05,6.45585751044564e-05,6.489691440947354e-05,6.414714152924716e-05,6.487182690761983e-05,6.277073407545686e-05,6.298188236542046e-05,6.167185347294435e-05,6.183202640386298e-05,6.110249523771927e-05,6.071762982173823e-05,6.010313154547475e-05,6.054769619368017e-05,
mae,0.27068039774894714,0.1243574395775795,0.09075047820806503,0.05298943072557449,0.030904890969395638,0.02573501132428646,0.022549612447619438,0.019858114421367645,0.017911862581968307,0.016555827111005783,0.015547871589660645,0.014716554433107376,0.014035684987902641,0.013486815616488457,0.013054133392870426,0.012582276947796345,0.012182031758129597,0.011854887008666992,0.011577066034078598,0.01132917683571577,0.010967990383505821,0.010770349763333797,0.01051186304539442,0.01036010030657053,0.01013270765542984,0.00992244016379118,0.009793465957045555,0.009568880312144756,0.00943061150610447,0.00931521039456129,0.0091774333268404,0.009129590354859829,0.008958770893514156,0.008863215334713459,0.008714720606803894,0.008640826679766178,0.00846448726952076,0.008439980447292328,0.008316504769027233,0.008255246095359325,0.00817512720823288,0.008149302564561367,0.008040112443268299,0.007841004058718681,0.007982076145708561,0.00781282689422369,0.007745983544737101,0.007670244202017784,0.0075929854065179825,0.007581640966236591,0.007598113268613815,0.007483631372451782,0.007404538337141275,0.007367647252976894,0.0072916108183562756,0.007233955431729555,0.007254263386130333,0.007156510837376118,0.007132743019610643,0.00711154704913497,0.0070053464733064175,0.007032002788037062,0.006938946433365345,0.006943747401237488,0.0068251341581344604,0.0068632434122264385,0.006834670435637236,0.006672407500445843,0.006749185733497143,0.006659059319645166,0.006687304470688105,0.006641039624810219,0.006613550242036581,0.006583433598279953,0.006524440832436085,0.006521488539874554,0.006408520974218845,0.006466553080826998,0.0064006675966084,0.006317957770079374,0.0063779233023524284,0.0063384766690433025,0.006255475338548422,0.006281205918639898,0.0062270998023450375,0.006192145403474569,0.006181268021464348,0.006137269549071789,0.006074133329093456,0.006074266973882914,0.006053479854017496,0.006090572103857994,0.005980880465358496,0.006002924405038357,0.005932056810706854,0.005940863862633705,0.005917019210755825,0.005880964919924736,0.0058572422713041306,0.005891850683838129,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 619       
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 620       
=================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 619
Trainable params: 619
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 620
Trainable params: 620
Non-trainable params: 0
_________________________________________________________________
