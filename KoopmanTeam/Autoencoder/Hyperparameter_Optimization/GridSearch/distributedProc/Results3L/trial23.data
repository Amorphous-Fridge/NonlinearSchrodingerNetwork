2021-06-26
loss,0.357627272605896,0.22618761658668518,0.2198878824710846,0.1635662019252777,0.0842943787574768,0.06009555235505104,0.05165162682533264,0.04454249516129494,0.04046566039323807,0.03786678984761238,0.03562634065747261,0.0345006138086319,0.03273160383105278,0.03137870132923126,0.03039591573178768,0.029388047754764557,0.028570914641022682,0.028403978794813156,0.0275102686136961,0.026471147313714027,0.026265347376465797,0.02558605931699276,0.025047430768609047,0.024563858285546303,0.02414906769990921,0.023852240294218063,0.023280924186110497,0.023005880415439606,0.02266079932451248,0.022251691669225693,0.022145288065075874,0.02182425558567047,0.021427461877465248,0.02123979851603508,0.02104751020669937,0.020878951996564865,0.02049645408987999,0.02024146355688572,0.02013992704451084,0.01988079398870468,0.01959586702287197,0.01949038915336132,0.019446969032287598,0.019243426620960236,0.01914313994348049,0.01881212182343006,0.01878671906888485,0.0186875369399786,0.01851966790854931,0.02863413654267788,0.029242470860481262,0.029819486662745476,0.028187546879053116,0.026602130383253098,0.02577579766511917,0.02476300299167633,0.024144170805811882,0.023341290652751923,0.022804072126746178,0.021776530891656876,0.021894684061408043,0.03428744152188301,0.03034200519323349,0.02771749347448349,0.026022274047136307,0.024871060624718666,0.02410082146525383,0.024160120636224747,0.03656991943717003,0.031782299280166626,0.029687214642763138,0.028170060366392136,0.02706132084131241,0.02617439441382885,0.02534397877752781,0.02480044588446617,0.024123387411236763,0.02369268238544464,0.02311723306775093,0.02250421606004238,0.021093711256980896,0.01886371336877346,0.018464256078004837,0.017350906506180763,0.0167067963629961,0.016378913074731827,0.021675800904631615,0.021555177867412567,0.02195627987384796,0.02088124118745327,0.02000919170677662,0.019247306510806084,0.02451574243605137,0.02714795060455799,0.02471574954688549,0.023229198530316353,0.022571565583348274,0.021702280268073082,0.018860917538404465,0.02703220397233963,
mse,0.05560814216732979,0.018360506743192673,0.017622990533709526,0.00983535498380661,0.0023077023215591908,0.0011859849328175187,0.0008735940791666508,0.0006526586366817355,0.0005327148828655481,0.00045463812421076,0.00039352785097435117,0.00036219015601091087,0.0003246467967983335,0.000294806610327214,0.00027639567269943655,0.00025635931524448097,0.0002409235166851431,0.0002371992595726624,0.00022177881328389049,0.0002044749999186024,0.000200195427169092,0.0001900025235954672,0.0001816740696085617,0.0001741152082104236,0.00016777405107859522,0.00016386673087254167,0.00015539777814410627,0.00015252047160174698,0.000147844577440992,0.00014221380115486681,0.00014033203478902578,0.00013581462553702295,0.00013017028686590493,0.0001283763413084671,0.00012605771189555526,0.000123991456348449,0.00011943160643568262,0.00011652831017272547,0.00011518181418068707,0.00011239820014452562,0.00011094397632405162,0.00010820776515174657,0.0001066447512130253,0.00010492165893083438,0.0001041338691720739,0.00010033431317424402,0.00010001565533457324,9.900780423777178e-05,9.737629443407059e-05,0.0002480654511600733,0.0002600614388938993,0.0002486558514647186,0.0002209825615864247,0.0001982854155357927,0.00018715791520662606,0.00017159619892481714,0.00016270465857814997,0.0001517042110208422,0.0001441257627448067,0.000131033782963641,0.00013915116142015904,0.0003278250223957002,0.0002506134333088994,0.0002098349796142429,0.000185955737833865,0.00017064089479390532,0.00016205906285904348,0.00017288180242758244,0.0003668536664918065,0.00027552031679078937,0.00024315401969943196,0.00022134921164251864,0.00020368015975691378,0.00019084183441009372,0.00018141909094993025,0.00017243485490325838,0.00016412949480582029,0.00015843793516978621,0.0001511605951236561,0.00014483151608146727,0.00012907377094961703,0.00010459676559548825,9.908946958603337e-05,8.901069668354467e-05,8.225364581448957e-05,7.986572745721787e-05,0.00013926083920523524,0.00013441989722196013,0.00013368244981393218,0.00012189069821033627,0.00011315905430819839,0.00010536947229411453,0.00017439758812543005,0.0002026245347224176,0.00016754768148530275,0.00015020734281279147,0.0001426574308425188,0.00013352028327062726,0.00010596094944048673,0.00020445609698072076,
mae,0.15292280912399292,0.09616967290639877,0.09718815982341766,0.07038283348083496,0.03639114275574684,0.02591109275817871,0.022207636386156082,0.019117480143904686,0.01728937216103077,0.016148032620549202,0.015190888196229935,0.014704964123666286,0.0139288529753685,0.013385516591370106,0.01308530569076538,0.012504791840910912,0.012221102602779865,0.01214207336306572,0.011764084920287132,0.011303854174911976,0.011190688237547874,0.010945875197649002,0.010680382139980793,0.010445321910083294,0.010367481969296932,0.010303990915417671,0.00985424593091011,0.009785083122551441,0.009678664617240429,0.009560922160744667,0.00947700534015894,0.009319465607404709,0.009253730066120625,0.009092641994357109,0.008938247337937355,0.008908318355679512,0.008836743421852589,0.008616684004664421,0.00867002084851265,0.008396115154027939,0.008430969901382923,0.00833374634385109,0.008295363746583462,0.008138670586049557,0.008155989460647106,0.007937767542898655,0.008002500981092453,0.008073147386312485,0.007974070496857166,0.012149650603532791,0.012114123441278934,0.01229421142488718,0.011713982559740543,0.01116657629609108,0.010892612859606743,0.010520845651626587,0.010316201485693455,0.010024663992226124,0.009822072461247444,0.009240847080945969,0.009242286905646324,0.01487010344862938,0.013318001292645931,0.012254377827048302,0.011564582586288452,0.011156477965414524,0.010551911778748035,0.010250109247863293,0.01684720814228058,0.014728226698935032,0.013641148805618286,0.01288004033267498,0.012304136529564857,0.011898824945092201,0.01146037969738245,0.011212540790438652,0.01080707460641861,0.010460213758051395,0.009946976788341999,0.009437955915927887,0.008725014515221119,0.008175941184163094,0.008146706037223339,0.007755139842629433,0.007330785505473614,0.007142266724258661,0.009277119301259518,0.009151807054877281,0.00952929351478815,0.009061467833817005,0.008676078170537949,0.00840230006724596,0.010506656020879745,0.012123141437768936,0.011221246793866158,0.010541182942688465,0.010249270126223564,0.009830432943999767,0.008114710450172424,0.011902309954166412,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6499      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6500      
=================================================================
Total params: 12,999
Trainable params: 12,999
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 6,499
Trainable params: 6,499
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 6,500
Trainable params: 6,500
Non-trainable params: 0
_________________________________________________________________
