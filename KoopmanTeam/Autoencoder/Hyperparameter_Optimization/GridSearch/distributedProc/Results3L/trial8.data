2021-06-26
loss,0.3442479968070984,0.1976795196533203,0.08575937151908875,0.06214507669210434,0.05085202306509018,0.04576313868165016,0.041126932948827744,0.03795735538005829,0.034966886043548584,0.032712969928979874,0.03107648901641369,0.029994655400514603,0.02917724847793579,0.028374772518873215,0.027611827477812767,0.027032820507884026,0.02639058791100979,0.025842878967523575,0.025316007435321808,0.02484787255525589,0.02452024258673191,0.023920938372612,0.023700708523392677,0.023180192336440086,0.022824622690677643,0.022492244839668274,0.022270498797297478,0.02199184149503708,0.021695245057344437,0.02144584245979786,0.021253278478980064,0.020913563668727875,0.020662665367126465,0.020617356523871422,0.020263435319066048,0.02026149071753025,0.019982071593403816,0.019677886739373207,0.019620802253484726,0.019454937428236008,0.019252441823482513,0.019040055572986603,0.0188967976719141,0.018828649073839188,0.01860140822827816,0.01852620579302311,0.018301796168088913,0.018212314695119858,0.01767623797059059,0.018187204375863075,0.01796642690896988,0.01769588142633438,0.017604535445570946,0.017465973272919655,0.017327560111880302,0.01727977953851223,0.01715567335486412,0.017114950343966484,0.016991958022117615,0.016833828762173653,0.01684712804853916,0.01665380224585533,0.016673339530825615,0.01656506024301052,0.016474997624754906,0.01635619066655636,0.016294069588184357,0.016198713332414627,0.01604529283940792,0.016081692650914192,0.0159782525151968,0.01589719019830227,0.015742458403110504,0.01573294587433338,0.0157066248357296,0.015601033344864845,0.01558268815279007,0.015435749664902687,0.015396097674965858,0.01531527191400528,0.015301045030355453,0.015208513475954533,0.01509789191186428,0.015233478508889675,0.014930733479559422,0.015114327892661095,0.015008091926574707,0.014802942052483559,0.014888579957187176,0.014734766446053982,0.014893963001668453,0.014694218523800373,0.014713925309479237,0.014641138724982738,0.01454210001975298,0.014504408463835716,0.01448467094451189,0.014490503817796707,0.014438970014452934,0.014074867591261864,
mse,0.04322578385472298,0.014345891773700714,0.002615321194753051,0.0013580677332356572,0.0009568387758918107,0.0007768606883473694,0.0006361380801536143,0.0005443540285341442,0.00045390130253508687,0.0003958705347031355,0.0003508025547489524,0.00032108387676998973,0.00029909113072790205,0.00028311190544627607,0.00026427782722748816,0.0002502304851077497,0.00023741021868772805,0.00022602906392421573,0.00021500910224858671,0.00020772383140865713,0.00020033519831486046,0.00018982274923473597,0.0001848077226895839,0.0001756669080350548,0.000169957842445001,0.0001652654609642923,0.0001598452072357759,0.00015705925761722028,0.0001518037897767499,0.00014763652870897204,0.0001445333764422685,0.00013960915384814143,0.00013645536091644317,0.00013458677858579904,0.00013040759949944913,0.0001297613634960726,0.00012633667211048305,0.00012187463289592415,0.00012084814079571515,0.00011845991684822366,0.0001158446611952968,0.00011360695498296991,0.00011139993875985965,0.00011069158790633082,0.00010787971405079588,0.00010684950393624604,0.00010345134069211781,0.00010321338049834594,9.762784611666575e-05,0.00010197055235039443,9.958542796084657e-05,9.61701080086641e-05,9.50372705119662e-05,9.385117300553247e-05,9.196628525387496e-05,9.162149217445403e-05,8.989467460196465e-05,8.974184311227873e-05,8.810056169750169e-05,8.645413618069142e-05,8.626469207229093e-05,8.437689393758774e-05,8.44555688672699e-05,8.339222404174507e-05,8.246416837209836e-05,8.114963566185907e-05,8.057193190325052e-05,7.976644701557234e-05,7.816951983841136e-05,7.824657222954556e-05,7.705302414251491e-05,7.611661567352712e-05,7.47358426451683e-05,7.47771337046288e-05,7.396377623081207e-05,7.332742097787559e-05,7.330623338930309e-05,7.157523941714317e-05,7.132560131140053e-05,7.015911978669465e-05,7.020474004093558e-05,6.920866871951148e-05,6.822202703915536e-05,6.95300695952028e-05,6.67450440232642e-05,6.841043796157464e-05,6.71034213155508e-05,6.51617519906722e-05,6.586134259123355e-05,6.47630076855421e-05,6.588846736121923e-05,6.432476948248222e-05,6.456243863794953e-05,6.378105899784714e-05,6.302177644101903e-05,6.237508205231279e-05,6.250562728382647e-05,6.232264422578737e-05,6.190668500494212e-05,5.859504744876176e-05,
mae,0.14642493426799774,0.08502940088510513,0.03683047369122505,0.02661483734846115,0.021772177889943123,0.019617857411503792,0.017618326470255852,0.016242705285549164,0.014924564398825169,0.013939660042524338,0.013220076449215412,0.012756177224218845,0.012405277229845524,0.012059603817760944,0.011739238165318966,0.011492470279335976,0.011210278607904911,0.010987929999828339,0.010767425410449505,0.010570546612143517,0.010407148860394955,0.010180666111409664,0.01008490938693285,0.009879473596811295,0.009704272262752056,0.009572339244186878,0.009519962593913078,0.009364147670567036,0.009241831488907337,0.00913560763001442,0.009067400358617306,0.00892283208668232,0.008775641210377216,0.008800644427537918,0.008628904819488525,0.008630706928670406,0.00851486250758171,0.00840219296514988,0.008372807875275612,0.008323161862790585,0.00821178313344717,0.008150774985551834,0.008053310215473175,0.008074642159044743,0.007926039397716522,0.007914961315691471,0.007822724990546703,0.007806462701410055,0.007476137951016426,0.00779210589826107,0.00768831605091691,0.007554295007139444,0.00755704939365387,0.0074142348021268845,0.007410033140331507,0.007427073083817959,0.007385752629488707,0.007314336486160755,0.007296154275536537,0.0071915858425199986,0.007159177679568529,0.007079582195729017,0.007132888305932283,0.007050672546029091,0.007031964138150215,0.0070146191865205765,0.006951864343136549,0.006934927776455879,0.006840656511485577,0.006870537530630827,0.0067980969324707985,0.006809467449784279,0.006752619054168463,0.006689306348562241,0.006697805132716894,0.006700971629470587,0.0066634840331971645,0.00663484912365675,0.006586045492440462,0.006556311622262001,0.006505927070975304,0.006495771463960409,0.006442003883421421,0.006422562524676323,0.006352351978421211,0.0064081717282533646,0.006423709448426962,0.006365886889398098,0.006345191039144993,0.006231494713574648,0.006357572041451931,0.006286492571234703,0.006286175921559334,0.006221321877092123,0.006151499226689339,0.0061865877360105515,0.006185369100421667,0.006224513053894043,0.006096527446061373,0.0059473467990756035,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1715      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1716      
=================================================================
Total params: 3,431
Trainable params: 3,431
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 1,715
Trainable params: 1,715
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 1,716
Trainable params: 1,716
Non-trainable params: 0
_________________________________________________________________
