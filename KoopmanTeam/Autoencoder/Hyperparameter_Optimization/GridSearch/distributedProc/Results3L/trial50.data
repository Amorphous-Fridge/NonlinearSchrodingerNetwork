2021-06-26
loss,0.37985607981681824,0.15941457450389862,0.07583566755056381,0.06301566958427429,0.06561397761106491,0.05856037512421608,0.058345746248960495,0.05009764805436134,0.05236400291323662,0.04003942385315895,0.028703635558485985,0.032097503542900085,0.0443737730383873,0.029685785993933678,0.030181482434272766,0.03264202922582626,0.03904828056693077,0.040256068110466,0.031412672251462936,0.031768444925546646,0.03407203406095505,0.03830879554152489,0.030534666031599045,0.02952061966061592,0.03407982364296913,0.029967650771141052,0.024142052978277206,0.022718455642461777,0.02928389608860016,0.03189278766512871,0.032942354679107666,0.028937725350260735,0.02235679142177105,0.01920817792415619,0.028266116976737976,0.029773198068141937,0.02690293826162815,0.027969488874077797,0.026377754285931587,0.028731130063533783,0.02533538267016411,0.02476627565920353,0.022287489846348763,0.024480506777763367,0.02739051543176174,0.02399187721312046,0.022510237991809845,0.023229414597153664,0.025792891159653664,0.025934480130672455,0.023249495774507523,0.01964080147445202,0.017331378534436226,0.017717815935611725,0.018839020282030106,0.026901327073574066,0.023221878334879875,0.021908821538090706,0.025003110989928246,0.021042000502347946,0.02020157314836979,0.021138057112693787,0.01905582845211029,0.02139049582183361,0.023074287921190262,0.02220623753964901,0.020708389580249786,0.018324369564652443,0.015049303881824017,0.01663343608379364,0.019587475806474686,0.0189130287617445,0.018992874771356583,0.015357401221990585,0.017388345673680305,0.019277401268482208,0.02195482887327671,0.02245633862912655,0.01911291293799877,0.017997823655605316,0.0182277113199234,0.01781744696199894,0.01890563778579235,0.020027821883559227,0.014989938586950302,0.013738494366407394,0.01640566997230053,0.018701935186982155,0.020970776677131653,0.019340043887495995,0.018081042915582657,0.017102085053920746,0.015958860516548157,0.014862943440675735,0.013545982539653778,0.018396548926830292,0.01958712376654148,0.01734367199242115,0.016163848340511322,0.01584012247622013,
mse,0.05266459286212921,0.009311600588262081,0.0017102848505601287,0.0011880260426551104,0.0012874132953584194,0.0009913588874042034,0.000989060732536018,0.0007230578921735287,0.0007764410693198442,0.0004725861072074622,0.0002485369041096419,0.0003095704014413059,0.000592774769756943,0.00026504453853704035,0.00027407347806729376,0.00030893084476701915,0.0004413848801050335,0.00048616950516588986,0.00030349145526997745,0.00030290373251773417,0.00033356319181621075,0.0004298862477298826,0.0002709791006054729,0.0002543180016800761,0.0003358371614012867,0.0002590354415588081,0.0001736579870339483,0.00015192976570688188,0.00024387321900576353,0.0002950687485281378,0.0003064307675231248,0.0002489208709448576,0.000149699451867491,0.00011349974374752492,0.00023443791724275798,0.00025239671231247485,0.0002093084476655349,0.00021936878329142928,0.00020453482284210622,0.00023887664428912103,0.00018595585424918681,0.00017421398661099374,0.0001449592673452571,0.0001721834414638579,0.00021588329400401562,0.00016604532720521092,0.00014922521950211376,0.0001534256007289514,0.00019285122107248753,0.00018956599524244666,0.0001555709750391543,0.00011654384434223175,9.055434929905459e-05,9.21954051591456e-05,0.00010551325249252841,0.0002046322770183906,0.0001516339834779501,0.0001357390865450725,0.00017618811398278922,0.000128528248751536,0.00011780372733483091,0.0001271096698474139,0.00010515114263398573,0.00013229997421149164,0.0001476689358241856,0.00013952744484413415,0.00012266797421034425,9.889530338114128e-05,6.84608457959257e-05,8.408648864133283e-05,0.0001118011714424938,0.00010064776870422065,0.00010623954585753381,7.212880154838786e-05,8.918783714761958e-05,0.00010554426989983767,0.0001350172533420846,0.00014472779002971947,0.00010399080929346383,9.121445327764377e-05,9.513695113128051e-05,9.006367326946929e-05,0.00010297223343513906,0.00011279859609203413,7.030207780189812e-05,5.947981480858289e-05,8.163118036463857e-05,9.7385942353867e-05,0.0001242932048626244,0.00010474491864442825,9.255536861019209e-05,8.192379027605057e-05,7.20477182767354e-05,6.448623025789857e-05,5.6312463129870594e-05,9.721095557324588e-05,0.00011031901522073895,8.517699461663142e-05,7.519750215578824e-05,7.312129309866577e-05,
mae,0.16081756353378296,0.0685659870505333,0.032286301255226135,0.026994116604328156,0.027682773768901825,0.024901194497942924,0.024853715673089027,0.02113392762839794,0.022372238337993622,0.016926059499382973,0.012277130968868732,0.013563821092247963,0.018783580511808395,0.012590533122420311,0.01278987992554903,0.013843020424246788,0.016633104532957077,0.017231369391083717,0.013444848358631134,0.013602502644062042,0.014463093131780624,0.016392149031162262,0.012888354249298573,0.012365026399493217,0.014576427638530731,0.012801512144505978,0.010313120670616627,0.00966139417141676,0.012396897189319134,0.01366912480443716,0.014091751538217068,0.012348175048828125,0.009480763226747513,0.008215089328587055,0.012063583359122276,0.012648740783333778,0.01129101775586605,0.011884769424796104,0.011049296706914902,0.012372511439025402,0.01079247985035181,0.010364281944930553,0.009388972073793411,0.010392563417553902,0.011622459627687931,0.010033841244876385,0.009634081274271011,0.00996919721364975,0.010938060469925404,0.011110564693808556,0.009746103547513485,0.008260553702712059,0.0072782873176038265,0.007513436023145914,0.00803624652326107,0.011489931493997574,0.009808206930756569,0.00923266913741827,0.010505599901080132,0.00894203782081604,0.008550597354769707,0.008960019797086716,0.00797550193965435,0.009097941219806671,0.009828750975430012,0.009411025792360306,0.008863038383424282,0.007760575506836176,0.006243341136723757,0.007062693126499653,0.008266405202448368,0.007907141000032425,0.00801611877977848,0.006582530681043863,0.007404537405818701,0.007978005334734917,0.00938697624951601,0.009659039787948132,0.008205265738070011,0.007604531012475491,0.00773799791932106,0.00761553505435586,0.00805240124464035,0.008582119829952717,0.006347761955112219,0.005822332575917244,0.006976719480007887,0.007950522005558014,0.009005100466310978,0.008341658860445023,0.00767754390835762,0.007168568205088377,0.0066840676590800285,0.00633488642051816,0.005781202111393213,0.0079006003215909,0.008382978849112988,0.007303942926228046,0.006793587934225798,0.0067016687244176865,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 35747     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 35748     
=================================================================
Total params: 71,495
Trainable params: 71,495
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 35,747
Trainable params: 35,747
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 35,748
Trainable params: 35,748
Non-trainable params: 0
_________________________________________________________________
