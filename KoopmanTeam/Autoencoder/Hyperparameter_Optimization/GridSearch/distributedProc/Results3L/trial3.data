2021-06-26
loss,0.704420804977417,0.24019820988178253,0.08900293707847595,0.05939265713095665,0.048846740275621414,0.042417578399181366,0.038305506110191345,0.034709032624959946,0.032451383769512177,0.030602233484387398,0.029211996123194695,0.027533136308193207,0.026684489101171494,0.025605645030736923,0.024773292243480682,0.023935196921229362,0.02313477359712124,0.022548438981175423,0.02188022807240486,0.021286211907863617,0.020840415731072426,0.020403115078806877,0.020081035792827606,0.019760210067033768,0.019342374056577682,0.019002635031938553,0.018658969551324844,0.018534516915678978,0.01832249015569687,0.01799287274479866,0.017763478681445122,0.017495213076472282,0.01734924502670765,0.017011171206831932,0.01690887287259102,0.016707638278603554,0.01649387553334236,0.01633809693157673,0.016103968024253845,0.01585979200899601,0.01588730700314045,0.015575380064547062,0.015466611832380295,0.015374110080301762,0.015126828104257584,0.014998355880379677,0.014970874413847923,0.014798338524997234,0.01470423024147749,0.014520900323987007,0.014454799704253674,0.014300943352282047,0.014196660369634628,0.014069668017327785,0.013975993730127811,0.013818291015923023,0.013954902067780495,0.013800735585391521,0.013665879145264626,0.0135650048032403,0.013559650629758835,0.01331033930182457,0.013359138742089272,0.013320814818143845,0.013160905800759792,0.013019527308642864,0.012918336316943169,0.012934702448546886,0.012823175638914108,0.01276039332151413,0.012746449559926987,0.012672148644924164,0.012611903250217438,0.012497863732278347,0.012476631440222263,0.012399180792272091,0.012316866777837276,0.012211599387228489,0.01223793625831604,0.012251798063516617,0.012101730331778526,0.01204726006835699,0.01193650346249342,0.01199745386838913,0.011937900446355343,0.011893939226865768,0.011888754554092884,0.011769894510507584,0.011656427755951881,0.011646036058664322,0.011691548861563206,0.01159669179469347,0.011548127047717571,0.011600621044635773,0.011470076628029346,0.011433715932071209,0.011376075446605682,0.0113718556240201,0.011286204680800438,0.011231218464672565,
mse,0.18170137703418732,0.01849471405148506,0.0030143551994115114,0.0013163083931431174,0.0009016003459692001,0.0006762515986338258,0.000536956824362278,0.00043362422729842365,0.0003707523283082992,0.0003258456999901682,0.0002915480872616172,0.00025794238899834454,0.00023777884780429304,0.00021862563153263181,0.00020231878443155438,0.00018735587946139276,0.00017492659389972687,0.00016583413525950164,0.0001559978845762089,0.00014814383757766336,0.0001419084146618843,0.00013582466635853052,0.00013036288146395236,0.0001260184362763539,0.00012100927415303886,0.00011699008609866723,0.00011272641859250143,0.00011054909555241466,0.00010761128942249343,0.00010375704005127773,0.00010126963024958968,9.831756324274465e-05,9.636156028136611e-05,9.307304571848363e-05,9.134684660239145e-05,8.922722190618515e-05,8.719148900127038e-05,8.518921822542325e-05,8.297264866996557e-05,8.062578126555309e-05,8.041255932766944e-05,7.737498526694253e-05,7.675636879866943e-05,7.549827569164336e-05,7.308433123398572e-05,7.202893903013319e-05,7.149970770115033e-05,7.017858297331259e-05,6.885344919282943e-05,6.739237142028287e-05,6.635416502831504e-05,6.490256055258214e-05,6.413971277652308e-05,6.308079173322767e-05,6.209503771970049e-05,6.107656372478232e-05,6.130844121798873e-05,6.032766759744845e-05,5.908350431127474e-05,5.8069577789865434e-05,5.7842498790705577e-05,5.5864249588921666e-05,5.6510678405174986e-05,5.5691038141958416e-05,5.4705342336092144e-05,5.3504012612393126e-05,5.2728879381902516e-05,5.251036418485455e-05,5.16379986947868e-05,5.09813689859584e-05,5.0967737479368225e-05,5.064099605078809e-05,4.963489845977165e-05,4.909587005386129e-05,4.858399915974587e-05,4.798496956937015e-05,4.7325574996648356e-05,4.692965012509376e-05,4.656444798456505e-05,4.663241270463914e-05,4.562683534459211e-05,4.511926817940548e-05,4.4316599087323993e-05,4.4779106247005984e-05,4.42097989434842e-05,4.368553345557302e-05,4.378096491564065e-05,4.297194391256198e-05,4.215756052872166e-05,4.1923885873984545e-05,4.219546462991275e-05,4.152680412516929e-05,4.1212286305380985e-05,4.159285526839085e-05,4.070763316121884e-05,4.0229017031379044e-05,3.989300239481963e-05,4.0097584133036435e-05,3.9083752199076116e-05,3.9070680941222236e-05,
mae,0.29257845878601074,0.09562399238348007,0.03699834272265434,0.024612607434391975,0.020382869988679886,0.017828889191150665,0.01616835966706276,0.014709110371768475,0.013793165795505047,0.013018017634749413,0.012394829653203487,0.011677234433591366,0.011308803223073483,0.010848382487893105,0.01047510001808405,0.010120910592377186,0.00977572426199913,0.009533124975860119,0.009237304329872131,0.008993926458060741,0.008804098702967167,0.008621140383183956,0.008481178432703018,0.00834778230637312,0.008173163048923016,0.008020521141588688,0.007880407385528088,0.007824881933629513,0.007734007202088833,0.007590188179165125,0.007499800529330969,0.007382404059171677,0.007322872988879681,0.007173431571573019,0.007137414999306202,0.007051632273942232,0.006957726553082466,0.006894425023347139,0.006796545814722776,0.006693554110825062,0.006702528800815344,0.006581461057066917,0.006526693236082792,0.0064857155084609985,0.006388804875314236,0.006342038512229919,0.006319514941424131,0.006242650561034679,0.006203805096447468,0.006135410629212856,0.006099996156990528,0.006042191758751869,0.00599603122100234,0.005945080425590277,0.005904905963689089,0.005829689092934132,0.005909166764467955,0.00582533935084939,0.005777075886726379,0.005732314195483923,0.005733928177505732,0.005629859399050474,0.005638746544718742,0.005631076171994209,0.005559447221457958,0.005501706153154373,0.005458609666675329,0.005483733024448156,0.005419837310910225,0.005400898400694132,0.00538233295083046,0.005348226986825466,0.005344855599105358,0.00528722582384944,0.005282714497298002,0.005248519126325846,0.005217603873461485,0.005166370887309313,0.005166465416550636,0.0051791672594845295,0.005131533369421959,0.0051058814860880375,0.00506319897249341,0.0050698863342404366,0.005048154387623072,0.005044006276875734,0.0050199441611766815,0.004971913993358612,0.004936840385198593,0.004927202593535185,0.0049612089060246944,0.004915562923997641,0.00487292418256402,0.004902390763163567,0.00485329469665885,0.004841916728764772,0.004808430094271898,0.004802606999874115,0.004791020881384611,0.004729642067104578,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 915       
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 916       
=================================================================
Total params: 1,831
Trainable params: 1,831
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 915
Trainable params: 915
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 916
Trainable params: 916
Non-trainable params: 0
_________________________________________________________________
