2021-06-26
loss,0.342197448015213,0.14385539293289185,0.07268854975700378,0.044999875128269196,0.03883662819862366,0.03485565632581711,0.03240982070565224,0.030646970495581627,0.028979741036891937,0.0281930323690176,0.02686365693807602,0.026529556140303612,0.0257321335375309,0.024602599442005157,0.024334268644452095,0.023897534236311913,0.023396635428071022,0.02289784699678421,0.022771721705794334,0.02214730903506279,0.021685529500246048,0.02157897688448429,0.021357882767915726,0.02095777355134487,0.020707350224256516,0.020287327468395233,0.020268378779292107,0.01989622227847576,0.019668160006403923,0.01945471204817295,0.019290383905172348,0.01906074956059456,0.018796050921082497,0.01874769665300846,0.018687831237912178,0.018243826925754547,0.018333101645112038,0.018149590119719505,0.017956994473934174,0.017774632200598717,0.017616024240851402,0.017546208575367928,0.017303859815001488,0.017105979844927788,0.01697753742337227,0.01695466786623001,0.01675824262201786,0.016605932265520096,0.016557300463318825,0.01620427891612053,0.016194267198443413,0.01605822704732418,0.01602322608232498,0.015811625868082047,0.015782546252012253,0.015639709308743477,0.015483344905078411,0.015392324887216091,0.015292639844119549,0.015176543034613132,0.014950793236494064,0.015096515417098999,0.015026235952973366,0.014912374317646027,0.014731798321008682,0.01465234998613596,0.01461719535291195,0.014459686353802681,0.014304415322840214,0.014287407509982586,0.01425336953252554,0.014112111181020737,0.01411466859281063,0.014029486104846,0.013930710963904858,0.01380668394267559,0.013863840140402317,0.013617422431707382,0.013637913390994072,0.01358736865222454,0.01350299920886755,0.013478820212185383,0.013282018713653088,0.013315793126821518,0.013188663870096207,0.013186679221689701,0.01304362528026104,0.012964111752808094,0.013095902279019356,0.012808470986783504,0.012875170446932316,0.012811318971216679,0.0127217136323452,0.012505173683166504,0.012627971358597279,0.012620247900485992,0.012511754408478737,0.01238124817609787,0.012409047223627567,0.012403595261275768,
mse,0.043257247656583786,0.007660780102014542,0.0018004273297265172,0.0006512469844892621,0.00047283421736210585,0.00037728185998275876,0.0003204677195753902,0.00027908978518098593,0.000247124902671203,0.00023443317331839353,0.00021158579329494387,0.00020613256492652,0.00019237933156546205,0.00017843583191279322,0.0001744682085700333,0.0001650723279453814,0.00015941128367558122,0.00015223237278405577,0.00014936011575628072,0.00014237244613468647,0.00013715654495172203,0.0001358607696602121,0.00013110387953929603,0.0001271282380912453,0.0001234279916388914,0.00011829329014290124,0.0001186485678772442,0.00011340130731696263,0.0001123421243391931,0.00010852325794985518,0.00010765366459963843,0.00010521091462578624,0.0001012623033602722,0.0001015898960758932,0.0001005986487143673,9.681098163127899e-05,9.724018309498206e-05,9.354967914987355e-05,9.242184751201421e-05,9.07683206605725e-05,8.825767872622237e-05,8.758881449466571e-05,8.567359327571467e-05,8.400205842917785e-05,8.241430623456836e-05,8.187164348782972e-05,8.106561290333048e-05,7.851605914765969e-05,7.790818199282512e-05,7.573660695925355e-05,7.573982293251902e-05,7.357640424743295e-05,7.248849578900263e-05,7.131355232559144e-05,7.090460712788627e-05,7.020510383881629e-05,6.811612547608092e-05,6.742335972376168e-05,6.65312327328138e-05,6.561642658198252e-05,6.463593308581039e-05,6.573164137080312e-05,6.402209692168981e-05,6.300476525211707e-05,6.17681653238833e-05,6.11385257798247e-05,6.078192018321715e-05,5.9745372709585354e-05,5.816494012833573e-05,5.858593067387119e-05,5.7965513406088576e-05,5.702183261746541e-05,5.6837525335140526e-05,5.569956192630343e-05,5.479922401718795e-05,5.48224852536805e-05,5.443640111479908e-05,5.351264917408116e-05,5.3351166570791975e-05,5.249715832178481e-05,5.1767437980743125e-05,5.1214265113230795e-05,5.032019180362113e-05,5.049179162597284e-05,4.9866437620949e-05,4.90681231894996e-05,4.833991260966286e-05,4.8203797632595524e-05,4.8494417569600046e-05,4.723471647594124e-05,4.69388542114757e-05,4.6367513277800754e-05,4.593234552885406e-05,4.503021773416549e-05,4.5688786485698074e-05,4.507918856688775e-05,4.4533051550388336e-05,4.4063213863410056e-05,4.370453825686127e-05,4.428583997651003e-05,
mae,0.14569498598575592,0.06312805414199829,0.030834950506687164,0.018977565690875053,0.016369560733437538,0.014731241390109062,0.013640821911394596,0.012912043370306492,0.012393577955663204,0.011933819390833378,0.011372100561857224,0.011335923336446285,0.010874737054109573,0.010506334714591503,0.010312611237168312,0.010080481879413128,0.009862394072115421,0.009615570306777954,0.009620273485779762,0.009366286918520927,0.009266544133424759,0.009235021658241749,0.009001894854009151,0.008949441835284233,0.008845141157507896,0.008663861081004143,0.008595612831413746,0.008472194895148277,0.008352283388376236,0.008286707103252411,0.008208338171243668,0.00810402911156416,0.008055008947849274,0.007982381619513035,0.007857270538806915,0.00782207865267992,0.007776619866490364,0.0076765622943639755,0.007613000459969044,0.007610011845827103,0.007455502636730671,0.007499461993575096,0.007252256851643324,0.007275381125509739,0.0071377260610461235,0.007200994528830051,0.007138003595173359,0.006999845616519451,0.007019227370619774,0.006878139916807413,0.006876375526189804,0.006768849678337574,0.006796734873205423,0.0067390440963208675,0.006654960103332996,0.006610618904232979,0.006636070087552071,0.006555682979524136,0.006491557229310274,0.006378500256687403,0.006380787119269371,0.006417859345674515,0.006397409364581108,0.006349910981953144,0.006220347713679075,0.006242711562663317,0.006199671421200037,0.006178169045597315,0.0061376760713756084,0.00608915975317359,0.006015624850988388,0.006004749331623316,0.0059852381236851215,0.006014581769704819,0.005866661202162504,0.00582604156807065,0.005871547851711512,0.005749627947807312,0.005791498348116875,0.005761155858635902,0.005697045940905809,0.005727692972868681,0.005663027986884117,0.005600286647677422,0.005598470102995634,0.0056196413934230804,0.005576631054282188,0.005464452318847179,0.005615375004708767,0.005455600097775459,0.005466471426188946,0.0054128835909068584,0.005443110596388578,0.00528012216091156,0.005300185643136501,0.005391680169850588,0.005294464062899351,0.00522575993090868,0.005303358659148216,0.005285485181957483,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 10707     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 10708     
=================================================================
Total params: 21,415
Trainable params: 21,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 10,707
Trainable params: 10,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 10,708
Trainable params: 10,708
Non-trainable params: 0
_________________________________________________________________
