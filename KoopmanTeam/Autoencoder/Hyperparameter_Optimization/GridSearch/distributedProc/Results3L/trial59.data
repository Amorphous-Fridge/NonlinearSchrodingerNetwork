2021-06-26
loss,0.2856122851371765,0.08498846739530563,0.08019102364778519,0.05398857593536377,0.04924057424068451,0.04852662608027458,0.04899291694164276,0.0664566159248352,0.053850460797548294,0.046558938920497894,0.046756137162446976,0.03827309608459473,0.03450854867696762,0.03931635618209839,0.040086254477500916,0.03648616001009941,0.033326391130685806,0.02350763790309429,0.025944601744413376,0.025962572544813156,0.03111967258155346,0.02556191198527813,0.030893748626112938,0.0325726643204689,0.027996914461255074,0.025098416954278946,0.027603082358837128,0.028406966477632523,0.0271485336124897,0.026744525879621506,0.024225587025284767,0.022661671042442322,0.023027021437883377,0.024886097759008408,0.02353842183947563,0.021582117304205894,0.019735058769583702,0.01759456843137741,0.019101299345493317,0.021963845938444138,0.021795766428112984,0.02112012542784214,0.01999526657164097,0.016188066452741623,0.015431113541126251,0.01764456182718277,0.019875507801771164,0.017235375940799713,0.01920546218752861,0.024342574179172516,0.02186872996389866,0.019751034677028656,0.018349722027778625,0.018146997317671776,0.02065327577292919,0.019941043108701706,0.020694613456726074,0.01971517503261566,0.01987282559275627,0.01850062794983387,0.017100894823670387,0.018612854182720184,0.019311660900712013,0.018987560644745827,0.018930258229374886,0.017034856602549553,0.015058249235153198,0.01346726156771183,0.012911808677017689,0.013240976259112358,0.015711061656475067,0.01725056581199169,0.017926635220646858,0.018571577966213226,0.018125317990779877,0.016681089997291565,0.014865321107208729,0.015072468668222427,0.014703894034028053,0.013534950092434883,0.014366451650857925,0.0150755038484931,0.018406469374895096,0.01677742786705494,0.015496870502829552,0.014444679953157902,0.013515019789338112,0.013391182757914066,0.015814894810318947,0.017784327268600464,0.01595793291926384,0.015426336787641048,0.015383105725049973,0.015585300512611866,0.015926502645015717,0.015789948403835297,0.014822450466454029,0.014319086447358131,0.013588412664830685,0.012960555963218212,
mse,0.03223389759659767,0.0023604289162904024,0.0019240030087530613,0.0008757837931625545,0.0007213124772533774,0.0007134800544008613,0.0007712665246799588,0.001371894497424364,0.0009038293501362205,0.0006458995630964637,0.0006395938107743859,0.0004492446023505181,0.0003496742865536362,0.0004697139956988394,0.0004734104732051492,0.0003933995612896979,0.00033963550231419504,0.00017372170987073332,0.00021677468612324446,0.00020472124742809683,0.0002898413222283125,0.0002008320007007569,0.0002942932187579572,0.0003208365524187684,0.00023481807147618383,0.00019853655248880386,0.00023387836699839681,0.0002348523703403771,0.0002151874650735408,0.0002177633868996054,0.00018077658023685217,0.00015888450434431434,0.00016370730008929968,0.0001771921233739704,0.0001584375713719055,0.000139119743835181,0.00011771021672757342,9.446453623240814e-05,0.00011188775533810258,0.00014259076851885766,0.0001391781697748229,0.0001358558947686106,0.00012085684284102172,8.130473725032061e-05,7.306943007279187e-05,9.512454562354833e-05,0.00012003986194031313,9.183279325952753e-05,0.00011722114140866324,0.00017315275908913463,0.00013535791367758065,0.00011404499673517421,9.940595191437751e-05,9.8994372820016e-05,0.00012917238927911967,0.00011663397890515625,0.000123703372082673,0.00011224744230275974,0.00011671226820908487,9.93308422039263e-05,8.91878007678315e-05,0.00010273748193867505,0.0001073858147719875,0.0001037594338413328,0.00010286400356562808,8.585312752984464e-05,7.003750215517357e-05,5.586335464613512e-05,5.0444308726582676e-05,5.5095333664212376e-05,7.477289182133973e-05,8.834130858303979e-05,9.468464850215241e-05,9.684667020337656e-05,9.391373896505684e-05,8.165908366208896e-05,6.805668090237305e-05,6.946539360797033e-05,6.559772737091407e-05,5.74455589230638e-05,6.400729762390256e-05,6.825830496381968e-05,9.450440120417625e-05,8.133333176374435e-05,7.200374966487288e-05,6.303074769675732e-05,5.54113976249937e-05,5.571627480094321e-05,7.394723797915503e-05,9.014870738610625e-05,7.170166645664722e-05,6.890178337926045e-05,6.807051249779761e-05,7.030476990621537e-05,7.142784306779504e-05,7.077049667714164e-05,6.428159394999966e-05,5.9903602959821e-05,5.378360947361216e-05,4.914779856335372e-05,
mae,0.12596666812896729,0.03716038912534714,0.0343509241938591,0.023068955168128014,0.020913774147629738,0.02069995179772377,0.021323077380657196,0.029204292222857475,0.023779548704624176,0.020078375935554504,0.02058098092675209,0.01630779542028904,0.014798501506447792,0.017158230766654015,0.017556168138980865,0.015890123322606087,0.014430176466703415,0.010043864138424397,0.011090453714132309,0.010997221805155277,0.013242444954812527,0.010933187790215015,0.013386806473135948,0.014340238645672798,0.012191345915198326,0.010772429406642914,0.011938504874706268,0.012405618093907833,0.011726966127753258,0.011572593823075294,0.010207902640104294,0.00958309881389141,0.009842691011726856,0.010674957185983658,0.01008334755897522,0.009079525247216225,0.008327261544764042,0.007595979142934084,0.00813752319663763,0.00947408564388752,0.009352805092930794,0.009154565632343292,0.008529171347618103,0.006874171085655689,0.006565545219928026,0.007484728004783392,0.008463384583592415,0.007421492133289576,0.00831542257219553,0.010748293250799179,0.009592791087925434,0.008665754459798336,0.008008602075278759,0.007736982777714729,0.008767493069171906,0.008408704772591591,0.008733294904232025,0.008334215730428696,0.008405222557485104,0.00774177722632885,0.00728873023763299,0.008087008260190487,0.008371503092348576,0.00815510656684637,0.00806411076337099,0.007168913260102272,0.006391221657395363,0.005679531488567591,0.005436377599835396,0.005670060403645039,0.00668182410299778,0.007342421915382147,0.007605133578181267,0.00804935209453106,0.007831891067326069,0.007085714489221573,0.0062380386516451836,0.006452402099967003,0.006188854109495878,0.005617509596049786,0.0060640377923846245,0.006357801146805286,0.008015305735170841,0.0071161300875246525,0.006431026384234428,0.00616772286593914,0.005826007574796677,0.005768729839473963,0.006762961857020855,0.007556605152785778,0.006724068894982338,0.006578291766345501,0.0065802354365587234,0.006565210409462452,0.006773433648049831,0.006789054721593857,0.006423019338399172,0.006153125315904617,0.005771770607680082,0.005537533201277256,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 70699     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 70700     
=================================================================
Total params: 141,399
Trainable params: 141,399
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 70,699
Trainable params: 70,699
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 70,700
Trainable params: 70,700
Non-trainable params: 0
_________________________________________________________________
