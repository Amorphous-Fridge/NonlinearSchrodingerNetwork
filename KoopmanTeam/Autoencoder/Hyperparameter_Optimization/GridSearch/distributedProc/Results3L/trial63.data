2021-06-26
loss,0.334586501121521,0.1286296397447586,0.08182577043771744,0.056892815977334976,0.05741451680660248,0.05612112581729889,0.0396537184715271,0.043303295969963074,0.03551369160413742,0.03240540996193886,0.026947608217597008,0.02523617446422577,0.02451285906136036,0.023642273619771004,0.023043978959321976,0.02255646511912346,0.022328106686472893,0.021770786494016647,0.021420998498797417,0.020987460389733315,0.020754262804985046,0.020581413060426712,0.02018151432275772,0.019987711682915688,0.019831346347928047,0.01953697018325329,0.019267067313194275,0.019156252965331078,0.023236973211169243,0.024446573108434677,0.032587721943855286,0.030269108712673187,0.029435232281684875,0.03095349110662937,0.023178555071353912,0.02897602878510952,0.026670703664422035,0.02855246514081955,0.027291394770145416,0.02421077899634838,0.021856999024748802,0.02559869922697544,0.022225283086299896,0.020754491910338402,0.024681856855750084,0.0288630910217762,0.026029501110315323,0.025490017607808113,0.02378802001476288,0.016578834503889084,0.017056941986083984,0.017381487414240837,0.01811297796666622,0.023087458685040474,0.024862069636583328,0.026107896119356155,0.0235699862241745,0.023274287581443787,0.023358896374702454,0.024783466011285782,0.02181115932762623,0.020281467586755753,0.022381026297807693,0.02265479974448681,0.022635530680418015,0.020984649658203125,0.01933324709534645,0.017918547615408897,0.01971343345940113,0.022772548720240593,0.02204703725874424,0.021743135526776314,0.019205614924430847,0.020853323861956596,0.020564639940857887,0.018884213641285896,0.01662229374051094,0.01498265378177166,0.01260816678404808,0.012015247717499733,0.011694190092384815,0.011581650003790855,0.011402414180338383,0.011392992921173573,0.011292469687759876,0.011313188821077347,0.011232283897697926,0.011249606497585773,0.011209006421267986,0.011148596182465553,0.011130603961646557,0.010955996811389923,0.011027761735022068,0.010881023481488228,0.011023079976439476,0.01093013770878315,0.010842843912541866,0.010939810425043106,0.010852903127670288,0.010832182131707668,
mse,0.041716694831848145,0.0054330723360180855,0.0020742034539580345,0.0009665784309618175,0.0009760340326465666,0.0009129685931839049,0.0004621429252438247,0.0005314184236340225,0.0003592793655116111,0.00030371424509212375,0.00020872151071671396,0.00018540203745942563,0.0001733660465106368,0.00016174612392205745,0.00015304397675208747,0.00014784563973080367,0.00014314785948954523,0.0001359347952529788,0.00013130190200172365,0.00012693664757534862,0.00012306452845223248,0.00012177322059869766,0.00011683455522870645,0.00011392942542443052,0.00011188962525920942,0.00010834677232196555,0.00010571754683041945,0.00010666443267837167,0.00016773697279859334,0.00018605185323394835,0.00031089605181477964,0.0002723531797528267,0.0002500464615877718,0.00028525543166324496,0.0001624204742256552,0.000245357136009261,0.00020826136460527778,0.00023473896726500243,0.00021402766287792474,0.0001746012276271358,0.00014636832929681987,0.00018980391905643046,0.00014630967052653432,0.00012604607036337256,0.00017840799409896135,0.0002350795257370919,0.00018905699835158885,0.0001859762123785913,0.00016741396393626928,8.203709148801863e-05,8.773253648541868e-05,9.073803084902465e-05,9.953046537702903e-05,0.00015644777158740908,0.0001745451008901,0.00019414292182773352,0.0001573355693835765,0.00015614755102433264,0.0001549170265207067,0.00017050266615115106,0.00014023315452504903,0.00012342237459961325,0.00014648892101831734,0.00014908490993548185,0.00014672453107777983,0.00012690342555288225,0.00011145388998556882,9.486819908488542e-05,0.00011571003415156156,0.0001478546910220757,0.00013832043623551726,0.00013298536941874772,0.00010812558321049437,0.000123739373520948,0.00011753020953619853,0.00010282902076141909,8.366906695300713e-05,6.920195301063359e-05,4.6328106691362336e-05,4.214841828797944e-05,3.943314732168801e-05,3.8952846807660535e-05,3.8068221329012886e-05,3.796117380261421e-05,3.7345253076637164e-05,3.690302764880471e-05,3.6485394957708195e-05,3.66103122360073e-05,3.6385448765940964e-05,3.60542799171526e-05,3.553166607161984e-05,3.46632041328121e-05,3.4944798244396225e-05,3.437876875977963e-05,3.485770139377564e-05,3.4125419915653765e-05,3.4425760532030836e-05,3.4142871299991384e-05,3.381145143066533e-05,3.406383257242851e-05,
mae,0.14628928899765015,0.05494678020477295,0.035051122307777405,0.023900676518678665,0.0242928359657526,0.024049358442425728,0.016851093620061874,0.018199602141976357,0.014965281821787357,0.013811131939291954,0.011547591537237167,0.0109261404722929,0.010585619136691093,0.010228436440229416,0.009883581660687923,0.009771986864507198,0.009585073217749596,0.009298156946897507,0.009211622178554535,0.008975532837212086,0.008891775272786617,0.008841663599014282,0.008635655976831913,0.008550822734832764,0.008449353277683258,0.008310394361615181,0.008169157430529594,0.008148727007210255,0.00991982314735651,0.010525219142436981,0.013757394626736641,0.012997892685234547,0.01247631199657917,0.013201069086790085,0.009867716580629349,0.012295806780457497,0.01135523896664381,0.012191406451165676,0.01137494295835495,0.010321301408112049,0.009402373805642128,0.010848603211343288,0.009436757303774357,0.008810235187411308,0.010445880703628063,0.012377362698316574,0.011014781892299652,0.010737772099673748,0.010122368112206459,0.007033488247543573,0.00724057899788022,0.007403166498988867,0.007726756390184164,0.00982693862169981,0.010412059724330902,0.011161948554217815,0.009869920089840889,0.009854060597717762,0.009917864575982094,0.010530469007790089,0.009227716363966465,0.008587051182985306,0.009587199427187443,0.009712226688861847,0.009631644934415817,0.008895676583051682,0.008204187266528606,0.0075743901543319225,0.008381799794733524,0.00972939282655716,0.009408686310052872,0.00915555004030466,0.008180034346878529,0.008890465833246708,0.008659666404128075,0.008016495034098625,0.007032015360891819,0.006379371974617243,0.00539749301970005,0.005132197868078947,0.004981933627277613,0.004971443675458431,0.004844158422201872,0.004871109034866095,0.0048207249492406845,0.004845807328820229,0.004780090879648924,0.004787832964211702,0.004798753187060356,0.004737307783216238,0.004744418431073427,0.004660027101635933,0.0047021121717989445,0.004621000029146671,0.004714581184089184,0.004616497550159693,0.004596569575369358,0.0046410951763391495,0.004610343836247921,0.004601589869707823,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25299     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25300     
=================================================================
Total params: 50,599
Trainable params: 50,599
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 25,299
Trainable params: 25,299
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 25,300
Trainable params: 25,300
Non-trainable params: 0
_________________________________________________________________
