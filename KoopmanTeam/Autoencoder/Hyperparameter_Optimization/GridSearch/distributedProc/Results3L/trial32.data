2021-06-26
loss,0.3102799654006958,0.09645427763462067,0.06321427971124649,0.051273785531520844,0.0445171557366848,0.04027717933058739,0.0376582108438015,0.03519991785287857,0.033449556678533554,0.03185950219631195,0.03054048866033554,0.05131305754184723,0.043399568647146225,0.03807394206523895,0.027067160233855247,0.025153055787086487,0.024476511403918266,0.02394484542310238,0.02361995540559292,0.022712552919983864,0.022541215643286705,0.03300455957651138,0.0332714281976223,0.02500552125275135,0.022701485082507133,0.03154996410012245,0.0291613657027483,0.03021392785012722,0.029169753193855286,0.030635833740234375,0.028769681230187416,0.026427917182445526,0.02494754083454609,0.024053627625107765,0.02186017669737339,0.01923166587948799,0.018307985737919807,0.017880063503980637,0.01764177531003952,0.017247412353754044,0.017174148932099342,0.01683909259736538,0.016714269295334816,0.01650393195450306,0.016242777928709984,0.016136538237333298,0.01597975753247738,0.015594834461808205,0.01576872169971466,0.015655208379030228,0.01551892515271902,0.015480488538742065,0.015277612954378128,0.015268656425178051,0.015099053271114826,0.015078979544341564,0.015001104213297367,0.014903491362929344,0.01489212829619646,0.014743471518158913,0.014681143686175346,0.014545739628374577,0.014525043778121471,0.014380929060280323,0.014442410320043564,0.014241449534893036,0.014221465215086937,0.014138693921267986,0.01407722756266594,0.013989543542265892,0.013926822692155838,0.013774557039141655,0.013765169307589531,0.013730859383940697,0.013623194769024849,0.013893106952309608,0.01621200516819954,0.021655984222888947,0.023635534569621086,0.023120461031794548,0.021255740895867348,0.019021276384592056,0.016822611913084984,0.02217029593884945,0.01581411622464657,0.02014489471912384,0.019577866420149803,0.01961054652929306,0.02193647436797619,0.020720556378364563,0.024682212620973587,0.020901227369904518,0.01968403346836567,0.022212283685803413,0.02243523858487606,0.02115412801504135,0.019636215642094612,0.018543962389230728,0.017027534544467926,0.01850687339901924,
mse,0.03899552300572395,0.0032249069772660732,0.0013067699037492275,0.0008175078546628356,0.0006022904999554157,0.00048409574083052576,0.0004174021305516362,0.0003622010408435017,0.0003227665147278458,0.0002954840019810945,0.00027289948775433004,0.0008033523918129504,0.0005417722277343273,0.0004197800299152732,0.0002224128256784752,0.00018762642866931856,0.00017688008665572852,0.00016876848530955613,0.00016442245396319777,0.0001577904331497848,0.00015605258522555232,0.0003317592781968415,0.0003149437834508717,0.000190916660358198,0.00015528251242358238,0.0002924622967839241,0.00024692597799003124,0.0002639918529894203,0.00024861720157787204,0.000278049788903445,0.00023909889569040388,0.00020094487990718335,0.00017982369172386825,0.0001663558214204386,0.00013847684022039175,0.00010919866326730698,0.00010016803571488708,9.517477155895904e-05,9.324835264123976e-05,8.880400855559856e-05,8.820420771371573e-05,8.444795093964785e-05,8.335306483786553e-05,8.117208199109882e-05,7.917309267213568e-05,7.80320042395033e-05,7.661960262339562e-05,7.392570114461705e-05,7.375919085461646e-05,7.269805792020634e-05,7.188049494288862e-05,7.131108577596024e-05,6.946535722818226e-05,6.93782712914981e-05,6.740237586200237e-05,6.783001299481839e-05,6.703635153826326e-05,6.524607306346297e-05,6.528085214085877e-05,6.428049528039992e-05,6.385144661180675e-05,6.32682567811571e-05,6.278341606957838e-05,6.106729415478185e-05,6.175495218485594e-05,6.062370812287554e-05,5.986334872432053e-05,5.928647078690119e-05,5.8466135669732466e-05,5.785300527350046e-05,5.7013428886421025e-05,5.6507415138185024e-05,5.6697012041695416e-05,5.622331809718162e-05,5.484712892211974e-05,5.834706098539755e-05,8.254028216470033e-05,0.00013823248445987701,0.00016179661906789988,0.00015130722022149712,0.00012729078298434615,0.00010662137356121093,8.748527761781588e-05,0.00014229933731257915,7.692590588703752e-05,0.00011932137567782775,0.0001114887636504136,0.00011149005877086893,0.00013689426123164594,0.00012422664440236986,0.0001699963613646105,0.00012653185694944113,0.00011392117448849604,0.00014239721349440515,0.00014460367674473673,0.00013042801583651453,0.00011382641241652891,0.00010049271077150479,8.806063124211505e-05,9.853751544142142e-05,
mae,0.13256114721298218,0.040899671614170074,0.026935245841741562,0.02180621586740017,0.018906032666563988,0.017207833006978035,0.016011126339435577,0.0150424400344491,0.014177403412759304,0.01357807032763958,0.013004270382225513,0.021253060549497604,0.01863689161837101,0.0163425300270319,0.011369369924068451,0.010586793534457684,0.01034851185977459,0.010197133757174015,0.010053540579974651,0.009642125107347965,0.009516165591776371,0.013924666680395603,0.01419982872903347,0.010536901652812958,0.009690767154097557,0.01344009954482317,0.01205679215490818,0.012978723272681236,0.012558660469949245,0.013411462306976318,0.01251037698239088,0.01085866242647171,0.010262328200042248,0.009955832734704018,0.009204855188727379,0.008018468506634235,0.007765712216496468,0.007585776969790459,0.007498911581933498,0.007383011747151613,0.007304099854081869,0.007214874494820833,0.007160165812820196,0.007035557180643082,0.006920523010194302,0.0068435161374509335,0.006854557897895575,0.0066516464576125145,0.006710021290928125,0.006681844592094421,0.006642674095928669,0.006615079008042812,0.006571661215275526,0.006474567577242851,0.006433260627090931,0.006424766965210438,0.006401770282536745,0.00633451621979475,0.006320729851722717,0.006294589024037123,0.00625786604359746,0.0061574941501021385,0.006206317339092493,0.006085950881242752,0.00614670105278492,0.00611909618601203,0.006033981218934059,0.006017003674060106,0.006004921160638332,0.005950806196779013,0.00588037446141243,0.005891820881515741,0.005835722200572491,0.005803787615150213,0.005834486335515976,0.005931675899773836,0.006881473120301962,0.0093081621453166,0.010085179470479488,0.009719427675008774,0.009084933437407017,0.008186264894902706,0.007153040263801813,0.009587794542312622,0.0066932495683431625,0.008560407906770706,0.008335230872035027,0.008315343409776688,0.009465011768043041,0.008766532875597477,0.010204200632870197,0.009094939567148685,0.008521958254277706,0.009379840455949306,0.00942368432879448,0.008915955200791359,0.008282866328954697,0.007807317189872265,0.007261307444423437,0.007878378033638,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 10667     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 10668     
=================================================================
Total params: 21,335
Trainable params: 21,335
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 10,667
Trainable params: 10,667
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 10,668
Trainable params: 10,668
Non-trainable params: 0
_________________________________________________________________
