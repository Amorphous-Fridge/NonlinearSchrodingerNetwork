2021-06-26
loss,0.3454623520374298,0.21653157472610474,0.13984021544456482,0.09747103601694107,0.07137805223464966,0.06536588817834854,0.05732383206486702,0.06136336177587509,0.062225695699453354,0.08275852352380753,0.0731443539261818,0.04449944943189621,0.041281603276729584,0.04758749529719353,0.04759569093585014,0.06272494047880173,0.05921727046370506,0.049422893673181534,0.04002408683300018,0.03172660246491432,0.03442104533314705,0.044644881039857864,0.05344357341527939,0.044909972697496414,0.04615405946969986,0.042123083025217056,0.03975006565451622,0.03711242973804474,0.03417693451046944,0.0305398628115654,0.03060934506356716,0.03692382574081421,0.035424698144197464,0.031590536236763,0.032935142517089844,0.030656902119517326,0.026916854083538055,0.02549956552684307,0.024648034945130348,0.02572789415717125,0.034484878182411194,0.03085314668715,0.034187328070402145,0.030509063974022865,0.027360396459698677,0.024229753762483597,0.02474568597972393,0.02667793445289135,0.031785789877176285,0.028718523681163788,0.025254396721720695,0.026496008038520813,0.026298439130187035,0.02259964682161808,0.020784633234143257,0.02081829309463501,0.021049926057457924,0.020387258380651474,0.019571034237742424,0.02479427494108677,0.029368389397859573,0.026889724656939507,0.023938721045851707,0.022619474679231644,0.02143947407603264,0.02005307748913765,0.01880803145468235,0.018728740513324738,0.01837916299700737,0.016695374622941017,0.01583905890583992,0.014975510537624359,0.014628628268837929,0.014019490219652653,0.013765858486294746,0.01350165531039238,0.013453071005642414,0.01337232906371355,0.013197233900427818,0.01316093560308218,0.013000134378671646,0.013005384244024754,0.01306765154004097,0.012958335690200329,0.012798693962395191,0.012764735147356987,0.012820888310670853,0.012653427198529243,0.012656225822865963,0.01247757114470005,0.012477709911763668,0.012384829111397266,0.012431400828063488,0.01232729572802782,0.01227192860096693,0.012153609655797482,0.012149471789598465,0.012091808021068573,0.01207209937274456,0.012003015726804733,
mse,0.043125685304403305,0.016804398968815804,0.006650247145444155,0.0029113348573446274,0.0015663447557017207,0.0013260674895718694,0.001006305101327598,0.001176713965833187,0.001170554431155324,0.0019412238616496325,0.0015655175084248185,0.0006215327302925289,0.0005267141968943179,0.0006884601898491383,0.0006768998573534191,0.001104684080928564,0.0010202748235315084,0.0007384250056929886,0.0004780538147315383,0.00032025735708884895,0.00035589616163633764,0.000595710938796401,0.0008147429907694459,0.0005815927288495004,0.000602309824898839,0.0005141445435583591,0.00045089732157066464,0.0004036224272567779,0.00034197649802081287,0.00028166986885480583,0.00028644726262427866,0.00040228303987532854,0.0003560880140867084,0.00029469700530171394,0.00031585461692884564,0.0002754712477326393,0.00021725035912822932,0.0001971263554878533,0.00018483684107195586,0.00019854499259963632,0.00033819786040112376,0.0002811151498463005,0.0003292345500085503,0.00026100731338374317,0.0002160556468879804,0.00017763086361810565,0.0001815414580050856,0.00020864982798229903,0.00028760635177604854,0.00023703531769569963,0.00019301332940813154,0.00020273383415769786,0.00019701464043464512,0.00014949568139854819,0.00012721751409117132,0.0001327215286437422,0.00013446842785924673,0.00012312176113482565,0.00011328508844599128,0.00018987702787853777,0.00024347817816305906,0.00020269442757125944,0.000161875577759929,0.00014740065671503544,0.00013465163647197187,0.00011910052853636444,0.00010851716797333211,0.00010558427311480045,0.00010197562369285151,8.756548049859703e-05,7.361335883615538e-05,6.500232848338783e-05,6.144389772089198e-05,5.665537537424825e-05,5.438126027001999e-05,5.188932118471712e-05,5.242959741735831e-05,5.0785441999323666e-05,4.94107480335515e-05,4.9505233619129285e-05,4.937366975354962e-05,4.873169746133499e-05,4.812534461962059e-05,4.7861249186098576e-05,4.64341246697586e-05,4.8471403715666384e-05,4.679807898355648e-05,4.565896961139515e-05,4.555562190944329e-05,4.4438311306294054e-05,4.4447053369367495e-05,4.351240932010114e-05,4.396773874759674e-05,4.314968828111887e-05,4.2718133045127615e-05,4.1707917262101546e-05,4.257545879227109e-05,4.198975511826575e-05,4.1433009755564854e-05,4.02230434701778e-05,
mae,0.1452980935573578,0.08207987993955612,0.057051148265600204,0.041612643748521805,0.030579708516597748,0.028196297585964203,0.024514107033610344,0.026063082739710808,0.02625490352511406,0.03667677193880081,0.03330567106604576,0.019056877121329308,0.017772240564227104,0.020586585626006126,0.02029705047607422,0.027431391179561615,0.026335766538977623,0.02139824628829956,0.017043406143784523,0.01359956618398428,0.014696639031171799,0.019036877900362015,0.023947782814502716,0.019600534811615944,0.020979924127459526,0.0192112997174263,0.01812790520489216,0.016580166295170784,0.014687436632812023,0.012599856592714787,0.013092748820781708,0.01550647709518671,0.014748003333806992,0.013616448268294334,0.014054124243557453,0.013045855797827244,0.011219849810004234,0.010694218799471855,0.010269427672028542,0.010920817963778973,0.01484965905547142,0.013058295473456383,0.01536896824836731,0.012805798090994358,0.011263386346399784,0.010417512618005276,0.010499962605535984,0.01140398159623146,0.014282976277172565,0.012580730952322483,0.010803645476698875,0.011262563057243824,0.010921245440840721,0.009619741700589657,0.00887366198003292,0.00881502777338028,0.009042688645422459,0.00866015162318945,0.008303632959723473,0.010722036473453045,0.013219976797699928,0.01185467466711998,0.009778243489563465,0.009314238093793392,0.009088470600545406,0.008517713285982609,0.007991177961230278,0.007950100116431713,0.007815025746822357,0.007149664219468832,0.006925342604517937,0.00666483398526907,0.006513656582683325,0.006257272325456142,0.006003118585795164,0.005874456837773323,0.0058181011117994785,0.0057398914359509945,0.005683114752173424,0.005708527751266956,0.005563716869801283,0.005596759729087353,0.005544587969779968,0.005589677486568689,0.0055140601471066475,0.0054642572067677975,0.005502901040017605,0.005450932774692774,0.005399420391768217,0.005324472673237324,0.005327017977833748,0.005270776338875294,0.005306436214596033,0.0052982959896326065,0.005258453544229269,0.005227538291364908,0.005236308556050062,0.005140974652022123,0.005190594587475061,0.005120983347296715,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 37675     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 37676     
=================================================================
Total params: 75,351
Trainable params: 75,351
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 37,675
Trainable params: 37,675
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 37,676
Trainable params: 37,676
Non-trainable params: 0
_________________________________________________________________
