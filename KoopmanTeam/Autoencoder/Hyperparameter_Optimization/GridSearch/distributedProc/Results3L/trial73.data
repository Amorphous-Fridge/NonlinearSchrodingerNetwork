2021-06-26
loss,0.3364144563674927,0.08043333142995834,0.05051293224096298,0.054258715361356735,0.05690232291817665,0.04238145798444748,0.043485064059495926,0.04525339975953102,0.04474843665957451,0.04573529213666916,0.039968106895685196,0.02901531383395195,0.03277133032679558,0.037298306822776794,0.03390786051750183,0.030628230422735214,0.03022998385131359,0.027952319011092186,0.02969176135957241,0.031591013073921204,0.02785653993487358,0.026446456089615822,0.026158440858125687,0.03270548954606056,0.03201872855424881,0.02959456481039524,0.02455909736454487,0.02338571473956108,0.0221101026982069,0.022679291665554047,0.023389644920825958,0.02662593126296997,0.029685933142900467,0.02868948131799698,0.026468437165021896,0.023449014872312546,0.020599912852048874,0.018680470064282417,0.019567521288990974,0.023064445704221725,0.02315180003643036,0.021830754354596138,0.022556452080607414,0.025545619428157806,0.0228236336261034,0.021389678120613098,0.02028474025428295,0.020914917811751366,0.020927669480443,0.02037394978106022,0.021837256848812103,0.021967429667711258,0.02164539322257042,0.019536934792995453,0.018095307052135468,0.01663288287818432,0.01603545993566513,0.014712604694068432,0.01936374418437481,0.021469561383128166,0.01989438198506832,0.02312753163278103,0.019257424399256706,0.017735980451107025,0.015207840129733086,0.01394148264080286,0.017958955839276314,0.01973346248269081,0.019343238323926926,0.020128943026065826,0.017709199339151382,0.019204571843147278,0.017618535086512566,0.016520729288458824,0.015262119472026825,0.016555223613977432,0.020515158772468567,0.01820460334420204,0.01740896701812744,0.016073090955615044,0.014756206423044205,0.014306710101664066,0.013723139651119709,0.01451139897108078,0.018700499087572098,0.01695989817380905,0.01838754117488861,0.017479272559285164,0.016361188143491745,0.015178017318248749,0.016972851008176804,0.016154492273926735,0.013539385981857777,0.011466532945632935,0.013489391654729843,0.01634865254163742,0.014991078525781631,0.01477645430713892,0.01832098327577114,0.016310520470142365,
mse,0.044757939875125885,0.0022651103790849447,0.0008205579943023622,0.0008928955066949129,0.0009484013426117599,0.0005269000539556146,0.0005473701748996973,0.0005725832306779921,0.0005872954498045146,0.0005994752864353359,0.00045690828119404614,0.00024861772544682026,0.0003134695580229163,0.00039069223566912115,0.00033386627910658717,0.00027537011192180216,0.0002615860721562058,0.00022995691688265651,0.0002543460577726364,0.0002798760251607746,0.00022102578077465296,0.00019981421064585447,0.0002001314569497481,0.00031046909862197936,0.0003057992144022137,0.00025697468663565814,0.0001754012337187305,0.00015899172285571694,0.00014404307876247913,0.0001493931486038491,0.0001595166395418346,0.00020224267791491002,0.0002508539764676243,0.00023053419135976583,0.00019741458527278155,0.0001531533052911982,0.0001209516849485226,0.00010464945080457255,0.00011662027100101113,0.00016146976849995553,0.00015509480726905167,0.00013607805885840207,0.00014893864863552153,0.0001843734789872542,0.0001460195635445416,0.00012808205792680383,0.00011881574027938768,0.00012400020204950124,0.00012339344539213926,0.0001217461031046696,0.00013564020628109574,0.0001375981664750725,0.0001336173590971157,0.00010694328375393525,9.491514356341213e-05,8.226186037063599e-05,7.716911932220683e-05,6.45903346594423e-05,0.00011158272536704317,0.00012714011245407164,0.00011429517326178029,0.0001503414532635361,0.00010484284575795755,8.907628944143653e-05,7.005991210462525e-05,5.824198160553351e-05,9.553333802614361e-05,0.00010852976993191987,0.00010638485400704667,0.00011463620467111468,8.933894423535094e-05,0.0001027343823807314,9.072612738236785e-05,7.942654337966815e-05,7.043591904221103e-05,8.055056241573766e-05,0.00011523751891218126,9.202652290696278e-05,8.552533836336806e-05,7.443585491273552e-05,6.536752334795892e-05,6.206005491549149e-05,5.776295802206732e-05,6.473687244579196e-05,9.620553464628756e-05,8.086787420324981e-05,9.437114931643009e-05,8.64786998135969e-05,7.724604802206159e-05,6.728264270350337e-05,8.062399865593761e-05,7.256034587044269e-05,5.4665975767420605e-05,4.0599621570436284e-05,5.559667624766007e-05,7.49492974136956e-05,6.406087049981579e-05,6.453028618125245e-05,9.520823368802667e-05,7.57362722652033e-05,
mae,0.1429782211780548,0.034229084849357605,0.021611705422401428,0.022976789623498917,0.02400682121515274,0.017998533323407173,0.018449099734425545,0.0191565603017807,0.018893972039222717,0.01929791271686554,0.016988135874271393,0.012273754924535751,0.013979033567011356,0.015552669763565063,0.014247114770114422,0.013035864569246769,0.013035876676440239,0.012037456035614014,0.012531383894383907,0.013523740693926811,0.011885855346918106,0.011094467714428902,0.010995205491781235,0.013614249415695667,0.013314804993569851,0.01252136193215847,0.010433427058160305,0.009993573650717735,0.009326616302132607,0.009538829326629639,0.009881780482828617,0.011194335296750069,0.01254189107567072,0.012145076878368855,0.011218257248401642,0.0098505187779665,0.008807200938463211,0.007910315878689289,0.008223898708820343,0.009721468202769756,0.009725438430905342,0.00924824457615614,0.009500863030552864,0.010843046940863132,0.009782607667148113,0.009023549035191536,0.008566069416701794,0.008887377567589283,0.008822217583656311,0.008647546172142029,0.009201686829328537,0.009380669333040714,0.009237134829163551,0.008175642229616642,0.007416097447276115,0.006958997808396816,0.0067934379912912846,0.006233129650354385,0.008268814533948898,0.009068639017641544,0.00843792874366045,0.009820695966482162,0.007968166843056679,0.007458116393536329,0.006434069946408272,0.005904164165258408,0.0075335269793868065,0.008370717987418175,0.00819674413651228,0.008438336662948132,0.007519653998315334,0.00808927696198225,0.007363693322986364,0.007126041688024998,0.006474122405052185,0.0069463904947042465,0.008753451518714428,0.007728941272944212,0.00725376233458519,0.006836770102381706,0.006324170157313347,0.006101532373577356,0.005787037778645754,0.006125013343989849,0.00782803911715746,0.007152501493692398,0.007784751243889332,0.007407052908092737,0.006928371265530586,0.0064231581054627895,0.007207397371530533,0.006805486511439085,0.005655818618834019,0.004889510106295347,0.005724636372178793,0.006883583497256041,0.006261201109737158,0.006219683215022087,0.0078109935857355595,0.006892993580549955,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 37731     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 37732     
=================================================================
Total params: 75,463
Trainable params: 75,463
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 37,731
Trainable params: 37,731
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 37,732
Trainable params: 37,732
Non-trainable params: 0
_________________________________________________________________
