2021-06-26
loss,0.4686781167984009,0.13133969902992249,0.11615913361310959,0.08462228626012802,0.07181967049837112,0.06161186099052429,0.055806417018175125,0.05883720517158508,0.04779263958334923,0.043190859258174896,0.04666999354958534,0.03833824023604393,0.043470244854688644,0.03616533428430557,0.04269783943891525,0.03841487318277359,0.03783329948782921,0.03886568173766136,0.036867253482341766,0.035508397966623306,0.031677693128585815,0.028576357290148735,0.029735829681158066,0.03170133754611015,0.028416981920599937,0.02929788827896118,0.02612365409731865,0.02704932726919651,0.02392382174730301,0.023049836978316307,0.025997377932071686,0.024221524596214294,0.020185813307762146,0.021606002002954483,0.02487662062048912,0.024154221639037132,0.02152509242296219,0.022411100566387177,0.021975690498948097,0.01777176931500435,0.018825119361281395,0.019644739106297493,0.01885809190571308,0.020898757502436638,0.019923970103263855,0.017578424885869026,0.0195882860571146,0.019823241978883743,0.018242381513118744,0.015199047513306141,0.015692099928855896,0.0182376429438591,0.0177904199808836,0.016143018379807472,0.01810392178595066,0.01808151789009571,0.015385720878839493,0.017789805307984352,0.017579374834895134,0.015904387459158897,0.015128958970308304,0.014845972880721092,0.013577206060290337,0.015315852127969265,0.01849130354821682,0.017799483612179756,0.01565668173134327,0.014155352488160133,0.012748228386044502,0.01866328902542591,0.018052712082862854,0.016249284148216248,0.013407353311777115,0.013431441970169544,0.015440249815583229,0.01513681374490261,0.015162303112447262,0.01428814884275198,0.015559314750134945,0.015205154195427895,0.014508225955069065,0.015271004289388657,0.015551920048892498,0.01496050227433443,0.013198374770581722,0.012262355536222458,0.013256501406431198,0.014690258540213108,0.014258903451263905,0.013489242643117905,0.014808744192123413,0.014309059828519821,0.013535126112401485,0.013417606242001057,0.013145535252988338,0.013323214836418629,0.013225574046373367,0.013008356094360352,0.013430317863821983,0.014025883749127388,
mse,0.09586559236049652,0.0053411247208714485,0.004106974229216576,0.0020937982480973005,0.0015297665959224105,0.0011163563467562199,0.0009152577258646488,0.0009979300666600466,0.0006597451283596456,0.0005464993300847709,0.0006244049873203039,0.00043239115620963275,0.0005429832963272929,0.00038998411037027836,0.0005307025858201087,0.00043718513916246593,0.0004173888883087784,0.0004244753217790276,0.0003867320774588734,0.00036598186125047505,0.00029889136203564703,0.00024261727230623364,0.0002589355281088501,0.0002815223124343902,0.00023066738503985107,0.0002450999163556844,0.00019960972713306546,0.00021140907483641058,0.00016690618940629065,0.00015842242282815278,0.00019528612028807402,0.0001805514912120998,0.0001208025569212623,0.0001371318503515795,0.00017185443721245974,0.00016796175623312593,0.00013728653721045703,0.00014374818420037627,0.00013717697584070265,9.633464651415125e-05,0.00010954802564810961,0.0001133859041146934,0.00010239273979095742,0.0001243763108504936,0.00011191578232683241,9.233761375071481e-05,0.00011133308726130053,0.0001127431751228869,0.00010117111378349364,6.961853068787605e-05,7.508636190323159e-05,9.713279723655432e-05,9.259465150535107e-05,7.756943523418158e-05,9.385324665345252e-05,9.836698154686019e-05,7.176317012635991e-05,9.153664723271504e-05,8.655573037685826e-05,7.228786853374913e-05,6.471890810644254e-05,6.664519605692476e-05,5.5436241382267326e-05,7.106758857844397e-05,9.626129030948505e-05,8.837009954731911e-05,7.044813537504524e-05,5.805127875646576e-05,4.832434933632612e-05,0.00010066192771773785,9.309493179898709e-05,7.36130095901899e-05,5.470150790642947e-05,5.4719312174711376e-05,6.969180685700849e-05,6.776509690098464e-05,6.801665585953742e-05,6.11667928751558e-05,7.08606603438966e-05,6.698953075101599e-05,6.322978879325092e-05,6.801565905334428e-05,6.788880273234099e-05,6.480645970441401e-05,5.19865752721671e-05,4.6484885388053954e-05,5.32973681401927e-05,6.282384129008278e-05,5.932002022746019e-05,5.289418186293915e-05,6.225355173228309e-05,5.936033994657919e-05,5.4577300033997744e-05,5.4663698392687365e-05,5.1311235438333824e-05,5.2173956646583974e-05,5.175238402443938e-05,5.134803359396756e-05,5.335007153917104e-05,5.706008232664317e-05,
mae,0.20257358253002167,0.055889107286930084,0.04979337379336357,0.03609685227274895,0.030444324016571045,0.02623160369694233,0.023700647056102753,0.02487991377711296,0.020485591143369675,0.01829652674496174,0.019823890179395676,0.016286877915263176,0.01862196996808052,0.015647582709789276,0.018221227452158928,0.016359923407435417,0.01598324440419674,0.01664048247039318,0.015709910541772842,0.01507391408085823,0.013369042426347733,0.01211593858897686,0.01259199995547533,0.013422364369034767,0.011984467506408691,0.012396070174872875,0.011096818372607231,0.011484205722808838,0.010145633481442928,0.00980744045227766,0.011039500124752522,0.010205897502601147,0.008456232026219368,0.009111633524298668,0.010414502583444118,0.010218259878456593,0.009182002395391464,0.009384474717080593,0.009274651296436787,0.0076027000322937965,0.007978222332894802,0.008336465805768967,0.007956644520163536,0.008785512298345566,0.00845319963991642,0.00751514034345746,0.00833955779671669,0.008362147957086563,0.007736458908766508,0.006404065527021885,0.006677374709397554,0.007680231239646673,0.00747636565938592,0.006813889369368553,0.007703516632318497,0.007645178586244583,0.006546491757035255,0.007519398350268602,0.007359016686677933,0.006602766457945108,0.0063927145674824715,0.006339467596262693,0.005765172652900219,0.006453356705605984,0.007715095765888691,0.007540445774793625,0.006574913393706083,0.005944979842752218,0.005490888375788927,0.007894927635788918,0.007638877723366022,0.006838205270469189,0.005683381110429764,0.00572000490501523,0.006547319702804089,0.006388065870851278,0.006354274693876505,0.006100830622017384,0.006600814871490002,0.006501935888081789,0.00615017069503665,0.006464706268161535,0.006665813270956278,0.006288966163992882,0.005564448889344931,0.005296500399708748,0.005675535649061203,0.006221381481736898,0.006101371254771948,0.005708177573978901,0.0062550329603254795,0.006004608701914549,0.0057519590482115746,0.005550246685743332,0.00559209892526269,0.005637798458337784,0.005619601812213659,0.005493579898029566,0.005711877718567848,0.005913241300731897,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 149379    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 149380    
=================================================================
Total params: 298,759
Trainable params: 298,759
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 149,379
Trainable params: 149,379
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 149,380
Trainable params: 149,380
Non-trainable params: 0
_________________________________________________________________
