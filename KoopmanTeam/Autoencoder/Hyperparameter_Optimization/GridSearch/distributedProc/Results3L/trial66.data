2021-06-26
loss,0.3733937740325928,0.08080118149518967,0.07964165508747101,0.056213852018117905,0.05291134864091873,0.04836433380842209,0.040803298354148865,0.04731649532914162,0.04921763017773628,0.044995855540037155,0.05006536468863487,0.04144878312945366,0.04072233662009239,0.04345302656292915,0.03976498916745186,0.0312452744692564,0.035930391401052475,0.03973216563463211,0.032911404967308044,0.039517033845186234,0.032401394098997116,0.031776536256074905,0.02722753956913948,0.03279786929488182,0.029734697192907333,0.026695815846323967,0.02870330959558487,0.02469438873231411,0.025133166462183,0.029887989163398743,0.03030315600335598,0.025413352996110916,0.021999714896082878,0.021069517359137535,0.025669243186712265,0.023004431277513504,0.020323023200035095,0.02446531504392624,0.025047004222869873,0.023359091952443123,0.02256379835307598,0.022864658385515213,0.0237656831741333,0.02142392098903656,0.018871964886784554,0.018905725330114365,0.020313456654548645,0.018801385536789894,0.018898343667387962,0.02167871780693531,0.020540399476885796,0.018661459907889366,0.016548851504921913,0.019404171034693718,0.021310215815901756,0.018610425293445587,0.019509222358465195,0.016927510499954224,0.019447069615125656,0.018890032544732094,0.01784084364771843,0.01590815559029579,0.013637051917612553,0.01484079472720623,0.013122745789587498,0.015018395148217678,0.017828138545155525,0.01782376319169998,0.016162123531103134,0.016358979046344757,0.016234420239925385,0.018026139587163925,0.017137804999947548,0.01704176515340805,0.016772408038377762,0.016926851123571396,0.014726880006492138,0.013449396938085556,0.014562003314495087,0.01702088676393032,0.015254130586981773,0.012325188145041466,0.015132295899093151,0.013328909873962402,0.013517213985323906,0.01450299471616745,0.014682366512715816,0.013883679173886776,0.012053114362061024,0.014628509059548378,0.016201410442590714,0.015717636793851852,0.015492335893213749,0.014780358411371708,0.015543277375400066,0.016397403553128242,0.016213132068514824,0.014746244065463543,0.013592627830803394,0.012563538737595081,
mse,0.086632139980793,0.0019430838292464614,0.0019459228496998549,0.0009912550449371338,0.0008467272855341434,0.0006981375627219677,0.0004978966317139566,0.0006642250227741897,0.0007397957378998399,0.0006132309790700674,0.0007395872380584478,0.0005181827582418919,0.0004990561865270138,0.0005613187095150352,0.0004736818082164973,0.0002916960511356592,0.00038715070695616305,0.0004711359506472945,0.00032411166466772556,0.00047528010327368975,0.00031461913022212684,0.00031012314138934016,0.0002197187568526715,0.00031514037982560694,0.00026145385345444083,0.00021673271839972585,0.00024219017359428108,0.0001842686760937795,0.0001901224022731185,0.0002639911253936589,0.00026387552497908473,0.00019225165306124836,0.00014718320744577795,0.0001360008609481156,0.00019722836441360414,0.00015912074013613164,0.00012595541193149984,0.00017721133190207183,0.00018406880553811789,0.00016384101763833314,0.000149098428664729,0.0001546709827380255,0.00016590220911893994,0.00013570819282904267,0.0001094057151931338,0.00011157291010022163,0.00012320348469074816,0.00010578120418358594,0.00010981982632074505,0.00013920698256697506,0.0001228247710969299,0.0001046461402438581,8.260138565674424e-05,0.00011529370385687798,0.00013042622595094144,0.00010507796832825989,0.00011004118277924135,8.655004785396159e-05,0.00010987623682012782,0.00010285550524713472,9.239852079190314e-05,7.556815398856997e-05,5.7740966440178454e-05,6.697850039927289e-05,5.410795711213723e-05,7.273365918081254e-05,9.285719715990126e-05,9.30682072066702e-05,7.732436642982066e-05,7.868850661907345e-05,7.965089025674388e-05,9.232164302375168e-05,8.310403063660488e-05,8.228872320614755e-05,8.36435065139085e-05,8.41441287775524e-05,6.634536839555949e-05,5.6279175623785704e-05,6.338086677715182e-05,8.337353938259184e-05,6.866673356853426e-05,4.730793079943396e-05,7.151347381295636e-05,5.4612486565019935e-05,5.386502016335726e-05,6.204638339113444e-05,6.260627560550347e-05,5.809705180581659e-05,4.372516195871867e-05,6.24465465079993e-05,7.419495523208752e-05,7.314460526686162e-05,7.02104953234084e-05,6.483449396910146e-05,7.099859067238867e-05,7.743775495328009e-05,7.662086864002049e-05,6.355164077831432e-05,5.395913467509672e-05,4.512295708991587e-05,
mae,0.16176839172840118,0.03421938046813011,0.033388517796993256,0.0239933580160141,0.02245679683983326,0.020503435283899307,0.01722518354654312,0.020025864243507385,0.020849574357271194,0.01894957572221756,0.021348504349589348,0.017889253795146942,0.01738644763827324,0.018538035452365875,0.016803890466690063,0.013223775662481785,0.015202228911221027,0.01693497598171234,0.014082386158406734,0.01677069254219532,0.013742621056735516,0.013484295457601547,0.011616897769272327,0.013946512714028358,0.012765834107995033,0.011300654150545597,0.012151811271905899,0.010459802113473415,0.010706940665841103,0.012652101926505566,0.012834387831389904,0.01076921820640564,0.009358011186122894,0.008857096545398235,0.01086683850735426,0.00970951747149229,0.008633139543235302,0.01016281358897686,0.01075480692088604,0.009819929488003254,0.009561817161738873,0.009597343392670155,0.009947908110916615,0.009110933169722557,0.008009531535208225,0.008092917501926422,0.008612501434981823,0.008021615445613861,0.008135892450809479,0.009175542742013931,0.00864358153194189,0.00792300421744585,0.006993556395173073,0.008208109997212887,0.008882946334779263,0.007939771749079227,0.008274688385426998,0.00706947548314929,0.008240948431193829,0.008020302280783653,0.007517760619521141,0.00680018262937665,0.0057975188829004765,0.006284978240728378,0.005561645142734051,0.00619682390242815,0.0075639886781573296,0.007541352417320013,0.0069052171893417835,0.006932596676051617,0.006914817728102207,0.007630312815308571,0.0072279684245586395,0.0071779037825763226,0.007090685423463583,0.007153000216931105,0.006214717403054237,0.0057416073977947235,0.006217018235474825,0.0071682701818645,0.0063926223665475845,0.00521064642816782,0.006458454765379429,0.005435675382614136,0.005758125334978104,0.006170549429953098,0.006173314526677132,0.005862345919013023,0.005151507444679737,0.0061356667429208755,0.006835780572146177,0.006717042997479439,0.006523075047880411,0.006196152418851852,0.006649683695286512,0.006982379127293825,0.0069405739195644855,0.006228727288544178,0.005657287314534187,0.005315161310136318,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 140883    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 140884    
=================================================================
Total params: 281,767
Trainable params: 281,767
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 140,883
Trainable params: 140,883
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 140,884
Trainable params: 140,884
Non-trainable params: 0
_________________________________________________________________
