2021-06-26
loss,0.34673163294792175,0.1042109876871109,0.06892117857933044,0.055530428886413574,0.04794272407889366,0.04383770003914833,0.04708787053823471,0.044142745435237885,0.04725146293640137,0.04906865209341049,0.04176425561308861,0.03806651756167412,0.04745442792773247,0.0406370684504509,0.037370868027210236,0.0575619600713253,0.05383170768618584,0.04681224375963211,0.042929064482450485,0.045784879475831985,0.039615195244550705,0.030662408098578453,0.027512216940522194,0.03276130184531212,0.03157060965895653,0.028852587565779686,0.027628762647509575,0.038580361753702164,0.04289204627275467,0.038544923067092896,0.03593093529343605,0.033776022493839264,0.031532272696495056,0.02809477597475052,0.024696828797459602,0.025369539856910706,0.03415575623512268,0.030459566041827202,0.026574168354272842,0.024328792467713356,0.02334304340183735,0.0250600166618824,0.03294655680656433,0.029877152293920517,0.025802839547395706,0.023232270032167435,0.021979646757245064,0.021049952134490013,0.019405383616685867,0.020104389637708664,0.02175498753786087,0.03163772448897362,0.027392501011490822,0.027284128591418266,0.023693112656474113,0.023302605375647545,0.025544967502355576,0.022357046604156494,0.02103807032108307,0.020227055996656418,0.02278931438922882,0.02710571512579918,0.02453548274934292,0.022246260195970535,0.0242321640253067,0.024632375687360764,0.02176574617624283,0.023161107674241066,0.021280622109770775,0.019288580864667892,0.017918623983860016,0.017328696325421333,0.01658487133681774,0.016182156279683113,0.01564858853816986,0.01516756135970354,0.01618816703557968,0.01703472249209881,0.014494290575385094,0.013690555468201637,0.013258542865514755,0.012944203801453114,0.012862419709563255,0.012664751149713993,0.012648724019527435,0.012439122423529625,0.012318598106503487,0.012315098196268082,0.012208927422761917,0.012044195085763931,0.01191023550927639,0.011890175752341747,0.011880666948854923,0.011674651876091957,0.011699432507157326,0.011663908138871193,0.011423365212976933,0.011515366844832897,0.011428347788751125,0.011322197504341602,
mse,0.05178457871079445,0.003546112449839711,0.0014817186165601015,0.0009458145359531045,0.0006877260166220367,0.0005574206006713212,0.0007061447249725461,0.0006054562982171774,0.0007115097832866013,0.0007540041697211564,0.0004933468298986554,0.00042112887604162097,0.000634601863566786,0.0004656797682400793,0.0004037916660308838,0.0009633360896259546,0.0008340707281604409,0.0006289692828431726,0.000547185365576297,0.0005920174880884588,0.0004630794283002615,0.0002714338479563594,0.0002218051376985386,0.000301984982797876,0.00028276967350393534,0.00023888371651992202,0.00021946715423837304,0.0004586191207636148,0.000518203538376838,0.00042532701627351344,0.0003708158328663558,0.00032399490009993315,0.0002828789292834699,0.00022437144070863724,0.00017224486509803683,0.00018725142581388354,0.0003341906995046884,0.0002570085343904793,0.00019710049673449248,0.00016896471788641065,0.00015478848945349455,0.0001880137133412063,0.0003024053876288235,0.00025497807655483484,0.00018509490473661572,0.00015370342589449137,0.00013859232421964407,0.00012844214506912977,0.00011243196058785543,0.00012272574531380087,0.00014246691716834903,0.00027560535818338394,0.00021099785226397216,0.00020759897597599775,0.00015968734805937856,0.00015124563651625067,0.00017793236474972218,0.0001392140256939456,0.0001246935862582177,0.00012372751371003687,0.00015354095376096666,0.00020626987679861486,0.0001693314261501655,0.0001414249709341675,0.00016462098574265838,0.00016943819355219603,0.00013457689783535898,0.00014835545152891427,0.00012794318899977952,0.00010598666267469525,9.174623846774921e-05,8.587427146267146e-05,7.917762559372932e-05,7.602034020237625e-05,7.133802864700556e-05,6.698200013488531e-05,7.966933480929583e-05,9.089273225981742e-05,6.293247133726254e-05,5.314719965099357e-05,4.9921472964342684e-05,4.8177338612731546e-05,4.738862480735406e-05,4.709686618298292e-05,4.5776934712193906e-05,4.463253208086826e-05,4.3898635340156034e-05,4.340419400250539e-05,4.2790099541889504e-05,4.155480201006867e-05,4.110311783733778e-05,4.092236849828623e-05,4.006682866020128e-05,3.936484790756367e-05,3.875913535011932e-05,3.84373779525049e-05,3.7530360714299604e-05,3.7900852476013824e-05,3.727264629560523e-05,3.6669665860245004e-05,
mae,0.14055834710597992,0.043573640286922455,0.029120251536369324,0.023837782442569733,0.02049790695309639,0.01893368363380432,0.019948063418269157,0.01887439377605915,0.020127851516008377,0.020635854452848434,0.018260953947901726,0.016299545764923096,0.02024265006184578,0.017598312348127365,0.016028352081775665,0.024468906223773956,0.023067200556397438,0.02053171396255493,0.0187812689691782,0.019994942471385002,0.017201796174049377,0.013211019337177277,0.011960859410464764,0.013897661119699478,0.013578547164797783,0.012394113466143608,0.011918626725673676,0.0169425867497921,0.01874336414039135,0.016926651820540428,0.0156830083578825,0.014623455703258514,0.013813636265695095,0.011722017079591751,0.010138081386685371,0.01067267544567585,0.014949053525924683,0.012719857506453991,0.011100418865680695,0.01027095876634121,0.010260695591568947,0.010716311633586884,0.014542914927005768,0.013476783409714699,0.011075935326516628,0.009564238600432873,0.00897496473044157,0.008713314309716225,0.008346096612513065,0.008498545736074448,0.0092970822006464,0.013774615712463856,0.011792545206844807,0.01182864885777235,0.01012568548321724,0.009962700307369232,0.01099424809217453,0.009135638363659382,0.008623987436294556,0.008550134487450123,0.009453034028410912,0.011749988421797752,0.010657398961484432,0.009506701491773129,0.010397992096841335,0.01086392905563116,0.009486931376159191,0.009765798225998878,0.009119337424635887,0.007899550721049309,0.0074480269104242325,0.007346412632614374,0.007043894380331039,0.006908152252435684,0.006698573939502239,0.006497263442724943,0.006854907143861055,0.0072326743975281715,0.006239541340619326,0.0059419963508844376,0.005714145954698324,0.0055472105741500854,0.005530005786567926,0.00540251424536109,0.005394924432039261,0.005358505994081497,0.005254728719592094,0.005275125615298748,0.005193411838263273,0.005166362039744854,0.005095605738461018,0.005115768406540155,0.005101913586258888,0.005020198877900839,0.005055292975157499,0.00505168316885829,0.004911807365715504,0.004951095674186945,0.004941465333104134,0.004844900220632553,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 12771     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 12772     
=================================================================
Total params: 25,543
Trainable params: 25,543
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 12,771
Trainable params: 12,771
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 12,772
Trainable params: 12,772
Non-trainable params: 0
_________________________________________________________________
