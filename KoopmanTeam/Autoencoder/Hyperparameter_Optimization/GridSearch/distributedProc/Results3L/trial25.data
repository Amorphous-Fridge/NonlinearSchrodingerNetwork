2021-06-26
loss,0.27774855494499207,0.08739151060581207,0.055959925055503845,0.05529423803091049,0.06495291739702225,0.058147281408309937,0.05835086852312088,0.05261976271867752,0.04430093243718147,0.038143765181303024,0.034839361906051636,0.030483022332191467,0.02868625335395336,0.027578027918934822,0.02632683701813221,0.025631025433540344,0.02484184317290783,0.024132464081048965,0.024020493030548096,0.023467253893613815,0.023096539080142975,0.02278914675116539,0.022526010870933533,0.02202155999839306,0.02191990055143833,0.02133060060441494,0.02120841108262539,0.021035287529230118,0.020632736384868622,0.02061527967453003,0.02021164819598198,0.020208515226840973,0.0198591947555542,0.019613953307271004,0.01951875537633896,0.019480613991618156,0.019354302436113358,0.01902453415095806,0.018789956346154213,0.018617192283272743,0.018487364053726196,0.018201710656285286,0.018157409504055977,0.017857838422060013,0.01783754676580429,0.01747559942305088,0.017422320321202278,0.017295407131314278,0.01730821654200554,0.01707649976015091,0.01700437441468239,0.016758406534790993,0.016824835911393166,0.016501780599355698,0.016512347385287285,0.016290005296468735,0.01628853753209114,0.01609383150935173,0.016062267124652863,0.015841538086533546,0.01707340031862259,0.017631445080041885,0.018790362402796745,0.020414123311638832,0.02812851406633854,0.025532927364110947,0.023154648020863533,0.02250504307448864,0.02590092457830906,0.025444600731134415,0.028751390054821968,0.023993371054530144,0.02101399376988411,0.01950138248503208,0.018134139478206635,0.017214249819517136,0.016605418175458908,0.017451900988817215,0.025818075984716415,0.026573682203888893,0.024017803370952606,0.024389486759901047,0.02433861419558525,0.02203414961695671,0.02088099531829357,0.01990908570587635,0.019262881949543953,0.018334869295358658,0.017733799293637276,0.017229914665222168,0.016690123826265335,0.016462653875350952,0.019984636455774307,0.021548140794038773,0.019793502986431122,0.018748896196484566,0.01782902702689171,0.016907785087823868,0.016179874539375305,0.015557190403342247,
mse,0.0336492545902729,0.0024221371859312057,0.0009682111558504403,0.0009183324873447418,0.0012050900841131806,0.0009696414927020669,0.0009760521352291107,0.0007924028323031962,0.0005424801493063569,0.00041405658703297377,0.00034371792571619153,0.00026163581060245633,0.00023108057212084532,0.000212022103369236,0.00019373843679204583,0.00018321428797207773,0.00017095357179641724,0.00016145402332767844,0.00015906682529021055,0.00015310918388422579,0.00014669803204014897,0.00014321990602184087,0.0001395220315316692,0.0001328462385572493,0.00013201383990235627,0.00012598700413946062,0.00012501254968810827,0.00012198741751490161,0.0001189188114949502,0.00011742667993530631,0.00011288355744909495,0.00011189175711479038,0.00010867400123970583,0.00010742016456788406,0.00010738768469309434,0.00010641407425282523,0.00010255784582113847,9.92386121652089e-05,9.786043665371835e-05,9.56320291152224e-05,9.3582428235095e-05,9.07966386876069e-05,9.054731344804168e-05,8.720378536963835e-05,8.759208139963448e-05,8.491170592606068e-05,8.40970897115767e-05,8.323609654325992e-05,8.255469583673403e-05,8.125966269290075e-05,7.948634447529912e-05,7.77649474912323e-05,7.73747669882141e-05,7.527394336648285e-05,7.485928654205054e-05,7.305244798772037e-05,7.358058064710349e-05,7.14498310117051e-05,7.142745016608387e-05,7.127258868422359e-05,8.593317033955827e-05,9.2008885985706e-05,0.00010662619752110913,0.00012354104546830058,0.00022705629817210138,0.00017947860760614276,0.00015103790792636573,0.0001505611144239083,0.00019485237135086209,0.00018161973275709897,0.00022581424855161458,0.00015966975479386747,0.0001218577817780897,0.00010554483742453158,9.24216874409467e-05,8.344182424480096e-05,7.747275230940431e-05,8.818561036605388e-05,0.00019056488235946745,0.000192988125490956,0.00016062102804426104,0.0001648317847866565,0.0001612926134839654,0.00013400515308603644,0.00012167559179943055,0.00011069510219385847,0.00010374137491453439,9.338894597021863e-05,8.776657341513783e-05,8.268288365798071e-05,7.836857548682019e-05,7.719602581346408e-05,0.00011382914090063423,0.00012631324352696538,0.00010826032666955143,9.816705278353766e-05,8.966319001046941e-05,8.075372170424089e-05,7.469673437299207e-05,6.993547867750749e-05,
mae,0.11721447110176086,0.037043455988168716,0.023759376257658005,0.02354217693209648,0.02719150483608246,0.024969927966594696,0.024870671331882477,0.022583559155464172,0.018145810812711716,0.01596844010055065,0.014828295446932316,0.012953974306583405,0.012198307551443577,0.011723600327968597,0.011213746853172779,0.010858372785151005,0.010593767277896404,0.010264859534800053,0.010252480395138264,0.009985130280256271,0.009783795103430748,0.009725792333483696,0.00945988018065691,0.009384693577885628,0.009352531284093857,0.009092134423553944,0.009020001627504826,0.008952944539487362,0.008750761859118938,0.00871368870139122,0.008529440499842167,0.008586626499891281,0.008484769612550735,0.008250459097325802,0.008215854875743389,0.008242828771471977,0.00817304290831089,0.00802572350949049,0.00807556789368391,0.007925471290946007,0.007904961705207825,0.007775778882205486,0.007672060281038284,0.007604868616908789,0.007672216277569532,0.007486492395401001,0.007493707351386547,0.007413981482386589,0.007326178718358278,0.0072192298248410225,0.007217694073915482,0.0071592205204069614,0.007177817169576883,0.006976785603910685,0.007000066805630922,0.006913638208061457,0.00691495044156909,0.006856640800833702,0.006809956394135952,0.006734637543559074,0.00717887980863452,0.007506613619625568,0.008046803995966911,0.008657058700919151,0.012104497291147709,0.011196648702025414,0.009972352534532547,0.009546617045998573,0.01101973932236433,0.010849389247596264,0.01221062894910574,0.010067331604659557,0.008867989294230938,0.008231169544160366,0.0077714682556688786,0.0073929294012486935,0.00710277259349823,0.007391622755676508,0.010952625423669815,0.011386080645024776,0.009956743568181992,0.010369776748120785,0.010600523091852665,0.009733075276017189,0.009140925481915474,0.00855439156293869,0.00821369607001543,0.007648186758160591,0.007370687555521727,0.007145541254431009,0.006989338435232639,0.006929907947778702,0.008461968041956425,0.00914691761136055,0.00853266753256321,0.008156687021255493,0.007832410745322704,0.00742828706279397,0.00690876878798008,0.006481291726231575,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 12835     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 12836     
=================================================================
Total params: 25,671
Trainable params: 25,671
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 12,835
Trainable params: 12,835
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 12,836
Trainable params: 12,836
Non-trainable params: 0
_________________________________________________________________
