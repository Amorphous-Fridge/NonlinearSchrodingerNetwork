2021-06-26
loss,0.33188509941101074,0.09008428454399109,0.06884143501520157,0.060605354607105255,0.06626841425895691,0.049802374094724655,0.044050559401512146,0.03670920431613922,0.03830555081367493,0.03154303506016731,0.03464394435286522,0.037030402570962906,0.03373170271515846,0.03463489189743996,0.037271805107593536,0.03625873476266861,0.02972451038658619,0.02394648641347885,0.030251985415816307,0.032599616795778275,0.03422345221042633,0.03148874640464783,0.02912553772330284,0.024675939232110977,0.028992634266614914,0.02848443202674389,0.027329277247190475,0.027172906324267387,0.029440490528941154,0.027169039472937584,0.02818608097732067,0.025619568303227425,0.023872585967183113,0.02477618306875229,0.018454695120453835,0.019188230857253075,0.020181018859148026,0.018025439232587814,0.027376390993595123,0.02319566160440445,0.02112470380961895,0.020290136337280273,0.020315324887633324,0.023982148617506027,0.023790452629327774,0.022910159081220627,0.020884165540337563,0.020631149411201477,0.021343376487493515,0.019835494458675385,0.019568216055631638,0.02014879137277603,0.019736144691705704,0.01910790428519249,0.018901286646723747,0.020633604377508163,0.01944233849644661,0.016839925199747086,0.016587242484092712,0.016601286828517914,0.016526293009519577,0.017109133303165436,0.018123196437954903,0.01865980215370655,0.01631946675479412,0.01726388745009899,0.017287058755755424,0.015100028365850449,0.014599391259253025,0.01826462149620056,0.016979120671749115,0.01645663008093834,0.01442624256014824,0.015774616971611977,0.014517074450850487,0.016110308468341827,0.015663446858525276,0.0160587839782238,0.01624637469649315,0.015819964930415154,0.016405737027525902,0.017504511401057243,0.01493116095662117,0.012576132081449032,0.011598467826843262,0.01174332108348608,0.013504666276276112,0.015177947469055653,0.01370580866932869,0.015976740047335625,0.014528450556099415,0.01415505912154913,0.015680115669965744,0.016047293320298195,0.014385301619768143,0.012874376960098743,0.0111197205260396,0.011367308907210827,0.013436130248010159,0.012703776359558105,
mse,0.04335573688149452,0.0026124692521989346,0.0013703475706279278,0.0010554332984611392,0.0012848026817664504,0.0007086410187184811,0.0005800074432045221,0.00039707368705421686,0.0004234020016156137,0.000293455901555717,0.00035492778988555074,0.00039656608714722097,0.00033838750096037984,0.00034864217741414905,0.0004136177012696862,0.0003740050015039742,0.00026506700669415295,0.00016836458235047758,0.0002799219510052353,0.0003051666426472366,0.0003359559632372111,0.0002783206000458449,0.00023819140915293247,0.00017806023242883384,0.00024033877707552165,0.00023040661471895874,0.00021753140026703477,0.0002110730274580419,0.0002499392139725387,0.0002080323320114985,0.0002201717725256458,0.0001850338449003175,0.00016930415586102754,0.00018010215717367828,0.00010790809756144881,0.00011085953883593902,0.00012176546442788094,9.558034071233124e-05,0.00020627772028092295,0.0001508984132669866,0.0001320875744568184,0.0001274018723051995,0.00012117304868297651,0.0001604954741196707,0.00015803544374648482,0.00014726558583788574,0.00012360700930003077,0.00012223962403368205,0.00013122116797603667,0.00011337424803059548,0.00011130882194265723,0.00011695565626723692,0.00010991678573191166,0.00010459726036060601,0.00010351449600420892,0.00012134997814428061,0.00010920690692728385,8.312410500366241e-05,8.086244633886963e-05,8.179683209164068e-05,7.97398024587892e-05,8.70793592184782e-05,9.340875840280205e-05,9.938640869222581e-05,7.82058050390333e-05,8.440525562036783e-05,8.383748354390264e-05,6.892232340760529e-05,6.507078069262207e-05,9.40497120609507e-05,8.200910815503448e-05,7.735031249467283e-05,6.249709258554503e-05,7.224392174975947e-05,6.357642996590585e-05,7.557983190054074e-05,7.130938320187852e-05,7.400547474389896e-05,7.474310405086726e-05,7.049846317386255e-05,7.702281436650082e-05,8.529130718670785e-05,6.440951256081462e-05,4.6700588427484035e-05,4.031805292470381e-05,4.129783337702975e-05,5.5601674830541015e-05,6.770157779101282e-05,5.6142500397982076e-05,7.272910443134606e-05,6.077907528379001e-05,5.7781333453021944e-05,7.082155207172036e-05,7.16273279977031e-05,5.953610525466502e-05,4.812098268303089e-05,3.8392656279029325e-05,3.935836866730824e-05,5.3165480494499207e-05,4.7739547881064937e-05,
mae,0.1419752687215805,0.039092883467674255,0.02942799963057041,0.02616119384765625,0.02873922884464264,0.02139122039079666,0.01874726451933384,0.015626078471541405,0.016296228393912315,0.013374635949730873,0.014748232439160347,0.015748651698231697,0.014335897751152515,0.014707443304359913,0.016133775934576988,0.015306326560676098,0.012707160785794258,0.010120953433215618,0.01296618115156889,0.013854552060365677,0.014566865749657154,0.013434338383376598,0.01236859429627657,0.010472791269421577,0.012344849295914173,0.012084837071597576,0.011559626087546349,0.01139905583113432,0.012631658464670181,0.011764878407120705,0.01201364304870367,0.010863278061151505,0.010111365467309952,0.010603617876768112,0.008017106913030148,0.00811533723026514,0.008504804223775864,0.007629353553056717,0.011595799587666988,0.009765229187905788,0.008959691971540451,0.008544662967324257,0.008627685718238354,0.010154958814382553,0.010132228955626488,0.009709996171295643,0.008662588894367218,0.008764299564063549,0.009109382517635822,0.008427862077951431,0.008380484767258167,0.00858347024768591,0.008180723525583744,0.008062024600803852,0.007982979528605938,0.00878202822059393,0.00821742508560419,0.007130675483494997,0.0071318428963422775,0.0070205614902079105,0.007034719455987215,0.007272633258253336,0.007732084486633539,0.007864742539823055,0.006919035222381353,0.007333613000810146,0.007377231027930975,0.006517354398965836,0.006264207884669304,0.007852606475353241,0.007164623588323593,0.006972623988986015,0.006209171377122402,0.006698200479149818,0.006191564723849297,0.006837200373411179,0.006517766043543816,0.006782038137316704,0.00687043834477663,0.006722767371684313,0.007010384928435087,0.007426497992128134,0.006281407084316015,0.005380250047892332,0.004999774508178234,0.005006846971809864,0.005646843463182449,0.0064696865156292915,0.005727454554289579,0.0067937434650957584,0.00613710843026638,0.006085623521357775,0.006591695360839367,0.006821002811193466,0.005956618580967188,0.00537386117503047,0.004705325234681368,0.0048376331105828285,0.0056944130919873714,0.005371016915887594,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 41891     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 41892     
=================================================================
Total params: 83,783
Trainable params: 83,783
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 41,891
Trainable params: 41,891
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 41,892
Trainable params: 41,892
Non-trainable params: 0
_________________________________________________________________
