2021-06-26
loss,0.34224075078964233,0.08351244777441025,0.06759413331747055,0.06513053178787231,0.05925393104553223,0.0460071861743927,0.039873044937849045,0.04831693693995476,0.037485696375370026,0.044964347034692764,0.04243619740009308,0.04151134938001633,0.03769731894135475,0.027925945818424225,0.040882498025894165,0.029769528657197952,0.03219650313258171,0.03468357026576996,0.03392723202705383,0.03141750022768974,0.02846848964691162,0.02735447697341442,0.02906123176217079,0.026124892756342888,0.02638533152639866,0.02571943774819374,0.03203275799751282,0.02837502956390381,0.027534237131476402,0.026236822828650475,0.025920234620571136,0.02432294376194477,0.023437127470970154,0.02611088752746582,0.023098163306713104,0.02178969420492649,0.021369842812418938,0.022084230557084084,0.016676675528287888,0.016071442514657974,0.017806928604841232,0.02445688284933567,0.022733481600880623,0.021067047491669655,0.021127061918377876,0.019860822707414627,0.019621115177869797,0.018950117751955986,0.01809818297624588,0.01713222824037075,0.01685025542974472,0.020221982151269913,0.01665307581424713,0.019483918324112892,0.018427008762955666,0.01839347369968891,0.019294971600174904,0.017213081941008568,0.017722435295581818,0.015931295230984688,0.01533577125519514,0.01745685189962387,0.0169245395809412,0.017013216391205788,0.01772058755159378,0.01658713072538376,0.01785263419151306,0.014495649375021458,0.01434911135584116,0.015143568627536297,0.016201119869947433,0.017666159197688103,0.015345791354775429,0.013542523607611656,0.01222373265773058,0.011450197547674179,0.014129788614809513,0.014816117472946644,0.017037399113178253,0.01610378548502922,0.0146348737180233,0.012806062586605549,0.012102394364774227,0.013873512856662273,0.015037712641060352,0.014728674665093422,0.015332727693021297,0.014115110971033573,0.014609862118959427,0.015954429283738136,0.014082417823374271,0.0126699423417449,0.013813343830406666,0.01444301288574934,0.01393002737313509,0.013831921853125095,0.01350705698132515,0.013146944344043732,0.013993832282721996,0.014104396104812622,
mse,0.06230154633522034,0.0020792901050299406,0.0013439776375889778,0.0012657627230510116,0.0011194051476195455,0.0006293816841207445,0.00046414294047281146,0.0006793501088395715,0.0004077199846506119,0.00057394546456635,0.0005101177375763655,0.0004868177929893136,0.0004160395765211433,0.00023224519100040197,0.0004672135110013187,0.00025927351089194417,0.00029356073355302215,0.0003408411575946957,0.00032517005456611514,0.00027819190290756524,0.00023687139037065208,0.00021654815645888448,0.00023697868164163083,0.00020085202413611114,0.00019831264216918498,0.00019042585336137563,0.00029156910022720695,0.0002291532582603395,0.0002159891155315563,0.00019921733473893255,0.00018758786609396338,0.00016918146866373718,0.00015791080659255385,0.00019289099145680666,0.00015059698489494622,0.00013797558494843543,0.00013434865104500204,0.00014136562822386622,8.331905701197684e-05,7.895053568063304e-05,9.690295701147988e-05,0.00016542612866032869,0.00014384249516297132,0.00012643932132050395,0.00012506163329817355,0.00011225153866689652,0.00011003985127899796,0.0001009201878332533,9.486105409450829e-05,8.677146979607642e-05,8.201639138860628e-05,0.00011379451461834833,8.016137144295499e-05,0.00010894155275309458,9.630811109673232e-05,9.844918531598523e-05,0.00010544208635110408,8.48311246954836e-05,8.79960207385011e-05,7.329145591938868e-05,6.928014772711322e-05,8.556702960049734e-05,8.107912435662001e-05,8.234817505581304e-05,8.68100396473892e-05,7.781084423186257e-05,8.91718445927836e-05,6.255343760130927e-05,6.045996633474715e-05,6.74333714414388e-05,7.481276406906545e-05,8.759046613704413e-05,6.648461567237973e-05,5.375909313443117e-05,4.4465741666499525e-05,3.895905683748424e-05,5.9117744967807084e-05,6.392928480636328e-05,8.195575355784968e-05,7.218830432975665e-05,5.965944365016185e-05,4.8329024139093235e-05,4.3576612370088696e-05,5.708742901333608e-05,6.564705836353824e-05,6.244380347197875e-05,6.632583244936541e-05,5.852968752151355e-05,6.144616781966761e-05,7.108302816050127e-05,5.560932549997233e-05,4.742159944726154e-05,5.5216285545611754e-05,5.844128463650122e-05,5.4797808843431994e-05,5.5359610996674746e-05,5.3626237786374986e-05,5.07032273162622e-05,5.637923823087476e-05,5.571067231358029e-05,
mae,0.1463046669960022,0.03538013622164726,0.0285932756960392,0.02778906188905239,0.02504352480173111,0.019494863227009773,0.016839202493429184,0.020384512841701508,0.015901563689112663,0.019174618646502495,0.018263570964336395,0.01782994344830513,0.015962718054652214,0.011922755278646946,0.017430733889341354,0.01262882724404335,0.01364219281822443,0.014725386165082455,0.01435793749988079,0.013414821587502956,0.012102805078029633,0.01162038091570139,0.012387664057314396,0.011110255494713783,0.011166160926222801,0.010929977521300316,0.01351779606193304,0.012059480883181095,0.01173685397952795,0.011102224700152874,0.01110280491411686,0.010295496322214603,0.009911117143929005,0.011143096722662449,0.009670631028711796,0.009317952208220959,0.00918236467987299,0.009411306120455265,0.007094183005392551,0.006843249779194593,0.007562278304249048,0.010425032116472721,0.009685534983873367,0.008927248418331146,0.0089246965944767,0.008528176695108414,0.008357176557183266,0.008026450872421265,0.007657581940293312,0.007275104522705078,0.007226527202874422,0.0086200051009655,0.007011780049651861,0.008197087794542313,0.007840768434107304,0.007789335213601589,0.008110913448035717,0.007331401575356722,0.007479825988411903,0.0066911871545016766,0.006487222854048014,0.00735919876024127,0.007151786237955093,0.007251511327922344,0.007518210913985968,0.007013856898993254,0.007594401016831398,0.006197309121489525,0.0060941362753510475,0.006520296912640333,0.0067948088981211185,0.007429224904626608,0.006429016124457121,0.005761368665844202,0.005212315823882818,0.004812067840248346,0.005955841392278671,0.0062590898014605045,0.007208897266536951,0.006827501580119133,0.00616113469004631,0.005453888326883316,0.005140517372637987,0.005859981290996075,0.006275740452110767,0.006259094458073378,0.006462544668465853,0.006009829230606556,0.006214137654751539,0.006718222983181477,0.0059513067826628685,0.005357932299375534,0.005831385962665081,0.006076210644096136,0.005903028417378664,0.005910819862037897,0.005719474982470274,0.005598241463303566,0.005930690094828606,0.006033857353031635,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 50307     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 50308     
=================================================================
Total params: 100,615
Trainable params: 100,615
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 50,307
Trainable params: 50,307
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 50,308
Trainable params: 50,308
Non-trainable params: 0
_________________________________________________________________
