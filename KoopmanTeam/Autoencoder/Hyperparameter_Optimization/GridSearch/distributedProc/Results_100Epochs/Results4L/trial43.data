2021-06-26
loss,0.4980216324329376,0.28772827982902527,0.24692918360233307,0.2281007319688797,0.18495945632457733,0.15547910332679749,0.1242147833108902,0.12012726068496704,0.10985416173934937,0.09122559428215027,0.0892704501748085,0.08507435023784637,0.07966018468141556,0.07120925188064575,0.07421129941940308,0.06462642550468445,0.05834995582699776,0.040998391807079315,0.05305171385407448,0.05642867460846901,0.04821167141199112,0.05560799688100815,0.05277528241276741,0.04568694159388542,0.04928478226065636,0.043524935841560364,0.04240845516324043,0.03608126565814018,0.03783855214715004,0.028882570564746857,0.027483517304062843,0.026599444448947906,0.028601502999663353,0.030925681814551353,0.03419594466686249,0.03706881403923035,0.04288943111896515,0.03471327945590019,0.037674374878406525,0.037322718650102615,0.03129063919186592,0.03338925912976265,0.03701508417725563,0.03220602869987488,0.03082514926791191,0.029698025435209274,0.03373732045292854,0.029884101822972298,0.033197205513715744,0.028250228613615036,0.029474414885044098,0.028514394536614418,0.02922835573554039,0.026614926755428314,0.029672326520085335,0.026981959119439125,0.027116121724247932,0.024677591398358345,0.024954281747341156,0.02937101572751999,0.02518715150654316,0.02591353841125965,0.02757318690419197,0.026094716042280197,0.023957431316375732,0.02422097511589527,0.025981135666370392,0.025434548035264015,0.022636739537119865,0.021025298163294792,0.022911692038178444,0.02496943436563015,0.022178715094923973,0.020546365529298782,0.019856907427310944,0.021893085911870003,0.02322639711201191,0.024938322603702545,0.02332775853574276,0.02092406526207924,0.02143479883670807,0.02214621566236019,0.022955188527703285,0.02096663787961006,0.020779432728886604,0.019687466323375702,0.01864684745669365,0.017768127843737602,0.016122257336974144,0.015056556090712547,0.020828330889344215,0.016869056969881058,0.020810827612876892,0.022493038326501846,0.023928098380565643,0.022253334522247314,0.020109498873353004,0.018972212448716164,0.017693201079964638,0.018139228224754333,
mse,0.09522984176874161,0.025937804952263832,0.0201587937772274,0.017111051827669144,0.010741212405264378,0.007019458804279566,0.004555949941277504,0.004207933787256479,0.003509619738906622,0.002476403024047613,0.0024049270432442427,0.002034432254731655,0.001825910061597824,0.0014805856626480818,0.0016078789485618472,0.0011676070280373096,0.0010120582301169634,0.0005179898580536246,0.0008029417949728668,0.0009006477775983512,0.000658289878629148,0.0008734806906431913,0.0007766096387058496,0.0005960983689874411,0.0006905137561261654,0.0005432322504930198,0.0005150132346898317,0.00038031142321415246,0.0004102399980183691,0.00025051998090930283,0.0002254627615911886,0.00020314345601946115,0.0002393529430264607,0.0002851321187335998,0.000340201222570613,0.0004021014319732785,0.0005370486178435385,0.0003491679090075195,0.0004053536686114967,0.00039050690247677267,0.00028352925437502563,0.00032480404479429126,0.00038681659498251975,0.00030007847817614675,0.0002736045280471444,0.00025420135352760553,0.0003214705502614379,0.00025236603687517345,0.00031125376699492335,0.00022969568090047687,0.0002474033972248435,0.00022671087936032563,0.00024140081950463355,0.00020563790167216212,0.0002486125158611685,0.00020375959866214544,0.0002010015450650826,0.00016868140664882958,0.0001779142185114324,0.0002499240217730403,0.00018605847435537726,0.00019179000810254365,0.0002145697217201814,0.0001934613101184368,0.00016282591968774796,0.00017096087685786188,0.0001921120856422931,0.0001879936462501064,0.00014783562801312655,0.00013155738997738808,0.00014745464432053268,0.00017705175559967756,0.00013987714191898704,0.00011739654291886836,0.00011741987691493705,0.00013778962602373213,0.00015377282397821546,0.00017388752894476056,0.0001501995575381443,0.00012532933033071458,0.00013291109644342214,0.00014418800128623843,0.0001477772166253999,0.0001257122348761186,0.00012105293717468157,0.00010759751603472978,9.820552804740146e-05,9.169492841465399e-05,7.95983214629814e-05,6.823914009146392e-05,0.00012247303675394505,8.384395187022164e-05,0.00012633224832825363,0.00014054018538445234,0.00015996297588571906,0.00014031337923370302,0.0001173404889414087,0.00010233782086288556,8.979562699096277e-05,9.463500464335084e-05,
mae,0.2144426703453064,0.1281895786523819,0.11249644309282303,0.10012966394424438,0.07871918380260468,0.06512989848852158,0.05241991579532623,0.05173172801733017,0.04678390175104141,0.03896932676434517,0.03843957930803299,0.03570205345749855,0.03392360359430313,0.030660858377814293,0.032517947256565094,0.027794191613793373,0.02517920546233654,0.01736351102590561,0.022626619786024094,0.024233650416135788,0.020404480397701263,0.023643789812922478,0.022487889975309372,0.019399745389819145,0.021002409979701042,0.018794842064380646,0.018092455342411995,0.01525160949677229,0.015834547579288483,0.012418132275342941,0.011877604760229588,0.011538272723555565,0.012126177549362183,0.013166265562176704,0.014521782286465168,0.01570773310959339,0.01827370561659336,0.014640075154602528,0.016125265508890152,0.015987884253263474,0.01335570216178894,0.01417621597647667,0.01626240648329258,0.013830030336976051,0.01325724832713604,0.01263019721955061,0.014639484696090221,0.012853161431849003,0.014465199783444405,0.011969476006925106,0.012652630917727947,0.012013967148959637,0.012582971714437008,0.011330148205161095,0.01283495407551527,0.011368846520781517,0.011513186618685722,0.010383283719420433,0.010438745841383934,0.01290174014866352,0.010942590422928333,0.011243063025176525,0.011801022104918957,0.011233392171561718,0.010082569904625416,0.010355819016695023,0.011179214343428612,0.011084100231528282,0.009582140482962132,0.008981894701719284,0.009829388000071049,0.010789085179567337,0.009461935609579086,0.008693311363458633,0.00855481717735529,0.00934329442679882,0.009982838295400143,0.01074173767119646,0.009866554290056229,0.00871923565864563,0.009109997190535069,0.009695258922874928,0.009860333986580372,0.008890717290341854,0.0088485237210989,0.008435674011707306,0.007995536550879478,0.007582155056297779,0.006851512007415295,0.00641325768083334,0.008727870881557465,0.00719994492828846,0.008958700112998486,0.009591225534677505,0.010444347746670246,0.00970105268061161,0.00848174188286066,0.007970063015818596,0.007283432874828577,0.007618611678481102,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 72299     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 72300     
=================================================================
Total params: 144,599
Trainable params: 144,599
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 72,299
Trainable params: 72,299
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 72,300
Trainable params: 72,300
Non-trainable params: 0
_________________________________________________________________
