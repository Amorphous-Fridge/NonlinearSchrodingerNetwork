2021-06-26
loss,2.3498117923736572,2.2058534622192383,2.203598976135254,2.2055280208587646,1.7226815223693848,0.3528783321380615,0.21442578732967377,0.203707754611969,0.11727495491504669,0.09252262115478516,0.06617491692304611,0.05082813277840614,0.04229598492383957,0.0435975082218647,0.03790130466222763,0.03353048861026764,0.03147374093532562,0.034193601459264755,0.031318437308073044,0.02650538645684719,0.03300713002681732,0.03190695121884346,0.02913520857691765,0.02760111726820469,0.023269884288311005,0.02603062614798546,0.025284603238105774,0.02624785155057907,0.02365129627287388,0.02584431692957878,0.02447967790067196,0.020961584523320198,0.02425634302198887,0.02343693934381008,0.026040909811854362,0.02488548681139946,0.022028818726539612,0.022287962958216667,0.022610709071159363,0.02531065046787262,0.024241382256150246,0.020168829709291458,0.023272119462490082,0.02330092340707779,0.022673822939395905,0.021204158663749695,0.019236966967582703,0.017737211659550667,0.016981568187475204,0.022298574447631836,0.021371319890022278,0.01895492896437645,0.021548235788941383,0.022908298298716545,0.01909187249839306,0.019606631249189377,0.022802870720624924,0.021876802667975426,0.01877000741660595,0.022149162366986275,0.021133990958333015,0.01754690147936344,0.018516456708312035,0.019004561007022858,0.01965399831533432,0.02182629331946373,0.02128332294523716,0.02062598429620266,0.018994633108377457,0.019808022305369377,0.021612288430333138,0.020008893683552742,0.019521038979291916,0.018791239708662033,0.01928003877401352,0.020025677978992462,0.019561544060707092,0.018094444647431374,0.018817635253071785,0.015096187591552734,0.01909034512937069,0.018297826871275902,0.01719963550567627,0.01645599491894245,0.017921259626746178,0.018326694145798683,0.018102431669831276,0.0183277428150177,0.01926046423614025,0.017999116331338882,0.017415065318346024,0.017506316304206848,0.015640027821063995,0.01847124472260475,0.018045548349618912,0.017846740782260895,0.01735132560133934,0.0162854865193367,0.017600594088435173,0.018570169806480408,
mse,1.4257031679153442,1.2304288148880005,1.2279577255249023,1.2301117181777954,0.8709218502044678,0.03805441036820412,0.014036105945706367,0.013908389024436474,0.0040391115471720695,0.0024120479356497526,0.0012445688480511308,0.0007610113825649023,0.0005184744950383902,0.0005329652922227979,0.000420141703216359,0.00032964599085971713,0.00029018110944889486,0.000339344929670915,0.0002877697697840631,0.00020677398424595594,0.00031676291837356985,0.00028887015650980175,0.0002447930455673486,0.00022213353076949716,0.00015983046614564955,0.00020099058747291565,0.00018809447647072375,0.00020026574202347547,0.00016526113904546946,0.00019348837668076158,0.00017376198957208544,0.0001337443827651441,0.00017355690943077207,0.00016382090689148754,0.00019625722779892385,0.0001834830327425152,0.00014460645616054535,0.00014907873992342502,0.00014970368647482246,0.00017873282195068896,0.00017112366913352162,0.00012557065929286182,0.0001588647864991799,0.00015500136942137033,0.00015074980910867453,0.00013263808796182275,0.00011093515058746561,9.56247968133539e-05,8.533216896466911e-05,0.0001460932253394276,0.00013376848073676229,0.00010846171790035442,0.00013507521362043917,0.000153534158016555,0.00011268539674347267,0.00011567345063667744,0.0001490165013819933,0.00013623898848891258,0.00010519449278945103,0.0001422397035639733,0.00012698354839812964,9.273868636228144e-05,0.00010413050040369853,0.00011255438585067168,0.0001131361786974594,0.00013518708874471486,0.00012962233449798077,0.00012182813952676952,0.00010645007569110021,0.00011473557242425159,0.00013423379277810454,0.00011397072375984862,0.00011162998271174729,0.0001039211856550537,0.00010889498662436381,0.00011665272177197039,0.00010880474292207509,9.652121661929414e-05,0.00010352728713769466,6.875900726299733e-05,0.00010608798766043037,9.792856144485995e-05,8.953059295890853e-05,8.306695963256061e-05,9.573281568009406e-05,9.89116815617308e-05,9.875531395664439e-05,9.832187788560987e-05,0.00010744677274487913,9.42628103075549e-05,9.121037874137983e-05,9.125443466473371e-05,7.545676635345444e-05,0.00010052789730252698,9.26394495763816e-05,8.938882820075378e-05,9.039603173732758e-05,8.013770275283605e-05,9.181960194837302e-05,9.808134927880019e-05,
mae,0.7977908253669739,0.607123851776123,0.5996282696723938,0.6033098101615906,0.6083936095237732,0.15095245838165283,0.09102333337068558,0.08722089976072311,0.0489535890519619,0.03952232003211975,0.028143158182501793,0.02178977243602276,0.01805112324655056,0.018614541739225388,0.016105474904179573,0.014275447465479374,0.013240243308246136,0.014473109506070614,0.013191000558435917,0.011204849928617477,0.013874446973204613,0.01352912187576294,0.01237606629729271,0.011706006713211536,0.009879281744360924,0.011057674884796143,0.010660112835466862,0.011088656261563301,0.010113175958395004,0.011016598902642727,0.010353484191000462,0.008870052173733711,0.010230145417153835,0.00996928010135889,0.011075833812355995,0.010576614178717136,0.009303257800638676,0.00938174407929182,0.009488793089985847,0.010779052972793579,0.010339860804378986,0.008666559122502804,0.009994752705097198,0.009836790151894093,0.009624803438782692,0.00892821978777647,0.008145305328071117,0.007544723339378834,0.0072832065634429455,0.009483895264565945,0.009154755622148514,0.008013860322535038,0.009148147888481617,0.009672285988926888,0.00806641485542059,0.008330367505550385,0.009467940777540207,0.009412389248609543,0.007920174859464169,0.009455454535782337,0.008966632187366486,0.007394920568913221,0.007839423604309559,0.008116010576486588,0.008297866210341454,0.009304029867053032,0.00907306931912899,0.008736162446439266,0.008078666403889656,0.008409889414906502,0.009271185845136642,0.008500915952026844,0.008304214105010033,0.008047928102314472,0.008146927691996098,0.008466703817248344,0.00830741599202156,0.007680159993469715,0.00807912927120924,0.0064590186811983585,0.008125030435621738,0.007805092725902796,0.0073416405357420444,0.0069954185746610165,0.007544646970927715,0.007862994447350502,0.007690866477787495,0.007847433909773827,0.008205248042941093,0.007666987832635641,0.0072702388279139996,0.007495252415537834,0.00671378243714571,0.007875921204686165,0.007722809445112944,0.007540892343968153,0.007357982452958822,0.006806895136833191,0.007408688776195049,0.007891601882874966,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 231299    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 231300    
=================================================================
Total params: 462,599
Trainable params: 462,599
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 231,299
Trainable params: 231,299
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 231,300
Trainable params: 231,300
Non-trainable params: 0
_________________________________________________________________
