2021-06-26
loss,0.37409594655036926,0.23184174299240112,0.20491988956928253,0.08776668459177017,0.055589187890291214,0.04676353931427002,0.040914908051490784,0.0382065623998642,0.035222459584474564,0.03338012844324112,0.03199980407953262,0.030854836106300354,0.02990296296775341,0.02901430055499077,0.02838713675737381,0.02772034890949726,0.027106214314699173,0.026645569130778313,0.026157429441809654,0.02561606466770172,0.02515297941863537,0.02500864677131176,0.024210071191191673,0.02419573813676834,0.023864097893238068,0.02372012659907341,0.023337330669164658,0.02312055416405201,0.02265726402401924,0.022368960082530975,0.022159993648529053,0.021998532116413116,0.021805617958307266,0.021620973944664,0.02118142694234848,0.021108148619532585,0.020941663533449173,0.02063392661511898,0.020594781264662743,0.02046903595328331,0.02011720836162567,0.020076870918273926,0.01988380402326584,0.0197377260774374,0.019663484767079353,0.01944824866950512,0.019470952451229095,0.01924639567732811,0.019109804183244705,0.019044000655412674,0.018684547394514084,0.018693353980779648,0.018705112859606743,0.018551170825958252,0.018413733690977097,0.0182938352227211,0.018167631700634956,0.01809481903910637,0.018069252371788025,0.017828017473220825,0.01772109791636467,0.01762714982032776,0.01764722540974617,0.017420673742890358,0.017288383096456528,0.017180943861603737,0.017171448096632957,0.01698431745171547,0.017265696078538895,0.01694006472826004,0.01685705967247486,0.01679736003279686,0.016792410984635353,0.016622882336378098,0.016550512984395027,0.01653224043548107,0.01644209213554859,0.016293004155158997,0.01641949824988842,0.016216928139328957,0.01624342054128647,0.016078008338809013,0.016084684059023857,0.01600302942097187,0.015956846997141838,0.015721820294857025,0.015894994139671326,0.015730276703834534,0.01561978179961443,0.015712657943367958,0.015443340875208378,0.01560608483850956,0.01535292249172926,0.01529289036989212,0.015540681779384613,0.015276704914867878,0.015151082538068295,0.01512895803898573,0.015334448777139187,0.014893071725964546,
mse,0.05174572020769119,0.018991373479366302,0.015546475537121296,0.002850727643817663,0.0010433983989059925,0.0007158885127864778,0.0005522388382814825,0.0004731735971290618,0.0004019772750325501,0.0003606177924666554,0.0003302169207017869,0.0003060054441448301,0.0002872188633773476,0.00026920103118754923,0.00025679077953100204,0.000243842470808886,0.00023360476188827306,0.00022510168491862714,0.00021654146257787943,0.0002076790842693299,0.00019894515571650118,0.0001963454851647839,0.00018508671200834215,0.0001832546986406669,0.00017838989151641726,0.0001751945383148268,0.00016919222252909094,0.00016583609976805747,0.00015910262300167233,0.00015511568926740438,0.0001518657081760466,0.00014958182873670012,0.00014711858239024878,0.0001440653286408633,0.00013812507677357644,0.0001374502753606066,0.00013529707212001085,0.00013148346624802798,0.00013085502723697573,0.00012877790140919387,0.00012477365089580417,0.00012421587598510087,0.00012174448056612164,0.00011947016173508018,0.00011847683344967663,0.00011602674931054935,0.00011628403444774449,0.00011339438060531393,0.00011151921353302896,0.00011112801439594477,0.00010678891703719273,0.00010722706792876124,0.0001071874430635944,0.00010502505756448954,0.00010351216769777238,0.00010225221194559708,0.00010103039676323533,0.00010019330511568114,9.946477803168818e-05,9.67795931501314e-05,9.58115269895643e-05,9.472407691646367e-05,9.567649976816028e-05,9.204589150613174e-05,9.126549412030727e-05,9.000430145533755e-05,8.953063661465421e-05,8.790760330157354e-05,9.091332321986556e-05,8.6977583123371e-05,8.647570211905986e-05,8.569249621359631e-05,8.630405500298366e-05,8.441440149908885e-05,8.34488237160258e-05,8.297580643557012e-05,8.209983934648335e-05,8.06249663583003e-05,8.219783194363117e-05,7.976777123985812e-05,8.005885320017114e-05,7.80508344178088e-05,7.85041629569605e-05,7.775743870297447e-05,7.733683742117137e-05,7.460674532921985e-05,7.659972470719367e-05,7.515205652453005e-05,7.382607873296365e-05,7.471645949408412e-05,7.216979429358616e-05,7.443111826432869e-05,7.119781366782263e-05,7.041603385005146e-05,7.313548121601343e-05,7.034620648482814e-05,6.931662210263312e-05,6.910409138072282e-05,7.15815185685642e-05,6.691121961921453e-05,
mae,0.1623239666223526,0.09466749429702759,0.08487367630004883,0.03719547763466835,0.023570453748106956,0.019929327070713043,0.01747356355190277,0.016312677413225174,0.015061084181070328,0.014272384345531464,0.013712299056351185,0.013218083418905735,0.012821640819311142,0.012443103827536106,0.012184999883174896,0.011907119303941727,0.011641360819339752,0.011447098106145859,0.01124484557658434,0.010999861173331738,0.010786512866616249,0.010743941180408001,0.010393069125711918,0.010393612086772919,0.010245271027088165,0.010189260356128216,0.010020538233220577,0.009915740229189396,0.009734222665429115,0.009572173468768597,0.009506162256002426,0.009451784193515778,0.009356453083455563,0.009285282343626022,0.009082641452550888,0.009045013226568699,0.008986780419945717,0.008837326429784298,0.008859020657837391,0.008768988773226738,0.00861336849629879,0.008596298284828663,0.008504144847393036,0.00843503512442112,0.008430041372776031,0.008321075700223446,0.008367626927793026,0.008245512843132019,0.008174368180334568,0.008152175694704056,0.007980072870850563,0.008013487793505192,0.00797058455646038,0.007976410910487175,0.007881038822233677,0.007807701826095581,0.007795018143951893,0.007732591591775417,0.007730972021818161,0.007606899365782738,0.0075927418656647205,0.007528428453952074,0.00756425503641367,0.007442048750817776,0.0073720533400774,0.0073417676612734795,0.00735648674890399,0.007257906720042229,0.007384964264929295,0.007243335247039795,0.007213848177343607,0.007189866155385971,0.007173555437475443,0.007078260648995638,0.007061028853058815,0.007077550515532494,0.007040081545710564,0.0069252727553248405,0.007038874551653862,0.006910212803632021,0.006928844843059778,0.0068736630491912365,0.006883883848786354,0.006811458617448807,0.006806937977671623,0.006728611420840025,0.006795097608119249,0.006752829998731613,0.006652612239122391,0.006726203020662069,0.006589885335415602,0.006653809454292059,0.006569213699549437,0.006529094185680151,0.006630648393183947,0.0065162163227796555,0.006469907239079475,0.006451060995459557,0.006539281457662582,0.006339909043163061,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1675      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1676      
=================================================================
Total params: 3,351
Trainable params: 3,351
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 1,675
Trainable params: 1,675
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 1,676
Trainable params: 1,676
Non-trainable params: 0
_________________________________________________________________
