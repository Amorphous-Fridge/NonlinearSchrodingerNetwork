2021-06-26
loss,2.592345952987671,2.2184133529663086,2.1843008995056152,0.500519335269928,0.2525535821914673,0.23569293320178986,0.23322130739688873,0.23058085143566132,0.22837863862514496,0.22636041045188904,0.22501754760742188,0.22583144903182983,0.2195393443107605,0.2196199595928192,0.21656855940818787,0.21422243118286133,0.21344660222530365,0.21035535633563995,0.20896491408348083,0.2097802758216858,0.19777145981788635,0.19124801456928253,0.16049760580062866,0.15212076902389526,0.1529768705368042,0.11999618262052536,0.10114540159702301,0.09103168547153473,0.09411363303661346,0.07713998109102249,0.056368209421634674,0.059937283396720886,0.05195709317922592,0.06038327142596245,0.04598042368888855,0.05974351987242699,0.05688853561878204,0.05354776233434677,0.053406864404678345,0.047513481229543686,0.04265201464295387,0.04794587939977646,0.04801367595791817,0.04321615397930145,0.04029686003923416,0.04001622274518013,0.04206138476729393,0.04268399253487587,0.03808480128645897,0.041044220328330994,0.03705412521958351,0.030852409079670906,0.03852479159832001,0.03686986863613129,0.03283195197582245,0.03796166926622391,0.037230655550956726,0.03033110871911049,0.03269347921013832,0.034221239387989044,0.03896796703338623,0.03632352873682976,0.03352903202176094,0.030993394553661346,0.03358493372797966,0.03423301875591278,0.034163400530815125,0.03017144277691841,0.029344862326979637,0.03093702532351017,0.0339946486055851,0.02782934345304966,0.033149588853120804,0.03151173144578934,0.03105642832815647,0.027063559740781784,0.03340847045183182,0.033032841980457306,0.033606115728616714,0.029271872714161873,0.030624937266111374,0.02897181734442711,0.03008032590150833,0.030995383858680725,0.0293282363563776,0.02625776082277298,0.02591656520962715,0.031941112130880356,0.03178941830992699,0.03034043498337269,0.02621864713728428,0.025193501263856888,0.02349618449807167,0.02455734647810459,0.03200950473546982,0.02744751237332821,0.0258338563144207,0.023113742470741272,0.027592061087489128,0.026392431929707527,
mse,1.8296657800674438,1.2438379526138306,1.213840365409851,0.08595678210258484,0.0210263654589653,0.019322818145155907,0.019104568287730217,0.01882508210837841,0.018539827316999435,0.018279094249010086,0.01805783621966839,0.017973868176341057,0.017370492219924927,0.017188968136906624,0.016805289313197136,0.0163724422454834,0.016072040423750877,0.015379873104393482,0.014895264990627766,0.014572091400623322,0.012974227778613567,0.01207023486495018,0.00883178785443306,0.008030892349779606,0.007977028377354145,0.004973845090717077,0.003487679874524474,0.002702651545405388,0.002984594786539674,0.0019140818621963263,0.0010012787533923984,0.0011384089011698961,0.0008193272515200078,0.001102726673707366,0.0006649981369264424,0.001056959736160934,0.0009750127792358398,0.0008470222819596529,0.0008400479564443231,0.0006771964835934341,0.0005582721787504852,0.0006682880339212716,0.0006844859453849494,0.0005560662830248475,0.0005013496265746653,0.000474028434837237,0.000519806460943073,0.0005329094710759819,0.00043869324144907296,0.0005030368338339031,0.00039977513370104134,0.0002900297986343503,0.0004417478630784899,0.0003941017494071275,0.00032033291063271463,0.0004160669050179422,0.00041830659029074013,0.0002725602244026959,0.00031793914968147874,0.0003546648076735437,0.00045297437463887036,0.0003920009476132691,0.0003333621716592461,0.0002937836979981512,0.0003341978299431503,0.0003505661734379828,0.0003369851328898221,0.0002668870147317648,0.00026109686587005854,0.000290471623884514,0.00033764448016881943,0.0002341072104172781,0.0003142112400382757,0.00029348782845772803,0.00029172084759920835,0.00021643373474944383,0.00032181155984289944,0.0003243811661377549,0.00032701969030313194,0.00025703010032884777,0.00028559789643622935,0.0002468767634127289,0.0002565479662735015,0.00027568486984819174,0.0002477667003404349,0.00019806828640867025,0.00020569941261783242,0.000294129247777164,0.0002993537054862827,0.00026441834052093327,0.00020625494653359056,0.0001929132267832756,0.00016592764586675912,0.0001795139687601477,0.0002909943868871778,0.00021865294547751546,0.00019463823991827667,0.0001587236183695495,0.00022317905677482486,0.00020528337336145341,
mae,0.9788726568222046,0.6466255187988281,0.6120849847793579,0.2122274786233902,0.10740507394075394,0.10154519230127335,0.10197898000478745,0.10203364491462708,0.10223320126533508,0.1023702546954155,0.10217390209436417,0.10277486592531204,0.09991135448217392,0.0990518257021904,0.09684707969427109,0.09478287398815155,0.0930422767996788,0.09031625837087631,0.0894797146320343,0.08989133685827255,0.08452928811311722,0.08158509433269501,0.06856293976306915,0.06506194919347763,0.06499762833118439,0.051228467375040054,0.043131180107593536,0.0386229045689106,0.04054180532693863,0.033077385276556015,0.024157054722309113,0.025553546845912933,0.022086940705776215,0.02565613016486168,0.019550615921616554,0.02506033144891262,0.02399327978491783,0.022535614669322968,0.02302786149084568,0.02029159478843212,0.018199630081653595,0.020291250199079514,0.02053273469209671,0.01844979263842106,0.017306335270404816,0.01701023243367672,0.018175188452005386,0.01818692497909069,0.016010832041502,0.0177470650523901,0.016034476459026337,0.01327374018728733,0.01663953624665737,0.015835849568247795,0.013964839279651642,0.016236169263720512,0.015813833102583885,0.012802030891180038,0.013868843205273151,0.01455749198794365,0.01669502444565296,0.015678957104682922,0.014443806372582912,0.013239205814898014,0.014278214424848557,0.014378078281879425,0.014621182344853878,0.012949909083545208,0.012612955644726753,0.013169263489544392,0.01462057325989008,0.0118708536028862,0.014191459864377975,0.013354348950088024,0.013380634598433971,0.011503070592880249,0.014257008209824562,0.014083652757108212,0.014415322802960873,0.012356224469840527,0.013204041868448257,0.012364664115011692,0.013065614737570286,0.013432348147034645,0.01277989149093628,0.01117484550923109,0.011153903789818287,0.013836432248353958,0.013442141935229301,0.012992221862077713,0.011298708617687225,0.010738469660282135,0.0098926005885005,0.010517735034227371,0.013781547546386719,0.011582556180655956,0.011034083552658558,0.009845613501966,0.011639871634542942,0.01143977977335453,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 279699    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 279700    
=================================================================
Total params: 559,399
Trainable params: 559,399
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 279,699
Trainable params: 279,699
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 279,700
Trainable params: 279,700
Non-trainable params: 0
_________________________________________________________________
