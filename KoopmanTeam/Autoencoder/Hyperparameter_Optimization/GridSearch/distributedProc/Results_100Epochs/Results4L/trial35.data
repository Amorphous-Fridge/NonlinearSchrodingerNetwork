2021-06-26
loss,0.3535313010215759,0.0996885746717453,0.08138037472963333,0.09142564982175827,0.07863129675388336,0.0666680708527565,0.05901074409484863,0.06546775996685028,0.0517522469162941,0.06618881970643997,0.05925178900361061,0.054720450192689896,0.05215787515044212,0.05325569212436676,0.053038790822029114,0.04392940178513527,0.032406553626060486,0.0458688922226429,0.04011894762516022,0.030989419668912888,0.04287896677851677,0.0468469113111496,0.03781960904598236,0.03647416830062866,0.03457970544695854,0.03779149428009987,0.04062211886048317,0.030047237873077393,0.02712544985115528,0.030467601493000984,0.03655761852860451,0.03400515392422676,0.03013445809483528,0.03718651086091995,0.02980034612119198,0.026439698413014412,0.027005143463611603,0.023047303780913353,0.027951478958129883,0.023701883852481842,0.03042534738779068,0.032598789781332016,0.02832518145442009,0.025805797427892685,0.029508154839277267,0.028476886451244354,0.027147438377141953,0.024372844025492668,0.030331220477819443,0.026768343523144722,0.026710640639066696,0.028206955641508102,0.027790982276201248,0.025465087965130806,0.02206283062696457,0.020698165521025658,0.024289213120937347,0.02180202305316925,0.022169122472405434,0.022799812257289886,0.025976812466979027,0.025959474965929985,0.023073876276612282,0.020771684125065804,0.019009191542863846,0.01749001257121563,0.01833646185696125,0.022010451182723045,0.023589132353663445,0.025121962651610374,0.026365069672465324,0.024392150342464447,0.024691199883818626,0.022533154115080833,0.020808003842830658,0.018561191856861115,0.01673812046647072,0.016754213720560074,0.015789592638611794,0.017107071354985237,0.017278868705034256,0.02088899537920952,0.021580787375569344,0.021185005083680153,0.019843189045786858,0.02182236686348915,0.022780142724514008,0.021710870787501335,0.019339658319950104,0.017332283779978752,0.016783589497208595,0.019334940239787102,0.022873008623719215,0.020657522603869438,0.01712126098573208,0.015117231756448746,0.018473438918590546,0.020511185750365257,0.021701157093048096,0.01762603595852852,
mse,0.05858566612005234,0.0029553337953984737,0.0018916343105956912,0.0023856405168771744,0.0017757888417690992,0.001262160949409008,0.00100514420773834,0.0012384403962641954,0.0007705723401159048,0.0012700750958174467,0.0009905145270749927,0.0008383928798139095,0.0007904326776042581,0.0007938400376588106,0.0007937672198750079,0.0005523912259377539,0.0003047993523068726,0.000598055892623961,0.00046577490866184235,0.0002854342164937407,0.000531043391674757,0.0006271513411775231,0.000395336770452559,0.0003790163609664887,0.00034747819881886244,0.0004114439361728728,0.00047039572382345796,0.00027247113757766783,0.00021927006309852004,0.0002707843668758869,0.0003739692911040038,0.0003307513543404639,0.0002672431874088943,0.00038510080776177347,0.0002509492333047092,0.00020795580348931253,0.00021834111248608679,0.0001563948899274692,0.0002249945537187159,0.0001640603441046551,0.000267847441136837,0.0003023268363904208,0.00022603357501793653,0.0001978514774236828,0.0002530940982978791,0.00023530669568572193,0.0002110210043611005,0.00017385817773174495,0.00025741325225681067,0.0002035400684690103,0.00020212418166920543,0.00022750087373424321,0.00021604144421871752,0.00017902742547448725,0.00013895049050915986,0.0001275483227800578,0.0001678518601693213,0.00013855136057827622,0.00014427794667426497,0.00015156122390180826,0.00019395425624679774,0.0001854536822065711,0.00015030444774311036,0.00012526662612799555,0.00010805915371747687,9.231231524609029e-05,0.00010085988469654694,0.00014400988584384322,0.00015611524577252567,0.00018105960043612868,0.00019347236957401037,0.0001690753415459767,0.00017220445442944765,0.00014550454216077924,0.000124538826639764,0.00010315695544704795,8.598255953984335e-05,8.471615001326427e-05,7.368101796600968e-05,8.736398012842983e-05,8.916832302929834e-05,0.0001239015400642529,0.000130409374833107,0.0001243996957782656,0.0001110551820602268,0.00013613112969323993,0.00014828085841145366,0.0001310128136537969,0.00010933274461422116,8.879034430719912e-05,8.386573608731851e-05,0.00010633508645696566,0.00014727943926118314,0.00011845143308164552,8.74919060152024e-05,6.784369907109067e-05,0.00010011327685788274,0.00011918444943148643,0.00013648608000949025,9.091661195270717e-05,
mae,0.15130117535591125,0.04284017160534859,0.03467167913913727,0.0388399213552475,0.032984863966703415,0.028011277318000793,0.024768304079771042,0.027979407459497452,0.0221013855189085,0.028215624392032623,0.02512849122285843,0.023256191983819008,0.022200671955943108,0.022639431059360504,0.0228635985404253,0.0188936498016119,0.013684717006981373,0.019145626574754715,0.016633804887533188,0.013252762146294117,0.01833365112543106,0.02034580521285534,0.016073165461421013,0.015538530424237251,0.014691815711557865,0.01608162559568882,0.016787990927696228,0.01268182322382927,0.011517520993947983,0.0128107825294137,0.015306893736124039,0.014206557534635067,0.01273533795028925,0.015649352222681046,0.012715084478259087,0.011323344893753529,0.011368335224688053,0.009760593995451927,0.011837062425911427,0.010098326951265335,0.01282424945384264,0.01399223692715168,0.012088998220860958,0.01095129456371069,0.012506336905062199,0.012173822149634361,0.011466443538665771,0.010348587296903133,0.012878715991973877,0.011360866017639637,0.011422445997595787,0.012234561145305634,0.011418209411203861,0.010618400759994984,0.009172208607196808,0.00870009046047926,0.010219229385256767,0.00925897341221571,0.009396204724907875,0.00959858950227499,0.011006981134414673,0.011094137094914913,0.009871277958154678,0.008857903070747852,0.008142096921801567,0.007430847268551588,0.007821661420166492,0.00931945163756609,0.010015049017965794,0.010743241757154465,0.011293178424239159,0.010636179707944393,0.010578409768640995,0.00950177013874054,0.008867349475622177,0.00787539966404438,0.007146905642002821,0.007094531785696745,0.00671196635812521,0.007203140761703253,0.007284501567482948,0.00895597506314516,0.009229224175214767,0.009087013080716133,0.008435986936092377,0.009335476905107498,0.009766059927642345,0.00919598899781704,0.008141597732901573,0.0073740677908062935,0.007038768380880356,0.008215196430683136,0.0098952017724514,0.008744625374674797,0.00732304947450757,0.006488391663879156,0.007844380103051662,0.008694032207131386,0.00931750051677227,0.007531699724495411,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 39443     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 39444     
=================================================================
Total params: 78,887
Trainable params: 78,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 39,443
Trainable params: 39,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 39,444
Trainable params: 39,444
Non-trainable params: 0
_________________________________________________________________
