2021-06-26
loss,0.3375857174396515,0.10156380385160446,0.10740525275468826,0.08871802687644958,0.06656387448310852,0.05528511852025986,0.05051880702376366,0.04769828915596008,0.06044231355190277,0.06287894397974014,0.06528282910585403,0.05282064527273178,0.04010510817170143,0.0532563179731369,0.05740583315491676,0.059145618230104446,0.04568704590201378,0.0384858101606369,0.03522991016507149,0.03257361054420471,0.031577445566654205,0.030584216117858887,0.029886851087212563,0.029434502124786377,0.029159093275666237,0.028745224699378014,0.028390279039740562,0.02795853652060032,0.02806703746318817,0.027525246143341064,0.03967202082276344,0.04107894003391266,0.046660520136356354,0.043910037726163864,0.039907462894916534,0.03745672479271889,0.041411176323890686,0.046277403831481934,0.04227728769183159,0.035604268312454224,0.032610468566417694,0.030889621004462242,0.02704322524368763,0.025317110121250153,0.025494040921330452,0.035244885832071304,0.04416969418525696,0.03773927316069603,0.03799442574381828,0.03847704827785492,0.034931156784296036,0.03637966513633728,0.03514232486486435,0.03187911584973335,0.03716074675321579,0.03219606727361679,0.029443221166729927,0.030062828212976456,0.034697920083999634,0.03395957499742508,0.03174491226673126,0.029924292117357254,0.028244171291589737,0.027665572240948677,0.026714645326137543,0.02627747505903244,0.025437472388148308,0.02525978535413742,0.03330463543534279,0.03124839998781681,0.029185211285948753,0.027248118072748184,0.02571515366435051,0.01997566595673561,0.0192041527479887,0.028358986601233482,0.02839464135468006,0.025747310370206833,0.02442237176001072,0.026377534493803978,0.03414211794734001,0.029121913015842438,0.029470806941390038,0.029523301869630814,0.025690939277410507,0.023705890402197838,0.022565409541130066,0.02151571214199066,0.02042968198657036,0.019626539200544357,0.01916387304663658,0.02551119774580002,0.030765898525714874,0.02745104394853115,0.024770811200141907,0.027195200324058533,0.02704159915447235,0.022279299795627594,0.023314006626605988,0.02410796657204628,
mse,0.043383415788412094,0.0032936357893049717,0.004043749067932367,0.002470101695507765,0.0013217772357165813,0.0008919115643948317,0.0007427107775583863,0.0006649416172876954,0.0010747304186224937,0.0011581126600503922,0.0012731156311929226,0.0008549196063540876,0.0004694847739301622,0.0008626547642052174,0.0009556649019941688,0.0010274641681462526,0.0006077119614928961,0.0004317529092077166,0.00034944424987770617,0.0003026830672752112,0.0002815741754602641,0.0002644734049681574,0.0002541321737226099,0.0002476515364833176,0.00024477203260175884,0.00023440152290277183,0.00022805108164902776,0.00022125974646769464,0.00022148732386995107,0.00021246488904580474,0.00047933997120708227,0.0004768863436765969,0.0006258927751332521,0.0005496565136127174,0.0004601886903401464,0.0004088369314558804,0.000492764578666538,0.0005916862282902002,0.0005013718036934733,0.0003554598370101303,0.0002950587950181216,0.00026847890694625676,0.00021525217744056135,0.00018705653201323003,0.00019559211796149611,0.00036350946174934506,0.0005540433339774609,0.00041432809666730464,0.0004222185234539211,0.0004147392464801669,0.0003517205186653882,0.00038559912354685366,0.0003477183636277914,0.0002948151668533683,0.00038714666152372956,0.0003004909376613796,0.0002506018499843776,0.000260671426076442,0.00034062351915054023,0.0003232599701732397,0.00028514000587165356,0.0002567303308751434,0.00022821140009909868,0.00021788098092656583,0.00020272366236895323,0.00019548143609426916,0.00018487211491446942,0.00018667327822186053,0.0003140701446682215,0.0002757987822405994,0.00024153619597200304,0.00020960740221198648,0.00019031572446692735,0.00012221344513818622,0.00011025104322470725,0.00022657529916614294,0.0002236836007796228,0.00018811537302099168,0.00016835459973663092,0.00020150937780272216,0.00032691561500541866,0.00024199378094635904,0.0002422519028186798,0.0002496631059329957,0.00018684353563003242,0.0001570376189192757,0.00014343400835059583,0.00013049696281086653,0.00011720035399775952,0.00010925680544460192,0.00010378702427260578,0.00019302799773868173,0.00026891837478615344,0.00021353397460188717,0.00017346728418488055,0.0002133185917045921,0.00021375394135247916,0.00014501583063974977,0.00015881768194958568,0.00016421311011072248,
mae,0.14478956162929535,0.04281787574291229,0.043303944170475006,0.036412909626960754,0.0274618212133646,0.023074055090546608,0.02109081670641899,0.019893938675522804,0.025112314149737358,0.0260473545640707,0.027152035385370255,0.02220192737877369,0.017040768638253212,0.022089675068855286,0.024174300953745842,0.024947836995124817,0.01895468309521675,0.01621396839618683,0.014822516590356827,0.013823348097503185,0.013569086790084839,0.012951578013598919,0.012778506614267826,0.012585903517901897,0.012131858617067337,0.012198803015053272,0.012090827338397503,0.011667133308947086,0.012023353949189186,0.011586490087211132,0.016547316685318947,0.016941338777542114,0.019595015794038773,0.018230559304356575,0.01662072353065014,0.015630092471837997,0.017076971009373665,0.020075149834156036,0.017687544226646423,0.01461023185402155,0.013621579855680466,0.01312384381890297,0.01157277263700962,0.010692423209547997,0.010838364250957966,0.014758204109966755,0.018856320530176163,0.016498789191246033,0.01590345986187458,0.0158943310379982,0.014507248066365719,0.01541886106133461,0.015276060439646244,0.013267233036458492,0.015652397647500038,0.013196553103625774,0.012132937088608742,0.012464108876883984,0.014323456212878227,0.014590025879442692,0.013900892809033394,0.013250368647277355,0.012187182903289795,0.011795745231211185,0.01097160205245018,0.010922631248831749,0.010737931355834007,0.010502051562070847,0.01354373712092638,0.013222862035036087,0.012415669858455658,0.011688844300806522,0.01088720839470625,0.00845405738800764,0.008039970882236958,0.012104945257306099,0.01205343846231699,0.011020077392458916,0.010682810097932816,0.011181244626641273,0.013870757073163986,0.011886301450431347,0.012017757631838322,0.012098836712539196,0.010874059051275253,0.010127590969204903,0.009554453194141388,0.009135322645306587,0.008773650974035263,0.008431044407188892,0.008241608738899231,0.010509658604860306,0.012370293959975243,0.011336511000990868,0.010137497447431087,0.011115111410617828,0.011096627451479435,0.009334824979305267,0.009639441035687923,0.010368227027356625,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 19819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 19820     
=================================================================
Total params: 39,639
Trainable params: 39,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 19,819
Trainable params: 19,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 19,820
Trainable params: 19,820
Non-trainable params: 0
_________________________________________________________________
