2021-06-26
loss,0.2277720421552658,0.09097252041101456,0.07105288654565811,0.05893814563751221,0.05234277620911598,0.04846564680337906,0.04538486525416374,0.04295659065246582,0.04084708169102669,0.039511751383543015,0.03811633959412575,0.03685544431209564,0.03587157651782036,0.0349818654358387,0.03427114337682724,0.03320905938744545,0.03316643834114075,0.03209303691983223,0.03156572952866554,0.031107470393180847,0.030537281185388565,0.02994285151362419,0.02980579435825348,0.028986264020204544,0.028948474675416946,0.028348257765173912,0.02800765447318554,0.027704007923603058,0.027252240106463432,0.026880182325839996,0.026611028239130974,0.0261605903506279,0.026056108996272087,0.02580517716705799,0.02545679546892643,0.025084851309657097,0.02467690408229828,0.04295242950320244,0.03655701503157616,0.04205000028014183,0.0396001897752285,0.03772209212183952,0.035298604518175125,0.03244761377573013,0.02993079647421837,0.02780260145664215,0.040460243821144104,0.041834961622953415,0.03723903372883797,0.035247597843408585,0.03343642130494118,0.03243108093738556,0.03125879913568497,0.03732604160904884,0.04472442716360092,0.041307199746370316,0.03859187662601471,0.036508411169052124,0.03472837805747986,0.03225553035736084,0.02983294241130352,0.02803890034556389,0.026826685294508934,0.025654904544353485,0.024769388139247894,0.024074800312519073,0.023372774943709373,0.022827809676527977,0.022441627457737923,0.029727347195148468,0.03572189807891846,0.03332994878292084,0.030925963073968887,0.02805100940167904,0.025686409324407578,0.023822791874408722,0.022304458543658257,0.02100958861410618,0.028230903670191765,0.03141440451145172,0.02932245470583439,0.028009403496980667,0.02696327492594719,0.025598883628845215,0.03516266867518425,0.036881908774375916,0.03387992084026337,0.03192221000790596,0.030375292524695396,0.0292095635086298,0.028151867911219597,0.026953019201755524,0.02620682306587696,0.02438056282699108,0.02199803665280342,0.02591806650161743,0.02492278628051281,0.023235619068145752,0.02199557051062584,0.02114798314869404,
mse,0.024938827380537987,0.002607099013403058,0.0015629970002919436,0.0010573486797511578,0.000830502191092819,0.000690119806677103,0.0005968803889118135,0.0005312018329277635,0.00047871153219603,0.0004442933131940663,0.00041247837361879647,0.0003852641675621271,0.00036345369881018996,0.00034579061320982873,0.0003322768316138536,0.00031147542176768184,0.0003089570382144302,0.0002891280746553093,0.00027997608412988484,0.0002707404491957277,0.00026101942057721317,0.0002496310044080019,0.00024758701329119503,0.00023318376042880118,0.00023311091354116797,0.00022283164435066283,0.00021661078790202737,0.0002118741103913635,0.00020493507327046245,0.00019916000019293278,0.00019585552217904478,0.00018806764273904264,0.00018688505224417895,0.0001822464109864086,0.0001777328143361956,0.00017320462211500853,0.00017801093054004014,0.0005687384982593358,0.0004052911826875061,0.0005255138967186213,0.00047595315845683217,0.0003987408708781004,0.0003333987551741302,0.00028558020130731165,0.0002483640855643898,0.0002198392030550167,0.00046775926603004336,0.0004736999690067023,0.0003785105363931507,0.0003421809524297714,0.0003107057709712535,0.00029054126935079694,0.00026999457622878253,0.0004105754487682134,0.0005544964224100113,0.00046814291272312403,0.00040911755058914423,0.00036756444023922086,0.00033218786120414734,0.0002858662628568709,0.0002455313806422055,0.00021697561896871775,0.0001991562603507191,0.00018303933029528707,0.0001705947652226314,0.00016188182053156197,0.00015292475291062146,0.00014599025598727167,0.00014116372040007263,0.0002615958219394088,0.0003498148871585727,0.0003028673818334937,0.00026134730433113873,0.00022125703981146216,0.0001891387946670875,0.00016609590966254473,0.0001448963157599792,0.00012829381739720702,0.00023229856742545962,0.00026887410786002874,0.0002382293314440176,0.0002196989080403,0.00020284413767512888,0.00018116105638910085,0.00036833155900239944,0.000379144970793277,0.0003167435643263161,0.0002818772627506405,0.00025533384177833796,0.00023644190514460206,0.0002200556918978691,0.00020352723367977887,0.00019277278624940664,0.0001718126004561782,0.00014554690278600901,0.00019293832883704454,0.00016904437507037073,0.00014823119272477925,0.00013470774865709245,0.00012512500688899308,
mae,0.0961667001247406,0.03767474740743637,0.02958736941218376,0.0246699508279562,0.022006692364811897,0.020460596308112144,0.019247082993388176,0.01818360760807991,0.01732722297310829,0.016736004501581192,0.01614106260240078,0.015682006254792213,0.015208031982183456,0.01475155632942915,0.014621010981500149,0.013974439352750778,0.0141535559669137,0.013615117408335209,0.013345685787498951,0.013219291344285011,0.01300592441111803,0.012632259167730808,0.01271877996623516,0.012217985466122627,0.012330678291618824,0.011937279254198074,0.01182817667722702,0.011729760095477104,0.011685197241604328,0.011429027654230595,0.011273510754108429,0.010968894697725773,0.010907735675573349,0.010937376879155636,0.010794962756335735,0.01069050095975399,0.010492540895938873,0.017776133492588997,0.01586846634745598,0.017678914591670036,0.016777150332927704,0.01637302152812481,0.014323242008686066,0.012952250428497791,0.012868913821876049,0.012291351333260536,0.017296424135565758,0.0178378839045763,0.016006849706172943,0.015279179438948631,0.014484226703643799,0.013893800787627697,0.012957459315657616,0.01587168499827385,0.02036130428314209,0.018805865198373795,0.01746491715312004,0.016417084261775017,0.01558456290513277,0.014369433745741844,0.013218133710324764,0.012106014415621758,0.011591058224439621,0.011103106662631035,0.01071853656321764,0.010430101305246353,0.010138184763491154,0.009904840029776096,0.009756282903254032,0.012691967189311981,0.015138093382120132,0.014753647148609161,0.013715548440814018,0.012211579829454422,0.011241087689995766,0.01037511508911848,0.009366635233163834,0.009020834229886532,0.011709912680089474,0.013167730532586575,0.012612950056791306,0.012040968984365463,0.011748130433261395,0.010993832722306252,0.015080530196428299,0.016341935843229294,0.014980384148657322,0.014017670415341854,0.013316555880010128,0.012785186991095543,0.012416955083608627,0.011861584149301052,0.01142512634396553,0.010593835264444351,0.009669985622167587,0.01106883306056261,0.010723411105573177,0.010034658014774323,0.00957905687391758,0.00920097529888153,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6419      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6420      
=================================================================
Total params: 12,839
Trainable params: 12,839
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 6,419
Trainable params: 6,419
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 6,420
Trainable params: 6,420
Non-trainable params: 0
_________________________________________________________________
