2021-06-26
loss,2.109616994857788,0.46792101860046387,0.46994277834892273,0.40551891922950745,0.31258726119995117,0.2555772662162781,0.2478826940059662,0.23829242587089539,0.22507859766483307,0.21698720753192902,0.22272330522537231,0.17161807417869568,0.14804425835609436,0.10379450023174286,0.10930051654577255,0.08958807587623596,0.08520440012216568,0.06433209776878357,0.0727645680308342,0.06693004816770554,0.05788321793079376,0.05658533051609993,0.046191081404685974,0.06160058453679085,0.04062143713235855,0.05450178682804108,0.049268689006567,0.0442148894071579,0.04371845722198486,0.04390883073210716,0.04884852096438408,0.040101900696754456,0.0421019047498703,0.03998519480228424,0.03950021415948868,0.03636178374290466,0.03887917846441269,0.03267962113022804,0.02702249214053154,0.030186988413333893,0.033033788204193115,0.03276556357741356,0.03277912363409996,0.031207570806145668,0.030191496014595032,0.03241622820496559,0.02967515029013157,0.027994532138109207,0.02631160244345665,0.03182307258248329,0.027934830635786057,0.028253579512238503,0.025624319911003113,0.028252074494957924,0.0256196316331625,0.025050029158592224,0.02497714012861252,0.02499099262058735,0.02592209167778492,0.024640576913952827,0.025047052651643753,0.021705348044633865,0.02356472797691822,0.025035135447978973,0.020712628960609436,0.022873826324939728,0.0225833673030138,0.023456702008843422,0.02383703738451004,0.02186046913266182,0.024534760043025017,0.022430801764130592,0.02217373624444008,0.02261877804994583,0.019953083246946335,0.021302437409758568,0.023261774331331253,0.019756659865379333,0.018833253532648087,0.021422021090984344,0.018524399027228355,0.021021759137511253,0.019630370661616325,0.019187115132808685,0.01913963258266449,0.016573701053857803,0.021311407908797264,0.021363111212849617,0.020467594265937805,0.020693905651569366,0.018729448318481445,0.019039999693632126,0.02019663341343403,0.01898679882287979,0.020000360906124115,0.020651040598750114,0.017998531460762024,0.018675047904253006,0.018591390922665596,0.0195480864495039,
mse,1.3895692825317383,0.06159590184688568,0.06304296106100082,0.04754635691642761,0.029518375173211098,0.02134528011083603,0.020299164578318596,0.019115347415208817,0.017286578193306923,0.015550210140645504,0.015483777970075607,0.008728732354938984,0.006322093773633242,0.0031714290380477905,0.0033978791907429695,0.002381677972152829,0.0020669635850936174,0.0012496878625825047,0.001497777528129518,0.001310864114202559,0.0009818131802603602,0.0009336498333141208,0.000621557526756078,0.001050738152116537,0.0004932728479616344,0.0008464349084533751,0.0006890605436637998,0.0005522219580598176,0.0005825053667649627,0.0005378422210924327,0.0006720610545016825,0.0004538178036455065,0.0005084329168312252,0.00045097232214175165,0.0004380565951578319,0.0003738451050594449,0.0004310053482186049,0.00031877082074061036,0.0002242996561108157,0.0002640712773427367,0.00031767948530614376,0.00030409652390517294,0.0003024409234058112,0.00028225299320183694,0.0002545116003602743,0.00029412322328425944,0.00024862997815944254,0.00021690651192329824,0.0001978800428332761,0.00028651219327002764,0.00021852747886441648,0.00022588070714846253,0.00018675174214877188,0.00022932965657673776,0.00018563447520136833,0.00017691221728455275,0.00017681258032098413,0.00018210239068139344,0.00018927585915662348,0.00017409124120604247,0.00017646243213675916,0.00013590727758128196,0.00016222643898800015,0.00017698336159810424,0.00012592152052093297,0.00015420553972944617,0.00014658804866485298,0.00015345266729127616,0.00016130840231198817,0.00013473328726831824,0.0001706816110527143,0.00014294961874838918,0.0001399779721396044,0.0001448562106816098,0.00011571992217795923,0.0001306729536736384,0.00015144962526392192,0.0001139432642958127,0.0001054815948009491,0.0001299072173424065,0.00010101142106577754,0.00012570858234539628,0.00010931223368970677,0.00010755583934951574,0.00010855981963686645,8.195890404749662e-05,0.00013033286086283624,0.0001263609592569992,0.00011993889347650111,0.00012246401456650347,0.00010361069871578366,0.00010563636169536039,0.0001143928529927507,0.00010360813757870346,0.0001133376790676266,0.00011729382094927132,9.412055806024e-05,9.958219015970826e-05,0.00010042950452771038,0.00010764734906842932,
mae,0.8604837656021118,0.20602399110794067,0.20502041280269623,0.17619459331035614,0.1370587795972824,0.11600174754858017,0.11255379766225815,0.10735321789979935,0.09889162331819534,0.0932302251458168,0.09352495521306992,0.07175823301076889,0.06338657438755035,0.04463672637939453,0.04681544750928879,0.038395874202251434,0.03633702173829079,0.02777395211160183,0.03098457120358944,0.02854086644947529,0.02434566430747509,0.024195626378059387,0.01968231052160263,0.02624315209686756,0.017259076237678528,0.023335494101047516,0.02078753150999546,0.018403686583042145,0.018563522025942802,0.018440507352352142,0.020686551928520203,0.016892803832888603,0.017736271023750305,0.016946280375123024,0.016913196071982384,0.015505143441259861,0.016489865258336067,0.013739585876464844,0.011577866040170193,0.012836797162890434,0.013866660185158253,0.0138822877779603,0.013933437876403332,0.013103820383548737,0.012922188267111778,0.013853490352630615,0.01255501713603735,0.011990970000624657,0.010916824452579021,0.014095318503677845,0.011762653477489948,0.011960490606725216,0.010902320966124535,0.011743171140551567,0.01070062629878521,0.010700817219913006,0.010733703151345253,0.010487968102097511,0.011076466180384159,0.01062881201505661,0.01063719391822815,0.009246218018233776,0.009903447702527046,0.010536352172493935,0.00883632805198431,0.00971406139433384,0.009692732244729996,0.009974543936550617,0.010081848129630089,0.009262505918741226,0.01043758261948824,0.009479767642915249,0.009375058114528656,0.009624695405364037,0.008467203006148338,0.008937995880842209,0.009933785535395145,0.008299295790493488,0.007992496713995934,0.009060878306627274,0.007943535223603249,0.009073132649064064,0.008428400382399559,0.008000293746590614,0.008132019080221653,0.007026843260973692,0.009128169156610966,0.009119928814470768,0.008765005506575108,0.008782207034528255,0.007960297167301178,0.00816338136792183,0.008585681207478046,0.00805850699543953,0.008500409312546253,0.008651566691696644,0.0077382163144648075,0.007906599901616573,0.007920539937913418,0.008286572061479092,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 312771    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 312772    
=================================================================
Total params: 625,543
Trainable params: 625,543
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 312,771
Trainable params: 312,771
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 312,772
Trainable params: 312,772
Non-trainable params: 0
_________________________________________________________________
