2021-06-26
loss,0.6059715747833252,0.25557470321655273,0.2113019824028015,0.14780206978321075,0.11096354573965073,0.0940127819776535,0.08514813333749771,0.09320135414600372,0.06669893860816956,0.058841533958911896,0.06838323920965195,0.060132455080747604,0.05087626352906227,0.050495028495788574,0.048529163002967834,0.04013267904520035,0.03743946924805641,0.03670484200119972,0.04322173073887825,0.04018358886241913,0.037713322788476944,0.031529899686574936,0.03045649267733097,0.03034297004342079,0.026788854971528053,0.03614059090614319,0.032788023352622986,0.031180324032902718,0.031644560396671295,0.024000786244869232,0.022623609751462936,0.0320107564330101,0.025371389463543892,0.022429270669817924,0.027014408260583878,0.027207989245653152,0.027178246527910233,0.02654195763170719,0.025052104145288467,0.024188730865716934,0.02004656009376049,0.0198340006172657,0.02361857332289219,0.02592826448380947,0.023351382464170456,0.019690467044711113,0.018932299688458443,0.02389228157699108,0.022547272965312004,0.022355912253260612,0.021042201668024063,0.02108328603208065,0.018908800557255745,0.02182513289153576,0.021571781486272812,0.021210838109254837,0.0189424529671669,0.019924618303775787,0.022084252908825874,0.019660359248518944,0.017494983971118927,0.01680820994079113,0.020399071276187897,0.02080637402832508,0.020770518109202385,0.01974528469145298,0.018168335780501366,0.01588965207338333,0.015995001420378685,0.020139288157224655,0.019606981426477432,0.01850547268986702,0.017654940485954285,0.018133148550987244,0.018771717324852943,0.01805759035050869,0.019279489293694496,0.017887359485030174,0.014190452173352242,0.013138805516064167,0.017225004732608795,0.018953464925289154,0.01758274994790554,0.017129413783550262,0.01852077804505825,0.016574006527662277,0.014291461557149887,0.014054881408810616,0.017097318544983864,0.017417922616004944,0.016597822308540344,0.01657770574092865,0.017050910741090775,0.016012955456972122,0.014970630407333374,0.015100705437362194,0.014972166158258915,0.012722903862595558,0.016173670068383217,0.015584290958940983,
mse,0.14553436636924744,0.02107066847383976,0.013138648122549057,0.00637854915112257,0.003531723516061902,0.0024246841203421354,0.0020789385307580233,0.0026725726202130318,0.001316022127866745,0.0010352084646001458,0.0013575090561062098,0.0010086472611874342,0.0007333611720241606,0.0007277142140083015,0.0006837717373855412,0.0004749672953039408,0.0004159560485277325,0.0003993371792603284,0.0005447466974146664,0.0004691682697739452,0.00040489513776265085,0.0002919659309554845,0.00027909845812246203,0.0002706062514334917,0.00021843287686351687,0.0003681822563521564,0.0003077620640397072,0.000287312752334401,0.00029040424851700664,0.0001733142271405086,0.00015322622493840754,0.00029426763649098575,0.00019044673535972834,0.00014976281090639532,0.0002129596541635692,0.0002118554839398712,0.00020973417849745601,0.00020018935902044177,0.00018052748055197299,0.0001706527400529012,0.00012454464740585536,0.00011783635272877291,0.00016137733473442495,0.00018846409511752427,0.00015340710524469614,0.00011638772411970422,0.00010962254600599408,0.00016218544624280185,0.00014214737166184932,0.00014748326793778688,0.00012586508819367737,0.00012778732343576849,0.00010775223199743778,0.00013538275379687548,0.00013056944590061903,0.00012555645662359893,0.00010224122524959967,0.00012026999320369214,0.00013863852655049413,0.00011281220213277265,9.061070159077644e-05,8.616206469014287e-05,0.00011875660857185721,0.0001223844737978652,0.0001212705101352185,0.00010716552060330287,9.196064638672397e-05,7.519878272432834e-05,7.88742836448364e-05,0.00011382587399566546,0.00010760696022771299,9.833295189309865e-05,9.009951463667676e-05,9.446571493754163e-05,9.948746446752921e-05,9.05288543435745e-05,0.00010326017945772037,9.082054748432711e-05,6.0619964642683044e-05,5.1764200179604813e-05,8.989495108835399e-05,0.000101846904726699,8.78413047757931e-05,8.504380821250379e-05,9.700292866909876e-05,7.976024062372744e-05,6.0729118558811024e-05,6.000425491947681e-05,8.392951713176444e-05,8.470963075524196e-05,7.969765283633024e-05,7.841016486054286e-05,8.186389459297061e-05,7.325703336391598e-05,6.383473373716697e-05,6.828980258433148e-05,6.638302147621289e-05,4.89087869937066e-05,7.657415699213743e-05,7.102335803210735e-05,
mae,0.26260051131248474,0.11350488662719727,0.08986411243677139,0.06236567348241806,0.04709075018763542,0.04002659395337105,0.036623500287532806,0.04007438197731972,0.02822636067867279,0.025155797600746155,0.028606919571757317,0.025773968547582626,0.02168523333966732,0.021396296098828316,0.020563099533319473,0.017019694671034813,0.01590377278625965,0.01575455255806446,0.01834285445511341,0.017164548859000206,0.015946734696626663,0.013388063758611679,0.012936187908053398,0.012999271973967552,0.011306200176477432,0.015388582833111286,0.014225573278963566,0.013218340463936329,0.013398987241089344,0.010188436135649681,0.009558960795402527,0.013663431629538536,0.01071677915751934,0.009516913443803787,0.011314058676362038,0.011503849178552628,0.01143302209675312,0.01131050381809473,0.010717775672674179,0.010319048538804054,0.00853563193231821,0.008410090580582619,0.009950738400220871,0.011091236025094986,0.009896058589220047,0.008279758505523205,0.007937399670481682,0.01009361818432808,0.009505967609584332,0.009526689536869526,0.008937764912843704,0.009034975431859493,0.008017041720449924,0.009228629060089588,0.00906648300588131,0.00896483100950718,0.008114558644592762,0.008476720191538334,0.009477607905864716,0.008320696651935577,0.007471206597983837,0.007165536750108004,0.00861185509711504,0.008863098919391632,0.008774954825639725,0.008282618597149849,0.007725985255092382,0.006687497720122337,0.006794128566980362,0.00861169584095478,0.008319932967424393,0.007932011969387531,0.007505263201892376,0.007720012217760086,0.007998248562216759,0.007710492704063654,0.00830355379730463,0.007634496781975031,0.006021695211529732,0.005486749578267336,0.007221604697406292,0.00818677805364132,0.007492012344300747,0.007256822660565376,0.00784349162131548,0.007073532789945602,0.0060790223069489,0.005911336746066809,0.007233824115246534,0.007375651504844427,0.007049511652439833,0.006971330847591162,0.007259783335030079,0.0066704535856842995,0.006295862141996622,0.006452878937125206,0.006375502794981003,0.005432111211121082,0.006763228680938482,0.006596906576305628,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 91075     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 91076     
=================================================================
Total params: 182,151
Trainable params: 182,151
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 91,075
Trainable params: 91,075
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 91,076
Trainable params: 91,076
Non-trainable params: 0
_________________________________________________________________
