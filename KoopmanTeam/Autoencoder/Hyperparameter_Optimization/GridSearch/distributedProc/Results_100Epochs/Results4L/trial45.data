2021-06-26
loss,1.0908665657043457,0.25920701026916504,0.23702171444892883,0.24029523134231567,0.23023250699043274,0.21973618865013123,0.21128758788108826,0.2061561644077301,0.18956267833709717,0.14612166583538055,0.1101023405790329,0.09992299973964691,0.07615559548139572,0.06431033462285995,0.07353983074426651,0.08678165078163147,0.06188321113586426,0.049990586936473846,0.04769616201519966,0.062772236764431,0.05702076479792595,0.05616731569170952,0.04494309797883034,0.036228079348802567,0.0326324887573719,0.03382454439997673,0.038422588258981705,0.04837245121598244,0.04108851030468941,0.03425513952970505,0.030467117205262184,0.02747749350965023,0.03306449577212334,0.030472712591290474,0.030004262924194336,0.03527376800775528,0.03386174514889717,0.03552264720201492,0.03656413033604622,0.03194652870297432,0.02933192439377308,0.02720078080892563,0.022825710475444794,0.02446376159787178,0.030212998390197754,0.031011497601866722,0.02658224105834961,0.029388153925538063,0.02883259207010269,0.027881497517228127,0.025652065873146057,0.023829204961657524,0.021914947777986526,0.02093936875462532,0.021538442000746727,0.023712705820798874,0.025591015815734863,0.023836862295866013,0.02275793068110943,0.0186409130692482,0.01835482567548752,0.022785712033510208,0.024393152445554733,0.02766471914947033,0.02552664838731289,0.0250515416264534,0.02221425622701645,0.021038906648755074,0.021105147898197174,0.021952034905552864,0.02297062799334526,0.021495549008250237,0.01874699629843235,0.02215811423957348,0.02216198667883873,0.022039521485567093,0.020764200016856194,0.020871706306934357,0.021830381825566292,0.021652808412909508,0.01919296197593212,0.019045379012823105,0.02109885960817337,0.018467815592885017,0.01720030978322029,0.01691659726202488,0.01871863193809986,0.019167043268680573,0.017607830464839935,0.022034170106053352,0.018844161182641983,0.017382636666297913,0.01636822521686554,0.018080294132232666,0.01783614233136177,0.01946515403687954,0.020516209304332733,0.01738630421459675,0.015508197247982025,0.01718602515757084,
mse,0.5490562319755554,0.02213364839553833,0.01949334889650345,0.0196617990732193,0.018446678295731544,0.01705651357769966,0.01585254818201065,0.01481983158737421,0.012299740687012672,0.006803438067436218,0.003576698713004589,0.0029921967070549726,0.0017183274030685425,0.0012147489469498396,0.0016029697144404054,0.0021418489050120115,0.0010869922116398811,0.0007280625286512077,0.0006738852243870497,0.0011457580840215087,0.0009159687906503677,0.0008913354831747711,0.0005704992800019681,0.00039364778785966337,0.0003136614977847785,0.0003404711897019297,0.0004323761095292866,0.0006534784915857017,0.00047136907232925296,0.00033531602821312845,0.00026548586902208626,0.000225406329263933,0.0003166345413774252,0.0002693287096917629,0.0002736623282544315,0.0003560018085408956,0.0003339184040669352,0.00036063813604414463,0.00036301437648944557,0.0002893242926802486,0.0002463821729179472,0.00021552116959355772,0.00015770856407471,0.00018188256944995373,0.00026309204986318946,0.000264637463260442,0.0002004877314902842,0.0002455869980622083,0.00023391871945932508,0.0002143464662367478,0.00018526872736401856,0.00015985920617822558,0.0001358997105853632,0.00012673538003582507,0.00013545506226364523,0.00016184263222385198,0.0001827421219786629,0.00015981528849806637,0.0001580153766553849,0.00011080110562033951,0.00010016350279329345,0.0001502205413999036,0.00016994237375911325,0.00021142321929801255,0.0001805605716072023,0.00017759999900590628,0.00013977922208141536,0.00012472270464058965,0.00012854166561737657,0.00014176787226460874,0.00014846460544504225,0.00012808962492272258,0.00010338207357563078,0.00014188102795742452,0.00013582955580204725,0.00013637290976475924,0.00012383841385599226,0.0001224558800458908,0.00013486373063642532,0.00013001012848690152,0.0001061881412169896,0.00010805766942212358,0.00012317208165768534,9.743127156980336e-05,8.72035016072914e-05,8.78728023963049e-05,0.00010093041782965884,0.00010772245877888054,9.155792940873653e-05,0.00013414613204076886,9.957144357031211e-05,8.6348140030168e-05,8.13985025160946e-05,9.47558946791105e-05,9.006580512505025e-05,0.00010798045695992187,0.00011839906801469624,8.915134094422683e-05,7.121445378288627e-05,8.711744885658845e-05,
mae,0.45960327982902527,0.10986226797103882,0.09671866148710251,0.09769885241985321,0.09489583224058151,0.09303455054759979,0.09102711826562881,0.08856040984392166,0.08120414614677429,0.06296804547309875,0.04710664600133896,0.04343776777386665,0.032537396997213364,0.027342569082975388,0.03174122795462608,0.03757713735103607,0.026772305369377136,0.021318675950169563,0.02032698132097721,0.027325758710503578,0.02427908591926098,0.02477499283850193,0.019241252914071083,0.015526595525443554,0.014040403068065643,0.014371441677212715,0.01634025014936924,0.02118033356964588,0.01786993071436882,0.01482672244310379,0.013234389014542103,0.0117395780980587,0.014029745943844318,0.012958003208041191,0.0128025496378541,0.015118319541215897,0.014624626375734806,0.015351039357483387,0.01602589339017868,0.013753097504377365,0.012287658639252186,0.01143237017095089,0.00982130877673626,0.010385310277342796,0.013077609241008759,0.013380210846662521,0.011288370005786419,0.012591827660799026,0.012291415594518185,0.012117325328290462,0.01101741474121809,0.010186671279370785,0.009354186244308949,0.008893735706806183,0.009155236184597015,0.00996176153421402,0.010536231100559235,0.009800439700484276,0.009609892033040524,0.007993013598024845,0.007744272239506245,0.009549535810947418,0.010368258692324162,0.01203240267932415,0.010988728143274784,0.010778906755149364,0.009390115737915039,0.008815322071313858,0.00897687766700983,0.009413846768438816,0.009740356355905533,0.009168492630124092,0.00799402967095375,0.00950796902179718,0.009565907530486584,0.009382065385580063,0.008870085701346397,0.008963276632130146,0.009287414140999317,0.009309884160757065,0.007998606190085411,0.00813398975878954,0.009076998569071293,0.007897955365478992,0.0072662984021008015,0.007161818910390139,0.008013990707695484,0.008243588730692863,0.0074690598994493484,0.009533178992569447,0.007830525748431683,0.00731468852609396,0.006936533842235804,0.0077147032134234905,0.007528560236096382,0.008327651768922806,0.008824853226542473,0.007362146861851215,0.006600556429475546,0.007253819610923529,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 74387     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 74388     
=================================================================
Total params: 148,775
Trainable params: 148,775
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 74,387
Trainable params: 74,387
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 74,388
Trainable params: 74,388
Non-trainable params: 0
_________________________________________________________________
