2021-06-26
loss,0.6223046779632568,0.25528401136398315,0.19378845393657684,0.11397693306207657,0.11442277580499649,0.08766365051269531,0.09245974570512772,0.09722836315631866,0.072138212621212,0.07152249664068222,0.061964549124240875,0.056895822286605835,0.05324268713593483,0.04486733302474022,0.045448943972587585,0.046269796788692474,0.03941177576780319,0.04091589152812958,0.046238575130701065,0.04094614461064339,0.03644750267267227,0.03289623185992241,0.03253374621272087,0.03635453060269356,0.029084572568535805,0.025851422920823097,0.02528662234544754,0.026525121182203293,0.03275955095887184,0.029727354645729065,0.026013491675257683,0.025045674294233322,0.026164954528212547,0.025112826377153397,0.026510553434491158,0.026687461882829666,0.025981036946177483,0.020744459703564644,0.02109397202730179,0.024245833978056908,0.023183166980743408,0.02266712114214897,0.021640382707118988,0.023138277232646942,0.020721009001135826,0.021768955513834953,0.024695344269275665,0.02125631272792816,0.02072533406317234,0.021117473021149635,0.023080237209796906,0.020894188433885574,0.0195994321256876,0.02104138769209385,0.021343395113945007,0.018304724246263504,0.016188785433769226,0.016170887276530266,0.020536458119750023,0.019871147349476814,0.019372692331671715,0.021072234958410263,0.018270043656229973,0.01924160122871399,0.020030563697218895,0.018631378188729286,0.01729109324514866,0.01630021072924137,0.016276396811008453,0.017319591715931892,0.019188009202480316,0.016870932653546333,0.017988059669733047,0.017631899565458298,0.018330439925193787,0.017056424170732498,0.018122529610991478,0.018012601882219315,0.01695140451192856,0.01411510445177555,0.018750324845314026,0.017659377306699753,0.01875201426446438,0.0176411010324955,0.015056263655424118,0.01766590215265751,0.015849102288484573,0.01427878625690937,0.015658974647521973,0.016853950917720795,0.018947787582874298,0.01825925149023533,0.016239775344729424,0.014827001839876175,0.015413268469274044,0.017141563817858696,0.01624678447842598,0.014424873515963554,0.01587495021522045,0.015459269285202026,
mse,0.16469985246658325,0.02076442539691925,0.011430252343416214,0.0037008430808782578,0.003962154965847731,0.0022497179452329874,0.0025599447544664145,0.002798120491206646,0.0014609735226258636,0.0014545380836352706,0.0010955013567581773,0.0009120326722040772,0.0007958356873132288,0.0005997669650241733,0.0005848491564393044,0.000636049488093704,0.00045593458344228566,0.00048421855899505317,0.000615814293269068,0.00048027042066678405,0.0003917037684004754,0.0003128214448224753,0.00030673088622279465,0.0003780316619668156,0.0002552963560447097,0.00019664924184326082,0.00019076572789344937,0.00021082203602418303,0.0002971682697534561,0.00025416482822038233,0.00019477528985589743,0.00018859228293877095,0.00020184712775517255,0.0001821080077206716,0.00020395305182319134,0.0002062254789052531,0.00018839869881048799,0.00012928145588375628,0.0001345179189229384,0.00017680854944046587,0.00015734157932456583,0.00015055420226417482,0.00013651927292812616,0.00015408374019898474,0.00012754318595398217,0.0001357982837362215,0.00016845902428030968,0.00012913662067148834,0.00012555932335089892,0.00012789138418156654,0.00015245268878061324,0.0001233404182130471,0.0001145664500654675,0.00012805528240278363,0.0001264827005797997,9.65432554949075e-05,7.682688010390848e-05,7.857132004573941e-05,0.00012235890608280897,0.0001113736507249996,0.00010960982763208449,0.00012290122685953975,9.518759179627523e-05,0.00010872172424569726,0.00011417699715821072,9.995575965149328e-05,8.958184480434284e-05,7.9401841503568e-05,7.993806502781808e-05,8.772051660344005e-05,0.00010658952669473365,8.263697964139283e-05,9.442938608117402e-05,8.965490269474685e-05,9.53119233599864e-05,8.334113954333588e-05,9.593045251676813e-05,9.147656965069473e-05,8.587503543822095e-05,6.018884960212745e-05,0.00010221752017969266,9.105894423555583e-05,0.00010098420170834288,8.887936564860865e-05,6.728944572387263e-05,9.10396411200054e-05,7.481669308617711e-05,6.173059227876365e-05,7.54518696339801e-05,8.42924855533056e-05,0.00010118959471583366,9.201833745464683e-05,7.848753739381209e-05,6.543911877088249e-05,7.257782999658957e-05,8.494068606523797e-05,7.775399717502296e-05,6.324397691059858e-05,7.361140887951478e-05,7.078521593939513e-05,
mae,0.2618878185749054,0.11179187148809433,0.08248762041330338,0.048193152993917465,0.04855384677648544,0.03717316314578056,0.037930767983198166,0.04209545627236366,0.030650127679109573,0.030563106760382652,0.026180805638432503,0.024319017305970192,0.0225273035466671,0.01932941935956478,0.019395383074879646,0.01944120228290558,0.016816502436995506,0.01734275184571743,0.01956086792051792,0.01726377196609974,0.015366073697805405,0.01398477703332901,0.013971401378512383,0.015439257957041264,0.01231284998357296,0.010958162136375904,0.010782747529447079,0.011226173490285873,0.013928668573498726,0.012843141332268715,0.011087744496762753,0.010759272612631321,0.011233752593398094,0.010554088279604912,0.011214673519134521,0.011365553364157677,0.011081214062869549,0.008797435089945793,0.00901275034993887,0.010261165909469128,0.009813947603106499,0.009604363702237606,0.009160279296338558,0.009838270954787731,0.00877708476036787,0.009175308980047703,0.010636789724230766,0.009069324471056461,0.00878862664103508,0.008897420950233936,0.009912454523146152,0.008966452442109585,0.0081406831741333,0.008967149071395397,0.008939147926867008,0.007651473395526409,0.006797147449105978,0.0068964846432209015,0.00871206820011139,0.008415639400482178,0.008189030922949314,0.00888117402791977,0.007733376696705818,0.008162681013345718,0.008569244295358658,0.00794549472630024,0.0073128920048475266,0.006898775231093168,0.0069338483735919,0.007407449651509523,0.008177092298865318,0.0070435418747365475,0.007562720216810703,0.007507546339184046,0.00771919684484601,0.00724929291754961,0.0076877884566783905,0.007651614025235176,0.007282189093530178,0.005990944337099791,0.00799271184951067,0.007514351978898048,0.007914571091532707,0.007478276267647743,0.0063336570747196674,0.007494064047932625,0.006741765886545181,0.006093025207519531,0.00653604744002223,0.007164949085563421,0.008052937686443329,0.007788680028170347,0.006836073938757181,0.006270817946642637,0.006574888713657856,0.007226795423775911,0.006976159289479256,0.006155258510261774,0.006736624054610729,0.0064977603033185005,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 99395     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 99396     
=================================================================
Total params: 198,791
Trainable params: 198,791
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 99,395
Trainable params: 99,395
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 99,396
Trainable params: 99,396
Non-trainable params: 0
_________________________________________________________________
