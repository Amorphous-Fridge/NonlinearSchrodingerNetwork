2021-06-26
loss,0.4407912492752075,0.23209749162197113,0.19036702811717987,0.1066330224275589,0.10268137603998184,0.07773826271295547,0.07671205699443817,0.08116140961647034,0.06724435091018677,0.06702764332294464,0.07185915112495422,0.05557531863451004,0.0462663471698761,0.04120701923966408,0.05585228279232979,0.04939574748277664,0.04718877747654915,0.04116019234061241,0.03863615170121193,0.044110823422670364,0.03856496140360832,0.036451324820518494,0.03612886369228363,0.052797891199588776,0.04771735519170761,0.043758779764175415,0.04217325523495674,0.0341230072081089,0.031871769577264786,0.02911832369863987,0.03644365817308426,0.03698016330599785,0.03577548637986183,0.036401115357875824,0.039027728140354156,0.040105924010276794,0.032418686896562576,0.03542156517505646,0.034599509090185165,0.029275553300976753,0.03370034694671631,0.03288877010345459,0.029428429901599884,0.02733517251908779,0.024821486324071884,0.029012314975261688,0.023929614573717117,0.024098386988043785,0.026938432827591896,0.02703089639544487,0.025141505524516106,0.024381712079048157,0.029630765318870544,0.02371755987405777,0.02283247746527195,0.0348442979156971,0.02984585240483284,0.026253771036863327,0.022829292342066765,0.02640186995267868,0.025850536301732063,0.02359871193766594,0.021852435544133186,0.0200645811855793,0.01892738975584507,0.018229536712169647,0.017069125548005104,0.017024829983711243,0.016866430640220642,0.018962349742650986,0.019203996285796165,0.024741962552070618,0.023533616214990616,0.027305804193019867,0.02592049352824688,0.022636152803897858,0.020794367417693138,0.01933612860739231,0.018364328891038895,0.017485368996858597,0.01635526306927204,0.016251301392912865,0.022549904882907867,0.023220915347337723,0.021139338612556458,0.01977476105093956,0.01843043975532055,0.0165485180914402,0.016236772760748863,0.017151914536952972,0.0179008599370718,0.022178519517183304,0.025161564350128174,0.021798918023705482,0.01976090483367443,0.01816774532198906,0.01668894849717617,0.015874840319156647,0.015260275453329086,0.014729469083249569,
mse,0.08135727047920227,0.01867501437664032,0.012751839123666286,0.003602749202400446,0.003101835260167718,0.0017642361344769597,0.0017180873546749353,0.0018880360294133425,0.0012919377768412232,0.0013119890354573727,0.0014423407847061753,0.0008719675242900848,0.0006111431866884232,0.0004874361911788583,0.000930734327994287,0.0006999102188274264,0.0006445946637541056,0.00047984745469875634,0.0004328748909756541,0.0005544589948840439,0.0004198807873763144,0.00037448390503413975,0.00038321406464092433,0.0008023104746825993,0.0006363538559526205,0.0005457861116155982,0.0004859997716266662,0.00033487085602246225,0.0002875030622817576,0.0002458038798067719,0.0003740996471606195,0.00038178268005140126,0.00035926775308325887,0.0003817543329205364,0.0004301387816667557,0.00044850484118796885,0.00029723774059675634,0.0003677940112538636,0.0003347531601320952,0.0002457483788020909,0.00032525009009987116,0.000301710533676669,0.0002446610014885664,0.00021060655126348138,0.00018047467165160924,0.00024060979194473475,0.00016775894619058818,0.00016869000683072954,0.0002057547535514459,0.00020102199050597847,0.0001775199780240655,0.00016809426597319543,0.0002425069542368874,0.0001641486887820065,0.0001609405444469303,0.00033817000803537667,0.00025202511460520327,0.00019158620852977037,0.00014655780978500843,0.00019700525444932282,0.00018201205239165574,0.0001569425076013431,0.00013693618529941887,0.00011777311738114804,0.00010475632734596729,9.567720553604886e-05,8.39439599076286e-05,8.636205166112632e-05,8.281178452307358e-05,0.00010513433517189696,0.00010935270984191447,0.00017198991554323584,0.00015514780534431338,0.0002076828241115436,0.0001878919283626601,0.0001429040712537244,0.00012330838944762945,0.00010717983241192997,9.690188016975299e-05,8.779934432823211e-05,7.929497223813087e-05,7.97731991042383e-05,0.0001448604598408565,0.00014792823640163988,0.00012540082389023155,0.0001101367233786732,9.6285788458772e-05,8.012193575268611e-05,7.823764462955296e-05,8.66736372699961e-05,9.430658974451944e-05,0.0001383304625051096,0.00017332939023617655,0.00013310456415638328,0.00011017810902558267,9.482305176788941e-05,8.28557531349361e-05,7.472933066310361e-05,6.862969166832045e-05,6.317757652141154e-05,
mae,0.1855526566505432,0.09644463658332825,0.08171499520540237,0.04567936435341835,0.04444613307714462,0.0329415500164032,0.03280113637447357,0.03519129753112793,0.028773881494998932,0.028177279978990555,0.03012215532362461,0.023911524564027786,0.01974737085402012,0.01746331714093685,0.023598961532115936,0.021261192858219147,0.019898008555173874,0.017576567828655243,0.016441775485873222,0.01879679225385189,0.0161194559186697,0.015411497093737125,0.015046061016619205,0.02207433059811592,0.020528554916381836,0.018651947379112244,0.018045661970973015,0.014109556563198566,0.013233935460448265,0.01263662800192833,0.015595696866512299,0.015641575679183006,0.015160087496042252,0.015530817210674286,0.016752751544117928,0.0167999230325222,0.013721037656068802,0.014994915574789047,0.014939852058887482,0.01251776423305273,0.014027253724634647,0.013966246508061886,0.012472608126699924,0.011750939302146435,0.01048256829380989,0.01233682967722416,0.010201635770499706,0.010232845321297646,0.011489298194646835,0.011408465914428234,0.010728724300861359,0.010431531816720963,0.012528883293271065,0.009973493404686451,0.00952177308499813,0.014494730159640312,0.012214981019496918,0.011318879202008247,0.009868809022009373,0.011256902478635311,0.010992837138473988,0.010088976472616196,0.009289921261370182,0.008523582480847836,0.008031814359128475,0.0077291023917496204,0.007279091980308294,0.007202499080449343,0.007207655813544989,0.008144623599946499,0.00817341823130846,0.010439623147249222,0.009993630461394787,0.011704375967383385,0.010794352740049362,0.009801833890378475,0.0089712580665946,0.007935309782624245,0.007609386462718248,0.007237870711833239,0.006816467270255089,0.006914258468896151,0.009430102072656155,0.00965298991650343,0.009152321144938469,0.00859301257878542,0.007865720428526402,0.007010822184383869,0.006789748091250658,0.007340264972299337,0.007583425845950842,0.009233105927705765,0.010588900186121464,0.00931456033140421,0.00865886453539133,0.0074966419488191605,0.007035619113594294,0.006742122117429972,0.006490756291896105,0.006278855726122856,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 22995     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 22996     
=================================================================
Total params: 45,991
Trainable params: 45,991
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 22,995
Trainable params: 22,995
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 22,996
Trainable params: 22,996
Non-trainable params: 0
_________________________________________________________________
