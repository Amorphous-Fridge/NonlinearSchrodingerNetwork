2021-06-26
loss,0.44354942440986633,0.2152329385280609,0.11848439276218414,0.06528207659721375,0.05241605266928673,0.04669727757573128,0.041534148156642914,0.038312096148729324,0.03568817302584648,0.03411580249667168,0.03229762613773346,0.0306836124509573,0.030109740793704987,0.028680041432380676,0.02827966772019863,0.027544183656573296,0.026805974543094635,0.02603684365749359,0.025730710476636887,0.025012901052832603,0.02486450970172882,0.024348542094230652,0.02398163080215454,0.023524172604084015,0.02321965992450714,0.022925157099962234,0.02251471020281315,0.022457174956798553,0.022142868489027023,0.021726086735725403,0.021395958960056305,0.021334288641810417,0.021025607362389565,0.020941533148288727,0.020686151459813118,0.020412299782037735,0.020323509350419044,0.02007013000547886,0.019901592284440994,0.019795970991253853,0.01962868869304657,0.019493581727147102,0.019334224984049797,0.019222991541028023,0.018992669880390167,0.01901927776634693,0.018858421593904495,0.01858554780483246,0.018605830147862434,0.018406176939606667,0.018282044678926468,0.01815793104469776,0.018044928088784218,0.018097763881087303,0.017813893035054207,0.017869656905531883,0.01765677146613598,0.017626415938138962,0.017504459246993065,0.017411008477211,0.017354784533381462,0.01731511391699314,0.017232010141015053,0.01708490215241909,0.01696663536131382,0.01700659468770027,0.0168791264295578,0.016871396452188492,0.01679856702685356,0.016721315681934357,0.016634877771139145,0.01648126356303692,0.01642034761607647,0.016482960432767868,0.01626112498342991,0.016364114359021187,0.01629256084561348,0.016118329018354416,0.016013696789741516,0.016061989590525627,0.01613476127386093,0.01591050811111927,0.01586393639445305,0.015907999128103256,0.015746528282761574,0.015803271904587746,0.015572271309792995,0.01573966071009636,0.015581052750349045,0.015609950758516788,0.015536300837993622,0.015371072106063366,0.015415233559906483,0.01544521376490593,0.015340444631874561,0.01534076314419508,0.015265485271811485,0.01517045870423317,0.015156494453549385,0.015054046176373959,
mse,0.09175548702478409,0.0157755259424448,0.005104124080389738,0.0015013006050139666,0.0009776623919606209,0.0007610847824253142,0.0005992251099087298,0.0005006684805266559,0.0004278492124285549,0.00038664863677695394,0.0003454035904724151,0.0003106350195594132,0.0002953157527372241,0.0002676080330274999,0.00025777966948226094,0.00024384850985370576,0.00022970314603298903,0.0002170765947084874,0.00020962030976079404,0.00019811172387562692,0.00019439542666077614,0.000186173667316325,0.0001797807781258598,0.0001735234254738316,0.000167276753927581,0.00016286784375552088,0.00015737501962576061,0.00015563576016575098,0.0001510405563749373,0.00014561059651896358,0.00014188555360306054,0.00014023701078258455,0.00013545707042794675,0.00013417088484857231,0.0001308912760578096,0.00012799882097169757,0.00012586727098096162,0.00012283860996831208,0.00012046200572513044,0.00011943941353820264,0.00011708457896020263,0.00011531166092026979,0.000113470341602806,0.00011208622890990227,0.00010948358249152079,0.00010939025378320366,0.0001076377448043786,0.00010415432916488498,0.00010425260552437976,0.00010172041947953403,0.00010143526742467657,9.939618757925928e-05,9.82648998615332e-05,9.831327042775229e-05,9.5146540843416e-05,9.581109770806506e-05,9.342837438452989e-05,9.356212103739381e-05,9.213367593474686e-05,9.066933125723153e-05,8.97797362995334e-05,8.94511686055921e-05,8.845655975164846e-05,8.711594273336232e-05,8.632573008071631e-05,8.608763891970739e-05,8.45900212880224e-05,8.477277879137546e-05,8.390940638491884e-05,8.318854816025123e-05,8.24432063382119e-05,8.033957419684157e-05,7.999704394023865e-05,8.055478247115389e-05,7.84861549618654e-05,7.905201346147805e-05,7.879099575802684e-05,7.715897663729265e-05,7.581664976896718e-05,7.601652760058641e-05,7.68589015933685e-05,7.453278522007167e-05,7.399584137601778e-05,7.476532482542098e-05,7.319586438825354e-05,7.369464583462104e-05,7.133038889151067e-05,7.290141365956515e-05,7.137741340557113e-05,7.195546641014516e-05,7.097730122040957e-05,6.93557012709789e-05,6.957651930861175e-05,6.991381087573245e-05,6.91749737598002e-05,6.916860729688779e-05,6.831904465798289e-05,6.749040767317638e-05,6.70989029458724e-05,6.635634053964168e-05,
mae,0.18466389179229736,0.08470509201288223,0.0482926070690155,0.027716021984815598,0.022351980209350586,0.01996607705950737,0.017799919471144676,0.016429370269179344,0.015281113795936108,0.014677541330456734,0.013891080394387245,0.013173574581742287,0.012957548722624779,0.012358295731246471,0.01217139046639204,0.011855478398501873,0.011533704586327076,0.0111998924985528,0.011098802089691162,0.010767631232738495,0.010677721351385117,0.010498473420739174,0.010363464243710041,0.010112435556948185,0.009994430467486382,0.0098781893029809,0.009707499295473099,0.009615243412554264,0.009506125934422016,0.00934787280857563,0.009147138334810734,0.009173684753477573,0.009018059819936752,0.009003710001707077,0.008920010179281235,0.008734834380447865,0.008743087761104107,0.00858362764120102,0.008575847372412682,0.008525442332029343,0.008463175967335701,0.00830579362809658,0.008324696682393551,0.008259596303105354,0.00820393767207861,0.008130168542265892,0.00804933626204729,0.007954436354339123,0.00801748689264059,0.007863271050155163,0.007911797612905502,0.00778241828083992,0.007733605336397886,0.007744770031422377,0.00762964366003871,0.007690640166401863,0.007580077275633812,0.007625446189194918,0.007498344872146845,0.007492760196328163,0.0074122208170592785,0.007460128515958786,0.007403599563986063,0.007324655540287495,0.00725641380995512,0.0073030502535402775,0.00724377017468214,0.0072058881632983685,0.007246294524520636,0.007206631824374199,0.007161808665841818,0.007025239523500204,0.0070129926316440105,0.00708397850394249,0.007000818382948637,0.007039091549813747,0.007039004936814308,0.006955140735954046,0.006771426647901535,0.0068962667137384415,0.006943609099835157,0.006789401639252901,0.006805123761296272,0.006860548630356789,0.006743614096194506,0.006787720136344433,0.006689159199595451,0.006713404785841703,0.006649306043982506,0.006678108125925064,0.0066756876185536385,0.006559951696544886,0.006580486427992582,0.006599913351237774,0.00660518417134881,0.006619113497436047,0.00656379759311676,0.006475680973380804,0.006487532984465361,0.0064592729322612286,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2259      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2260      
=================================================================
Total params: 4,519
Trainable params: 4,519
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 2,259
Trainable params: 2,259
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 2,260
Trainable params: 2,260
Non-trainable params: 0
_________________________________________________________________
