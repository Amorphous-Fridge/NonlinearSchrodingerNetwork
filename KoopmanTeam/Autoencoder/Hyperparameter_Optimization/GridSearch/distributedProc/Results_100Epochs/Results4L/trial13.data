2021-06-26
loss,0.3772152066230774,0.10161752998828888,0.058232665061950684,0.046356234699487686,0.04162731021642685,0.03871351107954979,0.0369529165327549,0.035664189606904984,0.034132007509469986,0.033709123730659485,0.03274907171726227,0.03192685544490814,0.031194567680358887,0.030530450865626335,0.03005092218518257,0.029562657698988914,0.02931887097656727,0.02870027720928192,0.0283481664955616,0.02791590616106987,0.027627509087324142,0.027261946350336075,0.02718021161854267,0.026759207248687744,0.02651199884712696,0.026261579245328903,0.025979219004511833,0.025686588138341904,0.024994149804115295,0.025208812206983566,0.0395180881023407,0.038827717304229736,0.03994099050760269,0.028080597519874573,0.025263261049985886,0.0246136412024498,0.02427348867058754,0.023943651467561722,0.023907825350761414,0.023665927350521088,0.02350827492773533,0.02332400530576706,0.023092396557331085,0.02304103411734104,0.022813832387328148,0.022825144231319427,0.022617274895310402,0.022373130545020103,0.02237076684832573,0.022298848256468773,0.02217680960893631,0.02202727645635605,0.021961679682135582,0.02175542153418064,0.021679503843188286,0.02165035717189312,0.021499691531062126,0.0213521309196949,0.02127624675631523,0.021067405119538307,0.0211319699883461,0.021023500710725784,0.021004242822527885,0.02091958373785019,0.020733481273055077,0.020626522600650787,0.02063564583659172,0.020531730726361275,0.020489489659667015,0.020392293110489845,0.020243464037775993,0.020166931673884392,0.020138587802648544,0.020077353343367577,0.019966743886470795,0.019907481968402863,0.01982887089252472,0.019795356318354607,0.01973450928926468,0.019517403095960617,0.019634153693914413,0.0195289496332407,0.019431041553616524,0.019332576543092728,0.01931650936603546,0.01935177855193615,0.019203312695026398,0.01909954659640789,0.019009292125701904,0.019229071214795113,0.01905341073870659,0.01891305111348629,0.01887832209467888,0.018954843282699585,0.018671127036213875,0.018718363717198372,0.01860940270125866,0.01848270185291767,0.018389316275715828,0.018620029091835022,
mse,0.05791444703936577,0.0035558417439460754,0.0010548110585659742,0.0006598420441150665,0.0005247407243587077,0.0004472591681405902,0.0004025991656817496,0.00037238694494590163,0.00034025657805614173,0.00033032550709322095,0.0003110672696493566,0.0002937910321634263,0.00028031590045429766,0.000267949013505131,0.00025840336456894875,0.0002509565674699843,0.00024534057592973113,0.00023503383272327483,0.00022827967768535018,0.0002208322985097766,0.00021636011661030352,0.00021036926773376763,0.00020761390624102205,0.00020262465113773942,0.00019752267689909786,0.00019453804998192936,0.0001891519350465387,0.00018664782692212611,0.00019100247300229967,0.00019064599473495036,0.0004791835672222078,0.00043594074668362737,0.00045481958659365773,0.00023281089670490474,0.0001794335839804262,0.00016900456103030592,0.00016477244207635522,0.00016045902157202363,0.00015959783922880888,0.00015565119974780828,0.00015406565216835588,0.00015142266056500375,0.0001482977095292881,0.00014729615941178054,0.00014492437185253948,0.00014432574971579015,0.00014147552428767085,0.00013886872329749167,0.00013892032438889146,0.00013759244757238775,0.00013630258035846055,0.00013385608326643705,0.00013428412785287946,0.00013167111319489777,0.00013003134517930448,0.0001298702700296417,0.0001279850403079763,0.00012589241669047624,0.00012537043949123472,0.00012269105354789644,0.000124073019833304,0.00012236785551067442,0.00012157750461483374,0.00012071542732883245,0.00011868586443597451,0.0001178123420686461,0.00011738738976418972,0.00011619398719631135,0.00011587392509682104,0.00011479001841507852,0.0001130463570007123,0.0001128050425904803,0.00011176925181644037,0.0001110499506467022,0.00010983322135871276,0.00010944446694338694,0.00010858548921532929,0.00010832398402271792,0.0001076171756722033,0.00010504377132747322,0.00010606391151668504,0.00010514601308386773,0.00010363708133809268,0.00010286664473824203,0.00010292047954862937,0.00010326193296350539,0.00010159848170587793,0.00010068011761177331,9.978718298953027e-05,0.00010232561180600896,9.975423017749563e-05,9.882273297989741e-05,9.812385542318225e-05,9.88988031167537e-05,9.621618664823472e-05,9.689307626103982e-05,9.521751053398475e-05,9.441231668461114e-05,9.358322131447494e-05,9.613767906557769e-05,
mae,0.16046150028705597,0.04311683773994446,0.0248167272657156,0.019808201119303703,0.01778065785765648,0.0165486391633749,0.015804894268512726,0.015211769379675388,0.014398643746972084,0.014547765254974365,0.014022456482052803,0.013554961420595646,0.013371513225138187,0.013030951842665672,0.012920625507831573,0.012676863931119442,0.012594331055879593,0.012371603399515152,0.012302855029702187,0.01197274774312973,0.011569814756512642,0.011744490824639797,0.01163951400667429,0.011529708281159401,0.011389697901904583,0.011225569061934948,0.011110334657132626,0.011058097705245018,0.010689144022762775,0.010711783543229103,0.01682835817337036,0.016772473230957985,0.017241667956113815,0.01188430655747652,0.011267057619988918,0.010602990165352821,0.010647847317159176,0.010197038762271404,0.01021636463701725,0.010360704734921455,0.010136212222278118,0.009876098483800888,0.00989189650863409,0.01009282935410738,0.009848455898463726,0.009886164218187332,0.009640593081712723,0.00946110486984253,0.00959077849984169,0.00939908530563116,0.009491028264164925,0.009401177987456322,0.00943587813526392,0.00908894743770361,0.009397068992257118,0.009328726679086685,0.009142914786934853,0.00925536174327135,0.008935295045375824,0.008760079741477966,0.008981913328170776,0.009052466601133347,0.008995499461889267,0.009093510918319225,0.008914872072637081,0.008710244670510292,0.008695540018379688,0.00873537827283144,0.00871842447668314,0.0086720185354352,0.008672981522977352,0.008550306782126427,0.008526619523763657,0.008474809117615223,0.008536548353731632,0.00827527604997158,0.008569841273128986,0.008459982462227345,0.008338856510818005,0.008150430396199226,0.008225240744650364,0.008272968232631683,0.008314475417137146,0.008089053444564342,0.008364302106201649,0.008132574148476124,0.00808657519519329,0.008034802973270416,0.008083474822342396,0.008202807046473026,0.008238513022661209,0.007955257780849934,0.008155550807714462,0.00814735796302557,0.007934179157018661,0.008139016106724739,0.0080908527597785,0.007850272580981255,0.007884356193244457,0.00799283292144537,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5875      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5876      
=================================================================
Total params: 11,751
Trainable params: 11,751
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 5,875
Trainable params: 5,875
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 5,876
Trainable params: 5,876
Non-trainable params: 0
_________________________________________________________________
