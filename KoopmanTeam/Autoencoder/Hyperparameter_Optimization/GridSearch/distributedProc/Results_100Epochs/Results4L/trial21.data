2021-06-26
loss,0.4048644006252289,0.14331910014152527,0.07695183902978897,0.06011512130498886,0.05205455794930458,0.04985307529568672,0.0479096993803978,0.04284961521625519,0.04011036828160286,0.03817949444055557,0.036523133516311646,0.03502645343542099,0.03374302387237549,0.033053018152713776,0.03211662918329239,0.0390341579914093,0.036580100655555725,0.034100573509931564,0.04980960488319397,0.048064056783914566,0.04317808151245117,0.04002278298139572,0.03672602400183678,0.035822030156850815,0.049353327602148056,0.044563908129930496,0.039675839245319366,0.03620603308081627,0.034015171229839325,0.0316477008163929,0.029069213196635246,0.027333075180649757,0.02577929198741913,0.024770069867372513,0.023016054183244705,0.02204206772148609,0.021602092310786247,0.02126023732125759,0.02107381634414196,0.02076500840485096,0.02042233757674694,0.020293081179261208,0.01997119002044201,0.01971498318016529,0.019518926739692688,0.019349947571754456,0.01909690909087658,0.01890375465154648,0.018667593598365784,0.018655722960829735,0.018468355759978294,0.018264466896653175,0.018206097185611725,0.018069783225655556,0.01798219233751297,0.017787868157029152,0.017745155841112137,0.017680741846561432,0.01751777157187462,0.01747039519250393,0.017445940524339676,0.017247216776013374,0.017169993370771408,0.0171024389564991,0.01695244014263153,0.016854804009199142,0.016805525869131088,0.016726311296224594,0.016666188836097717,0.01663333736360073,0.016505856066942215,0.0164172500371933,0.016309455037117004,0.016242478042840958,0.01619606465101242,0.01618950068950653,0.015941457822918892,0.015940066426992416,0.015882033854722977,0.015894554555416107,0.015694886445999146,0.01559364516288042,0.015549415722489357,0.015489527955651283,0.01542725320905447,0.015281454659998417,0.015337475575506687,0.015180682763457298,0.01510833390057087,0.01506696455180645,0.01497441902756691,0.015017833560705185,0.01488974317908287,0.014715323224663734,0.014879242517054081,0.014722861349582672,0.014708541333675385,0.014623533934354782,0.014517382718622684,0.014458822086453438,
mse,0.0627494752407074,0.00729038380086422,0.0017951986519619823,0.0010762596502900124,0.0008151725050993264,0.000741161173209548,0.0006698399083688855,0.0005296161398291588,0.000461040559457615,0.0004200356488581747,0.00038412786670960486,0.00035175628727301955,0.0003279022639617324,0.0003141198249068111,0.00030608646920882165,0.0004507202538661659,0.0003790846385527402,0.00033686161623336375,0.0007492484874092042,0.0006801148992963135,0.000553546124137938,0.00045435220818035305,0.0003853344824165106,0.00038166227750480175,0.0007131639285944402,0.000564030313398689,0.00045069470070302486,0.00037908804370090365,0.000332741707097739,0.0002842581598088145,0.00023949137539602816,0.000214107203646563,0.00019118435739073902,0.00017616389959584922,0.00015265669208019972,0.0001409142423653975,0.0001354344713035971,0.00013132457388564944,0.00012846260506194085,0.0001242831931449473,0.00012080204032827169,0.00011866164277307689,0.00011494602949824184,0.00011206174531253055,0.00011026547144865617,0.00010790031228680164,0.00010534795001149178,0.00010293399827787653,0.00010198408563155681,9.949967352440581e-05,9.810140181798488e-05,9.591069829184562e-05,9.527682414045557e-05,9.37859367695637e-05,9.242566011380404e-05,9.062883327715099e-05,8.977043762570247e-05,8.901411638362333e-05,8.794798486633226e-05,8.739132317714393e-05,8.68450733833015e-05,8.48822746775113e-05,8.478697418468073e-05,8.311584679177031e-05,8.174332469934598e-05,8.111447095870972e-05,8.091846393654123e-05,7.951595034683123e-05,7.93576764408499e-05,7.891708810348064e-05,7.71380728110671e-05,7.725499744992703e-05,7.6025135058444e-05,7.590738823637366e-05,7.505053508793935e-05,7.401617040159181e-05,7.206199370557442e-05,7.245750748552382e-05,7.190153701230884e-05,7.179231761256233e-05,6.99141455697827e-05,6.907606439199299e-05,6.839285924797878e-05,6.855222454760224e-05,6.794425280531868e-05,6.724830745952204e-05,6.649580609519035e-05,6.52394664939493e-05,6.458292773459107e-05,6.495005800388753e-05,6.447493797168136e-05,6.419973215088248e-05,6.337858940241858e-05,6.22672014287673e-05,6.323735578916967e-05,6.134463183116168e-05,6.112913251854479e-05,6.054830373614095e-05,5.9549991419771686e-05,5.9472851717146114e-05,
mae,0.17053650319576263,0.06274497509002686,0.032957784831523895,0.02583668753504753,0.022368786856532097,0.021294400095939636,0.020327391102910042,0.018446175381541252,0.017498943954706192,0.016384931281208992,0.015603363513946533,0.0151438657194376,0.014477411285042763,0.014034755527973175,0.013786437921226025,0.01672971434891224,0.015497091226279736,0.01441164594143629,0.021107075735926628,0.020499972626566887,0.018493527546525,0.01720605045557022,0.01585899293422699,0.01527499221265316,0.021172771230340004,0.02000039629638195,0.017950622364878654,0.016381721943616867,0.01525859721004963,0.01367236115038395,0.012603169307112694,0.01189101580530405,0.011111356317996979,0.010623430833220482,0.009739595465362072,0.009400161914527416,0.009244149550795555,0.009057557210326195,0.009110337123274803,0.008756197057664394,0.008911481127142906,0.008588834665715694,0.008612586185336113,0.008495571091771126,0.008352629840373993,0.008227153681218624,0.008272504433989525,0.008096953853964806,0.008086741901934147,0.007891801185905933,0.007961449213325977,0.007848409004509449,0.007752964273095131,0.007704558782279491,0.007682879455387592,0.0075896130874753,0.007606287486851215,0.0076020401902496815,0.00750843808054924,0.00744482409209013,0.007488761562854052,0.00736056687310338,0.007323031313717365,0.00733594736084342,0.007200291380286217,0.00723986467346549,0.007108599413186312,0.0072511364705860615,0.007134478073567152,0.00713563384488225,0.007020285353064537,0.00703740818426013,0.0069147758185863495,0.006930474191904068,0.006919634994119406,0.006956903263926506,0.006817949470132589,0.00681795971468091,0.006778620649129152,0.006830636877566576,0.006702600512653589,0.006686353590339422,0.006561218295246363,0.006579809822142124,0.00658425223082304,0.006535210646688938,0.006576061248779297,0.0064243134111166,0.006412035785615444,0.00647186953574419,0.00654133316129446,0.006356068886816502,0.0063442508690059185,0.0062343887984752655,0.006320296321064234,0.006314592435956001,0.006248900201171637,0.006241803057491779,0.006228144746273756,0.006132356356829405,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9995      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9996      
=================================================================
Total params: 19,991
Trainable params: 19,991
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 9,995
Trainable params: 9,995
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 9,996
Trainable params: 9,996
Non-trainable params: 0
_________________________________________________________________
