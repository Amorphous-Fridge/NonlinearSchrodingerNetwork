2021-06-26
loss,0.4218679368495941,0.13709576427936554,0.1071813553571701,0.08448868989944458,0.06539419293403625,0.05797545984387398,0.06624506413936615,0.07536952197551727,0.07850240916013718,0.07537215948104858,0.06327126920223236,0.057196244597435,0.07484264671802521,0.06100335717201233,0.0627746656537056,0.05362609773874283,0.047704268246889114,0.04334448650479317,0.04050677269697189,0.05808372050523758,0.0535641610622406,0.04342544451355934,0.03712041676044464,0.040711160749197006,0.0411272868514061,0.0452590137720108,0.04406362399458885,0.042821355164051056,0.041962385177612305,0.037765998393297195,0.03288896754384041,0.03035183995962143,0.029048478230834007,0.030258292332291603,0.03412938490509987,0.043506622314453125,0.04010568931698799,0.0365145280957222,0.034107886254787445,0.04110277071595192,0.039397016167640686,0.03583058714866638,0.03163595125079155,0.028869230300188065,0.026728129014372826,0.03748958930373192,0.03647395595908165,0.03309154883027077,0.029933033511042595,0.028113387525081635,0.02682841382920742,0.031217055395245552,0.0380072146654129,0.03616480529308319,0.03351176902651787,0.03220614790916443,0.030733318999409676,0.02803252451121807,0.029361587017774582,0.027231920510530472,0.0251653790473938,0.025330660864710808,0.02628001756966114,0.030393248423933983,0.028117595240473747,0.02629806473851204,0.025182491168379784,0.024241995066404343,0.023595761507749557,0.023421579971909523,0.035014133900403976,0.030814459547400475,0.026713388040661812,0.024376049637794495,0.022861545905470848,0.02741559036076069,0.02609708532691002,0.0243765227496624,0.029875149950385094,0.025869999080896378,0.023455293849110603,0.022504394873976707,0.021387219429016113,0.021734997630119324,0.027018412947654724,0.023911751806735992,0.022199535742402077,0.021282756701111794,0.02039807103574276,0.018608087673783302,0.015804357826709747,0.015493744984269142,0.014818954281508923,0.014312125742435455,0.01421993225812912,0.014038863591849804,0.013941420242190361,0.01383897103369236,0.01367542427033186,0.01366305723786354,
mse,0.08127804100513458,0.005843447521328926,0.003424690570682287,0.0020920345559716225,0.0012194318696856499,0.0009401303250342607,0.001351722632534802,0.0016720743151381612,0.0017326843226328492,0.0015639711637049913,0.0010891545098274946,0.0008962005376815796,0.0016140311490744352,0.001035187509842217,0.0010812414111569524,0.0007936282199807465,0.0006238126661628485,0.0005172322271391749,0.00045183568727225065,0.0009442214504815638,0.0007799799786880612,0.0005415039486251771,0.0003988947719335556,0.00045986167970113456,0.0004819000605493784,0.0005928529426455498,0.0005398127250373363,0.0005068156169727445,0.0004911177675239742,0.0004024724185001105,0.00030466559110209346,0.0002613023098092526,0.00024124035553541034,0.00026286981301382184,0.0003352931817062199,0.0005362262018024921,0.0004345816851127893,0.0003593912988435477,0.00032624401501379907,0.00047775174607522786,0.00042826152639463544,0.000345882581314072,0.0002701164921745658,0.00022764464665669948,0.00020099029643461108,0.00038886931724846363,0.00037038562004454434,0.00029266055207699537,0.00024634116562083364,0.00021889121853746474,0.00020269524247851223,0.00026958558009937406,0.00040102226193994284,0.00035921568633057177,0.00031354461680166423,0.00028500574990175664,0.0002573610399849713,0.00021778058726340532,0.0002427141007501632,0.00020598352421075106,0.00017916224896907806,0.00017879734514281154,0.00019459934264887124,0.0002491066697984934,0.0002143489255104214,0.00018978610751219094,0.00017479658708907664,0.00016220677935052663,0.000153040760778822,0.00015524146147072315,0.00034747752943076193,0.00026555691147223115,0.00019821565365418792,0.0001618363312445581,0.00014396941696759313,0.00020858658535871655,0.00018752607866190374,0.00016992674500215799,0.000246893527219072,0.00018183939391747117,0.0001484317472204566,0.00013814185513183475,0.00012481509475037456,0.00013089478306937963,0.00020035916531924158,0.00015790299221407622,0.00013744147145189345,0.0001251551730092615,0.00011562719737412408,9.905503247864544e-05,7.233722135424614e-05,6.723519618390128e-05,6.137608579592779e-05,5.6933145970106125e-05,5.599138239631429e-05,5.472606426337734e-05,5.413057442638092e-05,5.365529432310723e-05,5.232692637946457e-05,5.201235398999415e-05,
mae,0.181727334856987,0.058980852365493774,0.045599475502967834,0.03572501987218857,0.02816220372915268,0.024968601763248444,0.028341596946120262,0.032251618802547455,0.03287733718752861,0.0317281037569046,0.024825820699334145,0.0224692914634943,0.03197193518280983,0.02639959752559662,0.027406591922044754,0.02314605750143528,0.019976332783699036,0.018811460584402084,0.01755335181951523,0.024666426703333855,0.0230850912630558,0.018263980746269226,0.015894925221800804,0.01738007552921772,0.01772417314350605,0.019448649138212204,0.018824728205800056,0.01796603947877884,0.01784750074148178,0.016139376908540726,0.014367342926561832,0.01330915093421936,0.01270059123635292,0.012836324982345104,0.014308796264231205,0.018573349341750145,0.01659199595451355,0.014020425267517567,0.014694681391119957,0.01760110817849636,0.017060181125998497,0.015454376116394997,0.013812904246151447,0.01236010156571865,0.011438382789492607,0.01604258455336094,0.015694716945290565,0.014029350131750107,0.013266638852655888,0.011959293857216835,0.011406447738409042,0.013342274352908134,0.01643354445695877,0.015646349638700485,0.014609268866479397,0.01393868587911129,0.013181829825043678,0.011778193525969982,0.012425411492586136,0.01169525645673275,0.010807360522449017,0.010643251240253448,0.011162970215082169,0.013177493587136269,0.011826902627944946,0.011010194197297096,0.010564357042312622,0.010143209248781204,0.009873863309621811,0.009878532961010933,0.015220736153423786,0.013287169858813286,0.011038907803595066,0.01022519264370203,0.009626003913581371,0.011349252425134182,0.011151096783578396,0.010384507477283478,0.013164549134671688,0.011007653549313545,0.010344063863158226,0.009686005301773548,0.00888491328805685,0.009110519662499428,0.011228875257074833,0.010489043779671192,0.00968774314969778,0.009239932522177696,0.00865153968334198,0.007856646552681923,0.006739130709320307,0.006725708022713661,0.006438659969717264,0.006242530886083841,0.006181976292282343,0.006001670379191637,0.005953507963567972,0.005927859339863062,0.005827942863106728,0.005880517885088921,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 20883     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 20884     
=================================================================
Total params: 41,767
Trainable params: 41,767
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 20,883
Trainable params: 20,883
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 20,884
Trainable params: 20,884
Non-trainable params: 0
_________________________________________________________________
