2021-06-26
loss,3.305218458175659,3.124397039413452,3.123126268386841,3.121885299682617,3.1226303577423096,3.122994899749756,3.12265682220459,3.1224260330200195,3.1222312450408936,3.7293927669525146,3.3744287490844727,3.218226909637451,3.3900253772735596,3.134427547454834,3.132742404937744,3.1319973468780518,3.1311087608337402,3.1300508975982666,3.1290130615234375,3.1300454139709473,3.0801312923431396,2.2813453674316406,2.205902338027954,2.2043468952178955,2.2041449546813965,2.2047784328460693,2.387225389480591,2.2304909229278564,1.1454819440841675,0.3151066303253174,0.25333860516548157,0.2401498407125473,0.22746983170509338,0.21875101327896118,0.21471044421195984,0.21032679080963135,0.2048875391483307,0.20138636231422424,0.1987307220697403,0.19636142253875732,0.19271038472652435,0.187683567404747,0.1873449832201004,0.17930948734283447,0.1786821484565735,0.17515446245670319,0.1715727597475052,0.16945894062519073,0.16694673895835876,0.16265186667442322,0.15993408858776093,0.15408258140087128,0.15016646683216095,0.13946428894996643,0.13719823956489563,0.11665736138820648,0.10435262322425842,0.12539848685264587,0.10156094282865524,0.11707250773906708,0.12197483330965042,0.10821132361888885,0.10909752547740936,0.08726310729980469,0.09273246675729752,0.0728030875325203,0.08083714544773102,0.0943073108792305,0.07067267596721649,0.06359457224607468,0.08188571780920029,0.07958651334047318,0.060224805027246475,0.06170953810214996,0.059671372175216675,0.06614860147237778,0.05921759456396103,0.06906519085168839,0.06912162154912949,0.057857219129800797,0.047094766050577164,0.05807898938655853,0.05157149210572243,0.04865672066807747,0.06007867678999901,0.05974108353257179,0.05640815198421478,0.05634848773479462,0.05373670905828476,0.05593112111091614,0.05187070369720459,0.06055203452706337,0.051760587841272354,0.05064145103096962,0.058441780507564545,0.050519008189439774,0.05349535495042801,0.05055755749344826,0.04595549404621124,0.04375433549284935,
mse,2.8161699771881104,2.450045108795166,2.448092460632324,2.446204423904419,2.4473319053649902,2.4478931427001953,2.44738507270813,2.4470345973968506,2.4467132091522217,3.871724843978882,3.0739898681640625,2.653425931930542,2.9031219482421875,2.465627431869507,2.4629976749420166,2.461855888366699,2.460461378097534,2.458895206451416,2.4573583602905273,2.4589433670043945,2.3880465030670166,1.316981554031372,1.2304741144180298,1.2288552522659302,1.228633165359497,1.2293071746826172,1.5168697834014893,1.256943702697754,0.452477365732193,0.030357755720615387,0.02106463350355625,0.019651107490062714,0.018050681799650192,0.016909657046198845,0.016282198950648308,0.01562060508877039,0.014917245134711266,0.014393315650522709,0.0139844361692667,0.013610538095235825,0.013028261251747608,0.012378819286823273,0.012255366891622543,0.011430489830672741,0.011202710680663586,0.010868413373827934,0.010512386448681355,0.010173583403229713,0.00987784843891859,0.009461965411901474,0.009027814492583275,0.008163935504853725,0.007180070970207453,0.00581580214202404,0.005522326100617647,0.003931553568691015,0.0032139590475708246,0.004579512868076563,0.0028526594396680593,0.004033741541206837,0.004184358287602663,0.003289724700152874,0.0032428333070129156,0.002172710606828332,0.002674320014193654,0.0015114772832021117,0.0018736949423328042,0.0024710341822355986,0.0013731456128880382,0.0011013526236638427,0.0018719795625656843,0.0017642597667872906,0.001017923466861248,0.001094604260288179,0.001019148388877511,0.0012036946136504412,0.0010009879479184747,0.0013305791653692722,0.0013145313132554293,0.0009061493910849094,0.000630189897492528,0.0009461503941565752,0.0007215093937702477,0.0006550702382810414,0.0010257433168590069,0.0009776692604646087,0.0008563418523408473,0.0009095169370993972,0.0008007441647350788,0.0008596006082370877,0.0007608883897773921,0.0010906868847087026,0.0007340674055740237,0.0007249994087032974,0.0009415268432348967,0.0007482892251573503,0.0008262750343419611,0.000699233787599951,0.0005917363450862467,0.0005126839387230575,
mae,1.3803431987762451,1.1250083446502686,1.1078566312789917,1.105475664138794,1.1044782400131226,1.1039789915084839,1.1034064292907715,1.1029772758483887,1.1031556129455566,1.6246219873428345,1.4041780233383179,1.24857497215271,1.404476284980774,1.1759140491485596,1.1691842079162598,1.1664762496948242,1.1640706062316895,1.1618345975875854,1.1599626541137695,1.1591023206710815,1.139224886894226,0.7357195019721985,0.6056529879570007,0.6004845499992371,0.5995884537696838,0.59941565990448,0.7978847026824951,0.6736009120941162,0.4081778824329376,0.13394755125045776,0.10422416031360626,0.10420247167348862,0.09967207908630371,0.09507336467504501,0.09134627133607864,0.08831576257944107,0.08491302281618118,0.08291676640510559,0.08144419640302658,0.08086296170949936,0.07984060794115067,0.07814951986074448,0.07846337556838989,0.07522643357515335,0.07534097880125046,0.07392715662717819,0.07242675125598907,0.07180944085121155,0.07065249234437943,0.06862915307283401,0.0678376704454422,0.06524769961833954,0.06390485912561417,0.05922725796699524,0.057904358953237534,0.04949286952614784,0.04390265792608261,0.05509042739868164,0.045584939420223236,0.04987255483865738,0.0505451001226902,0.04557447507977486,0.04627292603254318,0.03636212274432182,0.0402885302901268,0.031432513147592545,0.03420635685324669,0.041461557149887085,0.030666276812553406,0.027587799355387688,0.03493015468120575,0.03453749418258667,0.02549687586724758,0.02640357054769993,0.02611447125673294,0.027949411422014236,0.024438196793198586,0.029825899749994278,0.02815324254333973,0.02512575313448906,0.020528489723801613,0.024344488978385925,0.022612059488892555,0.021264657378196716,0.02630167454481125,0.025541985407471657,0.02339109592139721,0.023717772215604782,0.02323131635785103,0.023693211376667023,0.022064410150051117,0.02530493773519993,0.02231367863714695,0.021659648045897484,0.025822892785072327,0.02165682055056095,0.02258243039250374,0.021464034914970398,0.01940549910068512,0.016596827656030655,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 362371    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 362372    
=================================================================
Total params: 724,743
Trainable params: 724,743
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 362,371
Trainable params: 362,371
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 362,372
Trainable params: 362,372
Non-trainable params: 0
_________________________________________________________________
