2021-06-26
loss,0.35137394070625305,0.09692423790693283,0.06400809437036514,0.05155952274799347,0.04551040753722191,0.04126923903822899,0.03850967437028885,0.036718424409627914,0.03507435694336891,0.034101612865924835,0.03299187868833542,0.03186598792672157,0.031355686485767365,0.030682582408189774,0.029867392033338547,0.029306141659617424,0.02882475219666958,0.028410637751221657,0.02793714962899685,0.027356700971722603,0.027074474841356277,0.026719246059656143,0.02618822082877159,0.025817284360527992,0.02565389685332775,0.024829523637890816,0.02496357448399067,0.02477276884019375,0.024493908509612083,0.024066857993602753,0.023783862590789795,0.023855533450841904,0.02368118055164814,0.030342407524585724,0.03356119245290756,0.022839663550257683,0.022584296762943268,0.02228199690580368,0.022030189633369446,0.021973906084895134,0.0218803808093071,0.021605970337986946,0.021449202671647072,0.02129875123500824,0.021144332364201546,0.020951051265001297,0.020920725539326668,0.020679354667663574,0.026319794356822968,0.03255166858434677,0.031128089874982834,0.0361533984541893,0.03572983294725418,0.0314803346991539,0.028181085363030434,0.029910830780863762,0.021336693316698074,0.02033466286957264,0.01961001753807068,0.019198870286345482,0.018825091421604156,0.01887838914990425,0.018674498423933983,0.01853424869477749,0.018365735188126564,0.018403133377432823,0.018184330314397812,0.01810630038380623,0.017926184460520744,0.01788809895515442,0.017794108018279076,0.01778014376759529,0.01769082620739937,0.017636148259043694,0.017510373145341873,0.01746906340122223,0.01738555170595646,0.01723586767911911,0.01717192679643631,0.01722576655447483,0.017107577994465828,0.016935354098677635,0.016997359693050385,0.016853179782629013,0.01692657731473446,0.016748545691370964,0.016611965373158455,0.016519498080015182,0.016517044976353645,0.016455762088298798,0.016355883330106735,0.016395200043916702,0.016216348856687546,0.016158267855644226,0.016217952594161034,0.015990139916539192,0.016008369624614716,0.015925657004117966,0.01589813269674778,0.015676721930503845,
mse,0.057715948671102524,0.0032590655609965324,0.001315935398451984,0.0008415835327468812,0.0006356758531183004,0.0005144583992660046,0.00044661853462457657,0.00040144429658539593,0.00036501031718216836,0.00034356059040874243,0.00032041093800216913,0.00029962771805003285,0.00028809354989789426,0.00027558935107663274,0.0002607117348816246,0.000251511053647846,0.00024200777988880873,0.00023433957539964467,0.0002266247320221737,0.00021631058189086616,0.00021203121286816895,0.00020712768309749663,0.0001990869059227407,0.0001925930700963363,0.0001902061194414273,0.00018192629795521498,0.00018325966084375978,0.00017801324429456145,0.0001716614351607859,0.0001688073534751311,0.00016652267368044704,0.00016545236576348543,0.00016108667477965355,0.0003116769657935947,0.0003994507424067706,0.00015176978195086122,0.00014578003901988268,0.00014187878696247935,0.00013860937906429172,0.0001380577014060691,0.0001371196995023638,0.0001331430539721623,0.00013109746214468032,0.00012962269829586148,0.0001270563661819324,0.00012612278806045651,0.00012642242654692382,0.0001265483588213101,0.00021947495406493545,0.00031047119409777224,0.00028166957781650126,0.0003845801984425634,0.0003593088185880333,0.0002805608091875911,0.0002279650652781129,0.0002585768816061318,0.00013608363224193454,0.00011838849604828283,0.00011096729576820508,0.00010616671352181584,0.00010297527478542179,0.00010272199870087206,0.00010024876974057406,9.90491098491475e-05,9.644027159083635e-05,9.67567611951381e-05,9.508346556685865e-05,9.368669998366386e-05,9.132895502261817e-05,9.131472324952483e-05,9.051248343894258e-05,9.020105062518269e-05,8.897595398593694e-05,8.834570326143876e-05,8.765967504587024e-05,8.732904825592414e-05,8.676059223944321e-05,8.530428021913394e-05,8.373906894121319e-05,8.430698653683066e-05,8.40083448565565e-05,8.266594522865489e-05,8.37376865092665e-05,8.069703471846879e-05,8.09741613920778e-05,7.91477577877231e-05,7.848311361158267e-05,7.838987949071452e-05,7.726067997282371e-05,7.658824324607849e-05,7.647633901797235e-05,7.570278103230521e-05,7.47572848922573e-05,7.362705946434289e-05,7.449567783623934e-05,7.215829100459814e-05,7.31583422748372e-05,7.231111521832645e-05,7.196363731054589e-05,7.163801637943834e-05,
mae,0.1508239209651947,0.04184708744287491,0.027300206944346428,0.021926729008555412,0.019397908821702003,0.017637314274907112,0.016415124759078026,0.015605355612933636,0.014985177665948868,0.014558404684066772,0.01410220842808485,0.013652495108544827,0.01339086052030325,0.01311747170984745,0.012801676988601685,0.012556883506476879,0.012402699328958988,0.012207281775772572,0.011908255517482758,0.011771905235946178,0.011633354239165783,0.011457141488790512,0.011240564286708832,0.011023733764886856,0.01099727489054203,0.010625522583723068,0.010695371776819229,0.010627899318933487,0.010439685545861721,0.010309018194675446,0.010174470022320747,0.010241941548883915,0.010180030018091202,0.01320677064359188,0.014662347733974457,0.009886606596410275,0.009714198298752308,0.009625835344195366,0.009486899711191654,0.009421298280358315,0.009441755712032318,0.009304231964051723,0.009221039712429047,0.009108197875320911,0.008994054980576038,0.00899170059710741,0.00893032643944025,0.008794845081865788,0.010979557409882545,0.013291645795106888,0.012910237535834312,0.01553900633007288,0.015168320387601852,0.013290763832628727,0.011493852362036705,0.012497508898377419,0.00914720632135868,0.00864921323955059,0.008341600187122822,0.008209982886910439,0.008020985871553421,0.008119173347949982,0.00797075405716896,0.007980547845363617,0.007870771922171116,0.007930602878332138,0.007809935603290796,0.007750808726996183,0.007635585498064756,0.007661915849894285,0.007598863914608955,0.007614435162395239,0.007575431372970343,0.007562878541648388,0.0074334172531962395,0.007594100199639797,0.0074489302933216095,0.007342050783336163,0.007267077453434467,0.007325806189328432,0.007363415788859129,0.007248361594974995,0.007278186734765768,0.007277579978108406,0.007204973138868809,0.007168624550104141,0.00710603641346097,0.0070895301178097725,0.007051995489746332,0.0070761702954769135,0.007108215242624283,0.007027796469628811,0.006921085529029369,0.006914430297911167,0.007022449281066656,0.00680939294397831,0.006880775559693575,0.006806289777159691,0.00686250813305378,0.006758596748113632,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5867      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5868      
=================================================================
Total params: 11,735
Trainable params: 11,735
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 5,867
Trainable params: 5,867
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 5,868
Trainable params: 5,868
Non-trainable params: 0
_________________________________________________________________
