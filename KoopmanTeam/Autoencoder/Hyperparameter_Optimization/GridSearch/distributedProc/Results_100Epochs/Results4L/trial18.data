2021-06-26
loss,0.421527624130249,0.2307988405227661,0.19982442259788513,0.16046041250228882,0.12046099454164505,0.08415866643190384,0.06873142719268799,0.06063093990087509,0.0541277676820755,0.049648236483335495,0.04567347839474678,0.04290735349059105,0.03998609632253647,0.03817199170589447,0.03646942973136902,0.03507300466299057,0.034062519669532776,0.033227697014808655,0.0327993668615818,0.031741902232170105,0.03093251958489418,0.030657164752483368,0.02992045320570469,0.02928856760263443,0.028944872319698334,0.028334492817521095,0.028081391006708145,0.027655551210045815,0.027074135839939117,0.027100173756480217,0.026389291509985924,0.026095807552337646,0.02601552940905094,0.025504453107714653,0.025349264964461327,0.025218527764081955,0.0247071273624897,0.02473645843565464,0.024426275864243507,0.027834730222821236,0.028912195935845375,0.023854168131947517,0.023400062695145607,0.023247268050909042,0.02267884463071823,0.023035168647766113,0.022762734442949295,0.022599834948778152,0.022474827244877815,0.022323139011859894,0.02188975363969803,0.02192557416856289,0.021768704056739807,0.021580969914793968,0.021469812840223312,0.02120312862098217,0.021274790167808533,0.020984625443816185,0.02094443142414093,0.02072311006486416,0.020722907036542892,0.02047692984342575,0.020322848111391068,0.026893507689237595,0.03192070126533508,0.028833264485001564,0.027196694165468216,0.029582429677248,0.03399854898452759,0.03896471485495567,0.03566766530275345,0.03236512839794159,0.029889941215515137,0.028111018240451813,0.02685682289302349,0.02573295682668686,0.03410939872264862,0.03414839133620262,0.031368404626846313,0.028653118759393692,0.026127832010388374,0.024493275210261345,0.02343868650496006,0.022700579836964607,0.02708199992775917,0.03258614242076874,0.030990567058324814,0.029147973284125328,0.027394257485866547,0.0258527509868145,0.024878904223442078,0.02410976216197014,0.02337511256337166,0.022861218079924583,0.022289788350462914,0.02198108844459057,0.021434202790260315,0.02116134576499462,0.020725803449749947,0.019943589344620705,
mse,0.06791918724775314,0.018736261874437332,0.01398079376667738,0.008808664046227932,0.004849103279411793,0.0023139447439461946,0.0015164475189521909,0.001179091865196824,0.0009461380541324615,0.0007770359516143799,0.0006545536452904344,0.0005637076683342457,0.00048639107262715697,0.0004376473370939493,0.0003959439927712083,0.00036710489075630903,0.0003417257685214281,0.0003243559622205794,0.0003138200263492763,0.00029231689404696226,0.000277779035968706,0.0002707148087210953,0.00025786436162889004,0.0002466642181389034,0.00024006524472497404,0.00023037406208459288,0.00022471258125733584,0.00021811865735799074,0.00020877771021332592,0.00020920041424687952,0.0001984187838388607,0.00019415811402723193,0.00019343179883435369,0.00018389664182905108,0.00018286124395672232,0.00018132789409719408,0.0001750621886458248,0.00017261500761378556,0.0001685782481217757,0.0002580948348622769,0.0002900532854255289,0.00016378125292249024,0.0001550772285554558,0.0001539171062177047,0.00014977584942243993,0.0001496544573456049,0.00014779870980419219,0.00014478468801826239,0.0001423258800059557,0.00014094931248109788,0.00013723115262109786,0.00013806478818878531,0.00013393261178862303,0.00013135677727404982,0.00013008163659833372,0.0001273087109439075,0.00012777672964148223,0.00012441151193343103,0.00012387576862238348,0.00012130490358686075,0.00012124237400712445,0.00011882754188263789,0.00011710715625667945,0.00023993362265173346,0.00028318329714238644,0.00023226122721098363,0.00020757033780682832,0.0002585543261375278,0.0003373132785782218,0.0004183931741863489,0.0003490673843771219,0.0002892383199650794,0.000248584256041795,0.00022093227016739547,0.00020261235476937145,0.00018660597561392933,0.0003343052521813661,0.0003203246451448649,0.00027033285005018115,0.00022648420417681336,0.00019127869745716453,0.00017030592425726354,0.0001564844569656998,0.0001487361587351188,0.00021515531989280134,0.00029266602359712124,0.00026489596348255873,0.00023582749417982996,0.00021109022782184184,0.00019002455519512296,0.00017836684128269553,0.00016842408513184637,0.000160139927174896,0.00015318728401325643,0.00014703627675771713,0.00014284932694863528,0.00013596848293673247,0.00013238938117865473,0.00012737209908664227,0.00011809570423793048,
mae,0.17577612400054932,0.09546743333339691,0.07847986370325089,0.06564279645681381,0.05180000886321068,0.036129727959632874,0.029333338141441345,0.025833357125520706,0.02304181084036827,0.021189508959650993,0.019415371119976044,0.0183036457747221,0.017043132334947586,0.016327183693647385,0.015625011175870895,0.014875493943691254,0.014540630392730236,0.014102556742727757,0.013935783877968788,0.013439485803246498,0.01319273840636015,0.01279265433549881,0.012742682360112667,0.012460671365261078,0.012290344573557377,0.01212331373244524,0.01188259944319725,0.011704840697348118,0.011493667028844357,0.011525113135576248,0.011193405836820602,0.011103430762887001,0.010958682745695114,0.010785544291138649,0.010711977258324623,0.010754663497209549,0.01049426756799221,0.010489042848348618,0.010499101132154465,0.011882130987942219,0.0122837470844388,0.010128278285264969,0.009918083436787128,0.009905601851642132,0.009546409361064434,0.009662183001637459,0.0097082844004035,0.009498829022049904,0.009617345407605171,0.009501485154032707,0.009415460750460625,0.009284588508307934,0.009321901015937328,0.009138916619122028,0.00910378247499466,0.009020168334245682,0.009001766331493855,0.008865482173860073,0.008928513154387474,0.00875625666230917,0.008867058902978897,0.008639098145067692,0.008699964731931686,0.011551647447049618,0.01396294217556715,0.012707463465631008,0.012032120488584042,0.012623745948076248,0.014289298094809055,0.016240419819951057,0.014663306064903736,0.013526517897844315,0.012502566911280155,0.011802490800619125,0.011312885209918022,0.010939869098365307,0.014313770458102226,0.014442335814237595,0.013498603366315365,0.012614687904715538,0.011459866538643837,0.010738138109445572,0.010322648100554943,0.009950616396963596,0.011691494844853878,0.013463195413351059,0.012770254164934158,0.012035115621984005,0.011574999429285526,0.01101923268288374,0.01056451816111803,0.010219183750450611,0.009887988679111004,0.009651802480220795,0.00942975003272295,0.009278858080506325,0.00903861690312624,0.008913742378354073,0.008643750101327896,0.00822209008038044,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9995      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9996      
=================================================================
Total params: 19,991
Trainable params: 19,991
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 9,995
Trainable params: 9,995
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 9,996
Trainable params: 9,996
Non-trainable params: 0
_________________________________________________________________
