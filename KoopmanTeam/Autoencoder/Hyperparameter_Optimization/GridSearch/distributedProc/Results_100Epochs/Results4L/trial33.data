2021-06-26
loss,0.4024891257286072,0.23049288988113403,0.2160521298646927,0.19068913161754608,0.13566574454307556,0.1254386305809021,0.12181253731250763,0.08035432547330856,0.06745366752147675,0.07453859597444534,0.07335877418518066,0.07036418467760086,0.054019007831811905,0.04921838268637657,0.06252814084291458,0.05085008963942528,0.04211299866437912,0.04323646053671837,0.042995430529117584,0.03261202946305275,0.03898337483406067,0.03418058902025223,0.030067438259720802,0.036116041243076324,0.03499555587768555,0.03320901468396187,0.030643513426184654,0.026683252304792404,0.03073529526591301,0.03099510632455349,0.030748015269637108,0.02917405590415001,0.025658080354332924,0.020460113883018494,0.019524775445461273,0.023836705833673477,0.02244887314736843,0.027823641896247864,0.02763492986559868,0.02762724831700325,0.027188073843717575,0.022701499983668327,0.01837587170302868,0.02238091640174389,0.021590042859315872,0.02011185884475708,0.019341973587870598,0.02299327217042446,0.023377766832709312,0.02320817857980728,0.019588273018598557,0.019710512831807137,0.0224514938890934,0.020863939076662064,0.01903890259563923,0.021516937762498856,0.021920615807175636,0.022027986124157906,0.021240003407001495,0.018938129767775536,0.018133042380213737,0.021431786939501762,0.020920345559716225,0.018573211506009102,0.017575519159436226,0.019543414935469627,0.018105296418070793,0.0175932664424181,0.01724625937640667,0.019608519971370697,0.018912963569164276,0.019054630771279335,0.018992504104971886,0.015771323814988136,0.014071711339056492,0.017062662169337273,0.019052302464842796,0.018148275092244148,0.01881607249379158,0.017743850126862526,0.0172391589730978,0.016001123934984207,0.01422744058072567,0.019027814269065857,0.017409877851605415,0.015818454325199127,0.014593196101486683,0.015951981768012047,0.016232438385486603,0.01718476600944996,0.017042873427271843,0.015460964292287827,0.017354751005768776,0.018104268237948418,0.016588659957051277,0.01671479642391205,0.015905719250440598,0.01704271137714386,0.016550391912460327,0.017255885526537895,
mse,0.060349345207214355,0.01826971396803856,0.016238879412412643,0.012486730702221394,0.005480929743498564,0.004501630552113056,0.004899770487099886,0.0019444340141490102,0.0013034912990406156,0.0016121136723086238,0.001594466157257557,0.0013665723381564021,0.0008287287782877684,0.000732561806216836,0.0011863014660775661,0.0007315466646105051,0.0005117470282129943,0.0005427267169579864,0.0005109020275995135,0.00031373300589621067,0.0004258044937159866,0.00034356993273831904,0.00027227154350839555,0.0003830167988780886,0.00035290696541778743,0.000312353135086596,0.00027064711321145296,0.00020700260938610882,0.0002755255554802716,0.0002709505206439644,0.000267492956481874,0.000243377813603729,0.00018855738744605333,0.00012780634278897196,0.0001149578602053225,0.00016458598838653415,0.00014606626064050943,0.00021813708008266985,0.00022026484657544643,0.0002121719007845968,0.00020415835024323314,0.00014818481577094644,0.0001027502294164151,0.00014345449744723737,0.00013626107829622924,0.00011810201976913959,0.00011088987230323255,0.0001541671372251585,0.00015678808267693967,0.00015391703345812857,0.00011079116666223854,0.00011207247007405385,0.00014278347953222692,0.0001287325139855966,0.00010519891657168046,0.00013133831089362502,0.00013430547551251948,0.0001383498020004481,0.000127621999126859,0.00010105806723004207,9.646134276408702e-05,0.00013100611977279186,0.0001246556785190478,9.873462840914726e-05,8.989560592453927e-05,0.00011160620488226414,9.818372927838936e-05,9.095938003156334e-05,8.691386028658599e-05,0.00010810504318214953,0.00010090655996464193,0.00010207770537817851,0.00010057880717795342,7.403537892969325e-05,5.905924990656786e-05,8.571107173338532e-05,0.00010119864600710571,9.355710062664002e-05,9.915106056723744e-05,8.885293209459633e-05,8.483965939376503e-05,7.837106386432424e-05,6.27476692898199e-05,0.00010041450877906755,8.438586519332603e-05,7.240878767333925e-05,6.406736792996526e-05,7.991798338480294e-05,7.64252181397751e-05,8.432262256974354e-05,8.00300549599342e-05,6.928892980795354e-05,8.734349103178829e-05,9.154274448519573e-05,7.76886663516052e-05,7.832575647626072e-05,7.227606693049893e-05,8.320296183228493e-05,7.946956611704081e-05,8.513759530615062e-05,
mae,0.17102468013763428,0.097112275660038,0.09362843632698059,0.08281931281089783,0.05813741683959961,0.05358912795782089,0.052882108837366104,0.0347290076315403,0.028862936422228813,0.031419917941093445,0.03126810863614082,0.02939184196293354,0.02368425764143467,0.020969796925783157,0.027225065976381302,0.02166086621582508,0.017706280574202538,0.01831423118710518,0.018397968262434006,0.013586803339421749,0.016787996515631676,0.014631692320108414,0.01280982606112957,0.015478437766432762,0.01499328762292862,0.014138592407107353,0.012950379401445389,0.011317521333694458,0.013112759217619896,0.013178051449358463,0.013160879723727703,0.012308083474636078,0.01080591045320034,0.008731930516660213,0.008307019248604774,0.010081149637699127,0.009534342214465141,0.011873681098222733,0.011528246104717255,0.011561497114598751,0.011358865536749363,0.009657411836087704,0.007816808298230171,0.009515365585684776,0.009311998263001442,0.008479021489620209,0.008167745545506477,0.009796349331736565,0.009884669445455074,0.009887458756566048,0.008325448259711266,0.008375044912099838,0.009470751509070396,0.008863040246069431,0.008005700074136257,0.009367784485220909,0.009322305209934711,0.00929324422031641,0.008925692178308964,0.008055278100073338,0.00767180509865284,0.00917043350636959,0.008881599642336369,0.00786836352199316,0.007425476331263781,0.008315999060869217,0.007759268395602703,0.007440655026584864,0.007258540950715542,0.008325183764100075,0.007989760488271713,0.008128237910568714,0.00805208645761013,0.006607770454138517,0.005960511509329081,0.007271410897374153,0.0080107431858778,0.007660738192498684,0.008143582381308079,0.007522776257246733,0.007343245204538107,0.006769924890249968,0.006047323811799288,0.008161966688930988,0.00739666260778904,0.00659970985725522,0.00621054507791996,0.006700076628476381,0.006917788181453943,0.007266061846166849,0.007355670910328627,0.0065834904089570045,0.007385826203972101,0.007731386926025152,0.006990348920226097,0.007086586207151413,0.006621177773922682,0.007166240829974413,0.006897310726344585,0.007262611296027899,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 33603     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 33604     
=================================================================
Total params: 67,207
Trainable params: 67,207
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 33,603
Trainable params: 33,603
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 33,604
Trainable params: 33,604
Non-trainable params: 0
_________________________________________________________________
