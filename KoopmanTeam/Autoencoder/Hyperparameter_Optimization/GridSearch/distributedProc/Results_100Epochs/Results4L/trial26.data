2021-06-26
loss,0.3317740559577942,0.2278703898191452,0.14979435503482819,0.08683037757873535,0.09437165409326553,0.06575779616832733,0.0830395296216011,0.08082965761423111,0.07663296163082123,0.07763435691595078,0.06310267746448517,0.04889839515089989,0.05035264045000076,0.04758017137646675,0.04433241859078407,0.06146645545959473,0.05581464618444443,0.0466909259557724,0.03746899962425232,0.03154929727315903,0.029214268550276756,0.027866432443261147,0.027477316558361053,0.026656806468963623,0.02595655992627144,0.02627846784889698,0.03773486241698265,0.03935305029153824,0.04251342639327049,0.04014703258872032,0.033468883484601974,0.03345411643385887,0.03491882607340813,0.029453637078404427,0.028126215562224388,0.02227441966533661,0.023371409624814987,0.02711683325469494,0.03635387122631073,0.034291476011276245,0.02984575740993023,0.027687760069966316,0.026399878785014153,0.026307718828320503,0.023926792666316032,0.02143194153904915,0.01985356956720352,0.01927119679749012,0.01878550834953785,0.01838419772684574,0.018147865310311317,0.017807448282837868,0.017500044777989388,0.01757480949163437,0.017303533852100372,0.017177805304527283,0.016987135633826256,0.016797447577118874,0.016875965520739555,0.01665961556136608,0.016521062701940536,0.016535475850105286,0.01650388352572918,0.016285113990306854,0.01612774096429348,0.016003139317035675,0.01596534438431263,0.01594366878271103,0.015842942520976067,0.0157161932438612,0.015605905093252659,0.01545458659529686,0.01551081147044897,0.015365490689873695,0.015350491739809513,0.015253711491823196,0.015108433552086353,0.014974646270275116,0.014959726482629776,0.014816266484558582,0.014828086830675602,0.01477203331887722,0.014647449366748333,0.014453083276748657,0.01438761968165636,0.014436035417020321,0.014333764091134071,0.014296055771410465,0.014142571948468685,0.014152985997498035,0.015629220753908157,0.02269633300602436,0.023224573582410812,0.02281050942838192,0.023214902728796005,0.023427359759807587,0.021198168396949768,0.02284090593457222,0.023502850905060768,0.022890225052833557,
mse,0.03725019097328186,0.017925243824720383,0.007712742779403925,0.0022715518716722727,0.0025998239871114492,0.0013126112753525376,0.0019776662811636925,0.001889833714812994,0.0016935993917286396,0.0017132925568148494,0.0011370009742677212,0.0007023735088296235,0.0007279575802385807,0.0006481438176706433,0.0005825969856232405,0.0010541498195379972,0.0009007474291138351,0.0006200091447681189,0.0004129151930101216,0.0002952032664325088,0.0002433986373944208,0.0002285976952407509,0.00021491300140041858,0.00020434606994967908,0.00019727356266230345,0.00019961096404585987,0.0004156676586717367,0.0004488737613428384,0.000509448058437556,0.0004456852620933205,0.0003173777076881379,0.0003238250210415572,0.00034566698013804853,0.00025643163826316595,0.00023880702792666852,0.00014345742238219827,0.00016232734196819365,0.00021061813458800316,0.00037256471114233136,0.00032485745032317936,0.00025561373331584036,0.00021667932742275298,0.00019960729696322232,0.0002018548984779045,0.00016987636627163738,0.000128541883896105,0.00011156161053804681,0.00010414085409138352,9.941479220287874e-05,9.469479118706658e-05,9.238019265467301e-05,8.942149725044146e-05,8.652056567370892e-05,8.775846799835563e-05,8.372894808417186e-05,8.283771603601053e-05,8.16924512037076e-05,7.964896940393373e-05,8.049597090575844e-05,7.806957000866532e-05,7.668259786441922e-05,7.676173117943108e-05,7.668199395993724e-05,7.454376464011148e-05,7.319211727008224e-05,7.239663682412356e-05,7.259319681907073e-05,7.129812001949176e-05,7.045787060633302e-05,6.922124157426879e-05,6.80062294122763e-05,6.732801557518542e-05,6.892282544868067e-05,6.662279338343069e-05,6.642516382271424e-05,6.485241465270519e-05,6.427356856875122e-05,6.351675256155431e-05,6.278049113461748e-05,6.166646926430985e-05,6.173902511363849e-05,6.0840960941277444e-05,5.984300150885247e-05,5.8284280385123566e-05,5.839149162056856e-05,5.850973684573546e-05,5.732821227866225e-05,5.693010098184459e-05,5.583611346082762e-05,5.617983697447926e-05,7.580006786156446e-05,0.00014852017920929939,0.00015249790158122778,0.00014787734835408628,0.00015377729141619056,0.0001536390627734363,0.00013088001287542284,0.00014912450569681823,0.0001551240566186607,0.00014730560360476375,
mae,0.13972076773643494,0.09656651318073273,0.06454675644636154,0.03722037747502327,0.039960335940122604,0.027864180505275726,0.03490612655878067,0.034602776169776917,0.032582882791757584,0.0336756594479084,0.02687659300863743,0.020515907555818558,0.02101254276931286,0.02016139216721058,0.018880570307374,0.02669394202530384,0.023870116099715233,0.01965489611029625,0.015655335038900375,0.013365448452532291,0.012622195295989513,0.011922738514840603,0.011797960847616196,0.011416562832891941,0.011077630333602428,0.011114442721009254,0.015567038208246231,0.016317209228873253,0.018428489565849304,0.017324674874544144,0.013795703649520874,0.014040139503777027,0.014830146916210651,0.012301601469516754,0.0118109080940485,0.009460781700909138,0.009990127757191658,0.011497953906655312,0.015523536130785942,0.014758408069610596,0.013105022720992565,0.012113251723349094,0.011364412494003773,0.011336833238601685,0.010121762752532959,0.009096689522266388,0.008506247773766518,0.008265931159257889,0.00803848821669817,0.007887100800871849,0.007729155942797661,0.00756633747369051,0.007400122471153736,0.007506202906370163,0.007458893116563559,0.007299261167645454,0.007262155879288912,0.007047976832836866,0.007226706948131323,0.007015315815806389,0.007080325856804848,0.007008523214608431,0.007084755692631006,0.006873000878840685,0.0069533418864011765,0.006821703165769577,0.006817428395152092,0.0067985947243869305,0.006685423199087381,0.006685731466859579,0.006618299521505833,0.0066336519084870815,0.006531253457069397,0.006525646895170212,0.006418006960302591,0.006574647501111031,0.006416333373636007,0.00638505257666111,0.006316827144473791,0.006313620135188103,0.006275093648582697,0.006294524762779474,0.006195947527885437,0.0061163268983364105,0.006109330803155899,0.006146848201751709,0.006039585918188095,0.006104282569140196,0.006003194488584995,0.00594365457072854,0.006557219196110964,0.00968912336975336,0.009849842637777328,0.00953331496566534,0.009861336089670658,0.009669548831880093,0.008822346106171608,0.009598711505532265,0.01004101149737835,0.009429981000721455,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 19827     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 19828     
=================================================================
Total params: 39,655
Trainable params: 39,655
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 19,827
Trainable params: 19,827
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 19,828
Trainable params: 19,828
Non-trainable params: 0
_________________________________________________________________
