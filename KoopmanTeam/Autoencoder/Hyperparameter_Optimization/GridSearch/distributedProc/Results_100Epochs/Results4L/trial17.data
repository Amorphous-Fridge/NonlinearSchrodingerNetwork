2021-06-26
loss,0.41278618574142456,0.09219902008771896,0.05670005828142166,0.04739489406347275,0.042478661984205246,0.039210714399814606,0.03754505515098572,0.03595488891005516,0.034289322793483734,0.032782815396785736,0.031853340566158295,0.030899198725819588,0.03027871437370777,0.02950776182115078,0.02862532064318657,0.02839716523885727,0.034112799912691116,0.0275002121925354,0.026735687628388405,0.026314496994018555,0.02592550218105316,0.027045929804444313,0.027829892933368683,0.026044936850667,0.044610075652599335,0.04148952662944794,0.037360720336437225,0.025538351386785507,0.023355694487690926,0.022976672276854515,0.022788193076848984,0.022589148953557014,0.022387830540537834,0.02196316048502922,0.02189401350915432,0.021499209105968475,0.021457407623529434,0.021070601418614388,0.021181480959057808,0.020825715735554695,0.02062806859612465,0.020574355497956276,0.02031417191028595,0.020326733589172363,0.02013072557747364,0.019978633150458336,0.019800864160060883,0.0196547769010067,0.022475140169262886,0.03314967080950737,0.026600966230034828,0.03183862939476967,0.03191662207245827,0.029106125235557556,0.026921410113573074,0.02526850625872612,0.02415669895708561,0.02304915338754654,0.03231723606586456,0.03387049213051796,0.03046990931034088,0.02831701748073101,0.026789262890815735,0.025573205202817917,0.026155991479754448,0.026135332882404327,0.025092942640185356,0.023975800722837448,0.02751227654516697,0.03642852231860161,0.033416442573070526,0.030131928622722626,0.027908870950341225,0.02629188820719719,0.02495240978896618,0.023955469951033592,0.02304864674806595,0.02232491783797741,0.021630791947245598,0.021151872351765633,0.02063484862446785,0.020039159804582596,0.019764572381973267,0.02972981706261635,0.030214061960577965,0.024507980793714523,0.022275976836681366,0.020784659311175346,0.019868535920977592,0.018931983038783073,0.018703365698456764,0.01845683716237545,0.017968138679862022,0.028510509058833122,0.028633978217840195,0.025764815509319305,0.023468727245926857,0.022297030314803123,0.022586314007639885,0.024398231878876686,
mse,0.07593072205781937,0.0028476885054260492,0.000943566847126931,0.0006448985077440739,0.0005057377275079489,0.00043351779459044337,0.00039042887510731816,0.00035762146580964327,0.00032337545417249203,0.0002937855024356395,0.0002781897783279419,0.00026191663346253335,0.00025157976779155433,0.00023716542636975646,0.00022582942619919777,0.00022140881628729403,0.00035778721212409437,0.0002066910092253238,0.00019488042744342238,0.00018856427050195634,0.00018365230062045157,0.00020398171909619123,0.00021342880791053176,0.00019202860130462795,0.0005891186883673072,0.0005046048318035901,0.0003924460324924439,0.0001865748199634254,0.0001500219659646973,0.00014456352801062167,0.00014234580157790333,0.00013848695380147547,0.0001372283441014588,0.00013166217831894755,0.0001298549905186519,0.00012535553833004087,0.0001249260240001604,0.00012038520799251273,0.00012190125562483445,0.000117382405733224,0.00011546860332600772,0.00011455060302978382,0.00011283211642876267,0.00011210815864615142,0.00011001118400599808,0.00010850653052330017,0.00010630747419781983,0.00010454519360791892,0.00016507100372109562,0.00035929062869399786,0.00022830741363577545,0.00029656157130375504,0.00028951754211448133,0.00023476504429709166,0.0001997686777031049,0.0001767463982105255,0.00016063626389950514,0.00014735697186551988,0.0003046680358238518,0.00031441249302588403,0.0002550772624090314,0.00022047296806704253,0.0001975826598936692,0.0001785644271876663,0.0001994084450416267,0.00019329201313667,0.00017749378457665443,0.00015730266750324517,0.0002270321419928223,0.0003813763032667339,0.0003056063433177769,0.00024772624601610005,0.00021458545234054327,0.00019117204647045583,0.00017262407345697284,0.0001586295838933438,0.0001468378322897479,0.0001384536299156025,0.000130361775518395,0.00012459758727345616,0.00011886870197486132,0.00011384469689801335,0.00011142103176098317,0.00024968833895400167,0.00025084783555939794,0.0001654377265367657,0.00013776044943369925,0.00012022865848848596,0.00010953388846246526,0.00010027809912571684,9.836298704613e-05,9.5320341642946e-05,9.330825560027733e-05,0.00023410769063048065,0.00022285305021796376,0.00018588652892503887,0.00015423439617734402,0.00014209368964657187,0.00014525545702781528,0.00016664975555613637,
mae,0.17861488461494446,0.03925098478794098,0.024162687361240387,0.02016839012503624,0.017952855676412582,0.016676317900419235,0.0158543698489666,0.015350496396422386,0.014580982737243176,0.013844753615558147,0.013490961864590645,0.013147803954780102,0.012907654047012329,0.01243691798299551,0.012081855908036232,0.01214556209743023,0.01428782194852829,0.011579147540032864,0.011362949386239052,0.011091099120676517,0.011009247042238712,0.01157400943338871,0.011873290874063969,0.011096477508544922,0.019052941352128983,0.017339743673801422,0.01596936397254467,0.01078186184167862,0.01001248974353075,0.009845954366028309,0.009685572236776352,0.009511961601674557,0.009640011005103588,0.00944127980619669,0.009393124841153622,0.009136187843978405,0.009252071380615234,0.008904700167477131,0.009067665785551071,0.008972009643912315,0.008941811509430408,0.008826064877212048,0.00867017637938261,0.008511793799698353,0.00862227100878954,0.008372179232537746,0.008425690233707428,0.00836206879466772,0.009503878653049469,0.013980771414935589,0.011304869316518307,0.013462172821164131,0.013877439312636852,0.013250193558633327,0.012260260991752148,0.011242971755564213,0.010451534762978554,0.009815421886742115,0.013906010426580906,0.014363400638103485,0.012849867343902588,0.011889771558344364,0.011128592304885387,0.010797752067446709,0.011236113496124744,0.010992790572345257,0.010568997822701931,0.01016891747713089,0.011762981303036213,0.015356970950961113,0.014429902657866478,0.013098763301968575,0.011988215148448944,0.011697492562234402,0.011236986145377159,0.010828191414475441,0.010377282276749611,0.00998544879257679,0.00961232278496027,0.009357609786093235,0.00907948613166809,0.008570855483412743,0.008307008072733879,0.01268037874251604,0.01324015948921442,0.009799694642424583,0.008430717512965202,0.008466195315122604,0.008244079537689686,0.007916100323200226,0.00794872548431158,0.007915802299976349,0.007709296885877848,0.012267738580703735,0.011997506953775883,0.010674912482500076,0.010177495889365673,0.009613532572984695,0.009517412632703781,0.010397988371551037,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8611      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8612      
=================================================================
Total params: 17,223
Trainable params: 17,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 8,611
Trainable params: 8,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 8,612
Trainable params: 8,612
Non-trainable params: 0
_________________________________________________________________
