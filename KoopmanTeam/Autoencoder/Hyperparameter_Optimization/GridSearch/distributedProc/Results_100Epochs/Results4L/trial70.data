2021-06-26
loss,0.7063982486724854,0.2486664205789566,0.23929743468761444,0.2296902984380722,0.22300338745117188,0.2045588493347168,0.16651073098182678,0.1581490933895111,0.09711732715368271,0.09700586646795273,0.08979771286249161,0.08041045069694519,0.06997650116682053,0.06439997255802155,0.0715811476111412,0.05462561920285225,0.06904289871454239,0.062012072652578354,0.04849350079894066,0.054005712270736694,0.0455605648458004,0.04308657348155975,0.05191879719495773,0.052602823823690414,0.045983146876096725,0.0426570400595665,0.044401198625564575,0.04241003841161728,0.031725529581308365,0.03967709839344025,0.03591329976916313,0.04068383574485779,0.0434073880314827,0.03488240763545036,0.03778541833162308,0.039314690977334976,0.031523432582616806,0.02925078198313713,0.03273630514740944,0.0312606543302536,0.0393199697136879,0.03138916939496994,0.03879414498806,0.03286381810903549,0.03331013396382332,0.028987636789679527,0.030048806220293045,0.032453976571559906,0.02943550981581211,0.02730441652238369,0.02932746335864067,0.029362108558416367,0.031160008162260056,0.02821764163672924,0.02110704593360424,0.03159059211611748,0.03230137750506401,0.029234400019049644,0.027665875852108,0.025283480063080788,0.024936936795711517,0.026784060522913933,0.022285187616944313,0.024309394881129265,0.026446383446455002,0.02267741598188877,0.02643207088112831,0.027494654059410095,0.03136458247900009,0.025700336322188377,0.023275358602404594,0.02295556850731373,0.021964769810438156,0.018134064972400665,0.023149659857153893,0.025008391588926315,0.022869408130645752,0.024369604885578156,0.025475449860095978,0.026904631406068802,0.02389933168888092,0.02608979493379593,0.022291449829936028,0.020687894895672798,0.020389648154377937,0.023612575605511665,0.023637985810637474,0.024188529700040817,0.02198512852191925,0.023445263504981995,0.018793247640132904,0.02153179794549942,0.023139970377087593,0.020749157294631004,0.021725108847022057,0.025516673922538757,0.022570155560970306,0.019189154729247093,0.024505963549017906,0.02188180759549141,
mse,0.3282170593738556,0.020274246111512184,0.019162504002451897,0.017923617735505104,0.01674031838774681,0.013605100102722645,0.008370981551706791,0.007618092931807041,0.0027399854734539986,0.002675780327990651,0.0023790958803147078,0.0019214965868741274,0.0014828280545771122,0.0012380860280245543,0.0015581143088638783,0.0008592124795541167,0.0013610012829303741,0.00108518882188946,0.0006844685995019972,0.0008126094471663237,0.000572388235013932,0.0005463960114866495,0.0007774239056743681,0.0008026053546927869,0.0005879466771148145,0.000520438130479306,0.0005489247851073742,0.000502728798892349,0.0003027274797204882,0.0004807162913493812,0.0003634063759818673,0.0004825668002013117,0.0005243840278126299,0.0003477037826087326,0.0003981822228524834,0.0004299365682527423,0.0002862433029804379,0.00024829659378156066,0.00029593671206384897,0.0002779706264846027,0.00044891185825690627,0.00027676549507305026,0.00041982397669926286,0.00029927180730737746,0.00030693531152792275,0.00023044970293994993,0.0002599563158582896,0.00029404228553175926,0.00023664427862968296,0.00020971649792045355,0.0002440928656142205,0.00024517421843484044,0.00027251828578300774,0.00022328700288198888,0.00013343646423891187,0.0002847439900506288,0.00029251776868477464,0.00024155425489880145,0.0002162306336686015,0.0001817089505493641,0.00017772370483726263,0.00020116787345614284,0.00014520989498123527,0.0001664136943873018,0.00019334604439791292,0.00015095618437044322,0.00019490574777591974,0.00021897962142247707,0.00027039559790864587,0.00018882649601437151,0.00015308271395042539,0.00015296736091841012,0.00014255578571464866,0.00010009370453190058,0.00015477408305741847,0.00017735401343088597,0.00014510542678181082,0.0001690363569650799,0.00018258404452353716,0.00020399877394083887,0.0001591016916790977,0.0001874035078799352,0.00014178751735016704,0.00012193942529847845,0.00011782431829487905,0.00016296497778967023,0.00015745130076538771,0.00016100167704280466,0.00013856953592039645,0.0001564125414006412,0.00010341771121602505,0.00013057974865660071,0.0001489674614276737,0.00011912576155737042,0.00013362600293476135,0.00018043900490738451,0.00014193894458003342,0.00010662322165444493,0.00016772093658801168,0.00013730610953643918,
mae,0.29463183879852295,0.10513316839933395,0.10364547371864319,0.09910225868225098,0.09614977985620499,0.08692959696054459,0.07099252939224243,0.06748654693365097,0.041563838720321655,0.04165665805339813,0.037639521062374115,0.03419814258813858,0.029545927420258522,0.027595777064561844,0.03061162866652012,0.0233171246945858,0.02964257262647152,0.026314105838537216,0.020834563300013542,0.023053321987390518,0.019647793844342232,0.018236029893159866,0.022026481106877327,0.02254016138613224,0.01963372342288494,0.018026430159807205,0.019089991226792336,0.017793994396924973,0.01341918669641018,0.016860129311680794,0.01532386988401413,0.017262278124690056,0.018407845869660378,0.014876190572977066,0.01589064486324787,0.016786586493253708,0.01333569549024105,0.012535151094198227,0.014086481183767319,0.013405011035501957,0.01644720323383808,0.013547824695706367,0.016165606677532196,0.013932567089796066,0.014260574243962765,0.012554515153169632,0.012734060175716877,0.01369269099086523,0.012317368760704994,0.011464841663837433,0.012317230924963951,0.01234225183725357,0.013185836374759674,0.01214268896728754,0.009084666147828102,0.013723441399633884,0.013492677360773087,0.012442621402442455,0.011504892259836197,0.010721080005168915,0.010541574098169804,0.011346111074090004,0.009241013787686825,0.01034111250191927,0.011154215782880783,0.009676583111286163,0.011506475508213043,0.01151141244918108,0.012914597988128662,0.010875483974814415,0.009965622797608376,0.009726251475512981,0.009297039359807968,0.007661780808120966,0.00979069247841835,0.010775354690849781,0.00982044730335474,0.010271765291690826,0.010750639252364635,0.011284511536359787,0.010127774439752102,0.01109630148857832,0.00925404392182827,0.008643890731036663,0.008710970170795918,0.010112471878528595,0.010144753381609917,0.010183524340391159,0.0093552116304636,0.010221371427178383,0.007941478863358498,0.00890820287168026,0.01002383604645729,0.009012499824166298,0.009075957350432873,0.010606254450976849,0.009593144990503788,0.008037231862545013,0.010284112766385078,0.009326008148491383,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 287971    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 287972    
=================================================================
Total params: 575,943
Trainable params: 575,943
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 287,971
Trainable params: 287,971
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 287,972
Trainable params: 287,972
Non-trainable params: 0
_________________________________________________________________
