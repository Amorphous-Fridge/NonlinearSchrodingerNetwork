2021-06-26
loss,1.0437226295471191,0.2340916246175766,0.20878279209136963,0.17359092831611633,0.1401577591896057,0.13208630681037903,0.11906474828720093,0.10049403458833694,0.08876262605190277,0.0751042291522026,0.0810905173420906,0.06496759504079819,0.06315174698829651,0.07305338978767395,0.053813401609659195,0.060964033007621765,0.0583663135766983,0.05420778691768646,0.05185747146606445,0.04977210611104965,0.05354789271950722,0.04542362317442894,0.047412775456905365,0.04747837409377098,0.04246013984084129,0.04270721599459648,0.04092433303594589,0.03857539966702461,0.04201754555106163,0.04108162224292755,0.03888213261961937,0.041191138327121735,0.039258722215890884,0.03442416340112686,0.036727260798215866,0.030769115313887596,0.025845589116215706,0.034790776669979095,0.03493262827396393,0.03389744460582733,0.031113335862755775,0.03047955594956875,0.03523627296090126,0.02982371114194393,0.034933872520923615,0.029260020703077316,0.030267465859651566,0.030599158257246017,0.029980864375829697,0.0275847390294075,0.026629634201526642,0.027980687096714973,0.028168123215436935,0.027512816712260246,0.026471490040421486,0.025825245305895805,0.02946295216679573,0.02267041616141796,0.030422093346714973,0.02633564919233322,0.025978298857808113,0.027836261317133904,0.028224637731909752,0.02626548334956169,0.027897559106349945,0.026400236412882805,0.025518853217363358,0.022912682965397835,0.024720722809433937,0.022320600226521492,0.022552773356437683,0.024567045271396637,0.025529978796839714,0.026646576821804047,0.023804375901818275,0.024102993309497833,0.024262579157948494,0.022669954225420952,0.027239274233579636,0.021387789398431778,0.020454252138733864,0.022861486300826073,0.02463761530816555,0.02215595729649067,0.022619256749749184,0.020275883376598358,0.02377157472074032,0.021722443401813507,0.0204536821693182,0.021999549120664597,0.021489767357707024,0.0208966713398695,0.020990289747714996,0.020405052229762077,0.02031414583325386,0.021623561158776283,0.020277809351682663,0.019880443811416626,0.020751411095261574,0.02020059898495674,
mse,0.5490734577178955,0.018051158636808395,0.013560623861849308,0.009030467830598354,0.005945064593106508,0.0051075126975774765,0.004010565113276243,0.002867054659873247,0.002175356261432171,0.001654765335842967,0.0019326773472130299,0.0011899375822395086,0.0011191722005605698,0.0015175177250057459,0.0008465988212265074,0.0010570691665634513,0.000987663515843451,0.000854571582749486,0.0007519046775996685,0.0006940970779396594,0.0007969574071466923,0.0005842058453708887,0.0006382018327713013,0.0006246839184314013,0.0005223087500780821,0.0005038974923081696,0.0004657443496398628,0.00041128916200250387,0.0004949130234308541,0.00047431018901988864,0.00042845529969781637,0.00048273929860442877,0.0004194931825622916,0.00033856049412861466,0.0003753539058379829,0.00026664198958314955,0.00019788309873547405,0.0003411110956221819,0.00034360308200120926,0.00031788740307092667,0.000270774558885023,0.00025723452563397586,0.0003493112453725189,0.00024918862618505955,0.0003358719404786825,0.00023822126968298107,0.00025966769317165017,0.00026595438248477876,0.00025058083701878786,0.00021634585573337972,0.00019851401157211512,0.00022513185103889555,0.00021784145792480558,0.0002162591554224491,0.0001966597919818014,0.0001996005157707259,0.00025053051649592817,0.0001499593781773001,0.0002542373549658805,0.00019110535504296422,0.00019263177819084376,0.00021751533495262265,0.00022097887995187193,0.00019150128355249763,0.00021454671514220536,0.0001927914854604751,0.00018156353326048702,0.0001522609672974795,0.00017125993326772004,0.00014476888463832438,0.0001466898393118754,0.00017295782163273543,0.00018952754908241332,0.00019841128960251808,0.00016002397751435637,0.00016175227938219905,0.00016512641741428524,0.0001496628683526069,0.00020095473155379295,0.00013268401380628347,0.0001225557061843574,0.000146636797580868,0.00016782930470071733,0.00013882332132197917,0.0001434469158994034,0.00012174989387858659,0.00015636019816156477,0.00013447242963593453,0.00011893321061506867,0.00013703323202207685,0.00013012424460612237,0.000124598023830913,0.00012829515617340803,0.00012114705168642104,0.00011909900058526546,0.00013557022612076253,0.00011778142652474344,0.00011188539792783558,0.00012144257198087871,0.00011516072117956355,
mae,0.46537989377975464,0.10203929990530014,0.08951456099748611,0.07365149259567261,0.05916549637913704,0.05615532770752907,0.0506303533911705,0.04213571548461914,0.03774644806981087,0.03183475509285927,0.03526315093040466,0.027953071519732475,0.026806890964508057,0.03120141662657261,0.023187808692455292,0.02626592107117176,0.02434668503701687,0.023246409371495247,0.022127928212285042,0.021039701998233795,0.02312603034079075,0.019316399469971657,0.020324669778347015,0.02071322500705719,0.018023574724793434,0.018054001033306122,0.0173249002546072,0.016196541488170624,0.01770528219640255,0.01763843186199665,0.016487762331962585,0.01721969246864319,0.01709008403122425,0.014348403550684452,0.015776468440890312,0.013167718425393105,0.011087673716247082,0.01493973657488823,0.015042761340737343,0.014488893561065197,0.013339758850634098,0.013096494600176811,0.01536188367754221,0.012655992060899734,0.015108401887118816,0.012480500154197216,0.013127421028912067,0.013031003065407276,0.012690002098679543,0.011798513121902943,0.011383093893527985,0.01196428295224905,0.012567882426083088,0.01177219394594431,0.011117623187601566,0.010878801345825195,0.012359300628304482,0.009584416635334492,0.013148187659680843,0.011360835283994675,0.011021746322512627,0.011777118779718876,0.012351968325674534,0.011143259704113007,0.011634561233222485,0.011205961927771568,0.010737083852291107,0.009717751294374466,0.010274836793541908,0.009389769285917282,0.009486820548772812,0.01043681986629963,0.010791145265102386,0.011594356037676334,0.009992002509534359,0.01039714552462101,0.010378608480095863,0.009684346616268158,0.011584706604480743,0.009162163361907005,0.008644871413707733,0.009756128303706646,0.010823420248925686,0.009402204304933548,0.009607006795704365,0.008637973107397556,0.010034207254648209,0.009128889068961143,0.008704965934157372,0.00905934814363718,0.009248707443475723,0.008957727812230587,0.008829198777675629,0.008599252440035343,0.008604035712778568,0.009088610298931599,0.008633998222649097,0.008461379446089268,0.008870928548276424,0.00857929140329361,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 312739    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 312740    
=================================================================
Total params: 625,479
Trainable params: 625,479
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 312,739
Trainable params: 312,739
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 312,740
Trainable params: 312,740
Non-trainable params: 0
_________________________________________________________________
