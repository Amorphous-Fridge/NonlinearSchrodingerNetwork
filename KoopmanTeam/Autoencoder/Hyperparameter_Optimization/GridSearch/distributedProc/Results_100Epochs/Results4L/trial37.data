2021-06-26
loss,0.49002543091773987,0.14123423397541046,0.1283259242773056,0.10039667785167694,0.08051487058401108,0.09418229013681412,0.06025952845811844,0.06828127056360245,0.07614755630493164,0.07080291956663132,0.05348384380340576,0.058637674897909164,0.052413925528526306,0.04980697110295296,0.039975348860025406,0.05433116480708122,0.047700587660074234,0.04314211383461952,0.03404005989432335,0.030156325548887253,0.02905987948179245,0.0377797894179821,0.03604811057448387,0.031495559960603714,0.03368265926837921,0.03378456085920334,0.0322565920650959,0.0286378376185894,0.027732517570257187,0.02636103332042694,0.02803836576640606,0.026772983372211456,0.02878211997449398,0.028417738154530525,0.022278258576989174,0.01932421885430813,0.020256604999303818,0.021086303517222404,0.025898611173033714,0.02595881186425686,0.026101408526301384,0.023598814383149147,0.024948330596089363,0.02412867732346058,0.025342172011733055,0.021663708612322807,0.01952635683119297,0.021167753264307976,0.02262042835354805,0.023374363780021667,0.0221465602517128,0.02046027034521103,0.01954803243279457,0.020782114937901497,0.02022111974656582,0.019785504788160324,0.019637152552604675,0.020541155710816383,0.019767342135310173,0.018790826201438904,0.019582699984312057,0.019357018172740936,0.021106036379933357,0.019000956788659096,0.020284652709960938,0.019387520849704742,0.019788747653365135,0.019598333165049553,0.01739545911550522,0.016715720295906067,0.017970623448491096,0.017619766294956207,0.016438718885183334,0.017324555665254593,0.018554016947746277,0.018728042021393776,0.016275782138109207,0.015262999571859837,0.018152685835957527,0.018565567210316658,0.01763429120182991,0.015789365395903587,0.017351534217596054,0.017022401094436646,0.017663950100541115,0.01585742086172104,0.01647205650806427,0.016461173072457314,0.01642894558608532,0.016126753762364388,0.01503368467092514,0.016835570335388184,0.01710035279393196,0.016933655366301537,0.016884619370102882,0.01630309782922268,0.015566021203994751,0.014958051033318043,0.015444930642843246,0.014441289938986301,
mse,0.10424371063709259,0.005765482783317566,0.004825237672775984,0.0029778792522847652,0.0018734086770564318,0.002534474479034543,0.001048612524755299,0.0013354193652048707,0.0016534629976376891,0.0015265123220160604,0.0008155041141435504,0.0009736067149788141,0.0007885603699833155,0.0007057149196043611,0.00047431851271539927,0.000870376592501998,0.0006373489159159362,0.0005237751756794751,0.00033763120882213116,0.000269884942099452,0.00024755994672887027,0.0004064390086568892,0.0003759011742658913,0.00028923439094796777,0.0003327250888105482,0.0003219022473786026,0.0002919409307651222,0.0002327915863133967,0.00022916035959497094,0.0002058294485323131,0.00023005878028925508,0.00021334525081329048,0.0002343434316571802,0.00023405547835864127,0.00014759086479898542,0.0001123916736105457,0.00012335967039689422,0.00013482326176017523,0.00019641339895315468,0.00019502866780385375,0.00019055436132475734,0.00016125084948725998,0.00017860483785625547,0.0001647708413656801,0.00018122051551472396,0.0001358057779725641,0.00011296703451080248,0.00013199880777392536,0.00014594972890336066,0.0001585605787113309,0.0001413024147041142,0.0001217840617755428,0.0001126026181736961,0.00012354820501059294,0.00011805394024122506,0.00011655656271614134,0.00011184373579453677,0.00012094201520085335,0.00010921759530901909,0.0001020610798150301,0.00011033485498046502,0.0001087863274733536,0.00013190975005272776,0.00010370231029810384,0.0001167174632428214,0.00010790396481752396,0.0001089569996111095,0.00010873124847421423,8.98652506293729e-05,8.238661393988878e-05,9.322219557361677e-05,9.13917101570405e-05,8.171453373506665e-05,8.635887206764892e-05,9.774286445463076e-05,9.669282735558227e-05,7.720644498476759e-05,6.949188536964357e-05,9.554673306411132e-05,9.793275967240334e-05,8.894088387023658e-05,7.299867866095155e-05,8.694243297213688e-05,8.397969213547185e-05,8.892414916772395e-05,7.339746662182733e-05,7.960060611367226e-05,7.851531699998304e-05,7.881010242272168e-05,7.614235073560849e-05,6.520978058688343e-05,8.136436372296885e-05,8.146422624122351e-05,8.16900355857797e-05,7.927216938696802e-05,7.671143976040184e-05,7.109378202585503e-05,6.50766960461624e-05,7.060412463033572e-05,6.191496504470706e-05,
mae,0.20480318367481232,0.05954466760158539,0.05448436364531517,0.0418454073369503,0.033940233290195465,0.03980670124292374,0.025371020659804344,0.02892591431736946,0.03261209651827812,0.030462604016065598,0.023085780441761017,0.025109069421887398,0.022419441491365433,0.021227842196822166,0.017010532319545746,0.02272607572376728,0.020107118412852287,0.018523763865232468,0.014468017965555191,0.012731632217764854,0.01239185594022274,0.0160844586789608,0.015298645943403244,0.013297722674906254,0.014201206155121326,0.014217060059309006,0.013849956914782524,0.01226959191262722,0.011733083985745907,0.011204310692846775,0.01188793033361435,0.011441503651440144,0.012316644191741943,0.011871032416820526,0.009445500560104847,0.00821760669350624,0.008599378168582916,0.008895990438759327,0.0111476955935359,0.011050759814679623,0.011080809868872166,0.010009021498262882,0.010587133467197418,0.010156210511922836,0.010777528397738934,0.009172119200229645,0.008234191685914993,0.008963431231677532,0.009619739837944508,0.009992742910981178,0.00945650041103363,0.008806552737951279,0.00830157846212387,0.008851896971464157,0.008501035161316395,0.00830336008220911,0.008295733481645584,0.008632209151983261,0.008499136194586754,0.007912769913673401,0.008280163630843163,0.008236409164965153,0.008959558792412281,0.007959106005728245,0.008647479116916656,0.008083274587988853,0.008436472155153751,0.008373701944947243,0.007394141983240843,0.007092786952853203,0.007625292520970106,0.007396041881293058,0.006889088544994593,0.007294389419257641,0.007903601974248886,0.007975362241268158,0.006972207222133875,0.006438648793846369,0.007744424976408482,0.007835784927010536,0.007516965270042419,0.006670199800282717,0.007274180185049772,0.007231357041746378,0.007584190461784601,0.006818896159529686,0.006989619228988886,0.006924567278474569,0.00701887859031558,0.006833027116954327,0.006400498561561108,0.007128487341105938,0.007241628598421812,0.007167769130319357,0.0070487502962350845,0.006928854156285524,0.006548204459249973,0.006380533799529076,0.006577278953045607,0.006105146836489439,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 58307     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 58308     
=================================================================
Total params: 116,615
Trainable params: 116,615
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 58,307
Trainable params: 58,307
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 58,308
Trainable params: 58,308
Non-trainable params: 0
_________________________________________________________________
