2021-06-26
loss,1.2235450744628906,0.3146708011627197,0.28683993220329285,0.2567083239555359,0.23768451809883118,0.21881435811519623,0.20674213767051697,0.19690820574760437,0.18375791609287262,0.1795661896467209,0.12443587183952332,0.11803381145000458,0.09566372632980347,0.0836920291185379,0.08832938969135284,0.07013604044914246,0.07583937048912048,0.07021306455135345,0.07017847895622253,0.06777508556842804,0.055392298847436905,0.05146174132823944,0.05612180754542351,0.05736790969967842,0.046828240156173706,0.046156145632267,0.042248860001564026,0.040591761469841,0.044910088181495667,0.04768609628081322,0.03794131428003311,0.04192410409450531,0.0432513952255249,0.03421562537550926,0.028676439076662064,0.03501895070075989,0.03325418382883072,0.041766658425331116,0.034838419407606125,0.03399600461125374,0.033231738954782486,0.032142166048288345,0.03244917094707489,0.030770452693104744,0.030080461874604225,0.026478884741663933,0.031125245615839958,0.03186352923512459,0.03014553152024746,0.026013178750872612,0.02669868990778923,0.025496583431959152,0.027083005756139755,0.027323435992002487,0.029896888881921768,0.029638497158885002,0.025572873651981354,0.0261003989726305,0.02576054073870182,0.026288123801350594,0.02530820295214653,0.022651491686701775,0.017681311815977097,0.021394619718194008,0.023974841460585594,0.02670436166226864,0.02408437989652157,0.022555505856871605,0.024230923503637314,0.024811547249555588,0.02144496515393257,0.02325110137462616,0.019917748868465424,0.025850975885987282,0.022470176219940186,0.0233936570584774,0.021528834477066994,0.021700067445635796,0.02033422887325287,0.021944820880889893,0.022384053096175194,0.02078450657427311,0.021901674568653107,0.0213735681027174,0.021908115595579147,0.022267021238803864,0.021019313484430313,0.02037900872528553,0.01904858835041523,0.019527753815054893,0.018392333760857582,0.018338067457079887,0.020213045179843903,0.019586896523833275,0.020258266478776932,0.019201867282390594,0.016854306682944298,0.02018531784415245,0.019826222211122513,0.017458852380514145,
mse,0.6524412631988525,0.030203523114323616,0.025194361805915833,0.021215977147221565,0.01868382655084133,0.016297563910484314,0.01477715466171503,0.013114677742123604,0.010497613810002804,0.009639671072363853,0.00459487596526742,0.0042606377974152565,0.002642618492245674,0.00202768063172698,0.00223260885104537,0.001458567101508379,0.0016706704627722502,0.0014180635334923863,0.0013830200769007206,0.001342881005257368,0.0008876986685208976,0.0008166136685758829,0.0008983316947706044,0.0009192305733449757,0.0006160967750474811,0.0006226536934264004,0.0005043267155997455,0.0004871551354881376,0.0005661383038386703,0.0006504452903755009,0.0004070287977810949,0.0004994979244656861,0.000523979018907994,0.000338392419507727,0.00024312676396220922,0.000354787043761462,0.00031242569093592465,0.0004736874543596059,0.00034095050068572164,0.00032320187892764807,0.0003135671722702682,0.0002969596826005727,0.00030052856891416013,0.00027114676777273417,0.000250875047640875,0.0002054476790362969,0.00027128439978696406,0.0002814830804709345,0.0002561626897659153,0.00019871551194228232,0.00020327616948634386,0.000188441903446801,0.00020743106142617762,0.00021495694818440825,0.00025219586677849293,0.0002449153980705887,0.00018289143918082118,0.00019658188102766871,0.0001903580268844962,0.0002003273111768067,0.00018138466111849993,0.0001517174532637,9.403107833350077e-05,0.0001365738280583173,0.00016184384003281593,0.0002037800441030413,0.00016664102440699935,0.00014744693180546165,0.00016486708773300052,0.00017439998919144273,0.00013592471077572554,0.00015390291810035706,0.00012050950317643583,0.00018655983149074018,0.00014756123709958047,0.0001555277849547565,0.00012874208914581686,0.00013684542500413954,0.0001225167652592063,0.00013871266855858266,0.00014256520080380142,0.00012515504204202443,0.0001392141857650131,0.00013181933900341392,0.00013475047308020294,0.00014153421216178685,0.0001245658495463431,0.00011855651973746717,0.00010502601799089462,0.00011126893514301628,9.815562225412577e-05,9.945850615622476e-05,0.00011899661330971867,0.00011147180339321494,0.00011883904517162591,0.00010546423436608166,8.577090920880437e-05,0.00011822726810351014,0.00011103097494924441,8.97754289326258e-05,
mae,0.5257099270820618,0.13358712196350098,0.12289862334728241,0.1117260754108429,0.10496643930673599,0.09620693325996399,0.08945069462060928,0.08360076695680618,0.07849744707345963,0.07665885239839554,0.05248301848769188,0.050085630267858505,0.03955177590250969,0.03495605289936066,0.03787492215633392,0.029636697843670845,0.03252703696489334,0.030193345621228218,0.029626082628965378,0.029320189729332924,0.023418432101607323,0.021564170718193054,0.023605933412909508,0.024280022829771042,0.01956409402191639,0.01959916204214096,0.017686480656266212,0.017206275835633278,0.019197821617126465,0.020429139956831932,0.01602061279118061,0.017877398058772087,0.018562082201242447,0.014561643823981285,0.012125027365982533,0.01468070037662983,0.014004038646817207,0.01790887676179409,0.015200745314359665,0.01468222588300705,0.01398331206291914,0.013609623536467552,0.013911559246480465,0.013160898350179195,0.0127268610522151,0.011233880184590816,0.013144059106707573,0.013410423882305622,0.013011986389756203,0.011013775132596493,0.011248189955949783,0.010814589448273182,0.011511729098856449,0.01163999829441309,0.012777670286595821,0.013052272610366344,0.010941027663648129,0.011101960204541683,0.011005314998328686,0.011252560652792454,0.010782100260257721,0.009593287482857704,0.007505645975470543,0.00909433700144291,0.010119843296706676,0.011726027354598045,0.010330417193472385,0.009519018232822418,0.01036375854164362,0.010272332467138767,0.00908829364925623,0.009912255220115185,0.008481365628540516,0.011010296642780304,0.009561578743159771,0.010051481425762177,0.009153950028121471,0.009177721105515957,0.008753922767937183,0.009217878803610802,0.009617110714316368,0.008741148747503757,0.009282524697482586,0.009048499166965485,0.009273999370634556,0.009372008964419365,0.008971101604402065,0.008566856384277344,0.008164643310010433,0.008215103298425674,0.007862898521125317,0.007852802984416485,0.008652233518660069,0.00843341276049614,0.008590401150286198,0.008235186338424683,0.007129234727472067,0.00869807880371809,0.008524558506906033,0.007438207045197487,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 296227    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 296228    
=================================================================
Total params: 592,455
Trainable params: 592,455
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 296,227
Trainable params: 296,227
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 296,228
Trainable params: 296,228
Non-trainable params: 0
_________________________________________________________________
