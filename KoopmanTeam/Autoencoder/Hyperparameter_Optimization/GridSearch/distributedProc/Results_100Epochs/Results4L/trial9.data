2021-06-26
loss,0.4611719250679016,0.20302914083003998,0.07891925424337387,0.054973017424345016,0.046775251626968384,0.04266590252518654,0.037611983716487885,0.035318199545145035,0.03293479606509209,0.03160618245601654,0.03020845353603363,0.029095854610204697,0.028193272650241852,0.027166547253727913,0.026485061272978783,0.025722062215209007,0.025031501427292824,0.024757683277130127,0.024313613772392273,0.02379663661122322,0.023169562220573425,0.022997360676527023,0.02262463979423046,0.022191865369677544,0.02179107256233692,0.021628499031066895,0.021357674151659012,0.021159319207072258,0.02092718333005905,0.020704569295048714,0.020487258210778236,0.020207637920975685,0.020066037774086,0.019845202565193176,0.019601307809352875,0.01953117549419403,0.019413555040955544,0.019291624426841736,0.01911151595413685,0.018731120973825455,0.018848532810807228,0.01866527646780014,0.018583836033940315,0.018551088869571686,0.018373310565948486,0.018190568313002586,0.0181423369795084,0.01794694922864437,0.017789281904697418,0.017795342952013016,0.01772376336157322,0.017631568014621735,0.017444433644413948,0.017362674698233604,0.017257191240787506,0.01720018871128559,0.01713862083852291,0.01696140319108963,0.016901183873414993,0.016832254827022552,0.01673320308327675,0.016759373247623444,0.016555694863200188,0.016381513327360153,0.016551300883293152,0.016377372667193413,0.01632676087319851,0.01619207113981247,0.016169697046279907,0.016253018751740456,0.0159654151648283,0.015967249870300293,0.01591554842889309,0.01582147181034088,0.01579628884792328,0.015686476603150368,0.01561279222369194,0.015508928336203098,0.015496362000703812,0.01549393218010664,0.015390024520456791,0.015357761643826962,0.01528019830584526,0.015289319679141045,0.015171871520578861,0.015140130184590816,0.01512613333761692,0.015058650635182858,0.01499104779213667,0.01489483006298542,0.014887489378452301,0.014872065745294094,0.014801226556301117,0.014745330438017845,0.014699440449476242,0.014566157013177872,0.014692944474518299,0.014523141086101532,0.01454679761081934,0.014469115994870663,
mse,0.09510509669780731,0.01475932914763689,0.0023339991457760334,0.0010984368855133653,0.0008011128520593047,0.0006459294236265123,0.0005007213330827653,0.00043960512266494334,0.0003752800403162837,0.000341985811246559,0.00031023702467791736,0.00028203276451677084,0.00026147710741497576,0.000240937719354406,0.00022729420743416995,0.0002136116527253762,0.0002023858978645876,0.00019454931316431612,0.000187631681910716,0.00017887454305309802,0.00016887202218640596,0.0001652280188864097,0.00015953590627759695,0.0001531804009573534,0.00014787490363232791,0.00014375244791153818,0.00014015453052707016,0.00013743479212280363,0.00013433571439236403,0.00013084009697195143,0.0001282358862226829,0.00012485182378441095,0.0001223963627126068,0.00012038800196023658,0.00011657521827146411,0.00011606395128183067,0.00011338949843775481,0.00011281086335657164,0.00010998038487741724,0.00010708510671975091,0.00010711841605370864,0.00010461099736858159,0.00010354411642765626,0.0001029903651215136,0.00010092310549225658,9.860377031145617e-05,9.864371531875804e-05,9.65273502515629e-05,9.434556704945862e-05,9.40386307775043e-05,9.342546400148422e-05,9.250015864381567e-05,9.00871236808598e-05,8.963672735262662e-05,8.797876216704026e-05,8.725899533601478e-05,8.709781832294539e-05,8.504406287102029e-05,8.434052870143205e-05,8.34842212498188e-05,8.265837095677853e-05,8.273624553112313e-05,8.090082701528445e-05,7.956601621117443e-05,8.05443778517656e-05,7.8758348536212e-05,7.842857303330675e-05,7.69510370446369e-05,7.657805690541863e-05,7.697496766922995e-05,7.476175960619003e-05,7.495650788769126e-05,7.370286039076746e-05,7.30139872757718e-05,7.25529680494219e-05,7.179941167123616e-05,7.126983109628782e-05,6.992581620579585e-05,7.044805533951148e-05,6.985864456510171e-05,6.89904554747045e-05,6.877323176013306e-05,6.793260399717838e-05,6.798100366722792e-05,6.684393883915618e-05,6.648476846748963e-05,6.61838857922703e-05,6.585716619156301e-05,6.516109715448692e-05,6.445377948693931e-05,6.423915328923613e-05,6.401918653864413e-05,6.321196997305378e-05,6.30053982604295e-05,6.225758988875896e-05,6.142771599115804e-05,6.265175034059212e-05,6.061155363568105e-05,6.094952914281748e-05,6.043929170118645e-05,
mae,0.1924925446510315,0.08383885025978088,0.03339279815554619,0.02338893711566925,0.01980006881058216,0.018054213374853134,0.015913646668195724,0.01495917048305273,0.013928533531725407,0.013397295027971268,0.012844782322645187,0.01233682967722416,0.011940671131014824,0.011551323346793652,0.011212153360247612,0.010890663601458073,0.010613257996737957,0.010503184050321579,0.010336722247302532,0.010111162438988686,0.009833971038460732,0.009734074585139751,0.009613716043531895,0.009419020265340805,0.009281324222683907,0.009233720600605011,0.009081621654331684,0.008984483778476715,0.008906960487365723,0.008824308402836323,0.008688372559845448,0.008584956638514996,0.008510041981935501,0.008420776575803757,0.00835429411381483,0.00833729188889265,0.008239110000431538,0.00827678944915533,0.008174825459718704,0.00794621929526329,0.008080330677330494,0.007823028601706028,0.007946302182972431,0.007873279973864555,0.007819602265954018,0.0077780429273843765,0.007694672793149948,0.007662977557629347,0.007564088329672813,0.007606189232319593,0.007541121914982796,0.007470267359167337,0.00743524543941021,0.0074192010797560215,0.007340066600590944,0.007295506540685892,0.007325869984924793,0.007247545290738344,0.007123766001313925,0.007132380735129118,0.007070867344737053,0.0071626221761107445,0.007030029781162739,0.006978985853493214,0.007134152110666037,0.006956192664802074,0.006988907232880592,0.006857927422970533,0.006862024776637554,0.006929861847311258,0.006781380157917738,0.006841773167252541,0.006792875938117504,0.006816275883466005,0.006678210571408272,0.006657198071479797,0.006683805026113987,0.0066781057976186275,0.006536189932376146,0.006628874689340591,0.006581563502550125,0.006531689781695604,0.006350846961140633,0.006552381906658411,0.006459293887019157,0.006458191201090813,0.006472253240644932,0.006376644596457481,0.006424329709261656,0.006386519875377417,0.006290879100561142,0.006395427510142326,0.006286353338509798,0.006205350160598755,0.006294499151408672,0.006255009677261114,0.006276251282542944,0.006185558624565601,0.0061315204948186874,0.0062253158539533615,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2987      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2988      
=================================================================
Total params: 5,975
Trainable params: 5,975
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 2,987
Trainable params: 2,987
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 2,988
Trainable params: 2,988
Non-trainable params: 0
_________________________________________________________________
