2021-06-26
loss,0.6233007907867432,0.2554645836353302,0.24475935101509094,0.23423407971858978,0.22461245954036713,0.2158789038658142,0.208397775888443,0.19361650943756104,0.17146725952625275,0.1574312448501587,0.11708351224660873,0.10363449901342392,0.094634048640728,0.07967578619718552,0.08121557533740997,0.07699044048786163,0.06627210229635239,0.0681355744600296,0.06626913696527481,0.05679807811975479,0.0502210296690464,0.05341799184679985,0.050114311277866364,0.04306144639849663,0.041401706635951996,0.042553626000881195,0.041667450219392776,0.03816720098257065,0.04210143908858299,0.03643834590911865,0.03245200216770172,0.03830043971538544,0.03246508911252022,0.036266203969717026,0.02875647321343422,0.02892962656915188,0.03186711296439171,0.031227510422468185,0.030264990404248238,0.03017464093863964,0.030101489275693893,0.027712740004062653,0.02408633939921856,0.023663215339183807,0.02630678378045559,0.027755696326494217,0.025351881980895996,0.022807441651821136,0.023422861471772194,0.025357984006404877,0.027893656864762306,0.024411970749497414,0.02368287369608879,0.021482909098267555,0.021744556725025177,0.024751493707299232,0.023082006722688675,0.023420535027980804,0.02164633199572563,0.019788231700658798,0.01947523094713688,0.020381547510623932,0.019734801724553108,0.021343929693102837,0.0215342715382576,0.021055011078715324,0.021509887650609016,0.01863602176308632,0.016989201307296753,0.016672898083925247,0.020473668351769447,0.022365134209394455,0.020151183009147644,0.02050553262233734,0.018935352563858032,0.019273245707154274,0.01902439445257187,0.018536940217018127,0.01894950680434704,0.01667354628443718,0.014960750006139278,0.020835544914007187,0.018660670146346092,0.01858658716082573,0.018755212426185608,0.018023693934082985,0.017504362389445305,0.018386585637927055,0.01882254332304001,0.01823061890900135,0.01588607393205166,0.013715427368879318,0.015750348567962646,0.01832752302289009,0.019010180607438087,0.015977848321199417,0.014231652952730656,0.013819103129208088,0.019609875977039337,0.019109196960926056,
mse,0.1600659042596817,0.020933715626597404,0.01966053619980812,0.018289875239133835,0.017061971127986908,0.01584199070930481,0.014649463817477226,0.012344812043011189,0.008890736848115921,0.007331441156566143,0.004324660170823336,0.003074023639783263,0.0025694426149129868,0.0018212185241281986,0.002013551304116845,0.0017113928915932775,0.001284538535401225,0.0013310798676684499,0.0012151853879913688,0.0009379046387039125,0.0007369103841483593,0.0008142080041579902,0.0007152375765144825,0.0005301263299770653,0.0005024929996579885,0.0005196839338168502,0.0005029721651226282,0.0004322307649999857,0.0005041014519520104,0.00037710677133873105,0.0003038416907656938,0.00043880415614694357,0.0003036453854292631,0.00037751361378468573,0.00023657912970520556,0.00024680656497366726,0.00030193847487680614,0.00027526242774911225,0.00025977371842600405,0.0002636374265421182,0.0002583026944193989,0.00021541689056903124,0.00017274057609029114,0.00016886892262846231,0.0001991489843931049,0.00021407402527984232,0.00018781963444780558,0.00015411878121085465,0.00016572883760090917,0.0001890030544018373,0.0002187336649512872,0.000168391372426413,0.00015882382285781205,0.00013593815674539655,0.00013945596583653241,0.00017165113240480423,0.00015324725245591253,0.000153517015860416,0.00013233954086899757,0.00011582011939026415,0.00011148836347274482,0.00012426153989508748,0.00011766216630348936,0.0001309671497438103,0.0001318828435614705,0.00012519081064965576,0.0001321145100519061,0.00010217109957011417,8.738617179915309e-05,8.359498315257952e-05,0.00012053791579091921,0.0001405511429766193,0.00011579439888009802,0.00011926377919735387,0.00010158574878005311,0.00010699878475861624,0.00010537369962548837,9.936017886502668e-05,0.00010184202983509749,8.225462079280987e-05,6.751976616214961e-05,0.00012331597099546343,9.955316636478528e-05,0.00010013720748247579,0.00010025196388596669,9.357679664390162e-05,9.011189104057848e-05,9.580873302184045e-05,0.00010047880641650409,9.44487692322582e-05,7.387843652395532e-05,5.63955181860365e-05,7.595028000650927e-05,9.532607509754598e-05,0.0001023343502311036,7.624424324603751e-05,6.170015694806352e-05,5.9761034208349884e-05,0.00010764351463876665,0.00010286403994541615,
mae,0.26814404129981995,0.10820145905017853,0.10548356175422668,0.10143005102872849,0.09543222188949585,0.09084396064281464,0.08735376596450806,0.08046580106019974,0.07196435332298279,0.06752314418554306,0.049940966069698334,0.04451064020395279,0.04002070054411888,0.03382334113121033,0.034730371087789536,0.03225281089544296,0.02789052575826645,0.029170384630560875,0.027882378548383713,0.024262933060526848,0.021082520484924316,0.02280658483505249,0.02102660946547985,0.018263312056660652,0.017166132107377052,0.018037091940641403,0.01783846877515316,0.016374990344047546,0.01767183654010296,0.01531057246029377,0.013780783861875534,0.016418766230344772,0.013871494680643082,0.015401777811348438,0.01214449293911457,0.012205207720398903,0.013574045151472092,0.013358010910451412,0.012806946411728859,0.012648900970816612,0.012630902230739594,0.011781837791204453,0.010038645006716251,0.009996354579925537,0.011116641573607922,0.011596948839724064,0.010857302695512772,0.009765572845935822,0.009900449775159359,0.010775239206850529,0.011721312068402767,0.010376018472015858,0.01016845740377903,0.00902132410556078,0.009275886230170727,0.010530262254178524,0.009856931865215302,0.009947528131306171,0.009160197339951992,0.008394827134907246,0.00828349869698286,0.008700639940798283,0.00835973396897316,0.009064854122698307,0.009165477007627487,0.008818912319839,0.00914994440972805,0.0077925086952745914,0.0071737151592969894,0.006981965154409409,0.00866004265844822,0.009422180242836475,0.008484091609716415,0.008731129579246044,0.00805610977113247,0.00817556120455265,0.00802489835768938,0.007926962338387966,0.007967366836965084,0.007069925777614117,0.006355948280543089,0.00876348651945591,0.007915250025689602,0.007918165065348148,0.008108639158308506,0.007687246426939964,0.007466534152626991,0.00782793015241623,0.007909195497632027,0.007758547086268663,0.006615645717829466,0.005764544475823641,0.006663994863629341,0.007729701232165098,0.008122473023831844,0.0067985774949193,0.0060282861813902855,0.005894458387047052,0.008396371267735958,0.008008167147636414,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 82723     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 82724     
=================================================================
Total params: 165,447
Trainable params: 165,447
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 82,723
Trainable params: 82,723
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 82,724
Trainable params: 82,724
Non-trainable params: 0
_________________________________________________________________
