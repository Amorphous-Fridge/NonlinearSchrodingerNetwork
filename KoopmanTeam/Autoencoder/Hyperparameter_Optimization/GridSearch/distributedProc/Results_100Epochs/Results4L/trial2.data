2021-06-26
loss,0.5608392953872681,0.24907465279102325,0.1970658153295517,0.10216722637414932,0.07448185235261917,0.06596298515796661,0.05998456850647926,0.05515794828534126,0.05157347768545151,0.04860954359173775,0.04551856219768524,0.04301070049405098,0.040780454874038696,0.03818804398179054,0.03597995638847351,0.03424585610628128,0.03252789378166199,0.03174719959497452,0.030684735625982285,0.02962622605264187,0.028865592554211617,0.027956757694482803,0.027490565553307533,0.026921257376670837,0.02623806893825531,0.025803592056035995,0.025239460170269012,0.024793462827801704,0.0246262289583683,0.023885732516646385,0.023812657222151756,0.023553144186735153,0.022878579795360565,0.022559959441423416,0.02227310836315155,0.022224927321076393,0.02206207998096943,0.0215957909822464,0.021403394639492035,0.02118523418903351,0.02104920893907547,0.02071932516992092,0.02074120193719864,0.020354077219963074,0.02013767696917057,0.02006003074347973,0.01993579789996147,0.01969381980597973,0.01955423317849636,0.01949538104236126,0.01928044483065605,0.01928875595331192,0.018971256911754608,0.018931318074464798,0.018802283331751823,0.0185370035469532,0.018337106332182884,0.018267737701535225,0.018301481381058693,0.01806221529841423,0.018017692491412163,0.017759796231985092,0.017694128677248955,0.017709823325276375,0.017579374834895134,0.017450442537665367,0.017408568412065506,0.017261315137147903,0.017256896942853928,0.01713469810783863,0.016942720860242844,0.016922835260629654,0.01681073009967804,0.016752641648054123,0.01669022999703884,0.016525357961654663,0.016486819833517075,0.016514843329787254,0.016367647796869278,0.016338711604475975,0.016192344948649406,0.01632596179842949,0.01615830883383751,0.015949927270412445,0.015955954790115356,0.016006676480174065,0.01590626686811447,0.015860669314861298,0.01580529473721981,0.015777235850691795,0.01567951589822769,0.015606287866830826,0.015622295439243317,0.015538420528173447,0.015565259382128716,0.015402339398860931,0.015380037017166615,0.015371348708868027,0.01538295391947031,0.015263177454471588,
mse,0.14182034134864807,0.020831510424613953,0.013820498250424862,0.0037046822253614664,0.0019525104435160756,0.001541173318400979,0.0012922995956614614,0.0011050214525312185,0.0009654770256020129,0.0008491656044498086,0.0007453514845110476,0.0006610068958252668,0.0005899909883737564,0.0005084825097583234,0.0004470659769140184,0.0004012529971078038,0.00036152228130958974,0.00034072247217409313,0.00031669982126913965,0.00029471793095581234,0.00027905264869332314,0.00026232132222503424,0.00025014884886331856,0.00023993344802875072,0.00022666783479508013,0.00021831592312082648,0.00020853831665590405,0.00020161406428087503,0.0001969638396985829,0.00018594648281577975,0.00018388446187600493,0.00017909269081428647,0.00017022775136865675,0.0001649746991461143,0.00016023039643187076,0.00015810001059435308,0.00015518303553108126,0.00014948766329325736,0.00014679196465294808,0.00014316853776108474,0.00014087984163779765,0.00013713748194277287,0.00013637772644869983,0.00013174609921406955,0.0001286287879338488,0.0001276934490306303,0.00012513611000031233,0.00012288220750633627,0.00012108686496503651,0.00011959756375290453,0.00011762758367694914,0.00011686620564432815,0.00011360560893081129,0.00011301435733912513,0.00011118855036329478,0.00010770107473945245,0.00010624730930430815,0.00010478888725629076,0.00010466659296071157,0.00010272998042637482,0.00010166960419155657,9.910719381878152e-05,9.84032012638636e-05,9.765080903889611e-05,9.645898535382003e-05,9.529411181574687e-05,9.475955448579043e-05,9.284375846618786e-05,9.26967550185509e-05,9.101539762923494e-05,8.90547307790257e-05,8.891362813301384e-05,8.764394442550838e-05,8.708827954251319e-05,8.629050716990605e-05,8.477360097458586e-05,8.434329356532544e-05,8.437754877377301e-05,8.345748938154429e-05,8.314406295539811e-05,8.172648085746914e-05,8.26328614493832e-05,8.088952017715201e-05,7.88951656431891e-05,7.932968583190814e-05,7.907809049356729e-05,7.827664376236498e-05,7.75919615989551e-05,7.730857032584026e-05,7.681240822421387e-05,7.591680332552642e-05,7.508298585889861e-05,7.5398369517643e-05,7.43813652661629e-05,7.461279892595485e-05,7.301282312255353e-05,7.296213880181313e-05,7.270208152476698e-05,7.239895057864487e-05,7.168450974859297e-05,
mae,0.24203772842884064,0.11002600938081741,0.0873299092054367,0.04391803592443466,0.032115861773490906,0.028609590604901314,0.026124870404601097,0.024049198254942894,0.02243873104453087,0.021063122898340225,0.01964450627565384,0.01848291978240013,0.01745988428592682,0.016293847933411598,0.015310733579099178,0.0145252775400877,0.013806721195578575,0.013464471325278282,0.013009347021579742,0.012564715929329395,0.012240653857588768,0.011869732290506363,0.011662963777780533,0.011429301463067532,0.011142845265567303,0.010960307903587818,0.010726230219006538,0.01054414827376604,0.0104681346565485,0.010156583972275257,0.010127568617463112,0.01000489667057991,0.009752153418958187,0.009608957916498184,0.009493370540440083,0.009464441798627377,0.009371756576001644,0.009211583063006401,0.009123469702899456,0.009019417688250542,0.008980205282568932,0.00881236046552658,0.008834103122353554,0.008710299618542194,0.00859665498137474,0.008571067824959755,0.008483273908495903,0.008387855254113674,0.00836533959954977,0.008297616615891457,0.00826853234320879,0.008230789564549923,0.008092429488897324,0.008104199543595314,0.008029269985854626,0.00792120210826397,0.007812474854290485,0.007838597521185875,0.007800472900271416,0.0077220075763762,0.0077026779763400555,0.00758341746404767,0.007568305358290672,0.007552206516265869,0.007523577660322189,0.00740711810067296,0.007461043074727058,0.007362831383943558,0.0073858569376170635,0.007338992320001125,0.007255232892930508,0.00723201222717762,0.007178100757300854,0.0071547264233231544,0.0071500749327242374,0.00708582391962409,0.007052266038954258,0.0070632221177220345,0.0070173125714063644,0.007000111974775791,0.006890788208693266,0.006969745736569166,0.006902203429490328,0.006824946962296963,0.0068099405616521835,0.006833221763372421,0.006810853257775307,0.0067815156653523445,0.006718894932419062,0.006755447015166283,0.006688809487968683,0.0066781314089894295,0.006685629952698946,0.006645236164331436,0.006654750555753708,0.006584018003195524,0.006590959616005421,0.006564519368112087,0.0065685720182955265,0.006532230880111456,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1019      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1020      
=================================================================
Total params: 2,039
Trainable params: 2,039
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 1,019
Trainable params: 1,019
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 1,020
Trainable params: 1,020
Non-trainable params: 0
_________________________________________________________________
