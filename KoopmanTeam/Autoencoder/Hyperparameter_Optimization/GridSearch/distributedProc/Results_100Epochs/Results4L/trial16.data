2021-06-26
loss,0.4191637337207794,0.22420501708984375,0.14138540625572205,0.09150154143571854,0.06582462042570114,0.07607610523700714,0.07361920177936554,0.058654069900512695,0.04982490465044975,0.07217013835906982,0.06764241307973862,0.06521579623222351,0.064776211977005,0.05832093209028244,0.05285172536969185,0.046783074736595154,0.038384854793548584,0.035466525703668594,0.03422607108950615,0.03274109214544296,0.032379139214754105,0.045916296541690826,0.046641916036605835,0.042368654161691666,0.0396682471036911,0.03748466446995735,0.0356319323182106,0.04059628024697304,0.05481678619980812,0.049415942281484604,0.044971857219934464,0.042220816016197205,0.039568401873111725,0.03729142248630524,0.03544672951102257,0.03352421149611473,0.031772203743457794,0.029914040118455887,0.028317151591181755,0.027145154774188995,0.026532823219895363,0.026090627536177635,0.031536515802145004,0.03579597547650337,0.03281310945749283,0.031165607273578644,0.029862504452466965,0.02892296575009823,0.027700381353497505,0.03991822525858879,0.041245125234127045,0.03757371008396149,0.03509410470724106,0.03350706025958061,0.03181826323270798,0.03018241375684738,0.027161285281181335,0.025015437975525856,0.02354753576219082,0.02766970545053482,0.019161051139235497,0.018543666228652,0.01805794984102249,0.01794903725385666,0.017943967133760452,0.017738649621605873,0.017496217042207718,0.029167506843805313,0.031090393662452698,0.029058583080768585,0.026261083781719208,0.02386309579014778,0.02254168689250946,0.021588945761322975,0.020901475101709366,0.025212213397026062,0.03202366083860397,0.030161039903759956,0.02804153598845005,0.026880240067839622,0.02591094747185707,0.025008780881762505,0.023221269249916077,0.021729355677962303,0.02761281095445156,0.031454525887966156,0.028126897290349007,0.026292551308870316,0.025273416191339493,0.024242622777819633,0.02358463779091835,0.022659599781036377,0.021915240213274956,0.0207031462341547,0.01984246075153351,0.018745748326182365,0.021986162289977074,0.021906955167651176,0.029391111806035042,0.02673567458987236,
mse,0.07779043912887573,0.017886105924844742,0.007064966019243002,0.0026136559899896383,0.0013387484941631556,0.0017251111567020416,0.0016687670722603798,0.0010628150776028633,0.0007571080350317061,0.0014536078087985516,0.0013270967174321413,0.0012449836358428001,0.0011519790859892964,0.0009464164031669497,0.0007946081459522247,0.0006257931818254292,0.0004290458164177835,0.00036434284993447363,0.00033611434628255665,0.0003074120613746345,0.000298918632324785,0.0006393888033926487,0.0006249959114938974,0.0005012156907469034,0.0004366463399492204,0.00039038245449773967,0.00035270798252895474,0.0005201259045861661,0.0008279227185994387,0.0006733651389367878,0.0005638288566842675,0.0004955451004207134,0.0004338409344200045,0.00038660477730445564,0.0003502624749671668,0.00031596372718922794,0.00028527426184155047,0.0002536993706598878,0.00023004660033620894,0.00020994190708734095,0.0002031650801654905,0.00019551199511624873,0.00029299603193067014,0.00034776702523231506,0.0002954980300273746,0.00026676434208638966,0.0002462001284584403,0.00023309468815568835,0.00021463757730089128,0.0004748108913190663,0.00047176878433674574,0.0003888313949573785,0.00034251195029355586,0.0003113146231044084,0.0002806913398671895,0.0002524122828617692,0.0002058976679109037,0.0001736552221700549,0.00015637939213775098,0.00022637320216745138,0.00010782806930365041,9.897164272842929e-05,9.313143527833745e-05,9.206512186210603e-05,9.13359981495887e-05,8.926625014282763e-05,8.966603490989655e-05,0.0002424209815217182,0.00026534570497460663,0.00023387740657199174,0.00019009837706107646,0.00015873523079790175,0.00014290727267507464,0.00013114188914187253,0.00012292168685235083,0.00018754202756099403,0.00029588231700472534,0.00024569511879235506,0.0002155256224796176,0.00019855894788634032,0.000185876022442244,0.00017464740085415542,0.00015073068789206445,0.00013072459842078388,0.00023365358356386423,0.00027197523741051555,0.00021710220607928932,0.00018972464022226632,0.00017540402768645436,0.00016233642236329615,0.00015341921243816614,0.00014204432955011725,0.0001333693799097091,0.00012119552411604673,0.00011250078387092799,0.00010335999832022935,0.00013724506425205618,0.00013538241910282522,0.00023675704142078757,0.0001952312159119174,
mae,0.17835445702075958,0.09744931012392044,0.060535844415426254,0.03895985707640648,0.028031781315803528,0.032768040895462036,0.03141054883599281,0.024980761110782623,0.02118673175573349,0.030884012579917908,0.029258403927087784,0.028718898072838783,0.02844545803964138,0.025577934458851814,0.023105543106794357,0.019968785345554352,0.015787435695528984,0.014859149232506752,0.014494847506284714,0.014032101258635521,0.013796764425933361,0.019636834040284157,0.01976202055811882,0.01810205914080143,0.01697707735002041,0.01622542180120945,0.015589860267937183,0.01727214641869068,0.0242474228143692,0.021836113184690475,0.019821016117930412,0.01860278844833374,0.017634883522987366,0.016743775457143784,0.0159436147660017,0.015037668868899345,0.013950572349131107,0.012882978655397892,0.012176093645393848,0.011647151783108711,0.011135381646454334,0.010856113396584988,0.013469931669533253,0.01572282612323761,0.014453135430812836,0.013715698383748531,0.013151679188013077,0.012754609808325768,0.011950267478823662,0.017323147505521774,0.01825757697224617,0.016642335802316666,0.015533403493463993,0.014822054654359818,0.014025324955582619,0.013098695315420628,0.011259861290454865,0.010302399285137653,0.009733671322464943,0.011847374029457569,0.008234120905399323,0.008087953552603722,0.007860147394239902,0.00782532338052988,0.007829803042113781,0.007731161080300808,0.00758674880489707,0.012621777132153511,0.013803801499307156,0.012529931031167507,0.010341091081500053,0.0095599964261055,0.009105979464948177,0.008715691044926643,0.008566626347601414,0.010820833034813404,0.013921532779932022,0.013234240934252739,0.012390834279358387,0.011852867901325226,0.011358201503753662,0.010693276301026344,0.009664134122431278,0.009092351421713829,0.011790258809924126,0.013797342777252197,0.012382574379444122,0.01159584615379572,0.011148127727210522,0.010699466802179813,0.01037610974162817,0.009766488336026669,0.009235209785401821,0.008568132296204567,0.00819364469498396,0.007848749868571758,0.009389320388436317,0.00924745574593544,0.012903081253170967,0.01195662934333086,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 7523      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 7524      
=================================================================
Total params: 15,047
Trainable params: 15,047
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 7,523
Trainable params: 7,523
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 7,524
Trainable params: 7,524
Non-trainable params: 0
_________________________________________________________________
