2021-06-26
loss,0.9326578378677368,0.16411751508712769,0.14625151455402374,0.10126146674156189,0.08704300224781036,0.06580943614244461,0.05252540484070778,0.05583633854985237,0.054291367530822754,0.03921184316277504,0.036583248525857925,0.041300904005765915,0.0356198213994503,0.03894620016217232,0.035779453814029694,0.035774074494838715,0.027324046939611435,0.02743193879723549,0.03327540308237076,0.031906794756650925,0.02947883866727352,0.03009791299700737,0.022922905161976814,0.02283383347094059,0.027187900617718697,0.02523859031498432,0.023835141211748123,0.024023039266467094,0.02378040738403797,0.02459295280277729,0.021863333880901337,0.02053798921406269,0.023649385198950768,0.024310724809765816,0.021346500143408775,0.021353397518396378,0.021373741328716278,0.023461297154426575,0.020986879244446754,0.02081826888024807,0.021643230691552162,0.019666150212287903,0.022748855873942375,0.018825409933924675,0.01694956235587597,0.01995917409658432,0.019937602803111076,0.022803695872426033,0.01987028308212757,0.02015472948551178,0.020739970728754997,0.021074559539556503,0.02142254263162613,0.019598716869950294,0.018844062462449074,0.02088618092238903,0.020905829966068268,0.019646991044282913,0.01916750706732273,0.017855199053883553,0.01907443255186081,0.018819056451320648,0.01902470923960209,0.01862451061606407,0.018962586298584938,0.01747516356408596,0.01880173198878765,0.019096964970231056,0.017910759896039963,0.016566524282097816,0.01949438266456127,0.020163891837000847,0.01950962282717228,0.017749646678566933,0.01870141178369522,0.01898440718650818,0.017664868384599686,0.016790255904197693,0.01658717915415764,0.018142415210604668,0.017701730132102966,0.01768985204398632,0.018307965248823166,0.017336372286081314,0.017764149233698845,0.015736456960439682,0.016526782885193825,0.019493231549859047,0.016004325821995735,0.01507481373846531,0.01730271242558956,0.017851227894425392,0.0180481169372797,0.016690997406840324,0.016457900404930115,0.017369471490383148,0.016609249636530876,0.016854163259267807,0.017415421083569527,0.01738646812736988,
mse,0.38183048367500305,0.008057788945734501,0.006390471011400223,0.0029902050737291574,0.0021509546786546707,0.0012382061686366796,0.0008135117823258042,0.0009025833569467068,0.0008868715376593173,0.0004672379873227328,0.00039571040542796254,0.0004970371956005692,0.000379408011212945,0.0004475424066185951,0.0003670318692456931,0.00035952520556747913,0.00022248589084483683,0.0002281525667058304,0.00031662630499340594,0.00028680573450401425,0.0002503559517208487,0.0002545147144701332,0.00015717644419055432,0.00015930522931739688,0.00021439902775455266,0.0001820097677409649,0.0001661001006141305,0.00017328691319562495,0.00017006504640448838,0.00018260352953802794,0.0001443164946977049,0.00012597143359016627,0.00016297724505420774,0.00016903622599784285,0.00013931290595792234,0.00013615196803584695,0.00013296696124598384,0.00016144329856615514,0.00013311095244716853,0.00012800921103917062,0.00013874858268536627,0.00011396461195545271,0.0001513894385425374,0.00010775155533337966,8.76801714184694e-05,0.00011809591524070129,0.00011684113997034729,0.0001470512943342328,0.00011684579658322036,0.00012325496936682612,0.00012893934035673738,0.00012783236161340028,0.0001363324117846787,0.00011734610598068684,0.00010543339885771275,0.00012677587801590562,0.00012704340042546391,0.00011668231309158728,0.0001130190648837015,9.776953811524436e-05,0.00010662621934898198,0.00010682329593691975,0.00010912154539255425,0.00010270039638271555,0.00010735617252066731,9.18842779356055e-05,0.00010509834828553721,0.0001069168938556686,9.677519119577482e-05,8.411816088482738e-05,0.00010983289394062012,0.00011668248771457002,0.00011206153430975974,9.343456622445956e-05,0.00010550135630182922,0.00010524340177653357,9.351209155283868e-05,8.459206583211198e-05,8.24306407594122e-05,9.778749517863616e-05,9.17836296139285e-05,9.027017949847504e-05,9.877565025817603e-05,8.91824602149427e-05,9.350983600597829e-05,7.735055987723172e-05,8.364032692043111e-05,0.00010980429942719638,7.902650395408273e-05,7.024735532468185e-05,9.0156783699058e-05,9.592266724212095e-05,9.616315946914256e-05,8.234342385549098e-05,8.036125655053183e-05,8.830630395095795e-05,8.278682798845693e-05,8.348272240255028e-05,9.015870455186814e-05,8.79596991580911e-05,
mae,0.39944565296173096,0.07013697922229767,0.06248224899172783,0.043314579874277115,0.03701375424861908,0.028034765273332596,0.022080479189753532,0.02364974282681942,0.023237600922584534,0.016661489382386208,0.015538671053946018,0.017675189301371574,0.015115227550268173,0.016598304733633995,0.01518233772367239,0.015353293158113956,0.011645511724054813,0.01164301484823227,0.014183683320879936,0.013538295403122902,0.012447270564734936,0.012591245584189892,0.009626849554479122,0.009724300354719162,0.011476725339889526,0.010807125829160213,0.010130404494702816,0.01020753476768732,0.010087493807077408,0.010523289442062378,0.00919980090111494,0.008786032907664776,0.010031559504568577,0.01025199331343174,0.009053770452737808,0.009098255075514317,0.009119712747633457,0.010006828233599663,0.008925913833081722,0.008873042650520802,0.009023360908031464,0.008275264874100685,0.009621587581932545,0.008001688867807388,0.00720806373283267,0.008506972342729568,0.008439267054200172,0.009696928784251213,0.008463481441140175,0.008545284159481525,0.008740196004509926,0.009001027792692184,0.009072067216038704,0.008346044458448887,0.008113253861665726,0.00883436854928732,0.00883341021835804,0.00830287579447031,0.008160087279975414,0.0075188810005784035,0.008086456917226315,0.007906251586973667,0.008139901794493198,0.007969040423631668,0.007976613938808441,0.0073919533751904964,0.008056707680225372,0.008168024010956287,0.007628685794770718,0.0070585813373327255,0.008272744715213776,0.008539026603102684,0.008361827582120895,0.007634712848812342,0.007999176159501076,0.008061954751610756,0.007502025458961725,0.0071973903104662895,0.007101644761860371,0.007713352330029011,0.007592908572405577,0.007528245449066162,0.007776821032166481,0.007341195363551378,0.00749973114579916,0.006707852706313133,0.0070334807969629765,0.008264719508588314,0.0068663046695292,0.006428095046430826,0.007246735505759716,0.00762604596093297,0.007731746416538954,0.007097730413079262,0.0070544658228755,0.0073260474018752575,0.007070357911288738,0.007159793749451637,0.007430810946971178,0.007444767747074366,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 132739    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 132740    
=================================================================
Total params: 265,479
Trainable params: 265,479
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 132,739
Trainable params: 132,739
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 132,740
Trainable params: 132,740
Non-trainable params: 0
_________________________________________________________________
