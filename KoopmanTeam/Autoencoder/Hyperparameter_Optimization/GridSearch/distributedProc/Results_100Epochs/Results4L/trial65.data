2021-06-26
loss,1.3331756591796875,0.2893584966659546,0.2563976049423218,0.2501845359802246,0.2427704930305481,0.23668470978736877,0.22812972962856293,0.21437236666679382,0.18228815495967865,0.16834750771522522,0.12145420908927917,0.16358284652233124,0.08973273634910583,0.09772982448339462,0.07858105003833771,0.06682693213224411,0.07330341637134552,0.07055500894784927,0.053134579211473465,0.05636116489768028,0.06803418695926666,0.059346962720155716,0.04818696156144142,0.04689328745007515,0.05277438461780548,0.043626293540000916,0.03265451267361641,0.03825177997350693,0.04621070995926857,0.044475007802248,0.03981751576066017,0.03493575006723404,0.031053414568305016,0.034914083778858185,0.033128079026937485,0.03360369801521301,0.02932852692902088,0.026005113497376442,0.024131858721375465,0.04054779186844826,0.035547297447919846,0.02793341875076294,0.02242247387766838,0.031668830662965775,0.038316309452056885,0.031068766489624977,0.030165163800120354,0.02864702045917511,0.031535111367702484,0.031922079622745514,0.03112676925957203,0.0200582854449749,0.01909017749130726,0.020228467881679535,0.026833653450012207,0.027139835059642792,0.033340875059366226,0.031395573168992996,0.031701382249593735,0.02358304336667061,0.02357419766485691,0.026368029415607452,0.030580105260014534,0.030728811398148537,0.025762679055333138,0.02198084443807602,0.022208111360669136,0.02710968442261219,0.02789994888007641,0.025711776688694954,0.030305039137601852,0.02464621141552925,0.02191147580742836,0.01892807148396969,0.02000110223889351,0.02708432264626026,0.027094874531030655,0.02810429409146309,0.022203929722309113,0.024066805839538574,0.022545967251062393,0.02070511132478714,0.02335817739367485,0.029431214556097984,0.02432824857532978,0.02178260125219822,0.02796309068799019,0.02484007179737091,0.022767553105950356,0.020443599671125412,0.021014390513300896,0.027443772181868553,0.022532420232892036,0.01602870784699917,0.016188165172934532,0.015130715444684029,0.020361805334687233,0.02724427543580532,0.02422083169221878,0.022252345457673073,
mse,0.7430259585380554,0.02606384828686714,0.021381638944149017,0.02070905640721321,0.019900821149349213,0.019086338579654694,0.01800748147070408,0.01575297676026821,0.010462610982358456,0.008795316331088543,0.004766419064253569,0.008849192410707474,0.0023787624668329954,0.002799464389681816,0.0018520188750699162,0.0013898425968363881,0.0016543620731681585,0.0014464244013652205,0.000876283273100853,0.000931079441215843,0.0012974796118214726,0.0010122805833816528,0.0006858152919448912,0.0006530380342155695,0.000781299895606935,0.0005573644302785397,0.0003268166328780353,0.00045270114787854254,0.0006227105623111129,0.0005663047777488828,0.00045725435484200716,0.00036330323200672865,0.0002954420924652368,0.0003591121349018067,0.00032231476507149637,0.0003418818232603371,0.00026532995980232954,0.0002137361589120701,0.0001798267912818119,0.0004691202484536916,0.0003534165152814239,0.000245698873186484,0.00015977391740307212,0.00030485005117952824,0.0004161102697253227,0.00029224625905044377,0.0002637048892211169,0.0002450871397741139,0.0002835189225152135,0.0002891632029786706,0.00028057239251211286,0.00012656384205911309,0.00011049637396354228,0.00012970995157957077,0.0002162495511583984,0.00021865582675673068,0.0003149517287965864,0.0002811233280226588,0.00028843534528277814,0.0001693061349214986,0.00016674005019012839,0.00020605990721378475,0.00026880932273343205,0.00026468338910490274,0.00018982023175340146,0.00014804152306169271,0.00014631084923166782,0.00022425118368119001,0.00021697449847124517,0.0001875036978162825,0.00026485053240321577,0.00017905147979035974,0.0001455577730666846,0.00011158777488162741,0.00012510584201663733,0.00021880997519474477,0.0002091379283228889,0.0002241828915430233,0.0001469433045713231,0.00016887929814402014,0.00014521415869239718,0.0001305311598116532,0.00016282525029964745,0.00024198152823373675,0.00017023830150719732,0.00014060051762498915,0.0002170100196963176,0.00017392527661286294,0.00015105641796253622,0.00012057271669618785,0.0001330732338828966,0.00021099990408401936,0.00014723851927556098,8.3780316344928e-05,8.432676986558363e-05,7.098614878486842e-05,0.00012758349475916475,0.00020897126523777843,0.00017040700186043978,0.0001467623806092888,
mae,0.5703797936439514,0.12880252301692963,0.11721161007881165,0.11531424522399902,0.11303377896547318,0.10866646468639374,0.10342888534069061,0.09444787353277206,0.0782226100564003,0.07207801938056946,0.051180921494960785,0.06661748141050339,0.03749704733490944,0.041526783257722855,0.03339719399809837,0.028563600033521652,0.031623803079128265,0.03021676279604435,0.022425610572099686,0.024206601083278656,0.029147639870643616,0.0256763007491827,0.0209202840924263,0.019983643665909767,0.023386476561427116,0.018871575593948364,0.013865415938198566,0.016320452094078064,0.01979319378733635,0.019380781799554825,0.017160689458251,0.014774092473089695,0.013246730901300907,0.0144488625228405,0.014131319709122181,0.014446418732404709,0.012563519179821014,0.0110298041254282,0.010294461622834206,0.01751101389527321,0.015605352818965912,0.011828157119452953,0.009570984169840813,0.01358956377953291,0.016690468415617943,0.013533425517380238,0.012773608788847923,0.012241407297551632,0.013607711531221867,0.013786536641418934,0.013345485553145409,0.008559449575841427,0.008213229477405548,0.008677102625370026,0.01140122301876545,0.011695610359311104,0.014333189465105534,0.013517284765839577,0.013734620064496994,0.010091936215758324,0.009996645152568817,0.010997814126312733,0.013049585744738579,0.013311317190527916,0.011349528096616268,0.009339314885437489,0.009580373764038086,0.011506072245538235,0.012096678838133812,0.011212033219635487,0.013386880047619343,0.010422480292618275,0.009284674189984798,0.00803538877516985,0.008449262008070946,0.01168848667293787,0.011659938842058182,0.012224700301885605,0.009341668337583542,0.010423638857901096,0.009658812545239925,0.008757147938013077,0.009961993433535099,0.012747040949761868,0.010440032929182053,0.009315768256783485,0.01220159325748682,0.010729112662374973,0.009660783223807812,0.00849910918623209,0.008903317153453827,0.011936595663428307,0.009606581181287766,0.00683538056910038,0.006868645083159208,0.006468660198152065,0.00878224615007639,0.011701155453920364,0.010366711765527725,0.009429102763533592,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 271435    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 271436    
=================================================================
Total params: 542,871
Trainable params: 542,871
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 271,435
Trainable params: 271,435
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 271,436
Trainable params: 271,436
Non-trainable params: 0
_________________________________________________________________
