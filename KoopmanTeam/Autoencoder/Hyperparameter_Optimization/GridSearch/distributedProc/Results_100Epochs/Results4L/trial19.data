2021-06-26
loss,0.28385013341903687,0.08105890452861786,0.056440144777297974,0.05250933766365051,0.04789844527840614,0.04279286414384842,0.04076472297310829,0.03872697800397873,0.04858875647187233,0.05585811659693718,0.04653322324156761,0.03982505202293396,0.05124881863594055,0.05148375406861305,0.058512795716524124,0.04901517555117607,0.04266028106212616,0.048378173261880875,0.04620882123708725,0.03761506825685501,0.03529839590191841,0.03290770202875137,0.03159983456134796,0.030189046636223793,0.028882117941975594,0.027152007445693016,0.026365678757429123,0.025444509461522102,0.0266879852861166,0.037992969155311584,0.03731720149517059,0.039731722325086594,0.043602991849184036,0.035445686429739,0.030990125611424446,0.030785078182816505,0.03559506684541702,0.03150011599063873,0.04098397120833397,0.036553096026182175,0.03284670412540436,0.028964178636670113,0.027192139998078346,0.02468276582658291,0.029494892805814743,0.03750607743859291,0.03162509575486183,0.033323001116514206,0.027048414573073387,0.027226267382502556,0.0250743106007576,0.030090104788541794,0.03279102221131325,0.032267339527606964,0.029574982821941376,0.02590925432741642,0.024486659094691277,0.024102047085762024,0.02304866537451744,0.027843154966831207,0.028057066723704338,0.028810754418373108,0.025919713079929352,0.0237496979534626,0.030278412625193596,0.031054744496941566,0.028520748019218445,0.025071967393159866,0.022036222741007805,0.01727920025587082,0.015442367643117905,0.015118305571377277,0.015014381147921085,0.014968990348279476,0.014864325523376465,0.014628454111516476,0.014668460935354233,0.014836090616881847,0.015018192119896412,0.014857875183224678,0.01479081716388464,0.01485653780400753,0.014859061688184738,0.014711038209497929,0.014682755805552006,0.014653951860964298,0.01702842302620411,0.025057639926671982,0.02525859884917736,0.024321241304278374,0.022963237017393112,0.02158808708190918,0.020243380218744278,0.01913834735751152,0.01832130365073681,0.01782047189772129,0.022531621158123016,0.02638598158955574,0.025895629078149796,0.026295391842722893,
mse,0.03055901825428009,0.002137006726115942,0.0009368507307954133,0.0008297227323055267,0.0006600633496418595,0.0005200158338993788,0.0004730606160592288,0.00042501886491663754,0.0007292054360732436,0.0009098072187043726,0.0006141773192211986,0.00044897853513248265,0.0007655865047127008,0.0007639702525921166,0.001026227604597807,0.0006879536667838693,0.000509826117195189,0.0006634395103901625,0.0006086957291699946,0.0004066687833983451,0.00035143151762895286,0.0003113830171059817,0.0002871100150514394,0.0002628119254950434,0.000244937080424279,0.00022092652216088027,0.00020297015726100653,0.0001877524919109419,0.00021705009567085654,0.00040489391540177166,0.0003888224018737674,0.00045753363519907,0.0005375791806727648,0.00035795755684375763,0.000274244521278888,0.00028328661574050784,0.00036367253051139414,0.00028813700191676617,0.00046522964839823544,0.00037912785774096847,0.0003023369063157588,0.00023815686290618032,0.00021117422147653997,0.00018023779557552189,0.00025341217406094074,0.0003940899623557925,0.00029272190295159817,0.00031254507484845817,0.0002155330585082993,0.0002120963326888159,0.00018845008162315935,0.0002540876448620111,0.00029749958775937557,0.00030191391124390066,0.00025025062495842576,0.00019120529759675264,0.0001714731624815613,0.00016689252515789121,0.00015364575665444136,0.0002385133848292753,0.00022089557023718953,0.00022945439559407532,0.00019076505850534886,0.00016207859152927995,0.0002602086460683495,0.000272532895905897,0.00023236505512613803,0.00018436025129631162,0.00014215799455996603,9.29451925912872e-05,7.14864072506316e-05,6.839172419859096e-05,6.795020453864709e-05,6.65568804834038e-05,6.53735114610754e-05,6.463487807195634e-05,6.508210935862735e-05,6.662125088041648e-05,6.722389662172645e-05,6.50194997433573e-05,6.480470619862899e-05,6.44599276711233e-05,6.512836262118071e-05,6.330327596515417e-05,6.345817382680252e-05,6.40263533568941e-05,9.15637137950398e-05,0.00017712438420858234,0.00017575632955413312,0.00016389990923926234,0.000147135928273201,0.00013002505875192583,0.00011374747555237263,0.00010189341264776886,9.436782420380041e-05,8.887039439287037e-05,0.0001479270140407607,0.0001922662922879681,0.00018834174261428416,0.0001907805126393214,
mae,0.1160302385687828,0.03398803249001503,0.023849375545978546,0.022093970328569412,0.020248116925358772,0.018136411905288696,0.01717466115951538,0.01648007333278656,0.0205520149320364,0.023912571370601654,0.020281076431274414,0.016887690871953964,0.021583277732133865,0.02206380106508732,0.024545280262827873,0.020789705216884613,0.017709879204630852,0.02034030109643936,0.019212979823350906,0.015296152792870998,0.014002608135342598,0.01327589899301529,0.013237979263067245,0.012665028683841228,0.011963147670030594,0.011547617614269257,0.011068371124565601,0.010735532268881798,0.011244663037359715,0.01592986285686493,0.016153423115611076,0.016738910228013992,0.017699668183922768,0.015196126885712147,0.013419815339148045,0.013096890412271023,0.015163972042500973,0.013298979960381985,0.017023490741848946,0.015179110690951347,0.014513191767036915,0.012652767822146416,0.01118574757128954,0.010379140265285969,0.012458099983632565,0.015376107767224312,0.013467663899064064,0.013802765868604183,0.011339233256876469,0.011585963889956474,0.010659430176019669,0.01280215010046959,0.013790563680231571,0.013435176573693752,0.01220247894525528,0.011157892644405365,0.010589364916086197,0.01041716430336237,0.009899251163005829,0.011564237996935844,0.01203861553221941,0.010986393317580223,0.010027322918176651,0.00978495366871357,0.012771248817443848,0.01247349288314581,0.01133804302662611,0.010666060261428356,0.009138140827417374,0.0073136985301971436,0.006500146817415953,0.006360962521284819,0.006394145544618368,0.00638518575578928,0.006332554388791323,0.006226701661944389,0.006161248777061701,0.006357803475111723,0.006427554879337549,0.006330615375190973,0.006308632902801037,0.006363379303365946,0.006313527934253216,0.00628250278532505,0.006202842574566603,0.006219447124749422,0.007132117636501789,0.0106135793030262,0.010807020589709282,0.010407637804746628,0.009867127053439617,0.009136276319622993,0.008214718662202358,0.007666764780879021,0.007340880576521158,0.007263892330229282,0.009364538826048374,0.011103183962404728,0.01083050761371851,0.010719317942857742,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 11603     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 11604     
=================================================================
Total params: 23,207
Trainable params: 23,207
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 11,603
Trainable params: 11,603
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 11,604
Trainable params: 11,604
Non-trainable params: 0
_________________________________________________________________
