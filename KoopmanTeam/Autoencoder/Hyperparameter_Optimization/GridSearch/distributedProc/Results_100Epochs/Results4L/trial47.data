2021-06-26
loss,0.6526902914047241,0.2512921988964081,0.2263583391904831,0.1856457144021988,0.14127030968666077,0.11458966881036758,0.1088363379240036,0.09884528070688248,0.08150577545166016,0.06560707837343216,0.07522795349359512,0.0714723989367485,0.06878925114870071,0.05756133049726486,0.057761240750551224,0.04570339247584343,0.050209298729896545,0.050541702657938004,0.04218368977308273,0.04742370918393135,0.0418122336268425,0.0385553278028965,0.04381311312317848,0.04467155039310455,0.04032012075185776,0.036086201667785645,0.03407328948378563,0.03688160702586174,0.03973250091075897,0.037188440561294556,0.03447004407644272,0.03597693145275116,0.03332849591970444,0.03260740637779236,0.03656042739748955,0.030618175864219666,0.025790518149733543,0.02340778335928917,0.029524173587560654,0.033417023718357086,0.031231308355927467,0.030990133062005043,0.02845354750752449,0.02225792221724987,0.02306828647851944,0.028281770646572113,0.03025694377720356,0.03031342104077339,0.030226707458496094,0.026436595246195793,0.028449933975934982,0.027193572372198105,0.027099190279841423,0.02663140557706356,0.025505397468805313,0.024348709732294083,0.023324348032474518,0.023079590871930122,0.02359633706510067,0.023897361010313034,0.025438422337174416,0.023929763585329056,0.023401904851198196,0.02397606149315834,0.02311072126030922,0.022027090191841125,0.020113013684749603,0.018822111189365387,0.01959552802145481,0.021171346306800842,0.021819861605763435,0.022225815802812576,0.023121507838368416,0.019149301573634148,0.020029619336128235,0.02045929618179798,0.01636447012424469,0.01603330671787262,0.01620299182832241,0.020282618701457977,0.020894240587949753,0.021198820322752,0.020474400371313095,0.019827233627438545,0.019346920773386955,0.018922802060842514,0.017842914909124374,0.018554523587226868,0.017621785402297974,0.015901435166597366,0.014917186461389065,0.013711589388549328,0.015095226466655731,0.013912534341216087,0.01612015813589096,0.019169241189956665,0.018154580146074295,0.01617243140935898,0.019046735018491745,0.018785450607538223,
mse,0.2084025740623474,0.02097507007420063,0.01690039597451687,0.010113431140780449,0.00584493950009346,0.0037205475382506847,0.0035146144218742847,0.002774245338514447,0.0019073199946433306,0.0012546292273327708,0.0016120102955028415,0.0014619878493249416,0.001341183320619166,0.0009436593391001225,0.0009382678545080125,0.0006149477558210492,0.0007315243128687143,0.0007316496921703219,0.0005183063913136721,0.0006580536137335002,0.0005148419295437634,0.00043644721154123545,0.0005457656807266176,0.0005603808094747365,0.00047341291792690754,0.00037823375896550715,0.00033252392313443124,0.00039291250868700445,0.00043698278022930026,0.00039113627281039953,0.00034322295687161386,0.0003718238731380552,0.00031971308635547757,0.00030876105302013457,0.0003820741840172559,0.00027704788953997195,0.0002011664619203657,0.0001625054719625041,0.0002605470363050699,0.0003226475673727691,0.0002849565353244543,0.00027693333686329424,0.00023671644157730043,0.00014876296336296946,0.00015895349497441202,0.0002388135326327756,0.00025779317365959287,0.00025746674509719014,0.0002582105516921729,0.00020226111519150436,0.00022733942023478448,0.00020941933325957507,0.00020756492449436337,0.00020189309725537896,0.0001841791527112946,0.00017022414249368012,0.00015788526798132807,0.00015426137542817742,0.0001606559962965548,0.00016699190018698573,0.00018212044960819185,0.00016042102652136236,0.00015550428361166269,0.000160788040375337,0.00015245727263391018,0.00013967468112241477,0.00011881703539984301,0.00010564616968622431,0.00011222261673538014,0.00012818831601180136,0.00013519615458790213,0.00013841301552020013,0.00015022345178294927,0.0001066682452801615,0.00011727004311978817,0.0001187602974823676,8.214802801376209e-05,7.727273623459041e-05,7.819092570571229e-05,0.00011897845979547128,0.0001221403363160789,0.00012502222671173513,0.00011728217214113101,0.0001115431368816644,0.00010791919339681044,0.00010402925545349717,9.284637053497136e-05,9.893252718029544e-05,8.979699487099424e-05,7.528875721618533e-05,6.669382128166035e-05,5.570825669565238e-05,6.705451232846826e-05,5.7496275985613465e-05,7.765954069327563e-05,0.00010417825251352042,9.380785922985524e-05,7.735325198154896e-05,0.0001024659359245561,9.991972910938784e-05,
mae,0.27682554721832275,0.10713350027799606,0.09764813631772995,0.07912958413362503,0.060015663504600525,0.04842423275113106,0.04685088247060776,0.04163394495844841,0.03373619541525841,0.028103889897465706,0.03211435675621033,0.030401943251490593,0.029421281069517136,0.024503657594323158,0.024811899289488792,0.01932937279343605,0.02159487083554268,0.02158142812550068,0.017968526110053062,0.02023712918162346,0.01769941858947277,0.01632515713572502,0.018567729741334915,0.018988488242030144,0.01697622239589691,0.015185744501650333,0.014438662678003311,0.01569650135934353,0.016765045002102852,0.015742553398013115,0.014560768380761147,0.015305131673812866,0.014344648458063602,0.013606990687549114,0.015591539442539215,0.012915154919028282,0.010985893197357655,0.01001352071762085,0.012553482316434383,0.014274208806455135,0.013108551502227783,0.013125563971698284,0.012165950611233711,0.009437832981348038,0.009851026348769665,0.011826583184301853,0.012787754647433758,0.012912582606077194,0.012709826231002808,0.011185240931808949,0.0119350366294384,0.01171440165489912,0.01162424311041832,0.01138809323310852,0.010944710113108158,0.010294817388057709,0.009921913966536522,0.009801319800317287,0.01008627936244011,0.010105243884027004,0.010860629379749298,0.010231566615402699,0.009926635771989822,0.010176219046115875,0.00983876921236515,0.009369473904371262,0.008508186787366867,0.008065743371844292,0.008341292850673199,0.00892192218452692,0.009201453067362309,0.00944621954113245,0.009902846068143845,0.008040200918912888,0.008546611294150352,0.00858360342681408,0.006968779489398003,0.006868269294500351,0.006929507479071617,0.008517421782016754,0.008955013006925583,0.0090074697509408,0.008676070719957352,0.008395548909902573,0.008153222501277924,0.007913541980087757,0.007681549992412329,0.007919808849692345,0.007471267133951187,0.006756178569048643,0.006344388239085674,0.005844177212566137,0.006374844815582037,0.005843243561685085,0.006834839470684528,0.008155249059200287,0.007665144745260477,0.006958755664527416,0.008072751574218273,0.00797456968575716,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 78563     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 78564     
=================================================================
Total params: 157,127
Trainable params: 157,127
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 78,563
Trainable params: 78,563
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 78,564
Trainable params: 78,564
Non-trainable params: 0
_________________________________________________________________
