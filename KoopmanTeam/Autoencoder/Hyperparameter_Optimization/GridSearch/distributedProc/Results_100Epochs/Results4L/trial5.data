2021-06-26
loss,0.5223000645637512,0.15804313123226166,0.09277123212814331,0.06952247023582458,0.06049700081348419,0.054815612733364105,0.05138618126511574,0.047685619443655014,0.04408055171370506,0.04102995991706848,0.03883235901594162,0.03624500334262848,0.03414019197225571,0.03256253898143768,0.03118309937417507,0.03022535890340805,0.02931048907339573,0.028366858139634132,0.027491087093949318,0.026948682963848114,0.026422126218676567,0.025899790227413177,0.025222506374120712,0.02504776045680046,0.024629762396216393,0.02436765283346176,0.023966576904058456,0.02366412617266178,0.023358236998319626,0.023131005465984344,0.022730035707354546,0.022509559988975525,0.022428888827562332,0.0220187995582819,0.0217866450548172,0.02160348743200302,0.021449457854032516,0.021206937730312347,0.021192170679569244,0.020959626883268356,0.020808354020118713,0.020642248913645744,0.020544253289699554,0.0203451756387949,0.020250771194696426,0.019933706149458885,0.02005070634186268,0.01978236995637417,0.019619695842266083,0.0194673091173172,0.01944781467318535,0.019244268536567688,0.019202902913093567,0.019102148711681366,0.01913234405219555,0.018856463953852654,0.01879470981657505,0.018657278269529343,0.01850362867116928,0.01847066916525364,0.018460754305124283,0.018278472125530243,0.01820690557360649,0.01817544549703598,0.018068168312311172,0.01807238534092903,0.017968446016311646,0.017918869853019714,0.01778314635157585,0.0177020151168108,0.017473924905061722,0.01756090670824051,0.01759892888367176,0.01745995320379734,0.017443858087062836,0.01748109608888626,0.017435584217309952,0.01720624789595604,0.017186850309371948,0.017215514555573463,0.0171833373606205,0.017013199627399445,0.016982465982437134,0.017037443816661835,0.016858374699950218,0.016899604350328445,0.016757098957896233,0.01669127866625786,0.016744544729590416,0.01657438836991787,0.01673876866698265,0.01676311157643795,0.01657041162252426,0.01649957150220871,0.016472799703478813,0.016511183232069016,0.016567235812544823,0.01641414500772953,0.01635829359292984,0.016161764040589333,
mse,0.11833135783672333,0.008490294218063354,0.003000170923769474,0.0016988617135211825,0.0012943425681442022,0.0010876154992729425,0.0009510723757557571,0.0008244157652370632,0.0007125801639631391,0.0006137711461633444,0.000541709188837558,0.00046764398575760424,0.0004108405555598438,0.00037049956154078245,0.00033491826616227627,0.00030853497446514666,0.00028295829542912543,0.0002622197207529098,0.00024217278405558318,0.0002316116588190198,0.00022071792045608163,0.0002099538396578282,0.00019855784194078296,0.00019502620853018016,0.0001872344728326425,0.00018240859208162874,0.00017578082042746246,0.00017149945779237896,0.00016591134772170335,0.0001633016363484785,0.0001564924605190754,0.00015254832396749407,0.00015045418695081025,0.00014540363918058574,0.00014222804747987539,0.00013877745368517935,0.0001374569837935269,0.00013351150846574455,0.000133287045173347,0.00012997188605368137,0.00012806235463358462,0.00012609019177034497,0.00012384260480757803,0.00012224691454321146,0.0001199712060042657,0.00011626134801190346,0.0001170640898635611,0.00011388570419512689,0.00011201286542927846,0.00011043300037272274,0.00010994730837410316,0.0001070053840521723,0.00010744817700469866,0.00010634302452672273,0.00010578081128187478,0.00010332804959034547,0.0001021661446429789,0.00010033843136625364,9.815623343456537e-05,9.87735838862136e-05,9.825199958868325e-05,9.57042066147551e-05,9.515494457446039e-05,9.533076809020713e-05,9.435670654056594e-05,9.368402243126184e-05,9.264666732633486e-05,9.19194717425853e-05,9.09500231500715e-05,8.910631731851026e-05,8.694505231687799e-05,8.831687591737136e-05,8.936825906857848e-05,8.832622552290559e-05,8.656513091409579e-05,8.766475366428494e-05,8.680771861691028e-05,8.43276793602854e-05,8.403114770771936e-05,8.47762858029455e-05,8.519681432517245e-05,8.239310409408063e-05,8.212625834858045e-05,8.279723260784522e-05,8.089837501756847e-05,8.186742343241349e-05,7.990891754161566e-05,7.932609150884673e-05,7.98089531599544e-05,7.831901166355237e-05,7.98524051788263e-05,8.005495328688994e-05,7.906393148005009e-05,7.736546103842556e-05,7.726299372734502e-05,7.775325502734631e-05,7.795488636475056e-05,7.644123252248392e-05,7.60404800530523e-05,7.39312163204886e-05,
mae,0.22158904373645782,0.06672687828540802,0.03905640169978142,0.029793046414852142,0.026177968829870224,0.023860128596425056,0.022225208580493927,0.020565109327435493,0.018980277702212334,0.017606742680072784,0.01656605303287506,0.015482212416827679,0.014553547836840153,0.013788772746920586,0.01326783373951912,0.01284661516547203,0.012434487231075764,0.011957862414419651,0.011634559370577335,0.011421049013733864,0.011204936541616917,0.010915810242295265,0.010715446434915066,0.010616682469844818,0.01039466354995966,0.010323191992938519,0.01008911058306694,0.010028952732682228,0.009867546148598194,0.009789581410586834,0.009654191322624683,0.009525865316390991,0.009477135725319386,0.00932527519762516,0.009247707203030586,0.009175803512334824,0.009034140035510063,0.008985213004052639,0.009032763540744781,0.008806968107819557,0.008753401227295399,0.008743224665522575,0.008654838427901268,0.008623194880783558,0.008528904989361763,0.00843671802431345,0.008491831831634045,0.008414078503847122,0.008272413164377213,0.008303877897560596,0.008193249814212322,0.008135261945426464,0.008165689185261726,0.008023862726986408,0.008134059607982635,0.007925827987492085,0.007900930009782314,0.007889246568083763,0.007782479748129845,0.007783069740980864,0.007831733673810959,0.007709860801696777,0.007721415255218744,0.007769267074763775,0.0076667447574436665,0.007606353145092726,0.007436609361320734,0.007514606695622206,0.007584571372717619,0.007439052686095238,0.0074093760922551155,0.0073221842758357525,0.00744634261354804,0.00741913914680481,0.007353750057518482,0.0074076903983950615,0.007322696968913078,0.007247811183333397,0.0072448719292879105,0.007202306762337685,0.00734084565192461,0.0072031510062515736,0.007137838751077652,0.0072156027890741825,0.007085601799190044,0.007154254242777824,0.0071189687587320805,0.007066814228892326,0.007115131244063377,0.007038408424705267,0.006982926279306412,0.007090985309332609,0.006923409178853035,0.0069182212464511395,0.006963021121919155,0.007035096175968647,0.0070582120679318905,0.006902154069393873,0.006953933741897345,0.006863953545689583,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1971      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1972      
=================================================================
Total params: 3,943
Trainable params: 3,943
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 1,971
Trainable params: 1,971
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                1056      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 1,972
Trainable params: 1,972
Non-trainable params: 0
_________________________________________________________________
