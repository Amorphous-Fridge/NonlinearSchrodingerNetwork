2021-06-26
loss,0.3355269730091095,0.10289281606674194,0.07274553924798965,0.06869061291217804,0.0657448023557663,0.06261628866195679,0.060478758066892624,0.040944382548332214,0.05514048412442207,0.048954810947179794,0.04405782371759415,0.04799859598278999,0.035665854811668396,0.04652863368391991,0.03754932060837746,0.04072995111346245,0.04180097579956055,0.047643695026636124,0.039087794721126556,0.03277630731463432,0.032150961458683014,0.035928063094615936,0.04180615022778511,0.035833150148391724,0.03634929284453392,0.035312965512275696,0.030098233371973038,0.0284288190305233,0.03271815925836563,0.032795146107673645,0.028432855382561684,0.027284789830446243,0.03229181841015816,0.0313308984041214,0.0272368174046278,0.023024344816803932,0.020085979253053665,0.025214385241270065,0.02919744700193405,0.029013048857450485,0.026818325743079185,0.0227527879178524,0.02054169960319996,0.023104915395379066,0.025178970769047737,0.024179885163903236,0.022478921338915825,0.01961498335003853,0.0171657744795084,0.016338175162672997,0.01575453393161297,0.015189669094979763,0.01499284990131855,0.014702259562909603,0.014418656006455421,0.014191976748406887,0.014165128581225872,0.01400813553482294,0.013905211351811886,0.013831008225679398,0.013792740181088448,0.013692175969481468,0.013646582141518593,0.013488265685737133,0.013482492417097092,0.01351074781268835,0.013409373350441456,0.01321243867278099,0.01323109120130539,0.013154817745089531,0.01307071465998888,0.012923203408718109,0.012922845780849457,0.01286478154361248,0.01284744217991829,0.012817705050110817,0.012635226361453533,0.012613282538950443,0.012543209828436375,0.012457668781280518,0.012438126839697361,0.012308047153055668,0.012276594527065754,0.012228698469698429,0.012190109118819237,0.012115790508687496,0.012088385410606861,0.012028886936604977,0.01196852046996355,0.011966520920395851,0.011849488131701946,0.011880559846758842,0.01172691024839878,0.011699029244482517,0.011673285625874996,0.011612261645495892,0.011411952786147594,0.011498285457491875,0.011504117399454117,0.01146092638373375,
mse,0.052067115902900696,0.0032148819882422686,0.00152378692291677,0.0013738343259319663,0.00124999915715307,0.001153550110757351,0.0010766034247353673,0.0004920837818644941,0.0008674421114847064,0.000682503858115524,0.0005662519251927733,0.0006475195987150073,0.0003669581201393157,0.0006228944403119385,0.000411583372624591,0.00046759124961681664,0.0004989409353584051,0.000641561986412853,0.0004368652880657464,0.0003115723957307637,0.0002993902890011668,0.00037172011798247695,0.0004981272504664958,0.00036592644755728543,0.00037686366704292595,0.0003466163179837167,0.0002597854472696781,0.00024097925052046776,0.00029704056214541197,0.0003130919358227402,0.00023223814787343144,0.00021656538592651486,0.0002915153745561838,0.00027339643565937877,0.0002111714711645618,0.00015633106522727758,0.00012165684893261641,0.00018118330626748502,0.00023506899015046656,0.0002313746663276106,0.0002014406054513529,0.00015202461509034038,0.00012584953219629824,0.00015195703599601984,0.00017839140491560102,0.00016461813356727362,0.00014556765381712466,0.00011314304720144719,8.569054625695571e-05,7.65077566029504e-05,6.984188803471625e-05,6.599071639357135e-05,6.27298213657923e-05,6.0568276239791885e-05,5.8075242122868076e-05,5.6418612075503916e-05,5.643749318551272e-05,5.4390100558521226e-05,5.372051236918196e-05,5.337143738870509e-05,5.320527998264879e-05,5.231137765804306e-05,5.205599154578522e-05,5.109588164486922e-05,5.0833376008085907e-05,5.091412094770931e-05,5.034620699007064e-05,4.868836549576372e-05,4.8610912926960737e-05,4.8065521696116775e-05,4.7836092562647536e-05,4.650489063351415e-05,4.687298132921569e-05,4.6459339500870556e-05,4.59899747511372e-05,4.564132905215956e-05,4.4419582991395146e-05,4.45664300059434e-05,4.4106720451964065e-05,4.3848511268151924e-05,4.323751272750087e-05,4.2479063267819583e-05,4.2176543502137065e-05,4.192536653135903e-05,4.173741035629064e-05,4.1322855395264924e-05,4.05903956561815e-05,4.0531969716539606e-05,4.021224958705716e-05,3.979439861723222e-05,3.93537811760325e-05,3.944168201996945e-05,3.869750435114838e-05,3.8178124668775126e-05,3.8040940125938505e-05,3.7958281609462574e-05,3.6962552258046344e-05,3.841464058496058e-05,3.710945384227671e-05,3.661845767055638e-05,
mae,0.14370906352996826,0.04358585178852081,0.030958158895373344,0.02911950647830963,0.027543742209672928,0.02636285312473774,0.02560022845864296,0.017494646832346916,0.023452118039131165,0.02051297202706337,0.01876359060406685,0.020402323454618454,0.015175111591815948,0.01944192312657833,0.015831051394343376,0.017559153959155083,0.01778469607234001,0.020345237106084824,0.016596559435129166,0.013775101862847805,0.013712869957089424,0.0153213981539011,0.017748624086380005,0.015307748690247536,0.015329000540077686,0.015019804239273071,0.012715491466224194,0.011825935915112495,0.01387561485171318,0.013882339932024479,0.011967512778937817,0.011549695394933224,0.013706881552934647,0.013280940242111683,0.011669660918414593,0.009814524091780186,0.008548240177333355,0.010727938264608383,0.012448710389435291,0.012453900650143623,0.011415554210543633,0.009608051739633083,0.00870298407971859,0.009840103797614574,0.01069636084139347,0.010185962542891502,0.009392366744577885,0.008254394866526127,0.007236836478114128,0.006917781662195921,0.006685154512524605,0.006447962485253811,0.00636158837005496,0.006237460765987635,0.006115617696195841,0.006030491553246975,0.005978526081889868,0.005952741950750351,0.005875198170542717,0.005861572455614805,0.005853893700987101,0.005786302033811808,0.00577534269541502,0.005691577214747667,0.00572077976539731,0.005745189264416695,0.005696833599358797,0.005577091593295336,0.0055943145416677,0.005560637917369604,0.005549466237425804,0.005480294115841389,0.005475707817822695,0.005464260466396809,0.00542578985914588,0.0054188878275454044,0.005357443820685148,0.005318652372807264,0.005326756741851568,0.005265700630843639,0.005249747075140476,0.005230432376265526,0.005182468332350254,0.005185544956475496,0.00513131357729435,0.0051309154368937016,0.005111346952617168,0.005105618853121996,0.005055258050560951,0.005095548462122679,0.005038070026785135,0.0050049335695803165,0.004984594415873289,0.004981047008186579,0.004950052592903376,0.004933659452944994,0.004839989822357893,0.004871114622801542,0.0048565915785729885,0.0048596239648759365,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 23011     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 23012     
=================================================================
Total params: 46,023
Trainable params: 46,023
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 23,011
Trainable params: 23,011
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 23,012
Trainable params: 23,012
Non-trainable params: 0
_________________________________________________________________
