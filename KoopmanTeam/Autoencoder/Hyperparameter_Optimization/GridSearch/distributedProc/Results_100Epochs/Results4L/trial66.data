2021-06-26
loss,0.7672340273857117,0.25575095415115356,0.24228356778621674,0.242475688457489,0.24642802774906158,0.2271082103252411,0.19215507805347443,0.14145466685295105,0.10318879038095474,0.10369938611984253,0.08386895805597305,0.07872629165649414,0.07786242663860321,0.0893402099609375,0.06553658097982407,0.05870331451296806,0.06577450037002563,0.05197078362107277,0.05101153254508972,0.051815424114465714,0.0601041354238987,0.049435753375291824,0.04832758009433746,0.04840588569641113,0.04033597558736801,0.038674548268318176,0.0336763821542263,0.04554184526205063,0.04118352383375168,0.04318344593048096,0.03926032409071922,0.037202686071395874,0.037518780678510666,0.034069184213876724,0.030471887439489365,0.032691363245248795,0.04023851826786995,0.03642033413052559,0.02924889326095581,0.02826613374054432,0.03529945760965347,0.0337495319545269,0.03192955255508423,0.03051345981657505,0.03194892778992653,0.03213321790099144,0.0277385376393795,0.027336614206433296,0.025268955156207085,0.02709931693971157,0.029884662479162216,0.031170323491096497,0.027522237971425056,0.022700145840644836,0.020593101158738136,0.02134784311056137,0.023548727855086327,0.029202641919255257,0.028707947582006454,0.02410135231912136,0.025194762274622917,0.02749275229871273,0.02720748446881771,0.024262428283691406,0.023453058674931526,0.021072285249829292,0.01774805597960949,0.021865906193852425,0.024086961522698402,0.025591569021344185,0.02492000162601471,0.02689768373966217,0.024116819724440575,0.021596811711788177,0.02216302417218685,0.024219296872615814,0.024894509464502335,0.021480552852153778,0.020949488505721092,0.023420266807079315,0.02366456761956215,0.022304663434624672,0.02205699495971203,0.021027255803346634,0.020456627011299133,0.023597247898578644,0.022713959217071533,0.02170286700129509,0.019795000553131104,0.02147785946726799,0.01936141401529312,0.018775230273604393,0.021534550935029984,0.02181265875697136,0.018897268921136856,0.017672529444098473,0.017343519255518913,0.02182992547750473,0.02235007844865322,0.019378837198019028,
mse,0.2694321870803833,0.021436510607600212,0.02006600610911846,0.019828109070658684,0.01960819959640503,0.01649632304906845,0.011197363026440144,0.006606464274227619,0.0032374514266848564,0.00317181134596467,0.0021501516457647085,0.001939165755175054,0.0018623737851157784,0.0022626451682299376,0.001297137001529336,0.0010793260298669338,0.0012685857946053147,0.0008054423378780484,0.0007899244083091617,0.0008095820085145533,0.0010417703306302428,0.0007525339024141431,0.0007003604550845921,0.0006849863566458225,0.00047736044507473707,0.0004414535651449114,0.0003519425808917731,0.0006088584777899086,0.0004972397000528872,0.0005449186428450048,0.0004388925153762102,0.0004043889348395169,0.0003992104029748589,0.00033755137701518834,0.00026413024170324206,0.00031848647631704807,0.0004607078153640032,0.00038362902705557644,0.0002565706381574273,0.00023727506049908698,0.00035672393278218806,0.0003252846363466233,0.0002961415739264339,0.0002630084636621177,0.0002931981871370226,0.0002910488401539624,0.0002309573465026915,0.00022303065634332597,0.0001893588196253404,0.00022152840392664075,0.00025896538863889873,0.0002764471573755145,0.00021756505884695798,0.00015426504251081496,0.00013774751278106123,0.00013976733316667378,0.0001680882414802909,0.00024365592980757356,0.0002303228829987347,0.00016846282233018428,0.00018399998953100294,0.0002139744465239346,0.00020744712674058974,0.00016566044359933585,0.00015535808051936328,0.00013345018669497222,9.747748845256865e-05,0.00014124443987384439,0.00016849878011271358,0.0001890608691610396,0.00017684584599919617,0.00020337036403361708,0.00016512389993295074,0.0001400782202836126,0.00014047898002900183,0.00016649160534143448,0.0001708517811493948,0.00013079492782708257,0.00013050621782895178,0.00015495612751692533,0.00016029944526962936,0.0001436225138604641,0.00013810118252877146,0.00012479026918299496,0.00012066752969985828,0.00015912589151412249,0.00014742671919520944,0.00013620009121950716,0.00011490679025882855,0.00013030515401624143,0.00010506524995435029,0.00010490265412954614,0.0001351663377135992,0.00013617250078823417,0.00010201906115980819,8.942221029428765e-05,8.961279672803357e-05,0.00013643769489135593,0.00014118669787421823,0.00010909663251368329,
mae,0.32930874824523926,0.1055244728922844,0.0989285483956337,0.100945845246315,0.10465774685144424,0.0957908034324646,0.08128977566957474,0.060516953468322754,0.04376692324876785,0.043831437826156616,0.03553272783756256,0.03350576013326645,0.03303490951657295,0.03808005154132843,0.027438996359705925,0.02493627369403839,0.02809125930070877,0.021664975211024284,0.021800464019179344,0.0219277236610651,0.025610577315092087,0.02094973251223564,0.02050844207406044,0.020367002114653587,0.017222486436367035,0.016457458958029747,0.014404562301933765,0.01920737698674202,0.017305731773376465,0.018308421596884727,0.016755757853388786,0.015801576897501945,0.015801100060343742,0.014683866873383522,0.013132235035300255,0.013644141145050526,0.01713252253830433,0.015507386066019535,0.012538766488432884,0.012057901360094547,0.014768482185900211,0.01439428050071001,0.013641809113323689,0.012978965416550636,0.013372497633099556,0.013622701168060303,0.012074491940438747,0.011737286113202572,0.010829959064722061,0.011542562395334244,0.012675940990447998,0.013277910649776459,0.01167556643486023,0.00959017500281334,0.008918313309550285,0.008990757167339325,0.01002301461994648,0.012441006489098072,0.012345257215201855,0.010371066629886627,0.010856496170163155,0.011600030586123466,0.011505561880767345,0.010420217178761959,0.01001404132694006,0.008870953693985939,0.007547933608293533,0.009037569165229797,0.010025045834481716,0.010674688033759594,0.01062575913965702,0.011495680548250675,0.010237368755042553,0.00913013331592083,0.009442802518606186,0.010354671627283096,0.010512475855648518,0.009099808521568775,0.00900402944535017,0.010193509981036186,0.010053698904812336,0.009417989291250706,0.009404096752405167,0.008801854215562344,0.008778205141425133,0.009980513714253902,0.009550967253744602,0.00929260440170765,0.00836904812604189,0.009149336256086826,0.008129042573273182,0.00800521019846201,0.009216049686074257,0.009267332032322884,0.007745771203190088,0.007300970144569874,0.007430150639265776,0.009282889775931835,0.009362812153995037,0.008223466575145721,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 275563    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 275564    
=================================================================
Total params: 551,127
Trainable params: 551,127
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 275,563
Trainable params: 275,563
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 275,564
Trainable params: 275,564
Non-trainable params: 0
_________________________________________________________________
