2021-06-26
loss,2.510728359222412,0.46091315150260925,0.2735525369644165,0.22119475901126862,0.17565643787384033,0.1340162605047226,0.14020824432373047,0.12167372554540634,0.08878720551729202,0.0698055699467659,0.07515811175107956,0.07180125266313553,0.06964489817619324,0.06287099421024323,0.05810313671827316,0.06221058964729309,0.05507946014404297,0.05035170167684555,0.04665176942944527,0.04423899948596954,0.05073252692818642,0.04061988368630409,0.03893713653087616,0.03970169648528099,0.036637309938669205,0.033363427966833115,0.03383931145071983,0.034227155148983,0.03180132061243057,0.03167476877570152,0.027986086905002594,0.03195984289050102,0.029199659824371338,0.027996594086289406,0.025751572102308273,0.026336055248975754,0.025172971189022064,0.027359673753380775,0.025316912680864334,0.023407451808452606,0.02153322659432888,0.0232686810195446,0.022238217294216156,0.01888270676136017,0.020072853192687035,0.027415579184889793,0.02224649488925934,0.021761756390333176,0.023225782439112663,0.02404853142797947,0.02436792105436325,0.02179333008825779,0.018538882955908775,0.019102610647678375,0.021956250071525574,0.023083975538611412,0.02036433294415474,0.01963687129318714,0.021093443036079407,0.020712900906801224,0.021260716021060944,0.020415373146533966,0.019236551597714424,0.01903052255511284,0.020782344043254852,0.01871747151017189,0.017649836838245392,0.019930996000766754,0.0186375193297863,0.016870999708771706,0.020330190658569336,0.01912098377943039,0.01911836303770542,0.017324484884738922,0.017927562817931175,0.019555246457457542,0.017873570322990417,0.019063735380768776,0.018199317157268524,0.017331233248114586,0.017833618447184563,0.01701122708618641,0.01700468733906746,0.016043061390519142,0.016088057309389114,0.016615426167845726,0.01850518025457859,0.0175246000289917,0.016640396788716316,0.016480017453432083,0.01763787306845188,0.017192259430885315,0.01644829474389553,0.014655322767794132,0.016597861424088478,0.017598358914256096,0.01766061782836914,0.016599265858530998,0.015940140932798386,0.017489077523350716,
mse,1.7418080568313599,0.07329998910427094,0.02342529594898224,0.015603211708366871,0.008960266597568989,0.005090426187962294,0.005680241622030735,0.004306250251829624,0.002196148270741105,0.0014093710342422128,0.0015886855544522405,0.00147822976578027,0.0014127253089100122,0.0011406756239011884,0.0009417516994290054,0.0011083772405982018,0.0008813951862975955,0.0007029675180092454,0.0006190500571392477,0.0005597459385171533,0.0007019028998911381,0.0004629984905477613,0.0004322619060985744,0.0004384195199236274,0.0003724466951098293,0.00031814855174161494,0.00032346375519409776,0.00032970120082609355,0.00028737372485920787,0.0002790515427477658,0.0002272558049298823,0.0002855102648027241,0.00023457880888599902,0.00021794125495944172,0.0001911354047479108,0.00019676570082083344,0.00018111729878000915,0.0002154655521735549,0.00017965164443012327,0.00015575527504552156,0.0001347147481283173,0.00015520873421337456,0.0001418071478838101,0.000106865081761498,0.00011921658006031066,0.00021333018958102912,0.00014398993516806513,0.0001358941663056612,0.00015701574739068747,0.00016285870515275747,0.00016435040743090212,0.00013126683188602328,0.00010314238170394674,0.00010821377509273589,0.00013596797361969948,0.0001498814090155065,0.000122649478726089,0.00011376896873116493,0.00012620868801604956,0.00012281995441298932,0.00012675065954681486,0.00011687555524986237,0.00010613911581458524,0.00010483637743163854,0.00012256851186975837,0.00010131610906682909,9.516216960037127e-05,0.00011285817163297907,9.92715431493707e-05,8.41993823996745e-05,0.00011695812281686813,0.00010382630716776475,0.00010431561531731859,9.146564843831584e-05,9.261251398129389e-05,0.00010786608618218452,9.294800111092627e-05,0.00010215678048552945,9.364960715174675e-05,8.711960981599987e-05,9.35472926357761e-05,8.421068196184933e-05,8.462386176688597e-05,7.668753823963925e-05,7.660277333343402e-05,8.277166489278898e-05,9.62143240030855e-05,8.958788384916261e-05,7.997409556992352e-05,8.038620580919087e-05,9.153663995675743e-05,8.484691352350637e-05,7.958689820952713e-05,6.416575342882425e-05,8.110845374176279e-05,9.011188376462087e-05,9.087063517654315e-05,8.115986565826461e-05,7.494028250221163e-05,8.880018867785111e-05,
mae,0.9729985594749451,0.19406557083129883,0.12019037455320358,0.09554348886013031,0.07355057448148727,0.05680116266012192,0.0604262501001358,0.05247488617897034,0.03714127466082573,0.02965327724814415,0.03168470785021782,0.03059028834104538,0.02928447537124157,0.026752298697829247,0.02413884922862053,0.02673206850886345,0.024311736226081848,0.02156379260122776,0.0194857157766819,0.01873152144253254,0.021974852308630943,0.017437569797039032,0.016530774533748627,0.017258480191230774,0.015826940536499023,0.014067462645471096,0.014368627220392227,0.014434657990932465,0.01344652846455574,0.013315487653017044,0.011820611543953419,0.013609613291919231,0.012218283489346504,0.011770752258598804,0.010871034115552902,0.011175827123224735,0.010704431682825089,0.01165636908262968,0.010792667046189308,0.009889439679682255,0.009182007052004337,0.009993450716137886,0.009335395880043507,0.007967396639287472,0.008449070155620575,0.01163387019187212,0.009306075982749462,0.009200319647789001,0.009673370979726315,0.010358905419707298,0.0105605348944664,0.009114095009863377,0.007902620360255241,0.008149917237460613,0.009300879202783108,0.009841607883572578,0.00870039127767086,0.008313631638884544,0.008725980296730995,0.008844698779284954,0.009108388796448708,0.008698645979166031,0.008177782408893108,0.008110213093459606,0.00896881241351366,0.007928086444735527,0.007452530320733786,0.008430802263319492,0.00785358902066946,0.007198778912425041,0.008726709522306919,0.00802629068493843,0.008083450607955456,0.007314924616366625,0.007630901876837015,0.00843440368771553,0.0076057626865804195,0.00817781314253807,0.00778627023100853,0.007428190670907497,0.007520012091845274,0.007303840946406126,0.007287890184670687,0.006815953645855188,0.006818814668804407,0.007064530160278082,0.007928023114800453,0.007471306249499321,0.0070358943194150925,0.006951743271201849,0.007518083322793245,0.00734118465334177,0.006993809714913368,0.006244337186217308,0.007038487587124109,0.007499683648347855,0.007458127569407225,0.007088534068316221,0.0068033961579203606,0.007439340464770794,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 181571    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 181572    
=================================================================
Total params: 363,143
Trainable params: 363,143
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 181,571
Trainable params: 181,571
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 181,572
Trainable params: 181,572
Non-trainable params: 0
_________________________________________________________________
