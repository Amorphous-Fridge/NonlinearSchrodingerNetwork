2021-06-26
loss,2.0421557426452637,0.26561257243156433,0.13016082346439362,0.09767219424247742,0.10449791699647903,0.09756091237068176,0.07923101633787155,0.08882781118154526,0.09481450915336609,0.08211749792098999,0.07107029110193253,0.07744519412517548,0.06970348954200745,0.07000276446342468,0.05875927582383156,0.05739067122340202,0.04992750287055969,0.0497591532766819,0.060233067721128464,0.05775061994791031,0.05418696254491806,0.051151007413864136,0.04962361976504326,0.047968801110982895,0.04304740950465202,0.04651840031147003,0.046591129153966904,0.03934245929121971,0.04595209285616875,0.04149149730801582,0.04266633093357086,0.04185798019170761,0.038861218839883804,0.041071873158216476,0.04135686904191971,0.0374501571059227,0.039996083825826645,0.03297559544444084,0.03566109761595726,0.03202921897172928,0.036905232816934586,0.03515918180346489,0.031998831778764725,0.03230782970786095,0.030596129596233368,0.03388986736536026,0.035297244787216187,0.031598497182130814,0.029867541044950485,0.028336314484477043,0.027752697467803955,0.02123861387372017,0.030442502349615097,0.028300711885094643,0.027047747746109962,0.027058353647589684,0.028389181941747665,0.025881657376885414,0.026214037090539932,0.02582678757607937,0.02771243080496788,0.02602778933942318,0.024309158325195312,0.02856401726603508,0.02569677121937275,0.025323111563920975,0.02381989173591137,0.02469583787024021,0.023124471306800842,0.02391846664249897,0.023516178131103516,0.024617141112685204,0.02483539655804634,0.024600040167570114,0.024246294051408768,0.023460542783141136,0.02167094312608242,0.01890987530350685,0.022887609899044037,0.02236824668943882,0.02177152782678604,0.02354550175368786,0.021902551874518394,0.020935775712132454,0.020541906356811523,0.021486399695277214,0.020732903853058815,0.022059552371501923,0.020100891590118408,0.022515887394547462,0.020094724372029305,0.020200485363602638,0.0204774197191,0.018978560343384743,0.020892227068543434,0.020091284066438675,0.018934087827801704,0.019479626789689064,0.0195467546582222,0.020812110975384712,
mse,1.210217833518982,0.022428719326853752,0.005226503126323223,0.0028150591533631086,0.0031312063802033663,0.002730682259425521,0.001989453798159957,0.002383436542004347,0.0025537919718772173,0.0019160485826432705,0.0014858944341540337,0.0017274686833843589,0.0013674844522029161,0.0013736060354858637,0.0010008544195443392,0.0008995698881335557,0.0007023976650089025,0.0007169002201408148,0.0010373360710218549,0.0009303154074586928,0.0008389922440983355,0.0007443847716785967,0.0007035063463263214,0.000669303466565907,0.0005286720697768033,0.0006011620862409472,0.0006095321732573211,0.0004367873480077833,0.0005842952523380518,0.00048280469491146505,0.0005101061542518437,0.0005039881798438728,0.0004345968773122877,0.000479182752314955,0.00047284390893764794,0.0003944505879189819,0.0004456670139916241,0.00030791183235123754,0.00035276298876851797,0.0002873745106626302,0.0003970760735683143,0.0003417598200030625,0.0002939507830888033,0.00029109104070812464,0.00025905523216351867,0.00031944760121405125,0.00034524756483733654,0.0002777591289486736,0.00024398468667641282,0.0002196296991314739,0.00021780902170576155,0.00013787402713205665,0.00026102885021828115,0.00022674458159599453,0.00020095032232347876,0.0002063150895992294,0.0002230168756796047,0.00018469145288690925,0.00018917283159680665,0.00018623577489051968,0.00021154845308046788,0.00019593043543864042,0.00016623975534457713,0.00022896897280588746,0.00018105277558788657,0.00017798104090616107,0.00016081567446235567,0.0001684203598415479,0.00014845877012703568,0.00016320290160365403,0.00015565886860713363,0.00016822222096379846,0.00017147540347650647,0.00016944478556979448,0.00016444158973172307,0.00015316203644033521,0.00013140590453986079,0.00010411768016638234,0.00015164200158324093,0.00014134890807326883,0.00013483285147231072,0.0001570914755575359,0.00013365503400564194,0.0001281546865357086,0.00012205274833831936,0.000133225490571931,0.00012332931510172784,0.00013502482033800334,0.00011606687621679157,0.00014516653027385473,0.0001156469588750042,0.00011823296517832205,0.00011909454042324796,0.00010535025649005547,0.00012050785153405741,0.00011249368981225416,0.00010044917144114152,0.00010794314584927633,0.00010573216422926635,0.00012051813246216625,
mae,0.7383663058280945,0.11328853666782379,0.05574292689561844,0.042354997247457504,0.0442715585231781,0.04142941161990166,0.03470393270254135,0.038423072546720505,0.04033007100224495,0.03492549806833267,0.03020106814801693,0.03278089687228203,0.029248226433992386,0.03076544962823391,0.025384478271007538,0.023699145764112473,0.021378185600042343,0.021212255582213402,0.0257667675614357,0.024982716888189316,0.023459922522306442,0.022545641288161278,0.021445555612444878,0.02033611759543419,0.018197666853666306,0.019722897559404373,0.02005915343761444,0.016871165484189987,0.019866732880473137,0.017705567181110382,0.018193071708083153,0.018086569383740425,0.016751835122704506,0.017256246879696846,0.017671603709459305,0.01614285074174404,0.016475651413202286,0.014172778464853764,0.014859344810247421,0.013738107867538929,0.01585116796195507,0.014949630945920944,0.01350878830999136,0.013734803535044193,0.01287796813994646,0.014653476886451244,0.015654869377613068,0.013931725174188614,0.012714726850390434,0.012130463495850563,0.011712572537362576,0.009042564779520035,0.012816566042602062,0.011996732093393803,0.011519786901772022,0.011623966507613659,0.011845500208437443,0.010797896422445774,0.011289916932582855,0.010903935879468918,0.01191833708435297,0.011016910895705223,0.010068008676171303,0.012202607467770576,0.010192189365625381,0.010897448286414146,0.010186419822275639,0.010154280811548233,0.009524463675916195,0.010143464431166649,0.009974612854421139,0.010231474414467812,0.010607834905385971,0.010554095730185509,0.010164428502321243,0.010178462602198124,0.009147927165031433,0.007954314351081848,0.009588275104761124,0.009469207376241684,0.009115690365433693,0.010182143189013004,0.009044269099831581,0.008939131163060665,0.008712203241884708,0.009016650728881359,0.00881178118288517,0.009178887121379375,0.00844663754105568,0.009640242904424667,0.008320841006934643,0.008646760135889053,0.008559219539165497,0.00795179046690464,0.008931470103561878,0.008169542998075485,0.007853725925087929,0.008221249096095562,0.00820730347186327,0.008708198554813862,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 156707    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 156708    
=================================================================
Total params: 313,415
Trainable params: 313,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 156,707
Trainable params: 156,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 156,708
Trainable params: 156,708
Non-trainable params: 0
_________________________________________________________________
