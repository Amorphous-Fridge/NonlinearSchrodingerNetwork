2021-06-26
loss,0.5623407363891602,0.15458360314369202,0.11247671395540237,0.08593098819255829,0.07703211158514023,0.06200104579329491,0.06771064549684525,0.05719516798853874,0.05602642521262169,0.05659370496869087,0.056295957416296005,0.05016471818089485,0.051154233515262604,0.04799634963274002,0.04707629606127739,0.039199456572532654,0.040155258029699326,0.04453478381037712,0.03577505424618721,0.031807173043489456,0.03498540446162224,0.03906252980232239,0.03281022608280182,0.03549595922231674,0.031839270144701004,0.02970551699399948,0.0272463820874691,0.027609482407569885,0.03177313879132271,0.028019754216074944,0.02369999885559082,0.025048553943634033,0.024957142770290375,0.025702180340886116,0.03217950463294983,0.027271706610918045,0.024619482457637787,0.022005466744303703,0.022923018783330917,0.024159684777259827,0.02487810142338276,0.01819468103349209,0.02325247786939144,0.023915119469165802,0.026264019310474396,0.021964730694890022,0.0184252317994833,0.016066377982497215,0.01836443319916725,0.019468441605567932,0.02361675538122654,0.01879885233938694,0.017738375812768936,0.02106231451034546,0.021678082644939423,0.01992901600897312,0.018478693440556526,0.018715502694249153,0.01872405596077442,0.018237311393022537,0.01916179247200489,0.018554503098130226,0.01866034045815468,0.01843639463186264,0.016826175153255463,0.017994701862335205,0.018211262300610542,0.016893474385142326,0.015846844762563705,0.018325941637158394,0.017829107120633125,0.017389709129929543,0.0170532688498497,0.016538523137569427,0.016933180391788483,0.01662909798324108,0.018009968101978302,0.01715235784649849,0.015101343393325806,0.014043140225112438,0.012398001737892628,0.015372424386441708,0.01662524789571762,0.017262348905205727,0.015398127026855946,0.016776403412222862,0.01623239368200302,0.01408317405730486,0.015613565221428871,0.014724327251315117,0.012034337967634201,0.01485438086092472,0.015106176026165485,0.015713313594460487,0.01582435332238674,0.01601874642074108,0.01625349558889866,0.014593465253710747,0.01388690248131752,0.015322643332183361,
mse,0.1751757264137268,0.007079124450683594,0.0036908178590238094,0.002201274735853076,0.0017509609460830688,0.0011250677052885294,0.001383973634801805,0.0009523436892777681,0.0009306721622124314,0.0009556575096212327,0.0009531286195851862,0.0007394232670776546,0.0007580289384350181,0.0006724331760779023,0.00063137715915218,0.00044292447273619473,0.00048325888928957283,0.0005827835411764681,0.00037701852852478623,0.0003000284486915916,0.0003581322089303285,0.0004520272486843169,0.0003185301320627332,0.0003718101361300796,0.0002980924036819488,0.00026030282606370747,0.0002195019624195993,0.00022408839140553027,0.0002864038688130677,0.00022753408120479435,0.00016225928266067058,0.00018951045058201998,0.0001842057827161625,0.00019390537636354566,0.0002959508274216205,0.00021596945589408278,0.00017614400712773204,0.0001434189034625888,0.00015371886547654867,0.00016657690866850317,0.00017763860523700714,0.0001002187782432884,0.00015623944636899978,0.0001658055407460779,0.00019150221487507224,0.0001360707829007879,0.00010125161497853696,7.780935993650928e-05,9.979322203435004e-05,0.00011226358765270561,0.00016189856978598982,0.00010538107017055154,9.523740300210193e-05,0.0001290658547077328,0.00013477281027007848,0.00011230329255340621,0.00010295338142896071,0.00010278495756210759,0.00010028332326328382,9.879090794129297e-05,0.00010294793173670769,9.953376866178587e-05,0.00010022288915934041,9.68409440247342e-05,8.30173958092928e-05,9.462429443374276e-05,9.775846410775557e-05,8.312293357448652e-05,7.408544479403645e-05,9.66243605944328e-05,9.033801325131208e-05,8.814159082248807e-05,8.638467988930643e-05,7.994732732186094e-05,8.18514236016199e-05,8.124786108965054e-05,9.307175787398592e-05,8.23431764729321e-05,6.732495967298746e-05,6.145265069790184e-05,4.694231029134244e-05,7.140296656871215e-05,7.989868754521012e-05,8.427979628322646e-05,6.959525489946827e-05,8.231994434027001e-05,7.653933425899595e-05,5.9753412642749026e-05,7.11578395566903e-05,6.690101145068184e-05,4.551890378934331e-05,6.662169471383095e-05,6.741335528204218e-05,7.490272400900722e-05,7.323538739001378e-05,7.500196807086468e-05,7.719694986008108e-05,6.290745659498498e-05,5.7677920267451555e-05,6.896253762533888e-05,
mae,0.2432587444782257,0.06476110965013504,0.04792134836316109,0.03677908331155777,0.032969892024993896,0.02651817351579666,0.028665829449892044,0.024293754249811172,0.0236037690192461,0.024081913754343987,0.02419627644121647,0.021318353712558746,0.021760866045951843,0.020320886746048927,0.020038241520524025,0.016676120460033417,0.016959231346845627,0.019027555361390114,0.01526822242885828,0.013599565252661705,0.014765636995434761,0.01660042256116867,0.014005906879901886,0.015103764832019806,0.013608550652861595,0.012587246485054493,0.011592617258429527,0.011624058708548546,0.013491153717041016,0.011868570931255817,0.01009486336261034,0.010602436028420925,0.010607677511870861,0.010875076986849308,0.013606023043394089,0.011595198884606361,0.010386819951236248,0.009190707467496395,0.00971998367458582,0.010317313484847546,0.010576525703072548,0.007704096380621195,0.00986055564135313,0.010155306197702885,0.011227530427277088,0.009387792088091373,0.007768731098622084,0.006861650850623846,0.00786020327359438,0.008205506019294262,0.010068354196846485,0.008015429601073265,0.007543668616563082,0.008852913975715637,0.009125963784754276,0.00853348895907402,0.007787850685417652,0.007899727672338486,0.007811303250491619,0.00767548568546772,0.008097431622445583,0.007917050272226334,0.007938855327665806,0.007780717685818672,0.00717596709728241,0.007611602544784546,0.007742328569293022,0.007198442239314318,0.006781082600355148,0.007659323047846556,0.007583841681480408,0.007357777561992407,0.007346800994127989,0.007042857352644205,0.007249047048389912,0.006982195191085339,0.00771105894818902,0.007224261295050383,0.0063711232505738735,0.00590481935068965,0.0052472734823822975,0.006556125357747078,0.007038782816380262,0.007360352668911219,0.00649150600656867,0.007099656853824854,0.006926801986992359,0.005998284090310335,0.006670529954135418,0.006242955103516579,0.005084386095404625,0.0063264938071370125,0.006354066077619791,0.0067283716052770615,0.006738999858498573,0.006800975650548935,0.00696704164147377,0.006157801952213049,0.005891885608434677,0.0065957922488451,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 91043     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 91044     
=================================================================
Total params: 182,087
Trainable params: 182,087
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 91,043
Trainable params: 91,043
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 91,044
Trainable params: 91,044
Non-trainable params: 0
_________________________________________________________________
