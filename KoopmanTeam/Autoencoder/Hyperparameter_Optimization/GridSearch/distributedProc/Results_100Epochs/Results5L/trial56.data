2021-06-26
loss,0.6963667273521423,0.26534387469291687,0.24715913832187653,0.22930948436260223,0.20594030618667603,0.15432710945606232,0.10839476436376572,0.11019311100244522,0.09537947922945023,0.08793695271015167,0.08120259642601013,0.06937049329280853,0.06382276117801666,0.07991716265678406,0.07843223214149475,0.06185324490070343,0.0540199913084507,0.05302036181092262,0.06115545332431793,0.05849454924464226,0.053588151931762695,0.04714922606945038,0.04621676355600357,0.04075409844517708,0.041883908212184906,0.04025711119174957,0.0408332496881485,0.04019875451922417,0.03643568977713585,0.03845265880227089,0.037581924349069595,0.03263568505644798,0.029511844739317894,0.025327010080218315,0.030995085835456848,0.03449980169534683,0.03698265552520752,0.03140591084957123,0.032308146357536316,0.033313654363155365,0.028294123709201813,0.02882329933345318,0.026630504056811333,0.026177098974585533,0.028841879218816757,0.030272934585809708,0.024970155209302902,0.02519664727151394,0.02478499710559845,0.025316601619124413,0.028329528868198395,0.02299041487276554,0.024683162569999695,0.026111101731657982,0.025316987186670303,0.01814275234937668,0.021305566653609276,0.025807911530137062,0.02452431432902813,0.024492861703038216,0.022698814049363136,0.024068770930171013,0.022253455594182014,0.021927325055003166,0.01825857162475586,0.020350242033600807,0.023595858365297318,0.021956171840429306,0.02073115110397339,0.02049093320965767,0.020895134657621384,0.019710320979356766,0.022223489359021187,0.021357018500566483,0.0212653037160635,0.02194671705365181,0.019025426357984543,0.02155841514468193,0.01950015127658844,0.0175915639847517,0.018992101773619652,0.019447363913059235,0.020342037081718445,0.020046140998601913,0.0172386784106493,0.01685315929353237,0.016182653605937958,0.01970168948173523,0.020019488409161568,0.019725695252418518,0.018403219059109688,0.018808545544743538,0.016327323392033577,0.01948283240199089,0.018741153180599213,0.014986959286034107,0.015523419715464115,0.016560416668653488,0.019731013104319572,0.017933933064341545,
mse,0.2505655288696289,0.022418199107050896,0.020030410960316658,0.016365746036171913,0.012719006277620792,0.006893565878272057,0.0034149133134633303,0.00343315745703876,0.0025999622885137796,0.0021808564197272062,0.0019003460183739662,0.0013609591405838728,0.0011591902002692223,0.0018399660475552082,0.0017672115936875343,0.0010853585554286838,0.0008140876307152212,0.0007982332026585937,0.0011090124025940895,0.0009685376426205039,0.0008276220178231597,0.0006336632650345564,0.0006268096040003002,0.0004718601703643799,0.0004986425046809018,0.0004687286273110658,0.0004703627491835505,0.00045875017531216145,0.0003791572817135602,0.00041681076982058585,0.0004010903066955507,0.00029857640038244426,0.00025632308097556233,0.0001950700971065089,0.00027732833405025303,0.0003336899389978498,0.000383438280550763,0.000278747349511832,0.0002946223830804229,0.0003073186380788684,0.00022893305867910385,0.00023321433400269598,0.00019937945762649179,0.0001969524601008743,0.00023917702492326498,0.0002551601210143417,0.0001828030653996393,0.00018399374675936997,0.00017739353643264621,0.00018827631720341742,0.0002255403232993558,0.00015093330875970423,0.00017381005454808474,0.00019208645971957594,0.00018870964413508773,0.00010016218584496528,0.00013762633898295462,0.00018593628192320466,0.00016822718316689134,0.0001714312966214493,0.00014937263040337712,0.00016358129505533725,0.00013981091615278274,0.00013357835996430367,0.00010154799383599311,0.00011911954788956791,0.00015742622781544924,0.0001363882765872404,0.00012509948282968253,0.00012051916564814746,0.00012346368748694658,0.00011254199489485472,0.00014013273175805807,0.0001313122920691967,0.00012855668319389224,0.00013472761202137917,0.00010541216761339456,0.00013214797945693135,0.00010955401376122609,9.278168727178127e-05,0.00010460252087796107,0.00011087434540968388,0.00011834681208711118,0.00011151697253808379,8.811488805804402e-05,8.561654249206185e-05,7.74636137066409e-05,0.00011091907799709588,0.00011581349826883525,0.00011043189442716539,9.947287617251277e-05,0.0001003262514132075,7.771043601678684e-05,0.00011059117241529748,9.846687316894531e-05,6.698094512103125e-05,7.138917135307565e-05,8.051480836002156e-05,0.00011151023500133306,9.26806969800964e-05,
mae,0.3087509274482727,0.11837891489267349,0.10656824707984924,0.09584102779626846,0.0878005251288414,0.0643366277217865,0.045738350600004196,0.04712230712175369,0.04094293713569641,0.03771967813372612,0.034427620470523834,0.029473915696144104,0.026862695813179016,0.03411952778697014,0.033658456057310104,0.026702990755438805,0.02309405617415905,0.022553114220499992,0.025906313210725784,0.02537531405687332,0.022733379155397415,0.01985311694443226,0.019556738436222076,0.01731816679239273,0.017691699787974358,0.016994668170809746,0.01729973405599594,0.01700160652399063,0.015260763466358185,0.016351552680134773,0.01584552228450775,0.013881738297641277,0.012506997212767601,0.01075854804366827,0.013239872641861439,0.01448683813214302,0.01597198285162449,0.013452802784740925,0.013590947724878788,0.014297123067080975,0.012115237303078175,0.012372792698442936,0.011297290213406086,0.011052791029214859,0.012213550508022308,0.012860821560025215,0.010519688948988914,0.010707871057093143,0.010566215962171555,0.010913367383182049,0.01215809304267168,0.009863077662885189,0.010515792295336723,0.01103870291262865,0.010810425505042076,0.00767876161262393,0.00908740609884262,0.011070864275097847,0.010237460024654865,0.01035314705222845,0.009605692699551582,0.010232684202492237,0.00943449791520834,0.009465176612138748,0.007825377397239208,0.008595528081059456,0.010034879669547081,0.009317807853221893,0.008731904439628124,0.00871676579117775,0.008940114639699459,0.008253930136561394,0.00946863554418087,0.009095484390854836,0.009059476666152477,0.00948916096240282,0.008166267536580563,0.00919073261320591,0.008198932744562626,0.007331750821322203,0.008058344945311546,0.008275480940937996,0.008633914403617382,0.008604118600487709,0.007228587754070759,0.007196294143795967,0.006828928366303444,0.008213010616600513,0.008478735573589802,0.008402896113693714,0.007835343480110168,0.007875138893723488,0.00688673323020339,0.008373821154236794,0.007938328199088573,0.006370984483510256,0.006531535182148218,0.007074976339936256,0.008368169888854027,0.0075468444265425205,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 74531     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 74532     
=================================================================
Total params: 149,063
Trainable params: 149,063
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 74,531
Trainable params: 74,531
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 74,532
Trainable params: 74,532
Non-trainable params: 0
_________________________________________________________________
