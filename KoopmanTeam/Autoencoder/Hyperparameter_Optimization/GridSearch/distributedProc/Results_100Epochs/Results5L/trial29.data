2021-06-26
loss,0.30811572074890137,0.08731385320425034,0.06483059376478195,0.06557384133338928,0.050567783415317535,0.06849338859319687,0.04834143817424774,0.04220941662788391,0.04146984964609146,0.03899728134274483,0.03669027239084244,0.03625193238258362,0.04957571625709534,0.052888236939907074,0.054415713995695114,0.04768909886479378,0.04128275439143181,0.044513262808322906,0.04780702665448189,0.031026458367705345,0.03549252077937126,0.040273766964673996,0.04207481071352959,0.04181845486164093,0.048509880900382996,0.04183660447597504,0.0355098694562912,0.03186841309070587,0.02931446023285389,0.02784324251115322,0.026777341961860657,0.025978727266192436,0.02437504567205906,0.023427672684192657,0.02362888492643833,0.028884708881378174,0.03674541041254997,0.03290724381804466,0.039399344474077225,0.03692195191979408,0.03367649018764496,0.02786487527191639,0.024271195754408836,0.027406267821788788,0.026923885568976402,0.02043088711798191,0.02333565056324005,0.03265120089054108,0.0270612183958292,0.025367720052599907,0.023644890636205673,0.02264183759689331,0.028151681646704674,0.031681060791015625,0.028718531131744385,0.02740643173456192,0.02504468895494938,0.024094030261039734,0.022375192493200302,0.02427566610276699,0.03134215995669365,0.030530111864209175,0.026059284806251526,0.024429738521575928,0.023000352084636688,0.02115299552679062,0.0203867107629776,0.0188604649156332,0.019034383818507195,0.023676447570323944,0.0220953319221735,0.02100398950278759,0.021685294806957245,0.026071013882756233,0.02530858665704727,0.023957619443535805,0.027877086773514748,0.02570430561900139,0.023026226088404655,0.020757803693413734,0.01959363743662834,0.01894340105354786,0.01809654012322426,0.017866333946585655,0.01899150013923645,0.024273119866847992,0.023666972294449806,0.02393100969493389,0.021935012191534042,0.020490791648626328,0.020002257078886032,0.022204194217920303,0.024812400341033936,0.022096436470746994,0.019448578357696533,0.020968234166502953,0.01888318918645382,0.018849177286028862,0.023836607113480568,0.020940015092492104,
mse,0.04457451030611992,0.002402076032012701,0.0012673927703872323,0.0013056779280304909,0.0007398428861051798,0.0013978471979498863,0.0006879418506287038,0.0005163836758583784,0.0005045192665420473,0.00043322890996932983,0.00038232392398640513,0.0003832170623354614,0.0007197896484285593,0.0008060718537308276,0.0008469463209621608,0.0006434547831304371,0.0004724354366771877,0.0005861661629751325,0.0006856808322481811,0.000286159454844892,0.0003739782841876149,0.0004674741649068892,0.0004940100479871035,0.0004980427329428494,0.0006673575844615698,0.0004990749293938279,0.00036393062327988446,0.00028284877771511674,0.000241417161305435,0.00021988996013533324,0.00020467596186790615,0.00019303361477795988,0.0001747735368553549,0.00015819053805898875,0.00016469335241708905,0.0002457161608617753,0.0003800671547651291,0.00031196229974739254,0.0004394509014673531,0.0003854957176372409,0.0003243100654799491,0.0002254269493278116,0.00017256620049010962,0.0002192207466578111,0.0002144605532521382,0.00012347521260380745,0.00015904374595265836,0.000301658408716321,0.0002031941112363711,0.000178432950633578,0.00015594004071317613,0.0001443127985112369,0.00023450162552762777,0.00028097466565668583,0.00023377408797387034,0.00020983921422157437,0.00018007778271567076,0.00016957467596512288,0.00014650796947535127,0.0001759566366672516,0.00028164268587715924,0.0002717097522690892,0.00018964715127367526,0.000166013662237674,0.0001476924808230251,0.0001268434862140566,0.00011723485658876598,0.00010586989083094522,0.00010606717114569619,0.00015573568816762418,0.00013903570652473718,0.00012647877156268805,0.00014345094677992165,0.00019676904776133597,0.00018032647494692355,0.00016349133511539549,0.00022133257880341262,0.0001948535064002499,0.00014880234084557742,0.000120757773402147,0.00010932129953289405,0.00010181550896959379,9.254252654500306e-05,9.295676136389375e-05,0.00010437469609314576,0.000167390942806378,0.00015907576016616076,0.00016170862363651395,0.0001361553295282647,0.00012141348997829482,0.00011327133688610047,0.00014423119137063622,0.000179450202267617,0.00013936671894043684,0.00010833852138603106,0.0001232239737873897,0.00010340174048906192,0.0001019227784126997,0.00016280222916975617,0.00012706297275144607,
mae,0.13069778680801392,0.036897964775562286,0.027218617498874664,0.02767970971763134,0.021465107798576355,0.028283627703785896,0.020666826516389847,0.017943495884537697,0.017498988658189774,0.01657344028353691,0.015664303675293922,0.015282988548278809,0.02136060781776905,0.02253606729209423,0.023340798914432526,0.01960819773375988,0.016233906149864197,0.018885407596826553,0.020221231505274773,0.013108423911035061,0.015195276588201523,0.017118655145168304,0.017799442633986473,0.017155088484287262,0.01857968233525753,0.016649167984724045,0.015163003467023373,0.01336415484547615,0.012585818767547607,0.01198087353259325,0.011528676375746727,0.011158614419400692,0.010307753458619118,0.009807408787310123,0.00999804399907589,0.012272370047867298,0.01545623317360878,0.013921779580414295,0.015675557777285576,0.013946078717708588,0.013236165046691895,0.011569894850254059,0.01031589787453413,0.01145545020699501,0.01109741535037756,0.00872394535690546,0.009915770962834358,0.013675405643880367,0.010830499231815338,0.010170484893023968,0.00994078442454338,0.009534857235848904,0.011982712894678116,0.013423296622931957,0.011979423463344574,0.011536147445440292,0.010587774217128754,0.01038442924618721,0.009574570693075657,0.010249032638967037,0.012959934771060944,0.012010463513433933,0.011144280433654785,0.010519023053348064,0.009993378072977066,0.009190445765852928,0.008604130707681179,0.008073754608631134,0.008068961091339588,0.010194946080446243,0.009599980898201466,0.009095963090658188,0.009087199345231056,0.010888847522437572,0.01068933680653572,0.010213710367679596,0.011634972877800465,0.01017705537378788,0.009605665691196918,0.009017568081617355,0.008479774929583073,0.008218863978981972,0.007834622636437416,0.0076665026135742664,0.008100032806396484,0.01023520715534687,0.00988486222922802,0.010298460721969604,0.009290257468819618,0.008621064014732838,0.00843382254242897,0.00953250378370285,0.010427335277199745,0.009487268514931202,0.008162439800798893,0.009116514585912228,0.008204879239201546,0.008145395666360855,0.010032312013208866,0.009003891609609127,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17291     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17292     
=================================================================
Total params: 34,583
Trainable params: 34,583
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 17,291
Trainable params: 17,291
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 17,292
Trainable params: 17,292
Non-trainable params: 0
_________________________________________________________________
