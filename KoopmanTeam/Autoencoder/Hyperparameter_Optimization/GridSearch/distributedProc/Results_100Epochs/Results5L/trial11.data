2021-06-26
loss,0.3349134922027588,0.1896890103816986,0.08767744898796082,0.0579422228038311,0.07431870698928833,0.056131891906261444,0.049997806549072266,0.045342396944761276,0.037577614188194275,0.03464962914586067,0.033579785376787186,0.03208364546298981,0.031463753432035446,0.030634142458438873,0.029547061771154404,0.028551774099469185,0.0280448030680418,0.027262510731816292,0.026536736637353897,0.026194607838988304,0.02629736252129078,0.025708990171551704,0.037564657628536224,0.037076421082019806,0.026779472827911377,0.02534995786845684,0.02481767162680626,0.024040410295128822,0.02353336289525032,0.03773920610547066,0.035076290369033813,0.031546372920274734,0.02888430841267109,0.027007171884179115,0.027204427868127823,0.040420036762952805,0.03561290726065636,0.033056117594242096,0.031027553603053093,0.029525315389037132,0.02810719795525074,0.02611842006444931,0.03970121219754219,0.039758894592523575,0.03817679360508919,0.0350152924656868,0.03271569684147835,0.031308818608522415,0.029974091798067093,0.028842978179454803,0.027332201600074768,0.02483810856938362,0.024888845160603523,0.03187260031700134,0.01835188828408718,0.01778913103044033,0.017406916245818138,0.017331793904304504,0.017490046098828316,0.017379822209477425,0.01727624423801899,0.017234690487384796,0.01727447472512722,0.017120519652962685,0.01702686958014965,0.016985923051834106,0.01686875894665718,0.016884196549654007,0.016727901995182037,0.024996355175971985,0.022525615990161896,0.02752227522432804,0.02799290232360363,0.026491153985261917,0.026686565950512886,0.031060416251420975,0.027702324092388153,0.025950763374567032,0.02472132258117199,0.023674292489886284,0.027121132239699364,0.03357386961579323,0.029801582917571068,0.028078293427824974,0.026449058204889297,0.024688996374607086,0.02197209559381008,0.018594879657030106,0.015566528774797916,0.015689626336097717,0.015834497287869453,0.021028053015470505,0.026366963982582092,0.026989227160811424,0.024721156805753708,0.022193755954504013,0.024776916950941086,0.023916173726320267,0.028157152235507965,0.026781586930155754,
mse,0.04877479001879692,0.012644629925489426,0.0024970851372927427,0.0010451253037899733,0.0016798139549791813,0.000910572474822402,0.0007103830575942993,0.0006221606745384634,0.0004135137132834643,0.0003484720073174685,0.0003293116460554302,0.0002954349620267749,0.00028355029644444585,0.000268175033852458,0.0002482829731889069,0.00023064350534696132,0.00022399722365662456,0.00021059111168142408,0.00019831504323519766,0.00019469200924504548,0.0001998526422539726,0.00018900854047387838,0.0004605595313478261,0.00040915884892456234,0.000207521952688694,0.00018145896319765598,0.000172424188349396,0.0001620791881578043,0.00015556621656287462,0.00042519293492659926,0.00034221317037008703,0.0002767507976386696,0.00024006477906368673,0.00021586586080957204,0.00021465074678417295,0.000454488443210721,0.00034852680983021855,0.0003021033189725131,0.00026619722484610975,0.0002411060850135982,0.00021824461873620749,0.00019379693549126387,0.0004976976779289544,0.0004580009263008833,0.0004037360195070505,0.00034072453854605556,0.00030058532138355076,0.00027479202253744006,0.000252470257692039,0.00023450910521205515,0.00020846813276875764,0.00017817878688219935,0.00017954684153664857,0.00029767362866550684,9.80269251158461e-05,9.097906149690971e-05,8.620299195172265e-05,8.48853014758788e-05,8.631084347143769e-05,8.483165584038943e-05,8.388256537728012e-05,8.345935202669352e-05,8.385128603549674e-05,8.174889808287844e-05,8.164259634213522e-05,8.023854024941102e-05,7.924906094558537e-05,7.971463492140174e-05,8.15414750832133e-05,0.00018682343943510205,0.00014878681395202875,0.00021920818835496902,0.000217929293285124,0.00019695350783877075,0.000207742748898454,0.00026403553783893585,0.00020903789845760912,0.0001859816547948867,0.0001689770579105243,0.0001555666676722467,0.00022078979236539453,0.00031904742354527116,0.0002544999006204307,0.00022143656678963453,0.000194335647393018,0.00017015058256220073,0.00013668394240085036,0.00010387550719315186,7.104869291651994e-05,7.380206079687923e-05,7.368848309852183e-05,0.00013407018559519202,0.0001988762232940644,0.00021909600764047354,0.00017463471158407629,0.0001415792794432491,0.00017577264225110412,0.00016357703134417534,0.00022326856560539454,0.00019880058243870735,
mae,0.1482706516981125,0.08537711203098297,0.035910964012145996,0.023544425144791603,0.0291384719312191,0.02478126995265484,0.021757015958428383,0.01911196857690811,0.01552540622651577,0.014100808650255203,0.013891344889998436,0.013116145506501198,0.012731256894767284,0.012450815178453922,0.012109312228858471,0.011757688596844673,0.011393746361136436,0.01117840688675642,0.011209329590201378,0.011065194383263588,0.010993588715791702,0.010802695527672768,0.016124648973345757,0.015966514125466347,0.011221826076507568,0.010466142557561398,0.010100092738866806,0.009745977818965912,0.009642589837312698,0.015722408890724182,0.01456479448825121,0.012874739244580269,0.012024229392409325,0.011561345309019089,0.011553973890841007,0.016563504934310913,0.01408025249838829,0.013201961293816566,0.012852164916694164,0.012492870911955833,0.012058218941092491,0.010953054763376713,0.016250578686594963,0.01676228828728199,0.01643526367843151,0.015012621879577637,0.013977676630020142,0.013261338695883751,0.012731995433568954,0.012469207867980003,0.011947572231292725,0.01020942535251379,0.010416572913527489,0.01320679858326912,0.007737243548035622,0.007415372878313065,0.0073407115414738655,0.007302343379706144,0.0071799480356276035,0.007208563853055239,0.00712392944842577,0.0071057952009141445,0.007173026911914349,0.006966221146285534,0.007127687800675631,0.006948988419026136,0.007015444803982973,0.006982613354921341,0.0069649070501327515,0.010488679632544518,0.009343009442090988,0.01180559303611517,0.01162529457360506,0.010675069876015186,0.010940352454781532,0.012155839242041111,0.010622079484164715,0.010048708878457546,0.009840615093708038,0.009581576101481915,0.01162039302289486,0.014393721707165241,0.012785476632416248,0.012121655978262424,0.011609813198447227,0.010754014365375042,0.008950888179242611,0.007668570149689913,0.00653263321146369,0.006546624470502138,0.006680805701762438,0.008784063160419464,0.01102401502430439,0.011189347133040428,0.010607508011162281,0.009458375163376331,0.010717556811869144,0.010014884173870087,0.011674749664962292,0.010437561199069023,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8971      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8972      
=================================================================
Total params: 17,943
Trainable params: 17,943
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 8,971
Trainable params: 8,971
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 8,972
Trainable params: 8,972
Non-trainable params: 0
_________________________________________________________________
