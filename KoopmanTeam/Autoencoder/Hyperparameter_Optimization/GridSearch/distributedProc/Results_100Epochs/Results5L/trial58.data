2021-06-26
loss,2.2797744274139404,2.047706365585327,0.5048044323921204,0.23750217258930206,0.2069847136735916,0.15448439121246338,0.16482557356357574,0.13466545939445496,0.11137595027685165,0.12246540188789368,0.10656114667654037,0.09426018595695496,0.09060654789209366,0.10554380714893341,0.09718698263168335,0.0722818672657013,0.07735410332679749,0.06431858241558075,0.07307559996843338,0.06945128738880157,0.05514577403664589,0.08408939093351364,0.05943778157234192,0.0525156706571579,0.061554621905088425,0.056698232889175415,0.07504349946975708,0.05904661491513252,0.05176461860537529,0.050431955605745316,0.059077098965644836,0.049258217215538025,0.04353809356689453,0.05371778458356857,0.05169767886400223,0.0497419498860836,0.04935605078935623,0.04717792570590973,0.04547907039523125,0.03960918262600899,0.03909076750278473,0.042267829179763794,0.045300401747226715,0.04068033769726753,0.04388289898633957,0.037444546818733215,0.03885887190699577,0.033981285989284515,0.03347368538379669,0.034604258835315704,0.03797636181116104,0.0362924225628376,0.037301432341337204,0.03280416876077652,0.030639393255114555,0.032544512301683426,0.03523771092295647,0.03407815098762512,0.0308983214199543,0.030364634469151497,0.034452393651008606,0.030839258804917336,0.031582627445459366,0.03219744190573692,0.02655252441763878,0.029582343995571136,0.030139468610286713,0.030391106382012367,0.026694204658269882,0.027875054627656937,0.03279494866728783,0.028516270220279694,0.027151191607117653,0.026311630383133888,0.02693777345120907,0.027791889384388924,0.026001401245594025,0.02558986470103264,0.02703140303492546,0.026478536427021027,0.026177678257226944,0.024923870339989662,0.022027356550097466,0.021538345143198967,0.024646611884236336,0.02387756109237671,0.024394769221544266,0.025049975141882896,0.02441050484776497,0.024703627452254295,0.024938378483057022,0.021533573046326637,0.019200505688786507,0.025532877072691917,0.021889083087444305,0.020778197795152664,0.021745331585407257,0.022960543632507324,0.020730040967464447,0.019277043640613556,
mse,1.3213324546813965,1.096421480178833,0.08156933635473251,0.016153939068317413,0.01229699607938528,0.0066425371915102005,0.007684770040214062,0.005255143158137798,0.003493219381198287,0.004832370672374964,0.003466424299404025,0.002495046239346266,0.0024276606272906065,0.0031784125603735447,0.002697872230783105,0.001505925552919507,0.0016464203363284469,0.0011367968982085586,0.001484423759393394,0.0013558572391048074,0.0008591382065787911,0.002009257208555937,0.0010842416668310761,0.0007751549710519612,0.00104912044480443,0.00091720832278952,0.0015661269426345825,0.0009904202306643128,0.0007839812315069139,0.0007166073191910982,0.0009737559594213963,0.0006886973860673606,0.0005403108661994338,0.0008235164568759501,0.0007501593790948391,0.000684353697579354,0.000691762485075742,0.0006319946842268109,0.0005767300026491284,0.0004356516292318702,0.00043954551802016795,0.0005007713916711509,0.0005534635274671018,0.0004713052767328918,0.0005314789596013725,0.000382995669497177,0.0004133596958126873,0.0003213094314560294,0.00032458975329063833,0.00033099029678851366,0.00040724474820308387,0.00036209262907505035,0.0003858460404444486,0.0002967793552670628,0.00026252149837091565,0.000304192682961002,0.0003470861411187798,0.00031860280432738364,0.0002627239446155727,0.00027192983543500304,0.00032189246849156916,0.0002566771872807294,0.0002853060723282397,0.0002844059781637043,0.00020043218682985753,0.000252498866757378,0.00025816934066824615,0.00025220244424417615,0.00020038116781506687,0.00022366101620718837,0.00029578249086625874,0.00022440827160608023,0.00020448376017156988,0.0001922012452268973,0.0002035312500083819,0.00021437557006720454,0.0001861315977293998,0.00018710910808295012,0.00020355553715489805,0.00019510398851707578,0.0001934259053086862,0.00016975222388282418,0.00014346452371682972,0.00013615880743600428,0.0001695768878562376,0.0001592902117408812,0.0001706699695205316,0.00017763067444320768,0.0001672795624472201,0.00017168125486932695,0.0001723741297610104,0.00013232081255409867,0.00010910889250226319,0.0001843745994847268,0.00014045386342331767,0.00012378141400404274,0.0001339455775450915,0.00014562248543370515,0.00012048070493619889,0.00010738810669863597,
mae,0.7318835258483887,0.6048290133476257,0.21316631138324738,0.10056370496749878,0.08953939378261566,0.0657787024974823,0.06924302875995636,0.05828375369310379,0.04738941788673401,0.05275749787688255,0.04656808823347092,0.04013828933238983,0.038746725767850876,0.045777592808008194,0.03975634649395943,0.030778981745243073,0.03259677439928055,0.027517665177583694,0.03159656375646591,0.028670504689216614,0.02351066656410694,0.03625470772385597,0.02487635612487793,0.02217782475054264,0.026050973683595657,0.02448844164609909,0.03223847225308418,0.025591706857085228,0.02200380712747574,0.02147532068192959,0.02495630271732807,0.020536934956908226,0.018364129588007927,0.023086784407496452,0.021699493750929832,0.020974524319171906,0.021809805184602737,0.020498063415288925,0.01903606578707695,0.016688009724020958,0.016630634665489197,0.017907408997416496,0.0197380930185318,0.017254335805773735,0.018244357779622078,0.015955118462443352,0.016608091071248055,0.01459450088441372,0.01426312793046236,0.014630893245339394,0.01638227514922619,0.015272977761924267,0.01612311415374279,0.01372157409787178,0.012834099121391773,0.013877784833312035,0.01484632957726717,0.014441007748246193,0.012968407943844795,0.012992781586945057,0.015186382457613945,0.01320727914571762,0.01357160322368145,0.01401169691234827,0.011156432330608368,0.01245930790901184,0.01296885497868061,0.01297407504171133,0.011188246309757233,0.011766149662435055,0.01414390467107296,0.012235964648425579,0.011619307100772858,0.011144504882395267,0.011463334783911705,0.011966210789978504,0.010891970247030258,0.010839900001883507,0.011351283639669418,0.0113645875826478,0.010786360129714012,0.010411563329398632,0.009219355881214142,0.009105860255658627,0.01037682220339775,0.00988198071718216,0.010266879573464394,0.010666122660040855,0.010438220575451851,0.01058921217918396,0.010659974999725819,0.00903845950961113,0.008159712888300419,0.010876936838030815,0.009392103180289268,0.00877238530665636,0.009247135370969772,0.009378595277667046,0.008284855633974075,0.008174804970622063,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 78787     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 78788     
=================================================================
Total params: 157,575
Trainable params: 157,575
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 78,787
Trainable params: 78,787
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 78,788
Trainable params: 78,788
Non-trainable params: 0
_________________________________________________________________
