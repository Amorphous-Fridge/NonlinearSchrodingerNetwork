2021-06-26
loss,0.4156950116157532,0.1313277781009674,0.08922091126441956,0.08174391835927963,0.08747784793376923,0.06987834721803665,0.05819935351610184,0.05035584419965744,0.048774708062410355,0.045136742293834686,0.04284795746207237,0.05672982335090637,0.05419272556900978,0.06496338546276093,0.061716947704553604,0.058595042675733566,0.04851784184575081,0.04696027189493179,0.03758228197693825,0.035344596952199936,0.05264270305633545,0.049489960074424744,0.05297042056918144,0.04842539131641388,0.042973171919584274,0.04305564984679222,0.04332594573497772,0.03891133889555931,0.039357155561447144,0.02373436465859413,0.024117983877658844,0.028691887855529785,0.024492338299751282,0.04426763579249382,0.03660179674625397,0.03090537153184414,0.03510098531842232,0.032567646354436874,0.033015623688697815,0.035140544176101685,0.03356678783893585,0.038174837827682495,0.0398896224796772,0.03709321841597557,0.033204205334186554,0.02921084314584732,0.019748592749238014,0.019176578149199486,0.02945895493030548,0.02630653791129589,0.03121805191040039,0.028129661455750465,0.029901331290602684,0.02901638299226761,0.02614404261112213,0.019917698577046394,0.02906622737646103,0.03667476400732994,0.03405267372727394,0.031685832887887955,0.026945268735289574,0.024969056248664856,0.02329684980213642,0.02161104418337345,0.02896529622375965,0.02773379348218441,0.033002182841300964,0.028038019314408302,0.02590450458228588,0.029201680794358253,0.026585573330521584,0.026757890358567238,0.029012387618422508,0.027571897953748703,0.018138274550437927,0.02481287159025669,0.024167237803339958,0.026371929794549942,0.028403522446751595,0.02603326365351677,0.022732757031917572,0.021564560011029243,0.02523595094680786,0.024897653609514236,0.023888619616627693,0.024258239194750786,0.023178134113550186,0.02206430956721306,0.01731538213789463,0.02228754200041294,0.026474816724658012,0.024791641160845757,0.021974043920636177,0.01971491612493992,0.017620688304305077,0.01988389901816845,0.021578406915068626,0.023377059027552605,0.02075357735157013,0.025817936286330223,
mse,0.07351084053516388,0.005662217736244202,0.002443524543195963,0.0020291160326451063,0.0023930517490953207,0.0014944642316550016,0.0009914827533066273,0.0007398283341899514,0.0007038071635179222,0.0005894860369153321,0.0005306360544636846,0.001062203897163272,0.0008931092452257872,0.0011946638114750385,0.0010949489660561085,0.0009816576493903995,0.0006752710323780775,0.0006296341889537871,0.00041958768269978464,0.0003857629490084946,0.0007940086652524769,0.0006899322033859789,0.0007638877141289413,0.0006618626648560166,0.0005285989609546959,0.0005250477115623653,0.0005236017168499529,0.00042918522376567125,0.0004466527025215328,0.00016336209955625236,0.0001743502216413617,0.00025167473359033465,0.00017511265468783677,0.0005505093140527606,0.0003862091398332268,0.00028693300555460155,0.0003468692011665553,0.00030699814669787884,0.0003105612413492054,0.0003401065187063068,0.00032746445504017174,0.00042277731699869037,0.00044038714258931577,0.0003774950164370239,0.0003055748820770532,0.00024380654213018715,0.00011745101073756814,0.000109160813735798,0.0002600276784505695,0.00019694140064530075,0.00027822903939522803,0.00022387456556316465,0.0002501342969480902,0.00023507345758844167,0.00020035143825225532,0.0001179805985884741,0.0002595795376691967,0.000378246302716434,0.0003239765646867454,0.0002759330382104963,0.00020813720766454935,0.0001764897460816428,0.00015387301391456276,0.00013888382818549871,0.00024080724688246846,0.00021753308828920126,0.00030063537997193635,0.0002234014100395143,0.0001952247112058103,0.0002471214102115482,0.00019740062998607755,0.00021096187992952764,0.00022991200967226177,0.00021194135479163378,0.00010275041859131306,0.00017757520254235715,0.0001657633692957461,0.00019538801279850304,0.00022390420781448483,0.00018847512546926737,0.00014919783279765397,0.0001334663393208757,0.00018001241551246494,0.00017421205120626837,0.00016223434067796916,0.0001645527227083221,0.00015836936654523015,0.00013656227383762598,8.993051596917212e-05,0.00013922098150942475,0.00019531170255504549,0.0001736942504066974,0.00013734583626501262,0.00011110957711935043,9.190473065245897e-05,0.00011492423072922975,0.00013328978093340993,0.0001520530931884423,0.00012115517893107608,0.00018792564515024424,
mae,0.17742149531841278,0.05611603707075119,0.03821035847067833,0.0351082868874073,0.03733633831143379,0.029735691845417023,0.024851690977811813,0.021347472444176674,0.02076706476509571,0.019405879080295563,0.01834840141236782,0.024265119805932045,0.023503713309764862,0.028389323502779007,0.026902878656983376,0.02548876963555813,0.020816059783101082,0.019687574356794357,0.0160830058157444,0.015242013148963451,0.0229413490742445,0.020874349400401115,0.023029861971735954,0.02098623663187027,0.018410565331578255,0.0185378510504961,0.01823592558503151,0.016853854060173035,0.0168017465621233,0.010081332176923752,0.010380489751696587,0.012216719798743725,0.010559499263763428,0.019225401803851128,0.01574861817061901,0.013239940628409386,0.0151516767218709,0.014094901271164417,0.01401191484183073,0.015495997853577137,0.014605265110731125,0.016029605641961098,0.017202934250235558,0.016481582075357437,0.014291508123278618,0.012677797116339207,0.00836082361638546,0.008132467977702618,0.01271508913487196,0.011099448427557945,0.013487943448126316,0.011848066002130508,0.012941312976181507,0.012731123715639114,0.011480236425995827,0.008566134609282017,0.012515964917838573,0.016329605132341385,0.01513909175992012,0.013736584223806858,0.011581837199628353,0.010739070363342762,0.010104412212967873,0.009250747039914131,0.012566963210701942,0.011820375919342041,0.014369528740644455,0.012088187038898468,0.011590671725571156,0.012483843602240086,0.011280207894742489,0.011151036247611046,0.012567868456244469,0.012210278771817684,0.0077625154517591,0.010478303767740726,0.010020132176578045,0.011134698055684566,0.012626495212316513,0.011074342764914036,0.009465023875236511,0.00902603194117546,0.010859494097530842,0.01071341522037983,0.010399741120636463,0.010142416693270206,0.009953894652426243,0.009300488978624344,0.0073547158390283585,0.009237675927579403,0.011374375782907009,0.010912364348769188,0.009303200989961624,0.008129788562655449,0.007478979881852865,0.0084735918790102,0.009106711484491825,0.010263612493872643,0.008581895381212234,0.011014832183718681,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34219     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34220     
=================================================================
Total params: 68,439
Trainable params: 68,439
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 34,219
Trainable params: 34,219
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 34,220
Trainable params: 34,220
Non-trainable params: 0
_________________________________________________________________
