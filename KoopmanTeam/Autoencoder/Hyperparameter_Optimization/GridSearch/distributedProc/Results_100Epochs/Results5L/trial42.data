2021-06-26
loss,0.5615280270576477,0.25111544132232666,0.18123167753219604,0.14406391978263855,0.10242161154747009,0.11456633359193802,0.08624975383281708,0.11997995525598526,0.06237257644534111,0.07788874953985214,0.07849133014678955,0.06992207467556,0.07799876481294632,0.07470056414604187,0.06329204887151718,0.05133918300271034,0.04774904623627663,0.06289085000753403,0.07301174104213715,0.07248885184526443,0.06291402131319046,0.0552784763276577,0.04941718280315399,0.058431025594472885,0.058795999735593796,0.05596528202295303,0.05091102421283722,0.04286917299032211,0.033552102744579315,0.03152845799922943,0.04640386998653412,0.04367145150899887,0.04269067198038101,0.03975240886211395,0.037302181124687195,0.03283165395259857,0.0462002232670784,0.04586244001984596,0.04648459330201149,0.039228007197380066,0.03968363627791405,0.03767455741763115,0.03461584448814392,0.029803063720464706,0.028219496831297874,0.046320151537656784,0.043174151331186295,0.03897443786263466,0.03307196497917175,0.03208545595407486,0.0364055261015892,0.037906061857938766,0.03279490768909454,0.039536941796541214,0.036820001900196075,0.03204143047332764,0.031214481219649315,0.03671582415699959,0.031969886273145676,0.028567172586917877,0.031395863741636276,0.028330545872449875,0.03334931284189224,0.03525621443986893,0.03199709951877594,0.03071211837232113,0.027709994465112686,0.02955191396176815,0.027596700936555862,0.026730883866548538,0.034842148423194885,0.032895058393478394,0.029102016240358353,0.023467013612389565,0.026879457756876945,0.030818549916148186,0.028706710785627365,0.02556673064827919,0.021794982254505157,0.030169453471899033,0.030471114441752434,0.03240082785487175,0.028896091505885124,0.028828706592321396,0.02173302136361599,0.018226267769932747,0.02746458351612091,0.025441035628318787,0.02192630060017109,0.021700458601117134,0.03125888481736183,0.030854376032948494,0.02829870767891407,0.023886844515800476,0.022230422124266624,0.030526738613843918,0.025673622265458107,0.024202611297369003,0.025846250355243683,0.028219902887940407,
mse,0.1428995281457901,0.02042260393500328,0.010309956036508083,0.006895720958709717,0.0030483233276754618,0.003921761177480221,0.0022027113009244204,0.004148651380091906,0.0011860738741233945,0.0018659181660041213,0.0017128151375800371,0.0013690313789993525,0.0017702359473332763,0.0016698434483259916,0.0011422813404351473,0.0008198440773412585,0.0006589530385099351,0.0013274853117763996,0.0014859650982543826,0.001452662399969995,0.001113510807044804,0.0008588675991632044,0.0006853408995084465,0.0009392619831487536,0.0009553358540870249,0.0008652866818010807,0.0007182132685557008,0.0005128345801495016,0.0003223332460038364,0.00028352762456052005,0.0006306293653324246,0.000529573648236692,0.0005001479876227677,0.00043221181840635836,0.0004055301542393863,0.00032531877513974905,0.0005989322089590132,0.0005826384876854718,0.0005989461787976325,0.00043473069672472775,0.0004445251543074846,0.0003919365117326379,0.0003302496625110507,0.0002564642927609384,0.00023044718545861542,0.0006011914229020476,0.0005091055645607412,0.0004120610246900469,0.0003029322833754122,0.0002994492824655026,0.00037335933302529156,0.00039461086271330714,0.000299248902592808,0.0004263725131750107,0.0003753377532120794,0.00029366009403020144,0.00027591336402110755,0.0003681432572193444,0.0002803144452627748,0.00024361495161429048,0.0002712062851060182,0.00022008856467437,0.0003244894614908844,0.00033729930873960257,0.00028723690775223076,0.00026264676125720143,0.00021768122678622603,0.00023943197447806597,0.0002110225905198604,0.00020384317031130195,0.00033728574635460973,0.0002991902001667768,0.0002351667790208012,0.00016036532178986818,0.00020755130390170962,0.00026616480317898095,0.0002342181105632335,0.00018611318955663592,0.00013990055595058948,0.0002560204593464732,0.0002632169926073402,0.00028657118673436344,0.00022976334730628878,0.00022912921849638224,0.00013978518836665899,9.953892003977671e-05,0.00020950735779479146,0.00018022407311946154,0.00014017564535606652,0.00013503128138836473,0.00027221356867812574,0.0002624772023409605,0.00021522369934245944,0.00016643731214571744,0.00014489502063952386,0.00024819737882353365,0.00018441084830556065,0.00016646072617731988,0.00018855760572478175,0.00021767175348941237,
mae,0.23976148664951324,0.10475373268127441,0.07731475681066513,0.060328539460897446,0.04306943714618683,0.04904459789395332,0.03695705533027649,0.05082850158214569,0.026689322665333748,0.03310288116335869,0.03368478640913963,0.030815694481134415,0.033685650676488876,0.03256906569004059,0.02728264592587948,0.0220018457621336,0.020468540489673615,0.027218841016292572,0.030855510383844376,0.03197943791747093,0.028594939038157463,0.023997073993086815,0.021245701238512993,0.02486383728682995,0.02446618489921093,0.02294122613966465,0.020073067396879196,0.018478011712431908,0.014560211449861526,0.013601910322904587,0.019659146666526794,0.018392879515886307,0.01883472502231598,0.018140465021133423,0.01627054437994957,0.014446297660470009,0.0197751522064209,0.019534889608621597,0.02025797590613365,0.016929177567362785,0.01699920743703842,0.017035899683833122,0.015632495284080505,0.012705288827419281,0.012015406042337418,0.020394539460539818,0.018699921667575836,0.01581256091594696,0.013950071297585964,0.01394334714859724,0.015666455030441284,0.016319114714860916,0.01416989229619503,0.017408253625035286,0.01730162836611271,0.013917690142989159,0.01314531359821558,0.0161279309540987,0.014196187257766724,0.01222196128219366,0.01393822580575943,0.012366188690066338,0.014176551252603531,0.014496661722660065,0.013197734020650387,0.01324458234012127,0.011719290167093277,0.01278405450284481,0.012021954171359539,0.011485244147479534,0.014751180075109005,0.013657455332577229,0.011994719505310059,0.01017840951681137,0.011698348447680473,0.013060740195214748,0.012408329173922539,0.011312907561659813,0.009302645921707153,0.012800872325897217,0.013049950823187828,0.014550195075571537,0.012632935307919979,0.012418946251273155,0.009300264529883862,0.007696513552218676,0.011809995397925377,0.011182143352925777,0.00928812101483345,0.009185310453176498,0.013218339532613754,0.012754066847264767,0.011784430593252182,0.010465172119438648,0.009516225196421146,0.01392974890768528,0.011357617564499378,0.010332662612199783,0.01091704610735178,0.012682531960308552,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 36435     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 36436     
=================================================================
Total params: 72,871
Trainable params: 72,871
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 36,435
Trainable params: 36,435
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 36,436
Trainable params: 36,436
Non-trainable params: 0
_________________________________________________________________
