2021-06-26
loss,0.39626559615135193,0.13708332180976868,0.12413232773542404,0.10453030467033386,0.0996256172657013,0.07927829772233963,0.07877907902002335,0.07134464383125305,0.06123504787683487,0.07830137014389038,0.07206553965806961,0.05365360900759697,0.07121268659830093,0.05968935042619705,0.054812632501125336,0.059110451489686966,0.05026281997561455,0.045891061425209045,0.0400005541741848,0.04278750345110893,0.055499471724033356,0.043394289910793304,0.043265171349048615,0.050824861973524094,0.04459589347243309,0.03682158142328262,0.04077748954296112,0.036093614995479584,0.04554680362343788,0.04075392335653305,0.042738720774650574,0.036146435886621475,0.03299996256828308,0.03586532920598984,0.03342438116669655,0.030129287391901016,0.03349080681800842,0.03015313856303692,0.029648082330822945,0.02793862111866474,0.025097863748669624,0.032719992101192474,0.032177459448575974,0.03374540060758591,0.031498413532972336,0.028675828129053116,0.025475911796092987,0.028223326429724693,0.030072592198848724,0.026879457756876945,0.02452581375837326,0.024253452196717262,0.024975242093205452,0.0230391938239336,0.021942641586065292,0.02228601649403572,0.022122425958514214,0.021600820124149323,0.027299154549837112,0.027726076543331146,0.024197610095143318,0.02227211184799671,0.02092895098030567,0.02067815326154232,0.020452287048101425,0.025693882256746292,0.026507776230573654,0.022966615855693817,0.021180884912610054,0.01923295110464096,0.020816093310713768,0.024691099300980568,0.02484205737709999,0.022842619568109512,0.02061241678893566,0.01929544284939766,0.019013982266187668,0.020436136052012444,0.020828865468502045,0.021088898181915283,0.023743662983179092,0.020955823361873627,0.019641965627670288,0.018282854929566383,0.02049877494573593,0.022223785519599915,0.022108420729637146,0.02002067118883133,0.018279314041137695,0.019367968663573265,0.017597489058971405,0.019866229966282845,0.01919163390994072,0.019081516191363335,0.019324403256177902,0.019332125782966614,0.020019661635160446,0.019160296767950058,0.01786666549742222,0.01803344488143921,
mse,0.08820781856775284,0.00582614541053772,0.004441882483661175,0.003146443283185363,0.00290549430064857,0.0018206435488536954,0.0017558000981807709,0.001473581651225686,0.0010459702461957932,0.0018560932949185371,0.0014893912011757493,0.0008062903652898967,0.0014733083080500364,0.0009973675478249788,0.0008668232476338744,0.0009654871537350118,0.0006922156317159534,0.0005885496502742171,0.0004592861223500222,0.000521789537742734,0.0008540449198335409,0.0005221973406150937,0.0005383313982747495,0.0007250449270941317,0.0005551763460971415,0.00037673910264857113,0.0004629756440408528,0.0003661602095235139,0.0005952483625151217,0.00047648235340602696,0.0004917606129311025,0.0003604256780818105,0.0003057038120459765,0.00037005211925134063,0.0003048698417842388,0.00025639566592872143,0.00032450430444441736,0.0002596430422272533,0.0002428887237329036,0.00022003924823366106,0.0001849527907324955,0.0003044441982638091,0.00029772092238999903,0.000317649741191417,0.0002739244082476944,0.0002245531795779243,0.00018423837900627404,0.00022757753322366625,0.00024841492995619774,0.00019915381562896073,0.00016968139971140772,0.00016826449427753687,0.0001703270390862599,0.00014799901691731066,0.0001349175872746855,0.00013911121641285717,0.00013710254279430956,0.00013606398715637624,0.0002092822833219543,0.0002119881974067539,0.00016413077537436038,0.0001375114661641419,0.00012419820996001363,0.00012734871415887028,0.00012300192611292005,0.0001865510130301118,0.00019108124251943082,0.0001477751648053527,0.00012528977822512388,0.00010491092689335346,0.00013145871344022453,0.00017055428179446608,0.00017130389460362494,0.0001459139457438141,0.00011876069038407877,0.00010595060302875936,0.0001062065566657111,0.00012343398702796549,0.00012155200965935364,0.0001308540377067402,0.00015548040391877294,0.0001241914724232629,0.00010986131383106112,9.927140490617603e-05,0.00012275512563064694,0.00013815720740240067,0.00013676920207217336,0.00011104736768174917,9.453138045500964e-05,0.00010339140862924978,8.916622755350545e-05,0.00011206128692720085,0.00010698269034037367,0.00010448438115417957,0.00010867785022128373,0.00010424260835861787,0.00011246379290241748,0.00010229840700048953,9.10472881514579e-05,9.494239202467725e-05,
mae,0.1632332056760788,0.055684689432382584,0.05167549103498459,0.04451602324843407,0.041453756392002106,0.03364286571741104,0.03336773067712784,0.030190516263246536,0.025771763175725937,0.032919496297836304,0.030213892459869385,0.0221752617508173,0.030364947393536568,0.025196904316544533,0.023978622630238533,0.024878622964024544,0.02119874767959118,0.019378013908863068,0.016951050609350204,0.018132247030735016,0.023802481591701508,0.018481215462088585,0.018262751400470734,0.021612195298075676,0.019127264618873596,0.01589564047753811,0.016726937144994736,0.015666790306568146,0.019227979704737663,0.0172861497849226,0.01782018505036831,0.015090656466782093,0.014099094085395336,0.015118596144020557,0.014586174860596657,0.012866029515862465,0.014150711707770824,0.01288521382957697,0.012340951710939407,0.011605915613472462,0.010434916242957115,0.013206823728978634,0.013921706937253475,0.014304294250905514,0.013570609502494335,0.012139544822275639,0.01067641843110323,0.01210008841007948,0.012895656749606133,0.011432107537984848,0.010423250496387482,0.010355941019952297,0.01111152395606041,0.010200892575085163,0.009511197917163372,0.009696416556835175,0.009542057290673256,0.009167028591036797,0.011600229889154434,0.011983102187514305,0.01032954454421997,0.009196906350553036,0.008720975369215012,0.008718926459550858,0.00870671309530735,0.010815363377332687,0.01120691653341055,0.009326301515102386,0.008488079532980919,0.00796982366591692,0.00875792745500803,0.010586870834231377,0.010610556229948997,0.009625009261071682,0.008527832105755806,0.007908879779279232,0.008043975569307804,0.008707837201654911,0.00872354581952095,0.008986311964690685,0.009999272413551807,0.008947585709393024,0.008243471384048462,0.007724817842245102,0.008511295542120934,0.009447293356060982,0.00951319094747305,0.008517879992723465,0.0076640285551548,0.007999521680176258,0.007490009535104036,0.008279390633106232,0.00798663031309843,0.007975430227816105,0.008142700418829918,0.008142422884702682,0.008373982273042202,0.008138990961015224,0.007436768617480993,0.0076435343362390995,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 37539     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 37540     
=================================================================
Total params: 75,079
Trainable params: 75,079
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 37,539
Trainable params: 37,539
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 37,540
Trainable params: 37,540
Non-trainable params: 0
_________________________________________________________________
