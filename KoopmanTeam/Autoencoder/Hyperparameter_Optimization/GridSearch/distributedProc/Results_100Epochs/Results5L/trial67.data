2021-06-26
loss,0.3969050943851471,0.12696126103401184,0.09214457869529724,0.08342086523771286,0.0795389860868454,0.08025413751602173,0.061129745095968246,0.07691217213869095,0.06207200139760971,0.05505933240056038,0.04399724304676056,0.05250060558319092,0.04438389837741852,0.034068264067173004,0.03429953753948212,0.03952248394489288,0.042747825384140015,0.04453282803297043,0.03835245594382286,0.04415275156497955,0.04448103532195091,0.03843830153346062,0.03720027580857277,0.033299364149570465,0.03091535158455372,0.03574023395776749,0.03558948263525963,0.0335141196846962,0.029595468193292618,0.03003750555217266,0.02836320921778679,0.026720236986875534,0.02646549418568611,0.023981528356671333,0.02235223539173603,0.023104282096028328,0.027188001200556755,0.02949840947985649,0.02256869710981846,0.01950591430068016,0.018842613324522972,0.017874129116535187,0.01775820553302765,0.017487579956650734,0.01717606745660305,0.0169609934091568,0.016819965094327927,0.016733797267079353,0.016756806522607803,0.016450732946395874,0.016267187893390656,0.01624092273414135,0.016119029372930527,0.016125667840242386,0.01595335826277733,0.015901710838079453,0.01585528813302517,0.015576974488794804,0.015646694228053093,0.015551935881376266,0.015420005656778812,0.015336377546191216,0.015247157774865627,0.015090269967913628,0.015132014639675617,0.01496975775808096,0.014857632108032703,0.014804813079535961,0.014763695187866688,0.014716164208948612,0.01456438284367323,0.014496374875307083,0.014452037401497364,0.014339098706841469,0.014245866797864437,0.014100125059485435,0.014132475480437279,0.013989592902362347,0.01394601445645094,0.013885258696973324,0.01388167217373848,0.013779766857624054,0.013586708344519138,0.013703614473342896,0.013551904819905758,0.01346144825220108,0.01350541040301323,0.013284604996442795,0.013319083489477634,0.013142832554876804,0.01324921939522028,0.013034798204898834,0.0131381805986166,0.012983331456780434,0.01293396670371294,0.012834306806325912,0.012704108841717243,0.012749284505844116,0.012789790518581867,0.01264263316988945,
mse,0.08167467266321182,0.004922364838421345,0.0024787194561213255,0.0020133918151259422,0.0018088665092363954,0.0020814677700400352,0.0011168394703418016,0.0016798436408862472,0.0011036621872335672,0.0008559864945709705,0.0005597631097771227,0.0008055031066760421,0.0006078919977881014,0.0003379633999429643,0.00034248558222316206,0.0004624103894457221,0.0005164869944564998,0.0005677001317963004,0.00041382398921996355,0.0005783286178484559,0.0005539045087061822,0.0004164454585406929,0.0003884146281052381,0.00032571254996582866,0.00028031686088070273,0.0003927258658222854,0.0003584598016459495,0.0003153676516376436,0.00025253271451219916,0.0002570615033619106,0.00022715704108122736,0.0002019951498368755,0.00019623886328190565,0.0001668490149313584,0.00014514510985463858,0.0001584264828125015,0.00021323356486391276,0.0002521792193874717,0.00015692008309997618,0.00011280841863481328,0.00010151735477847978,9.138386667473242e-05,8.994290692498907e-05,8.74620964168571e-05,8.362859807675704e-05,8.142690057866275e-05,8.078182145254686e-05,7.984731200849637e-05,7.861063932068646e-05,7.64134747441858e-05,7.538567297160625e-05,7.481306238332763e-05,7.350482337642461e-05,7.302346784854308e-05,7.234697113744915e-05,7.240798004204407e-05,7.055735477479175e-05,6.833457155153155e-05,6.901217420818284e-05,6.826738535892218e-05,6.814854714320973e-05,6.63606624584645e-05,6.53000533930026e-05,6.406597094610333e-05,6.495164416264743e-05,6.265039701247588e-05,6.26335313427262e-05,6.150300760054961e-05,6.159119220683351e-05,6.200989446369931e-05,6.035125989001244e-05,5.9549791330937296e-05,5.8579156757332385e-05,5.791728835902177e-05,5.7000030210474506e-05,5.628858707495965e-05,5.6277724070241675e-05,5.473543569678441e-05,5.469760435516946e-05,5.4185991757549345e-05,5.522413266589865e-05,5.324497033143416e-05,5.24475472047925e-05,5.245747888693586e-05,5.1980077842017636e-05,5.1806367991957814e-05,5.11566067871172e-05,4.9961861805059016e-05,4.999250086257234e-05,4.939831705996767e-05,4.924212407786399e-05,4.798511145054363e-05,4.903225271846168e-05,4.755958798341453e-05,4.682029248215258e-05,4.621370317181572e-05,4.684653686126694e-05,4.637317397282459e-05,4.568995427689515e-05,4.535968037089333e-05,
mae,0.1714095175266266,0.05418490245938301,0.038984958082437515,0.03535688295960426,0.03392411395907402,0.03465166687965393,0.02614276483654976,0.033123403787612915,0.026573725044727325,0.023588480427861214,0.018560603260993958,0.022140629589557648,0.01891961134970188,0.014543097466230392,0.014573416672647,0.016742052510380745,0.018146807327866554,0.018924523144960403,0.016394127160310745,0.019047705456614494,0.019165752455592155,0.0163356214761734,0.015872875228524208,0.014204799197614193,0.013232951983809471,0.015557093545794487,0.01517848577350378,0.014316149987280369,0.012509610503911972,0.012815610505640507,0.01217182632535696,0.011332236230373383,0.011126888915896416,0.01014640647917986,0.009517082944512367,0.00975020881742239,0.011517959646880627,0.012789567932486534,0.009763961657881737,0.008320341818034649,0.00817656610161066,0.0077132852748036385,0.0077431960962712765,0.007531553041189909,0.0074015771970152855,0.007301878184080124,0.0072082350961863995,0.007182767614722252,0.007156559266149998,0.006984088569879532,0.006931991782039404,0.006979153025895357,0.006855731830000877,0.006878891959786415,0.006797237321734428,0.006768005434423685,0.006797146052122116,0.00662597082555294,0.006696355529129505,0.00667214673012495,0.006600612308830023,0.006525158416479826,0.006490933708846569,0.0063891177996993065,0.006498375441879034,0.0063757263123989105,0.006334326229989529,0.006341912783682346,0.006293844431638718,0.006265840958803892,0.006181466393172741,0.0061724307015538216,0.00617096247151494,0.006077879574149847,0.006039471831172705,0.005995447747409344,0.0060027833096683025,0.005903975572437048,0.005940841510891914,0.005911190528422594,0.0058921766467392445,0.005866575054824352,0.005764937028288841,0.005813431926071644,0.00578234251588583,0.00573750538751483,0.005749461706727743,0.00560641847550869,0.005693557672202587,0.005590313579887152,0.0056196553632617,0.005505895707756281,0.0055841743014752865,0.005517789628356695,0.005468208342790604,0.005460417829453945,0.0054076798260211945,0.0054253083653748035,0.00544327637180686,0.005370404105633497,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34515     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34516     
=================================================================
Total params: 69,031
Trainable params: 69,031
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 34,515
Trainable params: 34,515
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 34,516
Trainable params: 34,516
Non-trainable params: 0
_________________________________________________________________
