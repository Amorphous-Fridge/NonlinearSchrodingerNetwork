2021-06-26
loss,1.0478146076202393,0.2667486369609833,0.22848168015480042,0.1754988729953766,0.1545366644859314,0.15467558801174164,0.1216793954372406,0.11317678540945053,0.09950433671474457,0.11304270476102829,0.08249972015619278,0.0885186567902565,0.07689520716667175,0.06853873282670975,0.06325551867485046,0.06851851940155029,0.0725305825471878,0.06011322885751724,0.05221445858478546,0.0670689269900322,0.04991307109594345,0.05352301523089409,0.04538743197917938,0.04552251473069191,0.052740637212991714,0.04488924518227577,0.0378604494035244,0.029552357271313667,0.036052193492650986,0.043243683874607086,0.04085436463356018,0.03944601118564606,0.039042383432388306,0.03524409234523773,0.02979528345167637,0.031198367476463318,0.02883213199675083,0.03258240595459938,0.036351755261421204,0.031961869448423386,0.02668699435889721,0.029461555182933807,0.0324326790869236,0.032343797385692596,0.027393538504838943,0.026057684794068336,0.028206035494804382,0.02922966331243515,0.02780480682849884,0.026647720485925674,0.026723379269242287,0.025024378672242165,0.02638203464448452,0.02832026034593582,0.024451687932014465,0.022490568459033966,0.022833440452814102,0.02697964757680893,0.02455916628241539,0.022999119013547897,0.022418616339564323,0.023225774988532066,0.023598238825798035,0.026173168793320656,0.024604327976703644,0.022685153409838676,0.02440524660050869,0.02208814211189747,0.02420610375702381,0.022569119930267334,0.022067325189709663,0.021245311945676804,0.021950488910079002,0.02158023603260517,0.017891617491841316,0.020193876698613167,0.02518542855978012,0.022779302671551704,0.01902177184820175,0.020429721102118492,0.020945722237229347,0.021475205197930336,0.02016318403184414,0.02097107656300068,0.021197611466050148,0.019693026319146156,0.020730741322040558,0.020132357254624367,0.02005005069077015,0.021626412868499756,0.020118946209549904,0.01734260283410549,0.01974671334028244,0.021060235798358917,0.018119344487786293,0.019978133961558342,0.017209718003869057,0.019462313503026962,0.021417243406176567,0.01989656873047352,
mse,0.5100269913673401,0.020868053659796715,0.016518324613571167,0.00886700488626957,0.006781679578125477,0.007096716668456793,0.00422384450212121,0.0037038258742541075,0.002822781912982464,0.003809856716543436,0.0019641995895653963,0.00227702921256423,0.001727160532027483,0.0013789469376206398,0.0011681189062073827,0.0013747690245509148,0.001535597606562078,0.001083553652279079,0.0008164254832081497,0.0012939986772835255,0.0007323428289964795,0.0008558838162571192,0.0005732182180508971,0.0005832710885442793,0.0007819565944373608,0.0005507763125933707,0.00040736558730714023,0.00025471209664829075,0.00039277534233406186,0.000526303076185286,0.0004591926990542561,0.00044060088112019,0.0004356284043751657,0.00033786677522584796,0.0002564253518357873,0.0002895510697271675,0.0002431494795018807,0.0003026928461622447,0.00037405185867100954,0.0002818564826156944,0.00020627975754905492,0.0002480127150192857,0.0002965155290439725,0.00029457907658070326,0.0002130343928001821,0.0001965273404493928,0.00022560104844160378,0.00024027275503613055,0.00021299783838912845,0.0002036090736510232,0.0002043482818407938,0.00018012696818914264,0.00019998229981865734,0.0002194008557125926,0.0001673096267040819,0.00014192088565323502,0.00015182519564405084,0.00020313385175541043,0.00016928698460105807,0.00015058793360367417,0.00014672608813270926,0.00015030043141450733,0.0001597442605998367,0.00019253413483966142,0.00017835407925304025,0.0001475839817430824,0.00017020553059410304,0.0001403131172992289,0.00016926262469496578,0.00014358524640556425,0.0001391176483593881,0.0001325967168668285,0.00013710296479985118,0.00013234313519205898,9.506325295660645e-05,0.00012073862308170646,0.00017468296573497355,0.00014564202865585685,0.00010692570504033938,0.0001187139714602381,0.00012425013119354844,0.0001285071048187092,0.00012003270239802077,0.00012530780804809183,0.0001273621164727956,0.00010937007027678192,0.000124298851005733,0.00011556855315575376,0.00011513949721120298,0.00013050901179667562,0.00011329235712764785,8.808458369458094e-05,0.00011367660772521049,0.00012512462853919715,9.66171282925643e-05,0.00011444064148236066,8.853979670675471e-05,0.00010845774522749707,0.0001301901793340221,0.00011305786028970033,
mae,0.4466608166694641,0.11274115741252899,0.09733212739229202,0.07460656762123108,0.06495003402233124,0.06492599844932556,0.052290644496679306,0.04780757054686546,0.041811615228652954,0.048380836844444275,0.03536754846572876,0.037030115723609924,0.03188612312078476,0.029784440994262695,0.026562554761767387,0.029329173266887665,0.030185172334313393,0.02583308517932892,0.022155828773975372,0.028569979593157768,0.02096588909626007,0.02263667620718479,0.019224870949983597,0.019313469529151917,0.022104816511273384,0.019197862595319748,0.015891237184405327,0.012589280493557453,0.015561857260763645,0.017986170947551727,0.017358453944325447,0.016720734536647797,0.01673095114529133,0.014917977154254913,0.012599880807101727,0.013336317613720894,0.012375038117170334,0.014038033783435822,0.015369725413620472,0.01346217654645443,0.011438501067459583,0.012375656515359879,0.014015682972967625,0.013915849849581718,0.011633554473519325,0.011044575832784176,0.011830274015665054,0.012481702491641045,0.011710723862051964,0.010891951620578766,0.011429976671934128,0.01059360895305872,0.011246089823544025,0.012084374204277992,0.010349576361477375,0.009301810525357723,0.009651292115449905,0.01144264917820692,0.010356849059462547,0.00984098669141531,0.009503386914730072,0.009842515923082829,0.009922865778207779,0.011089850217103958,0.010419336147606373,0.009601913392543793,0.010246705263853073,0.009432381018996239,0.010280340909957886,0.009518715552985668,0.009122030809521675,0.008862241171300411,0.009015444666147232,0.009037187322974205,0.007578324526548386,0.008498294278979301,0.010763688012957573,0.009622235782444477,0.00806092843413353,0.008666875772178173,0.009049318730831146,0.009158746339380741,0.008633135817945004,0.008882742375135422,0.008809767663478851,0.008406836539506912,0.008717427030205727,0.008376925252377987,0.00844620168209076,0.009154319763183594,0.00861878227442503,0.007386237382888794,0.0084683271124959,0.009024710394442081,0.007599227596074343,0.008418534882366657,0.007285491097718477,0.008166156709194183,0.009160084649920464,0.008568483404815197,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 138211    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 138212    
=================================================================
Total params: 276,423
Trainable params: 276,423
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 138,211
Trainable params: 138,211
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 138,212
Trainable params: 138,212
Non-trainable params: 0
_________________________________________________________________
