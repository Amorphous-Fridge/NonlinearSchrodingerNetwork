2021-06-26
loss,0.3960459530353546,0.21215657889842987,0.1950749158859253,0.14332398772239685,0.1274760365486145,0.0997159481048584,0.09964074194431305,0.08868462592363358,0.08639779686927795,0.09438984096050262,0.060982588678598404,0.06622562557458878,0.06942233443260193,0.058579221367836,0.060737717896699905,0.058984462171792984,0.05318009480834007,0.0618264339864254,0.07865547388792038,0.061106838285923004,0.05434688925743103,0.04922468960285187,0.05867390334606171,0.06198685243725777,0.04942220076918602,0.03960708528757095,0.05171848461031914,0.04991957172751427,0.04794762656092644,0.05906401947140694,0.04889853298664093,0.05000253766775131,0.050084881484508514,0.04353250563144684,0.04153215512633324,0.04505102336406708,0.04172308370471001,0.03885079175233841,0.04567638412117958,0.042348384857177734,0.03879338875412941,0.03848660737276077,0.04056249186396599,0.03874805569648743,0.034406859427690506,0.03972338140010834,0.038543395698070526,0.034073006361722946,0.03147627040743828,0.027389297261834145,0.028419993817806244,0.027236826717853546,0.02830512821674347,0.03248962387442589,0.038776107132434845,0.03270649537444115,0.030324751511216164,0.02450922504067421,0.024369578808546066,0.037190116941928864,0.03468210995197296,0.036762699484825134,0.03505074605345726,0.027780938893556595,0.03131324425339699,0.03178563714027405,0.02822241745889187,0.023620324209332466,0.022304963320493698,0.0337284691631794,0.028277434408664703,0.029565881937742233,0.032858818769454956,0.029787903651595116,0.027875937521457672,0.026457469910383224,0.02472587861120701,0.023013968020677567,0.02235928550362587,0.028297321870923042,0.027484025806188583,0.028186099603772163,0.028918607160449028,0.026375744491815567,0.024083146825432777,0.02322542853653431,0.024063728749752045,0.026120781898498535,0.025159981101751328,0.023763710632920265,0.022485995665192604,0.020607709884643555,0.01958620361983776,0.018802456557750702,0.017272239550948143,0.016744134947657585,0.015909291803836823,0.016260022297501564,0.02336663194000721,0.027871541678905487,
mse,0.06007995456457138,0.014309854246675968,0.011011648923158646,0.006016272120177746,0.0047013224102556705,0.0028284352738410234,0.00279314536601305,0.002320653758943081,0.002259134314954281,0.0027054976671934128,0.0010718670673668385,0.0013619463425129652,0.0013594680931419134,0.0009665170218795538,0.0010988289723172784,0.0009916407288983464,0.0008165030158124864,0.001130956457927823,0.001726247719489038,0.001048342790454626,0.0008400274091400206,0.0006904582842253149,0.0010363012552261353,0.0010579233057796955,0.0007102176314219832,0.0004635265504475683,0.000751789310015738,0.000699442345649004,0.0006527756340801716,0.0009567491943016648,0.0006636320031248033,0.0007150410092435777,0.0006952272960916162,0.0005422106478363276,0.0004820658650714904,0.0005686786607839167,0.000480798160424456,0.0004212575440760702,0.0005775991594418883,0.000495034852065146,0.00042692996794357896,0.00041829777183011174,0.0004528729186858982,0.0004245336458552629,0.00033877749228850007,0.00044321396853774786,0.00041297002462670207,0.00032198731787502766,0.0002755337336566299,0.00022146762057673186,0.00023236783454194665,0.00021049226052127779,0.00022804239415563643,0.0002957950346171856,0.0004183633136563003,0.00030043645529076457,0.000255701772402972,0.00017707164806779474,0.00016955388127826154,0.0003888257488142699,0.0003428907075431198,0.00036822044057771564,0.00033765853731893003,0.00022942491341382265,0.00027702809893526137,0.0002804266114253551,0.0002212609106209129,0.00016701208369340748,0.00014857357018627226,0.0003171208081766963,0.00022580547374673188,0.00024544628104195,0.000292340264422819,0.00024357445363420993,0.00021590627147816122,0.00019583040557336062,0.00017346742970403284,0.00014862902753520757,0.0001393580751027912,0.0002246764925075695,0.00021017168182879686,0.00022355471446644515,0.00023219553986564279,0.00019665277795866132,0.0001620430703042075,0.00015595945296809077,0.0001652701903367415,0.0001893702137749642,0.00017610467330086976,0.00015468697529286146,0.00013938992924522609,0.00012031829101033509,0.00010793546243803576,9.909236541716382e-05,8.702375635039061e-05,7.846942025935277e-05,7.463739166269079e-05,7.798971637384966e-05,0.00016000807227101177,0.00021368358284235,
mae,0.17115527391433716,0.09237135946750641,0.08373968303203583,0.061716195195913315,0.05267971381545067,0.04251430928707123,0.040430497378110886,0.03580233454704285,0.03667667508125305,0.0390925370156765,0.026016024872660637,0.027845771983265877,0.02968760021030903,0.025333188474178314,0.02624521404504776,0.02484525367617607,0.022835059091448784,0.025915587320923805,0.033959608525037766,0.025142071768641472,0.02254367619752884,0.020825056359171867,0.02489466965198517,0.02655114233493805,0.021069711074233055,0.016932465136051178,0.021713972091674805,0.021056722849607468,0.020203525200486183,0.025547051802277565,0.02097257785499096,0.021144749596714973,0.02095397561788559,0.01816406100988388,0.017551375553011894,0.01928892359137535,0.01785849966108799,0.016625557094812393,0.019705412909388542,0.018322311341762543,0.016634803265333176,0.016294138506054878,0.01752130687236786,0.01632622443139553,0.01440977118909359,0.016958527266979218,0.016358233988285065,0.014062812551856041,0.01321182120591402,0.011618571355938911,0.011701006442308426,0.011378834024071693,0.01177523285150528,0.01368476077914238,0.016514277085661888,0.01357821561396122,0.012804295867681503,0.01045779138803482,0.010294606909155846,0.016021734103560448,0.01481403224170208,0.01589021645486355,0.015198495239019394,0.011523767374455929,0.013511759229004383,0.013535019010305405,0.011623484082520008,0.01003267616033554,0.009374996647238731,0.014147171750664711,0.012037018314003944,0.012336688116192818,0.013862227089703083,0.012931781820952892,0.012302708812057972,0.011655986309051514,0.010792995803058147,0.009775005280971527,0.009326493367552757,0.011954765766859055,0.011335272341966629,0.011793254874646664,0.012419039383530617,0.011253348551690578,0.010158717632293701,0.009837418794631958,0.010098563507199287,0.0107651986181736,0.010364873334765434,0.010339310392737389,0.009598175063729286,0.008804076351225376,0.008385851047933102,0.00802706740796566,0.007312297355383635,0.007268026936799288,0.006761682685464621,0.006969231180846691,0.009776082821190357,0.012145515531301498,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 21027     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 21028     
=================================================================
Total params: 42,055
Trainable params: 42,055
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 21,027
Trainable params: 21,027
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 21,028
Trainable params: 21,028
Non-trainable params: 0
_________________________________________________________________
