2021-06-26
loss,0.7745199799537659,0.2636118233203888,0.23342964053153992,0.16875825822353363,0.14084051549434662,0.13041262328624725,0.13624703884124756,0.11069545894861221,0.08357880264520645,0.08747178316116333,0.07362790405750275,0.08164569735527039,0.06533531099557877,0.07812569290399551,0.08059658110141754,0.0691353902220726,0.05987904220819473,0.06204240769147873,0.05746855586767197,0.051587723195552826,0.05927647650241852,0.0494525320827961,0.04728080332279205,0.04700161889195442,0.04429972171783447,0.04687344655394554,0.05076916515827179,0.04776502028107643,0.04292847216129303,0.0440543070435524,0.04115375131368637,0.035464219748973846,0.03728973865509033,0.03579944744706154,0.04342327266931534,0.04049849137663841,0.038510169833898544,0.03520873561501503,0.034453436732292175,0.03927933797240257,0.039149459451436996,0.03095087967813015,0.02969207987189293,0.028349950909614563,0.031503211706876755,0.035679202526807785,0.03766066953539848,0.030657010152935982,0.031534913927316666,0.030902734026312828,0.033283669501543045,0.030020935460925102,0.03578851744532585,0.02924179844558239,0.02810882031917572,0.02855280600488186,0.02987687662243843,0.03282802924513817,0.02912418358027935,0.02701561152935028,0.023979799821972847,0.02634239010512829,0.02789565734565258,0.02985898219048977,0.027514562010765076,0.0269703920930624,0.025656841695308685,0.026543043553829193,0.023773787543177605,0.026344943791627884,0.026844527572393417,0.023059818893671036,0.02044565975666046,0.0259246826171875,0.027822168543934822,0.026329906657338142,0.02320040762424469,0.023464825004339218,0.024271903559565544,0.02320896089076996,0.022313153371214867,0.020510952919721603,0.020330380648374557,0.022833941504359245,0.024657411500811577,0.021756842732429504,0.02382052130997181,0.022260231897234917,0.023621773347258568,0.02197442017495632,0.02267635054886341,0.022030334919691086,0.023524906486272812,0.020550526678562164,0.016932141035795212,0.01807701401412487,0.02384113520383835,0.021645043045282364,0.019782787188887596,0.019341522827744484,
mse,0.2553632855415344,0.022951066493988037,0.018229316920042038,0.008484401740133762,0.005735475569963455,0.004969860427081585,0.0053824190981686115,0.003531321184709668,0.0020926278084516525,0.002194145694375038,0.001555663999170065,0.0018870733911171556,0.001320333918556571,0.001719753840006888,0.0017976464005187154,0.001372946542687714,0.001004982041195035,0.0010862414492294192,0.0009521544561721385,0.000745207245927304,0.0009787989547476172,0.0007251279894262552,0.000674420443829149,0.0006625418900512159,0.0005393894389271736,0.0006502451724372804,0.0007312585948966444,0.000642652390524745,0.0005268045933917165,0.0005650297971442342,0.00048260382027365267,0.0003541397163644433,0.0003963025228586048,0.0003695840132422745,0.0005257018492557108,0.0004543379764072597,0.0004209775070194155,0.0003467233618721366,0.0003337901143822819,0.00042900917469523847,0.0004249310586601496,0.00027112243697047234,0.0002591589873190969,0.00024061631120275706,0.0002846121205948293,0.00035399087937548757,0.00039359924267046154,0.00027262535877525806,0.0002739416668191552,0.00026478798827156425,0.0003042770258616656,0.0002529682533349842,0.0003527425287757069,0.00024590938119217753,0.0002173390967072919,0.0002325266832485795,0.00024844403378665447,0.0002947345783468336,0.0002342496591154486,0.00021181890042498708,0.0001652278151595965,0.0001994734484469518,0.00021622311032842845,0.00024248524277936667,0.0002085891755996272,0.00020303871133364737,0.00018566435028333217,0.00019181189418304712,0.00016093322483357042,0.0001949086581589654,0.0002020884130615741,0.00015169769176281989,0.00012725604756269604,0.00019221797992940992,0.00021551437384914607,0.00019368271750863642,0.00015510286903008819,0.00015600015467498451,0.00016581863746978343,0.00015122591867111623,0.00014094600919634104,0.00012072188110323623,0.00012001814320683479,0.00014998525148257613,0.00016755198885221034,0.00013402807235252112,0.000160052819410339,0.0001419657637597993,0.00015246612019836903,0.00013327146007213742,0.00014432994066737592,0.00013757971464656293,0.00015236632316373289,0.00011852300667669624,8.445212006336078e-05,9.729486191645265e-05,0.0001585228310432285,0.00012899874127469957,0.00011104409350082278,0.00010743560414994135,
mae,0.3402397036552429,0.11051000654697418,0.09682969003915787,0.07135581225156784,0.05960764363408089,0.055590275675058365,0.05794756859540939,0.047548845410346985,0.036311324685811996,0.03649492189288139,0.03093118593096733,0.03479410707950592,0.028172561898827553,0.03342677652835846,0.03527090698480606,0.03008456528186798,0.025576062500476837,0.027172639966011047,0.02486894093453884,0.02201959863305092,0.02576596662402153,0.021572494879364967,0.02043372206389904,0.020184047520160675,0.01891019009053707,0.0201079323887825,0.022148866206407547,0.02027890831232071,0.018498534336686134,0.01843850314617157,0.017303481698036194,0.015061591751873493,0.015837280079722404,0.01504148356616497,0.018380217254161835,0.017341677099466324,0.016383932903409004,0.014845632016658783,0.014792040921747684,0.017035581171512604,0.017207544296979904,0.012953451834619045,0.012808969244360924,0.012113485485315323,0.013131734915077686,0.015343312174081802,0.016481837257742882,0.01322465855628252,0.013519679196178913,0.013246276415884495,0.014311774633824825,0.01282589789479971,0.015931183472275734,0.012168304063379765,0.012079993262887001,0.012168659828603268,0.012800127267837524,0.014520958997309208,0.012686872854828835,0.011396721936762333,0.010156523436307907,0.011096498928964138,0.01197308674454689,0.012981799431145191,0.011680313386023045,0.011685117147862911,0.010970303788781166,0.01121204998344183,0.010153357870876789,0.011325011029839516,0.011401151306927204,0.009911651723086834,0.00884256511926651,0.011104766279459,0.011936997063457966,0.011257141828536987,0.009890714660286903,0.009948378428816795,0.010502617806196213,0.009726799093186855,0.009378950111567974,0.00875795166939497,0.008494642563164234,0.009672451764345169,0.010491037741303444,0.00930242333561182,0.010194139555096626,0.009396445006132126,0.010114720091223717,0.009290887042880058,0.009487318806350231,0.00950673595070839,0.009960667230188847,0.00865973811596632,0.007185792550444603,0.0076694488525390625,0.01024529431015253,0.009216112084686756,0.008460107259452343,0.00815743487328291,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 102227    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 102228    
=================================================================
Total params: 204,455
Trainable params: 204,455
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 102,227
Trainable params: 102,227
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 102,228
Trainable params: 102,228
Non-trainable params: 0
_________________________________________________________________
