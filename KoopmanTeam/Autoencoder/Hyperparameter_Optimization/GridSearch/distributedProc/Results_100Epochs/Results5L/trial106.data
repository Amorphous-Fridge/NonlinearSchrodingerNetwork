2021-06-26
loss,2.5435996055603027,1.3610131740570068,0.2526073455810547,0.16701602935791016,0.12056058645248413,0.14424724876880646,0.10482456535100937,0.09829524159431458,0.10503032803535461,0.09978825598955154,0.07377709448337555,0.08300536125898361,0.07686110585927963,0.07032766193151474,0.06283114105463028,0.06840171664953232,0.058231934905052185,0.05673392862081528,0.06346086412668228,0.05364175885915756,0.049362000077962875,0.048918914049863815,0.047155652195215225,0.04919464886188507,0.04461771994829178,0.04739278927445412,0.04217429459095001,0.04058408364653587,0.04493018984794617,0.039958830922842026,0.03769523650407791,0.037711676210165024,0.03673415258526802,0.03688421472907066,0.03791631758213043,0.040310777723789215,0.036029741168022156,0.03748376667499542,0.03494763746857643,0.03644093871116638,0.03685496002435684,0.030748968943953514,0.03567260876297951,0.03480783849954605,0.03309756517410278,0.029279306530952454,0.033584028482437134,0.031026527285575867,0.032496463507413864,0.02810470014810562,0.032003115862607956,0.030640222132205963,0.028822964057326317,0.032642289996147156,0.029271066188812256,0.031071117147803307,0.028029775246977806,0.02803676202893257,0.02819650247693062,0.0233486145734787,0.027744507417082787,0.026264164596796036,0.03010329231619835,0.028829164803028107,0.028165597468614578,0.02528952993452549,0.026018865406513214,0.026968397200107574,0.027721012011170387,0.024091437458992004,0.02599874883890152,0.026710305362939835,0.02444465644657612,0.02366451546549797,0.02617107704281807,0.027697239071130753,0.024622762575745583,0.02612387202680111,0.025852559134364128,0.02553657814860344,0.025203140452504158,0.024126209318637848,0.024169640615582466,0.02436995692551136,0.02383239008486271,0.021736588329076767,0.02267901413142681,0.021956181153655052,0.022041143849492073,0.023732446134090424,0.023638812825083733,0.0226928498595953,0.02358561009168625,0.02544526383280754,0.021562403067946434,0.02036554552614689,0.02507980912923813,0.021388059481978416,0.020719802007079124,0.023103486746549606,
mse,1.6904973983764648,0.6207094788551331,0.02048799954354763,0.008192774839699268,0.0041013555601239204,0.006007985677570105,0.003062642877921462,0.0027555825654417276,0.003153137629851699,0.002806680276989937,0.0015393166104331613,0.0019913783762604,0.001703251269645989,0.0014282211195677519,0.0011992711806669831,0.0013184983981773257,0.0009630032582208514,0.0009084168705157936,0.001197214936837554,0.0008173349779099226,0.0007074760505929589,0.0007142432150430977,0.0006533445557579398,0.0006688532303087413,0.0005708553362637758,0.0006251348531804979,0.0005125608877278864,0.000480970717035234,0.000581835163757205,0.00045325097744353116,0.000411705463193357,0.00040520430775359273,0.0003842368605546653,0.00039939332054927945,0.0004161842807661742,0.0004773741529788822,0.00037380639696493745,0.00040353756048716605,0.000349559064488858,0.00037433841498568654,0.00040251584141515195,0.0002690811234060675,0.0003578086325433105,0.00034463463816791773,0.0003033005923498422,0.0002535067906137556,0.0003158591571263969,0.0002823869581334293,0.0003037041751667857,0.00022230164904613048,0.00028977676993235946,0.00026731903199106455,0.00023979679099284112,0.00029841787181794643,0.0002456318761687726,0.00027939782012254,0.0002260871115140617,0.00022153057216200978,0.00022506109962705523,0.00016024291107896715,0.00021583506895694882,0.0002017239894485101,0.0002505551965441555,0.00023213567328639328,0.00022635541972704232,0.00018540849850978702,0.00019246258307248354,0.00020484246488194913,0.00021716720948461443,0.0001676984247751534,0.0001959191868081689,0.0001997804210986942,0.00017160414427053183,0.00016278641123790294,0.00019342500308994204,0.00021605417714454234,0.0001708478812361136,0.00020067511650267988,0.00019125403196085244,0.00018367590382695198,0.0001809264358598739,0.00016386847710236907,0.00016595511988271028,0.00016849572421051562,0.00016196373326238245,0.00013641062832903117,0.00014501599071081728,0.00013761485752183944,0.00013900859630666673,0.00015993774286471307,0.00015948315558489412,0.0001484024542151019,0.00015747279394418,0.00018634911975823343,0.00013285012391861528,0.0001232195063494146,0.00017735155415721238,0.000133125766296871,0.00012544909259304404,0.00015343246923293918,
mae,0.9184669256210327,0.4824143946170807,0.10975484549999237,0.0712476372718811,0.051438335329294205,0.061473723500967026,0.043848320841789246,0.041559457778930664,0.04393657296895981,0.04237630218267441,0.03142459690570831,0.03506996110081673,0.03224988281726837,0.029855387285351753,0.026194648817181587,0.0293570589274168,0.024382371455430984,0.023902738466858864,0.027140162885189056,0.022808421403169632,0.02085931971669197,0.021173205226659775,0.020175879821181297,0.020531730726361275,0.01828000135719776,0.02026541903614998,0.01786196045577526,0.01728300005197525,0.018898315727710724,0.01694190315902233,0.01562009658664465,0.016001354902982712,0.015405578538775444,0.015467453747987747,0.01623734086751938,0.01741969771683216,0.015177261084318161,0.016036788001656532,0.014853273518383503,0.015259640291333199,0.015143999829888344,0.012874395586550236,0.015208126045763493,0.014885139651596546,0.014030813239514828,0.012325849384069443,0.014300928451120853,0.013214893639087677,0.013655793853104115,0.011885405518114567,0.013758715242147446,0.013004640117287636,0.01238163746893406,0.01387729775160551,0.012475140392780304,0.013089217245578766,0.01179664209485054,0.011760910972952843,0.011913402937352657,0.00985338632017374,0.011896651238203049,0.01105455867946148,0.013067593798041344,0.012340144254267216,0.011979443021118641,0.010759132914245129,0.011083104647696018,0.011632862500846386,0.011721751652657986,0.01027454249560833,0.011010105721652508,0.011360930278897285,0.010358061641454697,0.010140779428184032,0.01115705817937851,0.011870099231600761,0.010465073399245739,0.01086200587451458,0.010920797474682331,0.011007442139089108,0.010796397924423218,0.010322216898202896,0.010285679250955582,0.010215374641120434,0.010171068832278252,0.009218117222189903,0.00969882681965828,0.009187420830130577,0.009413580410182476,0.010294148698449135,0.010171365924179554,0.009717144072055817,0.010159932076931,0.010797337628901005,0.00932465773075819,0.008574755862355232,0.010609743185341358,0.00916927121579647,0.008832091465592384,0.00992551539093256,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 275683    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 275684    
=================================================================
Total params: 551,367
Trainable params: 551,367
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 275,683
Trainable params: 275,683
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 275,684
Trainable params: 275,684
Non-trainable params: 0
_________________________________________________________________
