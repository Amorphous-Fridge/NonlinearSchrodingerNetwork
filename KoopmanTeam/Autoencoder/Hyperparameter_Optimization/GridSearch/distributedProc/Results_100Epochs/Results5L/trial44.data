2021-06-26
loss,0.464954674243927,0.22846625745296478,0.1432403028011322,0.103986956179142,0.10766833275556564,0.1016339659690857,0.07571319490671158,0.07378379255533218,0.060587167739868164,0.06945081055164337,0.06834957748651505,0.06949818134307861,0.06742242723703384,0.061298757791519165,0.05100386217236519,0.050062522292137146,0.049968816339969635,0.05060707405209541,0.04422935098409653,0.05614816024899483,0.04732412472367287,0.040316224098205566,0.04588659107685089,0.04487387835979462,0.0409003309905529,0.03681156784296036,0.0373346209526062,0.038654688745737076,0.03291695564985275,0.0356915146112442,0.039170268923044205,0.037598609924316406,0.03187095746397972,0.036346662789583206,0.0328441746532917,0.030289795249700546,0.02923920936882496,0.036002665758132935,0.034062109887599945,0.034646645188331604,0.027380289509892464,0.027377495542168617,0.028310710564255714,0.025145485997200012,0.02942325547337532,0.030064959079027176,0.029751325026154518,0.02854360267519951,0.02858102135360241,0.033087357878685,0.028605569154024124,0.025840766727924347,0.022339172661304474,0.019704202190041542,0.029836639761924744,0.025414109230041504,0.022627508267760277,0.017913976684212685,0.023465516045689583,0.025716345757246017,0.026889242231845856,0.022308355197310448,0.018287591636180878,0.01805047132074833,0.01864493452012539,0.017394650727510452,0.022263500839471817,0.028849683701992035,0.02424611896276474,0.02100658230483532,0.024486016482114792,0.022245997563004494,0.0195390023291111,0.016686424612998962,0.017073124647140503,0.02377345599234104,0.024518704041838646,0.025425005704164505,0.024107296019792557,0.022169744595885277,0.021271640434861183,0.023055538535118103,0.0238486360758543,0.019185341894626617,0.015221190638840199,0.01682981662452221,0.02018655277788639,0.019569044932723045,0.021509256213903427,0.020629310980439186,0.017316794022917747,0.014429730363190174,0.014555616304278374,0.01438447367399931,0.016134032979607582,0.01888412982225418,0.021445799618959427,0.020330870524048805,0.021312762051820755,0.018442440778017044,
mse,0.09256099909543991,0.018266186118125916,0.006438862532377243,0.0030532011296600103,0.003525485284626484,0.0029893137980252504,0.0016195003408938646,0.0015565776266157627,0.0010295215761289,0.0014312556013464928,0.001301366719417274,0.0013804808259010315,0.0012991443509235978,0.0011187678901478648,0.0007456652238033712,0.000714051362592727,0.0007158943335525692,0.0007189488969743252,0.0005493073258548975,0.0009067518403753638,0.0006285986164584756,0.00045930364285595715,0.000593457545619458,0.0005741165368817747,0.0004673921794164926,0.00037848003557883203,0.00040257559157907963,0.00043211947195231915,0.00031249833409674466,0.00035475302138365805,0.0004349176597315818,0.00040210376027971506,0.00028455667779780924,0.0003729448944795877,0.0003051672247238457,0.000259301217738539,0.0002504978619981557,0.00036739037022925913,0.0003289532323833555,0.0003358083195053041,0.0002189779479522258,0.00021965746418572962,0.00022478845494333655,0.00018164451466873288,0.0002458833623677492,0.00025838956935331225,0.0002448597806505859,0.0002299326442880556,0.00022770551731809974,0.0003071688988711685,0.00023069283633958548,0.00018563588673714548,0.0001447774120606482,0.0001150218304246664,0.0002587752533145249,0.0001770025846781209,0.00014474290946964175,9.39716337597929e-05,0.000159562099725008,0.0001838595198933035,0.00020379545458126813,0.00014322133210953325,9.954605047823861e-05,9.513832628726959e-05,0.00010527726408326998,8.848143625073135e-05,0.00014323124196380377,0.0002324259257875383,0.00016144303663168103,0.000127246486954391,0.00016799074364826083,0.00013746938202530146,0.00011206939961994067,8.429049194091931e-05,8.714195428183302e-05,0.00016140697698574513,0.00016795069677755237,0.00018256848852615803,0.00016305249300785363,0.00013713097723666579,0.00012608048564288765,0.00015184270159807056,0.00016134815814439207,0.00010599393135635182,6.86157145537436e-05,8.431848254986107e-05,0.00011657996947178617,0.00011027474829461426,0.00012849256745539606,0.00011871209426317364,8.613632235210389e-05,6.328858580673113e-05,6.246515840757638e-05,6.1065424233675e-05,7.746415940346196e-05,0.00010474758892087266,0.00012825574958696961,0.00011795546015491709,0.0001247397594852373,0.00010013251448981464,
mae,0.19345486164093018,0.09700517356395721,0.06066351383924484,0.043859146535396576,0.04574053734540939,0.04284140095114708,0.03227007016539574,0.03177732601761818,0.02605259232223034,0.02919306978583336,0.02895287424325943,0.029556879773736,0.028564441949129105,0.025574302300810814,0.021695256233215332,0.02143888920545578,0.021303558722138405,0.021414656192064285,0.018745116889476776,0.023761127144098282,0.020029623061418533,0.01717252843081951,0.019546104595065117,0.01880096271634102,0.017313051968812943,0.015622382052242756,0.015755143016576767,0.01633983664214611,0.013790955767035484,0.015165315009653568,0.016296789050102234,0.015946364030241966,0.013471255078911781,0.015144437551498413,0.01405235193669796,0.012828298844397068,0.012427682988345623,0.015040669590234756,0.01436186209321022,0.01495424285531044,0.011548113077878952,0.011796950362622738,0.01201725285500288,0.010630305856466293,0.012459954246878624,0.012698138132691383,0.012714478187263012,0.012201573699712753,0.012295800261199474,0.013825468719005585,0.011894571594893932,0.010721106082201004,0.00940199475735426,0.008236081339418888,0.0125760892406106,0.010905677452683449,0.009694746695458889,0.007616735063493252,0.010110539384186268,0.01095595583319664,0.011305541731417179,0.009403937496244907,0.007725504692643881,0.007691489066928625,0.00784997921437025,0.007350657135248184,0.00944606401026249,0.012043055146932602,0.010204269550740719,0.008946123532950878,0.010379867628216743,0.009409059770405293,0.008363507688045502,0.0069309622049331665,0.007279159035533667,0.010152172297239304,0.010333891026675701,0.010680646635591984,0.010112750343978405,0.009377513080835342,0.009054391644895077,0.009777872823178768,0.01000160537660122,0.008161096833646297,0.006447561550885439,0.007088773883879185,0.008605588227510452,0.008331084623932838,0.009169107303023338,0.008669739589095116,0.007328761741518974,0.00611415458843112,0.0061832391656935215,0.006082338280975819,0.006980246864259243,0.008063261397182941,0.009015971794724464,0.008730552159249783,0.009075979702174664,0.007865514606237411,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 36451     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 36452     
=================================================================
Total params: 72,903
Trainable params: 72,903
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 36,451
Trainable params: 36,451
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 36,452
Trainable params: 36,452
Non-trainable params: 0
_________________________________________________________________
