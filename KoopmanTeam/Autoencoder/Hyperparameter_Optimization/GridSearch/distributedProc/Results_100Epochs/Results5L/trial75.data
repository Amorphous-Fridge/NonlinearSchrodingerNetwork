2021-06-26
loss,0.6789054274559021,0.23881807923316956,0.16870225965976715,0.14158526062965393,0.14230366051197052,0.10721936821937561,0.09190767258405685,0.09356418251991272,0.08099442720413208,0.08674471825361252,0.07175121456384659,0.06236786022782326,0.06515756249427795,0.06704194843769073,0.05680626258254051,0.04847905784845352,0.053236331790685654,0.04439252242445946,0.044227343052625656,0.047314103692770004,0.039888765662908554,0.0500982329249382,0.03722763806581497,0.04045232757925987,0.03989768400788307,0.03210107237100601,0.03925226628780365,0.04089529067277908,0.03491055592894554,0.038700833916664124,0.03190836310386658,0.026799030601978302,0.038335151970386505,0.03541991859674454,0.025644047185778618,0.026522135362029076,0.030480358749628067,0.03505789861083031,0.029384899884462357,0.02696686051785946,0.03332524746656418,0.030282139778137207,0.028410255908966064,0.025967080146074295,0.024558519944548607,0.023584486916661263,0.025995567440986633,0.03173598274588585,0.02743625082075596,0.02374790422618389,0.031178154051303864,0.026986513286828995,0.026426011696457863,0.02395283244550228,0.021330978721380234,0.026634005829691887,0.026945676654577255,0.026244603097438812,0.025504233315587044,0.023377425968647003,0.022217392921447754,0.018460892140865326,0.020087452605366707,0.024791479110717773,0.026165716350078583,0.023081762716174126,0.02271946705877781,0.023699114099144936,0.020477386191487312,0.01884619891643524,0.021111546084284782,0.019566137343645096,0.02140413038432598,0.022508995607495308,0.02186088263988495,0.022425534203648567,0.01937030628323555,0.016264408826828003,0.016413478180766106,0.016174331307411194,0.02181711047887802,0.022630907595157623,0.020297521725296974,0.023865025490522385,0.020142577588558197,0.01992676965892315,0.020562399178743362,0.02039177156984806,0.018375225365161896,0.02101740427315235,0.02066422440111637,0.018018541857600212,0.015805941075086594,0.013597109355032444,0.01723097823560238,0.02162764221429825,0.019009195268154144,0.01996833272278309,0.018664240837097168,0.019166603684425354,
mse,0.23620231449604034,0.01897543855011463,0.008990851230919361,0.005905508995056152,0.005984059069305658,0.0034805736504495144,0.002480841940268874,0.002529418095946312,0.0018893092637881637,0.0022251824848353863,0.001516232150606811,0.001180877210572362,0.0012619239278137684,0.001269632251933217,0.0008900149841792881,0.0006536033470183611,0.0008140474674291909,0.0005842882092110813,0.0005642619798891246,0.0006355991354212165,0.0004648147150874138,0.0006952876574359834,0.0004055614408571273,0.00046192752779461443,0.0004412326088640839,0.00031501732883043587,0.00044735215487889946,0.0004721813602373004,0.00033535080729052424,0.00041730160592123866,0.00029348552925512195,0.0002219941234216094,0.00040104586514644325,0.000354000017978251,0.00019814611005131155,0.0002062871353700757,0.00026333873393014073,0.00033515560789965093,0.00023728147789370269,0.000207014090847224,0.00031631410820409656,0.0002571792574599385,0.00023057457292452455,0.0001874184381449595,0.00017453014152124524,0.00016630931349936873,0.0001972917962120846,0.00027484275051392615,0.00020613835658878088,0.00016584624245297164,0.0002749161794781685,0.0002061687409877777,0.0001896584581118077,0.00016070311539806426,0.0001376346917822957,0.00020945686264894903,0.00020566940656863153,0.00019340342259965837,0.00017910890164785087,0.00015639675257261842,0.00014645475312136114,0.00010240430128760636,0.00012030099605908617,0.0001727900526020676,0.00018830983026418835,0.0001508092536823824,0.00014966781600378454,0.00016078827320598066,0.00012167256500106305,0.0001070314392563887,0.00012762652477249503,0.00011251528485445306,0.00013257467071525753,0.0001412121346220374,0.00013616586511489004,0.0001385276991641149,0.00010652811033651233,8.039076783461496e-05,7.983818795764819e-05,7.859331526560709e-05,0.0001401653280481696,0.00014371878933161497,0.0001186661611427553,0.00015824475849512964,0.00011819594510598108,0.00011277800513198599,0.00012040935689583421,0.00011519665713422,9.66196384979412e-05,0.00012674220488406718,0.00011779194755945355,9.11507013370283e-05,7.508307317038998e-05,5.5395499657606706e-05,8.942995191318914e-05,0.00013044524530414492,0.00010595197090879083,0.0001138021907536313,9.971470717573538e-05,0.00010639402898959816,
mae,0.2872063219547272,0.10674404352903366,0.07209594547748566,0.06060938909649849,0.05824093520641327,0.044964421540498734,0.03872973844408989,0.039912596344947815,0.03415251895785332,0.03658508509397507,0.03005266934633255,0.026681236922740936,0.027018263936042786,0.02875630371272564,0.02377285249531269,0.01997484639286995,0.02260962873697281,0.01880447380244732,0.018731089308857918,0.020100198686122894,0.016759585589170456,0.020995793864130974,0.01578609086573124,0.01736782118678093,0.016999727115035057,0.013526005670428276,0.01661909744143486,0.017265697941184044,0.015049890615046024,0.016771236434578896,0.013532455079257488,0.011438829824328423,0.016431938856840134,0.015205265022814274,0.010998070240020752,0.011255230754613876,0.012891661375761032,0.014906403608620167,0.012642034329473972,0.01144788134843111,0.014341580681502819,0.01293100044131279,0.011728858575224876,0.011005768552422523,0.010355559177696705,0.009992118924856186,0.011075735092163086,0.013676084578037262,0.011751962825655937,0.010112614370882511,0.013103021308779716,0.011564207263290882,0.011492453515529633,0.010270987637341022,0.008890933357179165,0.011366967111825943,0.011522196233272552,0.011089283972978592,0.010700736194849014,0.009865001775324345,0.009424609132111073,0.00782703049480915,0.008575104176998138,0.010646814480423927,0.011109833605587482,0.009880905970931053,0.00963740423321724,0.010219412855803967,0.008724506944417953,0.00807654857635498,0.009007514454424381,0.008320433087646961,0.008988780900835991,0.0095240892842412,0.00935590174049139,0.00960502028465271,0.00846950151026249,0.006924662739038467,0.007018722128123045,0.006932807620614767,0.009086995385587215,0.00976921059191227,0.00874377228319645,0.009983398951590061,0.008434058167040348,0.008473762311041355,0.008498148061335087,0.00857301615178585,0.007716866210103035,0.008861958049237728,0.008823361247777939,0.007720740512013435,0.00678976671770215,0.005820434540510178,0.007373298984020948,0.009290831163525581,0.008066708222031593,0.008548568934202194,0.007878787815570831,0.008114714175462723,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 68371     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 68372     
=================================================================
Total params: 136,743
Trainable params: 136,743
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 68,371
Trainable params: 68,371
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 68,372
Trainable params: 68,372
Non-trainable params: 0
_________________________________________________________________
