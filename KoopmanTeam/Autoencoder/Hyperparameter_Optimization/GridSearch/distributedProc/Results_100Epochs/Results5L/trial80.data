2021-06-26
loss,0.8798409104347229,0.25608599185943604,0.23185785114765167,0.21566924452781677,0.15690405666828156,0.14281871914863586,0.12019923329353333,0.09685809910297394,0.08778758347034454,0.07456450909376144,0.07235848158597946,0.07085148990154266,0.06471969932317734,0.05560557544231415,0.05714457109570503,0.056277431547641754,0.04976542294025421,0.0465073361992836,0.052385762333869934,0.051138825714588165,0.04653828963637352,0.04164675623178482,0.04442828148603439,0.04536445066332817,0.045186806470155716,0.04124791547656059,0.043511003255844116,0.03914889320731163,0.03465961664915085,0.03277609497308731,0.04102686420083046,0.03575778007507324,0.03649180755019188,0.03255804628133774,0.03346711024641991,0.02991858497262001,0.033027082681655884,0.03068750537931919,0.028457164764404297,0.026668395847082138,0.025657406076788902,0.02733437530696392,0.03123336099088192,0.03207733854651451,0.029446814209222794,0.02654080092906952,0.02514556609094143,0.02462955191731453,0.023767292499542236,0.029351018369197845,0.02790716104209423,0.027314340695738792,0.026263171806931496,0.02396620810031891,0.024474279955029488,0.024089617654681206,0.02336663007736206,0.02300112321972847,0.022209003567695618,0.023657789453864098,0.02029995247721672,0.025825655087828636,0.024349845945835114,0.02279447764158249,0.02139948308467865,0.02483687363564968,0.024473071098327637,0.022412307560443878,0.020484481006860733,0.02072281204164028,0.021664055064320564,0.02446616441011429,0.020159391686320305,0.020445017144083977,0.020046548917889595,0.020180994644761086,0.02060294896364212,0.021724851801991463,0.01954801380634308,0.016497427597641945,0.019699910655617714,0.01963880844414234,0.02027399092912674,0.020855095237493515,0.019514260813593864,0.022510159760713577,0.020482363179326057,0.019491491839289665,0.018877124413847923,0.019557520747184753,0.01919860579073429,0.01889432966709137,0.016455473378300667,0.01798083260655403,0.021285468712449074,0.018995435908436775,0.020455775782465935,0.01898709125816822,0.01732311211526394,0.016266459599137306,
mse,0.38276591897010803,0.021277330815792084,0.01802581362426281,0.014373407699167728,0.007269309833645821,0.0059600649401545525,0.004003696609288454,0.0026334798894822598,0.002156599424779415,0.001567621249705553,0.0014889462618157268,0.0014407652197405696,0.0011886176653206348,0.0008827894926071167,0.0009426216129213572,0.0009015619289129972,0.0007024594233371317,0.0006379400147125125,0.0007878198521211743,0.0007368020014837384,0.0006096738507039845,0.0004971809103153646,0.0005724873044528067,0.0005701170302927494,0.0005618821596726775,0.0004783140611834824,0.0005378156783990562,0.0004218860703986138,0.0003347451565787196,0.0003024541074410081,0.00046538523747585714,0.00035726369242183864,0.0003779827675316483,0.0003030865336768329,0.0003113292041234672,0.00024703581584617496,0.00030347961001098156,0.0002611051022540778,0.00023200252326205373,0.00021034126984886825,0.00019140852964483202,0.00022461512708105147,0.0002727561513893306,0.00028529728297144175,0.00023510231403633952,0.00019472985877655447,0.0001737591956043616,0.00017492299957666546,0.0001654750813031569,0.00023927041911520064,0.00022416228603105992,0.0002073007490253076,0.00019415307906456292,0.00016336287080775946,0.00017336544988211244,0.00016319773567374796,0.00015512814570683986,0.00014848496357444674,0.00013903177750762552,0.0001562090910738334,0.00012261145457159728,0.00018755774362944067,0.00016408757073804736,0.00014813797315582633,0.00013054496957920492,0.0001717564882710576,0.0001675861276453361,0.0001391406694892794,0.0001204128930112347,0.000122403449495323,0.00013238565588835627,0.00016632703773211688,0.00011547193571459502,0.00011875703785335645,0.0001175357901956886,0.00011454283230705187,0.00011902893311344087,0.0001312575623160228,0.000107469895738177,8.230612729676068e-05,0.00011069471656810492,0.00010970618313876912,0.00011420781083870679,0.00012104659981559962,0.00010920209751930088,0.00013927448890171945,0.00011660251766443253,0.00010718152771005407,0.00010017275053542107,0.00010597828804748133,0.00010732767259469256,0.00010042072244687006,7.926226680865511e-05,9.416721877641976e-05,0.00012584030628204346,0.00010124130494659767,0.0001157973165391013,0.00010043754446087405,8.590297511545941e-05,7.751525117782876e-05,
mae,0.3693811297416687,0.1065841093659401,0.09998425841331482,0.0951155573129654,0.06797576695680618,0.060482438653707504,0.051429472863674164,0.04169893264770508,0.0380370207130909,0.031999677419662476,0.031139835715293884,0.030319426208734512,0.027509087696671486,0.023875724524259567,0.0248885340988636,0.02411860041320324,0.021288728341460228,0.019976045936346054,0.02246784418821335,0.021859915927052498,0.02020619809627533,0.01755315251648426,0.018915412947535515,0.018880778923630714,0.018970221281051636,0.01795908249914646,0.019331226125359535,0.0170670785009861,0.015230896882712841,0.01405367162078619,0.01758386567234993,0.015089272521436214,0.015531577169895172,0.013923145830631256,0.014448047615587711,0.012520032934844494,0.0141665730625391,0.012844945304095745,0.011844043619930744,0.011376320384442806,0.01092732883989811,0.011610573157668114,0.01317738089710474,0.013593523763120174,0.012294991873204708,0.011424324475228786,0.01057943794876337,0.010391843505203724,0.010145116597414017,0.012556318193674088,0.011814428493380547,0.011482213623821735,0.01119457371532917,0.01007022149860859,0.010412538424134254,0.010312814265489578,0.00995189044624567,0.009770292788743973,0.009359070099890232,0.01008114218711853,0.008590582758188248,0.011138292960822582,0.010391687974333763,0.009714057669043541,0.009145920164883137,0.01049983873963356,0.010409308597445488,0.009443681687116623,0.008598381653428078,0.008755569346249104,0.009113720618188381,0.010525144636631012,0.008482336066663265,0.008649260737001896,0.008454023860394955,0.008673551492393017,0.008798442780971527,0.009092825464904308,0.008178171701729298,0.007032883819192648,0.008290495723485947,0.008368754759430885,0.008641587570309639,0.008902020752429962,0.008308502845466137,0.009802975691854954,0.008853559382259846,0.008152863010764122,0.007956328801810741,0.008281286805868149,0.00807098113000393,0.008034063503146172,0.007044243160635233,0.0075575863011181355,0.009155495092272758,0.008107518777251244,0.008720138110220432,0.008038858883082867,0.007355600595474243,0.007020830642431974,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 105443    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 105444    
=================================================================
Total params: 210,887
Trainable params: 210,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 105,443
Trainable params: 105,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 105,444
Trainable params: 105,444
Non-trainable params: 0
_________________________________________________________________
