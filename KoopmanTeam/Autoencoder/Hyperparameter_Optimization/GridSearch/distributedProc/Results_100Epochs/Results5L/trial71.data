2021-06-26
loss,0.49277839064598083,0.15403752028942108,0.0998535230755806,0.0838019922375679,0.1006145179271698,0.07290677726268768,0.06411969661712646,0.05364757403731346,0.05002780258655548,0.05699269473552704,0.04054372385144234,0.044778771698474884,0.055201925337314606,0.03810085728764534,0.048400022089481354,0.0368441641330719,0.04370054230093956,0.047872547060251236,0.04000291973352432,0.03968162462115288,0.04134023189544678,0.045766137540340424,0.03549189493060112,0.03427959606051445,0.03544263914227486,0.03447050228714943,0.031222082674503326,0.03315657004714012,0.035599227994680405,0.030058035627007484,0.025441981852054596,0.031248098239302635,0.0334739126265049,0.03320784121751785,0.02853981964290142,0.023721611127257347,0.02265307493507862,0.030857810750603676,0.02952805906534195,0.026670146733522415,0.023205958306789398,0.021195558831095695,0.019610648974776268,0.02234676294028759,0.02782980166375637,0.027183352038264275,0.026697326451539993,0.023701556026935577,0.020792383700609207,0.02166067436337471,0.026078596711158752,0.02497965842485428,0.02550751157104969,0.02245066873729229,0.020842188969254494,0.02427360787987709,0.023556098341941833,0.021569762378931046,0.01990441046655178,0.017521843314170837,0.01636870950460434,0.016191555187106133,0.016291480511426926,0.017810415476560593,0.02330731600522995,0.02299950085580349,0.021014247089624405,0.021714646369218826,0.01970934495329857,0.01747690886259079,0.01583774760365486,0.01970907486975193,0.023311421275138855,0.020509304478764534,0.01850934326648712,0.016384795308113098,0.014115232042968273,0.014820649288594723,0.015741484239697456,0.01625598967075348,0.016760118305683136,0.019199257716536522,0.01687936671078205,0.01843119226396084,0.0204804427921772,0.022277021780610085,0.020416228100657463,0.019609443843364716,0.0189322791993618,0.017441870644688606,0.016148854047060013,0.014928899705410004,0.0139213427901268,0.014992688782513142,0.018984921276569366,0.016997283324599266,0.015557026490569115,0.013605470769107342,0.015759028494358063,0.018536681309342384,
mse,0.12734530866146088,0.007846520282328129,0.003054633503779769,0.002075545024126768,0.0030397167429327965,0.0015135066350921988,0.0011943681165575981,0.0008372021256946027,0.0007343456381931901,0.0009840507991611958,0.0004782411560881883,0.0006125729996711016,0.0009093963308259845,0.00042900300468318164,0.000674908165819943,0.00040793896187096834,0.0005574066890403628,0.000676264928188175,0.00046485208440572023,0.00045603193575516343,0.0004919920465908945,0.0006101347971707582,0.00037307199090719223,0.0003391655918676406,0.0003683384566102177,0.0003403713635634631,0.0002987573971040547,0.00032530014868825674,0.000351094757206738,0.0002606796915642917,0.00019428905216045678,0.00028233369812369347,0.0003214301250409335,0.00032527203438803554,0.0002403034013696015,0.0001715820690151304,0.00015820265980437398,0.00027339052758179605,0.00025029489188455045,0.00020172160293441266,0.000158252936671488,0.00013268055045045912,0.00011195897968718782,0.00015002914005890489,0.00021986820502206683,0.00021236046450212598,0.0001992352190427482,0.00016209024761337787,0.0001327014178968966,0.00013878551544621587,0.00018992794502992183,0.00017815909814089537,0.00018681288929656148,0.0001437449682271108,0.00012853108637500554,0.00016705004964023829,0.0001597017835592851,0.00013240688713267446,0.00011254175478825346,9.073727414943278e-05,7.921882934169844e-05,7.879217446316034e-05,7.7511889685411e-05,9.720100206322968e-05,0.00015832189819775522,0.00014930992620065808,0.0001278147246921435,0.00013352034147828817,0.00011098636605311185,9.165536903310567e-05,7.516118057537824e-05,0.00011559013364603743,0.00015289618750102818,0.00011616196570685133,9.780895197764039e-05,7.944372191559523e-05,6.0216236306587234e-05,6.687109998892993e-05,7.595068746013567e-05,7.832441770005971e-05,8.291462290799245e-05,0.00010714449308579788,8.259195601567626e-05,9.819153638090938e-05,0.00012034634710289538,0.00014144013402983546,0.00011868486035382375,0.00011028499284293503,9.954066626960412e-05,8.536905806977302e-05,7.560467201983556e-05,6.608767580473796e-05,5.7767647376749665e-05,6.675117037957534e-05,0.00010141995153389871,8.198732393793762e-05,6.924835906829685e-05,5.601951488642953e-05,7.389880920527503e-05,9.765222057467327e-05,
mae,0.2128438502550125,0.06490521878004074,0.04231318458914757,0.03552445396780968,0.04390789940953255,0.03123018890619278,0.02709081396460533,0.022769508883357048,0.021014487370848656,0.023693962022662163,0.016789454966783524,0.018986640498042107,0.022858669981360435,0.01628408022224903,0.020674077793955803,0.015575170516967773,0.01859970949590206,0.019700340926647186,0.016997601836919785,0.016888828948140144,0.017588043585419655,0.018800070509314537,0.015142708085477352,0.014532568864524364,0.015038426965475082,0.014471197500824928,0.013209665194153786,0.01380417961627245,0.01521872729063034,0.012786895968019962,0.010829592123627663,0.013455058448016644,0.014034220017492771,0.01333914790302515,0.012103386223316193,0.010067956522107124,0.009667603299021721,0.013120236806571484,0.01241464726626873,0.011820229701697826,0.01022263616323471,0.009121248498558998,0.008325830101966858,0.009472399950027466,0.011893700808286667,0.01126518938690424,0.011569730937480927,0.010015844367444515,0.008603167720139027,0.009182321839034557,0.011261598207056522,0.010408181697130203,0.01053689606487751,0.009558325633406639,0.008831019513309002,0.010099615901708603,0.010289603844285011,0.009516694582998753,0.008590098470449448,0.007509839721024036,0.006991861388087273,0.006766461301594973,0.006842715200036764,0.0075332834385335445,0.009737828746438026,0.009721992537379265,0.008944345638155937,0.009140866808593273,0.008320992812514305,0.007423418574035168,0.006606798619031906,0.008379943668842316,0.009631541557610035,0.00887961033731699,0.008045032620429993,0.007053637411445379,0.005974318832159042,0.006255983840674162,0.006626099813729525,0.006917600054293871,0.007071991451084614,0.008099270984530449,0.007159218657761812,0.00779386330395937,0.008652406744658947,0.009072097018361092,0.008633675053715706,0.008243998512625694,0.008101061917841434,0.007459750398993492,0.006788645870983601,0.006191250868141651,0.005845283158123493,0.006376029923558235,0.008007358759641647,0.007317328825592995,0.006696388591080904,0.005846553482115269,0.0066397422924637794,0.007876156829297543,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 67819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 67820     
=================================================================
Total params: 135,639
Trainable params: 135,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 67,819
Trainable params: 67,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 67,820
Trainable params: 67,820
Non-trainable params: 0
_________________________________________________________________
