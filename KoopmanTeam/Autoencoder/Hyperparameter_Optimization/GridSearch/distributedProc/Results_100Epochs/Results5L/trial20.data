2021-06-26
loss,0.4379722476005554,0.1564696878194809,0.09986584633588791,0.10154438763856888,0.11672089248895645,0.09539185464382172,0.10640601068735123,0.06564012169837952,0.06350293755531311,0.06320258975028992,0.06331350654363632,0.0769287645816803,0.0652947649359703,0.06311725825071335,0.05878984555602074,0.0923057571053505,0.08308510482311249,0.07441646605730057,0.0684802234172821,0.0593913234770298,0.0510547012090683,0.04502154514193535,0.043322157114744186,0.039152227342128754,0.03653496131300926,0.0428357757627964,0.06708692759275436,0.059869132936000824,0.05281073600053787,0.04579022899270058,0.04233882948756218,0.03923296555876732,0.04580065235495567,0.05060107260942459,0.04697096347808838,0.052923783659935,0.048492368310689926,0.04456114396452904,0.03849837929010391,0.03454826772212982,0.031161043792963028,0.0291800145059824,0.03519020974636078,0.04141535609960556,0.04309117794036865,0.044096168130636215,0.03838024288415909,0.034568868577480316,0.031544338911771774,0.028929993510246277,0.026699192821979523,0.025416918098926544,0.025674881413578987,0.024908218532800674,0.023675085976719856,0.022849829867482185,0.022058919072151184,0.0220145583152771,0.021748386323451996,0.0214119553565979,0.021205341443419456,0.021070264279842377,0.021347401663661003,0.03216855227947235,0.032834120094776154,0.028729146346449852,0.026120519265532494,0.024317828938364983,0.026064231991767883,0.03621590882539749,0.03907274082303047,0.034504588693380356,0.031078852713108063,0.028209935873746872,0.0260213240981102,0.025181617587804794,0.02285786159336567,0.02155262976884842,0.0231873020529747,0.03657824173569679,0.03342489153146744,0.029135389253497124,0.025695925578475,0.023495199158787727,0.027211995795369148,0.030590858310461044,0.031410541385412216,0.030140968039631844,0.027347583323717117,0.025212004780769348,0.023978866636753082,0.023994164541363716,0.029827091842889786,0.029367048293352127,0.027465179562568665,0.02512027695775032,0.023011742159724236,0.0216340534389019,0.020664876326918602,0.02019628696143627,
mse,0.08869630843400955,0.008283669129014015,0.0029689997900277376,0.0031028452794998884,0.0038523247931152582,0.0026644470635801554,0.003517736215144396,0.001254806644283235,0.0011731579434126616,0.0011568018235266209,0.0012001084396615624,0.0017838128842413425,0.0012071876553818583,0.0011277373414486647,0.0009894825052469969,0.002452162094414234,0.0019236905500292778,0.001547079416923225,0.0013188986340537667,0.0010031025158241391,0.0007304581813514233,0.0005788564449176192,0.0005371058359742165,0.00046037518768571317,0.0004011377750430256,0.0005396096967160702,0.0012403824366629124,0.0009861664148047566,0.0007911627762950957,0.0006098583107814193,0.0005213979166001081,0.0004465081437956542,0.000631370407063514,0.0007173387566581368,0.0006237945053726435,0.0007752052624709904,0.0006497505819424987,0.000550293130800128,0.0004174805944785476,0.00033110950607806444,0.00027386381407268345,0.00024103526084218174,0.0003702629473991692,0.00047459505731239915,0.0005142925074324012,0.0005382048548199236,0.00041496704216115177,0.0003376115346327424,0.00027785912971012294,0.0002359552454436198,0.0002050676557701081,0.00018569010717328638,0.00018906105833593756,0.0001743056927807629,0.0001565299171488732,0.00014700612518936396,0.00013807747745886445,0.00013606128050014377,0.00013327886699698865,0.00012948336370754987,0.000126747865579091,0.00012408694601617754,0.00013139583461452276,0.0002951203496195376,0.00029018634813837707,0.00022557102784048766,0.00019267864990979433,0.00016748145571909845,0.00020928317098878324,0.0003712679899763316,0.0004175906360615045,0.0003252436872571707,0.000265968672465533,0.0002252565900562331,0.00019009207608178258,0.0001783265615813434,0.0001488728739786893,0.00013548752758651972,0.00016399862943217158,0.00036314676981419325,0.0003038323193322867,0.00023930378665681928,0.0001814375864341855,0.00015713638276793063,0.00020772572315763682,0.00026959902606904507,0.00026866799453273416,0.0002490945626050234,0.0002054618817055598,0.00017535951337777078,0.00015930004883557558,0.0001596593065187335,0.00024725095136091113,0.00023546384181827307,0.00020817367476411164,0.0001744084438541904,0.00014704263594467193,0.000129984924569726,0.0001177702215500176,0.00011343090591253713,
mae,0.18726535141468048,0.06705477088689804,0.04266481474041939,0.04362046718597412,0.050339385867118835,0.0410294383764267,0.04747448489069939,0.02839449793100357,0.02771538496017456,0.02766217477619648,0.02755601890385151,0.03397905081510544,0.02786467783153057,0.026955679059028625,0.025383470579981804,0.041487205773591995,0.03749249130487442,0.03329867124557495,0.030343329533934593,0.025365857407450676,0.02205517515540123,0.01916440762579441,0.01826557144522667,0.016894107684493065,0.0157591812312603,0.01814168691635132,0.02956436388194561,0.027128534391522408,0.02319364808499813,0.019280647858977318,0.017811788246035576,0.016343966126441956,0.019915400072932243,0.02098042331635952,0.019465269520878792,0.022909201681613922,0.021575408056378365,0.019498808309435844,0.01690904051065445,0.01479922141879797,0.012760007753968239,0.012106593698263168,0.015001003630459309,0.017967263236641884,0.018835583701729774,0.02011762373149395,0.015895437449216843,0.014099333435297012,0.01343776099383831,0.012099460698664188,0.010995430871844292,0.010479053482413292,0.010767397470772266,0.010741550475358963,0.010368765331804752,0.010028691031038761,0.009434768930077553,0.009418575093150139,0.009308935143053532,0.009098347276449203,0.009041325189173222,0.009025822393596172,0.009075816720724106,0.013919656164944172,0.01418289914727211,0.011897443793714046,0.011338047683238983,0.010233636014163494,0.011106244288384914,0.015495874918997288,0.017860259860754013,0.015398415736854076,0.011926764622330666,0.011284499429166317,0.011254347860813141,0.010682658292353153,0.0094235735014081,0.008992214687168598,0.009905358776450157,0.016054261475801468,0.0147084416821599,0.012759639881551266,0.011116823181509972,0.010092748329043388,0.011794242076575756,0.013344851322472095,0.013856508769094944,0.013643613085150719,0.011569369584321976,0.010524444282054901,0.0101157883182168,0.010007687844336033,0.013137305155396461,0.01304042898118496,0.012059785425662994,0.010700627230107784,0.00969728920608759,0.009172899648547173,0.008709966205060482,0.00855992455035448,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 14195     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 14196     
=================================================================
Total params: 28,391
Trainable params: 28,391
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 14,195
Trainable params: 14,195
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 14,196
Trainable params: 14,196
Non-trainable params: 0
_________________________________________________________________
