2021-06-26
loss,0.4099539518356323,0.10818957537412643,0.06739019602537155,0.05497705563902855,0.050352077931165695,0.04523180425167084,0.042804595082998276,0.03992219641804695,0.03779015317559242,0.03691791370511055,0.035321541130542755,0.03442041575908661,0.03322996944189072,0.03257739171385765,0.03173702582716942,0.03135678172111511,0.030659133568406105,0.02974609285593033,0.02926289103925228,0.028896981850266457,0.028469936922192574,0.028312072157859802,0.027564967051148415,0.027668766677379608,0.02709035575389862,0.02700200304389,0.026439368724822998,0.0260164737701416,0.02567990869283676,0.02588498592376709,0.02546939067542553,0.025142591446638107,0.0247703455388546,0.02453203685581684,0.024419860914349556,0.024069318547844887,0.02410975843667984,0.0238503310829401,0.02374975197017193,0.023328663781285286,0.023114457726478577,0.022989407181739807,0.023001328110694885,0.022590452805161476,0.022713862359523773,0.022361405193805695,0.02222564071416855,0.02198859676718712,0.021857164800167084,0.021791920065879822,0.02177279070019722,0.021708661690354347,0.02150379680097103,0.021218663081526756,0.021105630323290825,0.021148283034563065,0.021273424848914146,0.021023457869887352,0.020453589037060738,0.03498869761824608,0.04141920059919357,0.036024659872055054,0.031507525593042374,0.028158215805888176,0.026406733319163322,0.02499699406325817,0.023955611512064934,0.02334481291472912,0.023593934252858162,0.04206437990069389,0.0373399443924427,0.0347103588283062,0.032766055315732956,0.031153151765465736,0.03005337156355381,0.028885656967759132,0.027276914566755295,0.025718271732330322,0.025307655334472656,0.041479162871837616,0.03759067878127098,0.03732207044959068,0.035510484129190445,0.03354896232485771,0.03219367563724518,0.03043874353170395,0.028666511178016663,0.027035757899284363,0.02528528682887554,0.023860115557909012,0.022713325917720795,0.021820664405822754,0.021093260496854782,0.02054460719227791,0.026344532147049904,0.03489495813846588,0.031033670529723167,0.027764208614826202,0.025979401543736458,0.024712955579161644,
mse,0.08421334624290466,0.0038631109055131674,0.0014485807623714209,0.0009583235369063914,0.0007617127848789096,0.0005977235268801451,0.0005234635900706053,0.0004507106204982847,0.00040207160054706037,0.00038116227369755507,0.0003495262935757637,0.00032809420372359455,0.0003075741115026176,0.0002937213866971433,0.00027903408044949174,0.00027285757823847234,0.0002619634033180773,0.0002450323954690248,0.00023648160276934505,0.00023012929887045175,0.0002231589751318097,0.00022274933871813118,0.00021113948605488986,0.00021202751668170094,0.00020315253641456366,0.00020079640671610832,0.00019355265249032527,0.00018625314987730235,0.0001818629098124802,0.0001852376153692603,0.0001792347029550001,0.0001738332211971283,0.00016877974849194288,0.00016538384079467505,0.00016460014740005136,0.00015946677012834698,0.00015972548862919211,0.0001562989637022838,0.00015473445819225162,0.00014933703641872853,0.0001468011614633724,0.0001449055562261492,0.00014464609557762742,0.00014005541743244976,0.0001414436992490664,0.00013825226051267236,0.0001351823448203504,0.00013231427874416113,0.00013116646732669324,0.0001304473407799378,0.0001304961770074442,0.00012926271301694214,0.00012638325279112905,0.00012316223001107574,0.00012252158194314688,0.00012246944243088365,0.0001241645950358361,0.00012143865023972467,0.00011911006004083902,0.0004519803333096206,0.0005191414966247976,0.0003813339280895889,0.0002753728476818651,0.00021650044072885066,0.00019112875452265143,0.00017282679618801922,0.00015885490574873984,0.0001500025246059522,0.000163918302860111,0.0004942928208038211,0.00038261510781012475,0.00032918303622864187,0.00029370267293415964,0.00026662368327379227,0.0002475896617397666,0.00022985122632235289,0.00020453792240004987,0.00018221387290395796,0.0001796645810827613,0.0005130685749463737,0.00040960978367365897,0.0003936045686714351,0.00034646326093934476,0.00031101994682103395,0.00028607953572645783,0.00025553713203407824,0.00022627838188782334,0.00020037294598296285,0.00017569713236298412,0.00015629074187017977,0.0001417915482306853,0.00013127406418789178,0.00012269767466932535,0.00011660731252050027,0.00020754056458827108,0.0003404070739634335,0.00026311323745176196,0.00020992025383748114,0.00018418770923744887,0.00016668513126205653,
mae,0.17445719242095947,0.04499382898211479,0.02843870222568512,0.023358123376965523,0.021283648908138275,0.019061686471104622,0.01807529293000698,0.01682555302977562,0.016062282025814056,0.015544379130005836,0.014908608980476856,0.014623207040131092,0.014075827784836292,0.013822444714605808,0.013524497859179974,0.013243875466287136,0.012976445257663727,0.012566047720611095,0.012439635582268238,0.012302130460739136,0.012183635495603085,0.012103898450732231,0.011775162070989609,0.01167072169482708,0.011414825916290283,0.011370927095413208,0.011107336729764938,0.011096618138253689,0.010935340076684952,0.011017135344445705,0.01089587714523077,0.010644372552633286,0.010515516623854637,0.010437189601361752,0.010445339605212212,0.01022183895111084,0.010173426941037178,0.010087664239108562,0.010004241019487381,0.009929558262228966,0.009773102588951588,0.009802352637052536,0.009865816682577133,0.009599735960364342,0.009544480592012405,0.0094486428424716,0.009283328428864479,0.00926024466753006,0.009170988574624062,0.009225189685821533,0.009305750951170921,0.009176278486847878,0.009063523262739182,0.009023558348417282,0.009088721126317978,0.008991888724267483,0.009025044739246368,0.008864831179380417,0.008671591989696026,0.015076382085680962,0.01803494431078434,0.01549482811242342,0.013629890978336334,0.01223711110651493,0.011430266313254833,0.01073337160050869,0.010021532885730267,0.0096546346321702,0.009889611974358559,0.01792961172759533,0.016168715432286263,0.015014066360890865,0.014183158054947853,0.01355435699224472,0.013084457255899906,0.012549773789942265,0.011823526583611965,0.011484887450933456,0.01105219405144453,0.017309825867414474,0.016012931242585182,0.01631968282163143,0.01568850316107273,0.015023933723568916,0.014305893331766129,0.013310403563082218,0.012655542232096195,0.01197892427444458,0.010968854650855064,0.010125136002898216,0.00965235847979784,0.009292710572481155,0.009017772041261196,0.008785299956798553,0.011308967135846615,0.014969258569180965,0.013719405047595501,0.012766475789248943,0.01192293968051672,0.011310859583318233,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5395      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5396      
=================================================================
Total params: 10,791
Trainable params: 10,791
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 5,395
Trainable params: 5,395
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 5,396
Trainable params: 5,396
Non-trainable params: 0
_________________________________________________________________
