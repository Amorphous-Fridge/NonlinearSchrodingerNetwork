2021-06-26
loss,0.3301958739757538,0.11804508417844772,0.09563560783863068,0.09829266369342804,0.07664475589990616,0.06524713337421417,0.07031680643558502,0.08006034791469574,0.06453639268875122,0.06168845295906067,0.05039398372173309,0.04196541756391525,0.03964495286345482,0.03554103523492813,0.03412633761763573,0.033062536269426346,0.03220938891172409,0.031296465545892715,0.03073229268193245,0.03493967652320862,0.04729858413338661,0.04383943974971771,0.03673640638589859,0.03327574580907822,0.03424952179193497,0.03797784447669983,0.04241953417658806,0.037485260516405106,0.048006221652030945,0.04102013632655144,0.03945419192314148,0.04209339991211891,0.03369501233100891,0.0298010166734457,0.027967020869255066,0.02658560313284397,0.025743870064616203,0.03676281124353409,0.04117347672581673,0.03477027267217636,0.030820684507489204,0.026688970625400543,0.022447193041443825,0.021912092342972755,0.021671853959560394,0.021358756348490715,0.02087222971022129,0.02535603567957878,0.03302028030157089,0.02881976217031479,0.035060420632362366,0.03357808291912079,0.03099776990711689,0.027409953996539116,0.02468157932162285,0.02288145013153553,0.02160382829606533,0.020941467955708504,0.020462641492486,0.020307909697294235,0.025526776909828186,0.03085070289671421,0.02871965430676937,0.024468956515192986,0.02988273836672306,0.029824526980519295,0.027162974700331688,0.02438894286751747,0.025222839787602425,0.023471033200621605,0.02429848350584507,0.027908433228731155,0.028634438291192055,0.025520971044898033,0.023647582158446312,0.022394714877009392,0.021315092220902443,0.02055569738149643,0.019970713183283806,0.019326547160744667,0.01898372359573841,0.018570266664028168,0.018006106838583946,0.020098887383937836,0.028114089742302895,0.025340626016259193,0.026901088654994965,0.024509765207767487,0.023117905482649803,0.021461378782987595,0.020233891904354095,0.01925463043153286,0.018349355086684227,0.01658266969025135,0.015216849744319916,0.014694779179990292,0.01440349593758583,0.013903489336371422,0.013631978072226048,0.01352820172905922,
mse,0.04660125821828842,0.004529603756964207,0.0027209159452468157,0.002774754771962762,0.0017243342008441687,0.0012784340651705861,0.0014566864119842649,0.0018566158832982183,0.0011990569764748216,0.0010880309855565429,0.0007207630551420152,0.000501478963997215,0.0004614727513398975,0.00036912402720190585,0.00033981792512349784,0.00031619012588635087,0.0002947493630927056,0.00027689532726071775,0.00026966154109686613,0.00038405583472922444,0.0006297781364992261,0.0005380742368288338,0.0003800838894676417,0.0003252076276112348,0.0003392745857127011,0.0004165121936239302,0.000495820480864495,0.0003982842026744038,0.000658388074953109,0.0004793751868419349,0.0004380996397230774,0.00049522117478773,0.0003187519614584744,0.0002488535246811807,0.00022045461810193956,0.00020049266458954662,0.00019460539624560624,0.00038957002107053995,0.0004719414282590151,0.00034019642043858767,0.0002670309622772038,0.0002064173313556239,0.00015908526256680489,0.00014403450768440962,0.0001385169307468459,0.0001290301588596776,0.00012512761168181896,0.00019348277419339865,0.0003064610355067998,0.00023650814546272159,0.0003446642367634922,0.00031462431070394814,0.0002643375191837549,0.0002114463277393952,0.00017094038776122034,0.00014774472219869494,0.0001318903232458979,0.00012526776117738336,0.00011881194222951308,0.00011656260176096112,0.00020497266086749732,0.0002668800298124552,0.0002277857856824994,0.0001773741823853925,0.0002591206575743854,0.00025984589592553675,0.00020610049250535667,0.00017554730584379286,0.00018515929696150124,0.00015948321379255503,0.00016194632917176932,0.0002291272976435721,0.00023048218281473964,0.00018014226225204766,0.00015601108316332102,0.00014145096065476537,0.00012820112169720232,0.00012031206279061735,0.0001139019223046489,0.00010710112837841734,0.00010364327317802235,9.923637844622135e-05,9.622232028050348e-05,0.00011858826474053785,0.00022557830379810184,0.0001811436959542334,0.00019980748766101897,0.00016662759298924357,0.00014887162251397967,0.00012987400987185538,0.00011517813254613429,0.0001048167614499107,9.610795677872375e-05,8.353914745384827e-05,7.084905519150198e-05,6.30073482170701e-05,5.928035534452647e-05,5.453392077470198e-05,5.225243148743175e-05,5.200707528274506e-05,
mae,0.14103327691555023,0.049399714916944504,0.04059161618351936,0.041810132563114166,0.03234894201159477,0.02749187871813774,0.029398532584309578,0.03357117995619774,0.027404606342315674,0.02628331258893013,0.021313853561878204,0.017760874703526497,0.016726559028029442,0.015149947255849838,0.014504802413284779,0.014096064493060112,0.013612124137580395,0.013373149558901787,0.01299641840159893,0.01476483978331089,0.01996578648686409,0.018803955987095833,0.015550962649285793,0.014053050428628922,0.014519598335027695,0.016162674874067307,0.017007216811180115,0.015522417612373829,0.020385866984725,0.017201481387019157,0.01682470738887787,0.017815319821238518,0.014140716753900051,0.012672560289502144,0.011870171874761581,0.011250820942223072,0.010767437517642975,0.015533835627138615,0.0171606857329607,0.014786661602556705,0.01272530946880579,0.011492506600916386,0.009454242885112762,0.00925885047763586,0.009197224862873554,0.008937662467360497,0.008785548619925976,0.010862532071769238,0.013648688793182373,0.012113012373447418,0.014624321833252907,0.014177117496728897,0.012913472950458527,0.011103409342467785,0.0106356181204319,0.00976527389138937,0.009213385172188282,0.00891459733247757,0.008690839633345604,0.008606434799730778,0.010901358909904957,0.01324430387467146,0.012290582992136478,0.010274295695126057,0.012562612071633339,0.012597817927598953,0.011805440299212933,0.010149448178708553,0.01059508603066206,0.00975840911269188,0.010176735930144787,0.011717311106622219,0.012016437016427517,0.011141297407448292,0.01036732830107212,0.009749993681907654,0.009098735637962818,0.008715346455574036,0.008454853668808937,0.008168112486600876,0.008048748597502708,0.007879670709371567,0.007588210050016642,0.008595560677349567,0.011690330691635609,0.010455920360982418,0.01124413963407278,0.010680141858756542,0.010205182246863842,0.009381972253322601,0.008541518822312355,0.008035899139940739,0.0076936352998018265,0.007031689397990704,0.006368583999574184,0.006171963643282652,0.006095504853874445,0.005767497234046459,0.0056535350158810616,0.005645638797432184,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25771     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25772     
=================================================================
Total params: 51,543
Trainable params: 51,543
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 25,771
Trainable params: 25,771
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 25,772
Trainable params: 25,772
Non-trainable params: 0
_________________________________________________________________
