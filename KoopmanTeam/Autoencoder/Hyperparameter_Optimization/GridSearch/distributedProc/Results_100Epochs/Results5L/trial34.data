2021-06-26
loss,0.7655254602432251,0.3315097391605377,0.24616998434066772,0.20421533286571503,0.12760256230831146,0.10617626458406448,0.09180095046758652,0.08000029623508453,0.07481494545936584,0.07132839411497116,0.0651935264468193,0.07313382625579834,0.061687927693128586,0.07948803901672363,0.07513520121574402,0.0564989410340786,0.06440582126379013,0.05083855986595154,0.05864078924059868,0.06921893358230591,0.047915827482938766,0.05798916518688202,0.056189797818660736,0.057968638837337494,0.051271937787532806,0.047893598675727844,0.038067661225795746,0.03540584817528725,0.032557446509599686,0.046632181853055954,0.04568229615688324,0.04056370630860329,0.036715734750032425,0.038782063871622086,0.049746252596378326,0.04432293400168419,0.0509304441511631,0.04501604661345482,0.03677584230899811,0.037188246846199036,0.03595539182424545,0.03354053571820259,0.0342293381690979,0.03691830113530159,0.045051220804452896,0.04552836716175079,0.03896519914269447,0.042675286531448364,0.040477313101291656,0.03486664220690727,0.03321094810962677,0.034804314374923706,0.030905265361070633,0.03164037689566612,0.03544437512755394,0.02698242850601673,0.021776003763079643,0.02138819731771946,0.021970193833112717,0.026317868381738663,0.03171681612730026,0.03453955799341202,0.03660811111330986,0.03074347786605358,0.030804181471467018,0.03284565359354019,0.03708423674106598,0.03564416244626045,0.03175697103142738,0.028715038672089577,0.0287784393876791,0.03396337851881981,0.028560487553477287,0.03290038928389549,0.031179068610072136,0.027550123631954193,0.03143477067351341,0.027101637795567513,0.022800205275416374,0.022769451141357422,0.026500647887587547,0.02458515577018261,0.02575657144188881,0.0261367317289114,0.030708301812410355,0.032715804874897,0.03006165102124214,0.02835967391729355,0.03133385255932808,0.0287012942135334,0.024721598252654076,0.02207189053297043,0.020621370524168015,0.019245482981204987,0.019332002848386765,0.025228917598724365,0.027178660035133362,0.027169425040483475,0.031726691871881485,0.028957702219486237,
mse,0.2329607456922531,0.03332899138331413,0.02017863839864731,0.013624358922243118,0.004805188626050949,0.003393980208784342,0.0024174917489290237,0.0018158400198444724,0.001651672413572669,0.001455030171200633,0.0012379821855574846,0.0015111566754058003,0.0011255753925070167,0.0017967275343835354,0.0016269296174868941,0.0009117306908592582,0.0011616391129791737,0.0007503311499021947,0.0010053837904706597,0.0013380752643570304,0.00069635413819924,0.0009823881555348635,0.0008741633500903845,0.0009217763436026871,0.0007363572949543595,0.0006554308347404003,0.0004193560453131795,0.00036891407216899097,0.0003092512779403478,0.000624810520093888,0.0005662858602590859,0.0004702272708527744,0.0003829006745945662,0.0004516599583439529,0.0007018370670266449,0.0005682383780367672,0.0007001528283581138,0.0005673876730725169,0.0003865082690026611,0.0003912716347258538,0.00037482703919522464,0.0003234730684198439,0.0003285623388364911,0.000406779523473233,0.0005689786048606038,0.0005672415718436241,0.00042361742816865444,0.0004982068203389645,0.00045270888949744403,0.0003553716524038464,0.0003159104671794921,0.0003361063136253506,0.0002727433166000992,0.00028868942172266543,0.0003563034115359187,0.00021549462690018117,0.0001412299752701074,0.00013021159975323826,0.00013928180851507932,0.00020344005315564573,0.0002833268081303686,0.0003383434668648988,0.0003735178615897894,0.0002702850615605712,0.0002662364859133959,0.0003062955802306533,0.0003801015845965594,0.0003527155495248735,0.0002755000605247915,0.00022700283443555236,0.0002429372980259359,0.00032370080589316785,0.00023360482009593397,0.00030031270580366254,0.000272136356215924,0.0002092027716571465,0.00027746681007556617,0.00021086135529913008,0.00015467332559637725,0.00015470011567231268,0.00019439270545262843,0.00017521136032883078,0.00018909561913460493,0.00018790847389027476,0.00027374859200790524,0.00029570257174782455,0.00024945716722868383,0.0002216770371887833,0.0002681964833755046,0.00023008603602647781,0.00017197744455188513,0.0001386327639920637,0.00012119003804400563,0.00010550731531111524,0.00011000053200405091,0.00017486583965364844,0.0002163402532460168,0.00020949967438355088,0.00027938102721236646,0.00023328710813075304,
mae,0.3254372775554657,0.1452702432870865,0.10953399538993835,0.09052600711584091,0.05433712527155876,0.04557633772492409,0.03908645734190941,0.03344567120075226,0.0315047986805439,0.030086101964116096,0.027924619615077972,0.031194131821393967,0.02620801143348217,0.03389069437980652,0.032472070306539536,0.02333693765103817,0.02773442678153515,0.021630894392728806,0.025423943996429443,0.030270788818597794,0.02035677433013916,0.024609947577118874,0.02439710684120655,0.02505909465253353,0.02194041572511196,0.02026621252298355,0.016206461936235428,0.015108326449990273,0.013954263180494308,0.019891930744051933,0.019655033946037292,0.017586112022399902,0.015623924322426319,0.016173530369997025,0.021597078070044518,0.01884576864540577,0.022583581507205963,0.019791370257735252,0.015442111529409885,0.015859033912420273,0.015105101279914379,0.01408289559185505,0.014635072089731693,0.015491388738155365,0.019734034314751625,0.020617950707674026,0.01693791337311268,0.018742704764008522,0.01811111532151699,0.014703755266964436,0.014282841235399246,0.014715313911437988,0.01323741301894188,0.013628038577735424,0.015081647783517838,0.011466538533568382,0.009332127869129181,0.009105530567467213,0.009471576660871506,0.011146697215735912,0.013389204628765583,0.01458717230707407,0.015423322096467018,0.013288096524775028,0.013303701765835285,0.014064698480069637,0.016003014519810677,0.01613488607108593,0.013920767232775688,0.012405896559357643,0.01229591853916645,0.01489147450774908,0.012209778651595116,0.014129558578133583,0.013238358311355114,0.011672965250909328,0.013345745392143726,0.011058693751692772,0.009700139984488487,0.009581035003066063,0.01133787538856268,0.01064435113221407,0.010968935675919056,0.011189602315425873,0.013110905885696411,0.014335394836962223,0.013018311001360416,0.012169728055596352,0.01329684630036354,0.012333857826888561,0.010738657787442207,0.009424361400306225,0.008931026794016361,0.008426660671830177,0.008162754587829113,0.010942582041025162,0.011808730661869049,0.011755688115954399,0.013601213693618774,0.01242874190211296,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 26611     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 26612     
=================================================================
Total params: 53,223
Trainable params: 53,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 26,611
Trainable params: 26,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 26,612
Trainable params: 26,612
Non-trainable params: 0
_________________________________________________________________
