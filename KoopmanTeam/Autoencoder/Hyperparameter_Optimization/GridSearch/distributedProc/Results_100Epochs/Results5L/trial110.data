2021-06-26
loss,3.5262269973754883,3.126763105392456,3.1228742599487305,3.123353958129883,3.1224441528320312,3.1220645904541016,3.122102737426758,3.122148036956787,3.1221184730529785,3.1216416358947754,3.1225991249084473,3.12176513671875,3.1221084594726562,3.1225197315216064,3.122926950454712,3.1365160942077637,3.1659772396087646,3.5807924270629883,1.0516293048858643,0.3343302607536316,0.27901068329811096,0.23923569917678833,0.18396179378032684,0.19103962182998657,0.12205280363559723,0.09851469099521637,0.14239482581615448,0.10143100470304489,0.10394777357578278,0.1301899403333664,0.10229513794183731,0.09765515476465225,0.07913428544998169,0.08467435836791992,0.09486640244722366,0.08674430847167969,0.07639024406671524,0.06342554837465286,0.07177628576755524,0.0685572549700737,0.05825250595808029,0.07592868059873581,0.07055672258138657,0.0624917708337307,0.05295560508966446,0.047863464802503586,0.044927313923835754,0.04118863493204117,0.054340243339538574,0.05384545028209686,0.05761222913861275,0.06790092587471008,0.062446337193250656,0.05480913817882538,0.046311262995004654,0.04351591691374779,0.04229257255792618,0.05627239868044853,0.058213621377944946,0.05326953902840614,0.04677780717611313,0.041717834770679474,0.03443998470902443,0.03232213854789734,0.05691233277320862,0.051433321088552475,0.04260621592402458,0.03908151760697365,0.036399126052856445,0.039121583104133606,0.04366927593946457,0.05056922510266304,0.05480925738811493,0.05089512839913368,0.04637214541435242,0.038799844682216644,0.03777814656496048,0.05012402683496475,0.042961105704307556,0.0378253236413002,0.03487849608063698,0.030327722430229187,0.02879064530134201,0.031094448640942574,0.038137346506118774,0.050029266625642776,0.04206658899784088,0.03609367087483406,0.04559791460633278,0.04650193080306053,0.04033277928829193,0.03584698587656021,0.03825907036662102,0.03988310694694519,0.03415354713797569,0.04211235046386719,0.04486003890633583,0.03561437502503395,0.02707541733980179,0.03832698240876198,
mse,3.2017626762390137,2.453801155090332,2.4477016925811768,2.4484353065490723,2.447035312652588,2.4464569091796875,2.446563243865967,2.4465982913970947,2.4465432167053223,2.445889949798584,2.447300910949707,2.445981740951538,2.446564197540283,2.4472501277923584,2.4478001594543457,2.469526529312134,2.517763137817383,3.717996120452881,0.49801114201545715,0.033243801444768906,0.023825738579034805,0.018413452431559563,0.010286381468176842,0.0119095453992486,0.004293086007237434,0.002864510752260685,0.005875234492123127,0.002940045204013586,0.003014791989699006,0.004680012818425894,0.0029601275455206633,0.0026290728710591793,0.0017235752893611789,0.0020642096642404795,0.0024648343678563833,0.002089156536385417,0.0016059336485341191,0.0011309386463835835,0.0014195169787853956,0.0012834693770855665,0.0010045479284599423,0.0015869647031649947,0.0013324501924216747,0.0010494451271370053,0.0007705804891884327,0.0006265124538913369,0.0005458944942802191,0.00045546048204414546,0.0009007721673697233,0.0008071421761997044,0.0009252282325178385,0.0012623050715774298,0.0010809085797518492,0.0008303896174766123,0.0005941935814917088,0.0005296290037222207,0.0005301253404468298,0.0008925409056246281,0.0009268676512874663,0.0007592827314510942,0.0006081449682824314,0.0004813726991415024,0.0003302335098851472,0.00028471931000240147,0.0008878667722456157,0.0007188267773017287,0.0005000955425202847,0.0004163784033153206,0.00036113758687861264,0.0004381501057650894,0.0005196852143853903,0.0007254223455674946,0.0008237841539084911,0.0007056796457618475,0.0006006881594657898,0.00043124661897309124,0.0004054807941429317,0.0006792383501306176,0.0005056148511357605,0.00039187853690236807,0.00032824455411173403,0.0002645427011884749,0.00023647317721042782,0.0002772616280708462,0.00042426108848303556,0.0006762839038856328,0.000486305943923071,0.00036121250013820827,0.0005748770199716091,0.0005853585316799581,0.0004430981061886996,0.00035130485775880516,0.00040687352884560823,0.0004335137491580099,0.0003320186515338719,0.0004990048473700881,0.0005448234733194113,0.00036206108052283525,0.00021501701849047095,0.00041088080615736544,
mae,1.5693856477737427,1.138981819152832,1.111527919769287,1.1079130172729492,1.105609655380249,1.1043199300765991,1.1036850214004517,1.1032527685165405,1.1029292345046997,1.1025370359420776,1.1026455163955688,1.102201223373413,1.1021766662597656,1.1022448539733887,1.1023792028427124,1.1371110677719116,1.233009696006775,1.4821537733078003,0.4318121075630188,0.14628398418426514,0.12350201606750488,0.10663251578807831,0.0784030482172966,0.08119306713342667,0.05309685319662094,0.04227596893906593,0.06149788200855255,0.042148903012275696,0.04516790434718132,0.057603273540735245,0.04473159462213516,0.041177645325660706,0.03103908710181713,0.03494863584637642,0.042814429849386215,0.039879895746707916,0.033784765750169754,0.025065748021006584,0.03054189123213291,0.029634738340973854,0.02485083043575287,0.03217834606766701,0.03166762739419937,0.02748263068497181,0.02252688631415367,0.020296059548854828,0.019171597436070442,0.017356136813759804,0.022818278521299362,0.022011559456586838,0.02349332720041275,0.03106711618602276,0.02945253811776638,0.023987064138054848,0.019893448799848557,0.018103189766407013,0.01745198667049408,0.024541489779949188,0.02567518875002861,0.023223357275128365,0.0177417304366827,0.018552357330918312,0.01489303819835186,0.01390950009226799,0.02450304664671421,0.0218728706240654,0.018709952011704445,0.017611823976039886,0.016090858727693558,0.016529936343431473,0.017322933301329613,0.02208377607166767,0.02473679557442665,0.023771995678544044,0.020607588812708855,0.01634872518479824,0.0162641704082489,0.021737398579716682,0.01818343810737133,0.01610075682401657,0.015655744820833206,0.013133973814547062,0.012162425555288792,0.01324984896928072,0.015948954969644547,0.022306082770228386,0.0186944380402565,0.01580209471285343,0.019910214468836784,0.02152656391263008,0.017897935584187508,0.015681294724345207,0.016285141929984093,0.017376655712723732,0.01455642655491829,0.018115941435098648,0.019810926169157028,0.015430133789777756,0.011466030962765217,0.016666552051901817,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 288195    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 288196    
=================================================================
Total params: 576,391
Trainable params: 576,391
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 288,195
Trainable params: 288,195
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 288,196
Trainable params: 288,196
Non-trainable params: 0
_________________________________________________________________
