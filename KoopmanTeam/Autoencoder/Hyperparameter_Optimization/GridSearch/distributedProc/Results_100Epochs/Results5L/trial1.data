2021-06-26
loss,0.45839500427246094,0.2869257926940918,0.2009998857975006,0.10753688961267471,0.06890232861042023,0.05783615633845329,0.05040762573480606,0.045113664120435715,0.04159059002995491,0.03815426304936409,0.035466741770505905,0.03345438092947006,0.03183610737323761,0.030443312600255013,0.029245199635624886,0.028512127697467804,0.02809481881558895,0.02692318707704544,0.026146747171878815,0.02572907693684101,0.02512395568192005,0.024918103590607643,0.024147912859916687,0.023866016417741776,0.023407453671097755,0.023005321621894836,0.022930394858121872,0.022447898983955383,0.02221822552382946,0.021812761202454567,0.02160559594631195,0.021346017718315125,0.02113860286772251,0.020986199378967285,0.020778939127922058,0.02055276371538639,0.02038489654660225,0.02014295570552349,0.019815940409898758,0.019649937748908997,0.019758883863687515,0.019546741619706154,0.01912519708275795,0.019306043162941933,0.019103972241282463,0.01877869851887226,0.01882964000105858,0.01838146522641182,0.01847856119275093,0.018357470631599426,0.01823868229985237,0.017992202192544937,0.017970893532037735,0.018031075596809387,0.017939703539013863,0.01773868314921856,0.017693616449832916,0.01744920201599598,0.017483271658420563,0.017282990738749504,0.017192136496305466,0.017107844352722168,0.017176054418087006,0.016902953386306763,0.017007876187562943,0.016923269256949425,0.016767092049121857,0.016568627208471298,0.016707923263311386,0.016626648604869843,0.016371000558137894,0.016479726880788803,0.01604541577398777,0.01641949824988842,0.016301942989230156,0.015985334292054176,0.01608693040907383,0.01591392233967781,0.015986494719982147,0.01579992100596428,0.01588119938969612,0.01571098528802395,0.01572064310312271,0.01561908982694149,0.015564500354230404,0.015491137281060219,0.015447385609149933,0.015440361574292183,0.015363429673016071,0.015327079221606255,0.015306646004319191,0.015254165977239609,0.015203279443085194,0.01510506123304367,0.015039661899209023,0.014971325173974037,0.014981257729232311,0.014830670319497585,0.014918711967766285,0.014870934188365936,
mse,0.072585828602314,0.026416786015033722,0.014493554830551147,0.0038991854526102543,0.0015824787551537156,0.0011236011050641537,0.0008471070905216038,0.0006731759640388191,0.000559409090783447,0.000469656428322196,0.00040162040386348963,0.00035410557757131755,0.0003180165949743241,0.00028836895944550633,0.00026521063409745693,0.0002515140804462135,0.00024159066379070282,0.0002215399726992473,0.0002070753398584202,0.00019920604245271534,0.00018959175213240087,0.00018535110575612634,0.00017462590767536312,0.000169704930158332,0.00016360064910259098,0.0001574455964146182,0.00015534742851741612,0.0001492201554356143,0.0001455059536965564,0.00014013158215675503,0.00013780857261735946,0.00013410154497250915,0.00013064747327007353,0.00012868980411440134,0.00012619569315575063,0.00012386009620968252,0.00012082147441105917,0.00011817775521194562,0.00011399573850212619,0.00011222324974369258,0.00011351713328622282,0.0001107173811760731,0.00010637714876793325,0.00010794744594022632,0.00010582526010693982,0.00010202013072557747,0.00010285752796335146,9.764058631844819e-05,9.865665197139606e-05,9.74890062934719e-05,9.652339940657839e-05,9.35458519961685e-05,9.286723070545122e-05,9.349059109808877e-05,9.286220301873982e-05,9.052412497112527e-05,9.039698488777503e-05,8.777591574471444e-05,8.814067405182868e-05,8.65443580551073e-05,8.507165330229327e-05,8.436714415438473e-05,8.510595944244415e-05,8.230569801526144e-05,8.305945084430277e-05,8.247193181887269e-05,8.104411972453818e-05,7.89595942478627e-05,8.026882278500125e-05,7.969184662215412e-05,7.724724855506793e-05,7.836680015316233e-05,7.41146577638574e-05,7.772789831506088e-05,7.649466715520248e-05,7.349908992182463e-05,7.440939953085035e-05,7.2573842771817e-05,7.354440458584577e-05,7.203262066468596e-05,7.268948684213683e-05,7.104832911863923e-05,7.089853170327842e-05,7.018667383817956e-05,6.970721005927771e-05,6.906615453772247e-05,6.874521204736084e-05,6.847251643193886e-05,6.781089905416593e-05,6.73589383950457e-05,6.746940198354423e-05,6.663546082563698e-05,6.640988431172445e-05,6.538283196277916e-05,6.515876157209277e-05,6.442043377319351e-05,6.419136479962617e-05,6.298374501056969e-05,6.420150020858273e-05,6.356817902997136e-05,
mae,0.20122791826725006,0.127421572804451,0.09111693501472473,0.04573628306388855,0.029303085058927536,0.02463758923113346,0.021461796015501022,0.019175928086042404,0.01768490858376026,0.016238411888480186,0.015099807642400265,0.014259479008615017,0.013589123263955116,0.01299835555255413,0.012476645410060883,0.012187983840703964,0.012001224793493748,0.011509736999869347,0.011156678199768066,0.010952252894639969,0.010733201168477535,0.010624846443533897,0.010294036939740181,0.010175134986639023,0.010010735131800175,0.009797156788408756,0.009744915179908276,0.00960969552397728,0.0094836987555027,0.009274962358176708,0.00920992624014616,0.009088464081287384,0.008984575048089027,0.00897571723908186,0.00885479710996151,0.008804090321063995,0.008701557293534279,0.008592025376856327,0.008412251248955727,0.008405583910644054,0.008419581688940525,0.008340935222804546,0.008150761015713215,0.008247697725892067,0.008190903812646866,0.008042511530220509,0.008025157265365124,0.007795795798301697,0.007931712083518505,0.007822040468454361,0.0077714500948786736,0.0076436251401901245,0.0076593803241848946,0.007725822273641825,0.007672837004065514,0.0075975265353918076,0.007564110215753317,0.007481366395950317,0.007445354480296373,0.00741105992347002,0.007306012324988842,0.007305860985070467,0.007348519749939442,0.007234988268464804,0.0072991615161299706,0.007221108768135309,0.007166943978518248,0.007039711344987154,0.007164849434047937,0.007124505005776882,0.006995386444032192,0.0070695956237614155,0.006797775626182556,0.007053482346236706,0.0069951582700014114,0.006788493599742651,0.006883640773594379,0.006817621178925037,0.0067846341989934444,0.00676344521343708,0.006767204962670803,0.006725681480020285,0.006730345543473959,0.006673285737633705,0.006635338068008423,0.006609431933611631,0.006605855189263821,0.006594608537852764,0.0065873730927705765,0.0065304310992360115,0.006494624074548483,0.006542333867400885,0.006449871230870485,0.006459261756390333,0.006439298391342163,0.006437792908400297,0.006391655188053846,0.00632817205041647,0.0064047579653561115,0.006346569862216711,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2475      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2476      
=================================================================
Total params: 4,951
Trainable params: 4,951
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 2,475
Trainable params: 2,475
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 2,476
Trainable params: 2,476
Non-trainable params: 0
_________________________________________________________________
