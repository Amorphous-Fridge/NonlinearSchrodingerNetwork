2021-06-26
loss,0.5418983697891235,0.2570200562477112,0.24874307215213776,0.2397996336221695,0.2228180170059204,0.2218599170446396,0.16199082136154175,0.10897409170866013,0.12078547477722168,0.11083319038152695,0.09547142684459686,0.08061418682336807,0.0766792744398117,0.06453429162502289,0.06947319209575653,0.06458486616611481,0.0608663409948349,0.06615015119314194,0.062244344502687454,0.06483989208936691,0.04891635477542877,0.05001478269696236,0.04219886288046837,0.043537549674510956,0.05506254732608795,0.05053841695189476,0.04782421886920929,0.04460100084543228,0.04496733844280243,0.042693667113780975,0.04110869765281677,0.03771832212805748,0.04003729298710823,0.03705241531133652,0.03783777356147766,0.036994755268096924,0.039702996611595154,0.03199559077620506,0.03281226009130478,0.03283586725592613,0.03287708759307861,0.03539612144231796,0.032086681574583054,0.03245113790035248,0.028813231736421585,0.031467124819755554,0.02770763449370861,0.030449315905570984,0.03110544942319393,0.026811864227056503,0.02596271224319935,0.025107061490416527,0.03067835420370102,0.029416877776384354,0.026573965325951576,0.02903302200138569,0.026460930705070496,0.027879290282726288,0.026738755404949188,0.024207284674048424,0.02768184244632721,0.02443217672407627,0.02389894798398018,0.02859468199312687,0.024386536329984665,0.02571972645819187,0.022450193762779236,0.020602336153388023,0.022214693948626518,0.025269530713558197,0.023886052891612053,0.026186108589172363,0.022265035659074783,0.021786518394947052,0.019234180450439453,0.019083084538578987,0.023108957335352898,0.02434210479259491,0.022515473887324333,0.021134044975042343,0.023532168939709663,0.022798165678977966,0.02184351533651352,0.02163449116051197,0.01983896642923355,0.019462570548057556,0.023089785128831863,0.020355576649308205,0.019385389983654022,0.016763264313340187,0.018080230802297592,0.02197466418147087,0.022897321730852127,0.019706856459379196,0.022853929549455643,0.019222984090447426,0.01938031241297722,0.019592074677348137,0.01724541373550892,0.018177445977926254,
mse,0.13103963434696198,0.02124873548746109,0.02030084654688835,0.019237766042351723,0.016746962442994118,0.015419971197843552,0.007898333482444286,0.003538598772138357,0.004195749759674072,0.003473232965916395,0.0026087278965860605,0.001821310492232442,0.0016492435242980719,0.0011901587713509798,0.0013381007593125105,0.0012062682071700692,0.001065902761183679,0.0012286943383514881,0.0010970256989821792,0.0012016878463327885,0.0006873626261949539,0.0007171581964939833,0.0005013089394196868,0.0005647921352647245,0.0008728519314900041,0.0007168134907260537,0.0006326732109300792,0.000554115860722959,0.0005580261931754649,0.0005265056970529258,0.00046793167712166905,0.00039803553954698145,0.0004475382447708398,0.00037685196730308235,0.0004099025100003928,0.00039017025846987963,0.00043922863551415503,0.00029926796560175717,0.0003080116002820432,0.0003003238816745579,0.00030982232419773936,0.0003474195546004921,0.0002920663100667298,0.00029037476633675396,0.0002359857753617689,0.0002839116204995662,0.00021631443814840168,0.0002616239944472909,0.000266813556663692,0.00020697027503047138,0.00019145240366924554,0.00018489999638404697,0.0002613999240566045,0.00023969986068550497,0.0001958263892447576,0.00023690371017437428,0.00019663915736600757,0.0002135011600330472,0.00019568509014789015,0.000167514881468378,0.00021224337979219854,0.0001707366609480232,0.00016771076479926705,0.00022619044466409832,0.00016543036326766014,0.00018398716929368675,0.00014324262156151235,0.00012396916281431913,0.0001426254166290164,0.00017580419080331922,0.00015962887846399099,0.00019145445548929274,0.00013879621110390872,0.00013463695358950645,0.0001064540192601271,0.00010841009498108178,0.000149452593177557,0.00016551704902667552,0.00014383178495336324,0.00012741098180413246,0.00015393445210065693,0.00014486217696685344,0.00013373844558373094,0.0001298356510233134,0.00011135388194816187,0.00010955529432976618,0.00014973107317928225,0.00011587960761971772,0.00010475340241100639,8.385486580664292e-05,9.704849071567878e-05,0.00013645103899762034,0.0001506207772763446,0.00011120527051389217,0.00014557586109731346,0.00010561254748608917,0.00010499297786736861,0.00010691792704164982,8.748093387112021e-05,9.671458974480629e-05,
mae,0.22859178483486176,0.11020594835281372,0.10921012610197067,0.10477086901664734,0.0964011549949646,0.0957261472940445,0.06914356350898743,0.04582766443490982,0.050877247005701065,0.04674778878688812,0.040464531630277634,0.03433480113744736,0.032496992498636246,0.027150044217705727,0.02985106222331524,0.027480825781822205,0.025672484189271927,0.028457431122660637,0.02586309425532818,0.027683094143867493,0.02077564224600792,0.021261069923639297,0.018125686794519424,0.018537230789661407,0.023156888782978058,0.0219329334795475,0.020404161885380745,0.018979525193572044,0.019166192039847374,0.018245086073875427,0.017575424164533615,0.016054239124059677,0.017215082421898842,0.015565509907901287,0.01603640243411064,0.01580066606402397,0.017235785722732544,0.013553650118410587,0.013998854905366898,0.013819806277751923,0.014046980999410152,0.015213556587696075,0.013810237869620323,0.013413358479738235,0.011987336911261082,0.013529783114790916,0.011779330670833588,0.012995145283639431,0.013265017420053482,0.011177774518728256,0.010981177911162376,0.010642178356647491,0.013203891925513744,0.012599829584360123,0.011213227175176144,0.012299975380301476,0.011285580694675446,0.011799083091318607,0.011471671983599663,0.010281303897500038,0.011932933703064919,0.010428063571453094,0.010126691311597824,0.012207429856061935,0.010225419886410236,0.010904145427048206,0.009610364213585854,0.008610954508185387,0.009458698332309723,0.010807129554450512,0.010076675564050674,0.011197836138308048,0.009544284082949162,0.009324871003627777,0.008115759119391441,0.00806332565844059,0.00981927290558815,0.010360140353441238,0.009495564736425877,0.008900436572730541,0.01010345108807087,0.009684891439974308,0.009009736590087414,0.009304828941822052,0.00854469370096922,0.008161024190485477,0.00996064580976963,0.00856763869524002,0.008132973685860634,0.007160601206123829,0.007649072911590338,0.009195652790367603,0.009701315313577652,0.008383030071854591,0.009756054729223251,0.008154968731105328,0.008236738853156567,0.008279016241431236,0.007230812683701515,0.00770006887614727,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 69475     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 69476     
=================================================================
Total params: 138,951
Trainable params: 138,951
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 69,475
Trainable params: 69,475
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 69,476
Trainable params: 69,476
Non-trainable params: 0
_________________________________________________________________
