2021-06-26
loss,2.808286190032959,2.224081039428711,2.210799217224121,2.202298641204834,1.6550698280334473,0.42466163635253906,0.33465373516082764,0.3009572923183441,0.24352678656578064,0.2372814416885376,0.23188048601150513,0.2309122234582901,0.22764405608177185,0.2244860678911209,0.2202415019273758,0.21601355075836182,0.20738419890403748,0.20287393033504486,0.17910701036453247,0.12973618507385254,0.1136026382446289,0.09818543493747711,0.10978515446186066,0.09110487252473831,0.07490003108978271,0.0824052169919014,0.07258094102144241,0.06361455470323563,0.07159513235092163,0.06171395257115364,0.049044523388147354,0.0740262046456337,0.06400540471076965,0.061317987740039825,0.054934244602918625,0.05469838157296181,0.05037536099553108,0.045836690813302994,0.05205048993229866,0.046384695917367935,0.04324899613857269,0.045292723923921585,0.04995410144329071,0.048270221799612045,0.044377651065588,0.04238632321357727,0.03850996866822243,0.04022428020834923,0.031661465764045715,0.03443717584013939,0.030089031904935837,0.04326886311173439,0.044851433485746384,0.03828754276037216,0.04115884751081467,0.03664403781294823,0.03389236330986023,0.041603390127420425,0.039605751633644104,0.03518030792474747,0.03412957116961479,0.03989327326416969,0.03790581598877907,0.033365048468112946,0.03730887919664383,0.032540250569581985,0.030829938128590584,0.03658541291952133,0.03401565179228783,0.034149348735809326,0.031728971749544144,0.033055275678634644,0.02542867697775364,0.03353022411465645,0.03554977476596832,0.03186173737049103,0.033198121935129166,0.029980674386024475,0.02845781110227108,0.030282462015748024,0.030668726190924644,0.03186533600091934,0.02750466577708721,0.031032424420118332,0.02970067411661148,0.034735750406980515,0.03035261668264866,0.025827908888459206,0.030387071892619133,0.027875497937202454,0.027989111840724945,0.03295367211103439,0.02885723114013672,0.028097962960600853,0.029631929472088814,0.028590045869350433,0.025340504944324493,0.03003718890249729,0.028469691053032875,0.026423044502735138,
mse,2.1208202838897705,1.2500537633895874,1.2355856895446777,1.2265572547912598,0.799410343170166,0.05323246121406555,0.03371281921863556,0.02811000868678093,0.020027413964271545,0.019326042383909225,0.01884463243186474,0.01871310919523239,0.018307693302631378,0.01780584082007408,0.01714462973177433,0.016445083543658257,0.01474197581410408,0.01342035923153162,0.009861704893410206,0.005201952066272497,0.003936416003853083,0.002957551972940564,0.0037279801908880472,0.002471350133419037,0.0017315046861767769,0.001962770475074649,0.0015050157671794295,0.0012039835564792156,0.0014843441313132644,0.0011351293651387095,0.0007366123609244823,0.0015506802592426538,0.0011922051198780537,0.0011027627624571323,0.0008700889302417636,0.000853655394166708,0.0007075878093019128,0.0006452271481975913,0.0008013730403035879,0.0006227248813956976,0.0005397513741627336,0.0005847556167282164,0.0007221235428005457,0.0006655394099652767,0.0005735043669119477,0.0005278689786791801,0.0004509512218646705,0.0004609478637576103,0.0003032842942047864,0.0003610861022025347,0.0002716227900236845,0.0005540085257962346,0.0005733587895520031,0.000439097813796252,0.00047273284872062504,0.0003907980280928314,0.00033593724947422743,0.0004900736385025084,0.0004507963021751493,0.0003545130311977118,0.00033554251422174275,0.00045023925486020744,0.00042096921242773533,0.0003182672371622175,0.0003921366005670279,0.00030184219940565526,0.0002756867033895105,0.00038807568489573896,0.0003323594864923507,0.0003395848034415394,0.00028461613692343235,0.0003112780104856938,0.00019044494547415525,0.0003274711489211768,0.00035114577622152865,0.000294431927613914,0.00032009981805458665,0.00025930372066795826,0.00023696041898801923,0.0002619544102344662,0.00027461550780571997,0.0002907496818806976,0.00021617232414428145,0.00027150718960911036,0.00026081179385073483,0.00034239646629430354,0.0002587516501080245,0.00019509713456500322,0.0002624937624204904,0.00022314907982945442,0.000225384981604293,0.00030445135780610144,0.000232470003538765,0.00023206482001114637,0.00024952023522928357,0.00023012793099042028,0.00019242898270022124,0.00024945870973169804,0.0002289800759172067,0.00019892412819899619,
mae,1.1189401149749756,0.659019947052002,0.6199400424957275,0.6009066104888916,0.6376468539237976,0.1844720095396042,0.14552398025989532,0.12740963697433472,0.10060098022222519,0.09807984530925751,0.09610021859407425,0.09695693105459213,0.09691891819238663,0.09719282388687134,0.09491021186113358,0.0928535908460617,0.08863671123981476,0.08711802214384079,0.07677824795246124,0.055166494101285934,0.048740312457084656,0.042174115777015686,0.04705429449677467,0.03871619701385498,0.03133350983262062,0.03457322344183922,0.030451355502009392,0.027072716504335403,0.030949998646974564,0.026274630799889565,0.02090752311050892,0.03178027272224426,0.027703184634447098,0.026724202558398247,0.023599402979016304,0.02370091713964939,0.02162214368581772,0.019321145489811897,0.022525422275066376,0.019412808120250702,0.018418461084365845,0.01914595253765583,0.021603908389806747,0.020841998979449272,0.018809784203767776,0.0181276835501194,0.016503946855664253,0.016847439110279083,0.013324453495442867,0.01476459950208664,0.012951229698956013,0.018599096685647964,0.019626261666417122,0.016410674899816513,0.01788966730237007,0.015571396797895432,0.014278329908847809,0.017917253077030182,0.01719306781888008,0.014957201667129993,0.014571387320756912,0.017409473657608032,0.01644488237798214,0.014064056798815727,0.0160366278141737,0.013793639838695526,0.013095434755086899,0.01559477485716343,0.014443001709878445,0.014699671417474747,0.013315183110535145,0.014053147286176682,0.010823910124599934,0.014347719959914684,0.015212646685540676,0.013523709960281849,0.014249670319259167,0.012686151079833508,0.012071453034877777,0.013054338283836842,0.01313178613781929,0.013663968071341515,0.011453162878751755,0.013561764732003212,0.012943148612976074,0.015072562731802464,0.012866935692727566,0.01089667808264494,0.012859032489359379,0.011831640265882015,0.01168049592524767,0.014072740450501442,0.012053344398736954,0.01200935523957014,0.012672935612499714,0.012174416333436966,0.010893737897276878,0.013078736141324043,0.012251453474164009,0.011236011050641537,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 269427    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 269428    
=================================================================
Total params: 538,855
Trainable params: 538,855
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 269,427
Trainable params: 269,427
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 269,428
Trainable params: 269,428
Non-trainable params: 0
_________________________________________________________________
