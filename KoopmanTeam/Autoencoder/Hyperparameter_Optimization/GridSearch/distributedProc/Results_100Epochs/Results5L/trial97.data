2021-06-26
loss,2.4503724575042725,2.206862688064575,2.199638605117798,2.1996266841888428,2.242704391479492,1.2142810821533203,0.2283613383769989,0.18017296493053436,0.1425849050283432,0.10297614336013794,0.08374019712209702,0.0868682786822319,0.09760717302560806,0.11045835167169571,0.0915549099445343,0.08963298052549362,0.06858033686876297,0.08415113389492035,0.07755438983440399,0.06246434152126312,0.056065239012241364,0.05904143303632736,0.0698881447315216,0.07443248480558395,0.05372842773795128,0.05727849155664444,0.06497590243816376,0.05179990828037262,0.047635890543460846,0.05030098557472229,0.045179225504398346,0.05972651019692421,0.0613483302295208,0.0519920215010643,0.05615741387009621,0.05303100124001503,0.04549523442983627,0.053059834986925125,0.04318583011627197,0.043183740228414536,0.05650705844163895,0.05144071578979492,0.04672889783978462,0.049388837069272995,0.04123423993587494,0.03967168927192688,0.039967022836208344,0.04372034966945648,0.05179263651371002,0.04682692512869835,0.041236475110054016,0.04058249294757843,0.03664925694465637,0.040158066898584366,0.041500795632600784,0.037416163831949234,0.03874700143933296,0.04315660148859024,0.04232502356171608,0.044959090650081635,0.03583561256527901,0.037768010050058365,0.033491410315036774,0.04088294878602028,0.04270819574594498,0.035507090389728546,0.040486980229616165,0.040373239666223526,0.03380562365055084,0.039619170129299164,0.03907253220677376,0.03543057665228844,0.02861860767006874,0.031366754323244095,0.03682047873735428,0.035948049277067184,0.03180179372429848,0.0326765738427639,0.03877776488661766,0.03363245725631714,0.029925130307674408,0.03318982571363449,0.031163012608885765,0.032057538628578186,0.029028166085481644,0.03610190376639366,0.032603491097688675,0.03300347179174423,0.03881802409887314,0.03371848165988922,0.03434760123491287,0.030206836760044098,0.033258482813835144,0.03056730329990387,0.03102547861635685,0.03334128484129906,0.030447790399193764,0.03288612514734268,0.02995484322309494,0.034792184829711914,
mse,1.5678693056106567,1.231045126914978,1.2233368158340454,1.2232834100723267,1.2727243900299072,0.538219690322876,0.015693414956331253,0.009499050676822662,0.0061387778259813786,0.0030220455955713987,0.0019384718034416437,0.0021971254609525204,0.00269042095169425,0.0033710754942148924,0.002300170250236988,0.0022563396487385035,0.0013211453333497047,0.0019497814355418086,0.0016615588683634996,0.001149890711531043,0.0008903134148567915,0.001015246263705194,0.0014156069373711944,0.0014998852275311947,0.0008470129687339067,0.0009390156483277678,0.0011972334468737245,0.0007512304000556469,0.000663129088934511,0.0007005338557064533,0.0005580622237175703,0.0009692058665677905,0.0010523481760174036,0.0007732564699836075,0.0008697288576513529,0.0007840623729862273,0.0005781173822470009,0.0008020329405553639,0.0005119387642480433,0.0005327683757059276,0.0008762249490246177,0.0007269866182468832,0.000623420113697648,0.0006890205550007522,0.00047662892029620707,0.00042089165071956813,0.0004554104816634208,0.0005392056773416698,0.0007082708179950714,0.0005954138468950987,0.0004763250472024083,0.00045638371375389397,0.00037022249307483435,0.0004562300746329129,0.0004770267987623811,0.00038930121809244156,0.0004435326554812491,0.000510641373693943,0.0005006310530006886,0.0005551853682845831,0.00036610907409340143,0.00039528831257484853,0.00031579629285261035,0.0004678075492847711,0.0005012400797568262,0.0003490477683953941,0.0004558399668894708,0.0004425312508828938,0.00032387045212090015,0.0004429803811945021,0.0004164476995356381,0.0003349919861648232,0.000237506435951218,0.00028997124172747135,0.0003801073762588203,0.0003490105737000704,0.0002835855120792985,0.00029671721858903766,0.00041429902194067836,0.0003091659746132791,0.0002683622296899557,0.00030622296617366374,0.00027121714083477855,0.0002793731400743127,0.00023512197367381305,0.00035896210465580225,0.0002976736577693373,0.00031000300077721477,0.0004137854266446084,0.00031431642128154635,0.00032230731449089944,0.0002546789182815701,0.0003015803813468665,0.00026302921469323337,0.00026990490732714534,0.00030798514490015805,0.0002586829068604857,0.0002964537125080824,0.0002483889402355999,0.00032300991006195545,
mae,0.8554970026016235,0.6055460572242737,0.567004382610321,0.5646519064903259,0.6798240542411804,0.44045230746269226,0.09571180492639542,0.0765802413225174,0.06218511611223221,0.04224519431591034,0.034927092492580414,0.03670308738946915,0.04141223430633545,0.048364218324422836,0.03989658132195473,0.03845691308379173,0.028163960203528404,0.03675908222794533,0.03449114412069321,0.025336964055895805,0.02336137928068638,0.02501489408314228,0.029663844034075737,0.03335157781839371,0.023638784885406494,0.02382238209247589,0.02762940712273121,0.021129099652171135,0.020241284742951393,0.02141309715807438,0.019197266548871994,0.02610778994858265,0.027501141652464867,0.022213874384760857,0.023374177515506744,0.021767443045973778,0.019381070509552956,0.021824054419994354,0.018078362569212914,0.018535364419221878,0.024007543921470642,0.02290535718202591,0.019775962457060814,0.021735526621341705,0.017372459173202515,0.01642501913011074,0.01642461307346821,0.018625304102897644,0.02327529340982437,0.021078109741210938,0.017591197043657303,0.016175229102373123,0.01530227530747652,0.016508551314473152,0.017776913940906525,0.01565956324338913,0.01669069565832615,0.018812300637364388,0.017746413126587868,0.019408822059631348,0.015562143176794052,0.01597786508500576,0.014368784613907337,0.017607707530260086,0.01903698407113552,0.015453862026333809,0.017157239839434624,0.018202750012278557,0.014563844539225101,0.017460744827985764,0.018080394715070724,0.015981948003172874,0.012127559632062912,0.013409328646957874,0.016079870983958244,0.015393015928566456,0.013423084281384945,0.01365708839148283,0.01661420799791813,0.013791576959192753,0.012854626402258873,0.013680560514330864,0.013175741769373417,0.013614196330308914,0.012323529459536076,0.015118010342121124,0.013701221905648708,0.014004378579556942,0.01720932126045227,0.014765104278922081,0.015242869034409523,0.0128781758248806,0.014137671329081059,0.012964562512934208,0.01323774829506874,0.013682111166417599,0.012764513492584229,0.014103684574365616,0.012571454048156738,0.01533119659870863,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 222659    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 222660    
=================================================================
Total params: 445,319
Trainable params: 445,319
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 222,659
Trainable params: 222,659
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 222,660
Trainable params: 222,660
Non-trainable params: 0
_________________________________________________________________
