2021-06-26
loss,0.8176283836364746,0.3082498013973236,0.24556155502796173,0.19733776152133942,0.15848267078399658,0.14226408302783966,0.11772079765796661,0.13517425954341888,0.12883508205413818,0.09095489233732224,0.08272318542003632,0.078501395881176,0.06916926056146622,0.07659074664115906,0.06738357245922089,0.06320609897375107,0.06725776940584183,0.06042562052607536,0.06138892099261284,0.0579085536301136,0.05068971961736679,0.0446474552154541,0.04838579148054123,0.05269312858581543,0.04411901906132698,0.0406169593334198,0.03895063325762749,0.042125243693590164,0.042444247752428055,0.03752279654145241,0.04204750433564186,0.04539523646235466,0.038807809352874756,0.02980717457830906,0.037876203656196594,0.03580676391720772,0.030013151466846466,0.026883326470851898,0.03440411761403084,0.028739042580127716,0.028854239732027054,0.03161716088652611,0.02593281678855419,0.025763757526874542,0.031163888052105904,0.03232178837060928,0.0332227386534214,0.02958284318447113,0.025871334597468376,0.02866167388856411,0.027678245678544044,0.02993849478662014,0.026483425870537758,0.025274265557527542,0.026302268728613853,0.025939209386706352,0.025014925748109818,0.023348119109869003,0.027222540229558945,0.02609712816774845,0.025491511449217796,0.023858439177274704,0.025068819522857666,0.022029587998986244,0.02359403669834137,0.02384430728852749,0.02240712381899357,0.021340956911444664,0.020811330527067184,0.023618780076503754,0.02156680077314377,0.021296804770827293,0.02132328972220421,0.01962883025407791,0.020210400223731995,0.023572752252221107,0.020987985655665398,0.02262055315077305,0.02071579545736313,0.019626209512352943,0.02051975578069687,0.019911129027605057,0.019907498732209206,0.021107569336891174,0.0193353109061718,0.020090853795409203,0.020386982709169388,0.02179860509932041,0.02023961953818798,0.01954786852002144,0.019936997443437576,0.01713472791016102,0.01982995681464672,0.020095355808734894,0.020431797951459885,0.019591892138123512,0.018056752160191536,0.020061898976564407,0.018721699714660645,0.01776667684316635,
mse,0.31681036949157715,0.029343893751502037,0.01745360717177391,0.012073052115738392,0.007181114982813597,0.005790736060589552,0.0038920671213418245,0.005256088450551033,0.004714692011475563,0.0023582635913044214,0.0019892819691449404,0.001748133567161858,0.0013616856886073947,0.0016977143241092563,0.0012883198214694858,0.0011476435465738177,0.0012480299919843674,0.00104706478305161,0.0010374775156378746,0.000938001147005707,0.0007249268819577992,0.00057815364561975,0.0006723791593685746,0.0007618805975653231,0.0005497443489730358,0.00046710745664313436,0.00044294900726526976,0.0004922986263409257,0.0005060532130300999,0.00039804584230296314,0.000506544136442244,0.0005687234806828201,0.0004222053976263851,0.0002649101079441607,0.0004186149744782597,0.00035721331369131804,0.0002592710079625249,0.00021087074128445238,0.0003367920289747417,0.0002380257792538032,0.0002493212232366204,0.00028081881464459,0.00019434939895290881,0.00019357381097506732,0.00027945550391450524,0.00028579591889865696,0.0003064614429604262,0.0002493385982234031,0.00019774494285229594,0.00023046314890962094,0.0002152545057469979,0.0002484176366124302,0.00019977526972070336,0.00018172165437135845,0.00019519370107445866,0.00019299630366731435,0.00018155552970711142,0.0001556730130687356,0.0002116719406330958,0.00019631047325674444,0.00018022110452875495,0.0001655941887293011,0.0001745305780787021,0.0001395580911776051,0.00015683737001381814,0.00016093732847366482,0.0001461333449697122,0.00012937454448547214,0.00012794326175935566,0.00015628246183041483,0.00013336956908460706,0.00013061460049357265,0.0001290091749979183,0.00011022661783499643,0.00012061914458172396,0.00015488332428503782,0.0001264229358639568,0.00014509724860545248,0.00012190264533273876,0.0001122318280977197,0.00012221693759784102,0.00011321882629999891,0.0001134561825892888,0.0001292920351261273,0.00010888151155086234,0.00011552571959327906,0.00011699862079694867,0.00013489648699760437,0.00011347340478096157,0.00011013595212716609,0.00011554685625014827,8.702806371729821e-05,0.0001123406836995855,0.00011029552842956036,0.00011718602036125958,0.00010788581130327657,9.375857189297676e-05,0.00011428547441028059,0.00010039766493719071,8.966548193711787e-05,
mae,0.35116276144981384,0.13442157208919525,0.10432732850313187,0.0864158421754837,0.06710189580917358,0.06082804501056671,0.05036531388759613,0.05838023126125336,0.055385101586580276,0.03895885497331619,0.035767439752817154,0.03323734924197197,0.02945014089345932,0.03314267098903656,0.028570983558893204,0.02691447176039219,0.02932373248040676,0.02613259293138981,0.026140714064240456,0.025013960897922516,0.02146701142191887,0.018993031233549118,0.020424211397767067,0.023066803812980652,0.01852729730308056,0.017044737935066223,0.0165290255099535,0.01775362156331539,0.017868036404252052,0.015923481434583664,0.01800701580941677,0.020098572596907616,0.016728954389691353,0.01268219668418169,0.016626207157969475,0.015058486722409725,0.012628650292754173,0.011517362669110298,0.014806138351559639,0.012147613801062107,0.01230313815176487,0.013431894592940807,0.010954005643725395,0.010936396196484566,0.013347029685974121,0.01371534913778305,0.014477000571787357,0.012542997486889362,0.010935830883681774,0.012276564724743366,0.011828802525997162,0.012697501108050346,0.011236157268285751,0.010858641937375069,0.011071911081671715,0.011101040989160538,0.010626598261296749,0.00973273254930973,0.011830968782305717,0.011169424280524254,0.010988853871822357,0.010113636031746864,0.010628502815961838,0.009261867962777615,0.009982101619243622,0.010181257501244545,0.009596951305866241,0.00902625173330307,0.00889595877379179,0.01014345046132803,0.009057410061359406,0.00906960479915142,0.009003988467156887,0.00833057425916195,0.00861663930118084,0.010061761364340782,0.008898167870938778,0.009857908822596073,0.008775826543569565,0.00830781552940607,0.008728756569325924,0.008411869406700134,0.008505662903189659,0.00889911875128746,0.008260132744908333,0.008623666130006313,0.008746586740016937,0.00947663839906454,0.00869779847562313,0.008254678919911385,0.008344888687133789,0.007242585998028517,0.008384503424167633,0.008542623370885849,0.00886472687125206,0.008327108807861805,0.007633581291884184,0.00859853159636259,0.007949483580887318,0.007575551047921181,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 140323    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 140324    
=================================================================
Total params: 280,647
Trainable params: 280,647
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 140,323
Trainable params: 140,323
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 140,324
Trainable params: 140,324
Non-trainable params: 0
_________________________________________________________________
