2021-06-26
loss,0.3972380757331848,0.10980803519487381,0.08260604739189148,0.07952215522527695,0.0594078004360199,0.06420496106147766,0.048030704259872437,0.05621880665421486,0.050419602543115616,0.05165990814566612,0.05591776221990585,0.05148450285196304,0.045881420373916626,0.04605424776673317,0.048333145678043365,0.0443262942135334,0.046602144837379456,0.04095422849059105,0.03680471330881119,0.030858082696795464,0.03032802604138851,0.04144033417105675,0.038780197501182556,0.036183394491672516,0.031694911420345306,0.023544277995824814,0.022535793483257294,0.022104239091277122,0.021338069811463356,0.021386325359344482,0.021078472957015038,0.020794644951820374,0.021341586485505104,0.023061072453856468,0.020956560969352722,0.020791731774806976,0.020175030454993248,0.019950486719608307,0.019627146422863007,0.019521957263350487,0.019237490370869637,0.01924133114516735,0.01907786913216114,0.01868513412773609,0.018730059266090393,0.018682856112718582,0.01847604475915432,0.018431734293699265,0.018313484266400337,0.018009545281529427,0.018246641382575035,0.017988357692956924,0.01789361983537674,0.01767880469560623,0.01764701120555401,0.01747361570596695,0.01739112287759781,0.01719062216579914,0.017003189772367477,0.016873277723789215,0.016956502571702003,0.01681198924779892,0.016717541962862015,0.016671549528837204,0.016728978604078293,0.01634075492620468,0.016415508463978767,0.016316931694746017,0.01751815155148506,0.024562019854784012,0.02764742448925972,0.026238085702061653,0.025194235146045685,0.025322601199150085,0.026849379763007164,0.025966353714466095,0.02493332140147686,0.02468475140631199,0.02522299811244011,0.023317748680710793,0.021359236910939217,0.02266576699912548,0.024507718160748482,0.021798983216285706,0.020532384514808655,0.022060193121433258,0.020774098113179207,0.02005000039935112,0.014686898328363895,0.014175930060446262,0.013888316228985786,0.013809309341013432,0.01373007521033287,0.013666336424648762,0.013681244105100632,0.013558703474700451,0.01351776160299778,0.013516677543520927,0.013324996456503868,0.01336494367569685,
mse,0.07429210841655731,0.003898069029673934,0.002094583585858345,0.0018750086892396212,0.0010838586604222655,0.001261724391952157,0.0007217348320409656,0.0009572561248205602,0.0007765254122205079,0.0008364925743080676,0.0009304111590608954,0.0008056971710175276,0.0006134643917903304,0.0006224082899279892,0.0006962931947782636,0.0005694734281860292,0.000641186663415283,0.0004936427576467395,0.0003952258557546884,0.0002874996862374246,0.0002864483976736665,0.0004900815547443926,0.0004404012579470873,0.0003864653699565679,0.0002994908136315644,0.0001685551251284778,0.00015244417591020465,0.00014489587920252234,0.0001354082633042708,0.0001344102929579094,0.0001308632199652493,0.00012803339632228017,0.00013839305029250681,0.0001643596333451569,0.0001326787896687165,0.00012497160059865564,0.0001183890926768072,0.00011563247244339436,0.0001128078656620346,0.00011099928815383464,0.00010848171223187819,0.00010926090180873871,0.00010609779565129429,0.00010393057891633362,0.00010195501818088815,0.00010247730824630708,9.855790267465636e-05,9.882936137728393e-05,9.734854393173009e-05,9.45439314818941e-05,0.00010034540900960565,9.461083391215652e-05,9.286173735745251e-05,9.156949818134308e-05,9.072551620192826e-05,8.919186802813783e-05,8.713905845070258e-05,8.513971260981634e-05,8.416683704126626e-05,8.392720337724313e-05,8.309708937304094e-05,8.219870505854487e-05,8.160983998095617e-05,8.190239896066487e-05,8.057477680267766e-05,7.77105160523206e-05,7.833783456590027e-05,7.826298678992316e-05,9.442074224352837e-05,0.00018079440633300692,0.00022305412858258933,0.00019907925161533058,0.0001890025450848043,0.0001859201438492164,0.00020856395713053644,0.0001917020563269034,0.00017807552649173886,0.00017629482317715883,0.0001841397606767714,0.0001550650631543249,0.0001384563511237502,0.00015181511116679758,0.0001706240145722404,0.00014193799870554358,0.00012345437426120043,0.0001445016241632402,0.00012896570842713118,0.00012464830069802701,6.431635119952261e-05,5.897002120036632e-05,5.688480450771749e-05,5.608942228718661e-05,5.535915624932386e-05,5.483847053255886e-05,5.498265090864152e-05,5.421665628091432e-05,5.32421181560494e-05,5.375589171308093e-05,5.200895975576714e-05,5.223618427407928e-05,
mae,0.16994503140449524,0.04681514576077461,0.035244159400463104,0.033942364156246185,0.02494850568473339,0.026588084176182747,0.02016734890639782,0.02355254255235195,0.021213848143815994,0.021416330710053444,0.023315398022532463,0.021584095433354378,0.01937001384794712,0.01944972202181816,0.020400185137987137,0.018726520240306854,0.019918052479624748,0.017232518643140793,0.015425325371325016,0.012952432967722416,0.012795922346413136,0.01763889007270336,0.016379600390791893,0.01539052464067936,0.013393622823059559,0.010005506686866283,0.009585067629814148,0.009407734498381615,0.009072734974324703,0.009081325493752956,0.008934501558542252,0.00878223404288292,0.009073156863451004,0.00983109138906002,0.008852466009557247,0.008825471624732018,0.008571596816182137,0.008423668332397938,0.008297063410282135,0.008300941437482834,0.00818354170769453,0.008146501146256924,0.00809017289429903,0.007943703792989254,0.0079141054302454,0.00791383720934391,0.007851692847907543,0.007856630720198154,0.0077098822221159935,0.007566298358142376,0.007756586652249098,0.00763543788343668,0.007582796271890402,0.0074827284552156925,0.0074867429211735725,0.007333742454648018,0.007343447767198086,0.007275210693478584,0.007205218076705933,0.007201989181339741,0.007198506034910679,0.0071091316640377045,0.007117716129869223,0.007093382999300957,0.007064233534038067,0.006977317854762077,0.006932947784662247,0.006958844605833292,0.0074267033487558365,0.010450753383338451,0.011719414964318275,0.011010744608938694,0.010641973465681076,0.01067301258444786,0.011448740027844906,0.010814407840371132,0.010479463264346123,0.010597688145935535,0.010767251253128052,0.009958119131624699,0.00905456580221653,0.009623225778341293,0.010578637942671776,0.009363576769828796,0.008851909078657627,0.009338131174445152,0.00883383397012949,0.008390597067773342,0.006264831405133009,0.006029036827385426,0.005846493877470493,0.005820341873914003,0.005769883282482624,0.0057352096773684025,0.005742379929870367,0.005753168836236,0.005664239637553692,0.0057308971881866455,0.005657882895320654,0.00567465228959918,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17259     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17260     
=================================================================
Total params: 34,519
Trainable params: 34,519
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 17,259
Trainable params: 17,259
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 17,260
Trainable params: 17,260
Non-trainable params: 0
_________________________________________________________________
