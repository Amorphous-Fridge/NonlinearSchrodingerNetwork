2021-06-26
loss,0.3747006952762604,0.10315990447998047,0.07501412183046341,0.0810360535979271,0.07846283912658691,0.06810551881790161,0.042248014360666275,0.04528210684657097,0.048414796590805054,0.059939298778772354,0.06321752816438675,0.05409044772386551,0.04262401908636093,0.042455896735191345,0.03937922790646553,0.045856595039367676,0.048376746475696564,0.04311097040772438,0.03714681416749954,0.03184782341122627,0.028268825262784958,0.03189079463481903,0.03632986918091774,0.04115205630660057,0.036715373396873474,0.03302520141005516,0.029001854360103607,0.03037959523499012,0.03179757669568062,0.03632723167538643,0.03266776725649834,0.028550639748573303,0.026162486523389816,0.024444563314318657,0.02473246492445469,0.028266508132219315,0.036814093589782715,0.03350144252181053,0.028721380978822708,0.02504133991897106,0.023810669779777527,0.023070871829986572,0.018319254741072655,0.017846589908003807,0.017220694571733475,0.01685005985200405,0.0167399849742651,0.016563989222049713,0.016246065497398376,0.01633783057332039,0.016147062182426453,0.016015442088246346,0.015939587727189064,0.01595418155193329,0.015795407816767693,0.015833891928195953,0.015750445425510406,0.015538346953690052,0.015601640567183495,0.016934221610426903,0.022033147513866425,0.025335879996418953,0.026940936222672462,0.025752928107976913,0.021192116662859917,0.02183975651860237,0.024959422647953033,0.027219953015446663,0.026514733210206032,0.02623126283288002,0.025639085099101067,0.02385193668305874,0.023531775921583176,0.021416032686829567,0.019906949251890182,0.0182858444750309,0.0166996531188488,0.015483851544559002,0.024419238790869713,0.023613519966602325,0.021170862019062042,0.023856528103351593,0.02087152749300003,0.020963063463568687,0.021174676716327667,0.01973402313888073,0.018392279744148254,0.01608704961836338,0.018957003951072693,0.023545335978269577,0.02061532996594906,0.018695462495088577,0.01736048422753811,0.016693223267793655,0.023792309686541557,0.024671263992786407,0.02367481403052807,0.021181464195251465,0.019611405208706856,0.02157164365053177,
mse,0.06603419780731201,0.0033632656559348106,0.0017301044426858425,0.0019405640196055174,0.0018277582712471485,0.0013552162563428283,0.0005224596825428307,0.00060702720656991,0.0006693988107144833,0.0010474177543073893,0.0011438564397394657,0.0008328011608682573,0.0005199300358071923,0.0005072977510280907,0.00043272844050079584,0.0006157066090963781,0.000651621026918292,0.0005239981110207736,0.00037953592254780233,0.00028112262953072786,0.00023242503812070936,0.00031670532189309597,0.0003853298840112984,0.0004744941252283752,0.00037809903733432293,0.0003022782038897276,0.0002454225905239582,0.00026225452893413603,0.00029714469565078616,0.0003709677839651704,0.00029792299028486013,0.00022601666569244117,0.00018965033814311028,0.0001687816547928378,0.00017728438251651824,0.000233619604841806,0.0003787374880630523,0.00031386417686007917,0.00022887875093147159,0.00017742680211085826,0.00016398807929363102,0.00015525936032645404,9.761111141415313e-05,9.00301311048679e-05,8.329583943122998e-05,7.979072688613087e-05,7.869472756283358e-05,7.7131247962825e-05,7.428459502989426e-05,7.569274748675525e-05,7.257760444190353e-05,7.216860831249505e-05,7.140931847970933e-05,7.20087336958386e-05,7.0056805270724e-05,7.070007995935157e-05,6.942273466847837e-05,6.886314804432914e-05,6.848100747447461e-05,8.814864850137383e-05,0.00015360856195911765,0.0001871564018074423,0.00020459454390220344,0.00018104583432432264,0.00013361070887185633,0.00014110474148765206,0.0001712531957309693,0.0002031990297837183,0.00019682291895151138,0.00019263973808847368,0.00018293168977834284,0.00015825785521883518,0.0001520956284366548,0.00012865473399870098,0.00011621993326116353,9.880016295937821e-05,8.385378896491602e-05,7.112607272574678e-05,0.00017600554565433413,0.000159135801368393,0.00012587338278535753,0.0001680312561802566,0.00012450786016415805,0.00012811181659344584,0.0001244020095327869,0.00010723999730544165,9.538205631542951e-05,7.716364052612334e-05,0.0001062950977939181,0.00015845461166463792,0.00011969689512625337,9.74965951172635e-05,8.59690917422995e-05,8.259190508397296e-05,0.00016083303489722311,0.0001713938981993124,0.00015576438454445451,0.00012278124631848186,0.00010625080903992057,0.0001326358615187928,
mae,0.15715569257736206,0.043591536581516266,0.031768642365932465,0.03470180183649063,0.034024447202682495,0.02871999889612198,0.018050139769911766,0.019318781793117523,0.02079945243895054,0.025760579854249954,0.027367185801267624,0.023602399975061417,0.0183228999376297,0.018231960013508797,0.016211263835430145,0.019410645589232445,0.020613953471183777,0.018101206049323082,0.01572985202074051,0.013024495914578438,0.011682149954140186,0.013434388674795628,0.01550750806927681,0.017747651785612106,0.015161591582000256,0.014164085499942303,0.01230632048100233,0.012961634434759617,0.013726787641644478,0.01583128422498703,0.01353742927312851,0.012459192425012589,0.011432741768658161,0.010435892269015312,0.010450185276567936,0.012120326980948448,0.01622638665139675,0.014693592675030231,0.012210092507302761,0.010542589239776134,0.010026954114437103,0.009872389025986195,0.007927453145384789,0.007777918595820665,0.007481264416128397,0.007284434046596289,0.007219865918159485,0.007181606721132994,0.00698896124958992,0.007089931983500719,0.006901394575834274,0.006898911204189062,0.006889174692332745,0.0067976657301187515,0.006740220356732607,0.006751874461770058,0.00671533215790987,0.006667465437203646,0.0066696275025606155,0.007187725976109505,0.009271537885069847,0.010746288113296032,0.011512445285916328,0.011335572227835655,0.009091729298233986,0.009284698404371738,0.010808352380990982,0.01176763977855444,0.011406575329601765,0.011348076164722443,0.011042586527764797,0.010415904223918915,0.009782264940440655,0.009170622564852238,0.008413337171077728,0.007802519015967846,0.00716542499139905,0.006667614448815584,0.010558802634477615,0.00978176761418581,0.00906684435904026,0.010336623527109623,0.008969103917479515,0.008898737840354443,0.008881534449756145,0.008485018275678158,0.007818353362381458,0.00684535875916481,0.008123792707920074,0.010023131035268307,0.008754672482609749,0.007868540473282337,0.007333849556744099,0.007020292803645134,0.010249270126223564,0.010727808810770512,0.010378753766417503,0.009028398431837559,0.008495545014739037,0.009366026148200035,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17587     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17588     
=================================================================
Total params: 35,175
Trainable params: 35,175
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 17,587
Trainable params: 17,587
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 17,588
Trainable params: 17,588
Non-trainable params: 0
_________________________________________________________________
