2021-06-26
loss,0.6275854706764221,0.34450283646583557,0.2784789800643921,0.22204376757144928,0.1372443288564682,0.13587559759616852,0.14149145781993866,0.10752186924219131,0.08423303812742233,0.07755515724420547,0.08647534996271133,0.08894075453281403,0.07683717459440231,0.07241079956293106,0.06560438871383667,0.07740745693445206,0.07099128514528275,0.0627957433462143,0.06012747436761856,0.06585019826889038,0.05088451877236366,0.04531564190983772,0.05149248614907265,0.04994618520140648,0.050258535891771317,0.04498398303985596,0.048211563378572464,0.04826957359910011,0.047449130564928055,0.047778788954019547,0.04937967658042908,0.043281178921461105,0.03871144354343414,0.04507852718234062,0.04354187846183777,0.03636270388960838,0.03520742803812027,0.04042162373661995,0.03478441759943962,0.0331665575504303,0.034497931599617004,0.03485307842493057,0.03496427461504936,0.033403169363737106,0.031104128807783127,0.030750107020139694,0.028070731088519096,0.03136470913887024,0.03111206367611885,0.03269360959529877,0.03597463667392731,0.031145742163062096,0.027774011716246605,0.02680162340402603,0.029744591563940048,0.028455868363380432,0.02866004966199398,0.03014974296092987,0.02502618357539177,0.027502205222845078,0.02514820732176304,0.02810278907418251,0.028835278004407883,0.026966195553541183,0.024912141263484955,0.026852469891309738,0.02381877973675728,0.025572802871465683,0.02588433027267456,0.022368283942341805,0.022239448502659798,0.024124296382069588,0.02613208442926407,0.023168178275227547,0.021986544132232666,0.021811408922076225,0.021990638226270676,0.023174159228801727,0.023259492591023445,0.021511178463697433,0.019489608705043793,0.01681266725063324,0.02263965643942356,0.020334439352154732,0.01829834282398224,0.025801196694374084,0.021632695570588112,0.01993577554821968,0.02113812416791916,0.021168045699596405,0.022315502166748047,0.021944789215922356,0.019655421376228333,0.01919192634522915,0.019092366099357605,0.01856030896306038,0.01985802873969078,0.020934216678142548,0.022134488448500633,0.0209023617208004,
mse,0.16646553575992584,0.035022344440221786,0.023327428847551346,0.015135408379137516,0.005652051419019699,0.00548316678032279,0.005906769540160894,0.003281217999756336,0.0020890613086521626,0.0017688419902697206,0.0022512730211019516,0.002262585097923875,0.0016965168761089444,0.0015317195793613791,0.0012130552204325795,0.0016826256178319454,0.0014546725433319807,0.001134678372181952,0.001040891744196415,0.0012142688501626253,0.0007610119646415114,0.0005983174778521061,0.0007382819312624633,0.0007199575775302947,0.0007189749157987535,0.0005785000394098461,0.0006646417896263301,0.0006279177032411098,0.0006495186826214194,0.0006493896944448352,0.0006733851041644812,0.0005321915377862751,0.0004382491752039641,0.0005742367939092219,0.0005284965154714882,0.0003764365101233125,0.00035482668317854404,0.00044626332237385213,0.00034221887472085655,0.0003153518191538751,0.0003396138781681657,0.00035024542012251914,0.0003525737556628883,0.00031629035947844386,0.00027670824783854187,0.00026514887576922774,0.00022285857994575053,0.0002830899611581117,0.00027240137569606304,0.00030969924409873784,0.00035940599627792835,0.00026886994601227343,0.00021959781588520855,0.00020645905169658363,0.0002460055111441761,0.00022468682436738163,0.00022852339316159487,0.00025126495165750384,0.00017889888840727508,0.00020871705783065408,0.00017969441250897944,0.00022166736016515642,0.0002330284332856536,0.0002073937503155321,0.00017373237642459571,0.00020692330144811422,0.00016383439651690423,0.00018389780598226935,0.00018625262600835413,0.0001416552549926564,0.00013961477088741958,0.00016460148617625237,0.00018854519294109195,0.00015230808639898896,0.00013602280523627996,0.0001356422872049734,0.0001394662685925141,0.00015278301725629717,0.0001528398133814335,0.00013087970728520304,0.00010882925562327728,8.366405381821096e-05,0.00014497083611786366,0.00012048502685502172,9.88366809906438e-05,0.00018817973614204675,0.00013163351104594767,0.00011477987573016435,0.00012875440006610006,0.0001284221070818603,0.00014304024807643145,0.00013497094914782792,0.00011004448606399819,0.0001027964026434347,0.00010193484195042402,9.761959518073127e-05,0.00011261520558036864,0.00012442248407751322,0.00013987837883178145,0.00012131251423852518,
mae,0.27213528752326965,0.1491837054491043,0.12004515528678894,0.0945567712187767,0.05868667736649513,0.057645320892333984,0.06110471114516258,0.04570070281624794,0.03486495837569237,0.03307754918932915,0.03633789345622063,0.03929921239614487,0.03270476311445236,0.029875749722123146,0.027880288660526276,0.03349350392818451,0.02999015524983406,0.0266043059527874,0.02528851479291916,0.028508370742201805,0.02118081785738468,0.019138023257255554,0.021892184391617775,0.02105742134153843,0.021497070789337158,0.01931958831846714,0.02044236846268177,0.020692264661192894,0.020005114376544952,0.020490435883402824,0.021383708342909813,0.01823427341878414,0.01673274114727974,0.0189682524651289,0.017730481922626495,0.01554770115762949,0.014943008311092854,0.017649104818701744,0.014918956905603409,0.014249255880713463,0.014856216497719288,0.014857190661132336,0.014747895300388336,0.01407017931342125,0.01313094887882471,0.013070211745798588,0.011909502558410168,0.013218567706644535,0.013324039056897163,0.013935863971710205,0.015801699832081795,0.013525796122848988,0.011896460317075253,0.011344046331942081,0.012593689374625683,0.012109599076211452,0.012198800221085548,0.012688759714365005,0.010587595403194427,0.011337127536535263,0.010337443090975285,0.011701222509145737,0.012323633767664433,0.01132347621023655,0.010534565895795822,0.011444967240095139,0.01008874922990799,0.010879996232688427,0.011196797713637352,0.009580313228070736,0.009449423290789127,0.010228430852293968,0.011014518328011036,0.009717595763504505,0.0092682596296072,0.009208610281348228,0.009349381551146507,0.009686796925961971,0.009794343262910843,0.008886502124369144,0.00811384990811348,0.007071121130138636,0.009626551531255245,0.008628515526652336,0.007716110907495022,0.010702943429350853,0.009457459673285484,0.008691883645951748,0.008942150510847569,0.009068886749446392,0.009552933275699615,0.009394320659339428,0.008378432132303715,0.008041045628488064,0.008123079314827919,0.007810718845576048,0.008378892205655575,0.008824962191283703,0.009319485165178776,0.009092926047742367,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 56035     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 56036     
=================================================================
Total params: 112,071
Trainable params: 112,071
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 56,035
Trainable params: 56,035
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 56,036
Trainable params: 56,036
Non-trainable params: 0
_________________________________________________________________
