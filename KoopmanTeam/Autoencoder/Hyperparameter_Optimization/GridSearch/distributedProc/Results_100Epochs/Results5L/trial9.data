2021-06-26
loss,0.504996120929718,0.199269101023674,0.12336862832307816,0.08355198800563812,0.07059483230113983,0.0621856264770031,0.0557529479265213,0.050598759204149246,0.04707661271095276,0.0448107086122036,0.04286981746554375,0.04142880067229271,0.038851913064718246,0.03756722807884216,0.036202121526002884,0.03570599853992462,0.03440479189157486,0.03399686887860298,0.032601941376924515,0.03222402557730675,0.031330086290836334,0.03087788075208664,0.03035588562488556,0.02966342680156231,0.029132355004549026,0.0287870354950428,0.028368866071105003,0.027714671567082405,0.027624519541859627,0.0271507129073143,0.026689041405916214,0.026582734659314156,0.026095818728208542,0.025801554322242737,0.02567441202700138,0.025296296924352646,0.024931790307164192,0.024800680577754974,0.024446964263916016,0.024285247549414635,0.02404167503118515,0.02390441484749317,0.02355922944843769,0.023443493992090225,0.02344987355172634,0.02297484315931797,0.023055322468280792,0.022850701585412025,0.022512709721922874,0.022419612854719162,0.02232675813138485,0.02226429060101509,0.02198076993227005,0.022033097222447395,0.021651193499565125,0.021267585456371307,0.02150498330593109,0.02126598358154297,0.020880356431007385,0.02110566571354866,0.020899519324302673,0.020611725747585297,0.020726559683680534,0.020506808534264565,0.027604946866631508,0.0336427316069603,0.031103847548365593,0.028887808322906494,0.027302302420139313,0.026137420907616615,0.025182323530316353,0.024015557020902634,0.022945716977119446,0.02217567153275013,0.021273862570524216,0.021189112216234207,0.020824430510401726,0.020244553685188293,0.01998978666961193,0.026964936405420303,0.027861155569553375,0.03751157969236374,0.03287504240870476,0.029894409701228142,0.027468034997582436,0.02608819678425789,0.024727582931518555,0.02397281490266323,0.023366831243038177,0.02256377413868904,0.021869393065571785,0.02196364663541317,0.02136852964758873,0.02452143281698227,0.025102123618125916,0.0346539206802845,0.03136485442519188,0.034709226340055466,0.03409820422530174,0.031810324639081955,
mse,0.10731758922338486,0.013369138352572918,0.005044771824032068,0.0021896553225815296,0.0015748131554573774,0.0012287646532058716,0.0009685219847597182,0.0007839928730390966,0.0006672663148492575,0.000601866515353322,0.0005453161429613829,0.0004996118950657547,0.0004391075053717941,0.00040874580736272037,0.00037912785774096847,0.0003679931105580181,0.0003408734919503331,0.00033228221582248807,0.00030479583074338734,0.000297639548080042,0.00027891993522644043,0.0002726376987993717,0.000262162066064775,0.00024997800937853754,0.0002406690618954599,0.0002350667054997757,0.0002284319489262998,0.00021817073866259307,0.00021614672732539475,0.00020892929751425982,0.00020149104238953441,0.00020050125021953136,0.00019264475849922746,0.00018827388703357428,0.00018627761164680123,0.00018052016093861312,0.00017557598766870797,0.00017366529209539294,0.00016914302250370383,0.00016740272985771298,0.00016316326218657196,0.00016121052613016218,0.00015708325372543186,0.0001548500295029953,0.00015576233272440732,0.00014929764438420534,0.0001494091411586851,0.0001477391051594168,0.00014224623737391084,0.0001409199758199975,0.00013947224942967296,0.00013905145169701427,0.0001356938446406275,0.0001360206224489957,0.00013160845264792442,0.0001290280488319695,0.00013114730245433748,0.00012717144272755831,0.0001231332280440256,0.00012477343261707574,0.00012213322042953223,0.0001189407630590722,0.00012120293104089797,0.00011826503759948537,0.00023637004778720438,0.00032222975278273225,0.000267332507064566,0.00023251348466146737,0.00020953381317667663,0.0001934200117830187,0.00018184620421379805,0.0001661846472416073,0.00015167277888394892,0.00013796956045553088,0.00012814771616831422,0.0001260855933651328,0.00012136501027271152,0.00011494412319734693,0.00011662633914966136,0.0002318774349987507,0.00022408504446502775,0.00039443813147954643,0.000300480896839872,0.0002449089370202273,0.00020852404122706503,0.00018924866162706167,0.00017247290816158056,0.00016025794320739806,0.00015335950592998415,0.00014468382869381458,0.00013968734128866345,0.00014111134805716574,0.000135688460431993,0.00018477726553101093,0.0002121864672517404,0.00033495185198262334,0.0002762599033303559,0.00033818333758972585,0.0003185633977409452,0.0002781988005153835,
mae,0.21592199802398682,0.0839545950293541,0.05217396840453148,0.03515651822090149,0.029829800128936768,0.026291895657777786,0.02348339557647705,0.02128579095005989,0.019759010523557663,0.018905512988567352,0.018018942326307297,0.01746591180562973,0.01635723188519478,0.01575479842722416,0.01529686339199543,0.015097469091415405,0.014392340555787086,0.014375729486346245,0.013702098280191422,0.013577517122030258,0.013326723128557205,0.013025736436247826,0.012799568474292755,0.012523280456662178,0.012274043634533882,0.012173686176538467,0.01199151948094368,0.011628519743680954,0.011646471917629242,0.011330426670610905,0.011405862867832184,0.011367538012564182,0.011018466204404831,0.010944191366434097,0.010976803489029408,0.010584366507828236,0.010584830306470394,0.010428998619318008,0.010309998877346516,0.010383482091128826,0.010103128850460052,0.010055925697088242,0.010011293925344944,0.009942873381078243,0.009898451156914234,0.009734177961945534,0.009768704883754253,0.00965899508446455,0.009485282003879547,0.009654087014496326,0.009480706416070461,0.009348523803055286,0.009270959533751011,0.009324978105723858,0.009146914817392826,0.009075302630662918,0.009043666534125805,0.008909734897315502,0.008877783082425594,0.008896445855498314,0.008852475322782993,0.008653542026877403,0.00874567311257124,0.008735950104892254,0.011691778898239136,0.01475661713629961,0.014137388207018375,0.013004525564610958,0.012206828221678734,0.011526210233569145,0.010729419998824596,0.009785512462258339,0.00931637268513441,0.00936170481145382,0.009189766831696033,0.009171951562166214,0.008969099260866642,0.008676058612763882,0.008630942553281784,0.011626552790403366,0.011763956397771835,0.016201404854655266,0.013640176504850388,0.012393258512020111,0.011701077222824097,0.011196712031960487,0.010644677095115185,0.010318700224161148,0.00996461696922779,0.009407320991158485,0.009327536448836327,0.009417095221579075,0.0090685049071908,0.010525695979595184,0.010617893189191818,0.014655908569693565,0.013103161007165909,0.014769942499697208,0.014435120858252048,0.013469633646309376,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6779      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6780      
=================================================================
Total params: 13,559
Trainable params: 13,559
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 6,779
Trainable params: 6,779
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 6,780
Trainable params: 6,780
Non-trainable params: 0
_________________________________________________________________
