2021-06-26
loss,2.2938637733459473,0.47652173042297363,0.24424323439598083,0.23537957668304443,0.2265123575925827,0.22100849449634552,0.20847368240356445,0.20271705090999603,0.15591688454151154,0.13671736419200897,0.13454341888427734,0.12629860639572144,0.10377530008554459,0.11099866777658463,0.07919515669345856,0.07903358340263367,0.06720983982086182,0.061921682208776474,0.07477190345525742,0.06267216801643372,0.06270574778318405,0.0601600743830204,0.05419327691197395,0.05226782336831093,0.053768496960401535,0.04994349554181099,0.04314073547720909,0.043637510389089584,0.045658178627491,0.045264579355716705,0.045702528208494186,0.040971335023641586,0.04052669182419777,0.04149235412478447,0.03693293407559395,0.03660622984170914,0.03868063911795616,0.03462780639529228,0.03619501739740372,0.035789746791124344,0.033798009157180786,0.03263263404369354,0.03195013850927353,0.03174813091754913,0.03067409247159958,0.033462781459093094,0.03526042401790619,0.029642291367053986,0.031130554154515266,0.03138624131679535,0.03064008057117462,0.028865044936537743,0.02673865109682083,0.029033198952674866,0.028542732819914818,0.025652330368757248,0.025917774066329002,0.026874303817749023,0.030704014003276825,0.025608886033296585,0.024416517466306686,0.02373351901769638,0.025291237980127335,0.028441596776247025,0.026476025581359863,0.0239864569157362,0.02631596475839615,0.02447531186044216,0.02186785265803337,0.023146865889430046,0.02662428468465805,0.024976739659905434,0.024124765768647194,0.02427487075328827,0.022665468975901604,0.021198375150561333,0.023285996168851852,0.021709755063056946,0.019844800233840942,0.02497304230928421,0.023835744708776474,0.021146561950445175,0.01936306618154049,0.022265221923589706,0.02152997814118862,0.019766760990023613,0.01970304548740387,0.018418461084365845,0.021751565858721733,0.01961842179298401,0.018850911408662796,0.021939456462860107,0.02268611639738083,0.021511195227503777,0.02171788178384304,0.021238351240754128,0.019828371703624725,0.019731951877474785,0.02139241434633732,0.021813493221998215,
mse,1.356178879737854,0.08036214113235474,0.0199766643345356,0.01880350150167942,0.017682189121842384,0.017012476921081543,0.014857037924230099,0.013217137195169926,0.0070787277072668076,0.005355736240744591,0.005410140845924616,0.0045218877494335175,0.0030469077173620462,0.0036700228229165077,0.0017812043661251664,0.0017213716637343168,0.0012740492820739746,0.0010984063846990466,0.0015828728210180998,0.0011928010499104857,0.0011029444867745042,0.0010195388458669186,0.0008078358951024711,0.0007618466042913496,0.0008204194018617272,0.0007003314676694572,0.0005223005427978933,0.0005572407389990985,0.0005903352284803987,0.0005818776553496718,0.0005839459481649101,0.0004679901176132262,0.0004630076000466943,0.0004750187217723578,0.000390739762224257,0.0003726043796632439,0.0004114063922315836,0.0003431258664932102,0.0003662899835035205,0.0003552205744199455,0.0003218812926206738,0.00029575300868600607,0.0002939636760856956,0.00028514378936961293,0.0002736564783845097,0.00031476232106797397,0.0003424949536565691,0.00024755572667345405,0.00027317312196828425,0.00027770359884016216,0.00026422535302117467,0.00022996755433268845,0.00020200827566441149,0.00023711606627330184,0.00022845437342766672,0.00018390806508250535,0.00019313005032017827,0.00020189923816360533,0.00026306312065571547,0.00018527010979596525,0.0001714313984848559,0.0001635820372030139,0.00018767380970530212,0.00022607245773542672,0.00019657386292237788,0.00016317520930897444,0.00019469110702630132,0.0001698968990240246,0.00014035591448191553,0.00015473201347049326,0.00019994749163743109,0.0001755931443767622,0.00016363870236091316,0.00016495226009283215,0.000145450045238249,0.00013500092609319836,0.00015348248416557908,0.00013480208872351795,0.00011558635014807805,0.00017328369722235948,0.00015716454072389752,0.00012701816740445793,0.00011069818719988689,0.00014317466411739588,0.00013215481885708869,0.00011453594925114885,0.00011270483082626015,0.00010276066313963383,0.00013288391346577555,0.00011379343777662143,0.00010660765110515058,0.00013818207662552595,0.000145114041515626,0.0001295603287871927,0.00013606747961603105,0.0001279573916690424,0.00011529107723617926,0.00011426882701925933,0.00013248150935396552,0.00013622672122437507,
mae,0.7844362854957581,0.2021421492099762,0.10918593406677246,0.10697048157453537,0.1030627191066742,0.10000719875097275,0.09269623458385468,0.09005331248044968,0.06699076294898987,0.05736302211880684,0.058394722640514374,0.05433642491698265,0.04398399963974953,0.04792426526546478,0.03344741463661194,0.03359319642186165,0.028062712401151657,0.026487868279218674,0.032026346772909164,0.026718096807599068,0.02681351825594902,0.025791490450501442,0.02302462048828602,0.02163630537688732,0.023043660447001457,0.021392975002527237,0.018015239387750626,0.018361426889896393,0.019757699221372604,0.019448457285761833,0.019532926380634308,0.017394637688994408,0.017222439870238304,0.017571762204170227,0.015889544039964676,0.015378893353044987,0.016361132264137268,0.014519243501126766,0.015359645709395409,0.015132838860154152,0.01427959930151701,0.013879042118787766,0.013433861546218395,0.013580459170043468,0.013272413983941078,0.01438081543892622,0.015078562311828136,0.012547366321086884,0.013192662037909031,0.013474099338054657,0.013051292859017849,0.011917926371097565,0.011181226931512356,0.012183249928057194,0.012014839798212051,0.010551675222814083,0.010990183800458908,0.011159374378621578,0.013234193436801434,0.010778841562569141,0.01019364595413208,0.009970239363610744,0.010720125399529934,0.012238647788763046,0.01108037494122982,0.01015804335474968,0.011076959781348705,0.010335155762732029,0.009224176406860352,0.00983827468007803,0.011364535428583622,0.010653733275830746,0.010295724496245384,0.010370180942118168,0.009591097012162209,0.009002027101814747,0.00981847196817398,0.009024611674249172,0.008393987081944942,0.010792484506964684,0.010057318024337292,0.009037038311362267,0.008246906101703644,0.009577588178217411,0.009108570404350758,0.008446285501122475,0.008368606679141521,0.007842288352549076,0.009216699749231339,0.00841551460325718,0.007946167141199112,0.009442279115319252,0.009661536663770676,0.009205805137753487,0.009210276417434216,0.009042443707585335,0.008295911364257336,0.008456827141344547,0.009112812578678131,0.009324034675955772,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 83011     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 83012     
=================================================================
Total params: 166,023
Trainable params: 166,023
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 83,011
Trainable params: 83,011
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 83,012
Trainable params: 83,012
Non-trainable params: 0
_________________________________________________________________
