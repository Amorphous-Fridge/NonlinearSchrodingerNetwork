2021-06-26
loss,0.40994372963905334,0.18799228966236115,0.12634462118148804,0.07322792708873749,0.06325115263462067,0.05560331046581268,0.049626514315605164,0.046587686985731125,0.04423864185810089,0.0686478242278099,0.06165207922458649,0.07003603130578995,0.05978552997112274,0.04895155131816864,0.041692670434713364,0.035094715654850006,0.0343378521502018,0.034898802638053894,0.04943360015749931,0.05203545093536377,0.04984498396515846,0.048924002796411514,0.04717042297124863,0.04869212582707405,0.04325345531105995,0.03571717068552971,0.0405585952103138,0.038861773908138275,0.035789716988801956,0.034566041082143784,0.028059497475624084,0.027091197669506073,0.04184019938111305,0.0399613156914711,0.036959193646907806,0.03334863483905792,0.038894131779670715,0.044088564813137054,0.03850003331899643,0.035280559211969376,0.033054158091545105,0.03133033588528633,0.032489113509655,0.03148368373513222,0.02885141596198082,0.028088564053177834,0.027254115790128708,0.03208841010928154,0.03139256313443184,0.02496160939335823,0.0241459459066391,0.026502899825572968,0.025708111003041267,0.030561083927750587,0.02879652939736843,0.02613462693989277,0.034308839589357376,0.031126659363508224,0.028247520327568054,0.026850556954741478,0.03454888239502907,0.03184695541858673,0.029113445430994034,0.027157559990882874,0.02421257458627224,0.022532258182764053,0.022070417180657387,0.022314369678497314,0.02914879471063614,0.02715366519987583,0.025840895250439644,0.024881701916456223,0.023182647302746773,0.027666185051202774,0.027935972437262535,0.02566637471318245,0.027340708300471306,0.02836567908525467,0.025785138830542564,0.024083781987428665,0.022854769602417946,0.021552052348852158,0.024861618876457214,0.02287925034761429,0.022100141271948814,0.020801618695259094,0.022222938016057014,0.025326568633317947,0.02312125638127327,0.02165105752646923,0.02009899914264679,0.019662782549858093,0.01801661029458046,0.0195373073220253,0.02092381939291954,0.022725146263837814,0.02290513552725315,0.0212293341755867,0.01979721710085869,0.019791757687926292,
mse,0.08115261793136597,0.011884000152349472,0.0056058745831251144,0.0015991763211786747,0.0011619383003562689,0.0008689938695169985,0.0006800491246394813,0.0006007675547152758,0.0005588905769400299,0.001460533938370645,0.0010745644103735685,0.001358223962597549,0.0010328736389055848,0.0006989955436438322,0.0005070774350315332,0.00035340682370588183,0.0003247812273912132,0.0003536819713190198,0.0006921810563653708,0.0007663444266654551,0.0007137542124837637,0.0006766490405425429,0.000628135574515909,0.0006575597217306495,0.0005244151689112186,0.00037099033943377435,0.00046260710223577917,0.0004111604066565633,0.0003543172497302294,0.00033267639810219407,0.00023330202384386212,0.00021562491019722074,0.00048466891166754067,0.00043458922300487757,0.000375087809516117,0.00032276741694658995,0.00043895613634958863,0.0005439113592728972,0.00040780194103717804,0.00034623098326846957,0.00030500712455250323,0.00027417222736403346,0.000297940248856321,0.0002838265208993107,0.0002343195374123752,0.0002216475404566154,0.00020634908287320286,0.0002894342760555446,0.00027951659285463393,0.00018714899488259107,0.00017125064914580435,0.00019741777214221656,0.00019025125948246568,0.0002616100828163326,0.00023290417448151857,0.00019750712090171874,0.00032869723509065807,0.0002679851313587278,0.00022301670105662197,0.00020682108879555017,0.0003307017032057047,0.0002786321856547147,0.0002404879342066124,0.00020746272639371455,0.00016845489153638482,0.00014587887562811375,0.00014046994328964502,0.00014411935990210623,0.0002356790064368397,0.00020573483197949827,0.00018386478768661618,0.00016967639385256916,0.0001526943378848955,0.00021862340508960187,0.0002175726112909615,0.0001840296172304079,0.00020813295850530267,0.00022109509154688567,0.00018674314196687192,0.00016126366972457618,0.00014502966951113194,0.00013083021622151136,0.00017606931214686483,0.00014621822629123926,0.00013765078620053828,0.00012568861711770296,0.00014501326950266957,0.00017504765128251165,0.00014813555753789842,0.0001301322627114132,0.00011589694622671232,0.000110763190605212,9.601040073903278e-05,0.00011058747622882947,0.00012818332470487803,0.00014359125634655356,0.00014350518176797777,0.00012454074749257416,0.00010990611917804927,0.00011409472062950954,
mae,0.17495347559452057,0.0759410411119461,0.05296947807073593,0.031527549028396606,0.027437014505267143,0.023894796147942543,0.021404314786195755,0.019843535497784615,0.018717605620622635,0.02938152104616165,0.02629123628139496,0.029654258862137794,0.024963412433862686,0.020790323615074158,0.017592599615454674,0.014906469732522964,0.014616858214139938,0.014952342957258224,0.020675625652074814,0.02245299145579338,0.02112474851310253,0.019737031310796738,0.02000674046576023,0.020808963105082512,0.018711186945438385,0.01506748329848051,0.016944922506809235,0.017390679568052292,0.01590898633003235,0.014968606643378735,0.011898180469870567,0.0113203851506114,0.018312664702534676,0.017549116164445877,0.016258612275123596,0.014083714224398136,0.01619345135986805,0.017608216032385826,0.015161718241870403,0.013767288066446781,0.012997519224882126,0.012852148152887821,0.013829942792654037,0.012914908118546009,0.012158028781414032,0.01175733283162117,0.011320811696350574,0.013600007630884647,0.013278097845613956,0.010577564127743244,0.010268380865454674,0.01087790448218584,0.010964498855173588,0.012896998785436153,0.012097240425646305,0.010962026193737984,0.015012284740805626,0.013904600404202938,0.012458166107535362,0.011326001025736332,0.015133614651858807,0.014011924155056477,0.012920701876282692,0.011403437703847885,0.010189265012741089,0.009528914466500282,0.0091349296271801,0.009324180893599987,0.013039366342127323,0.01225119549781084,0.011610375717282295,0.011111126281321049,0.009890669956803322,0.011777855455875397,0.012664120644330978,0.011554159224033356,0.011271077208220959,0.011653775349259377,0.010902218520641327,0.010012197308242321,0.009447494521737099,0.008744902908802032,0.01085047610104084,0.00956434104591608,0.009086143225431442,0.008771647699177265,0.009411519393324852,0.010637408122420311,0.009943253360688686,0.009354484267532825,0.00855850800871849,0.008373236283659935,0.0076922206208109856,0.008276994340121746,0.008975598961114883,0.009678375907242298,0.009970302693545818,0.009337348863482475,0.00853310152888298,0.00834619253873825,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17875     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17876     
=================================================================
Total params: 35,751
Trainable params: 35,751
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 17,875
Trainable params: 17,875
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 17,876
Trainable params: 17,876
Non-trainable params: 0
_________________________________________________________________
