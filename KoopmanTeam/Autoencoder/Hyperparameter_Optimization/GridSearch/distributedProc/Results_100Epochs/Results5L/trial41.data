2021-06-26
loss,0.6021963357925415,0.23275639116764069,0.16709059476852417,0.1570149064064026,0.12735003232955933,0.12999331951141357,0.12548312544822693,0.10650862008333206,0.07889340072870255,0.11077564209699631,0.09480609744787216,0.08316438645124435,0.08211418986320496,0.0777306780219078,0.05090509355068207,0.0804300382733345,0.0754685252904892,0.07363317161798477,0.06903811544179916,0.06189219653606415,0.06371418386697769,0.05262686684727669,0.059034913778305054,0.059507571160793304,0.04831942170858383,0.04715734347701073,0.05432829260826111,0.04941721260547638,0.061412710696458817,0.05423307046294212,0.04210713878273964,0.04058069735765457,0.05522520840167999,0.047195568680763245,0.03923219069838524,0.05110069736838341,0.044744156301021576,0.04029509425163269,0.03581635653972626,0.04811413586139679,0.040359485894441605,0.03690160810947418,0.047913022339344025,0.040868304669857025,0.04163328558206558,0.04153578728437424,0.03752945363521576,0.03899738937616348,0.03865444287657738,0.03829677030444145,0.03658439218997955,0.03035358153283596,0.03346133604645729,0.039979565888643265,0.03295232728123665,0.035383012145757675,0.031541939824819565,0.03655446693301201,0.03505254164338112,0.034836649894714355,0.033218275755643845,0.03168782591819763,0.030466463416814804,0.03490098565816879,0.029650168493390083,0.026491081342101097,0.02603616937994957,0.021846158429980278,0.032804083079099655,0.0341164693236351,0.032044943422079086,0.033266931772232056,0.030740557238459587,0.03070015460252762,0.027521468698978424,0.02452763170003891,0.026674238964915276,0.025361748412251472,0.02243172377347946,0.030217180028557777,0.033034875988960266,0.028133707121014595,0.021392492577433586,0.028004691004753113,0.023816721513867378,0.03081398271024227,0.030597984790802002,0.02704019472002983,0.02525908872485161,0.023482030257582664,0.024254707619547844,0.027658546343445778,0.026392363011837006,0.025184450671076775,0.027934877201914787,0.023517491295933723,0.02876300737261772,0.02336561679840088,0.024742472916841507,0.023516204208135605,
mse,0.1593179851770401,0.018014544621109962,0.008623273111879826,0.007210182957351208,0.004688713699579239,0.004884805530309677,0.004819044377654791,0.0034236665815114975,0.001831352710723877,0.0036007047165185213,0.0025403457693755627,0.001966152573004365,0.0020811669528484344,0.0017512221820652485,0.0007755790138617158,0.0019711931236088276,0.001594445900991559,0.001516046468168497,0.0013416847214102745,0.001116878935135901,0.001140025444328785,0.0007807748625054955,0.0010310863144695759,0.0010054617887362838,0.0006426522159017622,0.0006207453552633524,0.0008419696823693812,0.0007027125102467835,0.0010576476342976093,0.0008013648330233991,0.0005158819258213043,0.00047776050632819533,0.000862088636495173,0.000611815310548991,0.00042666145600378513,0.0007208922761492431,0.0005673090927302837,0.0004542330570984632,0.00037002554745413363,0.0006708072032779455,0.0004592140903696418,0.00038936507189646363,0.0006242541130632162,0.00048086774768307805,0.00048521760618314147,0.0004969952278770506,0.00038612529169768095,0.0004341677122283727,0.0004082547384314239,0.00041183092980645597,0.0003629960410762578,0.0002629925438668579,0.00032205440220423043,0.00043391756480559707,0.00030524987960234284,0.0003525401698425412,0.000288016046397388,0.0003808982437476516,0.00034036411670967937,0.0003410604258533567,0.0003024702600669116,0.00027510698419064283,0.00025936795282177627,0.000325396511470899,0.0002421741810394451,0.00019763548334594816,0.00019230306497775018,0.00014046135765966028,0.00030119807342998683,0.00032199465204030275,0.0002763625525403768,0.00030471637728624046,0.00026909049483947456,0.00025487359380349517,0.00020455005869735032,0.00016916217282414436,0.00019871357653755695,0.00018069508951157331,0.0001503302191849798,0.0002595566329546273,0.00030160314054228365,0.00022003368940204382,0.00013273880176711828,0.00021672733419109136,0.00016336994303856045,0.00026637836708687246,0.00025627200375311077,0.00020239608420524746,0.0001760315935825929,0.00015900732250884175,0.0001656736567383632,0.0002149912907043472,0.00019372474343981594,0.00017827902047429234,0.00021536415442824364,0.00015207000251393765,0.00022783449094276875,0.0001572983164805919,0.0001716804108582437,0.00015730615996289998,
mae,0.2559039294719696,0.09996047616004944,0.07306201010942459,0.0673617571592331,0.05443502962589264,0.055888962000608444,0.053176358342170715,0.04466554522514343,0.033483706414699554,0.047506049275398254,0.04061437025666237,0.03598771244287491,0.034659579396247864,0.03323373943567276,0.02154782973229885,0.03439329192042351,0.03257356211543083,0.03169652819633484,0.029619384557008743,0.026318924501538277,0.026321489363908768,0.02228417433798313,0.025022627785801888,0.025346186012029648,0.02073010988533497,0.019533120095729828,0.022852880880236626,0.020778758451342583,0.025940237566828728,0.023111801594495773,0.01809128187596798,0.017095163464546204,0.02325860969722271,0.02032291144132614,0.016327325254678726,0.02194836176931858,0.019350454211235046,0.016909098252654076,0.015266059897840023,0.02049083448946476,0.01734171248972416,0.015501182526350021,0.020613698288798332,0.017175210639834404,0.01762327551841736,0.018016066402196884,0.016221126541495323,0.016462307423353195,0.01670144684612751,0.01626809500157833,0.016013871878385544,0.013016016222536564,0.014277261681854725,0.016983143985271454,0.014106162823736668,0.014926958829164505,0.013624532148241997,0.01564570516347885,0.015252730809152126,0.014983930625021458,0.014221814461052418,0.013713113032281399,0.013062301091849804,0.014742578379809856,0.013025406748056412,0.011237332597374916,0.010965454392135143,0.009255700744688511,0.014175239950418472,0.014460522681474686,0.01364148873835802,0.01414508931338787,0.013092998415231705,0.01360950618982315,0.011834297329187393,0.010273213498294353,0.011273127980530262,0.010615651495754719,0.009451036341488361,0.012907752767205238,0.01379083190113306,0.01221152301877737,0.009007367305457592,0.011965854093432426,0.009670079685747623,0.012945670634508133,0.012806214392185211,0.011822329834103584,0.010862743481993675,0.009908290579915047,0.01022130623459816,0.012030238285660744,0.011074020527303219,0.010751387104392052,0.011911523528397083,0.010316508822143078,0.012084092944860458,0.009929325431585312,0.010597443208098412,0.010120403952896595,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 35347     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 35348     
=================================================================
Total params: 70,695
Trainable params: 70,695
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 35,347
Trainable params: 35,347
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 35,348
Trainable params: 35,348
Non-trainable params: 0
_________________________________________________________________
