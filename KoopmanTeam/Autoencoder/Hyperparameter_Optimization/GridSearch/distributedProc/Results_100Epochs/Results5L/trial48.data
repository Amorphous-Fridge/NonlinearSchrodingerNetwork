2021-06-26
loss,0.6926098465919495,0.20033115148544312,0.1167125329375267,0.13264873623847961,0.10936997085809708,0.10352488607168198,0.10775895416736603,0.0984242707490921,0.08055134862661362,0.07865452021360397,0.07125332951545715,0.06837973743677139,0.07528626918792725,0.05469771847128868,0.061122115701436996,0.07421359419822693,0.06628838181495667,0.061755064874887466,0.06778597086668015,0.06203388050198555,0.06309757381677628,0.06599225848913193,0.05884523317217827,0.05090690031647682,0.04573528468608856,0.04377299174666405,0.049276407808065414,0.05675144121050835,0.05520277097821236,0.046240828931331635,0.033909305930137634,0.03676836937665939,0.04530520737171173,0.052287593483924866,0.04222483932971954,0.036688052117824554,0.03415624797344208,0.04357689991593361,0.04521436616778374,0.045184746384620667,0.038667164742946625,0.04119546338915825,0.03467211127281189,0.03133248910307884,0.03043266572058201,0.03498149290680885,0.033079445362091064,0.028079960495233536,0.029279928654432297,0.03615838289260864,0.04144742339849472,0.038492847234010696,0.03742777556180954,0.03070022538304329,0.025544431060552597,0.025960197672247887,0.030325232073664665,0.032460108399391174,0.03717804327607155,0.028598524630069733,0.034407276660203934,0.028485385701060295,0.025462711229920387,0.02745368331670761,0.03045511804521084,0.03406846150755882,0.029585683718323708,0.027888040989637375,0.024324920028448105,0.031436897814273834,0.030048571527004242,0.026664545759558678,0.02511717565357685,0.02734542079269886,0.024038663133978844,0.028350375592708588,0.030424918979406357,0.024908123537898064,0.021872784942388535,0.026514938101172447,0.025273077189922333,0.029565608128905296,0.02750083990395069,0.024516258388757706,0.021600427106022835,0.024926818907260895,0.02698785997927189,0.028431961312890053,0.02456156723201275,0.02078108862042427,0.018065977841615677,0.021630510687828064,0.0254385843873024,0.02423163689672947,0.027153540402650833,0.02534646727144718,0.0223443191498518,0.023561693727970123,0.02229193039238453,0.01955178938806057,
mse,0.23423853516578674,0.012166056782007217,0.004006516188383102,0.005203644745051861,0.00342989107593894,0.003045182442292571,0.0033800078090280294,0.0030868190806359053,0.0019823741167783737,0.001780543359927833,0.0014569595223292708,0.0013636266812682152,0.0016510899877175689,0.0008712743874639273,0.0010991885792464018,0.001633199630305171,0.001263657701201737,0.001077401451766491,0.00139274587854743,0.0010764183243736625,0.0011337634641677141,0.001219511148519814,0.0009911636589094996,0.0007245218148455024,0.0005899195675738156,0.0005609923973679543,0.0006961039616726339,0.0009028221829794347,0.0008497024537064135,0.0006068649236112833,0.00034102718927897513,0.00038270786171779037,0.0005860222736373544,0.0007800756138749421,0.0004934754688292742,0.00039130952791310847,0.0003329399914946407,0.0005558682605624199,0.0005780284991487861,0.0005745591479353607,0.00042265906813554466,0.0004927221452817321,0.00034527809475548565,0.00027349733863957226,0.0002670091635081917,0.0003460490261204541,0.0002991663641296327,0.00022035205620341003,0.0002531009668018669,0.00035888381535187364,0.0004938699421472847,0.0004190308100078255,0.00038417597534134984,0.0002708762476686388,0.00019011000404134393,0.00020075993961654603,0.0002628087531775236,0.00029474450275301933,0.0003975569852627814,0.0002395604969933629,0.00033052428625524044,0.0002248624514322728,0.00018447624461259693,0.00021259061759337783,0.00025302113499492407,0.0003327942977193743,0.00024737408966757357,0.00022096847533248365,0.00016978669737000018,0.00027352944016456604,0.0002530446508899331,0.00019743360462598503,0.00017721291806083173,0.00020805589156225324,0.0001660284906392917,0.00022592151071876287,0.0002602438908070326,0.00017406865663360804,0.000139389987452887,0.00020029363804496825,0.00018295578774996102,0.00024375361681450158,0.0002124743041349575,0.00016649138706270605,0.0001310942752752453,0.00017934443894773722,0.00020601236610673368,0.00023062671243678778,0.0001651151542318985,0.00011991018254775554,9.406477329321206e-05,0.0001399722823407501,0.0001838137541199103,0.00016679700638633221,0.0002077870594803244,0.0001781588653102517,0.00014000963710714132,0.00015949775115586817,0.00013994133041705936,0.00011506331793498248,
mae,0.29449766874313354,0.08518039435148239,0.05090070888400078,0.05606693774461746,0.04728669673204422,0.04474742338061333,0.04642510414123535,0.043320078402757645,0.034738559275865555,0.033667538315057755,0.03055310994386673,0.02952074445784092,0.03223659098148346,0.023291025310754776,0.02623598650097847,0.03192758187651634,0.02839229814708233,0.026600949466228485,0.029372744262218475,0.026581119745969772,0.027409734204411507,0.028582435101270676,0.025648849084973335,0.022411029785871506,0.019800787791609764,0.018517225980758667,0.02077479287981987,0.0243832990527153,0.02378016710281372,0.01961538754403591,0.014364688657224178,0.01570322923362255,0.019436625763773918,0.02235332690179348,0.01792445220053196,0.01554588321596384,0.014415429905056953,0.018802102655172348,0.01969737932085991,0.019791239872574806,0.016691487282514572,0.01790720596909523,0.014868157915771008,0.013220968656241894,0.012968518771231174,0.014960773289203644,0.014095675200223923,0.012020989321172237,0.012541137635707855,0.015936600044369698,0.017876815050840378,0.016630379483103752,0.01624857634305954,0.013282001949846745,0.010796635411679745,0.010787845589220524,0.012875663116574287,0.013846640475094318,0.01593143306672573,0.012320551089942455,0.01454914826899767,0.011900080367922783,0.010807394050061703,0.011683709919452667,0.01339311245828867,0.014569886960089207,0.012632331810891628,0.012053009122610092,0.010318169370293617,0.013454537838697433,0.012841527350246906,0.011228864081203938,0.01057451032102108,0.011913328431546688,0.01023270096629858,0.012091580778360367,0.013051892630755901,0.010469790548086166,0.009277602657675743,0.011380420997738838,0.010683704167604446,0.012744487263262272,0.011981695890426636,0.010407832451164722,0.009028893895447254,0.01080665085464716,0.011844461783766747,0.012011284939944744,0.010539805516600609,0.008798293769359589,0.00756265502423048,0.009321628138422966,0.010950424708425999,0.01043630763888359,0.011559074744582176,0.011201397515833378,0.00972159393131733,0.010020997375249863,0.009465287439525127,0.00823972187936306,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 68171     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 68172     
=================================================================
Total params: 136,343
Trainable params: 136,343
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 68,171
Trainable params: 68,171
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 68,172
Trainable params: 68,172
Non-trainable params: 0
_________________________________________________________________
