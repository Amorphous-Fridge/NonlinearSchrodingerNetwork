2021-06-26
loss,0.5398844480514526,0.22654595971107483,0.1759824901819229,0.14183366298675537,0.14122717082500458,0.13606514036655426,0.1143190860748291,0.09429127722978592,0.10306419432163239,0.09573930501937866,0.09135959297418594,0.07357560843229294,0.08767197281122208,0.09270177036523819,0.060937851667404175,0.07244864106178284,0.06066610664129257,0.056004080921411514,0.059309057891368866,0.04554194584488869,0.05108741670846939,0.05415010452270508,0.05393855273723602,0.0485553964972496,0.04168926179409027,0.04511544853448868,0.04330156743526459,0.03725867718458176,0.0402553528547287,0.04459905996918678,0.04148571938276291,0.04105468839406967,0.03485959395766258,0.03227146342396736,0.039035335183143616,0.03148733451962471,0.03131484240293503,0.03485344722867012,0.03519091755151749,0.035258401185274124,0.03250822052359581,0.031628191471099854,0.02789943479001522,0.028109131380915642,0.03619770333170891,0.031923964619636536,0.03457726165652275,0.03124285861849785,0.025430064648389816,0.030870744958519936,0.03055395558476448,0.03257922828197479,0.0297975093126297,0.026002924889326096,0.026168454438447952,0.028732147067785263,0.02770766243338585,0.021573185920715332,0.02462196536362171,0.02608894370496273,0.027269722893834114,0.02473338320851326,0.022523479536175728,0.026582924649119377,0.027208181098103523,0.02939995564520359,0.02355213835835457,0.023053107783198357,0.030313633382320404,0.025012439116835594,0.024820690974593163,0.023921387270092964,0.01942545920610428,0.02021489292383194,0.021285023540258408,0.025302648544311523,0.02474132739007473,0.024933915585279465,0.022732682526111603,0.023793017491698265,0.023375723510980606,0.021809851750731468,0.024258572608232498,0.022670846432447433,0.022933457046747208,0.019456511363387108,0.022062260657548904,0.023030005395412445,0.023631220683455467,0.01849035546183586,0.01759432442486286,0.017732534557580948,0.022682297974824905,0.021484436467289925,0.02256520465016365,0.019310560077428818,0.02162199653685093,0.02162490412592888,0.018150148913264275,0.020169060677289963,
mse,0.13211502134799957,0.015092705376446247,0.009424427524209023,0.005695368628948927,0.0061276499181985855,0.00558055704459548,0.0038097535725682974,0.0025299766566604376,0.0030411602929234505,0.002699844306334853,0.0024708309210836887,0.0015364651335403323,0.0021879489067941904,0.002545646158978343,0.0010835702996701002,0.001547971274703741,0.0010511683067306876,0.0008867167634889483,0.0010139183141291142,0.0005935770459473133,0.0007516999030485749,0.0008377762860618532,0.0008097709505818784,0.0006779015529900789,0.0005077191744931042,0.0005808805581182241,0.0005372650921344757,0.0003973314305767417,0.0004563995753414929,0.000563369074370712,0.00048445200081914663,0.00047344312770292163,0.0003495261480566114,0.00030586906359530985,0.00042883827700279653,0.0002817241766024381,0.0002873460471164435,0.0003541778714861721,0.0003504059568513185,0.000355372903868556,0.00029701105086132884,0.00028349386411719024,0.00022065833036322147,0.00022944727970752865,0.00036492853541858494,0.0002899122191593051,0.00033571221865713596,0.00027167960070073605,0.00019109969434794039,0.0002713298599701375,0.00026076039648614824,0.00030057941330596805,0.00024746646522544324,0.00019751369836740196,0.00019189967133570462,0.00023328085080720484,0.0002165605255868286,0.0001372785191051662,0.00017728582315612584,0.00019605763372965157,0.00021072692470625043,0.00017533317441120744,0.00014429923612624407,0.00019638957746792585,0.00021083645697217435,0.0002398274082224816,0.0001606210571480915,0.00015304161934182048,0.0002547853218857199,0.00018119192100130022,0.00017418418428860605,0.00015962615725584328,0.00011252235708525404,0.00012023223825963214,0.00012863948359154165,0.0001847470412030816,0.00017896079225465655,0.0001743769971653819,0.00014670210657641292,0.00015676046314183623,0.0001553819456603378,0.00014029791054781526,0.00016512304136995226,0.00014737219316884875,0.00015110154345165938,0.00010966678382828832,0.00013864730135537684,0.00015037036791909486,0.00015970827371347696,0.00010109825961990282,9.186936222249642e-05,9.443490853300318e-05,0.00014459120575338602,0.00012975376739632338,0.0001428270188625902,0.00010614530765451491,0.00013384864723775536,0.00012810270709451288,9.642584336688742e-05,0.00011761532368836924,
mae,0.2326183319091797,0.09555618464946747,0.07534976303577423,0.060739997774362564,0.05940839648246765,0.05904123932123184,0.048885978758335114,0.0400836355984211,0.04436047002673149,0.0413968451321125,0.038542862981557846,0.0312967412173748,0.03665775805711746,0.03904102370142937,0.025884704664349556,0.03135140985250473,0.026060156524181366,0.023884844034910202,0.0253385528922081,0.019223682582378387,0.022019701078534126,0.023287910968065262,0.023075511679053307,0.020937902852892876,0.017569078132510185,0.01925067976117134,0.018294265493750572,0.015781931579113007,0.017068753018975258,0.01896272599697113,0.01756705716252327,0.017342159524559975,0.01485095638781786,0.013778084889054298,0.016447091475129128,0.013432074338197708,0.013459610752761364,0.014900151640176773,0.014849774539470673,0.014858663082122803,0.013973694294691086,0.013392451219260693,0.011847627349197865,0.011990240775048733,0.015574089251458645,0.01345551572740078,0.01465692836791277,0.013325387611985207,0.010940521024167538,0.013083627447485924,0.012955156154930592,0.013892536982893944,0.01270882599055767,0.011100594885647297,0.010986868292093277,0.012188496999442577,0.011632437817752361,0.009162661619484425,0.010449688881635666,0.011123285628855228,0.011786255054175854,0.010666226036846638,0.00953824445605278,0.011068085208535194,0.011546634137630463,0.012538782320916653,0.010038485750555992,0.009771416895091534,0.013101134449243546,0.010817485861480236,0.010537166148424149,0.010361496359109879,0.008188813924789429,0.00862831436097622,0.00898933969438076,0.010724922642111778,0.010556595399975777,0.010722389444708824,0.009712192229926586,0.010234963148832321,0.010123190470039845,0.009241004474461079,0.010308733209967613,0.009682568721473217,0.009827724657952785,0.008396237157285213,0.009442079812288284,0.00980442576110363,0.010133729316294193,0.007968923076987267,0.007507520727813244,0.007547972723841667,0.009437575936317444,0.00916645210236311,0.00957352016121149,0.008159548975527287,0.009196968749165535,0.009146977216005325,0.007690886035561562,0.008599759079515934,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 69227     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 69228     
=================================================================
Total params: 138,455
Trainable params: 138,455
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 69,227
Trainable params: 69,227
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 69,228
Trainable params: 69,228
Non-trainable params: 0
_________________________________________________________________
