2021-06-26
loss,0.5568768978118896,0.2422793060541153,0.19141454994678497,0.16618335247039795,0.14887429773807526,0.12208043783903122,0.11167014390230179,0.13284823298454285,0.12626151740550995,0.10401604324579239,0.09352821111679077,0.0718986764550209,0.06812010705471039,0.07024507224559784,0.06968752294778824,0.0736793503165245,0.06797346472740173,0.07421078532934189,0.06416478753089905,0.05705123394727707,0.055727362632751465,0.053696680814027786,0.07002183794975281,0.06513246893882751,0.06162268668413162,0.05816992372274399,0.04974856972694397,0.05225973576307297,0.051733385771512985,0.0535709522664547,0.04826502874493599,0.043127965182065964,0.03705383464694023,0.040489133447408676,0.038572758436203,0.050213783979415894,0.04350205883383751,0.044729508459568024,0.04116835445165634,0.04025394096970558,0.03424757719039917,0.0451665036380291,0.041571274399757385,0.042738933116197586,0.03799781948328018,0.029149748384952545,0.02994557097554207,0.03044455125927925,0.040708936750888824,0.043414968997240067,0.03605204448103905,0.03444627672433853,0.031101396307349205,0.030969912186264992,0.0405346043407917,0.03114035166800022,0.029262559488415718,0.03690541535615921,0.037501297891139984,0.03176751732826233,0.03467599302530289,0.03479712828993797,0.030820345506072044,0.0292150117456913,0.029666680842638016,0.0247194841504097,0.028068415820598602,0.03048785775899887,0.02959468588232994,0.035007085651159286,0.03683618828654289,0.02971683256328106,0.02664618007838726,0.02797771245241165,0.03634904697537422,0.028916936367750168,0.028086848556995392,0.025123663246631622,0.030321553349494934,0.029989756643772125,0.032590266317129135,0.02826359122991562,0.030128180980682373,0.028246546164155006,0.027295231819152832,0.023585636168718338,0.02837604284286499,0.02972160093486309,0.026644017547369003,0.02451196499168873,0.025680329650640488,0.024986088275909424,0.026343083009123802,0.029813040047883987,0.02822614461183548,0.023132769390940666,0.023549750447273254,0.02591041289269924,0.02798391878604889,0.02409943751990795,
mse,0.13295429944992065,0.018671397119760513,0.011029423214495182,0.007904930040240288,0.006314288359135389,0.0045714350417256355,0.003614912275224924,0.00503639318048954,0.004444777965545654,0.003117495682090521,0.002503548748791218,0.0015770836034789681,0.0013418339658528566,0.0014646911295130849,0.0013861038023605943,0.0016294099623337388,0.0013447932433336973,0.0016398122534155846,0.0011663511395454407,0.0009562363266013563,0.0008667307556606829,0.0008301583584398031,0.0014026542194187641,0.0012228295672684908,0.0010535491164773703,0.0009295690688304603,0.000712090521119535,0.0007844598731026053,0.0007404029602184892,0.0007900221389718354,0.0006377433310262859,0.0005262377089820802,0.0004095218610018492,0.00046227796701714396,0.0004106830165255815,0.0007136620697565377,0.0005258659366518259,0.0005516906967386603,0.0004858044267166406,0.0004519446229096502,0.0003303913108538836,0.000564845628105104,0.0004943347885273397,0.0005030329339206219,0.00040408570202998817,0.00024780890089459717,0.00026210700161755085,0.00026962204719893634,0.00046800958807580173,0.0005186392227187753,0.0003608803090173751,0.0003299358068034053,0.0002703720238059759,0.00027357653016224504,0.00045087430044077337,0.0002692873531486839,0.00024155891151167452,0.00037441280437633395,0.0004015907761640847,0.0002887345035560429,0.00034600202343426645,0.00033675701706670225,0.00026576194795779884,0.0002404028200544417,0.00023907636932563037,0.0001732872478896752,0.0002246424410259351,0.00025211955653503537,0.00024987186770886183,0.0003489987284410745,0.00037721500848419964,0.00024401438713539392,0.00020111238700337708,0.00022112749866209924,0.00037221104139462113,0.0002359960926696658,0.0002233579580206424,0.00018103908223565668,0.0002643233456183225,0.00025336863473057747,0.0002977561380248517,0.00022364848700817674,0.0002505880256649107,0.00022122514201328158,0.0002050182083621621,0.00015878169506322592,0.00022132234880700707,0.00024624995421618223,0.00019666001026052982,0.00016887923993635923,0.00018226327665615827,0.00017241327441297472,0.00019177694048266858,0.00024447133182547987,0.00021916572586633265,0.00015139275637920946,0.00015959002485033125,0.0001878570910776034,0.00021572339755948633,0.0001632936327951029,
mae,0.23685650527477264,0.10150651633739471,0.081796795129776,0.07113231718540192,0.06247745826840401,0.05164001137018204,0.04788742586970329,0.05649483576416969,0.05456007644534111,0.04461491480469704,0.04001903906464577,0.030522771179676056,0.02783752977848053,0.02953021042048931,0.029047999531030655,0.031162194907665253,0.02861771173775196,0.030545981600880623,0.026903759688138962,0.023925352841615677,0.02343144454061985,0.02283710241317749,0.029622234404087067,0.02706863172352314,0.025849655270576477,0.02505170740187168,0.021021589636802673,0.02254536561667919,0.022930791601538658,0.022889435291290283,0.021804871037602425,0.01849205233156681,0.015722226351499557,0.017267756164073944,0.016374025493860245,0.02042597346007824,0.01825793646275997,0.019130956381559372,0.017502937465906143,0.017012344673275948,0.014513606205582619,0.01877698488533497,0.01779111847281456,0.018379388377070427,0.015975341200828552,0.012405243702232838,0.012763015925884247,0.012966351583600044,0.01740458607673645,0.018034659326076508,0.015139549970626831,0.014251615852117538,0.012866448611021042,0.012981381267309189,0.017063049599528313,0.013192271813750267,0.012496442534029484,0.016024256125092506,0.015583655796945095,0.013498065061867237,0.014735029079020023,0.014752797782421112,0.013090751133859158,0.012256140820682049,0.012168840505182743,0.010403203777968884,0.011974942870438099,0.01283425372093916,0.012527418322861195,0.014945393428206444,0.014929311349987984,0.012787772342562675,0.011313769035041332,0.011755482293665409,0.015294844284653664,0.012389179319143295,0.012073509395122528,0.01063956506550312,0.013015053234994411,0.013028446584939957,0.013581731356680393,0.01198795810341835,0.012566975317895412,0.012181221507489681,0.011412981897592545,0.009726653806865215,0.012013060040771961,0.012573957443237305,0.011295206844806671,0.010569030418992043,0.010752870701253414,0.01058292482048273,0.01120632141828537,0.012382041662931442,0.011997133493423462,0.009812685661017895,0.009948043152689934,0.011082383804023266,0.01177285797894001,0.010343658737838268,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 52819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 52820     
=================================================================
Total params: 105,639
Trainable params: 105,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 52,819
Trainable params: 52,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 52,820
Trainable params: 52,820
Non-trainable params: 0
_________________________________________________________________
