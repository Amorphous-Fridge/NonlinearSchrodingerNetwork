2021-06-26
loss,0.7669140100479126,0.2399991750717163,0.19814510643482208,0.17176805436611176,0.1348702758550644,0.12563025951385498,0.11085500568151474,0.10574552416801453,0.0988299772143364,0.10043482482433319,0.0799885243177414,0.07006916403770447,0.06110476329922676,0.07243683934211731,0.07120490819215775,0.0546409897506237,0.05447158217430115,0.054693277925252914,0.04564027488231659,0.05268679931759834,0.0639602541923523,0.06409802287817001,0.04950491338968277,0.046316079795360565,0.05181111395359039,0.04705650731921196,0.04843931272625923,0.04949845001101494,0.04393424838781357,0.039242640137672424,0.04204404354095459,0.03869733586907387,0.046176448464393616,0.03677951544523239,0.03820209205150604,0.03350621834397316,0.03368731588125229,0.03859386220574379,0.04238218441605568,0.03618684411048889,0.040057238191366196,0.035567134618759155,0.03160359710454941,0.028191260993480682,0.03323793783783913,0.03731300309300423,0.034193336963653564,0.028649302199482918,0.02865978516638279,0.03225241228938103,0.030766816809773445,0.03141549974679947,0.031773749738931656,0.030803928151726723,0.034075092524290085,0.030806394293904305,0.026066487655043602,0.03214157000184059,0.026799602434039116,0.026714293286204338,0.029167110100388527,0.026331597939133644,0.027539536356925964,0.03194846212863922,0.029035475105047226,0.02823271043598652,0.027930330485105515,0.025568842887878418,0.027745503932237625,0.027227086946368217,0.027832306921482086,0.024280812591314316,0.025751641020178795,0.023821581155061722,0.02665519528090954,0.02346973493695259,0.024283675476908684,0.027341853827238083,0.024815183132886887,0.02396167255938053,0.024412164464592934,0.023480961099267006,0.025738267228007317,0.023762624710798264,0.02354620024561882,0.023489907383918762,0.023790055885910988,0.022467244416475296,0.02309589833021164,0.022872397676110268,0.02233341708779335,0.021296046674251556,0.022857584059238434,0.023166615515947342,0.023302128538489342,0.020164191722869873,0.02241201139986515,0.022064296528697014,0.015128769911825657,0.020817814394831657,
mse,0.2902061343193054,0.019493360072374344,0.013003303669393063,0.009101572446525097,0.00520344777032733,0.004682487342506647,0.0034183852840214968,0.00331871397793293,0.0029080198146402836,0.002804502146318555,0.0018680387875065207,0.0014315795851871371,0.001056897221133113,0.0015112278051674366,0.0014507609885185957,0.0008489387691952288,0.0008335451129823923,0.0008665730711072683,0.0006178352050483227,0.0007810259703546762,0.0011648827930912375,0.0011459850938990712,0.0007350598461925983,0.0006298213265836239,0.0007676347158849239,0.0006248368299566209,0.000665421539451927,0.0006890357472002506,0.0005363032105378807,0.0004320816951803863,0.0005030804313719273,0.00041119250818155706,0.0006164188962429762,0.0003791433700826019,0.0004098120261915028,0.0003206473193131387,0.00032439458300359547,0.0004213335341773927,0.000508015276864171,0.0003734452184289694,0.0004383130872156471,0.00035844475496560335,0.0002782400115393102,0.0002327994880033657,0.0003223790554329753,0.00039754039607942104,0.0003294257912784815,0.00023335216974373907,0.00022980745416134596,0.0002924064756371081,0.00026863280800171196,0.00028747948817908764,0.00028528901748359203,0.00026862838421948254,0.00033340882509946823,0.00027469792985357344,0.00020779698388651013,0.00029170489870011806,0.00020620513532776386,0.00019965598767157644,0.00023456936469301581,0.00019851367687806487,0.00021210237173363566,0.0002904591092374176,0.00023937950027175248,0.0002210191305493936,0.00021584954811260104,0.00018381820700597018,0.00021426937018986791,0.00020679605950135738,0.00021319338702596724,0.00016957623302005231,0.0001857224851846695,0.00016011936531867832,0.00019957330368924886,0.00015322001127060503,0.00016746534674894065,0.00020419173233676702,0.00017766091332305223,0.00016038531612139195,0.00016456414596177638,0.00015752740728203207,0.00018495552649255842,0.0001564516860526055,0.0001582278055138886,0.00015489612997043878,0.00016395346028730273,0.0001417195308022201,0.0001520598161732778,0.0001457550679333508,0.0001410927507095039,0.0001276223483728245,0.00014607494813390076,0.00015226432878989726,0.0001509382709627971,0.00011634588008746505,0.00014104567526374012,0.00013623195991385728,6.913484685355797e-05,0.00012348797463346273,
mae,0.3272427022457123,0.11084496229887009,0.08820951730012894,0.07419990748167038,0.05697795748710632,0.05074353143572807,0.047355152666568756,0.04495721310377121,0.041530121117830276,0.04340745881199837,0.0343657061457634,0.029372625052928925,0.02592995949089527,0.03108787350356579,0.030649567022919655,0.02301607094705105,0.023336749523878098,0.023383069783449173,0.019416289404034615,0.02264537289738655,0.02696700021624565,0.028359031304717064,0.021060943603515625,0.020168090239167213,0.022336626425385475,0.02034367062151432,0.01998855546116829,0.020723609253764153,0.018039019778370857,0.016692083328962326,0.01787508837878704,0.017236189916729927,0.019779561087489128,0.015652811154723167,0.015949638560414314,0.01422165147960186,0.014342397451400757,0.01615850254893303,0.017961889505386353,0.015225857496261597,0.01747984252870083,0.015427002683281898,0.013772498816251755,0.011938962154090405,0.014356614090502262,0.016009269282221794,0.014509827829897404,0.012293023988604546,0.012183761224150658,0.013734216801822186,0.013008730486035347,0.013244455680251122,0.013649098575115204,0.013250193558633327,0.014524226076900959,0.013174271211028099,0.011040052399039268,0.013457567431032658,0.011504938825964928,0.011319335550069809,0.012697036378085613,0.011302853003144264,0.011798380874097347,0.013495032675564289,0.012311761267483234,0.011817902326583862,0.011829592287540436,0.010880572721362114,0.01171477884054184,0.011660164222121239,0.012045654468238354,0.010396645404398441,0.0109917763620615,0.010151521302759647,0.011510848999023438,0.01026624720543623,0.010377267375588417,0.011810502037405968,0.010594513267278671,0.009931329637765884,0.010162795893847942,0.009859980084002018,0.010903265327215195,0.010004191659390926,0.009916434064507484,0.010169196873903275,0.009976247325539589,0.009514115750789642,0.009794536978006363,0.00974965188652277,0.009564715437591076,0.009127727709710598,0.009758077561855316,0.00975592341274023,0.009854153729975224,0.008551644161343575,0.009448659606277943,0.009725690819323063,0.006400866433978081,0.008845639415085316,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 70291     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 70292     
=================================================================
Total params: 140,583
Trainable params: 140,583
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 70,291
Trainable params: 70,291
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 70,292
Trainable params: 70,292
Non-trainable params: 0
_________________________________________________________________
