2021-06-26
loss,0.52159184217453,0.22807736694812775,0.10453303158283234,0.06481464952230453,0.05373922362923622,0.047718919813632965,0.04498405009508133,0.042428482323884964,0.03982870653271675,0.03858901187777519,0.037199247628450394,0.03549309819936752,0.03450176492333412,0.033606015145778656,0.03281600773334503,0.032010916620492935,0.03152737021446228,0.03096959739923477,0.030378058552742004,0.03000514768064022,0.02929219789803028,0.029036488384008408,0.028462419286370277,0.028163447976112366,0.02772408165037632,0.027326535433530807,0.02714662067592144,0.027095332741737366,0.026543214917182922,0.02615628018975258,0.026280054822564125,0.02588588185608387,0.025395341217517853,0.02524516172707081,0.02535572089254856,0.02485605888068676,0.024703510105609894,0.024612214416265488,0.024184569716453552,0.02427862398326397,0.024073194712400436,0.0238416139036417,0.02348560094833374,0.023767290636897087,0.02368084341287613,0.023345179855823517,0.023054013028740883,0.023058848455548286,0.022756200283765793,0.022623570635914803,0.022670339792966843,0.022359764203429222,0.02220061980187893,0.02226204238831997,0.022027049213647842,0.0220364760607481,0.021856747567653656,0.021981820464134216,0.021798601374030113,0.021324921399354935,0.021522238850593567,0.021336030215024948,0.021417662501335144,0.021166818216443062,0.021045414730906487,0.021240411326289177,0.021033355966210365,0.020774416625499725,0.020583240315318108,0.02078479714691639,0.02142398990690708,0.021629657596349716,0.020388327538967133,0.020152857527136803,0.020178770646452904,0.020256083458662033,0.02021990530192852,0.020105233415961266,0.019910741597414017,0.019771868363022804,0.019955633208155632,0.019940093159675598,0.019627617672085762,0.019448833540081978,0.01961491070687771,0.019491614773869514,0.01950494572520256,0.019386116415262222,0.019229542464017868,0.01926415227353573,0.01932755671441555,0.01903010532259941,0.01911759190261364,0.019012022763490677,0.019054802134633064,0.018716417253017426,0.018917400389909744,0.018690479919314384,0.018761305138468742,0.018572481349110603,
mse,0.12614551186561584,0.018191812559962273,0.004122999496757984,0.0014225627528503537,0.0009541412582620978,0.0007438813336193562,0.0006459094001911581,0.0005661030882038176,0.0004957582568749785,0.00045973312808200717,0.00042536683031357825,0.00038409174885600805,0.0003631403960753232,0.00034305822919122875,0.0003256096679251641,0.00031152256997302175,0.0002973517111968249,0.00028612063033506274,0.0002767324331216514,0.000269151059910655,0.00025709555484354496,0.000250449898885563,0.00024045450845733285,0.00023559671535622329,0.00022803359024692327,0.00022018549498170614,0.00021883704175706953,0.0002175302943214774,0.0002083031286019832,0.00020222330931574106,0.0002031555341091007,0.00019758794223889709,0.00019012746633961797,0.00018877261027228087,0.00018806522712111473,0.0001813772541936487,0.0001795227435650304,0.0001772794930730015,0.00017338540055789053,0.00017227380885742605,0.00017063228006009012,0.00016782211605459452,0.0001615515211597085,0.0001659934059716761,0.00016446950030513108,0.00015961722237989306,0.0001553377805976197,0.00015478765999432653,0.0001521437370683998,0.00015062074817251414,0.00015048218483570963,0.00014609091158490628,0.00014414267207030207,0.0001454141893191263,0.00014129797636996955,0.0001421966153429821,0.00014127965550869703,0.00014118285616859794,0.00013843148190062493,0.00013481505447998643,0.00013563138782046735,0.0001327398349530995,0.00013417849550023675,0.00013090691936668009,0.0001332196407020092,0.00013177360233385116,0.00012860017886850983,0.00012728376896120608,0.000123017089208588,0.00012657239858526736,0.0001346464705420658,0.00014600255235563964,0.0001278944982914254,0.00012159685866208747,0.00011951193300774321,0.00011960214760620147,0.00011955474474234506,0.00011777283361880109,0.00011516983795445412,0.00011426000855863094,0.00011532783537404612,0.00011573285883059725,0.00011215583072043955,0.0001105920528061688,0.0001126046699937433,0.00011103822907898575,0.00011148314661113545,0.00010932597069768235,0.00010792467946885154,0.0001079957582987845,0.00010842376650543883,0.00010549555736361071,0.00010557576752034947,0.00010595296771498397,0.00010534725151956081,0.0001024690645863302,0.00010547102283453569,0.00010133954492630437,0.00010270551865687594,0.000100182973255869,
mae,0.2253485918045044,0.09935035556554794,0.0446561761200428,0.027440523728728294,0.022716067731380463,0.020214524120092392,0.018961576744914055,0.017883727326989174,0.016833819448947906,0.01618611067533493,0.01575356349349022,0.01488156896084547,0.014430983923375607,0.014215410687029362,0.013875243254005909,0.013548646122217178,0.01331998035311699,0.01307802926748991,0.012837260030210018,0.01270326692610979,0.012329259887337685,0.012229357846081257,0.012093033641576767,0.011980845592916012,0.011758017353713512,0.011595720425248146,0.011464381590485573,0.011505162343382835,0.011078992858529091,0.011060594581067562,0.011132520623505116,0.010844796895980835,0.010808379389345646,0.010742779821157455,0.010739966295659542,0.010528631508350372,0.010481324978172779,0.01040469016879797,0.010192510671913624,0.01023162342607975,0.010081714019179344,0.010071532800793648,0.009953976608812809,0.009968067519366741,0.01006501168012619,0.009803160093724728,0.009791075251996517,0.009665433317422867,0.009712737053632736,0.009546617045998573,0.009581029415130615,0.00936854537576437,0.00935190450400114,0.009444468654692173,0.009316815994679928,0.009322455152869225,0.009264523163437843,0.009286015294492245,0.009193368256092072,0.009036137722432613,0.009131845086812973,0.00889299251139164,0.009148649871349335,0.008978907950222492,0.008933843113481998,0.009008195251226425,0.008827761746942997,0.008826645091176033,0.00878089852631092,0.008888115175068378,0.009146668948233128,0.009314418770372868,0.008471347391605377,0.00849478505551815,0.008488127961754799,0.008471885696053505,0.008498894050717354,0.008540979586541653,0.008453899063169956,0.008358725346624851,0.008425951935350895,0.008357083424925804,0.00833713449537754,0.008266981691122055,0.008251180872321129,0.008308599703013897,0.008279458619654179,0.008192167617380619,0.008234753273427486,0.008258897811174393,0.008163932710886002,0.00808387715369463,0.008140773512423038,0.008030258119106293,0.008047656156122684,0.007957079447805882,0.008094477467238903,0.007982308976352215,0.007982377894222736,0.00786531437188387,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3643      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3644      
=================================================================
Total params: 7,287
Trainable params: 7,287
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 3,643
Trainable params: 3,643
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 3,644
Trainable params: 3,644
Non-trainable params: 0
_________________________________________________________________
