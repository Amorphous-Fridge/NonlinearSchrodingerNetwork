2021-06-26
loss,0.5341071486473083,0.11525493860244751,0.08308707922697067,0.08500541001558304,0.09703725576400757,0.0839698538184166,0.09625337272882462,0.0734453797340393,0.07177646458148956,0.06563735008239746,0.06253926455974579,0.0519213043153286,0.04430193826556206,0.04076738283038139,0.040299903601408005,0.06531257927417755,0.06271618604660034,0.053899623453617096,0.04700945317745209,0.05850190296769142,0.05302248150110245,0.039634354412555695,0.04134640097618103,0.0365670770406723,0.04600817710161209,0.0501018725335598,0.04730250686407089,0.04571925103664398,0.04130812734365463,0.041355013847351074,0.04713655635714531,0.03945830091834068,0.03766657039523125,0.03368397429585457,0.03392881527543068,0.03537224978208542,0.04357923939824104,0.04301973432302475,0.03776142746210098,0.03445708006620407,0.03242294490337372,0.02829408086836338,0.02776653692126274,0.03452556952834129,0.03186815232038498,0.02974807657301426,0.027942907065153122,0.026219923049211502,0.025904767215251923,0.025275299325585365,0.02377171255648136,0.02205508202314377,0.020318565890192986,0.01949051208794117,0.019416335970163345,0.01910308003425598,0.018830209970474243,0.018551841378211975,0.01834072545170784,0.018138691782951355,0.017987942323088646,0.017711689695715904,0.017688807100057602,0.017411435022950172,0.017221126705408096,0.017209595069289207,0.017207486554980278,0.01692228764295578,0.016851302236318588,0.016613995656371117,0.016568513587117195,0.01630646549165249,0.016456754878163338,0.016215674579143524,0.01619415357708931,0.01610073633491993,0.015835948288440704,0.01571853831410408,0.01579459011554718,0.015574997290968895,0.015839675441384315,0.015413666144013405,0.015367258340120316,0.015292692929506302,0.015155265107750893,0.015017900615930557,0.015127712860703468,0.014958146959543228,0.0147775923833251,0.014840305782854557,0.015038489364087582,0.0147201307117939,0.01451433077454567,0.014549192041158676,0.014472391456365585,0.014392700046300888,0.0142526151612401,0.014322013594210148,0.014240840449929237,0.014329983852803707,
mse,0.14120374619960785,0.004444135818630457,0.002057872246950865,0.0022617196664214134,0.0026777724269777536,0.002110115485265851,0.0027566817589104176,0.001536490861326456,0.0014330701669678092,0.0012445123866200447,0.0011028074659407139,0.0007747886120341718,0.0005721391062252223,0.00048535640235058963,0.0004782986652571708,0.001193589880131185,0.001153832534328103,0.0008528450853191316,0.0006307217990979552,0.0009848023764789104,0.0007928748382255435,0.0004678627592511475,0.00048339643399231136,0.0003835634852293879,0.0006295929197221994,0.0007284823223017156,0.0006502823671326041,0.0006074606790207326,0.0004957049386575818,0.0004961731610819697,0.0006182519136928022,0.00045000811223872006,0.00040504918433725834,0.00032977297087199986,0.00032311389804817736,0.00036887716851197183,0.0005478017264977098,0.0005257682641968131,0.0004074662283528596,0.00033801404060795903,0.00029674096731469035,0.00023448895080946386,0.00023233320098370314,0.0003480046580079943,0.00029570734477601945,0.0002446233993396163,0.00021878596453461796,0.00019712946959771216,0.0001938653294928372,0.00018269750580657274,0.00016339610738214105,0.00014243245823308825,0.00011952704517170787,0.00011114700464531779,0.00010974037286359817,0.000104518148873467,0.00010102324449690059,9.848563058767468e-05,9.644945384934545e-05,9.442637383472174e-05,9.26096981856972e-05,8.97235149750486e-05,8.969441114459187e-05,8.575774700148031e-05,8.552199869882315e-05,8.409855217905715e-05,8.339674968738109e-05,8.109431655611843e-05,8.048447489272803e-05,7.85656739026308e-05,7.770072261337191e-05,7.548728171968833e-05,7.674923836020753e-05,7.419780013151467e-05,7.39984170650132e-05,7.330263179028407e-05,7.092582382028922e-05,7.096667832229286e-05,7.173302583396435e-05,6.854267121525481e-05,7.095005275914446e-05,6.712700997013599e-05,6.639541970798746e-05,6.57012133160606e-05,6.475064583355561e-05,6.341294647427276e-05,6.494507397292182e-05,6.33105737506412e-05,6.167852552607656e-05,6.208469130797312e-05,6.403611041605473e-05,6.0770358686568215e-05,6.041559390723705e-05,5.9479731135070324e-05,5.902188422624022e-05,5.825877815368585e-05,5.8016175898956135e-05,5.7706238294485956e-05,5.699195389752276e-05,5.8163608628092334e-05,
mae,0.22810077667236328,0.04973384365439415,0.03533601015806198,0.03533355891704559,0.04038793221116066,0.035648442804813385,0.04108169674873352,0.03067661076784134,0.029346715658903122,0.02799922414124012,0.025921447202563286,0.021944571286439896,0.018247313797473907,0.01702936738729477,0.016865717247128487,0.026855841279029846,0.02657279558479786,0.02309764176607132,0.019743530079722404,0.02400672622025013,0.021040046587586403,0.016528071835637093,0.01700941100716591,0.015555521473288536,0.019951511174440384,0.021189363673329353,0.02039629966020584,0.01896209642291069,0.017455708235502243,0.017758402973413467,0.01981300674378872,0.01668603904545307,0.01604842208325863,0.014361642301082611,0.01427356619387865,0.015289299190044403,0.01818721927702427,0.01812530681490898,0.016073759645223618,0.01423945464193821,0.013465452939271927,0.012074973434209824,0.011804644018411636,0.014537305571138859,0.013702429831027985,0.012893319129943848,0.012255778536200523,0.01140513177961111,0.011026659049093723,0.010682271793484688,0.00986363273113966,0.009280918166041374,0.008629731833934784,0.008298104628920555,0.008246103301644325,0.008153132162988186,0.00796685554087162,0.007876702584326267,0.007791030220687389,0.007742019835859537,0.007683768402785063,0.007561175152659416,0.0075066350400447845,0.007376059424132109,0.007359211333096027,0.007341806776821613,0.007293472066521645,0.007172424346208572,0.007165959104895592,0.007064312230795622,0.006988825276494026,0.0069556329399347305,0.007003915961831808,0.006863934453576803,0.006822862662374973,0.006869227159768343,0.006728406995534897,0.006689046043902636,0.006757053546607494,0.0066189575009047985,0.006785350851714611,0.006568599957972765,0.0064954860135912895,0.00647355429828167,0.006457333452999592,0.00635134382173419,0.006431983318179846,0.006369907874614,0.0062678512185812,0.0063230665400624275,0.0063857571221888065,0.006254337262362242,0.006222226656973362,0.006073325406759977,0.006165531929582357,0.006042642053216696,0.006082035135477781,0.006102347746491432,0.0060434299521148205,0.0060540153644979,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 18291     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 18292     
=================================================================
Total params: 36,583
Trainable params: 36,583
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 18,291
Trainable params: 18,291
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 18,292
Trainable params: 18,292
Non-trainable params: 0
_________________________________________________________________
