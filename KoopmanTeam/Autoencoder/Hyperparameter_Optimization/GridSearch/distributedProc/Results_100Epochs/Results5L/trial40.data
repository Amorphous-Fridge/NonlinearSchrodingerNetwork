2021-06-26
loss,0.48689690232276917,0.24834094941616058,0.2372780740261078,0.2313586175441742,0.22633689641952515,0.20750494301319122,0.1413419097661972,0.11201194673776627,0.09160583466291428,0.09905613213777542,0.07694321870803833,0.08739019185304642,0.08404875546693802,0.07538312673568726,0.0682956725358963,0.06512683629989624,0.05223819613456726,0.06733079999685287,0.052691344171762466,0.05623086541891098,0.057136572897434235,0.04970766231417656,0.05694116652011871,0.04774264246225357,0.042812105268239975,0.04584106057882309,0.05019645392894745,0.04062482342123985,0.04490852728486061,0.04277145490050316,0.040685251355171204,0.04381069168448448,0.04011455550789833,0.037350114434957504,0.035141170024871826,0.043578341603279114,0.04107195511460304,0.041515156626701355,0.03451765328645706,0.039113592356443405,0.0377424992620945,0.03518425673246384,0.03261382877826691,0.03011941909790039,0.03507247567176819,0.03752371668815613,0.03803582116961479,0.032679568976163864,0.031311023980379105,0.02913009002804756,0.034749820828437805,0.03269261494278908,0.038268670439720154,0.03356834873557091,0.03081389144062996,0.03351353108882904,0.0329161137342453,0.029129724949598312,0.027448052540421486,0.025737881660461426,0.026437778025865555,0.025967266410589218,0.0274018794298172,0.024751264601945877,0.029015880078077316,0.0309634730219841,0.028615519404411316,0.02829950489103794,0.028047842904925346,0.027710897848010063,0.023195844143629074,0.02490495890378952,0.029590299353003502,0.02655864506959915,0.02505730651319027,0.030721943825483322,0.030159898102283478,0.02912474423646927,0.030645819380879402,0.028211519122123718,0.024947648867964745,0.023412108421325684,0.02722211182117462,0.02709904871881008,0.02479022927582264,0.023313570767641068,0.023439832031726837,0.026156499981880188,0.023611951619386673,0.023952171206474304,0.026848306879401207,0.025582021102309227,0.02317679114639759,0.02178780362010002,0.023204393684864044,0.02304130047559738,0.025167474523186684,0.022861020639538765,0.021350465714931488,0.022603444755077362,
mse,0.10155308991670609,0.020637383684515953,0.019611181691288948,0.01893136464059353,0.0181095153093338,0.013945603743195534,0.006002894137054682,0.0038290866650640965,0.0024670385755598545,0.0028429662343114614,0.001728791045024991,0.0022201603278517723,0.0020063617266714573,0.001619370887055993,0.0013309865025803447,0.0011704928474500775,0.0007973483297973871,0.0013249213807284832,0.0007933723391033709,0.0008970436174422503,0.0009098093723878264,0.0007053842418827116,0.0008886006544344127,0.0006423216545954347,0.0005482720443978906,0.000588166294619441,0.0006961941253393888,0.00047399039613083005,0.0005456657381728292,0.000524761329870671,0.00045888242311775684,0.000535361934453249,0.00044280634028837085,0.0003945939533878118,0.00035242244484834373,0.0005249626701697707,0.0004744750913232565,0.0004790977400261909,0.0003388809855096042,0.0004207946767564863,0.0003847282787319273,0.0003395153325982392,0.00029333942802622914,0.00025897857267409563,0.0003538568562362343,0.00040759402327239513,0.0003964229254052043,0.00029749140958301723,0.0002774672757368535,0.00024439464323222637,0.00033192470436915755,0.00030080927535891533,0.0003993367135990411,0.00031469561508856714,0.0002657049335539341,0.0003184547240380198,0.00029324550996534526,0.00023921234242152423,0.00020969350589439273,0.00018998250016011298,0.00019898252503480762,0.0001930198195623234,0.00021234455925878137,0.0001842170604504645,0.00024824339197948575,0.00026355215231887996,0.0002250641700811684,0.0002286910603288561,0.00021740149531979114,0.00021605240181088448,0.00016389063966926187,0.00017894637130666524,0.00023908088041935116,0.000194948457647115,0.00017649192886892706,0.0002788240381050855,0.000258212152402848,0.00023748254170641303,0.00025556274340488017,0.00022143151727505028,0.00017074064817279577,0.00015221517242025584,0.00020807867986150086,0.0002007864968618378,0.00017004409164655954,0.00015195668675005436,0.00015474548854399472,0.0001854791189543903,0.00015454262029379606,0.00016036193119361997,0.0001982485846383497,0.00018473602540325373,0.00015103396435733885,0.00013394876441452652,0.00015379692194983363,0.00015354726929217577,0.0001774366246536374,0.00014345590898301452,0.00012717726349364966,0.00014475002535618842,
mae,0.20422667264938354,0.11280311644077301,0.111113041639328,0.10947749018669128,0.10700123757123947,0.0904623419046402,0.059850215911865234,0.04737446829676628,0.038645774126052856,0.04302296042442322,0.03236386179924011,0.038020916283130646,0.03567482531070709,0.03272397071123123,0.028944849967956543,0.029628200456500053,0.022366736084222794,0.029186315834522247,0.022534117102622986,0.024090435355901718,0.024320846423506737,0.02087276615202427,0.024068329483270645,0.02052176557481289,0.01833304576575756,0.019886767491698265,0.021394670009613037,0.017457788810133934,0.01946083828806877,0.018315138295292854,0.01717749424278736,0.018638761714100838,0.017489124089479446,0.015880335122346878,0.015034537762403488,0.018506431952118874,0.017477186396718025,0.016970941796898842,0.01473427377641201,0.01699323207139969,0.016646217554807663,0.015619785524904728,0.01393140945583582,0.012590484693646431,0.01486936118453741,0.015616045333445072,0.016588659957051277,0.013479572720825672,0.012983101420104504,0.01244876254349947,0.014935288578271866,0.013772113248705864,0.0157728623598814,0.014361931011080742,0.013236334547400475,0.013792945072054863,0.013453603722155094,0.011895985342562199,0.011271100491285324,0.010747191496193409,0.01092437282204628,0.010946926660835743,0.011558767408132553,0.010541465133428574,0.012236079201102257,0.013552937656641006,0.01227820198982954,0.012002954259514809,0.012246699072420597,0.011562696658074856,0.009827450849115849,0.010430306196212769,0.012622819282114506,0.011686728335916996,0.01081776712089777,0.012898504734039307,0.01288347877562046,0.01244895439594984,0.013151207007467747,0.01213463768362999,0.010465579107403755,0.010049484670162201,0.011027065105736256,0.011030181311070919,0.01030031405389309,0.010124295949935913,0.010144073516130447,0.011360671371221542,0.010170727036893368,0.0102049820125103,0.011610469780862331,0.010954639874398708,0.009797328151762486,0.008891998790204525,0.009861689060926437,0.009824909269809723,0.01062707882374525,0.009830860421061516,0.008822040632367134,0.009587597101926804,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34803     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34804     
=================================================================
Total params: 69,607
Trainable params: 69,607
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 34,803
Trainable params: 34,803
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 34,804
Trainable params: 34,804
Non-trainable params: 0
_________________________________________________________________
