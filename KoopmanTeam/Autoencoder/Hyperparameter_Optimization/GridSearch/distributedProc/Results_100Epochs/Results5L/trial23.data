2021-06-26
loss,0.5665605068206787,0.17308446764945984,0.11378566920757294,0.09417790174484253,0.13187021017074585,0.12053656578063965,0.08573924750089645,0.09508635848760605,0.10503476858139038,0.08628546446561813,0.08225315064191818,0.08245520293712616,0.07927434146404266,0.06710655987262726,0.04167220741510391,0.056274913251399994,0.06318976730108261,0.07344413548707962,0.06564374268054962,0.04051397368311882,0.04178003966808319,0.0491134375333786,0.053682614117860794,0.04883355647325516,0.06729552149772644,0.06089916080236435,0.053791314363479614,0.03765513002872467,0.03280764818191528,0.04892323911190033,0.046447135508060455,0.042051803320646286,0.04033474996685982,0.044331904500722885,0.05036839097738266,0.043712787330150604,0.03388771414756775,0.04081264138221741,0.0452900230884552,0.038706760853528976,0.035641495138406754,0.046426139771938324,0.04336542263627052,0.0400986447930336,0.03500174731016159,0.02947993576526642,0.02707565762102604,0.0266819279640913,0.03892361745238304,0.03490256518125534,0.031147131696343422,0.040828555822372437,0.039454806596040726,0.036137234419584274,0.03222860023379326,0.02951710857450962,0.02632715180516243,0.031792446970939636,0.03705831617116928,0.03575238212943077,0.03289834409952164,0.029747335240244865,0.03312647342681885,0.030560247600078583,0.028009872883558273,0.02635476179420948,0.03460611030459404,0.028192628175020218,0.026520416140556335,0.031337086111307144,0.02645117975771427,0.021672707051038742,0.022083096206188202,0.029270699247717857,0.03261929377913475,0.029955469071865082,0.026136741042137146,0.02613948844373226,0.024757446721196175,0.024539627134799957,0.02233858034014702,0.02349374257028103,0.028652580454945564,0.025516031309962273,0.024119947105646133,0.030806146562099457,0.02714986354112625,0.024661311879754066,0.02319217659533024,0.020773019641637802,0.02230636402964592,0.027025215327739716,0.0266252513974905,0.022547461092472076,0.022078104317188263,0.026341745629906654,0.023456616327166557,0.02157430164515972,0.026748361065983772,0.027715271338820457,
mse,0.15815304219722748,0.010014835745096207,0.003869584295898676,0.0026548353489488363,0.004917762707918882,0.004342653788626194,0.002076065866276622,0.0026508013252168894,0.0031885961070656776,0.002251980360597372,0.0019101412035524845,0.0018515826668590307,0.0018317635403946042,0.001279824529774487,0.0005202703177928925,0.0009645092650316656,0.00113487069029361,0.0015356999356299639,0.0012163803912699223,0.0004892119904980063,0.0004891608259640634,0.0007130932644940913,0.000792234088294208,0.000644292333163321,0.0013201688416302204,0.0010479484917595983,0.0007943454547785223,0.0004645904991775751,0.00032663167803548276,0.000695448718033731,0.0006274408078752458,0.00048198600416071713,0.0004691016220021993,0.0005809770664200187,0.0007237932877615094,0.000533658021595329,0.00031247513834387064,0.0004916851175948977,0.0005636867717839777,0.000410617416491732,0.0003513483388815075,0.0006041827145963907,0.0005179719300940633,0.0004454347363207489,0.00033548270585015416,0.00023743099882267416,0.00020110815239604563,0.00019694013462867588,0.0004165255231782794,0.00033362943213433027,0.0002755940950009972,0.00047701632138341665,0.00042825506534427404,0.00036066959728486836,0.0002844792034011334,0.00023873770260252059,0.00019820686429738998,0.0002868605370167643,0.00037592154694721103,0.0003514415002427995,0.00029948930023238063,0.0002455662761349231,0.0003046488855034113,0.00025565357645973563,0.00021446068421937525,0.00020268672960810363,0.0003237999917473644,0.0002227755030617118,0.00019696376693900675,0.0002692611305974424,0.00019109460117761046,0.0001364123891107738,0.00015021921717561781,0.0002467849408276379,0.000290306459646672,0.00024592128465883434,0.00018821728008333594,0.00018902175361290574,0.00017467520956415683,0.00016658562526572496,0.00013856329314876348,0.00015740314847789705,0.0002372911258134991,0.00017592511721886694,0.00016607882571406662,0.0002639534941408783,0.00019987262203358114,0.00016595804481767118,0.00014866775018163025,0.00012405554298311472,0.00014768943947274238,0.0002038946549873799,0.00019791316299233586,0.00014185991312842816,0.00013547035632655025,0.00019471017003525048,0.00014929483586456627,0.00012714459444396198,0.00020471453899517655,0.00021076133998576552,
mae,0.23482245206832886,0.07468083500862122,0.04867434501647949,0.040197938680648804,0.05626140534877777,0.05128184333443642,0.03595028072595596,0.04033634066581726,0.046203624457120895,0.0373523011803627,0.035331908613443375,0.03596948832273483,0.03411512449383736,0.02830413356423378,0.017997993156313896,0.024128371849656105,0.026894066482782364,0.03241857513785362,0.029295675456523895,0.017496146261692047,0.018299559131264687,0.020670082420110703,0.022155320271849632,0.020510287955403328,0.029464976862072945,0.026399943977594376,0.023692915216088295,0.016776081174612045,0.014000999741256237,0.020880088210105896,0.019904850050807,0.017707502469420433,0.017313236370682716,0.019114844501018524,0.022083470597863197,0.01914326846599579,0.01504762563854456,0.01766211912035942,0.019750133156776428,0.016861572861671448,0.015218144282698631,0.020685551688075066,0.019955938681960106,0.018364913761615753,0.015426477417349815,0.012936582788825035,0.011861669830977917,0.011559809558093548,0.016821034252643585,0.015090648084878922,0.013374208472669125,0.01801806129515171,0.018132038414478302,0.01658306084573269,0.013180741108953953,0.012375209480524063,0.011086043901741505,0.013261944986879826,0.01574067212641239,0.015573011711239815,0.014450554735958576,0.012512334622442722,0.014411342330276966,0.013249673880636692,0.012099917978048325,0.011226126924157143,0.015330922789871693,0.01220659352838993,0.01102222129702568,0.013557191006839275,0.011323626153171062,0.009305360727012157,0.009545274078845978,0.012747198343276978,0.015177186578512192,0.013779770582914352,0.01147264800965786,0.011297229677438736,0.010371757671236992,0.01042627077549696,0.009432798251509666,0.00993394572287798,0.012478799559175968,0.011011187918484211,0.010470551438629627,0.013993347994983196,0.01142115518450737,0.010800790973007679,0.009506646543741226,0.008702144026756287,0.009411650709807873,0.011514482088387012,0.011591965332627296,0.009709437377750874,0.00942843034863472,0.01146027073264122,0.010204028338193893,0.009082511998713017,0.011953308247029781,0.012999825179576874,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 19923     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 19924     
=================================================================
Total params: 39,847
Trainable params: 39,847
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 19,923
Trainable params: 19,923
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 19,924
Trainable params: 19,924
Non-trainable params: 0
_________________________________________________________________
