2021-06-26
loss,0.3154011070728302,0.1258133053779602,0.08558502048254013,0.08001160621643066,0.07576838880777359,0.09081292152404785,0.08508303016424179,0.06422489881515503,0.05771660804748535,0.052164219319820404,0.048825010657310486,0.04743749275803566,0.04563245177268982,0.06432808935642242,0.06794434040784836,0.06068919226527214,0.05135773494839668,0.05457787960767746,0.07379457354545593,0.06560873985290527,0.061027683317661285,0.054975032806396484,0.033535413444042206,0.032861147075891495,0.04624138027429581,0.05213620141148567,0.04150748625397682,0.04625500366091728,0.038890399038791656,0.03986728563904762,0.03755570948123932,0.03619498386979103,0.03410257026553154,0.031641483306884766,0.030106334015727043,0.030186694115400314,0.031754180788993835,0.04159488156437874,0.04817939177155495,0.043984703719615936,0.03966493904590607,0.034234821796417236,0.03341349959373474,0.054331403225660324,0.04847361519932747,0.03969745337963104,0.028212187811732292,0.02556588500738144,0.028011221438646317,0.03556941822171211,0.04255865514278412,0.04385101795196533,0.04077538102865219,0.0432426780462265,0.03786657750606537,0.0356811061501503,0.040257807821035385,0.03964173421263695,0.03607071936130524,0.03301214799284935,0.030850110575556755,0.029131591320037842,0.026465022936463356,0.026492243632674217,0.026112394407391548,0.027655217796564102,0.026385994628071785,0.03102446347475052,0.0393538735806942,0.03596263378858566,0.030716486275196075,0.02858693338930607,0.02558640018105507,0.024102559313178062,0.022216998040676117,0.0227969903498888,0.024700846523046494,0.036509569734334946,0.039045702666044235,0.03408990055322647,0.03627127781510353,0.03319333493709564,0.029661454260349274,0.026679566130042076,0.024633893743157387,0.021445557475090027,0.018518559634685516,0.01871354505419731,0.017799843102693558,0.01799422688782215,0.017767611891031265,0.017449332401156425,0.017306677997112274,0.017058758065104485,0.01713898405432701,0.01700417324900627,0.01690509170293808,0.01666274107992649,0.01692250929772854,0.016886252909898758,
mse,0.042482148855924606,0.004722151439636946,0.0022123511880636215,0.0018949949881061912,0.001673386199399829,0.0023969279136508703,0.0020579511765390635,0.0012011552462354302,0.0009413757361471653,0.0007767797214910388,0.0006796001107431948,0.0006346157169900835,0.0005861511453986168,0.001266011269763112,0.0012927018105983734,0.0010191509500145912,0.0007268147892318666,0.000861282111145556,0.0015380799304693937,0.0012441374128684402,0.0010529326973482966,0.0008855962078087032,0.0003260872035752982,0.0003135698789265007,0.0006510294042527676,0.0007550792652182281,0.0005018855445086956,0.0006359957624226809,0.00043557363096624613,0.00044483982492238283,0.00038999662501737475,0.00036489462945610285,0.00031893420964479446,0.0002762500662356615,0.00024983330513350666,0.00025383391766808927,0.00029147317400202155,0.0004939602804370224,0.0006588077521882951,0.0005368405836634338,0.0004391865513753146,0.0003413113590795547,0.0003134230792056769,0.0008362854132428765,0.0006483931210823357,0.00044448208063840866,0.00023410312132909894,0.00018683509551919997,0.0002337181504117325,0.00035806468804366887,0.0005175017868168652,0.0005448716692626476,0.00047031600843183696,0.000514184299390763,0.0003943229094147682,0.0003616732428781688,0.0004547587886918336,0.0004336714628152549,0.00035862394724972546,0.00030036180396564305,0.0002633129770401865,0.0002352459414396435,0.0001980450178962201,0.00019695257651619613,0.0001940149668371305,0.0002141690201824531,0.00019380947924219072,0.0002776194305624813,0.0004372066759970039,0.0003553892020136118,0.0002699314500205219,0.0002257716259919107,0.00018145634385291487,0.0001618933747522533,0.00014788845146540552,0.00015434084343723953,0.00019051757408306003,0.00038113922346383333,0.00042582082096487284,0.00032646156614646316,0.00036833607009612024,0.0003052185056731105,0.00024290848523378372,0.00019723748846445233,0.00017178355483338237,0.00013756487169303,0.00010349397780373693,9.924154437612742e-05,9.130517719313502e-05,9.227310511050746e-05,8.877010259311646e-05,8.515806985087693e-05,8.412502938881516e-05,8.176903065759689e-05,8.21017092675902e-05,8.056763908825815e-05,7.909419218776748e-05,7.749117503408343e-05,7.990394806256518e-05,7.910896238172427e-05,
mae,0.13295525312423706,0.05349437892436981,0.036753423511981964,0.03372063487768173,0.03221770375967026,0.038972463458776474,0.036351993680000305,0.027503816410899162,0.024447008967399597,0.022645412012934685,0.020868176594376564,0.020304257050156593,0.01967046782374382,0.027223724871873856,0.02954067476093769,0.025996819138526917,0.021730341017246246,0.022739611566066742,0.031465671956539154,0.028691548854112625,0.02636953629553318,0.023847384378314018,0.014457007870078087,0.014173218980431557,0.019458262249827385,0.02246650494635105,0.017718728631734848,0.01939285174012184,0.016497239470481873,0.016568699851632118,0.015643930062651634,0.015189433470368385,0.014685423113405704,0.013844282366335392,0.012982948683202267,0.01309833861887455,0.01364840753376484,0.017619751393795013,0.02066638506948948,0.018810266628861427,0.01734509877860546,0.014559421688318253,0.014205818995833397,0.024057788774371147,0.02222815342247486,0.01707354746758938,0.011955737136304379,0.011068315245211124,0.012012911029160023,0.015031383372843266,0.018256278708577156,0.01916975900530815,0.017458420246839523,0.018437188118696213,0.015528565272688866,0.015097144991159439,0.017383594065904617,0.0179881788790226,0.015305589884519577,0.014236574992537498,0.013496482744812965,0.01267028134316206,0.011382400058209896,0.01136693824082613,0.01110390666872263,0.01180027611553669,0.011340249329805374,0.013307005167007446,0.01719936728477478,0.015319515019655228,0.013444713316857815,0.012415959499776363,0.010637683793902397,0.010182628408074379,0.009564031846821308,0.009641540236771107,0.010609755292534828,0.01608423888683319,0.017483269795775414,0.01472947932779789,0.016764525324106216,0.014422645792365074,0.012153140269219875,0.011368334293365479,0.010601818561553955,0.009209662675857544,0.007978830486536026,0.00831044465303421,0.007794263307005167,0.007915124297142029,0.00788978859782219,0.0076471311040222645,0.0075837839394807816,0.007390809711068869,0.007462760899215937,0.007304066326469183,0.007358693517744541,0.007147316820919514,0.007271608803421259,0.007317753974348307,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 13355     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 13356     
=================================================================
Total params: 26,711
Trainable params: 26,711
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 13,355
Trainable params: 13,355
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 13,356
Trainable params: 13,356
Non-trainable params: 0
_________________________________________________________________
