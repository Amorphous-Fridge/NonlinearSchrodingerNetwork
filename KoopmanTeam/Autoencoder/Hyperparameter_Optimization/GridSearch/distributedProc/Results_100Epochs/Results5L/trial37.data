2021-06-26
loss,0.40589848160743713,0.20615671575069427,0.13473904132843018,0.10026443749666214,0.0902964398264885,0.09906577318906784,0.08992399275302887,0.09020427614450455,0.09556829184293747,0.08423878997564316,0.09968961775302887,0.08396761119365692,0.06784769892692566,0.053560659289360046,0.057115692645311356,0.08369454741477966,0.07351993769407272,0.060277655720710754,0.05451451614499092,0.04539267718791962,0.04245303198695183,0.04347817599773407,0.04920322075486183,0.06753947585821152,0.0621839202940464,0.046458784490823746,0.04354967549443245,0.04226233810186386,0.03449489548802376,0.05235302075743675,0.04261121153831482,0.042172860354185104,0.03597273677587509,0.03687170520424843,0.03913765028119087,0.03410853073000908,0.048585209995508194,0.05528337508440018,0.049195218831300735,0.04246347025036812,0.03363873437047005,0.04440190643072128,0.04351651668548584,0.0383068211376667,0.03115370124578476,0.024079320952296257,0.03581468388438225,0.0379406176507473,0.04110890254378319,0.035597916692495346,0.03310483321547508,0.030001873150467873,0.027813879773020744,0.028775859624147415,0.034642066806554794,0.038345638662576675,0.032821174710989,0.0238741897046566,0.023715335875749588,0.0328684076666832,0.03612051159143448,0.0327754020690918,0.02848793752491474,0.03344647213816643,0.03261890262365341,0.030699267983436584,0.02638670615851879,0.02102242223918438,0.021004721522331238,0.02371067926287651,0.025613859295845032,0.030360789969563484,0.02972502075135708,0.0280730240046978,0.02415565773844719,0.024306295439600945,0.027225935831665993,0.03137250244617462,0.03018520586192608,0.027460606768727303,0.024482380598783493,0.021273044869303703,0.02293981984257698,0.025963686406612396,0.0258296187967062,0.027975481003522873,0.02978387102484703,0.02737407386302948,0.024888670071959496,0.022245587781071663,0.02096225507557392,0.023150455206632614,0.028975898399949074,0.026519320905208588,0.020093264058232307,0.01948770135641098,0.02174493856728077,0.022935835644602776,0.028050033375620842,0.025894736871123314,
mse,0.07347553223371506,0.01434311829507351,0.005400282796472311,0.003032482462003827,0.0024481264408677816,0.002905740635469556,0.00255244760774076,0.0023695239797234535,0.0025950083509087563,0.0020376634784042835,0.002852081088349223,0.0020372772123664618,0.0013235955266281962,0.0008351741707883775,0.000973642454482615,0.001983943162485957,0.0015154082793742418,0.0010463799117133021,0.0008272372651845217,0.0006134322029538453,0.0005476483493112028,0.000554606958758086,0.0006965920911170542,0.0012657736660912633,0.0010662153363227844,0.0006278774817474186,0.000538849039003253,0.000524899922311306,0.00035093032056465745,0.0008004143019206822,0.0005159578868187964,0.0004925993853248656,0.00037417991552501917,0.0003845343308057636,0.000421544915298,0.00034599489299580455,0.0006996315787546337,0.0008548320620320737,0.0006780991679988801,0.0004967846907675266,0.00032204441959038377,0.0005590736982412636,0.0005231393733993173,0.00040380589780397713,0.0002791355364024639,0.00017371638386975974,0.00037888329825364053,0.0004055116733070463,0.000469213497126475,0.0003531923284754157,0.00030541163869202137,0.0002534468949306756,0.00022519878984894603,0.0002462259435560554,0.0003396092797629535,0.00040395415271632373,0.0002975735696963966,0.0001726870541460812,0.00016709764895495027,0.0002996988478116691,0.00035970460157841444,0.0002930418704636395,0.00022692105267196894,0.00030623358907178044,0.0002891522890422493,0.0002587854687590152,0.00019977489137090743,0.00013249194307718426,0.00013263116125017405,0.00016458090976811945,0.0001838905009208247,0.00025527167599648237,0.00025106908287853,0.0002240116591565311,0.00016980682266876101,0.00016572559252381325,0.00020616130495909601,0.0002678517485037446,0.0002487829769961536,0.00020639452850446105,0.00016293436056002975,0.00012901498121209443,0.00015084769984241575,0.00018751088646240532,0.0001859644107753411,0.0002176104171667248,0.00024177019076887518,0.00020446343114599586,0.00016781259910203516,0.0001389406097587198,0.00013014214346185327,0.00015114406414795667,0.00022582009842153639,0.00019252501078881323,0.00012093705299776047,0.00011181805894011632,0.00013512818259187043,0.00014985151938162744,0.00021230956190265715,0.00018244450620841235,
mae,0.17138835787773132,0.08663811534643173,0.05769529938697815,0.042939119040966034,0.03810647875070572,0.04219925403594971,0.038882430642843246,0.03848988562822342,0.04094547778367996,0.035728324204683304,0.04264567792415619,0.03527296334505081,0.02880682237446308,0.02268642745912075,0.024269625544548035,0.035392604768276215,0.03160616755485535,0.025792580097913742,0.02349795773625374,0.019400309771299362,0.01817551627755165,0.01842905953526497,0.020810648798942566,0.029089154675602913,0.02668679878115654,0.01980965957045555,0.01832386665046215,0.017812343314290047,0.014760967344045639,0.02238043025135994,0.018174879252910614,0.018383122980594635,0.015531455166637897,0.015598323196172714,0.016820795834064484,0.014669448137283325,0.020029036328196526,0.023743433877825737,0.021044686436653137,0.017954133450984955,0.014266464859247208,0.018847482278943062,0.01863018050789833,0.015820352360606194,0.013193740509450436,0.01023704931139946,0.014806611463427544,0.01616659015417099,0.018399257212877274,0.015422290191054344,0.014163440093398094,0.012837723828852177,0.011756434105336666,0.012372373603284359,0.015108922496438026,0.016465716063976288,0.014005853794515133,0.010087878443300724,0.009977308101952076,0.014129238203167915,0.015288004651665688,0.013998151756823063,0.012114019133150578,0.014214009046554565,0.014443228021264076,0.012982970103621483,0.011330829001963139,0.008982132188975811,0.008830718696117401,0.010137643665075302,0.010983687825500965,0.013091884553432465,0.012642435729503632,0.011860376223921776,0.010154342278838158,0.010357022285461426,0.01162857748568058,0.013470294885337353,0.012961034663021564,0.011376873590052128,0.010652732104063034,0.009238768368959427,0.009612289257347584,0.01072736456990242,0.011052948422729969,0.011846870183944702,0.01280592754483223,0.011717772111296654,0.010723389685153961,0.00940986443310976,0.008744249120354652,0.00991277676075697,0.012792728841304779,0.011877610348165035,0.008609428070485592,0.008285160176455975,0.00916787888854742,0.009743668138980865,0.012034375220537186,0.011312463320791721,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34795     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34796     
=================================================================
Total params: 69,591
Trainable params: 69,591
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 34,795
Trainable params: 34,795
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 34,796
Trainable params: 34,796
Non-trainable params: 0
_________________________________________________________________
