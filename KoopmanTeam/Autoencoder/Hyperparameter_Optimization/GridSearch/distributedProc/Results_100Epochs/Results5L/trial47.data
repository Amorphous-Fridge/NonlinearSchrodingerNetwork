2021-06-26
loss,0.6864464282989502,0.23263275623321533,0.18188822269439697,0.10585814714431763,0.08504972606897354,0.09384068846702576,0.0743316262960434,0.08115441352128983,0.07894641160964966,0.08729787915945053,0.07387805730104446,0.05188048258423805,0.05116204917430878,0.07347980886697769,0.0687677264213562,0.055147022008895874,0.058753613382577896,0.050105929374694824,0.037268806248903275,0.03364100307226181,0.03611549735069275,0.0361500009894371,0.051564671099185944,0.04519842937588692,0.03940397873520851,0.03459075465798378,0.04418446123600006,0.03657618910074234,0.03337789699435234,0.03535407409071922,0.039312124252319336,0.032441645860672,0.030879266560077667,0.030911486595869064,0.03155127912759781,0.026010572910308838,0.0363384447991848,0.03241683542728424,0.029451392590999603,0.031024115160107613,0.034069307148456573,0.029845280572772026,0.02688109129667282,0.031121976673603058,0.03308741748332977,0.029240770265460014,0.02882472798228264,0.02887011505663395,0.026954038068652153,0.024043140932917595,0.024744441732764244,0.027915265411138535,0.027011429890990257,0.028982913121581078,0.028993165120482445,0.026768973097205162,0.024124909192323685,0.020006705075502396,0.02399883046746254,0.026817280799150467,0.02693820558488369,0.023838793858885765,0.0247807614505291,0.028562242165207863,0.025788147002458572,0.01967630907893181,0.027130791917443275,0.024029849097132683,0.026281729340553284,0.023950638249516487,0.0218490120023489,0.015573796816170216,0.014511924237012863,0.021829718723893166,0.022184215486049652,0.026232058182358742,0.02233727276325226,0.022737102583050728,0.023962726816534996,0.025388842448592186,0.021263660863041878,0.021509291604161263,0.024947132915258408,0.021272294223308563,0.021026160567998886,0.024488672614097595,0.020861182361841202,0.0243819709867239,0.023756759241223335,0.021884195506572723,0.020015502348542213,0.020925741642713547,0.02278284728527069,0.021246934309601784,0.020480221137404442,0.020022695884108543,0.017649061977863312,0.01810654252767563,0.020740576088428497,0.023278770968317986,
mse,0.23322352766990662,0.018420154228806496,0.011479610577225685,0.003373738843947649,0.0021261521615087986,0.0026519412640482187,0.0016209424939006567,0.001996804727241397,0.0017928577726706862,0.0021505914628505707,0.0016020734328776598,0.0007669719052501023,0.0007541446248069406,0.0016082263318821788,0.0013738824054598808,0.0008828481077216566,0.000958768418058753,0.0007117668283171952,0.0004119024670217186,0.0003421975998207927,0.00038173512439243495,0.00038409800617955625,0.0007415065774694085,0.0005681469920091331,0.0004401427577249706,0.00033997109858319163,0.0005411487654782832,0.0003801757702603936,0.00032426146208308637,0.00035828747786581516,0.00043883308535441756,0.0002999063581228256,0.00027222008793614805,0.0002800433721859008,0.0002975615789182484,0.00019735783280339092,0.0003684221301227808,0.0003062105970457196,0.0002504125004634261,0.00027423645951785147,0.0003232975723221898,0.00025501218624413013,0.00020536778902169317,0.0002772976004052907,0.0003015223192051053,0.00024006582680158317,0.00023492361651733518,0.0002358561905566603,0.00020365399541333318,0.0001692664372967556,0.00017509884492028505,0.0002198803995270282,0.00021054847456980497,0.0002382660168223083,0.00023234414402395487,0.00020705982751678675,0.00016277098620776087,0.00011765411909436807,0.00016327190678566694,0.00020154271624051034,0.00019820267334580421,0.00016113858146127313,0.0001723013847367838,0.00022575692855753005,0.00018612756684888154,0.00011832248128484935,0.0002005944843403995,0.0001638746471144259,0.00018878059927374125,0.00015984958736225963,0.0001379565364914015,7.623394776601344e-05,6.219800707185641e-05,0.0001397335436195135,0.0001387782976962626,0.00018844581791199744,0.00014194558025337756,0.00014487755834124982,0.00016307456826325506,0.00017844040121417493,0.0001285784674109891,0.00013746802869718522,0.0001732946402626112,0.00012805938604287803,0.00012606738891918212,0.0001683947048150003,0.00012427795445546508,0.000166018377058208,0.00015439277922268957,0.00013291731011122465,0.0001148985538748093,0.00012462855374906212,0.00014414389443118125,0.0001269036583835259,0.00011835514305857942,0.00011282198829576373,8.867435826687142e-05,9.347683953819796e-05,0.00012041485751979053,0.0001494737371103838,
mae,0.296323299407959,0.1070852279663086,0.08061176538467407,0.04521871730685234,0.03607570007443428,0.03955746814608574,0.03152261674404144,0.0345795601606369,0.03299916163086891,0.03721202537417412,0.031028924509882927,0.022023318335413933,0.021783189848065376,0.030878711491823196,0.02969181537628174,0.023491691797971725,0.02497135102748871,0.02126247249543667,0.015823645517230034,0.014288739301264286,0.015299893915653229,0.0154177937656641,0.022676952183246613,0.019742796197533607,0.016525540500879288,0.014480250887572765,0.019327478483319283,0.016020387411117554,0.014187298715114594,0.015099645592272282,0.016603734344244003,0.013432852923870087,0.013198751956224442,0.013209223747253418,0.013494504615664482,0.011178719811141491,0.015478890389204025,0.013657765462994576,0.012381535023450851,0.013344916515052319,0.0148216737434268,0.012545622885227203,0.011458462104201317,0.013388642109930515,0.01409248448908329,0.012533494271337986,0.012470816262066364,0.01230688113719225,0.011382723227143288,0.010221388190984726,0.01067008264362812,0.01195375807583332,0.011471545323729515,0.012403571978211403,0.012908863835036755,0.011514866724610329,0.010358056984841824,0.00841494556516409,0.01033055316656828,0.011474759317934513,0.011702447198331356,0.010109246708452702,0.010511064901947975,0.012369363568723202,0.010935497470200062,0.008205623365938663,0.011430126614868641,0.010295633226633072,0.011625131592154503,0.010555666871368885,0.009229389950633049,0.006655694451183081,0.006175414193421602,0.00930374301970005,0.009453365579247475,0.011086026206612587,0.009659716859459877,0.00982966460287571,0.010003430768847466,0.010549656115472317,0.009289784356951714,0.009218087419867516,0.010843610391020775,0.008986290544271469,0.008986959233880043,0.010629181750118732,0.008903873153030872,0.0105350436642766,0.010345633141696453,0.009306534193456173,0.008516985923051834,0.008796457201242447,0.009784279391169548,0.009070291183888912,0.008645333349704742,0.008115367032587528,0.007530570030212402,0.007637562230229378,0.008960179053246975,0.010278518311679363,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 51211     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 51212     
=================================================================
Total params: 102,423
Trainable params: 102,423
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 51,211
Trainable params: 51,211
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 51,212
Trainable params: 51,212
Non-trainable params: 0
_________________________________________________________________
