2021-06-26
loss,0.8353647589683533,0.27214425802230835,0.25256940722465515,0.23077799379825592,0.2082587480545044,0.1528066098690033,0.1380741149187088,0.10453972220420837,0.10169419646263123,0.0779687911272049,0.07851409912109375,0.09678798913955688,0.06928664445877075,0.08022841811180115,0.07571402937173843,0.06247543916106224,0.05552179366350174,0.05470180884003639,0.05627521127462387,0.05504521727561951,0.058177873492240906,0.04087914898991585,0.04648057371377945,0.05096779763698578,0.04978472366929054,0.04460613429546356,0.04224270209670067,0.04065261408686638,0.03960471972823143,0.03678213432431221,0.03652011975646019,0.04003370180726051,0.03543330356478691,0.032136209309101105,0.03613591566681862,0.03668281063437462,0.035540658980607986,0.0347326435148716,0.030357694253325462,0.03127530589699745,0.02867014706134796,0.03205309435725212,0.03316996619105339,0.03044937364757061,0.03174234554171562,0.02751944586634636,0.024060240015387535,0.02666962891817093,0.027215514332056046,0.03005017712712288,0.027113627642393112,0.02766364812850952,0.03130277246236801,0.02717128023505211,0.025642583146691322,0.023303689435124397,0.02454725094139576,0.025205405429005623,0.027438053861260414,0.026179520413279533,0.02473430708050728,0.028592202812433243,0.02443445660173893,0.022431235760450363,0.024109847843647003,0.024747468531131744,0.02472718432545662,0.02320260927081108,0.022372979670763016,0.026588020846247673,0.025606555864214897,0.02283678948879242,0.023636331781744957,0.020300164818763733,0.02445734478533268,0.0237528458237648,0.022057048976421356,0.022632887586951256,0.02094724029302597,0.02083880826830864,0.022961074486374855,0.022424669936299324,0.02337893284857273,0.021458303555846214,0.022703006863594055,0.020284177735447884,0.01722540520131588,0.022565007209777832,0.022107135504484177,0.021588720381259918,0.021074466407299042,0.01753256469964981,0.022193264216184616,0.022997377440333366,0.02421410381793976,0.022505732253193855,0.01932370848953724,0.01984245330095291,0.02197681926190853,0.02284226194024086,
mse,0.42016860842704773,0.023053478449583054,0.020758891478180885,0.017927762120962143,0.012808931060135365,0.006670136004686356,0.005550540518015623,0.0031956732273101807,0.003009582171216607,0.0017564716981723905,0.0017620861763134599,0.0026471803430467844,0.0013888272223994136,0.0018992358818650246,0.001569917774759233,0.0011378205381333828,0.0008913145284168422,0.0008486260194331408,0.0009186122333630919,0.000855043763294816,0.0009680486982688308,0.0004932366427965462,0.0006032575620338321,0.0007430948317050934,0.00069015147164464,0.0005530103808268905,0.0005086506716907024,0.0004651397466659546,0.00045052857603877783,0.0003882569435518235,0.0003805218730121851,0.0004538581124506891,0.0003578371542971581,0.0002955905220005661,0.0003731581091415137,0.0003826984029728919,0.0003569188411347568,0.0003333137137815356,0.00026057136710733175,0.00027712254086509347,0.00023497847723774612,0.0002942933060694486,0.0003108944511041045,0.00025441142497584224,0.0002784086100291461,0.00021359998208936304,0.0001675606908975169,0.00020797053002752364,0.00020989394397474825,0.0002496436645742506,0.0002061098493868485,0.00021952949464321136,0.0002676769800018519,0.00020419107750058174,0.00018373622151557356,0.00015500867448281497,0.00017186504555866122,0.00018053835083264858,0.00021568327792920172,0.00019170826999470592,0.0001715275866445154,0.00023394862364511937,0.00016984756803140044,0.00014440988888964057,0.00016671724733896554,0.00017069093883037567,0.00017301995831076056,0.00015079573495313525,0.00014539565017912537,0.00019500082999002188,0.0001828514941735193,0.00015074023394845426,0.0001578693772898987,0.00011924475256819278,0.0001706775656202808,0.0001573278132127598,0.000137994546093978,0.00014454121992457658,0.0001267117913812399,0.00012685034016612917,0.00014810678840149194,0.00014031161845196038,0.0001497616176493466,0.00012981660256627947,0.00014405191177502275,0.00011952679778914899,8.959768456406891e-05,0.0001421745982952416,0.00013889373803976923,0.00013110002328176051,0.00012423258158378303,9.227963164448738e-05,0.0001412183919455856,0.00014631604426540434,0.00016296590911224484,0.0001384518836857751,0.00010985213157255203,0.00011413831089157611,0.00013723256415687501,0.00014537698007188737,
mae,0.36251595616340637,0.1161527931690216,0.11064917594194412,0.10292278975248337,0.08909667283296585,0.06478216499090195,0.05802876129746437,0.04459552839398384,0.043607987463474274,0.03343485668301582,0.03345903009176254,0.04157888516783714,0.029441090300679207,0.03451044484972954,0.03227377310395241,0.027121733874082565,0.023713229224085808,0.023069705814123154,0.024181419983506203,0.023408982902765274,0.025476152077317238,0.01702612079679966,0.01935792714357376,0.021955594420433044,0.02160937339067459,0.019096842035651207,0.017963740974664688,0.017207249999046326,0.016922326758503914,0.015454556792974472,0.015734020620584488,0.016814226284623146,0.015150022692978382,0.013650506734848022,0.01570623554289341,0.01574466936290264,0.015056688338518143,0.0145048126578331,0.012769256718456745,0.013374928385019302,0.012275252491235733,0.013697247952222824,0.014364895410835743,0.012889477424323559,0.013636008836328983,0.011595010757446289,0.010197537951171398,0.011400209739804268,0.011493658646941185,0.01279602199792862,0.011724426411092281,0.01182028092443943,0.013903476297855377,0.011688235215842724,0.010946772061288357,0.009867786429822445,0.010453831404447556,0.010580220259726048,0.011894132941961288,0.011283112689852715,0.010502654127776623,0.0122674023732543,0.010374699719250202,0.00954454392194748,0.010288765653967857,0.010643282905220985,0.010337249375879765,0.009773831814527512,0.00932623166590929,0.011336472816765308,0.010930615477263927,0.009611050598323345,0.010068723931908607,0.00862034410238266,0.010494508780539036,0.010088606737554073,0.009349497966468334,0.009547666646540165,0.008910332806408405,0.008839480578899384,0.009733532555401325,0.009468385949730873,0.009969674982130527,0.009133639745414257,0.009705740958452225,0.00854589231312275,0.0073529500514268875,0.009694374166429043,0.009436419233679771,0.00920422188937664,0.009017635136842728,0.007521374616771936,0.009419593028724194,0.009716109372675419,0.01055732648819685,0.00968235731124878,0.008124797604978085,0.008532404899597168,0.009477931074798107,0.009853705763816833,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 144547    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 144548    
=================================================================
Total params: 289,095
Trainable params: 289,095
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 144,547
Trainable params: 144,547
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 144,548
Trainable params: 144,548
Non-trainable params: 0
_________________________________________________________________
