2021-06-26
loss,0.38713812828063965,0.15676669776439667,0.10106154531240463,0.08734282851219177,0.0662093237042427,0.05833179131150246,0.051883649080991745,0.04939786344766617,0.04898800700902939,0.045302268117666245,0.057965122163295746,0.0752565860748291,0.051850877702236176,0.05803745239973068,0.05829496681690216,0.054548267275094986,0.04907972738146782,0.0475739948451519,0.05925995856523514,0.04793452098965645,0.05005287006497383,0.047836046665906906,0.04413783177733421,0.04715413227677345,0.06283491849899292,0.05690416321158409,0.05118027701973915,0.046713825315237045,0.04068639129400253,0.04064757004380226,0.04207941144704819,0.0397171750664711,0.037414535880088806,0.03445469215512276,0.036362022161483765,0.04055654630064964,0.03687460348010063,0.03447021171450615,0.03307304158806801,0.031087134033441544,0.048920728266239166,0.045374561101198196,0.04120844230055809,0.03875485807657242,0.03584787994623184,0.03251396119594574,0.02898809127509594,0.02686549723148346,0.02532375045120716,0.024270424619317055,0.02336800843477249,0.022778348997235298,0.021495936438441277,0.02107357792556286,0.020612426102161407,0.020424963906407356,0.020202064886689186,0.020060958340764046,0.020088309422135353,0.019779765978455544,0.019700096920132637,0.01960764266550541,0.019335076212882996,0.019376253709197044,0.01910165697336197,0.019095849245786667,0.018953366205096245,0.018743552267551422,0.018877146765589714,0.018740562722086906,0.018466832116246223,0.018402721732854843,0.018447555601596832,0.018276989459991455,0.018153397366404533,0.02033444494009018,0.027424419298768044,0.029775820672512054,0.02966715767979622,0.027148639783263206,0.02541574463248253,0.02385161630809307,0.02280803956091404,0.022308025509119034,0.02916235476732254,0.031696077436208725,0.02838863432407379,0.026385987177491188,0.024901485070586205,0.023721855133771896,0.02363726682960987,0.03470021113753319,0.03391869366168976,0.031006677076220512,0.028660990297794342,0.02689194120466709,0.02491624653339386,0.023576384410262108,0.02227150648832321,0.021437713876366615,
mse,0.0505397766828537,0.007756025064736605,0.002949048299342394,0.0021366276778280735,0.0012484908802434802,0.0009651822620071471,0.0007496150792576373,0.0006777782691642642,0.0006711463793180883,0.000585898756980896,0.0010058815823867917,0.0015951915411278605,0.0007885263185016811,0.0009734526393003762,0.0009668784332461655,0.0008348983246833086,0.0006800245027989149,0.0006474542897194624,0.000984393758699298,0.0006429150234907866,0.0006923114997334778,0.0006254881154745817,0.0005332849104888737,0.0006802039570175111,0.0011191741796210408,0.0008841792587190866,0.0007156014908105135,0.0005986226606182754,0.0004855684528592974,0.00047021041973493993,0.0004970059380866587,0.0004425264778546989,0.00039047360769473016,0.0003347417223267257,0.0003826739266514778,0.00044699967838823795,0.00037203505053184927,0.00032756978180259466,0.00030215136939659715,0.0002694856666494161,0.0007070318097248673,0.0005599231226369739,0.00046356336679309607,0.0004096525954082608,0.0003526076325215399,0.0002898522943723947,0.0002314699231646955,0.00019906979287043214,0.00017660815501585603,0.00016270758351311088,0.00015084707411006093,0.000142901306389831,0.00012709604925476015,0.00012206347309984267,0.00011684266792144626,0.0001151302203652449,0.00011293091665720567,0.00011080221156589687,0.000111221699626185,0.00010793114051921293,0.00010650894546415657,0.00010579856461845338,0.00010285977623425424,0.00010304605530109257,0.00010044949885923415,0.00010014617146225646,9.822432912187651e-05,9.661898366175592e-05,9.72124544205144e-05,9.610468259779736e-05,9.409453923581168e-05,9.318746015196666e-05,9.273797331843525e-05,9.159121691482142e-05,8.996485121315345e-05,0.0001270994689548388,0.00020762950589414686,0.00025868386728689075,0.0002478018868714571,0.00020939219393767416,0.0001835454604588449,0.00016073850565589964,0.00014673305850010365,0.00014008481230121106,0.0002505810116417706,0.00027100552688352764,0.00021869152260478586,0.00018927932251244783,0.00016958943160716444,0.0001551768946228549,0.0001587532606208697,0.00034380273427814245,0.0003126163501292467,0.0002617810678202659,0.00022435009304899722,0.0001980651286430657,0.0001701139990473166,0.00015320040984079242,0.0001359878369839862,0.00012593684368766844,
mae,0.1692572385072708,0.06701879948377609,0.04284500703215599,0.03689880669116974,0.027929339557886124,0.02497975528240204,0.022378647699952126,0.021019382402300835,0.021047206595540047,0.01906845159828663,0.024331554770469666,0.03145043924450874,0.022114548832178116,0.024269061163067818,0.024596408009529114,0.02306320145726204,0.020982837304472923,0.019663959741592407,0.02548026479780674,0.0202338770031929,0.021570580080151558,0.021529462188482285,0.018926501274108887,0.01997801475226879,0.025338290259242058,0.022044992074370384,0.020016275346279144,0.02063148468732834,0.01726682484149933,0.016879022121429443,0.017713794484734535,0.016818232834339142,0.015328063629567623,0.014522318728268147,0.014786005020141602,0.016384121030569077,0.014649134129285812,0.013628683984279633,0.013131458312273026,0.012827440164983273,0.019148029386997223,0.017588233575224876,0.015842271968722343,0.014816608279943466,0.013732049614191055,0.013793030753731728,0.012488387525081635,0.011431139893829823,0.010732173919677734,0.010248839855194092,0.009838927537202835,0.009627892635762691,0.009161151014268398,0.009033332578837872,0.008747586980462074,0.008718781173229218,0.008553027175366879,0.008665647357702255,0.008555743843317032,0.008379947394132614,0.00814205501228571,0.008210612460970879,0.008223854005336761,0.008222624659538269,0.008227203041315079,0.008074291050434113,0.008090884424746037,0.007871861569583416,0.007898491807281971,0.007845867425203323,0.007768276147544384,0.00781982857733965,0.007918570190668106,0.007737470790743828,0.007711845450103283,0.00844664964824915,0.01146030705422163,0.013020179234445095,0.013468336313962936,0.012077398598194122,0.011351430788636208,0.010598639026284218,0.00992660503834486,0.00977676548063755,0.012087633833289146,0.013221430592238903,0.011779717169702053,0.010831156745553017,0.010297772474586964,0.010029887780547142,0.009991960600018501,0.014211955480277538,0.013380905613303185,0.012219259515404701,0.011503505520522594,0.010833297856152058,0.009915385395288467,0.009583259001374245,0.009371931664645672,0.009176531806588173,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9555      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9556      
=================================================================
Total params: 19,111
Trainable params: 19,111
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 9,555
Trainable params: 9,555
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 9,556
Trainable params: 9,556
Non-trainable params: 0
_________________________________________________________________
