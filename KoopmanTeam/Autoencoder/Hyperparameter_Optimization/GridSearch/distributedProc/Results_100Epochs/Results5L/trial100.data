2021-06-26
loss,1.6605256795883179,0.345152348279953,0.26624035835266113,0.19438552856445312,0.15956318378448486,0.15049922466278076,0.13782961666584015,0.13791224360466003,0.10408379882574081,0.10365083068609238,0.13826967775821686,0.09728025645017624,0.10789638757705688,0.10422232747077942,0.0804646909236908,0.08817537128925323,0.10723283141851425,0.07794088125228882,0.07035865634679794,0.05493788793683052,0.05421757698059082,0.05287681892514229,0.0824618935585022,0.07136529684066772,0.06923496723175049,0.056845732033252716,0.05569803714752197,0.05569545179605484,0.043935079127550125,0.056055355817079544,0.05385582894086838,0.04291679710149765,0.047508325427770615,0.046526309102773666,0.04821397736668587,0.04647223651409149,0.04204108193516731,0.045463334769010544,0.038138341158628464,0.03403783217072487,0.03513210639357567,0.03835596889257431,0.03634515032172203,0.039718952029943466,0.0373382531106472,0.040361419320106506,0.036565374583005905,0.03559022396802902,0.0396624431014061,0.03142397105693817,0.02760966494679451,0.03032105602324009,0.03604750707745552,0.03398679196834564,0.0289896372705698,0.030765941366553307,0.030874432995915413,0.029633022844791412,0.030225390568375587,0.03428378701210022,0.028573818504810333,0.026667891070246696,0.029644260182976723,0.03603028878569603,0.03264413774013519,0.029332712292671204,0.029689107090234756,0.028320297598838806,0.025446690618991852,0.027092372998595238,0.03186570480465889,0.030460746958851814,0.027764104306697845,0.02822750248014927,0.02330109104514122,0.022116390988230705,0.024844780564308167,0.027175772935152054,0.02992860972881317,0.025299405679106712,0.024427881464362144,0.026794878765940666,0.03248436376452446,0.028104672208428383,0.024222800508141518,0.021849574521183968,0.026602737605571747,0.02681792341172695,0.02645299583673477,0.025256728753447533,0.02576253190636635,0.023051263764500618,0.024895785376429558,0.02479521930217743,0.022703740745782852,0.021537285298109055,0.023752575740218163,0.022067135199904442,0.02636648714542389,0.025098716840147972,
mse,0.908444344997406,0.03495607152581215,0.020351815968751907,0.011161919683218002,0.007581294979900122,0.006662664469331503,0.0055414712987840176,0.005646648816764355,0.003134399652481079,0.0032477988861501217,0.005630348343402147,0.002996869385242462,0.0033863449934870005,0.003288522595539689,0.0018823054851964116,0.0022360237780958414,0.0031791969668120146,0.0018704417161643505,0.0015085465274751186,0.0008513903594575822,0.0008519323309883475,0.0008064170833677053,0.00197568628937006,0.0014871658058837056,0.0013712674845010042,0.0009257804485969245,0.00090671272482723,0.0008816155605018139,0.0005732401041314006,0.0009086196077987552,0.000808569835498929,0.0005291033303365111,0.000636151060461998,0.0006068049115128815,0.000652613933198154,0.0005941357230767608,0.0004984458792023361,0.0005847580614499748,0.00039889407344162464,0.00033373580663464963,0.00036969713983125985,0.0004134659538976848,0.000366713764378801,0.00046450018999166787,0.00039671052945777774,0.00045234945719130337,0.0003736029611900449,0.0003655323525890708,0.0004380732716526836,0.00028016234864480793,0.0002259526081616059,0.00026629207422956824,0.0003691503079608083,0.0003260185185354203,0.00023640398285351694,0.0002711157430894673,0.0002682803897187114,0.000256024650298059,0.00027740979567170143,0.00033321554656140506,0.0002262497873743996,0.00021017320977989584,0.00024573568953201175,0.0003613853477872908,0.00029787112725898623,0.0002468394231982529,0.00024677228066138923,0.00023880558728706092,0.00019049456750508398,0.00021149266103748232,0.00029052613535895944,0.0002622108440846205,0.00021555846615228802,0.00022303039440885186,0.00016052898718044162,0.0001455748570151627,0.000179498121724464,0.00020987122843507677,0.0002632612595334649,0.00018110842211171985,0.00016868770762812346,0.0002078750403597951,0.00029189017368480563,0.00022555353643838316,0.00017327573732472956,0.0001429621916031465,0.0002048946771537885,0.00020162819419056177,0.00020071705512236804,0.00018301347154192626,0.00018915606779046357,0.00015475612599402666,0.00018041525618173182,0.00017420008953195065,0.00014394414029084146,0.0001346925419056788,0.0001610971085028723,0.00013894555740989745,0.00019880509353242815,0.00017431954620406032,
mae,0.7015642523765564,0.14831188321113586,0.1126653254032135,0.0824325680732727,0.06825081259012222,0.06451554596424103,0.058193255215883255,0.05963997542858124,0.04532031714916229,0.04494956508278847,0.05928919464349747,0.041507020592689514,0.04620073363184929,0.045298706740140915,0.03401775658130646,0.03751722723245621,0.04678676649928093,0.034490350633859634,0.03077998012304306,0.023365551605820656,0.023385772481560707,0.022435259073972702,0.03723583742976189,0.03101148083806038,0.030962157994508743,0.024439776316285133,0.024030014872550964,0.02379980869591236,0.018738603219389915,0.02438029833137989,0.02379642054438591,0.018442656844854355,0.020561574026942253,0.02013753354549408,0.02139846794307232,0.020199377089738846,0.017715048044919968,0.020164845511317253,0.01644115522503853,0.014675631187856197,0.014977049082517624,0.016434259712696075,0.015459182672202587,0.017571069300174713,0.016534946858882904,0.01742854341864586,0.01599304936826229,0.015203564427793026,0.017582610249519348,0.01353475358337164,0.011791806668043137,0.013027702458202839,0.015720156952738762,0.014880193397402763,0.012407252565026283,0.013169585727155209,0.013006415218114853,0.012575190514326096,0.013088470324873924,0.01495390385389328,0.012318347580730915,0.011503320187330246,0.012788400985300541,0.015885740518569946,0.014126311987638474,0.012434294447302818,0.01259977463632822,0.01236106175929308,0.010848034173250198,0.011286970227956772,0.013666320592164993,0.013137498870491982,0.01181207224726677,0.012184099294245243,0.009911006316542625,0.00942525640130043,0.010609385557472706,0.011520316824316978,0.013114046305418015,0.010727149434387684,0.0104370703920722,0.011337855830788612,0.014478948898613453,0.012187998741865158,0.010195680893957615,0.009412686340510845,0.011635536327958107,0.011496744118630886,0.011333090253174305,0.010878317058086395,0.010827184654772282,0.009871031157672405,0.010542585514485836,0.010772236622869968,0.009707159362733364,0.009165575727820396,0.010190200060606003,0.00937808956950903,0.011446415446698666,0.010893970727920532,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 269419    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 269420    
=================================================================
Total params: 538,839
Trainable params: 538,839
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 269,419
Trainable params: 269,419
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 269,420
Trainable params: 269,420
Non-trainable params: 0
_________________________________________________________________
