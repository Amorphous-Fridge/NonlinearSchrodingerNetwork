2021-06-26
loss,0.6751286387443542,0.29320237040519714,0.23602411150932312,0.20903071761131287,0.19125398993492126,0.16569194197654724,0.12815752625465393,0.10244059562683105,0.08983523398637772,0.07486133277416229,0.079585500061512,0.08191431313753128,0.0667187049984932,0.08106783777475357,0.06388013064861298,0.058110930025577545,0.05770305544137955,0.06692885607481003,0.056996602565050125,0.05059531331062317,0.045070767402648926,0.039800163358449936,0.04062623158097267,0.05669409781694412,0.044955216348171234,0.04496746137738228,0.03814549744129181,0.042627401649951935,0.05021408572793007,0.04411161318421364,0.038908734917640686,0.041134063154459,0.04329412057995796,0.043077584356069565,0.036168746650218964,0.039146263152360916,0.037621840834617615,0.033066973090171814,0.032273270189762115,0.02493896894156933,0.02258576825261116,0.026021840050816536,0.03263721987605095,0.03290856257081032,0.03170178830623627,0.026500334963202477,0.031415730714797974,0.03928182274103165,0.03533508628606796,0.03254759684205055,0.033317673951387405,0.03413492813706398,0.0317046083509922,0.03048749640583992,0.03099319152534008,0.03278271108865738,0.03144453465938568,0.02871476486325264,0.025087477639317513,0.02169809304177761,0.021050821989774704,0.02921665646135807,0.030742961913347244,0.034332212060689926,0.03196045011281967,0.025967130437493324,0.025318598374724388,0.025720171630382538,0.030198078602552414,0.023014366626739502,0.022416986525058746,0.027959980070590973,0.027313154190778732,0.026265094056725502,0.028213387355208397,0.02528505027294159,0.02878788858652115,0.027188772335648537,0.024601876735687256,0.025067850947380066,0.022372551262378693,0.02356046438217163,0.02482626587152481,0.0290361400693655,0.02607489563524723,0.021087223663926125,0.01954055204987526,0.01833271235227585,0.017644859850406647,0.02132321335375309,0.02488761395215988,0.027323178946971893,0.02576831355690956,0.026223132386803627,0.021899478510022163,0.023323457688093185,0.0259635541588068,0.02356017753481865,0.021280799061059952,0.02207629382610321,
mse,0.18734422326087952,0.027243459597229958,0.0182843916118145,0.014704850502312183,0.012294670566916466,0.009156600572168827,0.0052596284076571465,0.003381271380931139,0.0024371601175516844,0.0017419938230887055,0.001930193742737174,0.0020158591214567423,0.001337819267064333,0.0019050901755690575,0.0012097280705347657,0.001033114967867732,0.0009531655232422054,0.0012934512924402952,0.0009287017746828496,0.000751311716157943,0.0006041129818186164,0.0004792386316694319,0.0004974362091161311,0.000902538828086108,0.0005946655292063951,0.000566024100407958,0.0004278078558854759,0.0005307150422595441,0.0007060792995616794,0.0005546062020584941,0.0004407365922816098,0.0004825027717743069,0.0005333516164682806,0.0005190584342926741,0.00038336310535669327,0.0004376916913315654,0.0003969190875068307,0.0003185664536431432,0.0003075632266700268,0.0001953910250449553,0.00015888881171122193,0.00021095316333230585,0.00030812175828032196,0.0003146681992802769,0.00029755523428320885,0.00020793845760636032,0.00028771511279046535,0.00043083331547677517,0.0003521030303090811,0.0003039658477064222,0.00031609079451300204,0.0003283430705778301,0.00028129879501648247,0.0002727964601945132,0.0002778502821456641,0.00030113381217233837,0.00028314022347331047,0.00023728069209028035,0.0001867113314801827,0.00014123575238045305,0.00012982706539332867,0.0002572698285803199,0.00027200192562304437,0.00032666686456650496,0.00028692695195786655,0.00019547755073290318,0.00018620876653585583,0.00018891217769123614,0.00025560572976246476,0.00015452348452527076,0.00015603689826093614,0.00021885466412641108,0.00021143033518455923,0.00019871523545589298,0.00022156894556246698,0.00018021362484432757,0.00023743053316138685,0.00021114054834470153,0.0001766818022588268,0.00017926740110851824,0.00014764470688533038,0.00016000826144590974,0.0001749693910824135,0.00023331255943048745,0.00018901664589066058,0.000130864602397196,0.00011131294741062447,9.96144735836424e-05,8.989814523374662e-05,0.0001354180567432195,0.00018079325673170388,0.0002143440069630742,0.00019374050316400826,0.0001931852602865547,0.00013927542022429407,0.00015880883438512683,0.00019093748414888978,0.00016002371557988226,0.00013308864436112344,0.00014683719200547785,
mae,0.28902214765548706,0.1239347904920578,0.10244583338499069,0.09255886822938919,0.08353166282176971,0.07184861600399017,0.05497855693101883,0.043488431721925735,0.03851649910211563,0.03191868215799332,0.033279333263635635,0.03476311266422272,0.027989346534013748,0.03502044826745987,0.026949627324938774,0.024304501712322235,0.02439705841243267,0.028485989198088646,0.02402234636247158,0.02163228951394558,0.01892618089914322,0.016805807128548622,0.017229290679097176,0.02445821836590767,0.0190428514033556,0.019244689494371414,0.016494376584887505,0.018119914457201958,0.021631617099046707,0.018879299983382225,0.01628536731004715,0.01730157807469368,0.018261276185512543,0.019211670383810997,0.015137692913413048,0.01658548042178154,0.015593978576362133,0.014005941338837147,0.013830168172717094,0.010556462220847607,0.009543885476887226,0.011116862297058105,0.014021393842995167,0.0139984842389822,0.013762583956122398,0.011229757219552994,0.013463510200381279,0.016838833689689636,0.014963707886636257,0.013639308512210846,0.014013762585818768,0.014458165504038334,0.013020523823797703,0.012892667204141617,0.013368780724704266,0.014082508161664009,0.013250548392534256,0.012036132626235485,0.01060974970459938,0.009251504205167294,0.008909671567380428,0.012103519402444363,0.012596496380865574,0.015526383183896542,0.014892395585775375,0.011227088049054146,0.010705744847655296,0.010824068449437618,0.012684868648648262,0.009848390705883503,0.009433744475245476,0.011659822426736355,0.011516358703374863,0.011171392165124416,0.012104135937988758,0.010752870701253414,0.012429501861333847,0.012187841348350048,0.010420768521726131,0.0106089161708951,0.009455461986362934,0.009891894645988941,0.01048545353114605,0.012755773961544037,0.010851902887225151,0.008996815420687199,0.00823390856385231,0.007688373327255249,0.007441100664436817,0.008948007598519325,0.010577683337032795,0.011496540158987045,0.010934199206531048,0.010858051478862762,0.009168606251478195,0.010003271512687206,0.010976524092257023,0.009886938147246838,0.009008202701807022,0.00919963326305151,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 50603     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 50604     
=================================================================
Total params: 101,207
Trainable params: 101,207
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 50,603
Trainable params: 50,603
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 50,604
Trainable params: 50,604
Non-trainable params: 0
_________________________________________________________________
