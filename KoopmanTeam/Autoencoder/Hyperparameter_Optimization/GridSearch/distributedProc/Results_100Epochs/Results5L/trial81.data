2021-06-26
loss,0.5360355973243713,0.2738112509250641,0.19052156805992126,0.18925122916698456,0.1095600351691246,0.13188482820987701,0.11529344320297241,0.0679367184638977,0.06293587386608124,0.07333344221115112,0.07222200185060501,0.07431593537330627,0.0651043951511383,0.07275935262441635,0.05513896048069,0.0544809065759182,0.05192023143172264,0.04294297844171524,0.041688222438097,0.05782117322087288,0.046146880835294724,0.04305782914161682,0.04805038124322891,0.0537242665886879,0.04459897056221962,0.04023446887731552,0.03137414529919624,0.03584085404872894,0.046306315809488297,0.038410428911447525,0.034625761210918427,0.03170054033398628,0.02951754257082939,0.03399115055799484,0.034982532262802124,0.03224386274814606,0.0322813019156456,0.03727632388472557,0.03385460749268532,0.029801223427057266,0.026670675724744797,0.02164984866976738,0.028878511860966682,0.03188478574156761,0.0290065910667181,0.027425363659858704,0.030856940895318985,0.0278471689671278,0.023970840498805046,0.02169080078601837,0.018615001812577248,0.019690852612257004,0.02714216709136963,0.025421230122447014,0.02676837518811226,0.027803177013993263,0.024257581681013107,0.02182852104306221,0.022722933441400528,0.02625604160130024,0.025922810658812523,0.024592461064457893,0.021630099043250084,0.019037729129195213,0.020656293258070946,0.02592904306948185,0.025297729298472404,0.022259339690208435,0.019716784358024597,0.022465266287326813,0.024380357936024666,0.023351771757006645,0.021346107125282288,0.022507810965180397,0.02224760130047798,0.02317258156836033,0.02004099078476429,0.018775464966893196,0.017358502373099327,0.01947004720568657,0.017664609476923943,0.017127681523561478,0.02278420515358448,0.020543484017252922,0.022384952753782272,0.021445777267217636,0.02184363640844822,0.02194802090525627,0.019587459042668343,0.019851064309477806,0.020899387076497078,0.019238188862800598,0.02188684418797493,0.01909623295068741,0.017683181911706924,0.016352206468582153,0.01641651801764965,0.021460363641381264,0.01902981474995613,0.01899094134569168,
mse,0.1306925117969513,0.0227256678044796,0.010675384663045406,0.010755807161331177,0.0035080385860055685,0.00504436157643795,0.003869227133691311,0.0013903550570830703,0.001174815814010799,0.0015865740133449435,0.0014955837978050113,0.0016337562119588256,0.001210956135764718,0.0014964049914851785,0.0008679574821144342,0.0008401565137319267,0.000781683309469372,0.000545980001334101,0.0005233651609160006,0.0009573230636306107,0.0006264908006414771,0.0005244500353001058,0.0006736748036928475,0.0008106484310701489,0.0005589163047261536,0.0004714996612165123,0.0002998871495947242,0.00037822051672264934,0.000594720768276602,0.0004130947345402092,0.00033296510810032487,0.00028729773475788534,0.0002588363422546536,0.0003378501278348267,0.0003472460084594786,0.0002951138012576848,0.0002957500983029604,0.0003888984792865813,0.00031922583002597094,0.00025617078063078225,0.0002058612008113414,0.0001413728459738195,0.0002402105019427836,0.00028134669992141426,0.00023369032714981586,0.00020837737247347832,0.0002674584393389523,0.00021536173881031573,0.00016639339446555823,0.00013930644490756094,0.00010243937140330672,0.00011632667883532122,0.00021040545834694058,0.00018657909822650254,0.00020129414042457938,0.0002143413876183331,0.00016564629913773388,0.0001356001157546416,0.00015170629194471985,0.00020327592210378498,0.00018694449681788683,0.00017055966600310057,0.00013950534048490226,0.0001113524631364271,0.00012794685608241707,0.00019364617764949799,0.00017749097605701536,0.00014091563934925944,0.0001159155071945861,0.00014819815987721086,0.00016671005869284272,0.0001527755957795307,0.00013005419168621302,0.00014502456178888679,0.0001423985231667757,0.00015158549649640918,0.00011749190161935985,0.00010303538147127256,8.918906678445637e-05,0.00011236979480599985,9.364888683194295e-05,8.930411422625184e-05,0.00015299092046916485,0.00011992122017545626,0.0001421447959728539,0.00012972553668078035,0.00013522333756554872,0.00013386752107180655,0.0001096932974178344,0.0001140308304456994,0.00012300434173084795,0.00010451786511112005,0.0001331684907199815,0.0001020074705593288,9.008577035274357e-05,8.08249315014109e-05,8.377953781746328e-05,0.00012795679504051805,0.00010486083920113742,0.00010439809557283297,
mae,0.23373478651046753,0.11868757009506226,0.08107147365808487,0.08119175583124161,0.04673267528414726,0.05738915130496025,0.04976101219654083,0.028670446947216988,0.026802878826856613,0.031370654702186584,0.031049737706780434,0.032177895307540894,0.027985651046037674,0.03176064416766167,0.0237068273127079,0.023228434845805168,0.02205677703022957,0.018367387354373932,0.017668381333351135,0.024567270651459694,0.019324423745274544,0.018032975494861603,0.02039731666445732,0.023546667769551277,0.01950066164135933,0.01720627397298813,0.013200705870985985,0.015080955810844898,0.019771737977862358,0.0162611436098814,0.01434023305773735,0.013144740834832191,0.012334111146628857,0.014292467385530472,0.014734740369021893,0.013934127055108547,0.013539092615246773,0.01641346886754036,0.014776399359107018,0.01260328572243452,0.011628895998001099,0.009298758581280708,0.012113167904317379,0.013764778152108192,0.01266087219119072,0.011885395273566246,0.013221748173236847,0.011781015433371067,0.010281485505402088,0.009192133322358131,0.007967889308929443,0.008425593376159668,0.011472053825855255,0.010457844473421574,0.011346917599439621,0.01187839638441801,0.010305112227797508,0.009299259632825851,0.009604758583009243,0.011347902938723564,0.011184768751263618,0.010448732413351536,0.00915074534714222,0.008183391764760017,0.008717797696590424,0.011128425598144531,0.011041510850191116,0.009654304012656212,0.008383906446397305,0.009630858898162842,0.01029872614890337,0.009912163019180298,0.009052976034581661,0.009592735208570957,0.009636000730097294,0.00993176456540823,0.00846183579415083,0.0079280911013484,0.007384749595075846,0.008277758955955505,0.007488174829632044,0.0072755939327180386,0.009618517011404037,0.008764779195189476,0.009484091773629189,0.00893466081470251,0.009354193694889545,0.009239446371793747,0.008270811289548874,0.008426781743764877,0.00886225514113903,0.008002039976418018,0.009584128856658936,0.008371260017156601,0.007554760668426752,0.006948625668883324,0.006992006674408913,0.00913633406162262,0.007930085994303226,0.008092413656413555,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 100619    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 100620    
=================================================================
Total params: 201,239
Trainable params: 201,239
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 100,619
Trainable params: 100,619
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 100,620
Trainable params: 100,620
Non-trainable params: 0
_________________________________________________________________
