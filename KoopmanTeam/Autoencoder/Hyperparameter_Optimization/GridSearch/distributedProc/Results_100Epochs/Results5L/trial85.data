2021-06-26
loss,0.5205737352371216,0.24814540147781372,0.23881042003631592,0.22628168761730194,0.21858744323253632,0.2052999883890152,0.19549110531806946,0.19581058621406555,0.16648456454277039,0.13646169006824493,0.13988997042179108,0.133883997797966,0.1253008395433426,0.0972541868686676,0.09045743197202682,0.08022032678127289,0.08931804448366165,0.07523472607135773,0.05632072314620018,0.049572695046663284,0.06455089896917343,0.0653797909617424,0.05520905554294586,0.04490569233894348,0.06000380590558052,0.05172482505440712,0.04507165029644966,0.04635376110672951,0.03997402265667915,0.04410960525274277,0.04052654653787613,0.03800687938928604,0.04150912165641785,0.04012676328420639,0.037313561886548996,0.036222826689481735,0.036232832819223404,0.033574994653463364,0.031203169375658035,0.030927004292607307,0.03153834491968155,0.031157076358795166,0.029507732018828392,0.028955521062016487,0.024632643908262253,0.025926997885107994,0.025527426972985268,0.02783443033695221,0.029830913990736008,0.029270799830555916,0.02695944346487522,0.025711441412568092,0.026036472991108894,0.028002772480249405,0.026426859200000763,0.024184977635741234,0.02185639552772045,0.025106558576226234,0.022916212677955627,0.02334696054458618,0.024521851912140846,0.022648803889751434,0.02577950432896614,0.022600378841161728,0.02217649668455124,0.02125406451523304,0.022165177389979362,0.021479573100805283,0.02211744338274002,0.02114851400256157,0.019160449504852295,0.01885608397424221,0.019939225167036057,0.021463872864842415,0.01819906383752823,0.017371056601405144,0.020515307784080505,0.024869058281183243,0.020592262968420982,0.021757686510682106,0.02080460824072361,0.02269098535180092,0.019769901409745216,0.017474757507443428,0.01550146471709013,0.017868345603346825,0.023561306297779083,0.019305886700749397,0.01976659707725048,0.018515994772315025,0.018950141966342926,0.021516963839530945,0.020489320158958435,0.018810797482728958,0.017355753108859062,0.017075959593057632,0.018943801522254944,0.01652037911117077,0.016032949090003967,0.020427772775292397,
mse,0.16037338972091675,0.02037833258509636,0.01900635100901127,0.0173536017537117,0.016030672937631607,0.014215334318578243,0.012893573381006718,0.012349716387689114,0.008860827423632145,0.00561448885127902,0.005970296449959278,0.00558853754773736,0.0046401116997003555,0.002767817350104451,0.0023770974949002266,0.0019287068862468004,0.0022660254035145044,0.0016512145521119237,0.0009651847067289054,0.0007287133485078812,0.0012085257330909371,0.001216425560414791,0.0009071745444089174,0.0006355009973049164,0.0010170919122174382,0.0007593641639687121,0.000583288143388927,0.000618447782471776,0.0004640853439923376,0.0005418098298832774,0.0004624934808816761,0.0004252954968251288,0.0004877517349086702,0.0004597469815053046,0.0003855621034745127,0.0003682427923195064,0.0003667972923722118,0.0003173244767822325,0.00028009957168251276,0.0002778974885586649,0.0002835279447026551,0.00027541693998500705,0.0002519881818443537,0.00023663023603148758,0.00018262825324200094,0.0002015878417296335,0.00019020862237084657,0.00022116747277323157,0.0002518922556191683,0.0002423772239126265,0.00020279144519008696,0.0001906615507323295,0.0001898520567920059,0.00021788530284538865,0.00019573335885070264,0.0001666145835770294,0.00014421901141759008,0.00018063309835270047,0.00015117156726773828,0.00015471564256586134,0.00016748011694289744,0.00014648158685304224,0.0001797860604710877,0.00014465574349742383,0.00014272135740611702,0.00013078264601062983,0.0001376728032482788,0.0001344231131952256,0.00014101609122008085,0.00012956451973877847,0.00010872408893192187,0.00010572426253929734,0.00011599539720918983,0.00012754913768731058,9.842026338446885e-05,9.049085929291323e-05,0.00012866660836152732,0.00017345621017739177,0.00012263304961379617,0.00013241042324807495,0.00012188229447929189,0.00014344323426485062,0.00011300363257760182,9.040165605256334e-05,7.297804404515773e-05,9.620339551474899e-05,0.00015395655645988882,0.00010535918409004807,0.00011160411668242887,9.895898983813822e-05,0.00010312318772776052,0.0001301229785894975,0.0001164214700111188,0.00010234193905489519,8.866620191838592e-05,8.688659727340564e-05,0.00010149859735975042,7.958620699355379e-05,7.668350008316338e-05,0.0001222210266860202,
mae,0.22291907668113708,0.10636166483163834,0.10306236147880554,0.09799724817276001,0.09452509135007858,0.0886068344116211,0.083347387611866,0.08275443315505981,0.07055097818374634,0.05778796225786209,0.0587032213807106,0.05709248036146164,0.05211063474416733,0.041266340762376785,0.03832761570811272,0.033907853066921234,0.03712569922208786,0.03183732554316521,0.023946426808834076,0.021197380498051643,0.027378642931580544,0.02794935554265976,0.023537898436188698,0.01924644410610199,0.026152832433581352,0.02253764308989048,0.019352775067090988,0.020231110975146294,0.0169416181743145,0.018641477450728416,0.01703312247991562,0.01615404151380062,0.01824762113392353,0.01729544810950756,0.016329674050211906,0.015735406428575516,0.01531035266816616,0.014249397441744804,0.013035319745540619,0.01316156703978777,0.013323365710675716,0.013433152809739113,0.01269859354943037,0.012158743105828762,0.010420113801956177,0.011073713190853596,0.010769670829176903,0.011848573572933674,0.012972228229045868,0.012878861278295517,0.011583012528717518,0.010809886269271374,0.011066954582929611,0.011911307461559772,0.011176581494510174,0.010230770334601402,0.009232291020452976,0.010746105574071407,0.009720281697809696,0.009804347530007362,0.010553015395998955,0.009660685434937477,0.011437910608947277,0.009831177070736885,0.009456115774810314,0.008969565853476524,0.009309194050729275,0.009147671051323414,0.009497088380157948,0.008970608934760094,0.008141080848872662,0.007997911423444748,0.008474204689264297,0.008764460682868958,0.007586346473544836,0.007377101108431816,0.008923251181840897,0.011225542053580284,0.008720812387764454,0.009128612466156483,0.008795664645731449,0.0097196688875556,0.008329879492521286,0.007441738620400429,0.006658186204731464,0.007566997781395912,0.010164748877286911,0.008117007091641426,0.008376612327992916,0.007918111979961395,0.008083554916083813,0.009373428300023079,0.008706619031727314,0.008001171983778477,0.007440036162734032,0.007205105386674404,0.007979253306984901,0.006966439541429281,0.006803547032177448,0.008731627836823463,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 102227    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 102228    
=================================================================
Total params: 204,455
Trainable params: 204,455
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 102,227
Trainable params: 102,227
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 102,228
Trainable params: 102,228
Non-trainable params: 0
_________________________________________________________________
