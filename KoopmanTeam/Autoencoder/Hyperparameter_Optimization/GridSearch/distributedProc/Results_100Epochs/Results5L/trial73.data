2021-06-26
loss,0.49524742364883423,0.2485625445842743,0.2341172844171524,0.223240464925766,0.21441951394081116,0.2064252495765686,0.1943415105342865,0.18297474086284637,0.1714988350868225,0.16144995391368866,0.15019351243972778,0.12383020669221878,0.12008939683437347,0.12743760645389557,0.1078914925456047,0.09012572467327118,0.08023324608802795,0.07228262722492218,0.061726827174425125,0.06484619528055191,0.05563339591026306,0.05282615125179291,0.054682616144418716,0.07083152234554291,0.05378476157784462,0.04101888835430145,0.05709737166762352,0.054751016199588776,0.04241945222020149,0.03353540971875191,0.0435011200606823,0.049510594457387924,0.04711074382066727,0.03751402348279953,0.033751893788576126,0.03256100043654442,0.038865827023983,0.04270296171307564,0.04524363949894905,0.03911367058753967,0.03604865446686745,0.038711026310920715,0.03908495977520943,0.03528562933206558,0.03366660326719284,0.030635537579655647,0.03099502995610237,0.033822864294052124,0.03711263835430145,0.03284097835421562,0.03230005130171776,0.03098219819366932,0.024089254438877106,0.022407377138733864,0.02078007534146309,0.02121783420443535,0.025132672861218452,0.02755698747932911,0.02423984743654728,0.029512863606214523,0.024195518344640732,0.03420043736696243,0.0305160041898489,0.030789963901042938,0.026850208640098572,0.025673769414424896,0.02891676500439644,0.027580399066209793,0.02452608197927475,0.02281755767762661,0.022022297605872154,0.020123183727264404,0.025612305849790573,0.026333261281251907,0.024708541110157967,0.027311356738209724,0.025288667529821396,0.01928704045712948,0.02179475873708725,0.027887767180800438,0.02365008555352688,0.02492048591375351,0.025911802425980568,0.025934744626283646,0.025985660031437874,0.022838108241558075,0.02177233248949051,0.020017145201563835,0.01747206412255764,0.016991768032312393,0.020757950842380524,0.026312535628676414,0.024429988116025925,0.025583693757653236,0.022242769598960876,0.022972023114562035,0.022636326029896736,0.020408570766448975,0.02094396762549877,0.021074550226330757,
mse,0.10474974662065506,0.020542195066809654,0.018954120576381683,0.017581719905138016,0.016261663287878036,0.014909927733242512,0.01313070673495531,0.011856957338750362,0.010575750842690468,0.009411642327904701,0.00789550319314003,0.004982548765838146,0.004352305084466934,0.0049322182312607765,0.0035357398446649313,0.0023731461260467768,0.0018957779975607991,0.0014785693492740393,0.00110604555811733,0.0012584034120664,0.0008683607447892427,0.0008236544672399759,0.0008877877844497561,0.001405302551575005,0.0008268493693321943,0.0005037442897446454,0.0009223379311151803,0.0008356325561180711,0.0005241342587396502,0.00034132483415305614,0.0005385407712310553,0.0006963037885725498,0.0006333606434054673,0.00039810032467357814,0.00032058433862403035,0.0003071973333135247,0.00045660720206797123,0.0005070909974165261,0.0005769208655692637,0.00043000755249522626,0.00035979729727841914,0.0004380111349746585,0.0004318628052715212,0.0003480158047750592,0.00032435214961878955,0.00027468029293231666,0.0002739004557952285,0.00032370761618949473,0.0003857685369439423,0.0003031702362932265,0.0002941507555078715,0.0002688242821022868,0.00017733953427523375,0.00015332104521803558,0.00012951741518918425,0.00013558917271438986,0.0001831232220865786,0.00021680546342395246,0.00017196012777276337,0.00024901985307224095,0.00017153946100734174,0.0003275434428360313,0.0002677249431144446,0.0002654670097399503,0.00020286998187657446,0.00019132092711515725,0.00023731736291665584,0.0002131926012225449,0.00017192056111525744,0.00015110500680748373,0.00013971114822197706,0.0001231743226526305,0.00019119359785690904,0.00019836433057207614,0.00017569851479493082,0.00021374423522502184,0.00017868373834062368,0.0001160376486950554,0.0001456396421417594,0.00021505825861822814,0.00015777656517457217,0.0001776320132194087,0.0001874224399216473,0.0001936854823725298,0.00018719708896242082,0.0001483967644162476,0.00013496838801074773,0.00011536266538314521,9.181995847029611e-05,8.72897362569347e-05,0.00012609208351932466,0.00019424302445258945,0.00017170127830468118,0.00018430480849929154,0.0001396321749780327,0.00014818372437730432,0.00014355180610436946,0.00012067897478118539,0.00012736623466480523,0.0001272010849788785,
mae,0.21303874254226685,0.10936316847801208,0.10771527141332626,0.10317985713481903,0.09683819115161896,0.0904686227440834,0.0836634561419487,0.0780298039317131,0.07268787175416946,0.0681561753153801,0.06331286579370499,0.05226227641105652,0.0509609691798687,0.05493218079209328,0.046483006328344345,0.03805528208613396,0.03406723588705063,0.030701160430908203,0.026254970580339432,0.027698151767253876,0.023848416283726692,0.02240973524749279,0.02326272428035736,0.030054941773414612,0.022882992401719093,0.017286023125052452,0.02405771054327488,0.023012468591332436,0.01805332489311695,0.014120825566351414,0.018444212153553963,0.020977184176445007,0.019683239981532097,0.01560781616717577,0.013927263207733631,0.013784343376755714,0.0164905097335577,0.0180389154702425,0.018689995631575584,0.01637406274676323,0.015359032899141312,0.016337277367711067,0.016458682715892792,0.015124631114304066,0.01429949514567852,0.013100805692374706,0.01308197621256113,0.014268116094172001,0.01575007475912571,0.013976040296256542,0.013615843839943409,0.01334358099848032,0.010180681943893433,0.009471296332776546,0.00874001532793045,0.009023786522448063,0.01069660671055317,0.011873727664351463,0.010324494913220406,0.012458099983632565,0.01026612427085638,0.014028876088559628,0.01248287782073021,0.013054406270384789,0.01125339139252901,0.0106752784922719,0.01207940373569727,0.011767026968300343,0.010408916510641575,0.009570213966071606,0.009310821071267128,0.008536763489246368,0.010908445343375206,0.011146705597639084,0.010488161817193031,0.011644329875707626,0.010813499800860882,0.008247331716120243,0.009065504185855389,0.011745835654437542,0.00993385724723339,0.0105417026206851,0.010747061111032963,0.011011525057256222,0.01106279343366623,0.009948711842298508,0.00917841773480177,0.008444849401712418,0.007372703403234482,0.007199055049568415,0.00884050503373146,0.011164793744683266,0.010517979972064495,0.011149164289236069,0.009540554136037827,0.009641429409384727,0.009548959322273731,0.008519936352968216,0.00875167828053236,0.00901816412806511,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 51443     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 51444     
=================================================================
Total params: 102,887
Trainable params: 102,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 51,443
Trainable params: 51,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 51,444
Trainable params: 51,444
Non-trainable params: 0
_________________________________________________________________
