2021-06-26
loss,0.41277122497558594,0.09410271048545837,0.1004008874297142,0.07465164363384247,0.09216169267892838,0.08023180812597275,0.07909813523292542,0.07876905798912048,0.06502912193536758,0.0558062307536602,0.04788674786686897,0.04136648029088974,0.05584261938929558,0.05606568232178688,0.05618142709136009,0.047043487429618835,0.05584065616130829,0.04587412253022194,0.038724418729543686,0.0336470901966095,0.036565009504556656,0.035516370087862015,0.03774745762348175,0.04704214632511139,0.041602972894907,0.03825543075799942,0.042876943945884705,0.03634345903992653,0.03061406873166561,0.03140300139784813,0.024966835975646973,0.02327011339366436,0.02177119255065918,0.021619156002998352,0.021030137315392494,0.02101329155266285,0.020679157227277756,0.020559167489409447,0.020215602591633797,0.02004404552280903,0.019793488085269928,0.01977396197617054,0.01957784779369831,0.019257543608546257,0.01925680600106716,0.01902373693883419,0.018839189782738686,0.018745118752121925,0.01855788379907608,0.01832304522395134,0.018347786739468575,0.01812082715332508,0.018063126131892204,0.017833251506090164,0.017719822004437447,0.017504574730992317,0.017360715195536613,0.017341913655400276,0.017200302332639694,0.01699989289045334,0.016979895532131195,0.01688404567539692,0.016660798341035843,0.01653512381017208,0.016432303935289383,0.01633414253592491,0.016103560104966164,0.016183407977223396,0.015942556783556938,0.016121715307235718,0.01594211347401142,0.01574482023715973,0.015573632903397083,0.015567098744213581,0.015375635586678982,0.01534939557313919,0.015444688498973846,0.015211162157356739,0.015098465606570244,0.015049580484628677,0.014939769171178341,0.014890666119754314,0.014789490960538387,0.014625308103859425,0.014546683058142662,0.014605343341827393,0.014475429430603981,0.014324581250548363,0.014316112734377384,0.0141753563657403,0.014175876043736935,0.01400105282664299,0.01402187068015337,0.013866462744772434,0.01403400395065546,0.013843505643308163,0.013690919615328312,0.013816598802804947,0.013598611578345299,0.013608826324343681,
mse,0.07955778390169144,0.0026336591690778732,0.0030656044837087393,0.001685278257355094,0.0024403429124504328,0.001901006675325334,0.0018256379989907146,0.0017607350600883365,0.0012270568404346704,0.0009078885777853429,0.0006631195428781211,0.0005048486054874957,0.0009144914802163839,0.0008977995021268725,0.0008870828896760941,0.0006361186970025301,0.0008777366019785404,0.000617346609942615,0.00043517473386600614,0.00032849356648512185,0.0003833600494544953,0.0003669957513920963,0.00043136024032719433,0.0006219562492333353,0.0004953871248289943,0.0004152689944021404,0.0005196376005187631,0.00037342478753998876,0.0002789314603433013,0.00029184349114075303,0.00018306059064343572,0.00015263065870385617,0.00013505887181963772,0.0001325861958321184,0.00012621789937838912,0.0001244790619239211,0.00012022246664855629,0.00011975567758781835,0.00011489852477097884,0.00011405707482481375,0.00011094179353676736,0.00011110903869848698,0.00010875636507989839,0.0001052253574016504,0.00010393201955594122,0.00010178414959227666,9.910726657835767e-05,9.895009861793369e-05,9.634750313125551e-05,9.466015035286546e-05,9.588545799488202e-05,9.234869503416121e-05,9.169287659460679e-05,8.914120553527027e-05,8.872373291524127e-05,8.580817666370422e-05,8.418428478762507e-05,8.427764259977266e-05,8.3346531027928e-05,8.104329754132777e-05,8.098028774838895e-05,8.011968748178333e-05,7.914049638202414e-05,7.634963549207896e-05,7.604269922012463e-05,7.485805690521374e-05,7.360986637650058e-05,7.329550135182217e-05,7.182378612924367e-05,7.427692617056891e-05,7.14741472620517e-05,6.980520993238315e-05,6.797741662012413e-05,6.831317296018824e-05,6.709494482493028e-05,6.672800373053178e-05,6.671787559753284e-05,6.449232023442164e-05,6.478954310296103e-05,6.33271993137896e-05,6.329271855065599e-05,6.260414374992251e-05,6.15667158854194e-05,5.999590575811453e-05,6.04909255343955e-05,5.9950893046334386e-05,5.891072942176834e-05,5.7679983001435176e-05,5.7684723287820816e-05,5.651506216963753e-05,5.6265140301547945e-05,5.5616586905671284e-05,5.5705011618556455e-05,5.4567954066442326e-05,5.5820881243562326e-05,5.399560905061662e-05,5.300810880726203e-05,5.3789593948749825e-05,5.171963493921794e-05,5.17779408255592e-05,
mae,0.17443011701107025,0.04004597291350365,0.04337900131940842,0.03157103434205055,0.038822073489427567,0.03461106866598129,0.03393560275435448,0.03371750935912132,0.02816125564277172,0.024036934599280357,0.02053217962384224,0.017751658335328102,0.024312090128660202,0.023692917078733444,0.023958800360560417,0.01978396624326706,0.024395709857344627,0.020290803164243698,0.01656308025121689,0.014221478253602982,0.015559041872620583,0.015094839036464691,0.016022462397813797,0.019694555550813675,0.0173660758882761,0.01591671071946621,0.01833433471620083,0.015248260460793972,0.013054315000772476,0.013244878500699997,0.010632729157805443,0.010152161121368408,0.00947530847042799,0.00935805682092905,0.009021342732012272,0.008922972716391087,0.008751838468015194,0.008770969696342945,0.008621295914053917,0.008616544306278229,0.008419671095907688,0.008357991464436054,0.008290165103971958,0.008129076100885868,0.008132713846862316,0.008097996935248375,0.008056924678385258,0.007877785712480545,0.007872053422033787,0.0078034065663814545,0.007771593518555164,0.007716934662312269,0.007687119767069817,0.007525418885052204,0.007502250839024782,0.007388073951005936,0.007389512844383717,0.007420756854116917,0.007356350310146809,0.007236388511955738,0.007229977753013372,0.007154378108680248,0.007043410092592239,0.007122765760868788,0.006970520596951246,0.0069549353793263435,0.006818076595664024,0.006920714396983385,0.0067696464248001575,0.006869066506624222,0.006787286605685949,0.006737971678376198,0.006545898970216513,0.0066087753511965275,0.00642067426815629,0.00647721765562892,0.006638375110924244,0.006497381720691919,0.006437457166612148,0.006399446167051792,0.006353683304041624,0.006331471260637045,0.006282261107116938,0.0061652809381484985,0.0061767143197357655,0.00625058077275753,0.006154118105769157,0.006117731332778931,0.006082215346395969,0.0059752082452178,0.0060327607207000256,0.005942581687122583,0.005976182408630848,0.005921735893934965,0.005944115109741688,0.005844901315867901,0.005819633137434721,0.005854776594787836,0.005765488371253014,0.005826076492667198,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 26611     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 26612     
=================================================================
Total params: 53,223
Trainable params: 53,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 26,611
Trainable params: 26,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 26,612
Trainable params: 26,612
Non-trainable params: 0
_________________________________________________________________
