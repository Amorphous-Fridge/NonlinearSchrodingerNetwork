2021-06-26
loss,0.5819411277770996,0.3512505292892456,0.298612505197525,0.2555045485496521,0.23889189958572388,0.22625508904457092,0.21894146502017975,0.20986367762088776,0.20285290479660034,0.19506102800369263,0.18882276117801666,0.18112359941005707,0.1729758381843567,0.1664646863937378,0.1390547752380371,0.11325757950544357,0.10238040238618851,0.09649357944726944,0.08317277580499649,0.07255575060844421,0.06781215965747833,0.05889785289764404,0.06711332499980927,0.05374486371874809,0.05543632432818413,0.04826927185058594,0.05438639968633652,0.05108097568154335,0.04186243191361427,0.044459592550992966,0.035870250314474106,0.035329438745975494,0.032354675233364105,0.03625623881816864,0.038765087723731995,0.03799015283584595,0.03163248300552368,0.032116688787937164,0.03339160978794098,0.028444437310099602,0.026029253378510475,0.03548748791217804,0.035091582685709,0.031197642907500267,0.0276617631316185,0.027484724298119545,0.021906349807977676,0.018818486481904984,0.017898553982377052,0.023293543606996536,0.028808698058128357,0.02419121004641056,0.03200048208236694,0.027721377089619637,0.026910239830613136,0.02877216786146164,0.024919714778661728,0.028180928900837898,0.028330886736512184,0.023262467235326767,0.020157599821686745,0.02047661319375038,0.02723272331058979,0.026126183569431305,0.02186395600438118,0.017729735001921654,0.02013443037867546,0.020253706723451614,0.02270324155688286,0.02386627346277237,0.026594756171107292,0.0263007003813982,0.021091168746352196,0.01846068724989891,0.024780597537755966,0.02232227474451065,0.0221698060631752,0.02312934212386608,0.02452280931174755,0.02129274420440197,0.01859757862985134,0.016752012073993683,0.0205121710896492,0.023320360109210014,0.02037636749446392,0.019908519461750984,0.01879739947617054,0.020993495360016823,0.024908432736992836,0.020741000771522522,0.020561952143907547,0.021338649094104767,0.020309114828705788,0.022764358669519424,0.02107577584683895,0.01908280700445175,0.019321558997035027,0.016580741852521896,0.01730981282889843,0.018325403332710266,
mse,0.13233405351638794,0.03664766252040863,0.026836145669221878,0.02080436237156391,0.018930384889245033,0.01741698943078518,0.01618240401148796,0.015012004412710667,0.01406053826212883,0.013171485625207424,0.01239913422614336,0.011341686360538006,0.009949473664164543,0.008590311743319035,0.00577128492295742,0.00384281063452363,0.0030546700581908226,0.0027691898867487907,0.0020493410993367434,0.0015600036131218076,0.0013694886583834887,0.001005583326332271,0.0012729206355288625,0.0008330922573804855,0.000880674400832504,0.0006960293394513428,0.0008602073648944497,0.0007495848694816232,0.0005041452241130173,0.0005612842505797744,0.0003782816929742694,0.0003684590628836304,0.0003098983142990619,0.00038905625115148723,0.0004292974481359124,0.0004072509764228016,0.0002856868668459356,0.0003057202266063541,0.0003128939133603126,0.00023937862715683877,0.0002009299205383286,0.0003542398917488754,0.0003415341197978705,0.00028148843557573855,0.0002191650855820626,0.0002144455793313682,0.00014464389823842794,0.00010042949725175276,9.02626634342596e-05,0.00016821184544824064,0.0002371712907915935,0.00017104802827816457,0.0002879533567465842,0.00021902946173213422,0.00021439377451315522,0.00023378292098641396,0.0001798468583729118,0.00022198660008143634,0.00022691443155054003,0.00016484591469634324,0.00012333141057752073,0.00012620148481801152,0.0002120148274116218,0.00018956259009428322,0.0001374640705762431,9.515163401374593e-05,0.00012014227831969038,0.00012344049173407257,0.00015165848890319467,0.00016348868666682392,0.000198156398255378,0.00019601052918005735,0.00012964628695044667,0.00010184188431594521,0.0001763503096299246,0.00014506129082292318,0.00014182698214426637,0.00015055590483825654,0.0001722638262435794,0.00012995826546102762,0.00010344272595830262,8.466113649774343e-05,0.00012405699817463756,0.0001536666095489636,0.00012576283188536763,0.00011745547089958563,0.00010294403182342649,0.0001258413540199399,0.00017105985898524523,0.00012348573363851756,0.00012321711983531713,0.00012920302106067538,0.0001176508521893993,0.00014607339107897133,0.00012562860501930118,0.00010800763266161084,0.00010924891830654815,8.207512291846797e-05,8.698848978383467e-05,9.997028246289119e-05,
mae,0.24895831942558289,0.15297448635101318,0.12615054845809937,0.10876161605119705,0.10193382948637009,0.09559821337461472,0.0923442617058754,0.08885353803634644,0.08757417649030685,0.08517111092805862,0.08310321718454361,0.07972881942987442,0.07557523995637894,0.07126940041780472,0.05955299362540245,0.04779468849301338,0.04315422847867012,0.04091593623161316,0.03565382584929466,0.03041086159646511,0.02881583198904991,0.02499903365969658,0.028188932687044144,0.02283596061170101,0.023607637733221054,0.020755095407366753,0.022856703028082848,0.021816102787852287,0.017858583480119705,0.01907629333436489,0.014993185177445412,0.014953612349927425,0.013570254668593407,0.015621531754732132,0.01670553721487522,0.016331518068909645,0.013279899023473263,0.013689329847693443,0.014343754388391972,0.011920101940631866,0.01103163231164217,0.015175136737525463,0.014905374497175217,0.013493410311639309,0.011784195899963379,0.01162990927696228,0.009336482733488083,0.008032094687223434,0.007627238053828478,0.00994142983108759,0.01223032083362341,0.010391240008175373,0.013543110340833664,0.01188477873802185,0.01152276061475277,0.012318570166826248,0.010611128062009811,0.011991001665592194,0.012151138857007027,0.00991126336157322,0.008581040427088737,0.008569824509322643,0.011619801633059978,0.011131316423416138,0.009333942085504532,0.007559917401522398,0.008497343398630619,0.008526897989213467,0.009473218582570553,0.010157451964914799,0.011308664456009865,0.011237558908760548,0.008881570771336555,0.007819942198693752,0.010619654320180416,0.009352494962513447,0.00937893707305193,0.00974118523299694,0.010500327683985233,0.009068841114640236,0.007888413965702057,0.00713506480678916,0.008787008933722973,0.01004255935549736,0.008587509393692017,0.008544506505131721,0.007944190874695778,0.008904702961444855,0.010646359995007515,0.008960556238889694,0.00861223042011261,0.009044026024639606,0.008564148098230362,0.009786742739379406,0.008869163691997528,0.008098396472632885,0.008221730589866638,0.0070692128501832485,0.00732799107208848,0.007770088966935873,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 69235     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 69236     
=================================================================
Total params: 138,471
Trainable params: 138,471
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 69,235
Trainable params: 69,235
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 69,236
Trainable params: 69,236
Non-trainable params: 0
_________________________________________________________________
