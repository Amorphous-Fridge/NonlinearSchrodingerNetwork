2021-06-26
loss,0.6138217449188232,0.29910382628440857,0.25400349497795105,0.2412758320569992,0.21817588806152344,0.20992368459701538,0.11280190199613571,0.10162176191806793,0.12595345079898834,0.08425117284059525,0.08453994989395142,0.08592941612005234,0.08029109984636307,0.08139092475175858,0.06598908454179764,0.05350098758935928,0.061134837567806244,0.05312759429216385,0.04891076683998108,0.06202284246683121,0.06611709296703339,0.06573580950498581,0.058844923973083496,0.054191794246435165,0.055516019463539124,0.05429442971944809,0.04740383103489876,0.05084943771362305,0.048620034009218216,0.04665444418787956,0.039742108434438705,0.029764922335743904,0.035943783819675446,0.04507581144571304,0.047333475202322006,0.04289332032203674,0.037701644003391266,0.04357702285051346,0.04124949499964714,0.04133427515625954,0.03943847492337227,0.03462336212396622,0.03784337639808655,0.03916267678141594,0.031250786036252975,0.029509639367461205,0.032999187707901,0.039092373102903366,0.038453396409749985,0.03532594069838524,0.032272811979055405,0.029229070991277695,0.026776937767863274,0.024345945566892624,0.0296377781778574,0.03409890457987785,0.03201964497566223,0.03665558248758316,0.03250452131032944,0.029659388586878777,0.027937225997447968,0.02530919574201107,0.027429992333054543,0.030965406447649002,0.03346113860607147,0.03098442032933235,0.028003958985209465,0.02460077591240406,0.028807664290070534,0.026258453726768494,0.02789289690554142,0.028486186638474464,0.02487141452729702,0.03090118244290352,0.02953297086060047,0.026342706754803658,0.024797620251774788,0.022810962051153183,0.019922645762562752,0.019910061731934547,0.02490020915865898,0.03140520676970482,0.02721310779452324,0.023977108299732208,0.02238762378692627,0.021756302565336227,0.02186664193868637,0.028878604993224144,0.028347546234726906,0.02514737658202648,0.022817926481366158,0.0252312533557415,0.02365262061357498,0.02563280425965786,0.021785667166113853,0.02107972837984562,0.02298898436129093,0.022556111216545105,0.021231813356280327,0.019934335723519325,
mse,0.15180279314517975,0.027267830446362495,0.02100788615643978,0.01930306851863861,0.015361559577286243,0.013055550865828991,0.0037866258062422276,0.003016294213011861,0.004758739378303289,0.002039671875536442,0.002016640268266201,0.0021088565699756145,0.0018537613796070218,0.0019231546903029084,0.0012569910613819957,0.0008144493913277984,0.001065764226950705,0.0008194217225536704,0.0006931211100891232,0.0011217690771445632,0.0012838460970669985,0.0012117414735257626,0.0009838894475251436,0.0008179243886843324,0.0008594903629273176,0.0008491979679092765,0.0006502477335743606,0.0007323747267946601,0.0006634167511947453,0.000615267432294786,0.00045562643208540976,0.00026496045757085085,0.0003851598594337702,0.0005816505290567875,0.0006266057025641203,0.0005083615542389452,0.00041048313141800463,0.0005422282265499234,0.00047226797323673964,0.0004855681909248233,0.0004421519406605512,0.0003405172028578818,0.0003960980975534767,0.00043368301703594625,0.00028023694176226854,0.00025245596771128476,0.0003125611983705312,0.0004248202603776008,0.00040688866283744574,0.00035163297434337437,0.0002961369464173913,0.00024146525538526475,0.00020872843742836267,0.00017894114716909826,0.0002557796542532742,0.00032408739207312465,0.00030138573492877185,0.0003734065976459533,0.00030136777786538005,0.0002492715138942003,0.00022028213425073773,0.00018504350737202913,0.00021735353220719844,0.00027426588349044323,0.00031518013565801084,0.000269881944404915,0.00021801276307087392,0.00017816582112573087,0.00023416962358169258,0.00019243330461904407,0.00022403159528039396,0.0002254067949252203,0.0001777143043000251,0.0002705272927414626,0.00024028256302699447,0.00019327280460856855,0.00017062891856767237,0.00014568908954970539,0.00011878829536726698,0.00012175160372862592,0.00018029446073342115,0.00027285038959234953,0.00020551936177071184,0.00016764426254667342,0.00014294555876404047,0.00013683510769624263,0.00013760922593064606,0.00023497510119341314,0.00022332930529955775,0.00017580688290763646,0.00014830619329586625,0.00017938981181941926,0.00015749354497529566,0.00017946194566320628,0.00013590157323051244,0.00012832213542424142,0.00014799420023337007,0.00014121200365480036,0.00012868591875303537,0.00011513446224853396,
mae,0.26523664593696594,0.12873144447803497,0.11129692196846008,0.1063196212053299,0.09497441351413727,0.08722874522209167,0.04757470637559891,0.04367082566022873,0.05332162231206894,0.03574394807219505,0.03540513664484024,0.0354415625333786,0.03363655135035515,0.03444361314177513,0.02756110392510891,0.022755254060029984,0.025970758870244026,0.022287223488092422,0.021008595824241638,0.026563145220279694,0.02829318307340145,0.028505094349384308,0.025575894862413406,0.023124318569898605,0.02376057207584381,0.02342592179775238,0.020129751414060593,0.022016029804944992,0.021279674023389816,0.02015756443142891,0.016747187823057175,0.012533169239759445,0.015127411112189293,0.018886450678110123,0.02051555924117565,0.01883329451084137,0.016045425087213516,0.018681181594729424,0.01772443763911724,0.01756901666522026,0.016796816140413284,0.014293193817138672,0.01611442118883133,0.016970735043287277,0.01327503565698862,0.012467625550925732,0.014026626013219357,0.01669807732105255,0.016773970797657967,0.015224679373204708,0.013629065826535225,0.012127062305808067,0.011110094375908375,0.010398311540484428,0.012478725984692574,0.014784867875277996,0.013782385736703873,0.015958555042743683,0.01440359279513359,0.012576417997479439,0.011807420291006565,0.010680723935365677,0.01161811500787735,0.013290328904986382,0.014519895426928997,0.013618703931570053,0.012402351014316082,0.010209442116320133,0.011868557892739773,0.011064719408750534,0.012064342387020588,0.012540556490421295,0.01074279099702835,0.012743303552269936,0.012664802372455597,0.01180663425475359,0.011075090616941452,0.009854181669652462,0.00848198402673006,0.008543281815946102,0.01057638879865408,0.013574924319982529,0.011287767440080643,0.010092225857079029,0.009315679781138897,0.009185749106109142,0.009242887608706951,0.012428704649209976,0.012480741366744041,0.010559248737990856,0.009607277810573578,0.010623514652252197,0.010038184002041817,0.010750900954008102,0.00922737643122673,0.008930427953600883,0.009830541908740997,0.009228899143636227,0.008681757375597954,0.008272617124021053,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 50603     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 50604     
=================================================================
Total params: 101,207
Trainable params: 101,207
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 50,603
Trainable params: 50,603
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 50,604
Trainable params: 50,604
Non-trainable params: 0
_________________________________________________________________
