2021-06-26
loss,0.6049527525901794,0.14535990357398987,0.1426016390323639,0.1493268609046936,0.10289395600557327,0.09484506398439407,0.08948774635791779,0.10550737380981445,0.09088414907455444,0.06998851150274277,0.060755208134651184,0.07017435878515244,0.07136747986078262,0.05739324167370796,0.06027840077877045,0.05573656037449837,0.04604349285364151,0.05360447242856026,0.04727155342698097,0.060077279806137085,0.048733875155448914,0.050668396055698395,0.05392109230160713,0.04686300456523895,0.04051518812775612,0.04468269273638725,0.042271457612514496,0.04504627361893654,0.045111436396837234,0.0379883274435997,0.03798014298081398,0.04104670137166977,0.038664087653160095,0.0440293550491333,0.038590747863054276,0.03563840687274933,0.03661797195672989,0.033876918256282806,0.030650822445750237,0.030793460085988045,0.031926512718200684,0.03405919298529625,0.03005300834774971,0.028408313170075417,0.03464435413479805,0.02869696542620659,0.03180689364671707,0.028792891651391983,0.025981424376368523,0.024928120896220207,0.03214911371469498,0.02904609590768814,0.026592997834086418,0.03434238210320473,0.03059709072113037,0.033031564205884933,0.027524972334504128,0.019340751692652702,0.021422674879431725,0.02609819360077381,0.02776597999036312,0.02584023028612137,0.024434423074126244,0.02306029573082924,0.02554820105433464,0.029455561190843582,0.0267452672123909,0.02748851105570793,0.024194033816456795,0.020571114495396614,0.023674700409173965,0.027715515345335007,0.02439412660896778,0.022874703630805016,0.02339947409927845,0.024192051962018013,0.0248036477714777,0.02207009308040142,0.01931936666369438,0.02420048974454403,0.02338651940226555,0.022266598418354988,0.02193254791200161,0.02165680006146431,0.019396917894482613,0.016937628388404846,0.01998397335410118,0.020779728889465332,0.02175879292190075,0.01935458369553089,0.02201489359140396,0.02137620374560356,0.01849847473204136,0.019714105874300003,0.020289266481995583,0.02394251897931099,0.021072879433631897,0.01886606588959694,0.017690446227788925,0.016040097922086716,
mse,0.18462352454662323,0.006102097686380148,0.0066679297015070915,0.006588342133909464,0.003023131750524044,0.0025017731823027134,0.002253385493531823,0.0033261559437960386,0.0024245292879641056,0.001388671575114131,0.0010673913639038801,0.0014110819902271032,0.0014359140768647194,0.0009732054895721376,0.0010269258636981249,0.0008994719246402383,0.0005976714310236275,0.0008127281325869262,0.0006401783903129399,0.0010441988706588745,0.0006732576293870807,0.0007110016304068267,0.0008092692587524652,0.0006483955075964332,0.00046080496395006776,0.0005613365210592747,0.0005001573590561748,0.0005697815213352442,0.000581159838475287,0.00040855156839825213,0.00040874775731936097,0.00046485240454785526,0.0004218746325932443,0.0005421246751211584,0.00041173427598550916,0.0003653119783848524,0.00037885273923166096,0.00032339588506147265,0.0002691250410862267,0.0002704186481423676,0.0002965703315567225,0.0003244257241021842,0.00025231632753275335,0.00023125817824620754,0.0003317024966236204,0.00023092515766620636,0.0002853888145182282,0.0002357053745072335,0.00019203512056265026,0.00018058159912470728,0.00028947394457645714,0.0002305200760019943,0.00019928898836951703,0.00032857016776688397,0.0002576744300313294,0.00030327751301229,0.00022456228907685727,0.00011412339517846704,0.00013630755711346865,0.00018998367886524647,0.00021926371846348047,0.00018496248230803758,0.0001661511923884973,0.00015236837498378009,0.0001922412047861144,0.0002430342137813568,0.00020405399845913053,0.0002094398223562166,0.00016697138198651373,0.00012462078302633017,0.0001615358196431771,0.00021053636737633497,0.00016799596778582782,0.00014852573804091662,0.0001546549319755286,0.0001639017282286659,0.00016983757086563855,0.0001369944802718237,0.00011226178321521729,0.0001643514260649681,0.0001543700200272724,0.0001405786315444857,0.00013620372919831425,0.00013077439507469535,0.00011051075853174552,8.810545114101842e-05,0.00011686572543112561,0.00012630845594685525,0.00013351699453778565,0.00010699849372031167,0.00013930445129517466,0.00012769315799232572,9.848715126281604e-05,0.00011036515206797048,0.00011526989692356437,0.0001573323243064806,0.00012610957492142916,0.0001008054314297624,8.889024320524186e-05,7.549621659563854e-05,
mae,0.26255595684051514,0.06132696941494942,0.06091882288455963,0.06348934769630432,0.043169837445020676,0.03998313099145889,0.03769388794898987,0.042922768741846085,0.0388026088476181,0.029477722942829132,0.025208113715052605,0.03025067411363125,0.030823344364762306,0.023912865668535233,0.0248351339250803,0.023887628689408302,0.019396284595131874,0.022296635434031487,0.01989298313856125,0.02496570535004139,0.02043033204972744,0.02151593752205372,0.022995606064796448,0.019667796790599823,0.016532979905605316,0.018636174499988556,0.017710424959659576,0.019228974357247353,0.018759163096547127,0.016020867973566055,0.016099603846669197,0.017353005707263947,0.01631552167236805,0.01928364299237728,0.01602238044142723,0.01520041935145855,0.015727346763014793,0.014344470575451851,0.012981444597244263,0.012793753296136856,0.013566384091973305,0.01438836008310318,0.012592911720275879,0.012019931338727474,0.014795202761888504,0.011995529755949974,0.013238322921097279,0.011978143826127052,0.010981546714901924,0.010621427558362484,0.01388600468635559,0.01224286574870348,0.011165197938680649,0.01461425144225359,0.012814166955649853,0.014095555990934372,0.01177209336310625,0.008242248557507992,0.009098149836063385,0.011020490899682045,0.011826854199171066,0.011033770628273487,0.010424315929412842,0.009798504412174225,0.010924492962658405,0.012691671028733253,0.01143789291381836,0.011448753997683525,0.01009503286331892,0.008665112778544426,0.010064137168228626,0.011666350066661835,0.01034451648592949,0.009713929146528244,0.009706761687994003,0.01011723279953003,0.010541089810431004,0.009601994417607784,0.008162764832377434,0.010161947458982468,0.009945515543222427,0.00927113089710474,0.009274890646338463,0.009106398560106754,0.008185876533389091,0.0071663022972643375,0.008492778986692429,0.008892133831977844,0.008990611881017685,0.007990092970430851,0.00912918895483017,0.008996631018817425,0.007893352769315243,0.008301359601318836,0.00860478263348341,0.009812131524085999,0.008994669653475285,0.007855682633817196,0.007507089525461197,0.0067985341884195805,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 67827     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 67828     
=================================================================
Total params: 135,655
Trainable params: 135,655
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 67,827
Trainable params: 67,827
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 67,828
Trainable params: 67,828
Non-trainable params: 0
_________________________________________________________________
