2021-06-26
loss,0.32071131467819214,0.09971214085817337,0.07690931111574173,0.07007104903459549,0.06304655224084854,0.04606427997350693,0.03902198374271393,0.037217821925878525,0.03504131734371185,0.03352401405572891,0.03243810683488846,0.0314871184527874,0.03115091100335121,0.02998592145740986,0.02911185473203659,0.028324197977781296,0.027607809752225876,0.027026094496250153,0.026724858209490776,0.02632763795554638,0.02592901699244976,0.025173654779791832,0.02481808513402939,0.02441497892141342,0.02361210808157921,0.02376876398921013,0.023632461205124855,0.023352764546871185,0.02284613810479641,0.022589022293686867,0.022442610934376717,0.02217782661318779,0.022016488015651703,0.021650372073054314,0.021280890330672264,0.021465182304382324,0.021160954609513283,0.02082083746790886,0.020514294505119324,0.02062336355447769,0.020313289016485214,0.02009466476738453,0.01996331661939621,0.019785258919000626,0.019712066277861595,0.01948368176817894,0.019394587725400925,0.019240930676460266,0.019129246473312378,0.01898900419473648,0.01868637278676033,0.01875041425228119,0.01869293488562107,0.018363384529948235,0.018398411571979523,0.01829717680811882,0.018170133233070374,0.01812628097832203,0.01796698570251465,0.017800502479076385,0.01777934841811657,0.017558619379997253,0.01753883995115757,0.01755635067820549,0.017403459176421165,0.01736811362206936,0.017201624810695648,0.017205549404025078,0.017125701531767845,0.017082620412111282,0.01673165149986744,0.01701171323657036,0.01668807491660118,0.016770945861935616,0.016620857641100883,0.016682583838701248,0.01653686910867691,0.016465703025460243,0.016397545114159584,0.01633055880665779,0.016177570447325706,0.01621236279606819,0.01612836681306362,0.015975359827280045,0.016088804230093956,0.015806900337338448,0.01596730947494507,0.01573624089360237,0.0157441645860672,0.015649564564228058,0.015733882784843445,0.015596738085150719,0.015459702350199223,0.015425223857164383,0.01557285524904728,0.015269283205270767,0.015370490960776806,0.015374629758298397,0.015330130234360695,0.015203622169792652,
mse,0.039750419557094574,0.003410061588510871,0.0019101096550002694,0.0015080575831234455,0.0011795824393630028,0.0006312377518042922,0.0004630862968042493,0.00040862945024855435,0.0003632750012911856,0.00033584804623387754,0.00030972916283644736,0.00029413687298074365,0.0002793875755742192,0.0002619914594106376,0.0002465330180712044,0.00023228461213875562,0.00021961353195365518,0.00021443783771246672,0.0002061617124127224,0.00019827291544061154,0.00019146934209857136,0.000179805705556646,0.00017601530998945236,0.0001698492415016517,0.00016275221423711628,0.000164172743097879,0.00016041439084801823,0.00015693914610892534,0.00014837959315627813,0.00014760922931600362,0.00014369917334988713,0.00013984374527353793,0.00013743358431383967,0.00013263782602734864,0.00013017875608056784,0.00013073443551547825,0.00012701793457381427,0.00012187530955998227,0.00011935222573811188,0.00012030127254547551,0.00011815981270046905,0.0001145136629929766,0.0001131371536757797,0.00011150698992423713,0.00011056125367758796,0.0001074725078069605,0.00010662329441402107,0.00010527433914830908,0.00010307927732355893,0.00010193551133852452,9.980575123336166e-05,0.000100679237220902,9.929232328431681e-05,9.563149069435894e-05,9.58206583163701e-05,9.526441863272339e-05,9.27190703805536e-05,9.302451508119702e-05,9.084847988560796e-05,9.036190749611706e-05,8.91772288014181e-05,8.805971447145566e-05,8.732289279578254e-05,8.749854168854654e-05,8.549454651074484e-05,8.57904669828713e-05,8.394731412408873e-05,8.407269342569634e-05,8.327134855790064e-05,8.207636710722e-05,7.985409320099279e-05,8.148625784087926e-05,7.994023326318711e-05,7.958261994645e-05,7.915845344541594e-05,7.93840445112437e-05,7.735499821137637e-05,7.638806710019708e-05,7.634401845280081e-05,7.549682050012052e-05,7.457377068931237e-05,7.367961370619014e-05,7.352243119385093e-05,7.198500679805875e-05,7.315482071135193e-05,7.000972254900262e-05,7.203283894341439e-05,7.040501077426597e-05,6.970299000386149e-05,6.972554547246546e-05,6.98449948686175e-05,6.909015792189166e-05,6.845979805802926e-05,6.751318869646639e-05,6.845998723292723e-05,6.549093086505309e-05,6.773990025976673e-05,6.74094189889729e-05,6.715825293213129e-05,6.537687295349315e-05,
mae,0.13463141024112701,0.04276052489876747,0.03280089423060417,0.029774753376841545,0.026582203805446625,0.01961071416735649,0.01666918396949768,0.0158779788762331,0.014964079484343529,0.014395535923540592,0.013851802796125412,0.013521536253392696,0.013408297672867775,0.012740310281515121,0.012493330053985119,0.012101823464035988,0.011807114817202091,0.011516076512634754,0.01135332603007555,0.011252394877374172,0.011139375157654285,0.010763484984636307,0.01070490013808012,0.010415717028081417,0.010044303722679615,0.010040797293186188,0.010096029378473759,0.009960207156836987,0.009721658192574978,0.009647536091506481,0.00956468190997839,0.00945225078612566,0.009391414001584053,0.009201422333717346,0.009057818911969662,0.009149545803666115,0.009046249091625214,0.008851826190948486,0.008677971549332142,0.00886920653283596,0.008662847802042961,0.008532566949725151,0.00851225946098566,0.008428018540143967,0.008365712128579617,0.008352834731340408,0.008274910040199757,0.008182781748473644,0.008165571838617325,0.008109696209430695,0.007938705384731293,0.007999256253242493,0.008011219091713428,0.007735836319625378,0.007865240797400475,0.007814076729118824,0.007709217257797718,0.0077186101116240025,0.00762353977188468,0.0076141320168972015,0.0075170076452195644,0.007514817640185356,0.007501576095819473,0.007496267557144165,0.007389888167381287,0.007391751278191805,0.007288293447345495,0.007272103801369667,0.007278389297425747,0.007265753578394651,0.007056009955704212,0.007220936007797718,0.007069781422615051,0.007165278308093548,0.007094346918165684,0.007029390893876553,0.007025076076388359,0.0070194979198277,0.006994502153247595,0.006924409884959459,0.006906451191753149,0.006868869531899691,0.006894463673233986,0.006738016381859779,0.006893919315189123,0.006725482176989317,0.006867053918540478,0.006699688266962767,0.006650074850767851,0.006633383221924305,0.006635304540395737,0.0066065555438399315,0.006618953309953213,0.006456447299569845,0.00660476041957736,0.0065402500331401825,0.006565149873495102,0.006553521379828453,0.0065391454845666885,0.006481758318841457,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 13051     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 13052     
=================================================================
Total params: 26,103
Trainable params: 26,103
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 13,051
Trainable params: 13,051
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 13,052
Trainable params: 13,052
Non-trainable params: 0
_________________________________________________________________
