2021-06-26
loss,0.38123536109924316,0.23361796140670776,0.2215668112039566,0.2073259800672531,0.1671585887670517,0.11333701759576797,0.09488504379987717,0.07584360241889954,0.0787399634718895,0.08550816774368286,0.05400991812348366,0.07028412073850632,0.06195053458213806,0.05010925233364105,0.051782332360744476,0.05358971282839775,0.0510593019425869,0.0708673894405365,0.054607052356004715,0.0319763645529747,0.030560538172721863,0.029534444212913513,0.02887778729200363,0.027954448014497757,0.027705594897270203,0.02875687927007675,0.043689142912626266,0.036115389317274094,0.02970985323190689,0.02789454534649849,0.026528174057602882,0.02582227624952793,0.025339724496006966,0.03349741920828819,0.041497763246297836,0.033169087022542953,0.02452508918941021,0.023178881034255028,0.02322378382086754,0.02207973226904869,0.02241482213139534,0.02214064821600914,0.02158818393945694,0.02797531522810459,0.03626728057861328,0.03225184977054596,0.026764443144202232,0.025344399735331535,0.021808983758091927,0.021298160776495934,0.021912403404712677,0.03178131952881813,0.03771587088704109,0.0324258916079998,0.027460064738988876,0.02480994164943695,0.032180145382881165,0.03062727302312851,0.031946875154972076,0.02898932620882988,0.026740115135908127,0.025375664234161377,0.023938503116369247,0.022816946730017662,0.02210940420627594,0.02121676504611969,0.022485798224806786,0.021916737779974937,0.021314449608325958,0.018370311707258224,0.017134200781583786,0.016571251675486565,0.01600600779056549,0.015885237604379654,0.015643024817109108,0.015393998473882675,0.015272479504346848,0.01519585121423006,0.015295632183551788,0.015113985165953636,0.015008311718702316,0.014954819343984127,0.015008972026407719,0.014830651693046093,0.0146773811429739,0.014800813980400562,0.014662644825875759,0.014590617269277573,0.014555779285728931,0.01446150429546833,0.014433557167649269,0.01431358978152275,0.014350934885442257,0.014335514046251774,0.014181985519826412,0.014155406504869461,0.014107409864664078,0.014141613617539406,0.014065511524677277,0.013925407081842422,
mse,0.06911682337522507,0.018697349354624748,0.017229629680514336,0.015102642588317394,0.009122844785451889,0.003962634596973658,0.0027043723966926336,0.0017378951888531446,0.0019179879454895854,0.0022847484797239304,0.0008995829266496003,0.0014716311125084758,0.0011113968212157488,0.0007418204913847148,0.0007756768027320504,0.0008274166029877961,0.0007841361803002656,0.0014459396479651332,0.0009075927664525807,0.00031483042403124273,0.0002833015751093626,0.0002581641310825944,0.00024727321579121053,0.0002296231541549787,0.00022719480330124497,0.0002574241952970624,0.0005374423926696181,0.0003860440046992153,0.00026500364765524864,0.00024007073079701513,0.00021173800632823259,0.000198205845663324,0.00019588181748986244,0.0003533857234288007,0.0004845684743486345,0.00033782541868276894,0.00017882324755191803,0.0001622842828510329,0.00015847766189835966,0.0001470209681428969,0.00014934288628865033,0.00014078851381782442,0.00013616803335025907,0.0002376806369284168,0.0003786663291975856,0.00030114135006442666,0.0002145173930330202,0.00019128502754028887,0.00014772822032682598,0.00013763064634986222,0.00014799759082961828,0.00029147573513910174,0.000403267185902223,0.00029865355463698506,0.0002201512106694281,0.00017726236546877772,0.00029992611962370574,0.00027120605227537453,0.0002868632145691663,0.00023861070803832263,0.00020610616775229573,0.00018555852875579149,0.00016711837088223547,0.00015372244524769485,0.00014367139374371618,0.0001362370530841872,0.0001485817920183763,0.00014145643217489123,0.00013457374006975442,0.00010219851537840441,8.590720244683325e-05,7.948509301058948e-05,7.560723315691575e-05,7.376538269454613e-05,7.108218414941803e-05,6.91849782015197e-05,6.817448593210429e-05,6.763001874787733e-05,6.778462557122111e-05,6.559534813277423e-05,6.53667448204942e-05,6.43664097879082e-05,6.48822751827538e-05,6.377470708684996e-05,6.297283107414842e-05,6.319398380583152e-05,6.161947385407984e-05,6.119156023487449e-05,6.126724474597722e-05,6.0736172599717975e-05,6.0123093135189265e-05,5.9168207371840253e-05,5.981016511213966e-05,5.913155109738e-05,5.842178507009521e-05,5.735996819566935e-05,5.773049269919284e-05,5.717689055018127e-05,5.682662958861329e-05,5.561451325775124e-05,
mae,0.1619916558265686,0.09960818290710449,0.09587901085615158,0.09109504520893097,0.07307757437229156,0.04870453476905823,0.0401921421289444,0.032141461968421936,0.03283829614520073,0.0358918271958828,0.023257121443748474,0.029938530176877975,0.025643743574619293,0.02111666463315487,0.021953316405415535,0.02243235521018505,0.021668000146746635,0.031494103372097015,0.023606831207871437,0.013781045563519001,0.01330661028623581,0.012743477709591389,0.012553044594824314,0.012024818919599056,0.011865830048918724,0.012169361114501953,0.018661584705114365,0.014782436192035675,0.012627759017050266,0.011947336606681347,0.0113594401627779,0.011124365031719208,0.010787217877805233,0.014138691127300262,0.017174039036035538,0.013472715392708778,0.010579942725598812,0.009898916818201542,0.009978624992072582,0.009450329467654228,0.009569020010530949,0.00949695985764265,0.009263064712285995,0.011797218583524227,0.014948206022381783,0.013177960179746151,0.011181665584445,0.010699255391955376,0.009326730854809284,0.00920408871024847,0.009245754219591618,0.013097872957587242,0.016263987869024277,0.01432870514690876,0.011390081606805325,0.010415657423436642,0.013758680783212185,0.01319432258605957,0.013539525680243969,0.012505762279033661,0.01169502455741167,0.01101301982998848,0.010182168334722519,0.00967121310532093,0.009250499308109283,0.008946161717176437,0.00924025196582079,0.009160849265754223,0.00898612942546606,0.007825341075658798,0.0073641277849674225,0.007126254960894585,0.006893392652273178,0.006773886736482382,0.006700318306684494,0.006614508107304573,0.006548259407281876,0.0065092663280665874,0.006553712300956249,0.006455549504607916,0.006377359852194786,0.006409116555005312,0.006381362676620483,0.006346375215798616,0.006280967500060797,0.006304212845861912,0.006225266959518194,0.0062452941201627254,0.006254558451473713,0.006121067330241203,0.006127180531620979,0.006140564102679491,0.006075899116694927,0.0061690849252045155,0.006025762762874365,0.006006892304867506,0.006043894216418266,0.006061977706849575,0.006058960687369108,0.005919269751757383,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17739     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17740     
=================================================================
Total params: 35,479
Trainable params: 35,479
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 17,739
Trainable params: 17,739
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 17,740
Trainable params: 17,740
Non-trainable params: 0
_________________________________________________________________
