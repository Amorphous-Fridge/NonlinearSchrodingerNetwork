2021-06-26
loss,0.50496906042099,0.1404886692762375,0.09611891955137253,0.06855033338069916,0.0543900690972805,0.0502651110291481,0.04913736507296562,0.04608554765582085,0.04475018009543419,0.04289758577942848,0.04275401681661606,0.0556747205555439,0.05605573207139969,0.03982087969779968,0.03905314579606056,0.03796500340104103,0.036452971398830414,0.03632306680083275,0.036282408982515335,0.036442313343286514,0.03539874032139778,0.054276786744594574,0.06658007204532623,0.07905404269695282,0.06429316848516464,0.05834584683179855,0.042178284376859665,0.048320017755031586,0.055465854704380035,0.05341995134949684,0.047090496867895126,0.039867695420980453,0.037239059805870056,0.05761778727173805,0.05495581030845642,0.05121363699436188,0.04740985482931137,0.043772172182798386,0.038044076412916183,0.03364366665482521,0.042135950177907944,0.04336097836494446,0.0353592187166214,0.032518815249204636,0.04712769016623497,0.03196436166763306,0.0302833691239357,0.04814538359642029,0.04707754775881767,0.045744236558675766,0.04101426526904106,0.03852568194270134,0.035091742873191833,0.03145206347107887,0.02935449406504631,0.04344288259744644,0.05080695450305939,0.04327881336212158,0.034938372671604156,0.023175682872533798,0.023173965513706207,0.02243014983832836,0.021879101172089577,0.022108884528279305,0.021601879969239235,0.021549062803387642,0.02157004550099373,0.02268320508301258,0.022611355409026146,0.022114437073469162,0.02241065725684166,0.02256547287106514,0.02213912643492222,0.021638572216033936,0.021570725366473198,0.021345311775803566,0.021122682839632034,0.02178356796503067,0.021120693534612656,0.02221047692000866,0.03648093715310097,0.03306781128048897,0.030039798468351364,0.02826116606593132,0.02687852829694748,0.026048505678772926,0.032485008239746094,0.0355423167347908,0.03326848894357681,0.026296652853488922,0.03154652938246727,0.03970954939723015,0.03485194966197014,0.025804569944739342,0.028463374823331833,0.031879495829343796,0.033681657165288925,0.030701972544193268,0.027311796322464943,0.025151122361421585,
mse,0.09890488535165787,0.007370507810264826,0.0030024293810129166,0.001435956684872508,0.0008719810866750777,0.0007312656962312758,0.0006937242578715086,0.000607259280513972,0.0005697685992345214,0.0005206948262639344,0.000515980995260179,0.0009300671517848969,0.0009487874922342598,0.0004634303622879088,0.0004220993141643703,0.00039938383270055056,0.0003672334423754364,0.0003639011410996318,0.00036657965392805636,0.00037263077683746815,0.0003571893903426826,0.000957099546212703,0.0013902275823056698,0.0018888707272708416,0.0012125552166253328,0.0010051480494439602,0.0005530008929781616,0.0006686642300337553,0.0008553084917366505,0.0007998180226422846,0.0006200208445079625,0.00044219999108463526,0.00039099532295949757,0.0009553272393532097,0.0008640061132609844,0.0007449912955053151,0.0006184633239172399,0.0005334097659215331,0.00039920888957567513,0.00031705081346444786,0.0005205631605349481,0.0005661231116391718,0.000343560881447047,0.00029324539355002344,0.0006833875086158514,0.0002910519251599908,0.0002558653359301388,0.0006613419391214848,0.0006384685402736068,0.0005937032983638346,0.0004667401663027704,0.00041738711297512054,0.0003439424326643348,0.00027481847791932523,0.0002445043355692178,0.0005681341281160712,0.0007248595356941223,0.0005243048653937876,0.00035746581852436066,0.0001533808244857937,0.00014939127140678465,0.00013996227062307298,0.00013311496877577156,0.0001354035921394825,0.00012952258111909032,0.0001281185686821118,0.0001280922588193789,0.0001466809626435861,0.0001441995264030993,0.00013910149573348463,0.00013993472384754568,0.00014096751692704856,0.00013397293514572084,0.0001277196715818718,0.00012681684165727347,0.0001241204736288637,0.00012263015378266573,0.00013755224063061178,0.00012456650438252836,0.0001473787851864472,0.0003983505303040147,0.00030062804580666125,0.00025211594766005874,0.00022304273443296552,0.00020022383250761777,0.00018757316865958273,0.00031071490957401693,0.0003506406501401216,0.00030743167735636234,0.0002013033372350037,0.00028493584250099957,0.00043349177576601505,0.00035187238245271146,0.00019907092791981995,0.000231245590839535,0.0002841414825525135,0.00031641204259358346,0.0002610932569950819,0.00020636964472942054,0.0001789516827557236,
mae,0.21605852246284485,0.05760960280895233,0.04099026322364807,0.02910814806818962,0.022906368598341942,0.021121807396411896,0.020938163623213768,0.01932237111032009,0.018886571750044823,0.018170645460486412,0.018199032172560692,0.022936712950468063,0.023079214617609978,0.017118319869041443,0.016726400703191757,0.016315948218107224,0.015462661162018776,0.015606760047376156,0.015640396624803543,0.015553713776171207,0.015232613310217857,0.023006044328212738,0.029065048322081566,0.03428871929645538,0.02913799323141575,0.025707906112074852,0.01805691234767437,0.0206524059176445,0.024035317823290825,0.022042399272322655,0.02024419978260994,0.01738978549838066,0.015829766169190407,0.025161050260066986,0.024058248847723007,0.021563148126006126,0.020207859575748444,0.019239576533436775,0.0167396143078804,0.014788874424993992,0.017625469714403152,0.018156159669160843,0.014663580805063248,0.013477270491421223,0.01976504735648632,0.013619902543723583,0.012816459871828556,0.02069077081978321,0.020165495574474335,0.01957385055720806,0.017147433012723923,0.016112275421619415,0.014847938902676105,0.012584120966494083,0.01195229310542345,0.01873040571808815,0.022388305515050888,0.018735535442829132,0.015114077366888523,0.009979654103517532,0.010175824165344238,0.009811010211706161,0.00948401726782322,0.009532573632895947,0.00921862106770277,0.009194652549922466,0.009318751282989979,0.009692237712442875,0.009506461210548878,0.00930717308074236,0.009504343383014202,0.009507600218057632,0.009348043240606785,0.009337863884866238,0.00941056665033102,0.009053143672645092,0.008951590396463871,0.009318682365119457,0.008922839537262917,0.009463516063988209,0.015172417275607586,0.014812327921390533,0.013962101191282272,0.01308154221624136,0.012360810302197933,0.011823177337646484,0.013762920163571835,0.01530961412936449,0.014535661786794662,0.011139913462102413,0.013428211212158203,0.01769094169139862,0.014927145093679428,0.011005443520843983,0.011971094645559788,0.013373383320868015,0.014372327364981174,0.01323658972978592,0.01120317354798317,0.010480898432433605,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9267      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9268      
=================================================================
Total params: 18,535
Trainable params: 18,535
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 9,267
Trainable params: 9,267
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 9,268
Trainable params: 9,268
Non-trainable params: 0
_________________________________________________________________
