2021-06-26
loss,0.3872116804122925,0.12810975313186646,0.0767958015203476,0.06359033286571503,0.05783132463693619,0.0536673367023468,0.050796810537576675,0.04820351302623749,0.04668663442134857,0.04414321854710579,0.04226984828710556,0.040611136704683304,0.03943589702248573,0.038406409323215485,0.037053365260362625,0.03707034885883331,0.035562530159950256,0.0350346602499485,0.03466516733169556,0.03434848412871361,0.033569179475307465,0.03268533572554588,0.03215114772319794,0.03240611404180527,0.031225033104419708,0.03084413707256317,0.030717983841896057,0.030205368995666504,0.029819240793585777,0.02886783331632614,0.029217833653092384,0.028865041211247444,0.028530050069093704,0.027926089242100716,0.027704309672117233,0.027363575994968414,0.027211323380470276,0.02723567932844162,0.026505742222070694,0.06271228939294815,0.06520144641399384,0.05578089877963066,0.05229678004980087,0.04856468737125397,0.044537898153066635,0.044035304337739944,0.03874550387263298,0.03534166142344475,0.03299519419670105,0.03139558807015419,0.03009871207177639,0.02915295585989952,0.0316041074693203,0.04930060729384422,0.04426153004169464,0.04079844802618027,0.0386652946472168,0.03688473254442215,0.03558787330985069,0.03311729431152344,0.029582418501377106,0.028881464153528214,0.03472799435257912,0.03427445515990257,0.03261840343475342,0.031570468097925186,0.030323540791869164,0.02881881408393383,0.02742677740752697,0.026005733758211136,0.024931054562330246,0.024038849398493767,0.02332708053290844,0.022652430459856987,0.022108104079961777,0.021450931206345558,0.021042941138148308,0.021110523492097855,0.027210459113121033,0.03478334844112396,0.032252971082925797,0.028631145134568214,0.026551291346549988,0.02524632401764393,0.024166377261281013,0.023357339203357697,0.022591421380639076,0.02189500257372856,0.02119746245443821,0.021029533818364143,0.020787157118320465,0.020295441150665283,0.021260950714349747,0.024605972692370415,0.023398933932185173,0.022281760349869728,0.023617422208189964,0.024962687864899635,0.032148703932762146,0.035016510635614395,
mse,0.07162557542324066,0.005819388199597597,0.0017975721275433898,0.0012355261715129018,0.0010224253637716174,0.0008810723666101694,0.0007831669645383954,0.0006959847523830831,0.0006459785508923233,0.0005711650010198355,0.0005174257094040513,0.0004735904512926936,0.0004448239633347839,0.00042010925244539976,0.00038964490522630513,0.00039373693289235234,0.0003787020978052169,0.0003595735761336982,0.00033796310890465975,0.00033251792774535716,0.00031505097285844386,0.0003010692889802158,0.0002890423347707838,0.0002940054691862315,0.0002722208446357399,0.0002668333472684026,0.0002631794777698815,0.00025560377980582416,0.0002478121023159474,0.0002339957864023745,0.0002376916236244142,0.00023359394981525838,0.00022724697191733867,0.00021798904344905168,0.000213276463910006,0.00020920812676195055,0.00020734305144287646,0.0002065024891635403,0.0002037442463915795,0.001379727735184133,0.0012790528126060963,0.0009227341506630182,0.0008094814256764948,0.0006909340736456215,0.0005697766900993884,0.0005453565390780568,0.00041840068297460675,0.0003476503770798445,0.0003035956178791821,0.0002751826250459999,0.00025341141736134887,0.00023794166918378323,0.0003037058049812913,0.0006742023397237062,0.0005466158618219197,0.0004654807271435857,0.00041904073441401124,0.00037959040491841733,0.00035337486770004034,0.0003057198482565582,0.000244955561356619,0.00023711417452432215,0.0003356778179295361,0.0003234062751289457,0.00029553595231845975,0.0002764977398328483,0.00025511591229587793,0.0002298479957971722,0.00020805733220186085,0.00018828629981726408,0.00017277532606385648,0.00016109863645397127,0.00015151052502915263,0.00014266885409597307,0.00013610957830678672,0.00012814105139113963,0.00012400251580402255,0.00012553784472402185,0.00022468571842182428,0.0003610499552451074,0.00028008941444568336,0.00022401312889996916,0.00019372480164747685,0.00017581386782694608,0.00016133123426698148,0.00015127957158256322,0.00014152911899145693,0.00013592088362202048,0.0001283285382669419,0.00012293565669097006,0.0001205579173984006,0.00012007871555397287,0.00013119980576448143,0.00016717078688088804,0.00014934208593331277,0.00013564540131483227,0.000160990355652757,0.00018245687533635646,0.00030977290589362383,0.00035253597889095545,
mae,0.15884387493133545,0.0524875782430172,0.03227018937468529,0.02683429792523384,0.024655155837535858,0.022922419011592865,0.021783120930194855,0.020565491169691086,0.02009810507297516,0.018959062173962593,0.01812397502362728,0.017337435856461525,0.01689552143216133,0.016397710889577866,0.01567355915904045,0.01583889313042164,0.015091801062226295,0.01509308535605669,0.014851126819849014,0.014770506881177425,0.014355423860251904,0.014058704487979412,0.01377739105373621,0.013934500515460968,0.013423982076346874,0.01321932952851057,0.013137808069586754,0.013104192912578583,0.012800995260477066,0.01230853796005249,0.012541634030640125,0.012311067432165146,0.01240022573620081,0.01196410320699215,0.011938342824578285,0.011728142388164997,0.011636976152658463,0.011565684340894222,0.011497332714498043,0.027035698294639587,0.02779749408364296,0.023779740557074547,0.022388381883502007,0.020715655758976936,0.01878674142062664,0.018317479640245438,0.015631183981895447,0.014431867748498917,0.01350223459303379,0.012989488430321217,0.012558774091303349,0.012310881167650223,0.013746597804129124,0.022045833989977837,0.020080793648958206,0.018501777201890945,0.017524393275380135,0.01680266670882702,0.016218354925513268,0.014879055321216583,0.01257859356701374,0.012304323725402355,0.014830070547759533,0.014988633804023266,0.014320772141218185,0.0136925233528018,0.0127172339707613,0.011942189186811447,0.01165816280990839,0.011259889230132103,0.010872343555092812,0.010517670772969723,0.010218224488198757,0.009926852770149708,0.009691973216831684,0.00934481993317604,0.009107976220548153,0.008972090668976307,0.011548317968845367,0.014990354888141155,0.014334592036902905,0.0130993677303195,0.01207340694963932,0.011412126012146473,0.010896380990743637,0.010543286800384521,0.009974556043744087,0.00933066662400961,0.009035698138177395,0.00888952799141407,0.008813077583909035,0.008645963855087757,0.009039873257279396,0.010327836498618126,0.009724942035973072,0.009255273267626762,0.010104869492352009,0.010874707251787186,0.013974206522107124,0.016218727454543114,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6779      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6780      
=================================================================
Total params: 13,559
Trainable params: 13,559
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 6,779
Trainable params: 6,779
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 6,780
Trainable params: 6,780
Non-trainable params: 0
_________________________________________________________________
