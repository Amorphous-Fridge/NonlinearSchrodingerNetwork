2021-06-26
loss,0.4493870437145233,0.19752198457717896,0.13462786376476288,0.1025848314166069,0.0853022113442421,0.07662668079137802,0.11762141436338425,0.0870712548494339,0.06587948650121689,0.05528245493769646,0.06240062415599823,0.07902415096759796,0.07009190320968628,0.04944003000855446,0.04283598065376282,0.04016125202178955,0.046850867569446564,0.056944750249385834,0.06436243653297424,0.05716601386666298,0.04065091162919998,0.03826450929045677,0.03728564828634262,0.03465423360466957,0.05715401470661163,0.04895460978150368,0.05138947442173958,0.044520001858472824,0.039725564420223236,0.03578668460249901,0.032807450741529465,0.031020164489746094,0.028087247163057327,0.027691951021552086,0.029509911313652992,0.03817044198513031,0.04872856289148331,0.04362404718995094,0.04536845535039902,0.028500309213995934,0.02446536347270012,0.025560837239027023,0.024348268285393715,0.023473074659705162,0.023748958483338356,0.023498235270380974,0.023018576204776764,0.02241699956357479,0.022419309243559837,0.022332100197672844,0.022132491692900658,0.021705837920308113,0.02202664688229561,0.021982848644256592,0.021525941789150238,0.021386224776506424,0.021241100504994392,0.0210383553057909,0.02284650318324566,0.023204360157251358,0.02161320485174656,0.03396686911582947,0.030026264488697052,0.02837359718978405,0.036708470433950424,0.03336513787508011,0.03505340963602066,0.031566258519887924,0.03211940824985504,0.028079699724912643,0.02461777999997139,0.022591328248381615,0.030415236949920654,0.028285538777709007,0.02923264540731907,0.033851467072963715,0.030091458931565285,0.029278090223670006,0.026807064190506935,0.024226710200309753,0.022343428805470467,0.021503474563360214,0.020726781338453293,0.01997038535773754,0.022443823516368866,0.033452924340963364,0.0317017138004303,0.029826970770955086,0.026470841839909554,0.02344723790884018,0.021232282742857933,0.021071264520287514,0.02003711462020874,0.018594181165099144,0.01780065707862377,0.017056405544281006,0.01730044186115265,0.020111797377467155,0.027146484702825546,0.028821833431720734,
mse,0.07747024297714233,0.012514514848589897,0.005457186605781317,0.003288544714450836,0.0022126343101263046,0.001751214382238686,0.004018828738480806,0.002242479007691145,0.001249848399311304,0.0009245648980140686,0.001179586979560554,0.00182042655069381,0.0014539104886353016,0.0007167044095695019,0.0005829135188832879,0.00048650027019903064,0.0006585879600606859,0.0009748015436343849,0.001197146251797676,0.0010122203966602683,0.0004922063089907169,0.00042729542474262416,0.00040107331005856395,0.00036554408143274486,0.0009585891384631395,0.0006847096956335008,0.0007600676035508513,0.0005636049318127334,0.0004709167405962944,0.000356556149199605,0.00030792035977356136,0.0002860222302842885,0.00023658994177822024,0.00023219705326482654,0.00026369039551354945,0.0004423608770594001,0.0006780512048862875,0.0005579744465649128,0.0005906570586375892,0.00025695771910250187,0.00018141776672564447,0.00019794824765995145,0.00017649997607804835,0.00016543945821467787,0.00016534228052478284,0.00016120313375722617,0.00015441325376741588,0.00014779898629058152,0.0001468526606913656,0.00014388986164703965,0.00014214293332770467,0.00013868008682038635,0.0001397606683894992,0.00013846276851836592,0.00013189908349886537,0.00013314974785316736,0.00013092547305859625,0.00013033831783104688,0.00015842722496017814,0.0001638185203773901,0.00013775592378806323,0.0003328252350911498,0.000255286053288728,0.00023128491011448205,0.000380722718546167,0.00032430465216748416,0.0003509976959321648,0.0003006705082952976,0.0002978790726047009,0.00021922677115071565,0.00017262202163692564,0.00015058944700285792,0.0002777559566311538,0.00023251563834492117,0.00025255660875700414,0.00032748020021244884,0.00025807798374444246,0.0002461175317876041,0.0002061631385004148,0.00016450464318040758,0.00014086253941059113,0.00013013042917009443,0.00012161201448179781,0.00011609560897340998,0.0001592811750015244,0.00032720883609727025,0.0002840378729160875,0.0002604706969577819,0.00019576374324969947,0.00015886593610048294,0.00013034064613748342,0.00012528305524028838,0.0001137665385613218,0.00010316364205209538,9.750725439516827e-05,8.782660006545484e-05,8.974527736427262e-05,0.00012129479728173465,0.00022134993923828006,0.00023660501756239682,
mae,0.1931716948747635,0.08609989285469055,0.05690789222717285,0.044050563126802444,0.036561205983161926,0.032568786293268204,0.05025102570652962,0.037300463765859604,0.028023265302181244,0.023516567423939705,0.026520149782299995,0.03394794836640358,0.02980116195976734,0.020878160372376442,0.018505794927477837,0.017270125448703766,0.020134337246418,0.02461543120443821,0.027979819104075432,0.024976253509521484,0.017282554879784584,0.016298282891511917,0.015934227034449577,0.014797680079936981,0.02464471571147442,0.02099388837814331,0.022249964997172356,0.018809672445058823,0.01688568852841854,0.01498396322131157,0.013872640207409859,0.01323185209184885,0.012133832089602947,0.011944000609219074,0.012607905082404613,0.016335846856236458,0.0209055058658123,0.0188827496021986,0.019630856812000275,0.012172766029834747,0.010530626401305199,0.011030936613678932,0.010512828826904297,0.010084244422614574,0.0102367689833045,0.010176689364016056,0.009976975619792938,0.00964870024472475,0.00966214295476675,0.009632423520088196,0.009465443901717663,0.009335244074463844,0.009489201009273529,0.009546676650643349,0.009261561557650566,0.009197862818837166,0.00913240946829319,0.008991857059299946,0.009742356836795807,0.009928840212523937,0.009305893443524837,0.014650524593889713,0.01314533967524767,0.012131900526583195,0.015771284699440002,0.014447123743593693,0.015318256802856922,0.013830901123583317,0.013950174674391747,0.011934309266507626,0.010584806092083454,0.009597070515155792,0.01310703530907631,0.012051832862198353,0.012728553265333176,0.014845972880721092,0.013122111558914185,0.012629296630620956,0.011648156680166721,0.010314589366316795,0.009576772339642048,0.009136349894106388,0.008807501755654812,0.008452879264950752,0.009731084108352661,0.014640104956924915,0.014063902199268341,0.01275544986128807,0.01147413719445467,0.010084676556289196,0.00915061216801405,0.009155244566500187,0.00858680997043848,0.007901915349066257,0.007619249634444714,0.0073961494490504265,0.007471152581274509,0.008566968142986298,0.011731251142919064,0.012511581182479858,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25595     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25596     
=================================================================
Total params: 51,191
Trainable params: 51,191
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 25,595
Trainable params: 25,595
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 25,596
Trainable params: 25,596
Non-trainable params: 0
_________________________________________________________________
