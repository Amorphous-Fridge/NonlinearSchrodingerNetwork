2021-06-26
loss,0.4378770887851715,0.08750735223293304,0.061621133238077164,0.05507226288318634,0.05145014822483063,0.043265294283628464,0.04769932106137276,0.04119071364402771,0.04192615672945976,0.04621998965740204,0.045857205986976624,0.04274296388030052,0.04291921481490135,0.0381089486181736,0.03925391659140587,0.037068966776132584,0.03604529798030853,0.035697996616363525,0.032982148230075836,0.027950190007686615,0.03159544616937637,0.03413013368844986,0.030774084851145744,0.027480697259306908,0.030169839039444923,0.029890399426221848,0.02737920545041561,0.029524540528655052,0.02572067454457283,0.023802682757377625,0.026439538225531578,0.025067446753382683,0.021611561998724937,0.022247323766350746,0.02190437540411949,0.026347029954195023,0.022409839555621147,0.021263355389237404,0.021960634738206863,0.022493910044431686,0.022798096761107445,0.021010566502809525,0.01935286447405815,0.019297122955322266,0.018861904740333557,0.020539002493023872,0.02037137746810913,0.01832006126642227,0.017837099730968475,0.020250044763088226,0.020818250253796577,0.019330918788909912,0.01693621464073658,0.018083149567246437,0.01643521524965763,0.015819445252418518,0.01955293118953705,0.019032305106520653,0.018572039902210236,0.01697506755590439,0.015517639927566051,0.01590033620595932,0.015034593641757965,0.01565825752913952,0.017956402152776718,0.017941078171133995,0.016975685954093933,0.01708114892244339,0.016479860991239548,0.016631586477160454,0.01657058671116829,0.015096914954483509,0.016121376305818558,0.01759934611618519,0.017457880079746246,0.015869557857513428,0.01551209669560194,0.015176861546933651,0.01277197990566492,0.014134161174297333,0.01682467758655548,0.015558252111077309,0.016034625470638275,0.017225097864866257,0.01626107655465603,0.015268702059984207,0.014449403621256351,0.013508661650121212,0.012913751415908337,0.013540811836719513,0.015221698209643364,0.014964061789214611,0.014767208136618137,0.014110145159065723,0.014935288578271866,0.014842385426163673,0.014540120027959347,0.013861510902643204,0.013881480321288109,0.014215992763638496,
mse,0.07892637699842453,0.002588265808299184,0.0011805739486590028,0.0008868941804394126,0.0008065661531873047,0.0005574636743403971,0.0006743692792952061,0.0005198958679102361,0.0005236195866018534,0.0006409740308299661,0.0006126952357590199,0.0005419499357230961,0.0005361767252907157,0.00044092570897191763,0.0004481074574869126,0.000416303490055725,0.0003820959245786071,0.00038449958083219826,0.0003311767941340804,0.0002351588918827474,0.0003028973878826946,0.0003294835623819381,0.00027710400172509253,0.00022593584435526282,0.0002780701615847647,0.0002562077424954623,0.00022506136156152934,0.0002470960025675595,0.000196619686903432,0.0001736948761390522,0.0002039439423242584,0.0001846436207415536,0.00014193222159519792,0.00014845130499452353,0.00014707441732753068,0.0001912604202516377,0.0001499592763138935,0.00013931489957030863,0.00014335654850583524,0.0001446733222110197,0.00014570775965694338,0.00012906885240226984,0.00011394827743060887,0.00011322012142045423,0.00010866328375414014,0.00012508781219366938,0.0001201476261485368,0.00010358113649999723,9.899372525978833e-05,0.00011977441317867488,0.00012150423572165892,0.00010980619117617607,8.844846888678148e-05,0.00010061158536700532,8.173373498721048e-05,7.971120794536546e-05,0.00011275563156232238,0.00010346771887270734,9.708386642159894e-05,8.362821245100349e-05,7.393724081339315e-05,7.852061389712617e-05,7.017656025709584e-05,7.502602238673717e-05,9.322552796220407e-05,9.04597545741126e-05,8.37483603390865e-05,8.4475010226015e-05,8.103738218778744e-05,7.994129555299878e-05,8.060949767241254e-05,6.967421359149739e-05,7.753859244985506e-05,8.880323002813384e-05,8.648111543152481e-05,7.186190487118438e-05,7.044540689093992e-05,6.84683327563107e-05,5.2231258450774476e-05,6.191823194967583e-05,8.126052853185683e-05,6.878453132230788e-05,7.531262235715985e-05,8.446093852398917e-05,7.504258974222466e-05,6.757648952770978e-05,6.133964780019596e-05,5.506668094312772e-05,5.224017513683066e-05,5.583671372733079e-05,6.86371058691293e-05,6.547735392814502e-05,6.419409328373149e-05,5.9945403336314484e-05,6.499701703432947e-05,6.299536471487954e-05,6.134522845968604e-05,5.763079388998449e-05,5.6757307902444154e-05,5.8937665016856045e-05,
mae,0.18800406157970428,0.03811037912964821,0.026355642825365067,0.02362496592104435,0.022019051015377045,0.01833600364625454,0.020026633515954018,0.017519161105155945,0.01776331104338169,0.01948690228164196,0.019571280106902122,0.018128227442502975,0.018390757963061333,0.016318174079060555,0.016784638166427612,0.015702039003372192,0.015177495777606964,0.01520860567688942,0.014050393365323544,0.011811080388724804,0.01332110445946455,0.014398524537682533,0.012945405207574368,0.011685347184538841,0.012782351113855839,0.012823019176721573,0.011772570200264454,0.012533247470855713,0.010757711715996265,0.009919939562678337,0.01113936211913824,0.010572758503258228,0.009174405597150326,0.009552735835313797,0.009397368878126144,0.011071261949837208,0.009404717944562435,0.009004258550703526,0.009301634505391121,0.009607711806893349,0.009493310004472733,0.008896756917238235,0.008242893032729626,0.008152984082698822,0.007970598526299,0.008654034696519375,0.008665737695991993,0.007695863954722881,0.00753897475078702,0.00854870118200779,0.008781364187598228,0.008089249022305012,0.007178682833909988,0.007613670080900192,0.007027246989309788,0.006682442035526037,0.00834245327860117,0.008018155582249165,0.007839170284569263,0.007169531192630529,0.0065962281078100204,0.006743526551872492,0.0063424622640013695,0.00654196972027421,0.007656174711883068,0.007566468790173531,0.007219946011900902,0.007315462455153465,0.006981204263865948,0.007079204544425011,0.007011836860328913,0.00637600664049387,0.006820095703005791,0.007473193574696779,0.007484755013138056,0.006709154695272446,0.006437078583985567,0.0064448220655322075,0.005429813172668219,0.0060969628393650055,0.007144490256905556,0.006588929332792759,0.006713715847581625,0.007298267912119627,0.006911279633641243,0.006379015278071165,0.00621480168774724,0.005840649828314781,0.005477160215377808,0.005798673257231712,0.006535752210766077,0.006419810000807047,0.0062912749126553535,0.005955261178314686,0.0064086043275892735,0.006243974436074495,0.006172382738441229,0.005895555485039949,0.005893271416425705,0.00603852141648531,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 266755    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 266756    
=================================================================
Total params: 533,511
Trainable params: 533,511
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 512)               2560      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               262656    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 1539      
=================================================================
Total params: 266,755
Trainable params: 266,755
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 512)               2048      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 2052      
=================================================================
Total params: 266,756
Trainable params: 266,756
Non-trainable params: 0
_________________________________________________________________
