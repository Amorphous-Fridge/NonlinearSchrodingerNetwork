2021-06-26
loss,0.290005624294281,0.129413902759552,0.0589057058095932,0.04554165527224541,0.04158350080251694,0.05189737677574158,0.041400887072086334,0.03536137193441391,0.030749892815947533,0.025496400892734528,0.027065934613347054,0.03983399271965027,0.028720665723085403,0.029645077884197235,0.03152262791991234,0.02647273987531662,0.024435723200440407,0.021576177328824997,0.01935213804244995,0.018218446522951126,0.017545748502016068,0.01714756339788437,0.016735054552555084,0.016442500054836273,0.015984440222382545,0.015737732872366905,0.015602810308337212,0.01525265071541071,0.015162545256316662,0.015001650899648666,0.01485563162714243,0.014625655487179756,0.01433604583144188,0.014295072294771671,0.01402889285236597,0.014021230861544609,0.013843282125890255,0.013834971003234386,0.013580722734332085,0.01343437097966671,0.013369079679250717,0.013158785179257393,0.013062115758657455,0.01289348490536213,0.012913601472973824,0.01275462657213211,0.012718718498945236,0.012519045732915401,0.012504429556429386,0.012321863323450089,0.012306693941354752,0.012170021422207355,0.01296867523342371,0.014507975429296494,0.019744746387004852,0.021539587527513504,0.02147791162133217,0.019510801881551743,0.018334172666072845,0.017981937155127525,0.01769091747701168,0.020529258996248245,0.01971471682190895,0.018414674326777458,0.017540836706757545,0.01703876443207264,0.01653272472321987,0.01573379710316658,0.014524346217513084,0.012643461115658283,0.011452185921370983,0.010855894535779953,0.010678702965378761,0.010531886480748653,0.010362538509070873,0.0109699796885252,0.01582810841500759,0.018631132319569588,0.017331227660179138,0.016724275425076485,0.016303496435284615,0.014833119697868824,0.013825973495841026,0.013134929351508617,0.012583491392433643,0.012184832245111465,0.011651400476694107,0.01393713615834713,0.016623735427856445,0.01914607174694538,0.017795734107494354,0.016266873106360435,0.015227992087602615,0.014397833496332169,0.013584336265921593,0.01268568355590105,0.01213853806257248,0.013280918821692467,0.017174744978547096,0.01758231595158577,
mse,0.029954979196190834,0.0059256888926029205,0.001206922810524702,0.000741259369533509,0.0005902299308218062,0.0007977541536092758,0.0005117682158015668,0.0003766730660572648,0.0002808170684147626,0.0002000568201765418,0.00022729071497451514,0.0004642874700948596,0.0002419429802102968,0.00025382154854014516,0.00027836847584694624,0.00020036633941344917,0.00017095476505346596,0.00013299862621352077,0.00010911701974691823,9.857010445557535e-05,9.160346235148609e-05,8.606142364442348e-05,8.200635784305632e-05,7.971608283696696e-05,7.519413338741288e-05,7.392383849946782e-05,7.16103968443349e-05,6.986530206631869e-05,6.804718577768654e-05,6.55425465083681e-05,6.419861892936751e-05,6.206798570929095e-05,6.108319212216884e-05,5.998555207042955e-05,5.835796764586121e-05,5.88204238738399e-05,5.712930578738451e-05,5.61085544177331e-05,5.3700481657870114e-05,5.220111052040011e-05,5.192001481191255e-05,5.169782889424823e-05,5.02022412547376e-05,4.876281673205085e-05,4.862985952058807e-05,4.7772988182259724e-05,4.7449128032894805e-05,4.605875437846407e-05,4.541299131233245e-05,4.393681592773646e-05,4.424843791639432e-05,4.373590854811482e-05,5.207166395848617e-05,6.514938286272809e-05,0.00011290387192275375,0.00013005251821596175,0.00012839674309361726,0.00010692985961213708,9.883441089186817e-05,9.317354124505073e-05,8.967229223344475e-05,0.00011974709923379123,0.00010908281547017395,9.558958845445886e-05,8.7711050582584e-05,8.292832353617996e-05,7.878890028223395e-05,7.372118125203997e-05,6.482985918410122e-05,4.743892350234091e-05,3.82556754630059e-05,3.517610821290873e-05,3.369403930264525e-05,3.266772910137661e-05,3.1755036616232246e-05,3.760508479899727e-05,7.644987636012957e-05,9.946248610503972e-05,8.482289558742195e-05,7.787710637785494e-05,7.358786388067529e-05,6.423972808988765e-05,5.6157074141083285e-05,5.0664468290051445e-05,4.658081161323935e-05,4.38261340605095e-05,3.963760536862537e-05,6.015421968186274e-05,7.963712414493784e-05,9.940318705048412e-05,8.597956184530631e-05,7.364011253230274e-05,6.548110832227394e-05,5.983373921480961e-05,5.447016155812889e-05,4.774983608513139e-05,4.3603522499324754e-05,5.4862728575244546e-05,8.386226545553654e-05,8.641466411063448e-05,
mae,0.12601308524608612,0.05817073956131935,0.02556402049958706,0.0197336096316576,0.017793014645576477,0.021936142817139626,0.0179140642285347,0.014931092038750648,0.013089349493384361,0.010889895260334015,0.011387089267373085,0.017090901732444763,0.012170258909463882,0.01229611411690712,0.012798487208783627,0.010651430115103722,0.010064374655485153,0.009076653979718685,0.008179012686014175,0.007737289182841778,0.007499586790800095,0.00727199949324131,0.007120964583009481,0.00698538264259696,0.00679290434345603,0.006721312180161476,0.00666488241404295,0.00651878397911787,0.006565488409250975,0.006391255185008049,0.0063922046683728695,0.006285843905061483,0.006163541693240404,0.006087592802941799,0.006017277017235756,0.006002348847687244,0.00590819725766778,0.005909825675189495,0.00582826416939497,0.005744466558098793,0.005678313784301281,0.00562259741127491,0.0055868919007480145,0.005507338792085648,0.00550362654030323,0.005457190331071615,0.005464919842779636,0.0053413729183375835,0.005355801433324814,0.005230005364865065,0.005243506282567978,0.005234799813479185,0.005454308353364468,0.006070835515856743,0.008335568942129612,0.009124452248215675,0.00877505261451006,0.008100097998976707,0.00782387237995863,0.007685093674808741,0.007460342720150948,0.008780109696090221,0.008497626520693302,0.007703935727477074,0.007354772184044123,0.007164288312196732,0.007005749735981226,0.006686649285256863,0.0061586289666593075,0.005378748755902052,0.004861045628786087,0.004605909343808889,0.004522863309830427,0.004492591135203838,0.0043891845270991325,0.004688592627644539,0.006700317375361919,0.007932019419968128,0.007416891865432262,0.007264516782015562,0.0069976989179849625,0.006320692133158445,0.00579824997112155,0.0054659973829984665,0.00525197247043252,0.005131640005856752,0.0049489340744912624,0.005923635326325893,0.007069636136293411,0.008281993679702282,0.0078177684918046,0.007071660365909338,0.0067207408137619495,0.006278346758335829,0.005817947443574667,0.005422181449830532,0.005177678540349007,0.005654638633131981,0.007375671993941069,0.007557975128293037,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17731     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17732     
=================================================================
Total params: 35,463
Trainable params: 35,463
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 17,731
Trainable params: 17,731
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 17,732
Trainable params: 17,732
Non-trainable params: 0
_________________________________________________________________
