2021-06-26
loss,0.2778126001358032,0.0669679343700409,0.04053281247615814,0.03029581345617771,0.02713894098997116,0.023714356124401093,0.0232354998588562,0.02666306309401989,0.026395952329039574,0.02469012886285782,0.021501904353499413,0.02510518580675125,0.028146779164671898,0.023769713938236237,0.021534178406000137,0.019838161766529083,0.018816906958818436,0.018494945019483566,0.02150312252342701,0.028050720691680908,0.024358639493584633,0.02166568674147129,0.019870204851031303,0.0182841457426548,0.015733376145362854,0.015007298439741135,0.01891160197556019,0.021992260590195656,0.020823607221245766,0.020527619868516922,0.018738996237516403,0.017731212079524994,0.016963833943009377,0.016423849388957024,0.01672438718378544,0.020816853269934654,0.018376242369413376,0.0170455202460289,0.01583152264356613,0.013470573350787163,0.014370059594511986,0.021014513447880745,0.019017213955521584,0.017673494294285774,0.016723131760954857,0.01581728458404541,0.014989294111728668,0.01421833410859108,0.012045860290527344,0.011032449081540108,0.010978695936501026,0.010413318872451782,0.010253936052322388,0.010029541328549385,0.009902684949338436,0.009862170554697514,0.009926711209118366,0.009859317913651466,0.009825014509260654,0.009779426269233227,0.00965798832476139,0.011844540014863014,0.013119015842676163,0.016658514738082886,0.017190296202898026,0.016357000917196274,0.0151339340955019,0.014208849519491196,0.01369909755885601,0.013275695033371449,0.012993594631552696,0.012626856565475464,0.012480027973651886,0.015407818369567394,0.01846902072429657,0.01642545685172081,0.01521330326795578,0.017109012231230736,0.017041055485606194,0.015434546396136284,0.014363531023263931,0.013905026949942112,0.013374379836022854,0.013373651541769505,0.015382371842861176,0.015298385173082352,0.014355055056512356,0.013800711371004581,0.013319871388375759,0.012860387563705444,0.012504088692367077,0.012056783773005009,0.011681181378662586,0.012963819317519665,0.013243019580841064,0.014584584161639214,0.01402322854846716,0.013156893663108349,0.01281071174889803,0.012482408434152603,
mse,0.03257625177502632,0.0015996139263734221,0.0006215089233592153,0.0003084772324655205,0.00023101016995497048,0.00017795030726119876,0.00017033910262398422,0.00021991976245772094,0.00020279963791836053,0.00018253442249260843,0.0001428614923497662,0.0001954613981069997,0.0002214950363850221,0.0001630788465263322,0.00013488827971741557,0.00011779327905969694,0.00011104991426691413,0.00010807505168486387,0.0001393066777382046,0.00022506799723487347,0.00016894597501959652,0.0001350987295154482,0.00011732080020010471,0.00010017680324381217,8.164991595549509e-05,7.29031817172654e-05,0.00010878775356104597,0.0001381773763569072,0.00012623191287275404,0.00011815372272394598,0.00010013893916038796,9.16425051400438e-05,8.502962737111375e-05,8.064999565249309e-05,8.441619866061956e-05,0.00012066496856277809,9.740187670104206e-05,8.378774509765208e-05,7.385674689430743e-05,5.904460704186931e-05,6.640048377448693e-05,0.00012489256914705038,0.00010281431605108082,9.103718912228942e-05,8.225710917031392e-05,7.373126572929323e-05,6.62522652419284e-05,6.0327889514155686e-05,4.7346766223199666e-05,4.014051955891773e-05,3.754425415536389e-05,3.261113670305349e-05,3.168928378727287e-05,3.057405410800129e-05,3.0662336939712986e-05,3.051062776648905e-05,3.0156808861647733e-05,3.01731051877141e-05,2.921557825175114e-05,2.9196764444350265e-05,2.894915633078199e-05,4.552201062324457e-05,5.661918839905411e-05,7.919994095573202e-05,8.286789670819417e-05,7.366772479144856e-05,6.388912152033299e-05,5.707157833967358e-05,5.398562643676996e-05,5.069461258244701e-05,4.861169873038307e-05,4.651598646887578e-05,4.578371954266913e-05,7.259008270921186e-05,9.272842726204544e-05,7.566915155621246e-05,6.588837277377024e-05,8.552418876206502e-05,8.250983228208497e-05,6.896114064147696e-05,5.939626498729922e-05,5.608363062492572e-05,5.304922888171859e-05,5.282483471091837e-05,6.825943273724988e-05,6.563486385857686e-05,5.7899178500520065e-05,5.4703275964129716e-05,5.085457087261602e-05,4.7583725972799584e-05,4.552171958494e-05,4.208026439300738e-05,4.0633243770571426e-05,4.992170215700753e-05,5.237134246272035e-05,6.021500666975044e-05,5.6120697990991175e-05,5.026054714107886e-05,4.741736120195128e-05,4.484914097702131e-05,
mae,0.12169847637414932,0.029673799872398376,0.017731783911585808,0.012964067049324512,0.011590485461056232,0.010188944637775421,0.00988803431391716,0.011264053173363209,0.011137123219668865,0.010502977296710014,0.009193255566060543,0.010824174620211124,0.01213887333869934,0.010344244539737701,0.009445123374462128,0.008587521500885487,0.008140522055327892,0.007954221218824387,0.009235070087015629,0.012231794185936451,0.010721737518906593,0.009495710954070091,0.008611506782472134,0.0077086263336241245,0.006796739064157009,0.006419111508876085,0.008130084723234177,0.009483334608376026,0.008977913297712803,0.008970910683274269,0.008191414177417755,0.007779193576425314,0.007458786480128765,0.00721766659989953,0.007256601937115192,0.009096474386751652,0.008192058652639389,0.007425312884151936,0.006720292381942272,0.005671012215316296,0.0061057195998728275,0.008809929713606834,0.008077630773186684,0.00745526235550642,0.007028892636299133,0.006742121186107397,0.006441987585276365,0.006106270011514425,0.005160492844879627,0.00469794450327754,0.004661702085286379,0.0044018286280334,0.004415255971252918,0.004286864772439003,0.0042480770498514175,0.004187651909887791,0.004219922237098217,0.00420032162219286,0.00423533795401454,0.004176297225058079,0.004153683315962553,0.005060100927948952,0.005524039268493652,0.007042996119707823,0.007408182602375746,0.007076229900121689,0.006553783547133207,0.0062283058650791645,0.006022158078849316,0.005810822360217571,0.005645865574479103,0.0054283468052744865,0.005349451210349798,0.006548918318003416,0.00798268523067236,0.006998030468821526,0.006518697366118431,0.007370734587311745,0.007260223850607872,0.006490541622042656,0.005969780497252941,0.0057779341004788876,0.005665992386639118,0.005712756421416998,0.006429669447243214,0.006595326121896505,0.006293762940913439,0.005989206023514271,0.00575725082308054,0.005552852060645819,0.0054188878275454044,0.005147950723767281,0.004913726821541786,0.00553453853353858,0.0056753940880298615,0.006150737404823303,0.0057222964242100716,0.005381652154028416,0.005478763487190008,0.005392697639763355,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 10323     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 10324     
=================================================================
Total params: 20,647
Trainable params: 20,647
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 1539      
=================================================================
Total params: 10,323
Trainable params: 10,323
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 512)               2048      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 10,324
Trainable params: 10,324
Non-trainable params: 0
_________________________________________________________________
