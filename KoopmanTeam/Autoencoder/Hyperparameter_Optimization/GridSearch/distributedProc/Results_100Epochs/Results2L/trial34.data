2021-06-26
loss,0.33863112330436707,0.20010271668434143,0.09365461021661758,0.060400355607271194,0.05394751951098442,0.04655419662594795,0.03698067367076874,0.0490775965154171,0.03231481462717056,0.028968434780836105,0.027496587485074997,0.027184806764125824,0.037203505635261536,0.03785063698887825,0.03984123095870018,0.03990383446216583,0.036114390939474106,0.033396512269973755,0.030765952542424202,0.02806737646460533,0.03386416286230087,0.03380807861685753,0.02834598533809185,0.02980322204530239,0.02575557492673397,0.03136906027793884,0.03064575605094433,0.028232617303729057,0.026541011407971382,0.024434003978967667,0.02250351756811142,0.021064110100269318,0.01978292502462864,0.01881687343120575,0.025085583329200745,0.024174895137548447,0.02233332395553589,0.02102264016866684,0.019514912739396095,0.025137387216091156,0.02724301628768444,0.024382269009947777,0.022890258580446243,0.021609945222735405,0.02076745219528675,0.019994234666228294,0.0193175021559,0.01853221468627453,0.022619349882006645,0.020880913361907005,0.0192588921636343,0.017982257530093193,0.016966480761766434,0.01658277027308941,0.013522463850677013,0.013919946737587452,0.015243807807564735,0.02220652997493744,0.020438693463802338,0.018821997568011284,0.01791778765618801,0.017002448439598083,0.01565057784318924,0.015161653980612755,0.017128221690654755,0.0196270439773798,0.018781663849949837,0.01717015542089939,0.016124285757541656,0.016469597816467285,0.017476804554462433,0.016573956236243248,0.015580989420413971,0.014928560703992844,0.01560545340180397,0.0164736807346344,0.01816372759640217,0.018769605085253716,0.017341632395982742,0.01635003834962845,0.015527511015534401,0.014879835769534111,0.014234243892133236,0.012883889488875866,0.0121273472905159,0.014715373516082764,0.0181669183075428,0.016535842791199684,0.015487391501665115,0.014816713519394398,0.014284058474004269,0.013746652752161026,0.013841276988387108,0.013630624860525131,0.013119262643158436,0.012315242551267147,0.013661223463714123,0.01417562272399664,0.015441098250448704,0.014362432062625885,
mse,0.04198294132947922,0.014943087473511696,0.003076881868764758,0.00122649606782943,0.000952092173974961,0.0006928950315341353,0.0004737828276120126,0.0007423937204293907,0.0003387451870366931,0.00026699958834797144,0.0002408064901828766,0.0002362986997468397,0.0004163222329225391,0.0004131507012061775,0.00046659301733598113,0.00044354196870699525,0.00036774639738723636,0.00031629562727175653,0.00027092889649793506,0.00022757005353923887,0.000334421667503193,0.00033321339287795126,0.0002361248480156064,0.0002486664743628353,0.00018916722910944372,0.00028055792790837586,0.0002610158990137279,0.00022657925728708506,0.00020062242401763797,0.00017183790623676032,0.00014758754696231335,0.00013013907300774008,0.00011809882562374696,0.00010947356349788606,0.00018275080947205424,0.00016537623014301062,0.00014367702533490956,0.00012581121700350195,0.00010982735693687573,0.00018860746058635414,0.00020617870904970914,0.00016851634427439421,0.00014986035239417106,0.0001346586795989424,0.00012454648094717413,0.00011608477507252246,0.00010860917245736346,0.00010227944585494697,0.00014790765999350697,0.00012252187298145145,0.00010582266986602917,9.432187653146684e-05,8.637854625703767e-05,8.302380592795089e-05,5.833194882143289e-05,6.124567880760878e-05,7.085628021741286e-05,0.00013939026393927634,0.00011702646588673815,0.00010245935845887288,9.533883712720126e-05,8.426330896327272e-05,7.469535194104537e-05,7.054945308482274e-05,8.564801828470081e-05,0.0001097333588404581,9.762479749042541e-05,8.36452963994816e-05,7.541915692854673e-05,8.053558121901006e-05,8.610413351561874e-05,7.734566315775737e-05,7.011588604655117e-05,6.548289093188941e-05,7.308849308174103e-05,7.906184328021482e-05,9.363364370074123e-05,9.827672329265624e-05,8.622297900728881e-05,7.741940498817712e-05,7.083653326844797e-05,6.486754136858508e-05,5.925551522523165e-05,5.2269188017817214e-05,4.675613672588952e-05,6.510358798550442e-05,9.36632786761038e-05,7.590649329358712e-05,6.815457891207188e-05,6.303547706920654e-05,5.9395217249402776e-05,5.47357922187075e-05,5.528829206014052e-05,5.583099482464604e-05,5.171854354557581e-05,4.641598934540525e-05,5.4599800932919607e-05,5.939965194556862e-05,6.703158578602597e-05,5.991528814774938e-05,
mae,0.14111588895320892,0.08699046820402145,0.04105009138584137,0.025787489488720894,0.023015787824988365,0.01972806081175804,0.015724623575806618,0.02090003900229931,0.013774311169981956,0.012393786571919918,0.011655761860311031,0.011595640331506729,0.015893004834651947,0.016085080802440643,0.016913780942559242,0.017350833863019943,0.01572512462735176,0.014625545591115952,0.01380514819175005,0.012293879874050617,0.014645388349890709,0.014499506913125515,0.011937391012907028,0.012617633678019047,0.01077278982847929,0.013477634638547897,0.013179966248571873,0.012255665846168995,0.01157504040747881,0.010282766073942184,0.009409583173692226,0.009092878550291061,0.008783685974776745,0.00813690759241581,0.010643483139574528,0.010446024127304554,0.009689983911812305,0.009071552194654942,0.008160600438714027,0.01053125225007534,0.011126539669930935,0.010145967826247215,0.00970232579857111,0.009199547581374645,0.008896008133888245,0.008665070869028568,0.008470077067613602,0.008112587966024876,0.009705069474875927,0.008923751302063465,0.00828874483704567,0.007619693875312805,0.007087492384016514,0.007029291242361069,0.005809929221868515,0.005948783829808235,0.006513508502393961,0.00935417041182518,0.008493615314364433,0.007673956919461489,0.007383167743682861,0.007111187558621168,0.0065574184991419315,0.006404082756489515,0.007272912189364433,0.00844766478985548,0.007934711873531342,0.007285409141331911,0.006554599851369858,0.006951183080673218,0.007356420625001192,0.006917985621839762,0.006722363643348217,0.006493268068879843,0.006696115713566542,0.006924738176167011,0.007762169931083918,0.00807350967079401,0.007440652698278427,0.006845214869827032,0.006550827994942665,0.006372982636094093,0.00602605938911438,0.005408525466918945,0.0051311589777469635,0.006218378432095051,0.007544232066720724,0.006894764956086874,0.0065648602321743965,0.006384579464793205,0.00616437615826726,0.005916240159422159,0.0059496015310287476,0.005719030275940895,0.005570860579609871,0.005197713151574135,0.005779579747468233,0.006055307574570179,0.006560744252055883,0.005869008135050535,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17923     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17924     
=================================================================
Total params: 35,847
Trainable params: 35,847
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 17,923
Trainable params: 17,923
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 17,924
Trainable params: 17,924
Non-trainable params: 0
_________________________________________________________________
