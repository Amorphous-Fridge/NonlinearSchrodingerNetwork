2021-06-26
loss,0.3324158191680908,0.1376763880252838,0.09033311903476715,0.05176151916384697,0.04819009453058243,0.042553797364234924,0.03322230279445648,0.035963669419288635,0.03644656762480736,0.03119250386953354,0.039202235639095306,0.0351034477353096,0.027103237807750702,0.02482035383582115,0.032674506306648254,0.03242485597729683,0.03029579669237137,0.03165728226304054,0.027976589277386665,0.02953483909368515,0.029032375663518906,0.027619805186986923,0.027360709384083748,0.02410593256354332,0.020578613504767418,0.022676078602671623,0.023734822869300842,0.02515832707285881,0.026663346216082573,0.025916598737239838,0.02378789149224758,0.02073192410171032,0.023394489660859108,0.022794749587774277,0.02144532836973667,0.0206013061106205,0.02181342802941799,0.021914876997470856,0.021855149418115616,0.021796049550175667,0.02118191495537758,0.020782161504030228,0.01987793855369091,0.020724918693304062,0.02092677541077137,0.018164778128266335,0.016089657321572304,0.01582310162484646,0.016552194952964783,0.018269842490553856,0.018941905349493027,0.017915260046720505,0.019553987309336662,0.018274279311299324,0.019976215437054634,0.019046509638428688,0.016651181504130363,0.014635557308793068,0.018679361790418625,0.01896798238158226,0.017448214814066887,0.01751725748181343,0.01662581041455269,0.017405575141310692,0.015403679572045803,0.013862439431250095,0.014362592250108719,0.017962278798222542,0.01695978082716465,0.015777546912431717,0.014870945364236832,0.016636142507195473,0.018184851855039597,0.017627619206905365,0.016049576923251152,0.014998551458120346,0.013469205237925053,0.013423741795122623,0.016606492921710014,0.015266691334545612,0.015217586420476437,0.015023954212665558,0.013704568147659302,0.014676354825496674,0.016331052407622337,0.015960190445184708,0.015855366364121437,0.014812112785875797,0.013436342589557171,0.013399091549217701,0.014269429259002209,0.013712756335735321,0.013739202171564102,0.013484609313309193,0.0155065031722188,0.015235375612974167,0.014974922873079777,0.01439616922289133,0.014309913851320744,0.014110039919614792,
mse,0.043707944452762604,0.006318316329270601,0.0024654080625623465,0.0008039203239604831,0.0006703712861053646,0.0005263449857011437,0.00033553317189216614,0.00037937439628876746,0.0003837362164631486,0.00029184806044213474,0.000439903000369668,0.0003652531886473298,0.00022705276205670089,0.0001907188125187531,0.000309234659653157,0.00030604933272115886,0.00026509459712542593,0.00028226387803442776,0.0002266311494167894,0.000252777332207188,0.00023942608095239848,0.00022449358948506415,0.00021128600928932428,0.00017121367272920907,0.00012908887583762407,0.00015845091547816992,0.0001665476302150637,0.00019053477444685996,0.00020072638290002942,0.0001884327211882919,0.00016453623538836837,0.00013236154336482286,0.00015588951646350324,0.00015010946663096547,0.00013520376523956656,0.00012805667938664556,0.0001375054125674069,0.00013931645662523806,0.00013900070916861296,0.00013245268200989813,0.0001296130067203194,0.00012612261343747377,0.00011388359416741878,0.00012457773846108466,0.00012239140050951391,9.790168405743316e-05,8.122435974655673e-05,7.927820115583017e-05,8.340213389601558e-05,9.888245403999463e-05,0.00010482738434802741,9.626431710785255e-05,0.00011009282752638683,9.911221422953531e-05,0.00011824131797766313,0.00010235763329546899,8.377450285479426e-05,6.747722363797948e-05,0.00010092566662933677,0.00010223946446785703,8.742089266888797e-05,8.713115676073357e-05,8.103543950710446e-05,8.620032895123586e-05,7.168203592300415e-05,6.151403795229271e-05,6.366188608808443e-05,9.087929356610402e-05,8.381726365769282e-05,7.197778904810548e-05,6.759012467227876e-05,8.106395398499444e-05,9.370718180434778e-05,8.797738701105118e-05,7.408898090943694e-05,6.605294765904546e-05,5.664913624059409e-05,5.634666376863606e-05,7.652353815501556e-05,6.681684317300096e-05,6.914891127962619e-05,6.605759699596092e-05,5.609610161627643e-05,6.206622492754832e-05,7.606198778375983e-05,7.218043901957572e-05,7.147826545406133e-05,6.21714279986918e-05,5.451322067528963e-05,5.338926348485984e-05,6.1022779846098274e-05,5.493868957273662e-05,5.5732707551214844e-05,5.3393658163258806e-05,6.814458902226761e-05,6.601576023967937e-05,6.394024967448786e-05,5.965438685961999e-05,5.8695502957561985e-05,5.5912161769811064e-05,
mae,0.14359015226364136,0.059526458382606506,0.038309495896101,0.02211841382086277,0.020562265068292618,0.01795089989900589,0.014066371135413647,0.015295462682843208,0.01546386443078518,0.013330619782209396,0.016456617042422295,0.014727598056197166,0.011476462706923485,0.01056936476379633,0.013941037468612194,0.013944024220108986,0.012841220945119858,0.01343519426882267,0.011884510517120361,0.012492283247411251,0.01244615763425827,0.011728989891707897,0.011560703627765179,0.010165607556700706,0.008679705671966076,0.009671756997704506,0.010081899352371693,0.010732891969382763,0.011338688433170319,0.010943148285150528,0.010352241806685925,0.008948033675551414,0.009954964742064476,0.009630071930587292,0.009079018607735634,0.008789561688899994,0.009212812408804893,0.009257707744836807,0.009244173765182495,0.009321838617324829,0.00902540236711502,0.008828799240291119,0.008416741155087948,0.008831608109176159,0.008891260251402855,0.007669555488973856,0.006848478689789772,0.006792102474719286,0.006948279682546854,0.007899454794824123,0.008139975368976593,0.007658203132450581,0.00837333220988512,0.007852942682802677,0.0084621487185359,0.00801006518304348,0.007038329262286425,0.006179117597639561,0.007955226115882397,0.008030502125620842,0.007436011917889118,0.007484236732125282,0.007145396433770657,0.007256980985403061,0.006480605807155371,0.005926868878304958,0.006110729184001684,0.007597350049763918,0.007117429748177528,0.006603440269827843,0.00633500050753355,0.007064263802021742,0.007664026226848364,0.007485042791813612,0.0067871566861867905,0.006351187359541655,0.00570856686681509,0.005634508095681667,0.007131582126021385,0.0064717852510511875,0.006473865360021591,0.0062930164858698845,0.005829596891999245,0.006303655914962292,0.006858444772660732,0.006714311894029379,0.006724879145622253,0.006298203021287918,0.005749204661697149,0.005705907475203276,0.005987210664898157,0.005755156744271517,0.005858640186488628,0.005753702484071255,0.0065467869862914085,0.006497904658317566,0.006345320958644152,0.006022065412253141,0.006025529466569424,0.005948945414274931,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 70915     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 70916     
=================================================================
Total params: 141,831
Trainable params: 141,831
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 1024)              5120      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                65600     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 70,915
Trainable params: 70,915
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 1024)              66560     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 4100      
=================================================================
Total params: 70,916
Trainable params: 70,916
Non-trainable params: 0
_________________________________________________________________
