2021-06-26
loss,0.29827892780303955,0.09674951434135437,0.06926531344652176,0.05542783811688423,0.046524710953235626,0.04585675150156021,0.056502364575862885,0.0426609180867672,0.03651373088359833,0.03272349014878273,0.0369168259203434,0.03190264105796814,0.02971424162387848,0.0286098700016737,0.03390206769108772,0.027647946029901505,0.023985907435417175,0.026697468012571335,0.029330715537071228,0.02981032058596611,0.031069545075297356,0.02675013244152069,0.024629950523376465,0.022765889763832092,0.022423597052693367,0.029339583590626717,0.025059251114726067,0.023466842249035835,0.02697869762778282,0.025490395724773407,0.025438085198402405,0.022580521181225777,0.021891701966524124,0.022981833666563034,0.019538067281246185,0.018845563754439354,0.020848385989665985,0.020191557705402374,0.02169743925333023,0.021794073283672333,0.020495302975177765,0.020587392151355743,0.02380477823317051,0.021858928725123405,0.02070857584476471,0.019024191424250603,0.018073705956339836,0.018333911895751953,0.020930921658873558,0.020048994570970535,0.018345974385738373,0.017752820625901222,0.017919475212693214,0.019804419949650764,0.02102653682231903,0.01886953040957451,0.015240591950714588,0.016065232455730438,0.016918707638978958,0.017296696081757545,0.017925428226590157,0.01879492774605751,0.017654472962021828,0.01729017309844494,0.01678171195089817,0.016839392483234406,0.016349656507372856,0.016863718628883362,0.01678880862891674,0.01642274111509323,0.016708312556147575,0.016681257635354996,0.016860103234648705,0.016900643706321716,0.015201522968709469,0.01505881268531084,0.015061154030263424,0.01420640479773283,0.014116409234702587,0.016972007229924202,0.016619309782981873,0.015357359312474728,0.013435913249850273,0.014683842658996582,0.016586119309067726,0.015322422608733177,0.014615789987146854,0.013197679072618484,0.012839067727327347,0.013220996595919132,0.014604395255446434,0.0160254817456007,0.01535347942262888,0.015661321580410004,0.01450244802981615,0.013884812593460083,0.013288544490933418,0.012737099081277847,0.012916186824440956,0.01464770920574665,
mse,0.03306381404399872,0.0030304354149848223,0.0014319159090518951,0.0009161133202724159,0.0006282356334850192,0.000646407890599221,0.0009651610744185746,0.000515675637871027,0.00038739031879231334,0.00031275791116058826,0.000391861773096025,0.00029080602689646184,0.00025955046294257045,0.00024580920580774546,0.0003221100487280637,0.00022470246767625213,0.00017421161464881152,0.00020794186275452375,0.00024438832770101726,0.0002534501254558563,0.00026578715187497437,0.00020226294873282313,0.0001741759479045868,0.00015352504851762205,0.00015483344031963497,0.00024245526583399624,0.00018047899357043207,0.00016123417299240828,0.0002060198166873306,0.00018395464576315135,0.00018212707072962075,0.00014663825277239084,0.00014017235662322491,0.00015709995932411402,0.00011792313307523727,0.00011033741611754522,0.00012908430653624237,0.00011801440268754959,0.00013770416262559593,0.0001351495156995952,0.00012743225670419633,0.00012763075937982649,0.00016120057262014598,0.00013273677905090153,0.00012628533295355737,0.00011175275722052902,9.980713366530836e-05,0.00010105787077918649,0.00012370872718747705,0.0001157990627689287,0.00010115118493558839,9.672836313256994e-05,9.381372365169227e-05,0.00011042852565879002,0.00012159600737504661,0.00010168046719627455,7.336058479268104e-05,7.983823161339387e-05,8.643438195576891e-05,8.926998998504132e-05,9.441337897442281e-05,9.845563909038901e-05,8.980394341051579e-05,8.691736729815602e-05,8.170482033165172e-05,8.08225740911439e-05,7.908682164270431e-05,8.028360753087327e-05,8.163555321516469e-05,7.9069119237829e-05,8.045397407840937e-05,7.962538074934855e-05,7.998141518328339e-05,8.038101805141196e-05,6.886693881824613e-05,6.846568430773914e-05,6.65222542011179e-05,5.990571662550792e-05,6.219580973265693e-05,8.017496293177828e-05,7.673705113120377e-05,6.956349534448236e-05,5.5574328143848106e-05,6.595910235773772e-05,7.642996206413954e-05,6.521976320073009e-05,6.107426452217624e-05,5.516604505828582e-05,5.1086997700622305e-05,5.210759263718501e-05,6.250604201341048e-05,7.111124432412907e-05,6.626851973123848e-05,6.90640663378872e-05,6.0273938288446516e-05,5.5479296861449257e-05,5.1433024054858834e-05,4.838462336920202e-05,5.020504249841906e-05,6.281506648520008e-05,
mae,0.11938714981079102,0.04019134119153023,0.02955564111471176,0.023748857900500298,0.01929377391934395,0.019813382998108864,0.024066612124443054,0.01813548617064953,0.015511632896959782,0.014008629135787487,0.015827974304556847,0.013554942794144154,0.012625816278159618,0.012172698974609375,0.014466483145952225,0.011751184239983559,0.010150372050702572,0.011338961310684681,0.012362396344542503,0.012705688364803791,0.013172218576073647,0.011543544940650463,0.010477590374648571,0.00962247047573328,0.009602854028344154,0.01246714498847723,0.010748123750090599,0.010038466192781925,0.011521066538989544,0.010874086990952492,0.010645832866430283,0.00960247591137886,0.009209904819726944,0.009706669487059116,0.00814850628376007,0.008029242046177387,0.008913337253034115,0.008605320937931538,0.009119516238570213,0.00884696003049612,0.008488102816045284,0.008791167289018631,0.010095592588186264,0.009289480745792389,0.008800391107797623,0.0080063221976161,0.007618403062224388,0.007864573039114475,0.008862285874783993,0.008538829162716866,0.007788289804011583,0.007654015906155109,0.007615288719534874,0.008365473710000515,0.008798516355454922,0.007849530316889286,0.006385918240994215,0.0068082381039857864,0.007170232944190502,0.007340154144912958,0.007565254345536232,0.007993591949343681,0.007629483472555876,0.007335886359214783,0.007098026107996702,0.007122482173144817,0.006850194185972214,0.007067208178341389,0.007126204203814268,0.006982271559536457,0.007161244284361601,0.006952943746000528,0.007014701142907143,0.0071794334799051285,0.0064029754139482975,0.006392532493919134,0.006404352840036154,0.006084080785512924,0.006028944626450539,0.007072621490806341,0.006929333321750164,0.006516761612147093,0.005772835575044155,0.0063012647442519665,0.007061204873025417,0.006358696613460779,0.006204182282090187,0.005542784929275513,0.005369278602302074,0.005688258446753025,0.006140689365565777,0.006774033885449171,0.006469598039984703,0.006514208856970072,0.006009180098772049,0.005814605392515659,0.005582326557487249,0.005410483106970787,0.005491286516189575,0.006179647520184517,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 68227     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 68228     
=================================================================
Total params: 136,455
Trainable params: 136,455
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 1539      
=================================================================
Total params: 68,227
Trainable params: 68,227
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 512)               2048      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 68,228
Trainable params: 68,228
Non-trainable params: 0
_________________________________________________________________
