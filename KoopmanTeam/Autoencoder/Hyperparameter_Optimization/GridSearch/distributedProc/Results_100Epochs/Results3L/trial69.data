2021-06-26
loss,0.3615296185016632,0.14417578279972076,0.07708217203617096,0.06193254888057709,0.0626460611820221,0.05892082676291466,0.0520702563226223,0.049268003553152084,0.02869422361254692,0.027210820466279984,0.02610650286078453,0.02480355277657509,0.03316739946603775,0.03239060565829277,0.034951578825712204,0.03664105013012886,0.02938203327357769,0.03305632248520851,0.026774022728204727,0.028724417090415955,0.02501017414033413,0.023960411548614502,0.0307595357298851,0.031066684052348137,0.03046315908432007,0.027043089270591736,0.024767212569713593,0.023171082139015198,0.02653273567557335,0.029700327664613724,0.024818098172545433,0.0242924802005291,0.01995784230530262,0.019140059128403664,0.021205253899097443,0.023308299481868744,0.0205299761146307,0.024211889132857323,0.020691651850938797,0.02076212875545025,0.02354475110769272,0.02373082935810089,0.02105529047548771,0.022743575274944305,0.021912667900323868,0.020193474367260933,0.017849678173661232,0.0224088616669178,0.02171165682375431,0.020846180617809296,0.019762249663472176,0.017307482659816742,0.01836312562227249,0.020535431802272797,0.018606720492243767,0.01992141827940941,0.01821771077811718,0.01939142495393753,0.017863672226667404,0.016719385981559753,0.015881255269050598,0.014531408436596394,0.018833033740520477,0.019162163138389587,0.017647234722971916,0.01839740201830864,0.018704088404774666,0.016980046406388283,0.015495219267904758,0.014785448089241982,0.01588226668536663,0.016823660582304,0.018215827643871307,0.01833713985979557,0.017116429284214973,0.015389995649456978,0.015883419662714005,0.01681382767856121,0.013704519718885422,0.012943871319293976,0.014517826028168201,0.013756093569099903,0.015091495588421822,0.016399485990405083,0.014899009838700294,0.013945650309324265,0.013542311266064644,0.015986116603016853,0.015918990597128868,0.014715058729052544,0.01448433194309473,0.014350934885442257,0.013993935659527779,0.014887078665196896,0.016056513413786888,0.015343431383371353,0.01328666228801012,0.013455964624881744,0.01481742225587368,0.01431968528777361,
mse,0.04932771623134613,0.007514281664043665,0.0017808906268328428,0.0011552730575203896,0.0012024600291624665,0.0010396888246759772,0.0007814535638317466,0.0007324357866309583,0.00024217175086960196,0.0002131398068740964,0.00019278308900538832,0.00017524788563605398,0.00033911288483068347,0.0003103298950009048,0.0003618178889155388,0.00039378265500999987,0.0002640272432472557,0.00031152344308793545,0.0002213718689745292,0.0002479717950336635,0.0001909917627926916,0.00017183534509968013,0.0002746802056208253,0.0002805910480674356,0.0002557334955781698,0.00020808094996027648,0.0001864032819867134,0.00016421210602857172,0.0002059717517113313,0.00025521471980027854,0.0001867320534074679,0.00017381312500219792,0.00012188091204734519,0.00011211865785298869,0.00013360175944399089,0.00015820162661839277,0.00012775184586644173,0.00016665470320731401,0.0001258730044355616,0.0001335589768132195,0.0001558370713610202,0.00016635291103739291,0.00013149617007002234,0.00014835814363323152,0.00013387725630309433,0.00011584701132960618,9.534895070828497e-05,0.00014688273950014263,0.00013760525325778872,0.00012595910811796784,0.00011498109233798459,9.160911577055231e-05,0.00010128793655894697,0.00011971972708124667,0.00010465711238794029,0.00011432326573412865,9.609714470570907e-05,0.0001088409626390785,9.255694021703675e-05,8.186338527593762e-05,7.328826177399606e-05,6.33381714578718e-05,0.00010536552144913003,0.00010627922893036157,9.249579306924716e-05,9.630763088352978e-05,9.920477896230295e-05,8.456957584712654e-05,7.229932816699147e-05,6.741548713762313e-05,7.598578667966649e-05,8.405696280533448e-05,9.363041317556053e-05,9.406300523551181e-05,8.445126150036231e-05,7.105727854650468e-05,7.410511170746759e-05,8.096194505924359e-05,5.748429975938052e-05,5.221709216129966e-05,6.438935815822333e-05,5.8267054555471987e-05,6.884237518534064e-05,7.590968016302213e-05,6.53529932606034e-05,5.7046228903345764e-05,5.4991898650769144e-05,7.492473378079012e-05,7.37624941393733e-05,6.55136609566398e-05,6.115551514085382e-05,6.149404362076893e-05,5.8748304581968114e-05,6.449523789342493e-05,7.298143464140594e-05,6.696820491924882e-05,5.233529009274207e-05,5.53520476387348e-05,6.4631829445716e-05,5.895378490095027e-05,
mae,0.15510834753513336,0.06115809455513954,0.032789893448352814,0.02644483372569084,0.02679724618792534,0.02560275048017502,0.02194800414144993,0.021113870665431023,0.01227122638374567,0.011639629490673542,0.011229531839489937,0.010647580958902836,0.013783980160951614,0.013658209703862667,0.014703000895678997,0.015575529076159,0.01253345888108015,0.013955078087747097,0.011518482118844986,0.012431733310222626,0.010582996532320976,0.010261395946145058,0.013048441149294376,0.013195632956922054,0.012781587429344654,0.011695843189954758,0.010536977089941502,0.009839390404522419,0.011279723607003689,0.012343499809503555,0.010548724792897701,0.010270599275827408,0.008487417362630367,0.008098598569631577,0.008864517323672771,0.00994039885699749,0.00870812963694334,0.010240946896374226,0.008769647218286991,0.008739101700484753,0.010047990828752518,0.010037366300821304,0.008972455747425556,0.009642206132411957,0.009278770536184311,0.008618131279945374,0.0075931670144200325,0.009544728323817253,0.009299536235630512,0.008916285820305347,0.008230852894484997,0.007323961704969406,0.007897339761257172,0.00862114131450653,0.007904681377112865,0.008446238934993744,0.00767712015658617,0.008264865726232529,0.007520658429712057,0.007195761427283287,0.006822630297392607,0.006180169992148876,0.007935436442494392,0.007937202230095863,0.00749281607568264,0.007794912904500961,0.008093361742794514,0.007275721523910761,0.006516681518405676,0.006261071190237999,0.00671972194686532,0.007183176930993795,0.007630016189068556,0.007746389135718346,0.007274417672306299,0.006499957293272018,0.006762340664863586,0.00707562081515789,0.005831819958984852,0.005455967970192432,0.006105509586632252,0.0058590625412762165,0.006440871395170689,0.006863736547529697,0.006087888963520527,0.005608122795820236,0.0056042904034256935,0.006847796496003866,0.006808056030422449,0.006304408423602581,0.006230456754565239,0.006129962392151356,0.005890827625989914,0.006319375708699226,0.006896925624459982,0.006512601859867573,0.005644134245812893,0.005731978453695774,0.006300137843936682,0.006073267664760351,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 33571     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 33572     
=================================================================
Total params: 67,143
Trainable params: 67,143
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 33,571
Trainable params: 33,571
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 33,572
Trainable params: 33,572
Non-trainable params: 0
_________________________________________________________________
