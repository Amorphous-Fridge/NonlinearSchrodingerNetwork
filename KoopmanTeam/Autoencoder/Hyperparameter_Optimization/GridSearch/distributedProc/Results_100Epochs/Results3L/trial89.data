2021-06-26
loss,0.8192148804664612,0.09599845111370087,0.07764673978090286,0.06105983257293701,0.05341589078307152,0.05479409173130989,0.04676124081015587,0.04545256122946739,0.0452808141708374,0.038582220673561096,0.0344863198697567,0.03921107202768326,0.036672890186309814,0.036496762186288834,0.03077486902475357,0.0318845771253109,0.034626130014657974,0.034492239356040955,0.0292793158441782,0.029113490134477615,0.02850039303302765,0.028613734990358353,0.02488577365875244,0.022412192076444626,0.021060654893517494,0.023373467847704887,0.024842984974384308,0.022997986525297165,0.02128271572291851,0.022432858124375343,0.023166827857494354,0.020439255982637405,0.021877365186810493,0.02279658056795597,0.02163117192685604,0.02086559683084488,0.018490007147192955,0.020563941448926926,0.019904883578419685,0.02065345272421837,0.018380088731646538,0.01985558308660984,0.019486451521515846,0.016252750530838966,0.018462911248207092,0.018250033259391785,0.017216280102729797,0.01992778107523918,0.021139543503522873,0.018941620364785194,0.017300762236118317,0.01842089183628559,0.01779302768409252,0.01597362942993641,0.018265219405293465,0.015733009204268456,0.018857832998037338,0.017233267426490784,0.015580282546579838,0.017563166096806526,0.018463820219039917,0.01741684228181839,0.01627563312649727,0.015409835614264011,0.015503673814237118,0.017174007371068,0.01713324338197708,0.016755659133195877,0.014189180918037891,0.016309233382344246,0.017663516104221344,0.016489477828145027,0.015106894075870514,0.016016684472560883,0.015253467485308647,0.01473790779709816,0.01555453147739172,0.01578689180314541,0.01696476899087429,0.015516476705670357,0.014882893301546574,0.014620458707213402,0.0145506476983428,0.015276785008609295,0.015523897483944893,0.013434120453894138,0.01361045241355896,0.013951539993286133,0.014291087165474892,0.014390907250344753,0.013930248096585274,0.01386219821870327,0.013441567309200764,0.01330812368541956,0.013876515440642834,0.014090781100094318,0.014397863298654556,0.012775400653481483,0.014133802615106106,0.013952471315860748,
mse,0.4847770631313324,0.0027456870302557945,0.0017956369556486607,0.0011271878611296415,0.0008380445651710033,0.0008868021541275084,0.0006580575718544424,0.0006174956215545535,0.0006106684450060129,0.00043476748396642506,0.00034879325539804995,0.00045370205771178007,0.0003953887789975852,0.0003817424294538796,0.0002760502102319151,0.00030552479438483715,0.0003412919177208096,0.00033762468956410885,0.00024203812063205987,0.00025029596872627735,0.00023711359244771302,0.00022777589038014412,0.00017742351337801665,0.00015045897453092039,0.0001335636043222621,0.00015855520905461162,0.00017747117090038955,0.00015733233885839581,0.00013320190191734582,0.00014777675096411258,0.0001527050626464188,0.0001213911164086312,0.0001354810519842431,0.00015007128240540624,0.00013562256935983896,0.00012483033060561866,0.00010492834553588182,0.0001246398314833641,0.0001150025418610312,0.00012123138731112704,0.00010071616270579398,0.00011341667413944378,0.00010809575906023383,8.060787513386458e-05,0.0001013056025840342,9.61969853960909e-05,9.044891339726746e-05,0.00011467142758192495,0.0001280402357224375,0.00010278950503561646,8.976362005341798e-05,9.85301667242311e-05,9.492086974205449e-05,7.84496296546422e-05,9.75912407739088e-05,7.582099351566285e-05,0.0001041585419443436,8.794388122623786e-05,7.5871343142353e-05,9.151716949418187e-05,9.964683704311028e-05,8.79760627867654e-05,7.844992796890438e-05,7.101961818989366e-05,7.296690455405042e-05,8.555554086342454e-05,8.456919022137299e-05,8.322038047481328e-05,6.222401862032712e-05,7.998491491889581e-05,9.139158646576107e-05,8.118009282043204e-05,6.642126390943304e-05,7.44770368328318e-05,7.068020931910723e-05,6.531900726258755e-05,7.162407564464957e-05,7.224657019833103e-05,8.247066580224782e-05,7.180104148574173e-05,6.537135050166398e-05,6.384795415215194e-05,6.220945215318352e-05,6.981988553889096e-05,7.144981645978987e-05,5.491832780535333e-05,5.582434459938668e-05,5.938539106864482e-05,6.197125185281038e-05,6.225394463399425e-05,6.037224011379294e-05,5.871166649740189e-05,5.5660941143287346e-05,5.320460695656948e-05,5.7629222283139825e-05,5.846197745995596e-05,6.089088856242597e-05,4.913883822155185e-05,5.90301351621747e-05,5.780403080279939e-05,
mae,0.35113075375556946,0.04109666869044304,0.033174458891153336,0.026230480521917343,0.022654050961136818,0.023202946409583092,0.01965305395424366,0.019423145800828934,0.01951943337917328,0.016314499080181122,0.014684939756989479,0.01666948013007641,0.015559632331132889,0.015451410785317421,0.013054749928414822,0.01362961158156395,0.01464479323476553,0.014539740048348904,0.012390006333589554,0.012278650887310505,0.012147697620093822,0.012050952762365341,0.0105257797986269,0.009450403042137623,0.008917846716940403,0.00995341781526804,0.010449031367897987,0.009679814800620079,0.009057609364390373,0.009529879316687584,0.009821634739637375,0.008625764399766922,0.009224829263985157,0.009598984383046627,0.009116820059716702,0.008861366659402847,0.0077455490827560425,0.008660673163831234,0.008472085930407047,0.008715574629604816,0.007798037026077509,0.008430556394159794,0.008347668685019016,0.006870084907859564,0.007802975829690695,0.007863396778702736,0.007399716414511204,0.008529079146683216,0.008975082077085972,0.007999306544661522,0.007462088484317064,0.007882138714194298,0.007486356422305107,0.006778904236853123,0.007725008297711611,0.006693667732179165,0.008063012734055519,0.007276249583810568,0.006559471599757671,0.007443152833729982,0.007774330209940672,0.0074892835691571236,0.006899910978972912,0.0065626297146081924,0.00650792196393013,0.007330716121941805,0.007151281926780939,0.007079027127474546,0.006027303170412779,0.0068215616047382355,0.007448235526680946,0.007023898418992758,0.006366301327943802,0.006700432393699884,0.006392510607838631,0.006190137937664986,0.006591568700969219,0.006707681342959404,0.007153745274990797,0.006515718065202236,0.0062065706588327885,0.006127554923295975,0.006191092077642679,0.006506423931568861,0.0065882508642971516,0.005760392174124718,0.00575573556125164,0.0059446729719638824,0.006026278715580702,0.006056199781596661,0.0059150587767362595,0.005929701495915651,0.005699847359210253,0.005616219248622656,0.0058746724389493465,0.006003355607390404,0.006154377479106188,0.005411852616816759,0.005941142328083515,0.0059255147352814674,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 198915    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 198916    
=================================================================
Total params: 397,831
Trainable params: 397,831
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 198,915
Trainable params: 198,915
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 198,916
Trainable params: 198,916
Non-trainable params: 0
_________________________________________________________________
