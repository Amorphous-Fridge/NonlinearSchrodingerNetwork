2021-06-26
loss,0.3294621407985687,0.22246921062469482,0.15661804378032684,0.07759532332420349,0.053982462733983994,0.04485370218753815,0.041037965565919876,0.03773830085992813,0.035087700933218,0.03346453979611397,0.03136228397488594,0.037217237055301666,0.039487723261117935,0.03560873121023178,0.03414398804306984,0.048215512186288834,0.04241211339831352,0.039178747683763504,0.03455072268843651,0.031124897301197052,0.02900967188179493,0.03294388949871063,0.04054323211312294,0.04076842963695526,0.034632254391908646,0.030857063829898834,0.037321608513593674,0.034458015114068985,0.03020516224205494,0.026960553601384163,0.024462999776005745,0.02249767631292343,0.02077295631170273,0.02012377791106701,0.024565301835536957,0.03167126327753067,0.03259623423218727,0.03432280570268631,0.032525114715099335,0.030633682385087013,0.02872782200574875,0.027096781879663467,0.025773871690034866,0.025019822642207146,0.023899216204881668,0.023378562182188034,0.02284223400056362,0.022235484793782234,0.0217586737126112,0.02137189544737339,0.020754065364599228,0.020232126116752625,0.025989923626184464,0.029848601669073105,0.031714532524347305,0.028934353962540627,0.02535654604434967,0.02355142869055271,0.022101009264588356,0.020688915625214577,0.019518814980983734,0.01992742531001568,0.026943689212203026,0.029218003153800964,0.02698778361082077,0.02564123645424843,0.0245540551841259,0.023690225556492805,0.021983124315738678,0.02089046500623226,0.020007014274597168,0.019185319542884827,0.01853984408080578,0.01804957538843155,0.01725691743195057,0.018044622614979744,0.016865674406290054,0.014975618571043015,0.014838279224932194,0.015028861351311207,0.025480374693870544,0.025526201352477074,0.023682696744799614,0.022548463195562363,0.021418767049908638,0.02051333338022232,0.0194983072578907,0.018787434324622154,0.017930051311850548,0.017008669674396515,0.013341730460524559,0.013024984858930111,0.01286209188401699,0.01256605889648199,0.012400494888424873,0.012164461426436901,0.012095017358660698,0.012060767039656639,0.011858038604259491,0.012034283019602299,
mse,0.03962762653827667,0.017885299399495125,0.008860663510859013,0.0019706638995558023,0.0009410908096469939,0.0006483971956185997,0.0005257069715298712,0.0004345733323134482,0.000371664238628,0.0003354171640239656,0.00029439496574923396,0.0004321637097746134,0.000452811480499804,0.0003675299813039601,0.0003430711221881211,0.0006754400092177093,0.0005325555102899671,0.0004333788820076734,0.0003459544386714697,0.0002781804942060262,0.00024710450088605285,0.00034006513305939734,0.0004966967389918864,0.0004680506244767457,0.0003492141840979457,0.0002864734560716897,0.00039188668597489595,0.000330631883116439,0.00026221590815111995,0.00021409746841527522,0.00018202015780843794,0.00016252505884040147,0.00014312165149021894,0.00012839185365010053,0.0001831569679779932,0.000288185547105968,0.0003118493768852204,0.00032808759715408087,0.00029312586411833763,0.00026140845147892833,0.00022938434267416596,0.0002065058215521276,0.00018702857778407633,0.00017650971130933613,0.0001621928677195683,0.00015746311692055315,0.00014890199236106128,0.00014109248877502978,0.00013528922863770276,0.00013157573994249105,0.0001233592483913526,0.00011591430666157976,0.00020432840392459184,0.0002506544697098434,0.0002759759081527591,0.000232544174650684,0.0001817219308577478,0.00015898878336884081,0.0001416396553395316,0.0001223119325004518,0.00010955706238746643,0.00011750774137908593,0.00021727637795265764,0.00023710489040240645,0.00020257309370208532,0.00018448861374054104,0.0001697099069133401,0.00015777470252942294,0.000137667782837525,0.00012415011588018388,0.00011386895494069904,0.00010569432924967259,9.884928294923156e-05,9.37277072807774e-05,8.517776586813852e-05,9.855152165982872e-05,8.710215479368344e-05,6.93524198140949e-05,6.496990681625903e-05,6.971732364036143e-05,0.00018174853175878525,0.00017717521404847503,0.00015598042227793485,0.00014194325194694102,0.00012941978638991714,0.00012041986337862909,0.00010928144911304116,0.00010148626461159438,9.246772242477164e-05,8.765620441408828e-05,5.299365147948265e-05,4.9917893193196505e-05,4.769324732478708e-05,4.591265678755008e-05,4.458420517039485e-05,4.2900603148154914e-05,4.212097337585874e-05,4.184416320640594e-05,4.092805465916172e-05,4.152360270381905e-05,
mae,0.14079852402210236,0.09699716418981552,0.06590889394283295,0.033054620027542114,0.022964980453252792,0.019094213843345642,0.017513127997517586,0.01594911888241768,0.014996453188359737,0.014259143732488155,0.013278871774673462,0.015876848250627518,0.016685903072357178,0.015160804614424706,0.014421671628952026,0.020923016592860222,0.018313642591238022,0.0169234462082386,0.014848633669316769,0.013268607668578625,0.012251069769263268,0.014144944958388805,0.01798027940094471,0.018167272210121155,0.0148904575034976,0.01334676705300808,0.01637466996908188,0.015038801357150078,0.01242738589644432,0.011205852963030338,0.010153049603104591,0.009716818109154701,0.009050426073372364,0.008761736564338207,0.010421072132885456,0.013606187887489796,0.01406760886311531,0.014828333631157875,0.014530752785503864,0.013302757404744625,0.012254866771399975,0.011463059112429619,0.010628977790474892,0.010025599040091038,0.00954165868461132,0.009385709650814533,0.009134091436862946,0.00892056617885828,0.008765597827732563,0.008636832237243652,0.00848224014043808,0.008502158336341381,0.011251062154769897,0.012886200100183487,0.014257468283176422,0.013192083686590195,0.011267784051597118,0.010301888920366764,0.009561261162161827,0.008945885114371777,0.00838499702513218,0.008422132581472397,0.011839993298053741,0.013071371242403984,0.012191086076200008,0.011549028567969799,0.010946858674287796,0.010249999351799488,0.009503401815891266,0.008999425917863846,0.00854366086423397,0.008145563304424286,0.007880721241235733,0.007685957010835409,0.00739583233371377,0.007751105353236198,0.007234115153551102,0.006383583415299654,0.00645808270201087,0.006495544221252203,0.011085085570812225,0.011689153499901295,0.010778000578284264,0.010069084353744984,0.009522871114313602,0.009094050154089928,0.00863413792103529,0.008328828029334545,0.007892369292676449,0.007326088380068541,0.005709549877792597,0.005604854319244623,0.0055419378913939,0.005430894438177347,0.0053568952716887,0.00528052169829607,0.005199615843594074,0.005232825409621,0.0050698937848210335,0.005252012517303228,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 12907     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 12908     
=================================================================
Total params: 25,815
Trainable params: 25,815
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 12,907
Trainable params: 12,907
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 12,908
Trainable params: 12,908
Non-trainable params: 0
_________________________________________________________________
