2021-06-26
loss,0.32648909091949463,0.11552367359399796,0.07716578245162964,0.06568750739097595,0.06294050812721252,0.06503663957118988,0.05679599195718765,0.06167963147163391,0.06319139152765274,0.05243907496333122,0.055084481835365295,0.03902031108736992,0.039820168167352676,0.04959053918719292,0.0462266243994236,0.040077801793813705,0.04139748215675354,0.03621066361665726,0.03696448355913162,0.03397563099861145,0.035681940615177155,0.033612534403800964,0.030750183388590813,0.02761674113571644,0.03336270526051521,0.030208248645067215,0.028473371639847755,0.029511667788028717,0.027709877118468285,0.02771889418363571,0.029598398134112358,0.026409385725855827,0.02535981498658657,0.023062925785779953,0.021964125335216522,0.020315460860729218,0.021995170041918755,0.02134489268064499,0.025544101372361183,0.02470628172159195,0.021629324182868004,0.021716328337788582,0.01888672076165676,0.023716839030385017,0.0186040997505188,0.02433622069656849,0.024214213714003563,0.022543666884303093,0.021684756502509117,0.023179931566119194,0.023578429594635963,0.022490430623292923,0.02097214199602604,0.019514314830303192,0.01988392323255539,0.019801080226898193,0.021466339007019997,0.019685102626681328,0.019139550626277924,0.021914543583989143,0.02136741578578949,0.01858609728515148,0.01549690030515194,0.013907987624406815,0.016276562586426735,0.02156204916536808,0.020843541249632835,0.02099204994738102,0.018634002655744553,0.01726013980805874,0.01702885888516903,0.015964696183800697,0.014991267584264278,0.015992863103747368,0.020105542615056038,0.019247643649578094,0.018368706107139587,0.01930014044046402,0.017765622586011887,0.01600191928446293,0.015080785378813744,0.0146183455362916,0.014989129267632961,0.015253654681146145,0.019468490034341812,0.017759356647729874,0.016601547598838806,0.014844912104308605,0.013761444017291069,0.012561982497572899,0.011897287331521511,0.016836948692798615,0.01630811020731926,0.018238049000501633,0.016727013513445854,0.015412219800055027,0.014104382134974003,0.012664052657783031,0.0121389739215374,0.013740924187004566,
mse,0.04062579944729805,0.004343107808381319,0.001816075760871172,0.0013189262244850397,0.0012256387853994966,0.001264729187823832,0.0009338895324617624,0.0010916455648839474,0.0011413092724978924,0.0007746824412606657,0.000848874100483954,0.0004487275436986238,0.0004678927653003484,0.0006862088339403272,0.0006082316976971924,0.0004533515020739287,0.00048010528553277254,0.0003732839541044086,0.00038811605190858245,0.00032929840381257236,0.00035977951483801007,0.0003189115086570382,0.00026370410341769457,0.00021696058684028685,0.0003176744212396443,0.000263284397078678,0.000230916659347713,0.00024241422943305224,0.00021926847693976015,0.0002200887684011832,0.0002431578905088827,0.00019705653539858758,0.00017807664698921144,0.00015007499314378947,0.00013778620632365346,0.00011994999658782035,0.00014237311552278697,0.0001321829331573099,0.00018334327614866197,0.00017010382725857198,0.00013855913130100816,0.0001387106312904507,0.00010855217260541394,0.00015642704966012388,0.00010298038250766695,0.0001692508376436308,0.00016260734992101789,0.00014478169032372534,0.00013619674427900463,0.00015127644292078912,0.00015514880942646414,0.00014621231821365654,0.00012606427480932325,0.00010848370584426448,0.0001100194567698054,0.00011355936294421554,0.0001293458917643875,0.0001119850276154466,0.00010331341763958335,0.00013674763613380492,0.00012761508696712554,0.00010130314331036061,7.3473114753142e-05,5.99931190663483e-05,7.997981447260827e-05,0.00013267452595755458,0.00012001894356217235,0.00012300345406401902,9.672399028204381e-05,8.596738189226016e-05,8.534737571608275e-05,7.614835340064019e-05,6.707840657327324e-05,7.48896345612593e-05,0.00011172278027515858,0.00010582101822365075,9.590667468728498e-05,0.00010383912012912333,8.795934991212562e-05,7.362708856817335e-05,6.720868987031281e-05,6.300520908553153e-05,6.73659160383977e-05,6.932915857760236e-05,0.0001068245037458837,8.864195115165785e-05,7.798518345225602e-05,6.547979864990339e-05,5.58994579478167e-05,4.731098670163192e-05,4.279648419469595e-05,8.322727808263153e-05,7.606339931953698e-05,9.12793620955199e-05,7.748948701191694e-05,6.667141860816628e-05,5.7069406466325745e-05,4.835877552977763e-05,4.387184890219942e-05,5.62638851988595e-05,
mae,0.134130597114563,0.04891668260097504,0.03290177136659622,0.027997134253382683,0.026726584881544113,0.027954917401075363,0.024260861799120903,0.02632363885641098,0.02714105322957039,0.022593259811401367,0.02396533451974392,0.016438661143183708,0.017006777226924896,0.021148113533854485,0.019968032836914062,0.017079215496778488,0.017794335260987282,0.015467490069568157,0.015786735340952873,0.014560963958501816,0.015227374620735645,0.014319543726742268,0.013036995194852352,0.011574127711355686,0.01443006657063961,0.012658358551561832,0.011957000941038132,0.012461320497095585,0.011700715869665146,0.011716886423528194,0.012515192851424217,0.011297856457531452,0.010871278122067451,0.009553974494338036,0.009092905558645725,0.008548373356461525,0.009360050782561302,0.009122620336711407,0.010825000703334808,0.010221941396594048,0.009194348938763142,0.0092268455773592,0.007967187091708183,0.010083012282848358,0.007926639169454575,0.010214928537607193,0.010249308310449123,0.009745530784130096,0.009289877489209175,0.009725403040647507,0.010051476769149303,0.009562987834215164,0.008921279571950436,0.00828660186380148,0.008639046922326088,0.008461739867925644,0.009194786660373211,0.008294477127492428,0.008187159895896912,0.00933766458183527,0.009022113867104053,0.007856426760554314,0.006541019771248102,0.005884708371013403,0.006865197792649269,0.009192757308483124,0.00884226430207491,0.008740777149796486,0.007768865674734116,0.007184972055256367,0.007175663486123085,0.006780290976166725,0.006354652810841799,0.006759475916624069,0.008541476912796497,0.008114590309560299,0.007761955726891756,0.008143937215209007,0.007460762280970812,0.006804042030125856,0.0064070504158735275,0.006179424002766609,0.006407720036804676,0.0064564477652311325,0.008149181492626667,0.007483100518584251,0.007023113314062357,0.006122652441263199,0.0056974315084517,0.005306829232722521,0.0050440263003110886,0.007109963800758123,0.0068952059373259544,0.0077009620144963264,0.007206857204437256,0.006531428080052137,0.005845084320753813,0.005423166789114475,0.00514956284314394,0.005882569123059511,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25283     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25284     
=================================================================
Total params: 50,567
Trainable params: 50,567
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 25,283
Trainable params: 25,283
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 25,284
Trainable params: 25,284
Non-trainable params: 0
_________________________________________________________________
