2021-06-26
loss,0.28401845693588257,0.069875568151474,0.04204939678311348,0.03413587063550949,0.030839305371046066,0.027951231226325035,0.026301579549908638,0.025156036019325256,0.03094106912612915,0.03495136275887489,0.03214007988572121,0.03767568990588188,0.033153556287288666,0.028396889567375183,0.024987487122416496,0.03269007056951523,0.03126192465424538,0.030957259237766266,0.02912040799856186,0.029448026791214943,0.026989493519067764,0.028031324967741966,0.026386501267552376,0.02483549155294895,0.02469959296286106,0.026249364018440247,0.025233736261725426,0.02488097921013832,0.024253131821751595,0.02324903942644596,0.022595658898353577,0.02474052459001541,0.022596675902605057,0.02137593924999237,0.01992863230407238,0.01744680665433407,0.01848379522562027,0.0167336817830801,0.02038183994591236,0.021916229277849197,0.022249562665820122,0.020658662542700768,0.018479039892554283,0.017543284222483635,0.015989474952220917,0.021326148882508278,0.02016318030655384,0.020220773294568062,0.019464567303657532,0.01614714413881302,0.01872020773589611,0.018502462655305862,0.015055375173687935,0.016568046063184738,0.020470183342695236,0.020838871598243713,0.017738893628120422,0.016619013622403145,0.016880005598068237,0.01935363933444023,0.01934332773089409,0.018930410966277122,0.01715618185698986,0.01495279185473919,0.01687459461390972,0.016923503950238228,0.016326503828167915,0.015338385477662086,0.014444035477936268,0.018085533753037453,0.017754167318344116,0.016767039895057678,0.016929782927036285,0.01663147285580635,0.016457602381706238,0.01501800399273634,0.014619017019867897,0.017643984407186508,0.01627899333834648,0.01611996255815029,0.01542812678962946,0.015494818799197674,0.015591391362249851,0.014469733461737633,0.013555038720369339,0.013565641827881336,0.016215382143855095,0.016758732497692108,0.01566544733941555,0.014517354778945446,0.013345232233405113,0.01277894340455532,0.013969932682812214,0.013800658285617828,0.012054677121341228,0.014416854828596115,0.015054839663207531,0.012993509881198406,0.011661628261208534,0.011172597296535969,
mse,0.033162981271743774,0.001654500956647098,0.0005470087635330856,0.00034132596920244396,0.0002735787129495293,0.00022711166820954531,0.00020305068755988032,0.00018356257351115346,0.00029787232051603496,0.0003631802974268794,0.0003143783251289278,0.000407704443205148,0.00031550193671137094,0.00023647811030969024,0.00018753448966890574,0.00032554008066654205,0.00027840901748277247,0.00027749757282435894,0.000246468058321625,0.0002512908249627799,0.00021149672102183104,0.00022414635168388486,0.0001975633786059916,0.00018213276052847505,0.00018038401321973652,0.00019642067491076887,0.00018052988161798567,0.00017454173939768225,0.00017133863002527505,0.00015523482579737902,0.00014971141354180872,0.000169674982316792,0.00014391855802387,0.00012908487406093627,0.0001126965435105376,8.785957470536232e-05,0.00010481247591087595,8.558269473724067e-05,0.00012624110968317837,0.0001418044848833233,0.00014200851728674024,0.000123816731502302,0.00010361419117543846,9.40188838285394e-05,7.826067303540185e-05,0.000133832567371428,0.00011583408922888339,0.00011749130499083549,0.0001084281611838378,7.977166387718171e-05,0.00010217380622634664,9.902672172756866e-05,7.208644092315808e-05,8.4166087617632e-05,0.00011953073408221826,0.0001211143535329029,9.273985051549971e-05,8.223696931963786e-05,8.476103539578617e-05,0.00010595515050226822,0.00010377814032835886,0.00010219029354630038,8.489804167766124e-05,6.730145832989365e-05,8.484767749905586e-05,8.346430695382878e-05,7.893746806075796e-05,7.05255224602297e-05,6.502347241621464e-05,9.354373469250277e-05,9.01079984032549e-05,8.133197843562812e-05,8.139902638504282e-05,7.811852992745116e-05,7.819957681931555e-05,7.005068619037047e-05,6.402430881280452e-05,8.628485375083983e-05,7.663691212655976e-05,7.480275235138834e-05,6.859443965367973e-05,6.944077904336154e-05,6.930685776751488e-05,6.216635665623471e-05,5.6658649555174634e-05,5.608185529126786e-05,7.393598207272589e-05,8.172709203790873e-05,7.103050302248448e-05,6.119172758189961e-05,5.1357066695345566e-05,4.9353147915098816e-05,5.813823372591287e-05,5.673344639944844e-05,4.41298725490924e-05,6.0724189097527415e-05,6.446111365221441e-05,4.998060467187315e-05,4.1929044527933e-05,3.857339106616564e-05,
mae,0.12143130600452423,0.030028488487005234,0.017919817939400673,0.014511309564113617,0.01307943556457758,0.011839257553219795,0.011095089837908745,0.010675603523850441,0.012951215729117393,0.014874049462378025,0.013852786272764206,0.01620541140437126,0.013716339133679867,0.0118850814178586,0.010424410924315453,0.013900424353778362,0.01322286855429411,0.012997479178011417,0.012223348952829838,0.012567568570375443,0.011486062780022621,0.011869631707668304,0.011074675247073174,0.010555379092693329,0.010435227304697037,0.011000526137650013,0.010655859485268593,0.010609389282763004,0.01020127534866333,0.009869949892163277,0.00952004361897707,0.01050281897187233,0.009681613184511662,0.009188767522573471,0.008677821606397629,0.0074365329928696156,0.007825924083590508,0.007176963612437248,0.008544454351067543,0.009269483387470245,0.009400577284395695,0.00879621971398592,0.007847506552934647,0.007538429461419582,0.006854770239442587,0.009022506885230541,0.00859289150685072,0.008603954687714577,0.008258924819529057,0.006830636411905289,0.007926637306809425,0.007902387529611588,0.006290122866630554,0.0070075541734695435,0.008531663566827774,0.008846434764564037,0.007471277844160795,0.007048500701785088,0.007171215955168009,0.008128972724080086,0.008192064240574837,0.007866728119552135,0.007285505998879671,0.006388245616108179,0.0071708871982991695,0.007215672172605991,0.006798824295401573,0.006429613102227449,0.006144785787910223,0.0076359957456588745,0.007466082461178303,0.007117497269064188,0.007118590641766787,0.007049168925732374,0.006904672831296921,0.006279060151427984,0.006228236015886068,0.007424988783895969,0.0068785822950303555,0.006859145127236843,0.006379174534231424,0.006554459221661091,0.006577847059816122,0.006114569958299398,0.005747874267399311,0.00581337558105588,0.0069240182638168335,0.007059850264340639,0.0065290965139865875,0.006034150253981352,0.0056940834037959576,0.005451729521155357,0.005991671234369278,0.005734501872211695,0.005138034000992775,0.006089291535317898,0.006373126059770584,0.005524814128875732,0.004962196573615074,0.004734671209007502,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25315     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25316     
=================================================================
Total params: 50,631
Trainable params: 50,631
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 25,315
Trainable params: 25,315
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 25,316
Trainable params: 25,316
Non-trainable params: 0
_________________________________________________________________
