2021-06-26
loss,0.3325430750846863,0.21229411661624908,0.1339266151189804,0.09866088628768921,0.05444005876779556,0.047390833497047424,0.049540091305971146,0.04783371463418007,0.04446537420153618,0.04617803171277046,0.03855609521269798,0.055737484246492386,0.03759133070707321,0.040166184306144714,0.041493602097034454,0.04102684557437897,0.0453370064496994,0.046638406813144684,0.035516999661922455,0.03411712497472763,0.03616717457771301,0.04173954576253891,0.03490804508328438,0.025131935253739357,0.022582167759537697,0.022088835015892982,0.021351242437958717,0.02097647823393345,0.02085697464644909,0.020591549575328827,0.03362483158707619,0.02966340258717537,0.021124688908457756,0.02588336169719696,0.032976943999528885,0.034774910658597946,0.030758323147892952,0.03284269943833351,0.02950197644531727,0.03151348978281021,0.02425498701632023,0.0248371884226799,0.023885972797870636,0.022735517472028732,0.027713926509022713,0.028571104630827904,0.029700839892029762,0.02586144022643566,0.023347925394773483,0.021535372361540794,0.018674742430448532,0.02269095368683338,0.027894988656044006,0.023937175050377846,0.021065082401037216,0.02636520192027092,0.024431338533759117,0.02277798391878605,0.019473930820822716,0.019671117886900902,0.0230062548071146,0.02069707401096821,0.019416313618421555,0.01862478442490101,0.019814081490039825,0.024414021521806717,0.024854805320501328,0.023389706388115883,0.021251296624541283,0.021028362214565277,0.023251380771398544,0.021071380004286766,0.019503097981214523,0.017391495406627655,0.014775753021240234,0.013778255321085453,0.016857106238603592,0.020698511973023415,0.021355407312512398,0.019294636324048042,0.01885397732257843,0.020631320774555206,0.020008079707622528,0.01984778605401516,0.01791037619113922,0.01684456504881382,0.016117319464683533,0.015570716001093388,0.014841497875750065,0.014821022748947144,0.0147360535338521,0.01911921612918377,0.020886342972517014,0.021114466711878777,0.019572975113987923,0.018563399091362953,0.01776725798845291,0.016819002106785774,0.01517573557794094,0.014383993111550808,
mse,0.04461011290550232,0.015889175236225128,0.005831684451550245,0.003014683024957776,0.0009117544395849109,0.0006908290670253336,0.0007153179030865431,0.0006569063407368958,0.0005923784337937832,0.000625048007350415,0.00043150392593815923,0.0008806137484498322,0.0004191742045804858,0.0004669125482905656,0.0004915031022392213,0.0004698305856436491,0.0005966400494799018,0.0006283511756919324,0.00036478761467151344,0.00032707626814953983,0.0003764611901715398,0.0004993221373297274,0.00034895396674983203,0.00018607777019497007,0.00014563222066499293,0.00013822747860103846,0.00012770690955221653,0.0001253025111509487,0.00012333343329373747,0.00012607726966962218,0.0003286240389570594,0.0002528037002775818,0.00013181372196413577,0.00019762110605370253,0.0003033332759514451,0.0003460331936366856,0.0002654864510986954,0.00030133212567307055,0.0002462766715325415,0.0002767220139503479,0.00016933468577917665,0.0001724293251754716,0.00016872402920853347,0.00015012551739346236,0.0002132099325535819,0.0002335936005692929,0.0002484929864294827,0.00018666456162463874,0.00015086006897035986,0.00013120268704369664,0.00010311317601008341,0.0001552138855913654,0.00021447033213917166,0.00015902327140793204,0.00013209201279096305,0.0001929910504259169,0.000168320068041794,0.00015108127263374627,0.00011057777010137215,0.00011401992378523573,0.00014451108290813863,0.0001188633032143116,0.0001052506995620206,9.718518413137645e-05,0.00011421758972574025,0.00016662378038745373,0.00017526494048070163,0.00015225140668917447,0.00012903401511721313,0.000126142636872828,0.00015358558448497206,0.00012604759831447154,0.000107252795714885,8.714821160538122e-05,6.653070158790797e-05,5.7205543271265924e-05,8.314966544276103e-05,0.00012142874038545415,0.0001251293288078159,0.00010431832924950868,0.00010347328498028219,0.00012121682084398344,0.000116902963782195,0.00011036734213121235,8.938901737565175e-05,7.927224214654416e-05,7.2924216510728e-05,6.8410619860515e-05,6.284931441769004e-05,6.307703006314114e-05,6.401415157597512e-05,0.00010599765664665028,0.00012244627578184009,0.00012669611896853894,0.00011129420454381034,0.0001006737002171576,9.18132791412063e-05,8.199346484616399e-05,6.669611320830882e-05,6.073662007111125e-05,
mae,0.14049680531024933,0.09327084571123123,0.05869249254465103,0.041983712464571,0.023183731362223625,0.020189115777611732,0.021128952503204346,0.020279722288250923,0.019063660874962807,0.019619671627879143,0.0164723452180624,0.023296132683753967,0.015867047011852264,0.017125535756349564,0.01757144182920456,0.017454057931900024,0.0193330105394125,0.019672278314828873,0.015160473994910717,0.014668353833258152,0.015537521801888943,0.01775262877345085,0.0147903086617589,0.010584217496216297,0.009491270408034325,0.009447768330574036,0.009106189012527466,0.008927291259169579,0.008815391920506954,0.00865283515304327,0.014126572757959366,0.01264359150081873,0.008950109593570232,0.011118421331048012,0.014011194929480553,0.014897763729095459,0.01329482439905405,0.014097868464887142,0.0126753319054842,0.012994029559195042,0.010304450057446957,0.010503989644348621,0.010126449167728424,0.009656300768256187,0.011755616404116154,0.011943099088966846,0.012539864517748356,0.011074420064687729,0.0100485198199749,0.009127655997872353,0.00795697420835495,0.009704135358333588,0.011877162382006645,0.010080643929541111,0.0089422557502985,0.011244493536651134,0.010350541211664677,0.009679137729108334,0.008289774879813194,0.00833070557564497,0.009686943143606186,0.008904894813895226,0.008345085196197033,0.00788156408816576,0.00827309861779213,0.010169107466936111,0.010413969866931438,0.009873882867395878,0.009006706066429615,0.00893687829375267,0.009910973720252514,0.008888553828001022,0.008327647112309933,0.007346027530729771,0.006279467139393091,0.005839408840984106,0.007152872625738382,0.008837239816784859,0.009009945206344128,0.008114098571240902,0.008039617910981178,0.008742952719330788,0.00851191021502018,0.008346188813447952,0.007623420562595129,0.0071322680450975895,0.006817981135100126,0.006620510946959257,0.006325581111013889,0.0063120829872787,0.006283563561737537,0.008132269605994225,0.008936035446822643,0.009007202461361885,0.008410653099417686,0.008010715246200562,0.007684614043682814,0.0072181629948318005,0.006403528619557619,0.0060689435340464115,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 17091     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 17092     
=================================================================
Total params: 34,183
Trainable params: 34,183
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 17,091
Trainable params: 17,091
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 17,092
Trainable params: 17,092
Non-trainable params: 0
_________________________________________________________________
