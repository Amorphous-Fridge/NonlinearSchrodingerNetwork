2021-06-26
loss,0.40085169672966003,0.1436983048915863,0.05644889920949936,0.04325264319777489,0.04318220168352127,0.05171198397874832,0.04555455222725868,0.043403614312410355,0.04341958090662956,0.041937652975320816,0.03920581191778183,0.03412260115146637,0.031954582780599594,0.027873821556568146,0.023721501231193542,0.02286936715245247,0.031565722078084946,0.029230132699012756,0.027042211964726448,0.025637462735176086,0.02315557934343815,0.021267268806695938,0.03118472546339035,0.026101980358362198,0.029405290260910988,0.026767080649733543,0.0283521581441164,0.02848752960562706,0.027128877118229866,0.02432355470955372,0.0259118489921093,0.023480404168367386,0.025919409468770027,0.021748578175902367,0.017509624361991882,0.016502246260643005,0.024607036262750626,0.023739006370306015,0.025067079812288284,0.021958863362669945,0.019060270860791206,0.020119834691286087,0.025043493136763573,0.02290981076657772,0.019808495417237282,0.019674895331263542,0.019491231068968773,0.020591281354427338,0.01960604637861252,0.022191829979419708,0.01948634721338749,0.0191679447889328,0.020778726786375046,0.019203148782253265,0.019118037074804306,0.01745111495256424,0.01877441257238388,0.018073992803692818,0.017361922189593315,0.015414669178426266,0.014517762698233128,0.015969466418027878,0.01757579855620861,0.015667296946048737,0.019158249720931053,0.021917743608355522,0.01978081651031971,0.018450794741511345,0.017394766211509705,0.017829934135079384,0.020971156656742096,0.01924620196223259,0.017801962792873383,0.01674545928835869,0.016272373497486115,0.01595027558505535,0.017763204872608185,0.019658643752336502,0.017973285168409348,0.01717233471572399,0.016460971906781197,0.015594013035297394,0.01403493620455265,0.01233951561152935,0.012035991996526718,0.011712784878909588,0.011130234226584435,0.011573544703423977,0.013788733631372452,0.017614372074604034,0.015988493338227272,0.015244525857269764,0.014680133201181889,0.013289094902575016,0.014524923637509346,0.017811501398682594,0.018378686159849167,0.016313210129737854,0.014936277642846107,0.014228221960365772,
mse,0.07225882261991501,0.007737288251519203,0.0009905420010909438,0.0005687075317837298,0.0005513117648661137,0.0007757285493426025,0.0005964161246083677,0.0005574998795054853,0.0005261371843516827,0.000498294597491622,0.0004344571498222649,0.00033013656502589583,0.0002909264585468918,0.00022282899590209126,0.00017009428120218217,0.00014954121434129775,0.00028974859742447734,0.00024343015684280545,0.00020641680748667568,0.00018780244863592088,0.00015837459068279713,0.0001293847890337929,0.0002855433849617839,0.00019022409105673432,0.00025140316574834287,0.00020609977946151048,0.00023048270668368787,0.000226880147238262,0.00020282949844840914,0.00016781473823357373,0.00019629130838438869,0.0001613225758774206,0.00018779592937789857,0.00013775895058643073,9.297701762989163e-05,8.232295658672228e-05,0.00017023258260451257,0.00016059726476669312,0.00017635093536227942,0.00013726792531087995,0.00010882638162001967,0.00011784366506617516,0.00017650351219344884,0.00015081436140462756,0.00011575395910767838,0.00011135883687529713,0.00011084524885518476,0.00012103718472644687,0.000110938424768392,0.00013592647155746818,0.00011318088218104094,0.00010586875578155741,0.00012114979472244158,0.0001034851957228966,0.00010189113527303562,8.964489097706974e-05,0.00010044770169770345,9.385516750626266e-05,8.754436566960067e-05,7.131477468647063e-05,6.358439713949338e-05,7.636463124072179e-05,8.87958231032826e-05,7.327759522013366e-05,0.00011142277071485296,0.00013487394608091563,0.00010971562733175233,9.612017311155796e-05,8.613354293629527e-05,9.150848927674815e-05,0.00012071331002516672,0.00010567761637503281,9.12378600332886e-05,8.117398829199374e-05,7.507234113290906e-05,7.423604256473482e-05,8.890983008313924e-05,0.00010929340351140127,9.487930947216228e-05,8.559616253478453e-05,7.863762584747747e-05,7.021053170319647e-05,5.9497520851437e-05,4.790921229869127e-05,4.529310535872355e-05,4.2027812014566734e-05,3.7690952012781054e-05,4.070210343343206e-05,5.727871030103415e-05,8.444963896181434e-05,7.169687887653708e-05,6.532430415973067e-05,6.09916023677215e-05,5.310936467139982e-05,6.357313395710662e-05,8.918901585275307e-05,9.402915020473301e-05,7.637132512172684e-05,6.31472357781604e-05,5.7844954426400363e-05,
mae,0.17274339497089386,0.06384886801242828,0.024145763367414474,0.018394073471426964,0.018345387652516365,0.021886611357331276,0.019479995593428612,0.018367283046245575,0.018617529422044754,0.01768583618104458,0.01666402444243431,0.014914670959115028,0.013490498065948486,0.011775437742471695,0.010115967132151127,0.009729278273880482,0.013447594828903675,0.012190751731395721,0.011286619119346142,0.010978086851537228,0.009896374307572842,0.009091437794268131,0.01345838513225317,0.010853043757379055,0.012713627889752388,0.011542081832885742,0.012046879157423973,0.012142308056354523,0.011462105438113213,0.010160801000893116,0.010899370536208153,0.010032081976532936,0.011053407564759254,0.009286888875067234,0.007410030346363783,0.006985046900808811,0.0104776406660676,0.010041564702987671,0.010744800791144371,0.009289049543440342,0.008135966025292873,0.008535458706319332,0.010592621751129627,0.009791969321668148,0.00826938170939684,0.008421950973570347,0.008256117813289165,0.008713750168681145,0.008295048959553242,0.009474938735365868,0.00807558186352253,0.008120917715132236,0.008723446168005466,0.008139383979141712,0.008124473504722118,0.007404124364256859,0.007933327928185463,0.0077206348069012165,0.0074444604106247425,0.00657228846102953,0.00618391577154398,0.006749493535608053,0.00749999238178134,0.006637366022914648,0.008253288455307484,0.009225203655660152,0.008293268270790577,0.007807460613548756,0.007397666573524475,0.007645573001354933,0.009053919464349747,0.008432471193373203,0.007649493403732777,0.007137168198823929,0.006921481341123581,0.006761608179658651,0.007591002620756626,0.00841544196009636,0.007623078767210245,0.007239615544676781,0.007022145204246044,0.006603138986974955,0.005951272323727608,0.005215883255004883,0.005127425771206617,0.004962053149938583,0.004707443993538618,0.004937297198921442,0.005807536654174328,0.00770903006196022,0.007044804282486439,0.006527029909193516,0.006152402143925428,0.00561021501198411,0.006064089480787516,0.007428490091115236,0.00786557886749506,0.006915053818374872,0.006417527329176664,0.0061383796855807304,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 16931     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 16932     
=================================================================
Total params: 33,863
Trainable params: 33,863
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 16,931
Trainable params: 16,931
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 16,932
Trainable params: 16,932
Non-trainable params: 0
_________________________________________________________________
