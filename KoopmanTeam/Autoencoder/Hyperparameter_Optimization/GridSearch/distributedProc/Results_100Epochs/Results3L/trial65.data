2021-06-26
loss,0.4006858170032501,0.21371322870254517,0.1428212821483612,0.09898324310779572,0.0862971618771553,0.09195017069578171,0.062433432787656784,0.059250883758068085,0.047085925936698914,0.04725291207432747,0.04528806731104851,0.03843057155609131,0.04460247978568077,0.04403999447822571,0.041839051991701126,0.03326437622308731,0.03723803162574768,0.03423795476555824,0.03219325467944145,0.04013461619615555,0.03903878852725029,0.03276067227125168,0.029030587524175644,0.03378566727042198,0.031177949160337448,0.030322980135679245,0.03600615635514259,0.029926110059022903,0.027831509709358215,0.0258981641381979,0.029416579753160477,0.031201232224702835,0.025384271517395973,0.024744078516960144,0.02529122307896614,0.026395168155431747,0.027833804488182068,0.026230592280626297,0.025776498019695282,0.022210784256458282,0.024322178214788437,0.02657608687877655,0.02272876352071762,0.02060682699084282,0.025526132434606552,0.025063926354050636,0.025338437408208847,0.023524992167949677,0.020779777318239212,0.020685577765107155,0.02345602586865425,0.022542519494891167,0.021266095340251923,0.023273684084415436,0.02020236663520336,0.017608555033802986,0.016879700124263763,0.018247704952955246,0.02161860279738903,0.021853091195225716,0.020039118826389313,0.017862219363451004,0.01899740844964981,0.0183184165507555,0.016224518418312073,0.021643493324518204,0.0236209686845541,0.020432250574231148,0.02000260166823864,0.018478162586688995,0.01939544454216957,0.018895389512181282,0.01868351548910141,0.01821225695312023,0.016407551243901253,0.016320686787366867,0.017869487404823303,0.017025673761963844,0.015395390801131725,0.019810575991868973,0.020604833960533142,0.01761438511312008,0.01622622087597847,0.014674030244350433,0.01331709511578083,0.017700226977467537,0.019147710874676704,0.016400104388594627,0.014156404882669449,0.014866248704493046,0.01756894402205944,0.016280176118016243,0.01675397902727127,0.015580467879772186,0.015787241980433464,0.016650989651679993,0.01480567455291748,0.01477387547492981,0.016244882717728615,0.01655118353664875,
mse,0.06483599543571472,0.015988290309906006,0.006252652034163475,0.0030449593905359507,0.0021777646616101265,0.0024811134207993746,0.001142867375165224,0.0010269128251820803,0.0006496815476566553,0.0006960533792153001,0.0005877562798559666,0.00041669010533951223,0.0005900698015466332,0.0005689985118806362,0.0005194608820602298,0.00033867493038997054,0.00041749581578187644,0.00035693481913767755,0.00031256471993401647,0.00046047207433730364,0.0004368326044641435,0.000322450214298442,0.00025497694150544703,0.0003387515898793936,0.0002822963579092175,0.0002815944026224315,0.0003752271586563438,0.00026375995366834104,0.00023590285854879767,0.00019618937221821398,0.00025299208937212825,0.0002867472358047962,0.0001902175135910511,0.00018943777831736952,0.00019556673942133784,0.00020978339307475835,0.00021878343250136822,0.00020139147818554193,0.0001972285972442478,0.00015138668823055923,0.00018024166638497263,0.0001993400219362229,0.00015451850777026266,0.00012982588668819517,0.0001862963690655306,0.00017501080583315343,0.00018467209883965552,0.00015857740072533488,0.00012876218534074724,0.00012939836597070098,0.0001610094477655366,0.00014715544239152223,0.00013104264508001506,0.00016109732678160071,0.00012114565470255911,9.410100028617308e-05,8.56784827192314e-05,0.00010255986853735521,0.0001392985286656767,0.0001386160438414663,0.00011708985402947292,9.595214214641601e-05,0.00010617348016239703,9.94359070318751e-05,7.928105333121493e-05,0.00014767424727324396,0.00015708114369772375,0.0001172462070826441,0.00011553818330867216,0.00010178882803302258,0.0001118300569942221,0.00010392938565928489,0.00010198431118624285,9.487443458056077e-05,8.048785821301863e-05,8.212369721150026e-05,9.242193482350558e-05,8.528292528353631e-05,7.195372745627537e-05,0.00011356514733051881,0.00011768172407755628,9.012093505589291e-05,7.899551565060392e-05,6.550720718223602e-05,5.3209740144666284e-05,9.169871918857098e-05,0.00010222751734545454,7.92593345977366e-05,6.138406024547294e-05,6.841351569164544e-05,8.821258234092966e-05,7.603508129250258e-05,8.287939272122458e-05,7.180360262282193e-05,7.365503552136943e-05,7.964124233694747e-05,6.609475531149656e-05,6.598621257580817e-05,7.713281229371205e-05,8.011771569726989e-05,
mae,0.17588463425636292,0.09759947657585144,0.060863375663757324,0.04197736829519272,0.036901336163282394,0.03908490017056465,0.026791507378220558,0.02569938637316227,0.020074862986803055,0.0202579777687788,0.01943356543779373,0.016612200066447258,0.019158216193318367,0.018741503357887268,0.01787203922867775,0.013997300527989864,0.01580619625747204,0.014564534649252892,0.013674936257302761,0.016901984810829163,0.016673089936375618,0.013899628072977066,0.0123809315264225,0.014244846999645233,0.01329228188842535,0.01277976669371128,0.015254958532750607,0.012872126884758472,0.01187328714877367,0.01095171645283699,0.012539377436041832,0.013266311027109623,0.010768179781734943,0.01049230620265007,0.010709363035857677,0.011264597065746784,0.011875704862177372,0.011204664595425129,0.010909516364336014,0.009506727568805218,0.010271328501403332,0.011235678568482399,0.009705438278615475,0.008839024230837822,0.01089932769536972,0.010755863972008228,0.010770305059850216,0.0099268713966012,0.008962128311395645,0.00879726093262434,0.009722636081278324,0.00959452148526907,0.009060642682015896,0.010046908631920815,0.008623383939266205,0.007505711168050766,0.007194059900939465,0.007756141480058432,0.009273581206798553,0.009266139008104801,0.008464663289487362,0.007524698972702026,0.008051356300711632,0.007761290762573481,0.006809011101722717,0.009161247871816158,0.010038410313427448,0.00866224430501461,0.008384417742490768,0.00786658376455307,0.008249732665717602,0.00793376937508583,0.007887796498835087,0.007703289855271578,0.006953914649784565,0.006939106620848179,0.007531461305916309,0.00711157638579607,0.006557391956448555,0.008543463423848152,0.008943422697484493,0.007525194901973009,0.006959178484976292,0.00628503505140543,0.005706682335585356,0.007438218221068382,0.008061223663389683,0.006963363382965326,0.006008977070450783,0.0063175056129693985,0.0074288672767579556,0.006853742059320211,0.007073855027556419,0.006698315963149071,0.006680080201476812,0.007046229671686888,0.006261104252189398,0.0062097772024571896,0.006833197548985481,0.007037445902824402,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 74835     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 74836     
=================================================================
Total params: 149,671
Trainable params: 149,671
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 74,835
Trainable params: 74,835
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 74,836
Trainable params: 74,836
Non-trainable params: 0
_________________________________________________________________
