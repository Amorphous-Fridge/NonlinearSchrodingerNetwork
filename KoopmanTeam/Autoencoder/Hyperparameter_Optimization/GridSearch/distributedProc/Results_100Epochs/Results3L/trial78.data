2021-06-26
loss,0.6819736957550049,0.26356661319732666,0.24094589054584503,0.2309931218624115,0.14596763253211975,0.10603636503219604,0.08561981469392776,0.07515209913253784,0.062076956033706665,0.06344916671514511,0.06032180413603783,0.04725692793726921,0.047056201845407486,0.03817194327712059,0.03527930751442909,0.04146843031048775,0.03556022047996521,0.03396701067686081,0.035186368972063065,0.03618365526199341,0.0290741678327322,0.031360555440187454,0.033284641802310944,0.02973037213087082,0.031017139554023743,0.029205890372395515,0.026277663186192513,0.024244200438261032,0.026571257039904594,0.02488042786717415,0.02384321019053459,0.02344147488474846,0.025038881227374077,0.02671044133603573,0.025075186043977737,0.022300785407423973,0.019766174256801605,0.02198159508407116,0.0230777096003294,0.024137161672115326,0.022876041010022163,0.0206389669328928,0.021548209711909294,0.022339871153235435,0.0212143175303936,0.021634528413414955,0.019016554579138756,0.01735161989927292,0.016416696831583977,0.021843085065484047,0.02050199918448925,0.019096186384558678,0.01786239817738533,0.019881995394825935,0.02107379026710987,0.020389439538121223,0.018470587208867073,0.015755154192447662,0.019709503278136253,0.019328109920024872,0.019677098840475082,0.019040364772081375,0.018335485830903053,0.017431091517210007,0.01803416945040226,0.016200726851820946,0.01964716985821724,0.018318651244044304,0.017988603562116623,0.017424341291189194,0.01711963675916195,0.016802329570055008,0.016615474596619606,0.01759492978453636,0.016074256971478462,0.014094855636358261,0.018303684890270233,0.0163571760058403,0.016623536124825478,0.0144236134365201,0.01597084291279316,0.016832465305924416,0.017481155693531036,0.017092857509851456,0.017642470076680183,0.01707124523818493,0.014415099285542965,0.013596129603683949,0.014841764234006405,0.013312630355358124,0.01226261630654335,0.01665669120848179,0.015444164164364338,0.016312265768647194,0.016404541209340096,0.015765082091093063,0.015066145919263363,0.01383188460022211,0.013613784685730934,0.01657569222152233,
mse,0.21153731644153595,0.02237786538898945,0.019666841253638268,0.017105834558606148,0.006500033661723137,0.0034472059924155474,0.0022130897268652916,0.0017117070965468884,0.0011073960922658443,0.0011634755646809936,0.0010283809388056397,0.0006561487098224461,0.0006468612118624151,0.000457759975688532,0.0003672158345580101,0.0005365282413549721,0.0003826884785667062,0.0003420906432438642,0.00037766192690469325,0.0003957166918553412,0.0002540813002269715,0.000286481692455709,0.0003240188816562295,0.0002562601584941149,0.0002765312965493649,0.00024303140526171774,0.00019824772607535124,0.00017995800590142608,0.0002058929967461154,0.00018383208953309804,0.00017222948372364044,0.00016075353778433055,0.00018360790272708982,0.00020240098820067942,0.00018364140123594552,0.00015339214587584138,0.00011808305134763941,0.00014388722775038332,0.00015572983829770237,0.0001656422537053004,0.00014933207421563566,0.0001260635763173923,0.00013779824075754732,0.00014022391405887902,0.00012727586727123708,0.0001316306588705629,0.00011042963888030499,9.265025437343866e-05,8.076955418800935e-05,0.00013590538583230227,0.00012510380474850535,0.00010698264668462798,9.614121518097818e-05,0.00011613729293458164,0.0001257466501556337,0.00011841594096040353,0.00010258198017254472,7.584132254123688e-05,0.00011689229722833261,0.00010635611397447065,0.00010995541379088536,0.00010273468069499359,9.754129860084504e-05,9.090706589631736e-05,9.502390457782894e-05,7.791710231686011e-05,0.00010978913633152843,9.500442683929577e-05,9.387143654748797e-05,8.789646381046623e-05,8.518610411556438e-05,8.332222932949662e-05,7.990620360942557e-05,9.039400174515322e-05,7.703245501033962e-05,6.001849033054896e-05,9.499687439529225e-05,7.828331581549719e-05,8.02075956016779e-05,6.269233563216403e-05,7.555617776233703e-05,8.340967906406149e-05,8.588300261180848e-05,8.410644659306854e-05,8.791647269390523e-05,8.171244553523138e-05,6.181456410558894e-05,5.654539927490987e-05,6.548833334818482e-05,5.4252388508757576e-05,4.458302282728255e-05,8.077846723608673e-05,7.190447649918497e-05,7.581863610539585e-05,7.489673589589074e-05,7.093913154676557e-05,6.527162622660398e-05,5.7397428463445976e-05,5.5615721066715196e-05,7.87352619227022e-05,
mae,0.29299816489219666,0.10826608538627625,0.1012631356716156,0.09794909507036209,0.06201150268316269,0.0449540838599205,0.03649374842643738,0.03174400329589844,0.026221871376037598,0.026790153235197067,0.025776779279112816,0.020062295719981194,0.02015657164156437,0.01648411713540554,0.014968068338930607,0.017925430089235306,0.01528835017234087,0.014289336279034615,0.015110508538782597,0.015365134924650192,0.012395663186907768,0.013321710750460625,0.014363902620971203,0.012513968162238598,0.013387811370193958,0.01237906888127327,0.010925672017037868,0.010409039445221424,0.01120584923774004,0.010594733990728855,0.01021147146821022,0.009967527352273464,0.010734550654888153,0.011522162705659866,0.010732199996709824,0.009368306025862694,0.008363176137208939,0.009261459112167358,0.009710466489195824,0.010313359089195728,0.00979558378458023,0.00886510405689478,0.00900192093104124,0.009343275800347328,0.008948877453804016,0.009187794290482998,0.008166635408997536,0.007449967321008444,0.00699002668261528,0.00921541079878807,0.008708092384040356,0.008107402361929417,0.007687381003051996,0.008587288670241833,0.008937799371778965,0.00868491642177105,0.007779072504490614,0.0067162592895329,0.008387291803956032,0.008076638914644718,0.008391842246055603,0.007984583266079426,0.007730662357062101,0.00734806340187788,0.007798054721206427,0.006892435718327761,0.008335980586707592,0.007701449561864138,0.007679937873035669,0.00738455168902874,0.007355220150202513,0.007183910813182592,0.007004497107118368,0.007452589459717274,0.00680633494630456,0.006027651485055685,0.007779900915920734,0.006930334959179163,0.00692669115960598,0.006032577250152826,0.006663944572210312,0.007195493672043085,0.007490070536732674,0.0072952997870743275,0.007494173012673855,0.007177442777901888,0.006048785522580147,0.0058220792561769485,0.0062973215244710445,0.005674859508872032,0.005250271409749985,0.007062925491482019,0.006446143612265587,0.0069540562108159065,0.007004323415458202,0.006661237683147192,0.0063896747305989265,0.005819142330437899,0.0058014304377138615,0.00697717908769846,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 165699    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 165700    
=================================================================
Total params: 331,399
Trainable params: 331,399
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 165,699
Trainable params: 165,699
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 165,700
Trainable params: 165,700
Non-trainable params: 0
_________________________________________________________________
