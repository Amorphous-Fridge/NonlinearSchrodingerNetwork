2021-06-26
loss,0.5200583338737488,0.2242942452430725,0.17001348733901978,0.10620337724685669,0.0720282569527626,0.0577351413667202,0.05021166428923607,0.04467965289950371,0.04045737907290459,0.03695415332913399,0.034704938530921936,0.03257459029555321,0.03090117685496807,0.02906249463558197,0.028053954243659973,0.026860110461711884,0.02608785778284073,0.025238383561372757,0.0244428850710392,0.024040117859840393,0.023481786251068115,0.022958951070904732,0.022441938519477844,0.022150646895170212,0.02160785160958767,0.021442163735628128,0.020941544324159622,0.020694632083177567,0.0205242857336998,0.02017013356089592,0.01978028379380703,0.019542718306183815,0.01944969780743122,0.019092615693807602,0.018954914063215256,0.018611988052725792,0.018545297905802727,0.018314898014068604,0.018118757754564285,0.01779302768409252,0.017828168347477913,0.01769626885652542,0.017490997910499573,0.017366860061883926,0.017281822860240936,0.017075635492801666,0.017009299248456955,0.016801899299025536,0.016771305352449417,0.016528397798538208,0.016504669561982155,0.01650686003267765,0.01627732813358307,0.01616896316409111,0.016202827915549278,0.016159553080797195,0.01589236408472061,0.015970181673765182,0.015837468206882477,0.01556518767029047,0.015834279358386993,0.015638932585716248,0.015580923296511173,0.015570619143545628,0.015427426435053349,0.015420282259583473,0.015325808897614479,0.015202831476926804,0.015162874013185501,0.015099274925887585,0.01509995199739933,0.015054494142532349,0.015005187131464481,0.01486254297196865,0.014892518520355225,0.01474818866699934,0.014812354929745197,0.014730613678693771,0.014653962105512619,0.014621671289205551,0.014633918181061745,0.014591878280043602,0.014434984885156155,0.014545445330440998,0.014349235221743584,0.014363952912390232,0.014305120334029198,0.01425283681601286,0.014251350425183773,0.014216960407793522,0.01420387253165245,0.014249129220843315,0.014188041910529137,0.014075687155127525,0.01395205594599247,0.013970267958939075,0.014015580527484417,0.013868659734725952,0.013869927264750004,0.013833558186888695,
mse,0.09425178170204163,0.01775234192609787,0.01023134682327509,0.004051480442285538,0.001861426280811429,0.0012094398261979222,0.0009484886541031301,0.0007655515801161528,0.0006323230918496847,0.0005289865075610578,0.00046295044012367725,0.00040679171797819436,0.00036108470521867275,0.00031720285187475383,0.00028808595379814506,0.00026166162570007145,0.0002431872271699831,0.000223546230699867,0.00020876336202491075,0.00019858480663970113,0.00018898403504863381,0.0001793077972251922,0.00016897235764190555,0.00016384580521844327,0.00015574300778098404,0.00015192240243777633,0.00014532382192555815,0.00014023343101143837,0.00013687489263247699,0.00013219799438957125,0.00012699200306087732,0.0001238849072251469,0.000122010700579267,0.00011758800246752799,0.00011468648153822869,0.00011056338553316891,0.00010954951721942052,0.0001064664320438169,0.00010408148227725178,0.0001000859119812958,9.999176836572587e-05,9.902312740450725e-05,9.591158595867455e-05,9.436529944650829e-05,9.283411054639146e-05,9.087688522413373e-05,9.040337317856029e-05,8.74362958711572e-05,8.757643081480637e-05,8.427165448665619e-05,8.37429179227911e-05,8.390513539779931e-05,8.13705482869409e-05,7.992012251634151e-05,8.061814878601581e-05,7.966268458403647e-05,7.660569826839492e-05,7.7904733188916e-05,7.643761637154967e-05,7.374370761681348e-05,7.599151285830885e-05,7.4472525739111e-05,7.374317647190765e-05,7.337471470236778e-05,7.157069921959192e-05,7.184794230852276e-05,7.085218385327607e-05,6.962046609260142e-05,6.920240412000567e-05,6.842318543931469e-05,6.835885142209008e-05,6.813125946791843e-05,6.732397014275193e-05,6.605566159123555e-05,6.603377551073208e-05,6.474580732174218e-05,6.533374835271388e-05,6.485407357104123e-05,6.416541145881638e-05,6.383068830473348e-05,6.390264752553776e-05,6.336099613690749e-05,6.172976281959563e-05,6.312864570645615e-05,6.169779953779653e-05,6.124402716523036e-05,6.063619002816267e-05,6.040863081580028e-05,6.0196896811248735e-05,6.0017315263394266e-05,5.98984224779997e-05,6.003525049891323e-05,5.95415840507485e-05,5.8516423450782895e-05,5.7523327996023e-05,5.7869856391334906e-05,5.7911212934413925e-05,5.6699951528571546e-05,5.6850687542464584e-05,5.6332464737351984e-05,
mae,0.22987326979637146,0.10392596572637558,0.07214284688234329,0.04361589252948761,0.030372289940714836,0.024662360548973083,0.021525468677282333,0.019143173471093178,0.017254777252674103,0.01576131023466587,0.014824563637375832,0.01393858902156353,0.013304663822054863,0.012460396625101566,0.012051217257976532,0.011527728289365768,0.011212905868887901,0.010844948701560497,0.010494205169379711,0.010351508855819702,0.010096999816596508,0.00986831821501255,0.009639500640332699,0.009508991613984108,0.009281677193939686,0.00923970714211464,0.009016105905175209,0.00888811144977808,0.00886418018490076,0.008698122575879097,0.008513680659234524,0.008419052697718143,0.008366049267351627,0.008209731429815292,0.008175654336810112,0.007995173335075378,0.00796541664749384,0.007879368960857391,0.0078182527795434,0.007644311059266329,0.007662890944629908,0.007620790041983128,0.007548097521066666,0.007486012764275074,0.007459611166268587,0.007335169240832329,0.007330629974603653,0.007228539790958166,0.007249787915498018,0.007089126855134964,0.0071164704859256744,0.007103585172444582,0.006983212660998106,0.0069590662606060505,0.006947977934032679,0.0069868797436356544,0.006789422128349543,0.006891059689223766,0.006795776542276144,0.006599262356758118,0.006812580395489931,0.006763311568647623,0.006708947475999594,0.006698952987790108,0.006614062003791332,0.006619380321353674,0.006604444235563278,0.006529823411256075,0.006542493589222431,0.006421265657991171,0.006521879229694605,0.006443112622946501,0.006452109664678574,0.006394749972969294,0.006406532600522041,0.006301943212747574,0.00638159504160285,0.00627289991825819,0.006263944320380688,0.006220398470759392,0.006262155249714851,0.0063211387023329735,0.006200057454407215,0.006272477563470602,0.0061629884876310825,0.0061759669333696365,0.006091945804655552,0.006140900310128927,0.006094173062592745,0.006030365824699402,0.006088842637836933,0.006112989038228989,0.006097672041505575,0.0060842144303023815,0.005974724888801575,0.0059835840947926044,0.006045854184776545,0.005872182082384825,0.0059664808213710785,0.005913080647587776,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1707      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1708      
=================================================================
Total params: 3,415
Trainable params: 3,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 1,707
Trainable params: 1,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 1,708
Trainable params: 1,708
Non-trainable params: 0
_________________________________________________________________
