2021-06-26
loss,0.5099020600318909,0.25770729780197144,0.22645114362239838,0.21305494010448456,0.18737976253032684,0.12207061052322388,0.07006389647722244,0.05643901973962784,0.0468808077275753,0.039784025400877,0.03680836781859398,0.03299582377076149,0.030870122835040092,0.02904149517416954,0.027453651651740074,0.026369288563728333,0.02556011453270912,0.02478223294019699,0.024010896682739258,0.023099876940250397,0.02274077944457531,0.02205090969800949,0.02164747565984726,0.02112172171473503,0.020565500482916832,0.02027537114918232,0.020011115819215775,0.019509296864271164,0.019055522978305817,0.01892775297164917,0.018551204353570938,0.018333252519369125,0.01813824474811554,0.017803309485316277,0.0177146065980196,0.017308570444583893,0.017166540026664734,0.016785262152552605,0.016738347709178925,0.016673384234309196,0.016331233084201813,0.016173282638192177,0.016311179846525192,0.015746435150504112,0.015808917582035065,0.015536320395767689,0.015607104636728764,0.015414439141750336,0.015238729305565357,0.015279666520655155,0.015118938870728016,0.0150222172960639,0.014905819669365883,0.014752868562936783,0.014762293547391891,0.014523519203066826,0.014511632733047009,0.014460358768701553,0.014275743626058102,0.014359243214130402,0.014160688035190105,0.014012626372277737,0.013959784060716629,0.01404719240963459,0.013760997913777828,0.013842553831636906,0.013845348730683327,0.013732549734413624,0.013508974574506283,0.013638454489409924,0.01359129510819912,0.013404649682343006,0.013389135710895061,0.01334347203373909,0.013312014751136303,0.013221251778304577,0.013140419498085976,0.01312826294451952,0.013036771677434444,0.012978192418813705,0.012930857948958874,0.01282541360706091,0.012897897511720657,0.012889343313872814,0.012791544198989868,0.01277329120784998,0.012762533500790596,0.012657159939408302,0.012629121541976929,0.012552482075989246,0.012525864876806736,0.012392104603350163,0.012447131797671318,0.01244302187114954,0.01243528351187706,0.012284433469176292,0.012368367053568363,0.012337698601186275,0.012302574701607227,0.012223157100379467,
mse,0.09980451315641403,0.021492157131433487,0.018098825588822365,0.016393903642892838,0.012864266522228718,0.005724615417420864,0.0017546920571476221,0.001154514029622078,0.0008177108247764409,0.000604542437940836,0.0004995623021386564,0.0004046069225296378,0.0003474670520517975,0.0003035576082766056,0.0002686808002181351,0.00024734248290769756,0.00022641694522462785,0.00021283999376464635,0.00019912207790184766,0.00018536756397224963,0.00017745261720847338,0.00016764670726843178,0.00016064822557382286,0.00015288750000763685,0.00014380192442331463,0.00014003388059791178,0.00013596529606729746,0.0001295669499086216,0.0001237584074260667,0.00012144548236392438,0.00011583611194510013,0.00011342138895997778,0.0001107053249143064,0.0001068249621312134,0.00010531173029448837,0.00010031910642283037,9.909268555929884e-05,9.399685222888365e-05,9.40756217460148e-05,9.286213753512129e-05,8.944359433371574e-05,8.690079994266853e-05,8.833900938043371e-05,8.3343249571044e-05,8.267194061772898e-05,8.019355300348252e-05,8.06824755272828e-05,7.85116499173455e-05,7.680872658966109e-05,7.666763121960685e-05,7.513495074817911e-05,7.440692570526153e-05,7.280707359313965e-05,7.147170254029334e-05,7.14177658664994e-05,6.897982530063018e-05,6.851242505945265e-05,6.804586155340075e-05,6.584876973647624e-05,6.724631384713575e-05,6.530802784254774e-05,6.384651351254433e-05,6.316327198874205e-05,6.353590288199484e-05,6.104840576881543e-05,6.152564310468733e-05,6.148553802631795e-05,6.057035716366954e-05,5.8304256526753306e-05,5.935843728366308e-05,5.96856334595941e-05,5.789190618088469e-05,5.74571022298187e-05,5.6951259466586635e-05,5.664579657604918e-05,5.583169695455581e-05,5.5093056289479136e-05,5.505482840817422e-05,5.448637966765091e-05,5.355698522180319e-05,5.322201468516141e-05,5.232505645835772e-05,5.279433389659971e-05,5.283587233861908e-05,5.199851148063317e-05,5.185239569982514e-05,5.1688817620743066e-05,5.072208296041936e-05,5.032178160035983e-05,4.9976410082308576e-05,4.9869409849634394e-05,4.8543028242420405e-05,4.893305595032871e-05,4.903902663500048e-05,4.859958426095545e-05,4.769166116602719e-05,4.831795013160445e-05,4.806377910426818e-05,4.7356574214063585e-05,4.705001265392639e-05,
mae,0.21576999127864838,0.11013713479042053,0.09831822663545609,0.09637679159641266,0.08566930890083313,0.054315172135829926,0.03004574589431286,0.024211322888731956,0.020183783024549484,0.017124691978096962,0.015776585787534714,0.014118173159658909,0.013184555806219578,0.012385529465973377,0.011706436052918434,0.011233117431402206,0.010889401659369469,0.010557744652032852,0.010243118740618229,0.009848312474787235,0.009713890962302685,0.009410429745912552,0.009250441566109657,0.009023846127092838,0.008778090588748455,0.008658427745103836,0.008554389700293541,0.008326633833348751,0.008150003850460052,0.008090239018201828,0.007905732840299606,0.007826928980648518,0.007744558621197939,0.007616087328642607,0.007588672451674938,0.0073841228149831295,0.007337016984820366,0.007167694624513388,0.007164342328906059,0.0071312058717012405,0.006977846845984459,0.006900424137711525,0.006990673020482063,0.0067241913639009,0.00677073048427701,0.006618591025471687,0.006673113908618689,0.006565500982105732,0.006527177058160305,0.006524748634546995,0.006465786602348089,0.006428832188248634,0.006366882938891649,0.006321693770587444,0.006296247243881226,0.006192023865878582,0.006209011655300856,0.006186467595398426,0.006098732352256775,0.006167295388877392,0.00605523819103837,0.006012475583702326,0.00597704341635108,0.005996072664856911,0.005868846084922552,0.005916516296565533,0.005940664559602737,0.005867333617061377,0.005783203989267349,0.005851782392710447,0.005819851066917181,0.005738416686654091,0.005743220914155245,0.005708271637558937,0.005673174746334553,0.005635701585561037,0.005627468228340149,0.005612500477582216,0.005585512146353722,0.0055345697328448296,0.005517251323908567,0.005466438364237547,0.005520537029951811,0.005545281805098057,0.005482577718794346,0.005473598837852478,0.005475873127579689,0.005405889358371496,0.005394039209932089,0.00535160768777132,0.005362365860491991,0.005322057753801346,0.005327322520315647,0.005335635505616665,0.005332715343683958,0.0052418177947402,0.0052998554892838,0.0052912551909685135,0.005254307761788368,0.0052473656833171844,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 907       
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 908       
=================================================================
Total params: 1,815
Trainable params: 1,815
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 907
Trainable params: 907
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 908
Trainable params: 908
Non-trainable params: 0
_________________________________________________________________
