2021-06-26
loss,0.39299270510673523,0.150754913687706,0.12000030279159546,0.07656433433294296,0.06975438445806503,0.06350947171449661,0.06309317797422409,0.04500016197562218,0.047558560967445374,0.04860823228955269,0.04125918447971344,0.043825335800647736,0.04178684577345848,0.03899562358856201,0.04254523292183876,0.04019898921251297,0.04098619148135185,0.04239313676953316,0.03741933032870293,0.03310498595237732,0.04060058668255806,0.039554812014102936,0.03587210178375244,0.02422761358320713,0.02855154685676098,0.028412995859980583,0.035002030432224274,0.03131236135959625,0.03355325758457184,0.035958532243967056,0.033023178577423096,0.03144092485308647,0.03525431826710701,0.03330480679869652,0.03242666274309158,0.027719393372535706,0.02823139913380146,0.03136979043483734,0.02751224674284458,0.02626451663672924,0.028463056311011314,0.029707295820116997,0.027496658265590668,0.027315299957990646,0.023877805098891258,0.02533216029405594,0.024338306859135628,0.025420524179935455,0.023638078942894936,0.021868551149964333,0.0223715640604496,0.02095668949186802,0.022000936791300774,0.02519901841878891,0.024070652201771736,0.025840386748313904,0.023109884932637215,0.021990370005369186,0.02018101140856743,0.020150499418377876,0.019373660907149315,0.01877881959080696,0.024122240021824837,0.02168300561606884,0.021945729851722717,0.02152411639690399,0.021715810522437096,0.01924092322587967,0.019862564280629158,0.0190130602568388,0.018776094540953636,0.01779819279909134,0.019004538655281067,0.01765047200024128,0.016651641577482224,0.017312396317720413,0.01543754618614912,0.015895437449216843,0.019238369539380074,0.01641550101339817,0.01805131323635578,0.021563353016972542,0.02009829692542553,0.01833849959075451,0.015539765357971191,0.015417221933603287,0.016828643158078194,0.017086699604988098,0.01729690469801426,0.017236584797501564,0.017519747838377953,0.016659924760460854,0.017728855833411217,0.016573861241340637,0.015542039647698402,0.014154433272778988,0.014940156601369381,0.016706300899386406,0.01605111174285412,0.01682194322347641,
mse,0.0582771822810173,0.007645399775356054,0.004209233447909355,0.0016923599177971482,0.001374351209960878,0.0011787620605900884,0.0011363234370946884,0.000597521080635488,0.0006661625229753554,0.0006776448572054505,0.0005187473143450916,0.0005503108259290457,0.0005086053861305118,0.00044517393689602613,0.0005167421768419445,0.00048235879512503743,0.000495029438752681,0.0005174765246920288,0.00040521766641177237,0.0003334794891998172,0.00046622034278698266,0.00044358137529343367,0.00037728543975390494,0.00017190419021062553,0.0002448668237775564,0.00023816015163902193,0.00035033299354836345,0.00029683555476367474,0.0003245895786676556,0.00036283672670833766,0.00031614420004189014,0.0002849606971722096,0.00035353261046111584,0.0003221608931198716,0.0002920093829743564,0.00022895536676514894,0.00023549917386844754,0.00027588140801526606,0.0002236486179754138,0.00020835062605328858,0.0002346508699702099,0.0002483548305463046,0.00021331016614567488,0.00021791568724438548,0.00016552102169953287,0.00018596806330606341,0.00016951080760918558,0.0001833809510571882,0.00016349686484318227,0.00014301999181043357,0.00014832128363195807,0.00013160565868020058,0.00014201427984517068,0.00018390599871054292,0.00016171463357750326,0.00018458552949596196,0.0001552327594254166,0.0001371020480291918,0.00012131466792197898,0.00012006506585748866,0.00011206790077267215,0.0001031441061059013,0.00016159396909642965,0.00013106731057632715,0.00013592712639365345,0.00013066522660665214,0.00013210861652623862,0.0001077015622286126,0.00011407147394493222,0.00010500952339498326,0.0001025587844196707,9.497874998487532e-05,0.00010591576574370265,9.152006532531232e-05,8.243385673267767e-05,8.856761996867135e-05,7.328233914449811e-05,7.623158307978883e-05,0.00011413003085181117,7.911492139101028e-05,9.351803601020947e-05,0.00013116330956108868,0.0001133933910750784,9.65228391578421e-05,7.410428224829957e-05,7.193913916125894e-05,8.037770021473989e-05,8.417598291998729e-05,8.355038153240457e-05,8.435858762823045e-05,8.872471516951919e-05,8.189534855773672e-05,8.824669930618256e-05,7.6424446888268e-05,6.809849583078176e-05,6.045057307346724e-05,6.69423898216337e-05,8.024228736758232e-05,7.408989040413871e-05,7.929692219477147e-05,
mae,0.1665440946817398,0.06413664668798447,0.050583869218826294,0.03269098699092865,0.02950296178460121,0.026866093277931213,0.0264433640986681,0.01905236579477787,0.020184176042675972,0.020366711542010307,0.017590945586562157,0.018772898241877556,0.0179183017462492,0.0164561215788126,0.017911329865455627,0.017111720517277718,0.01722579635679722,0.018089041113853455,0.015827275812625885,0.014106824062764645,0.017176322638988495,0.016991088166832924,0.015226482413709164,0.010332440957427025,0.012177339754998684,0.01207782607525587,0.014898544177412987,0.01334301382303238,0.014247425831854343,0.015257635153830051,0.01402895525097847,0.013226568698883057,0.014968319796025753,0.014368120580911636,0.013977688737213612,0.01171823125332594,0.012182014063000679,0.013179425150156021,0.011683473363518715,0.011077426373958588,0.012151687406003475,0.01240514311939478,0.01159708108752966,0.011529943905770779,0.010052626952528954,0.010777836665511131,0.01019174326211214,0.010819941759109497,0.010059855878353119,0.009357944130897522,0.009415174834430218,0.008831379003822803,0.009273022413253784,0.010741472244262695,0.010278668254613876,0.010766975581645966,0.009914104826748371,0.00935455970466137,0.008538191206753254,0.008566003292798996,0.008241997100412846,0.007985993288457394,0.010261395946145058,0.009150911122560501,0.009354994632303715,0.009114137850701809,0.009104578755795956,0.00804372038692236,0.008378333412110806,0.008014744147658348,0.007924978621304035,0.00744851166382432,0.008074681274592876,0.007369982078671455,0.0070699602365493774,0.007407264783978462,0.006516294553875923,0.006711791269481182,0.008135453797876835,0.006863719783723354,0.0076795220375061035,0.00920931901782751,0.008504434488713741,0.007833135314285755,0.006480979733169079,0.006580124609172344,0.0070764850825071335,0.007217172533273697,0.007433167193084955,0.007283080369234085,0.007425404619425535,0.007148004602640867,0.007412422448396683,0.007034091278910637,0.006715092808008194,0.006063912995159626,0.006368998438119888,0.0070755742490291595,0.006833233404904604,0.0070790559984743595,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 50083     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 50084     
=================================================================
Total params: 100,167
Trainable params: 100,167
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 50,083
Trainable params: 50,083
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 50,084
Trainable params: 50,084
Non-trainable params: 0
_________________________________________________________________
