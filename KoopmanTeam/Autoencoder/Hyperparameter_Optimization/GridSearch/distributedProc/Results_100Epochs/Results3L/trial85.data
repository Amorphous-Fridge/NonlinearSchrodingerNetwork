2021-06-26
loss,0.3746868968009949,0.16515865921974182,0.10658267885446548,0.07476656138896942,0.05576825514435768,0.04147189483046532,0.043413158506155014,0.04042952135205269,0.046721652150154114,0.045316070318222046,0.041777778416872025,0.040416646748781204,0.038609858602285385,0.03884130343794823,0.029690399765968323,0.028294408693909645,0.03577031195163727,0.03300857171416283,0.029185064136981964,0.0308473352342844,0.03278173878788948,0.028168892487883568,0.02740856632590294,0.03152846172451973,0.032088927924633026,0.02748185582458973,0.027502581477165222,0.0251394622027874,0.02194761112332344,0.02150106243789196,0.02344871498644352,0.02036348730325699,0.021879784762859344,0.02205423079431057,0.028584403917193413,0.027117619290947914,0.02401520311832428,0.021927986294031143,0.021371088922023773,0.020441778004169464,0.024945585057139397,0.02500038780272007,0.025415660813450813,0.02186080999672413,0.02070259302854538,0.019442034885287285,0.023938363417983055,0.021690085530281067,0.020469577983021736,0.020995713770389557,0.019177719950675964,0.021408839151263237,0.018326440826058388,0.020590469241142273,0.021947743371129036,0.019860967993736267,0.02077639102935791,0.01873292587697506,0.015983857214450836,0.015720538794994354,0.014155714772641659,0.015272059477865696,0.019745685160160065,0.01974646933376789,0.017760012298822403,0.016224445775151253,0.015324166044592857,0.015230157412588596,0.01562355738133192,0.014510374516248703,0.015320582315325737,0.01605696976184845,0.02074638195335865,0.019300319254398346,0.015423307195305824,0.0172278955578804,0.01908840425312519,0.018334830179810524,0.020238282158970833,0.01732170209288597,0.016378818079829216,0.016900017857551575,0.019370216876268387,0.017582010477781296,0.015901688486337662,0.014950182288885117,0.015227769501507282,0.01763995736837387,0.01570327766239643,0.014929666183888912,0.015959838405251503,0.01787971332669258,0.016954485327005386,0.017699534073472023,0.01573020964860916,0.01445070467889309,0.014974433928728104,0.016181176528334618,0.016164377331733704,0.01531178504228592,
mse,0.06556466221809387,0.010215593501925468,0.0035686716437339783,0.001630007871426642,0.0008753839647397399,0.0005343430093489587,0.0005620821029879153,0.0004770517407450825,0.0006234987522475421,0.0005893008201383054,0.0005029212916269898,0.0004647396272048354,0.0004340368905104697,0.0004320515727158636,0.0002615884004626423,0.00024253370065707713,0.00036679275217466056,0.00031753189978189766,0.0002498785324860364,0.0002709495020098984,0.000323856103932485,0.00023127874010242522,0.0002290714328410104,0.0002804296382237226,0.000294543948257342,0.00021374475909397006,0.00022285226441454142,0.0001870364649221301,0.0001438644976587966,0.000139055831823498,0.00016468744433950633,0.00012261499068699777,0.00014440325321629643,0.00014954204380046576,0.00022688224271405488,0.00020572534413076937,0.00016900166519917548,0.00014268529776018113,0.000135883194161579,0.0001274515816476196,0.00017720622417982668,0.0001777341094566509,0.00018218084005638957,0.00014009706501383334,0.00012600410263985395,0.00011152237857459113,0.00016456727462355047,0.00013155023043509573,0.00012154653086327016,0.00012704577238764614,0.00011166701006004587,0.00012907315976917744,9.99287876766175e-05,0.0001240622077602893,0.0001367937948089093,0.00011529723269632086,0.0001270122593268752,0.00010311243386240676,8.031874313019216e-05,7.584928971482441e-05,5.9200654504820704e-05,7.156168430810794e-05,0.00011181622539879754,0.00010706813191063702,8.947462629294023e-05,7.482673390768468e-05,6.780053809052333e-05,7.012760033831e-05,7.428628305206075e-05,6.503666372736916e-05,7.008398824837059e-05,7.863651990192011e-05,0.0001223144499817863,0.0001059100977727212,7.251798524521291e-05,8.828362479107454e-05,0.00010463725629961118,9.561722981743515e-05,0.00011935713700950146,8.446610445389524e-05,7.950884173624218e-05,8.576100663049147e-05,0.00010896899038925767,9.01532985153608e-05,7.371113315457478e-05,6.51804220979102e-05,7.009583350736648e-05,8.873364276951179e-05,7.124357216525823e-05,6.603110523428768e-05,7.554674084531143e-05,8.997853728942573e-05,8.319628250319511e-05,9.00139202713035e-05,7.106829434633255e-05,6.076036879676394e-05,6.589861732209101e-05,7.503672532038763e-05,7.639601972186938e-05,6.834678788436577e-05,
mae,0.1594603955745697,0.07112600654363632,0.045219551771879196,0.03163410723209381,0.02346678450703621,0.017382431775331497,0.018522681668400764,0.01710943505167961,0.019731000065803528,0.018955348059535027,0.017648251727223396,0.017145678400993347,0.01650019735097885,0.01631763018667698,0.012559772469103336,0.012012123130261898,0.015378895215690136,0.013958445750176907,0.012350431643426418,0.012989661656320095,0.013925994746387005,0.01198657602071762,0.011638935655355453,0.013442200608551502,0.013630347326397896,0.011672062799334526,0.011557523161172867,0.010818233713507652,0.009355273097753525,0.00916963443160057,0.00996694527566433,0.008525438606739044,0.009212684817612171,0.009344632737338543,0.012087528593838215,0.01137452945113182,0.010096934624016285,0.009362198412418365,0.008972871117293835,0.008636560291051865,0.010622669011354446,0.010721324943006039,0.010929811745882034,0.009151463396847248,0.008763330057263374,0.008293244056403637,0.009989181533455849,0.00913957878947258,0.008677278645336628,0.00879837479442358,0.008042304776608944,0.008946428075432777,0.007754305377602577,0.008721320889890194,0.009386330842971802,0.008453600108623505,0.00886999350041151,0.007875438779592514,0.006780032999813557,0.006620907690376043,0.006074461154639721,0.006405577529221773,0.008279533125460148,0.008296369574964046,0.0075449030846357346,0.006605674047023058,0.006249638739973307,0.006364049855619669,0.006543812341988087,0.006162117701023817,0.006424454972147942,0.006829021032899618,0.008746909908950329,0.00805426575243473,0.0065687368623912334,0.007248002104461193,0.008163957856595516,0.007723607588559389,0.008682736195623875,0.0073371692560613155,0.006934149656444788,0.007149344775825739,0.008151444606482983,0.0075033726170659065,0.006893842946738005,0.00645868293941021,0.00652740616351366,0.007512895856052637,0.006589971948415041,0.006278232205659151,0.006724589969962835,0.007546311244368553,0.007102838717401028,0.007404116913676262,0.006559418980032206,0.006072291638702154,0.006410001311451197,0.006814562249928713,0.006819280795753002,0.006471623200923204,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 136995    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 136996    
=================================================================
Total params: 273,991
Trainable params: 273,991
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 136,995
Trainable params: 136,995
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 136,996
Trainable params: 136,996
Non-trainable params: 0
_________________________________________________________________
