2021-06-26
loss,0.5594720840454102,0.10564324259757996,0.08326710015535355,0.07954540848731995,0.061444807797670364,0.05624806508421898,0.05355697125196457,0.052803169935941696,0.0469137541949749,0.04171112924814224,0.044113028794527054,0.03489222377538681,0.04030971601605415,0.035755082964897156,0.03885788843035698,0.03911693021655083,0.03716912865638733,0.03563351929187775,0.03762038052082062,0.034546464681625366,0.0342569462954998,0.03507740795612335,0.029043950140476227,0.029760338366031647,0.028622763231396675,0.026861343532800674,0.029927847906947136,0.026919029653072357,0.02367824874818325,0.0235876627266407,0.025405127555131912,0.024515481665730476,0.020833970978856087,0.025371866300702095,0.023992665112018585,0.022066039964556694,0.021133508533239365,0.024301717057824135,0.023955421522259712,0.021752528846263885,0.02128947339951992,0.021552909165620804,0.020081283524632454,0.01760420762002468,0.01690673641860485,0.019325338304042816,0.019185872748494148,0.01985493116080761,0.01983361691236496,0.01867234893143177,0.02035125531256199,0.019250063225626945,0.017181560397148132,0.0163651742041111,0.01939512975513935,0.019034450873732567,0.017523143440485,0.017294885590672493,0.016961881890892982,0.01731807179749012,0.017454341053962708,0.017649557441473007,0.016174228861927986,0.014840442687273026,0.016448205336928368,0.016453687101602554,0.015973076224327087,0.015225643292069435,0.016634393483400345,0.016700994223356247,0.0166618749499321,0.015765393152832985,0.014970063231885433,0.014399819076061249,0.01566242054104805,0.015031293965876102,0.014494615606963634,0.01646510511636734,0.014856492169201374,0.012880409136414528,0.016187500208616257,0.015852412208914757,0.016428763046860695,0.015082492493093014,0.014909442514181137,0.014069858007133007,0.013403804041445255,0.015768837183713913,0.01531466469168663,0.01483838353306055,0.014296097680926323,0.012425769120454788,0.012730095535516739,0.013659578748047352,0.015309816226363182,0.01477922685444355,0.014846623875200748,0.01325109601020813,0.012498023919761181,0.012819877825677395,
mse,0.16839244961738586,0.003870865097269416,0.002105647698044777,0.0019119968637824059,0.0011505108559504151,0.0009278275538235903,0.0008509100298397243,0.0007985999691300094,0.000638097058981657,0.0005247746594250202,0.0005727719981223345,0.0003641124349087477,0.00048225076170638204,0.0003903305041603744,0.0004472655418794602,0.00043603568337857723,0.0004102896782569587,0.00038828642573207617,0.00041989542660303414,0.0003592108259908855,0.0003426545881666243,0.0003441175213083625,0.00024989142548292875,0.00026153333601541817,0.00024077095440588892,0.0002167077036574483,0.00026377211906947196,0.00020951205806341022,0.0001678807893767953,0.00016638703527860343,0.00019215520296711475,0.00017182962619699538,0.0001297458802582696,0.00018850852211471647,0.0001682010042713955,0.0001420630724169314,0.0001314239198109135,0.00017331790877506137,0.00016088676056824625,0.00013751169899478555,0.0001344378397334367,0.00013208120071794838,0.00011561988503672183,9.170198609353974e-05,8.758160402067006e-05,0.00010972051677526906,0.00010745203326223418,0.00011463670671219006,0.00011546882888069376,0.0001017178874462843,0.00011758942855522037,0.0001053785890690051,8.673068805364892e-05,8.079070539679378e-05,0.00010788353392854333,0.00010022879723692313,8.837315544951707e-05,8.876847277861089e-05,8.552752115065232e-05,8.752183930482715e-05,8.792425796855241e-05,8.909117605071515e-05,7.530136645073071e-05,6.722488615196198e-05,7.943485979922116e-05,7.860000914661214e-05,7.520608050981537e-05,6.832528742961586e-05,8.007854921743274e-05,7.877413008827716e-05,7.911854481790215e-05,7.332829409278929e-05,6.559013127116486e-05,6.114583084126934e-05,7.081231888150796e-05,6.686669075861573e-05,6.270035373745486e-05,7.567454304080456e-05,6.236678746063262e-05,5.246927321422845e-05,7.724956958554685e-05,7.193491910584271e-05,7.546648703282699e-05,6.504057819256559e-05,6.410534115275368e-05,6.047455099178478e-05,5.4777930927230045e-05,7.005171937635168e-05,6.781151023460552e-05,6.276238127611578e-05,5.982175935059786e-05,4.682265716837719e-05,4.9980651965597644e-05,5.6289532949449494e-05,6.761390250176191e-05,6.141531048342586e-05,6.343490531435236e-05,5.134133971296251e-05,4.8100999265443534e-05,4.9482794565847144e-05,
mae,0.23495081067085266,0.045107364654541016,0.03533538058400154,0.034001924097537994,0.026310648769140244,0.023781612515449524,0.022617356851696968,0.022310087457299232,0.019928887486457825,0.017830030992627144,0.018628783524036407,0.014836045913398266,0.01718263514339924,0.015312297269701958,0.016564076766371727,0.016474096104502678,0.015797553583979607,0.015113827772438526,0.015833131968975067,0.014657093212008476,0.014594481326639652,0.014809489250183105,0.012308040633797646,0.012638983316719532,0.012073960155248642,0.011414116248488426,0.012690749019384384,0.011394276283681393,0.010092752054333687,0.009957453235983849,0.010846721939742565,0.01039074081927538,0.008824402466416359,0.01081380806863308,0.01014533918350935,0.009251007810235023,0.008888361044228077,0.01040466409176588,0.010142683982849121,0.009246534667909145,0.00895635411143303,0.009209106676280499,0.008688719011843204,0.00755548058077693,0.007261979393661022,0.00821513682603836,0.00818703044205904,0.008518196642398834,0.008407694287598133,0.007922422140836716,0.008640878833830357,0.008174993097782135,0.007284658960998058,0.006891177501529455,0.00825012568384409,0.007989211939275265,0.007498743943870068,0.007342800032347441,0.0072741322219371796,0.007371555082499981,0.007409971207380295,0.00751761207357049,0.006808639969676733,0.006333575118333101,0.006955891381949186,0.006920597981661558,0.00672647962346673,0.00646396866068244,0.007060145027935505,0.007054428569972515,0.007024276070296764,0.0067083630710840225,0.0064039104618132114,0.006062778178602457,0.006684354972094297,0.006397880148142576,0.006130914203822613,0.006875785067677498,0.006325652822852135,0.005494366865605116,0.0069284988567233086,0.006766693666577339,0.007004122249782085,0.006429831963032484,0.006379661615937948,0.005967103410512209,0.005637022200971842,0.006695662159472704,0.0064569259993731976,0.006267826072871685,0.006089797243475914,0.005217430181801319,0.005482321605086327,0.005877790041267872,0.006554198917001486,0.006211266387254,0.0063479309901595116,0.0056081535294651985,0.0053651356138288975,0.005432604346424341,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 99651     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 99652     
=================================================================
Total params: 199,303
Trainable params: 199,303
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 99,651
Trainable params: 99,651
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 99,652
Trainable params: 99,652
Non-trainable params: 0
_________________________________________________________________
