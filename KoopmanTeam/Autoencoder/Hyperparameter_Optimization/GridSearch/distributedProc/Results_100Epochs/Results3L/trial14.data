2021-06-26
loss,0.40366068482398987,0.1811288446187973,0.09549342095851898,0.07228722423315048,0.0629030242562294,0.05656767264008522,0.052334100008010864,0.04911646991968155,0.04589269310235977,0.043237634003162384,0.04055028036236763,0.037748564034700394,0.034865185618400574,0.0321907103061676,0.029872721061110497,0.027740102261304855,0.0265219584107399,0.025174666196107864,0.024581046774983406,0.023886149749159813,0.02311033569276333,0.02264435775578022,0.021980414167046547,0.021544765681028366,0.021136213093996048,0.020695770159363747,0.020274870097637177,0.020045746117830276,0.01975751481950283,0.01933423802256584,0.019214743748307228,0.018890440464019775,0.018709909170866013,0.01853547804057598,0.01814870908856392,0.01800876297056675,0.017868652939796448,0.017643636092543602,0.017526710405945778,0.017270024865865707,0.01712099090218544,0.01703817769885063,0.01687931828200817,0.016708465293049812,0.016605716198682785,0.016420258209109306,0.016328658908605576,0.016169561073184013,0.016114309430122375,0.015951571986079216,0.0158604234457016,0.01577296480536461,0.015667790547013283,0.015585334040224552,0.015430659987032413,0.015435061417520046,0.015243691392242908,0.015209836885333061,0.015081777237355709,0.015005948953330517,0.014914296567440033,0.014897298999130726,0.014843590557575226,0.014781568199396133,0.014624937437474728,0.014424488879740238,0.014632276259362698,0.014464981853961945,0.014391460455954075,0.0143566420301795,0.01426009088754654,0.014286463148891926,0.014189938083291054,0.014045249670743942,0.014120029285550117,0.01394786685705185,0.013980844989418983,0.013836068101227283,0.013872512616217136,0.013818008825182915,0.013751452788710594,0.013694796711206436,0.013651994056999683,0.013678517192602158,0.013542098924517632,0.013501460663974285,0.013420253060758114,0.013482755050063133,0.013429657556116581,0.013319486752152443,0.013327606953680515,0.01323552243411541,0.013245395384728909,0.013197511434555054,0.01317473966628313,0.013140562921762466,0.013116495683789253,0.013071605004370213,0.01297673862427473,0.013027907349169254,
mse,0.05689256265759468,0.011777167208492756,0.003161837114021182,0.0017951459158211946,0.0013838877202942967,0.0011594112729653716,0.001008795341476798,0.0008983334992080927,0.0007992375176399946,0.0007231358904391527,0.0006349147297441959,0.0005494926008395851,0.0004642544954549521,0.0003876144182868302,0.0003222736995667219,0.0002746374811977148,0.0002455602225381881,0.00022017312585376203,0.0002066687447950244,0.00019187451107427478,0.00018007740436587483,0.00016979561769403517,0.00015913331299088895,0.00015317005454562604,0.00014623510651290417,0.00013983892858959734,0.00013370331726036966,0.0001308350038016215,0.00012586875527631491,0.00012082022294634953,0.00011878945952048525,0.00011453992919996381,0.00011204804468434304,0.00010981029481627047,0.0001048534904839471,0.00010332092642784119,0.00010130256123375148,9.878226410364732e-05,9.702637908048928e-05,9.433209197595716e-05,9.225893154507503e-05,9.087073703994974e-05,8.949763287091628e-05,8.730514673516154e-05,8.600816363468766e-05,8.439491648459807e-05,8.293325663544238e-05,8.140607678797096e-05,8.069177420111373e-05,7.900588389020413e-05,7.79357214923948e-05,7.724998431513086e-05,7.572082540718839e-05,7.503534288844094e-05,7.348124199779704e-05,7.345441554207355e-05,7.162189285736531e-05,7.135220221243799e-05,6.989094254095107e-05,6.916857091709971e-05,6.884304457344115e-05,6.798266986152157e-05,6.743458652636036e-05,6.680381193291396e-05,6.550770194735378e-05,6.357093661790714e-05,6.548554665641859e-05,6.431991641875356e-05,6.321660475805402e-05,6.274488259805366e-05,6.192109867697582e-05,6.222224328666925e-05,6.122700142441317e-05,5.9880931075895205e-05,6.097870573285036e-05,5.921471893088892e-05,5.9096892073284835e-05,5.7964512961916625e-05,5.857681389898062e-05,5.7834982726490125e-05,5.731482451665215e-05,5.661012983182445e-05,5.63881330890581e-05,5.657448127749376e-05,5.531279384740628e-05,5.503660213435069e-05,5.439374945126474e-05,5.4872747568879277e-05,5.481974221765995e-05,5.304164733388461e-05,5.363066520658322e-05,5.250582762528211e-05,5.289564796839841e-05,5.237507139099762e-05,5.213971599005163e-05,5.185751797398552e-05,5.180152220418677e-05,5.141276778886095e-05,5.065915684099309e-05,5.1000020903302357e-05,
mae,0.17422044277191162,0.07848868519067764,0.040507517755031586,0.031270094215869904,0.027682719752192497,0.025108110159635544,0.023274188861250877,0.021736133843660355,0.02023918181657791,0.01897852122783661,0.017632201313972473,0.016271870583295822,0.014968439005315304,0.013765105977654457,0.012751595117151737,0.011827785521745682,0.011312680318951607,0.0107136694714427,0.010484060272574425,0.010194883681833744,0.009865702129900455,0.009659680537879467,0.009406204335391521,0.009189832955598831,0.009034528397023678,0.008829670958220959,0.008643034845590591,0.008525991812348366,0.008426498621702194,0.008256327360868454,0.008207350969314575,0.008045736700296402,0.007979385554790497,0.007905997335910797,0.007748371921479702,0.007655392866581678,0.007598006632179022,0.007478274870663881,0.007497803773730993,0.007371972780674696,0.007302704267203808,0.007273400202393532,0.007233423180878162,0.0071276272647082806,0.0070458995178341866,0.0070282332599163055,0.006952646188437939,0.006886748131364584,0.006839398760348558,0.006773180793970823,0.006717851851135492,0.006706622429192066,0.006651854608207941,0.006653409451246262,0.006550414487719536,0.006559131201356649,0.006527540273964405,0.006510305218398571,0.0064351921901106834,0.0063894204795360565,0.006313566118478775,0.006390034686774015,0.0063236551359295845,0.006297309882938862,0.0062425206415355206,0.00621016463264823,0.00626367749646306,0.006154556293040514,0.006109867710620165,0.006098462268710136,0.0060829962603747845,0.006088978610932827,0.005990017205476761,0.006005697883665562,0.006048991810530424,0.0058165728114545345,0.0059980531223118305,0.005886003840714693,0.005955809261649847,0.0058282120153307915,0.005859334487468004,0.00582293514162302,0.005841715261340141,0.005798560567200184,0.0057721505872905254,0.005768603179603815,0.005788025446236134,0.00573138240724802,0.005717725958675146,0.005648220889270306,0.005713058169931173,0.0056466334499418736,0.005679078865796328,0.005637618713080883,0.005619400646537542,0.005611002910882235,0.005612033419311047,0.005560295190662146,0.005522981286048889,0.005553944036364555,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2251      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2252      
=================================================================
Total params: 4,503
Trainable params: 4,503
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 2,251
Trainable params: 2,251
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 2,252
Trainable params: 2,252
Non-trainable params: 0
_________________________________________________________________
