2021-06-26
loss,0.3719189465045929,0.18998540937900543,0.10619799792766571,0.07247556746006012,0.05801539123058319,0.06063930690288544,0.05368523299694061,0.06248264014720917,0.06059853732585907,0.050281234085559845,0.05874427780508995,0.057997141033411026,0.04937082156538963,0.05548814684152603,0.050783224403858185,0.051317304372787476,0.05104333534836769,0.04522351920604706,0.03979467228055,0.03468197211623192,0.03312884643673897,0.03360465168952942,0.04448486492037773,0.04351501166820526,0.04210943356156349,0.0362098403275013,0.04101250693202019,0.03897556662559509,0.030258726328611374,0.031224023550748825,0.034421179443597794,0.033001236617565155,0.040790196508169174,0.035289160907268524,0.030878502875566483,0.02703072316944599,0.025873415172100067,0.0370069220662117,0.03170543164014816,0.03271012380719185,0.03237345069646835,0.026242852210998535,0.0322902537882328,0.02825780399143696,0.026583630591630936,0.025165768340229988,0.03423126041889191,0.028499944135546684,0.02800321765244007,0.030150657519698143,0.026682816445827484,0.02467001974582672,0.022990575060248375,0.020887212827801704,0.020990552380681038,0.028963694348931313,0.028400123119354248,0.0243351012468338,0.022212963551282883,0.02818819135427475,0.02552652172744274,0.024109289050102234,0.022676164284348488,0.02338164858520031,0.017201537266373634,0.014925028197467327,0.014732817187905312,0.014207993634045124,0.014057882130146027,0.013897934928536415,0.013898253440856934,0.013791467994451523,0.01374122779816389,0.013807808980345726,0.013730793260037899,0.013700336217880249,0.013667699880897999,0.01358603872358799,0.013460422866046429,0.013459482230246067,0.013479112647473812,0.013350987806916237,0.013346458785235882,0.013379519805312157,0.013315550051629543,0.01332075335085392,0.013152562081813812,0.013044068589806557,0.013086545281112194,0.012945996597409248,0.013018683530390263,0.012880180962383747,0.012972657568752766,0.012815836817026138,0.01278533972799778,0.012733452022075653,0.012647555209696293,0.012632743455469608,0.012590151280164719,0.012476073578000069,
mse,0.046506453305482864,0.012564687989652157,0.0033975630067288876,0.0015908480854704976,0.001036537578329444,0.0011003256076946855,0.0008787665283307433,0.0011954742949455976,0.001038778922520578,0.000741525727789849,0.0010281313443556428,0.0010134560288861394,0.0007289843051694334,0.0009136145818047225,0.0007572878967039287,0.0007507269037887454,0.0007691666251048446,0.0005844671395607293,0.0004569238517433405,0.0003442125453148037,0.00033263638033531606,0.0003269716107752174,0.0005939505062997341,0.0005751416902057827,0.0005109416670165956,0.00038760274765081704,0.0004915736499242485,0.00044135432108305395,0.00028199588996358216,0.0002895757497753948,0.00033859346876852214,0.00032447531702928245,0.00047434557927772403,0.0003645768156275153,0.0002734211157076061,0.00020879300427623093,0.00019538647029548883,0.000431731779826805,0.0003091015969403088,0.00030261315987445414,0.0002940869308076799,0.00019543057715054601,0.00030557074933312833,0.0002350521390326321,0.00021097046555951238,0.00019393675029277802,0.0003435378021094948,0.000238569249631837,0.00023385966778732836,0.00026231640367768705,0.00021719213691540062,0.00018156405712943524,0.0001567936851643026,0.0001349922240478918,0.0001367893855785951,0.00024069295614026487,0.00022966554388403893,0.0001753422402543947,0.00014754566655028611,0.0002195153501816094,0.00018565563368611038,0.00016817871073726565,0.00015309297305066139,0.0001699230633676052,9.258822683477774e-05,6.73849499435164e-05,6.33436138741672e-05,5.896690345252864e-05,5.830342342960648e-05,5.646155113936402e-05,5.669987149303779e-05,5.54148864466697e-05,5.5366443120874465e-05,5.529497138923034e-05,5.526882887352258e-05,5.415984560386278e-05,5.365471952245571e-05,5.421773676062003e-05,5.23719318152871e-05,5.1896717195631936e-05,5.3229327022563666e-05,5.222171239438467e-05,5.15033389092423e-05,5.1575563702499494e-05,5.200556915951893e-05,5.151340883458033e-05,5.0201324484078214e-05,4.902747969026677e-05,4.942696250509471e-05,4.850058030569926e-05,4.935016841045581e-05,4.8165242333197966e-05,4.8941466957330704e-05,4.763442120747641e-05,4.7352095862152055e-05,4.612695556716062e-05,4.6997851313790306e-05,4.5886416046414524e-05,4.6000895963516086e-05,4.50673651357647e-05,
mae,0.1576024442911148,0.08168580383062363,0.045429691672325134,0.03164093568921089,0.02531774528324604,0.025482546538114548,0.0234228428453207,0.026913657784461975,0.025593845173716545,0.021386660635471344,0.02501649595797062,0.02481880970299244,0.021235669031739235,0.02402329444885254,0.02212771587073803,0.022002076730132103,0.021938415244221687,0.01959313079714775,0.017012350261211395,0.014242857694625854,0.013900663703680038,0.013843447901308537,0.019159208983182907,0.01901698112487793,0.018483826890587807,0.015479803085327148,0.017399074509739876,0.01664232276380062,0.013006801716983318,0.013353929854929447,0.014260122552514076,0.013722763396799564,0.017885925248265266,0.015548736788332462,0.012690349481999874,0.01109942514449358,0.010818175971508026,0.01608663611114025,0.013832560740411282,0.014326410368084908,0.013696039095520973,0.01087380200624466,0.014116466045379639,0.012065776623785496,0.011144139803946018,0.010652064345777035,0.015099717304110527,0.012504632584750652,0.012129678390920162,0.012805495411157608,0.010865538381040096,0.010071308352053165,0.009551302529871464,0.00896425824612379,0.00898493081331253,0.01241865660995245,0.012333444319665432,0.010049695149064064,0.009126193821430206,0.012298689223825932,0.011093003675341606,0.010365639813244343,0.009724494069814682,0.010104471817612648,0.007379576098173857,0.006449833512306213,0.0064751459285616875,0.006219154689460993,0.0061638690531253815,0.006044634152203798,0.006049529183655977,0.005928101949393749,0.005867058411240578,0.00596834160387516,0.0058923326432704926,0.005870218388736248,0.0059283701702952385,0.005833941046148539,0.005772479344159365,0.005790141876786947,0.005748167168349028,0.005740446038544178,0.00567338801920414,0.005736848339438438,0.00574077945202589,0.005673267412930727,0.005639483220875263,0.005566329229623079,0.005554466973990202,0.005463057197630405,0.00549661461263895,0.005539102479815483,0.005553405731916428,0.005465161055326462,0.005452796351164579,0.0054825847037136555,0.005378131754696369,0.005385526455938816,0.005359062924981117,0.005314028821885586,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 35627     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 35628     
=================================================================
Total params: 71,255
Trainable params: 71,255
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 35,627
Trainable params: 35,627
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 35,628
Trainable params: 35,628
Non-trainable params: 0
_________________________________________________________________
