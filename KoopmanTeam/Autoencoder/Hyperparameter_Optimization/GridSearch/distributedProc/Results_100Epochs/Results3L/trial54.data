2021-06-26
loss,0.427325963973999,0.21099458634853363,0.13009846210479736,0.08499446511268616,0.08050219714641571,0.06343690305948257,0.0550047792494297,0.051871925592422485,0.05174636468291283,0.04412538930773735,0.03996431082487106,0.04201899841427803,0.03526366874575615,0.04482642188668251,0.03895158693194389,0.03303983062505722,0.03602346032857895,0.03404802829027176,0.029085850343108177,0.03177570179104805,0.03183463215827942,0.028676073998212814,0.027987653389573097,0.026054473593831062,0.025960808619856834,0.028021886944770813,0.027862215414643288,0.023152999579906464,0.02702714130282402,0.025178533047437668,0.02358107827603817,0.024274224415421486,0.020491356030106544,0.018684670329093933,0.01973137818276882,0.020963557064533234,0.021764621138572693,0.02299927920103073,0.022562438622117043,0.022078707814216614,0.02269047684967518,0.02115032449364662,0.020475024357438087,0.019768618047237396,0.018462447449564934,0.019238829612731934,0.016306612640619278,0.015780240297317505,0.019409533590078354,0.020570727065205574,0.01918785087764263,0.02050440013408661,0.017342746257781982,0.01774216815829277,0.01632620021700859,0.019171470776200294,0.019131848588585854,0.01822649873793125,0.017642119899392128,0.018371757119894028,0.0179181769490242,0.01783774048089981,0.018405234441161156,0.016794776543974876,0.017083024606108665,0.018065879121422768,0.016509458422660828,0.015004037879407406,0.015333069488406181,0.017944026738405228,0.017545126378536224,0.01697954721748829,0.015134218148887157,0.01601504534482956,0.016472848132252693,0.016749149188399315,0.014919048175215721,0.01552630215883255,0.016764989122748375,0.01651824079453945,0.016979556530714035,0.01705365628004074,0.014418301172554493,0.016137156635522842,0.015816722065210342,0.017124582082033157,0.015880506485700607,0.01540275290608406,0.014858794398605824,0.016437634825706482,0.015535911545157433,0.014397215098142624,0.014965176582336426,0.016163766384124756,0.015087056905031204,0.014262327924370766,0.015072914771735668,0.01557741779834032,0.014673670753836632,0.015068216249346733,
mse,0.0675613135099411,0.014009658247232437,0.005155947059392929,0.002090419176965952,0.0018461075378581882,0.0011382264783605933,0.0008669131784699857,0.0007732930243946612,0.0007917711045593023,0.000552631972823292,0.0004465416132006794,0.000500256079249084,0.000354655523551628,0.0006128370296210051,0.00043203032691963017,0.00032454179017804563,0.0003690187295433134,0.00032177355024032295,0.0002476257213857025,0.00028729529003612697,0.00028219292289577425,0.00023107111337594688,0.00022123794769868255,0.00019223614071961492,0.00019634104683063924,0.0002251820988021791,0.00022465563961304724,0.0001612195192137733,0.00020921783288940787,0.00017827408737502992,0.00016010209219530225,0.00017191434744745493,0.00012396881356835365,0.000104196609754581,0.00011824780085589737,0.0001283512101508677,0.00013782164023723453,0.0001508597342763096,0.00014415796613320708,0.00013568739814218134,0.00014558086695615202,0.0001266263279831037,0.00012037278065690771,0.00011607029591687024,0.00010097925405716524,0.00010841267794603482,7.888745312811807e-05,7.53484564484097e-05,0.00010926066170213744,0.00012060889275744557,0.00010499830386834219,0.00011693711712723598,8.938398241298273e-05,9.67130035860464e-05,8.060268010012805e-05,0.00010906799434451386,0.00010252392530674115,9.764233254827559e-05,9.133740968536586e-05,9.53394192038104e-05,9.270972805097699e-05,9.120321192312986e-05,9.517307626083493e-05,8.208930375985801e-05,8.697940211277455e-05,9.187162504531443e-05,7.952989835757762e-05,6.737314106430858e-05,7.040216587483883e-05,9.106341894948855e-05,8.539396367268637e-05,8.46714829094708e-05,6.747788575012237e-05,7.591603934997693e-05,7.83971045166254e-05,8.100637933239341e-05,6.44204264972359e-05,7.249000191222876e-05,8.188147330656648e-05,7.905394886620343e-05,8.295643056044355e-05,8.14712984720245e-05,6.154248694656417e-05,7.504864333895966e-05,7.210587500594556e-05,8.237134898081422e-05,7.124317926354706e-05,6.913567631272599e-05,6.378499529091641e-05,7.54430511733517e-05,6.840882997494191e-05,6.144728831714019e-05,6.52277740300633e-05,7.314759568544105e-05,6.548822420882061e-05,5.989567216602154e-05,6.564111390616745e-05,6.847405893495306e-05,6.16516190348193e-05,6.588530959561467e-05,
mae,0.18443700671195984,0.0898759663105011,0.05538494512438774,0.036566153168678284,0.03418369218707085,0.027130022644996643,0.023238396272063255,0.022220399230718613,0.021870052441954613,0.0186990387737751,0.017095739021897316,0.01787022314965725,0.015064483508467674,0.018973680213093758,0.016693582758307457,0.01413574256002903,0.015127468854188919,0.014479262754321098,0.012316401116549969,0.013485364615917206,0.013557362370193005,0.012144718319177628,0.011898879893124104,0.010889108292758465,0.011012044735252857,0.011861511506140232,0.011819113045930862,0.00985337421298027,0.011696669273078442,0.010757211595773697,0.010081367567181587,0.010140963830053806,0.00876099243760109,0.007965282537043095,0.008370297960937023,0.008818153291940689,0.009294713847339153,0.009888782165944576,0.009537918493151665,0.00924400333315134,0.009664453566074371,0.008983397856354713,0.00864587165415287,0.008360194973647594,0.00784542877227068,0.008153371512889862,0.006941851228475571,0.006711957510560751,0.008271101862192154,0.00869029387831688,0.008077607490122318,0.008738609030842781,0.007235261145979166,0.007498215418308973,0.006986504886299372,0.008225413039326668,0.008206687867641449,0.007764067500829697,0.007564270403236151,0.007693080231547356,0.0076151443645358086,0.007657771930098534,0.007744423113763332,0.007173457648605108,0.007305128034204245,0.0076266382820904255,0.007012626621872187,0.006355083081871271,0.006524141412228346,0.007509957067668438,0.007373492233455181,0.0071304310113191605,0.0064095621928572655,0.006775939837098122,0.007050848565995693,0.007025780621916056,0.006254434585571289,0.006602455396205187,0.007038600277155638,0.00696822814643383,0.007285593543201685,0.007224881090223789,0.00603695260360837,0.006803704891353846,0.006721032317727804,0.007420191075652838,0.006714499555528164,0.006479213945567608,0.006325927563011646,0.006865389179438353,0.006577227730304003,0.006051765754818916,0.006346775684505701,0.006744920741766691,0.006357470061630011,0.0060440064407885075,0.006405415944755077,0.0064865886233747005,0.006240784656256437,0.006411051377654076,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 66947     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 66948     
=================================================================
Total params: 133,895
Trainable params: 133,895
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 66,947
Trainable params: 66,947
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 66,948
Trainable params: 66,948
Non-trainable params: 0
_________________________________________________________________
