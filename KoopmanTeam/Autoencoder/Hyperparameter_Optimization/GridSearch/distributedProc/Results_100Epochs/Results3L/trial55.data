2021-06-26
loss,0.32026368379592896,0.21578435599803925,0.1041787788271904,0.05821623653173447,0.04523167759180069,0.03878170624375343,0.035538963973522186,0.03317289054393768,0.03155304491519928,0.030316026881337166,0.028831876814365387,0.028163321316242218,0.026933422312140465,0.026419512927532196,0.025695467367768288,0.025126928463578224,0.024480579420924187,0.023931939154863358,0.023549729958176613,0.028950583189725876,0.03188711777329445,0.0278373584151268,0.026471715420484543,0.038095857948064804,0.0315602570772171,0.028504054993391037,0.026704488322138786,0.02469700574874878,0.022960549220442772,0.02696904167532921,0.027581626549363136,0.02517786994576454,0.02408708818256855,0.041407402604818344,0.03794240579009056,0.03560983017086983,0.03373183310031891,0.030523182824254036,0.02561631239950657,0.023372167721390724,0.022175952792167664,0.021304016932845116,0.02066466026008129,0.025650467723608017,0.035523708909749985,0.0329076386988163,0.031179601326584816,0.030043594539165497,0.028719652444124222,0.02575835771858692,0.02339644730091095,0.021952440962195396,0.020874813199043274,0.020033102482557297,0.01950276456773281,0.01886533573269844,0.018213683739304543,0.017849240452051163,0.030022041872143745,0.030234262347221375,0.028049273416399956,0.02898288704454899,0.02751718834042549,0.024331150576472282,0.02068062126636505,0.017215151339769363,0.024579139426350594,0.02688617631793022,0.025675328448414803,0.023234177380800247,0.020694982260465622,0.019446799531579018,0.01880601793527603,0.017964983358979225,0.017533615231513977,0.022041862830519676,0.027600696310400963,0.026080071926116943,0.024827012792229652,0.023638758808374405,0.02099117450416088,0.018833555281162262,0.01954493671655655,0.021356865763664246,0.019946644082665443,0.018606895580887794,0.0176997072994709,0.017100851982831955,0.016694121062755585,0.015901712700724602,0.025270655751228333,0.025211920961737633,0.023923594504594803,0.02286137081682682,0.021872282028198242,0.02006416767835617,0.018792279064655304,0.017741292715072632,0.017142122611403465,0.022436438128352165,
mse,0.036039285361766815,0.016968555748462677,0.004068069625645876,0.0010990523733198643,0.0006492726970463991,0.0004749493964482099,0.0003949175006709993,0.0003399320412427187,0.00030624622013419867,0.0002805187541525811,0.0002546885807532817,0.00024225401284638792,0.00022086458920966834,0.00021309383737388998,0.00020077565568499267,0.00019072461873292923,0.00018104456830769777,0.0001734371908241883,0.0001692646328592673,0.00026942684780806303,0.00029156196978874505,0.0002308844996150583,0.00021204624499659985,0.0004085678665433079,0.0002847664291039109,0.00023638136917725205,0.0002101381542161107,0.0001839552860474214,0.00016569707076996565,0.0002147343329852447,0.0002233411796623841,0.00018915027612820268,0.0001773872209014371,0.0004920268547721207,0.00042092290823347867,0.0003688267315737903,0.00033120610169135034,0.00026363483630120754,0.00019278241961728781,0.0001640577829675749,0.0001492154988227412,0.00013880366168450564,0.0001308210048591718,0.0002077863027807325,0.0003660993243101984,0.00031674213823862374,0.000286424154182896,0.00026195376995019615,0.00023559007968287915,0.0001907802070491016,0.00016038161993492395,0.0001436540624126792,0.00013165027485229075,0.0001221418206114322,0.00011642205208772793,0.00010825494973687455,0.00010133515752386302,9.914483962347731e-05,0.00026714758132584393,0.0002644485211931169,0.00023608583433087915,0.00024039280833676457,0.0002179992152377963,0.00017477177607361227,0.0001333801046712324,9.549170499667525e-05,0.00018308789003640413,0.0002071500348392874,0.00019125500693917274,0.00015797186642885208,0.00012792951019946486,0.00011347603867761791,0.00010714853124227375,9.857671102508903e-05,9.438363485969603e-05,0.00015047260967548937,0.00022011045075487345,0.00019600597443059087,0.00017897695943247527,0.00016174704069271684,0.00012996201985515654,0.00010379879677202553,0.00011675394489429891,0.0001278780837310478,0.00011417584755690768,0.0001012405555229634,9.218100603902712e-05,8.705788059160113e-05,8.321952191181481e-05,7.74816726334393e-05,0.00018291646847501397,0.00018033749074675143,0.0001649292535148561,0.00014942919369786978,0.00013593000767286867,0.00011564031592570245,0.00010323242895537987,9.2969712568447e-05,8.679647726239637e-05,0.00014730340626556426,
mae,0.1420547217130661,0.09957048296928406,0.044713329523801804,0.024311667308211327,0.01886451058089733,0.016195282340049744,0.014834601432085037,0.014080129563808441,0.013412526808679104,0.012808066792786121,0.012177962809801102,0.011819467879831791,0.011447765864431858,0.011262428015470505,0.010832768864929676,0.010625774972140789,0.010340947657823563,0.01010305155068636,0.010004104115068913,0.012198071926832199,0.013408896513283253,0.011809122748672962,0.01128575298935175,0.016055678948760033,0.013414054177701473,0.012080749496817589,0.011465171352028847,0.01061927992850542,0.00970167014747858,0.011420168913900852,0.011728613637387753,0.010784086771309376,0.010152173228561878,0.01767721213400364,0.016184931620955467,0.01525303814560175,0.014282439835369587,0.012613858096301556,0.011140763759613037,0.009903070516884327,0.009406615048646927,0.00907419715076685,0.00883476436138153,0.011029553599655628,0.015215598046779633,0.014156273566186428,0.01338742021471262,0.012820431031286716,0.012051698751747608,0.011025309562683105,0.01015254482626915,0.00941898487508297,0.008905444294214249,0.00861464161425829,0.008460263721644878,0.008271321654319763,0.007969643920660019,0.007585030049085617,0.012803992256522179,0.01320795901119709,0.011692652478814125,0.012446422129869461,0.012005163356661797,0.010737486183643341,0.008680892176926136,0.007275525946170092,0.010426963679492474,0.011417987756431103,0.011208009906113148,0.010244959965348244,0.008690428920090199,0.008140205405652523,0.00792142003774643,0.007645010482519865,0.00750944297760725,0.009334545582532883,0.011516135185956955,0.010906005278229713,0.010478346608579159,0.010199734009802341,0.008805731311440468,0.008052493445575237,0.008267173543572426,0.008953946642577648,0.008426427841186523,0.007612171117216349,0.007388059049844742,0.007224207744002342,0.007036329712718725,0.006759247276932001,0.010385139845311642,0.010354522615671158,0.009843667037785053,0.009442203678190708,0.008562451228499413,0.008195105940103531,0.007807399146258831,0.007816031575202942,0.007500487379729748,0.00977892056107521,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8779      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8780      
=================================================================
Total params: 17,559
Trainable params: 17,559
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 8,779
Trainable params: 8,779
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 8,780
Trainable params: 8,780
Non-trainable params: 0
_________________________________________________________________
