2021-06-26
loss,0.3591458797454834,0.09970970451831818,0.06653302907943726,0.0754142627120018,0.0602564662694931,0.04885169118642807,0.05152153968811035,0.04825077950954437,0.05299067869782448,0.05553699657320976,0.042684659361839294,0.03362274169921875,0.04054683819413185,0.0381309874355793,0.030720796436071396,0.03168610483407974,0.03513925150036812,0.03516015410423279,0.03803841397166252,0.04296216368675232,0.031017832458019257,0.02976246550679207,0.035896025598049164,0.03772057220339775,0.03251854330301285,0.030747272074222565,0.027325015515089035,0.028628025203943253,0.032149769365787506,0.023496897891163826,0.026374315842986107,0.03125644102692604,0.028214726597070694,0.022179221734404564,0.022270141169428825,0.028890423476696014,0.027623681351542473,0.02837793342769146,0.024162180721759796,0.023671291768550873,0.020240746438503265,0.02116941288113594,0.022271154448390007,0.02138037048280239,0.019798846915364265,0.01973085291683674,0.023490378633141518,0.02191685512661934,0.021579522639513016,0.01943843625485897,0.01729295775294304,0.023613102734088898,0.02191416174173355,0.015910202637314796,0.015083623118698597,0.016618091613054276,0.024315372109413147,0.020222526043653488,0.01782989874482155,0.016631850972771645,0.017125427722930908,0.018301939591765404,0.019634077325463295,0.01932569406926632,0.019666440784931183,0.018735598772764206,0.017220167443156242,0.015891581773757935,0.01452020276337862,0.013579238206148148,0.013231061398983002,0.018491309136152267,0.017430504783988,0.01562768965959549,0.014119788073003292,0.014977646060287952,0.02018221840262413,0.016696538776159286,0.014641445130109787,0.017270565032958984,0.01702689379453659,0.015247984789311886,0.01775531657040119,0.015385584905743599,0.013003628700971603,0.011831676587462425,0.013322068378329277,0.015331137925386429,0.01684655249118805,0.016717901453375816,0.01638142392039299,0.01620846800506115,0.014480318874120712,0.014755588956177235,0.013804649002850056,0.013138500042259693,0.014436790719628334,0.015422672964632511,0.013517274521291256,0.013301068916916847,
mse,0.06739915907382965,0.003101177280768752,0.0013388149673119187,0.0016515892930328846,0.001046972000040114,0.0006934055127203465,0.0007759588188491762,0.000699210911989212,0.0008458034135401249,0.0009001594735309482,0.0005583156016655266,0.00032944275881163776,0.0005000208038836718,0.000416258058976382,0.0002759520139079541,0.00030713959131389856,0.0003593427827581763,0.0003555561706889421,0.0004174682835582644,0.0005311375134624541,0.00029130055918358266,0.0002611681120470166,0.00036715713213197887,0.0004034369485452771,0.0003109325189143419,0.0002706034283619374,0.00022474840807262808,0.00024504418252035975,0.0002934083458967507,0.00016513020091224462,0.00020504416897892952,0.0002762924414128065,0.0002328452974325046,0.00014536292292177677,0.00014765729429200292,0.00023884679831098765,0.0002166882186429575,0.00023025945120025426,0.00016346279880963266,0.00015894390526227653,0.00012506009079515934,0.00013537047198042274,0.00014391350850928575,0.00013195036444813013,0.0001142519322456792,0.00011603620805544779,0.00015180422633420676,0.00013738898269366473,0.000132466055219993,0.00010746646876214072,9.110493556363508e-05,0.00015891483053565025,0.00014177920820657164,7.799606100888923e-05,6.82802201481536e-05,8.321321365656331e-05,0.00016599455557297915,0.00011573552183108404,9.245619003195316e-05,8.278855966636911e-05,8.475944196106866e-05,9.728847362566739e-05,0.00010807856597239152,0.00010360547457821667,0.00010867257515201345,9.869338828139007e-05,8.252705447375774e-05,7.30250685592182e-05,6.279852823354304e-05,5.595238326350227e-05,5.380574657465331e-05,9.522768959868699e-05,8.814739703666419e-05,7.0940688601695e-05,6.147734529804438e-05,6.73126196488738e-05,0.00011299268953735009,8.189452637452632e-05,6.243924872251227e-05,8.691623224876821e-05,8.491371409036219e-05,6.882241723360494e-05,8.8662447524257e-05,6.871653749840334e-05,5.111383870826103e-05,4.27581398980692e-05,5.463768320623785e-05,6.796960951760411e-05,7.941530202515423e-05,7.731886580586433e-05,7.629418541910127e-05,7.592939800815657e-05,6.0554240917554125e-05,6.378391844918951e-05,5.6474265875294805e-05,5.134959064889699e-05,6.062469765311107e-05,6.777376984246075e-05,5.326220707502216e-05,5.25848736288026e-05,
mae,0.15502700209617615,0.04230878874659538,0.02846084162592888,0.031568292528390884,0.025567764416337013,0.02072819322347641,0.021912194788455963,0.020574823021888733,0.022293364629149437,0.023165471851825714,0.018137251958251,0.014249180443584919,0.01702568493783474,0.016300715506076813,0.013079073280096054,0.013633986935019493,0.015019812621176243,0.014996211975812912,0.016127226874232292,0.018246931955218315,0.0132614029571414,0.012535251677036285,0.01511526107788086,0.016142588108778,0.013689161278307438,0.012997603043913841,0.011601369827985764,0.012090886943042278,0.013729034923017025,0.009997119195759296,0.011010656133294106,0.013223712332546711,0.012002438306808472,0.009365676902234554,0.009282972663640976,0.012086000293493271,0.011645561084151268,0.011968311853706837,0.010295803658664227,0.010004458017647266,0.00858778040856123,0.008996994234621525,0.009457971900701523,0.009152588434517384,0.008449438959360123,0.008358664810657501,0.009908280335366726,0.00926221814006567,0.00918814167380333,0.008420375175774097,0.0073996945284307,0.010069068521261215,0.009315185248851776,0.00678225327283144,0.006449528504163027,0.007103188429027796,0.01029540691524744,0.008544698357582092,0.007581409066915512,0.007008820306509733,0.007198629900813103,0.007761891931295395,0.008323297835886478,0.008156430907547474,0.008284163661301136,0.007932847365736961,0.007334036286920309,0.00675546657294035,0.006179980468004942,0.005825187545269728,0.005632380954921246,0.00785790290683508,0.007349937688559294,0.006575918290764093,0.0060149384662508965,0.0063835326582193375,0.008553936146199703,0.007107066921889782,0.006232372485101223,0.007340885233134031,0.007189576048403978,0.006475223693996668,0.007555574644356966,0.0065892543643713,0.005542744416743517,0.005069952458143234,0.005653760861605406,0.006450111046433449,0.007082324009388685,0.007004003971815109,0.006996471434831619,0.006815737579017878,0.006097606383264065,0.006295659579336643,0.005807934794574976,0.005558484699577093,0.0061401622369885445,0.006501695141196251,0.005596457049250603,0.005672333762049675,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 74947     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 74948     
=================================================================
Total params: 149,895
Trainable params: 149,895
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 74,947
Trainable params: 74,947
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 74,948
Trainable params: 74,948
Non-trainable params: 0
_________________________________________________________________
