2021-06-26
loss,0.3457575738430023,0.11931189894676208,0.09628527611494064,0.06195957586169243,0.04926637187600136,0.037858907133340836,0.05211877450346947,0.044975873082876205,0.04752182587981224,0.03918393701314926,0.045033227652311325,0.04118815436959267,0.03753117099404335,0.032778069376945496,0.03463353216648102,0.037296172231435776,0.03315417096018791,0.03466903790831566,0.03573106229305267,0.03745466098189354,0.0350513719022274,0.02999190241098404,0.030392222106456757,0.031532905995845795,0.03316974267363548,0.028612622991204262,0.026158275082707405,0.021220967173576355,0.0290844663977623,0.025696586817502975,0.021116970106959343,0.021991031244397163,0.02793884091079235,0.02663988061249256,0.026713330298662186,0.029797423630952835,0.026165509596467018,0.026384884491562843,0.02563517726957798,0.026022976264357567,0.025421252474188805,0.02705470286309719,0.02547142468392849,0.023142023012042046,0.02326923795044422,0.024439888074994087,0.02658601850271225,0.02398529276251793,0.02297940105199814,0.0216841958463192,0.023482365533709526,0.02044740691781044,0.02141360007226467,0.024380702525377274,0.020454134792089462,0.016516221687197685,0.015195838175714016,0.019053656607866287,0.0206475667655468,0.02155480347573757,0.02306138351559639,0.021047625690698624,0.021583985537290573,0.02297847904264927,0.020680779591202736,0.0221405029296875,0.020833265036344528,0.019393570721149445,0.018462231382727623,0.01766873151063919,0.01700587198138237,0.016300374642014503,0.016316451132297516,0.017042383551597595,0.014658413827419281,0.01902235671877861,0.02075762115418911,0.01963813230395317,0.018177682533860207,0.01734340190887451,0.01734665222465992,0.01751658134162426,0.016045035794377327,0.016576940193772316,0.020917043089866638,0.01984315551817417,0.01772184669971466,0.016109799966216087,0.015037703327834606,0.014349191449582577,0.013499628752470016,0.012409206479787827,0.012270791456103325,0.014545307494699955,0.017505090683698654,0.018681379035115242,0.017635276541113853,0.01698143407702446,0.01793484203517437,0.016373658552765846,
mse,0.045158348977565765,0.0050039393827319145,0.003049666527658701,0.001128880656324327,0.000704726786352694,0.0004162812838330865,0.0008283542701974511,0.0006024232134222984,0.0006487395148724318,0.0004408368549775332,0.0005922812852077186,0.0004799565940629691,0.0003958052839152515,0.00031515531009063125,0.0003623309312388301,0.0003917511203326285,0.0003242343373131007,0.0003383076109457761,0.00036742573138326406,0.0003975871077273041,0.0003441299486439675,0.0002581083099357784,0.00026732494006864727,0.0002868911251425743,0.00030608533415943384,0.00023845740361139178,0.00020179146667942405,0.0001370008394587785,0.00024193915305659175,0.00019856711151078343,0.00013493013102561235,0.00014414696488529444,0.00022165742120705545,0.00021435448434203863,0.00021685434330720454,0.0002552974910940975,0.00019239891844335943,0.00019552119192667305,0.0001875646412372589,0.00019108271226286888,0.00018271901353728026,0.00020851835142821074,0.00018620077753439546,0.00015285180415958166,0.00015603804786223918,0.00016881206829566509,0.00019405351486057043,0.00016000181494746357,0.00015068337961565703,0.00013712474901694804,0.0001568305742694065,0.00012576552398968488,0.00013294973177835345,0.00016457268793601543,0.00012156195589341223,8.344613888766617e-05,6.781704723834991e-05,0.00010914415179286152,0.00012474710820242763,0.00013200761168263853,0.0001503719249740243,0.00012775504728779197,0.00013054758892394602,0.00014626629126723856,0.00012204452650621533,0.00013632529589813203,0.0001247882901225239,0.00010741582082118839,9.743755799718201e-05,8.912375778891146e-05,8.431114110862836e-05,7.736579573247582e-05,8.197930583264679e-05,8.853161853039637e-05,6.491917156381533e-05,0.00010894265142269433,0.00012192552821943536,0.00011061563418479636,9.726925782160833e-05,8.902107219910249e-05,8.762061770539731e-05,8.930751937441528e-05,7.54707507439889e-05,7.992168684722856e-05,0.00012342714762780815,0.00011093547800555825,8.951495692599565e-05,7.424813520628959e-05,6.585493974853307e-05,6.078462683944963e-05,5.405979754868895e-05,4.5258373575052246e-05,4.490440551307984e-05,6.369328912114725e-05,8.795000030659139e-05,9.983464406104758e-05,8.638004510430619e-05,8.021390385692939e-05,8.927442831918597e-05,7.727699994575232e-05,
mae,0.14766287803649902,0.05115629732608795,0.04066138342022896,0.02605029195547104,0.021091878414154053,0.016069898381829262,0.022037457674741745,0.018653232604265213,0.019958559423685074,0.016451360657811165,0.01898401789367199,0.017207441851496696,0.015833580866456032,0.013919484801590443,0.014696656726300716,0.015805227681994438,0.013966703787446022,0.014644713141024113,0.01536980364471674,0.016086237505078316,0.014823797158896923,0.012662358582019806,0.012760940939188004,0.013378666713833809,0.01422189548611641,0.012087074108421803,0.011127534322440624,0.009017358534038067,0.012263906188309193,0.01115860790014267,0.009017796255648136,0.009311521425843239,0.011826641857624054,0.011199699714779854,0.011387207545340061,0.013125517405569553,0.011095564812421799,0.011012929491698742,0.010601062327623367,0.011046875268220901,0.010854687541723251,0.011390591971576214,0.010703632608056068,0.009779288433492184,0.009818650782108307,0.010160657577216625,0.01130592729896307,0.010128477588295937,0.009840581566095352,0.009157580323517323,0.009976652450859547,0.008716732263565063,0.009090803563594818,0.010280712507665157,0.008699358440935612,0.006944513879716396,0.006407186854630709,0.008069143630564213,0.008716192096471786,0.009194852784276009,0.00985043216496706,0.008823971264064312,0.00915493629872799,0.00976664386689663,0.008623888716101646,0.009527718648314476,0.008901613764464855,0.008226935751736164,0.007929079234600067,0.007612813264131546,0.007499996572732925,0.007182095665484667,0.007052193861454725,0.007363342214375734,0.006287789903581142,0.00782967172563076,0.008754606358706951,0.008370568975806236,0.007842883467674255,0.007295825053006411,0.007345922756940126,0.00741837453097105,0.006824873853474855,0.00703532574698329,0.008990895934402943,0.008602360263466835,0.007618041709065437,0.006777257192879915,0.00633225217461586,0.006052318029105663,0.0057360888458788395,0.005248048808425665,0.005187132395803928,0.006162480916827917,0.007441272959113121,0.008054467849433422,0.007284599356353283,0.007032616529613733,0.007574060000479221,0.006848527118563652,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25251     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25252     
=================================================================
Total params: 50,503
Trainable params: 50,503
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 25,251
Trainable params: 25,251
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 25,252
Trainable params: 25,252
Non-trainable params: 0
_________________________________________________________________
