2021-06-26
loss,0.4625072181224823,0.1361059695482254,0.09793011844158173,0.06705351918935776,0.07440205663442612,0.06726164370775223,0.05932579189538956,0.047216080129146576,0.04712168872356415,0.051408976316452026,0.05215352401137352,0.04467748478055,0.04206044226884842,0.04242851585149765,0.042941976338624954,0.043749939650297165,0.04052000865340233,0.03862018883228302,0.04060571640729904,0.030843207612633705,0.03417254239320755,0.028443053364753723,0.032125137746334076,0.031643204391002655,0.03456069156527519,0.0344393290579319,0.02820776216685772,0.031245412304997444,0.026771867647767067,0.02778262086212635,0.0334436260163784,0.028048807755112648,0.025174736976623535,0.027390290051698685,0.02549579367041588,0.02865196205675602,0.027570871636271477,0.02514827437698841,0.026391858235001564,0.0244391318410635,0.023885559290647507,0.026669993996620178,0.022747717797756195,0.01966916397213936,0.01930776797235012,0.01759089156985283,0.018305517733097076,0.019133128225803375,0.021831505000591278,0.021312152966856956,0.022827669978141785,0.022681480273604393,0.01927408017218113,0.01664056070148945,0.018889442086219788,0.02200213260948658,0.02293385937809944,0.021003451198339462,0.0209954921156168,0.01939975842833519,0.01699642837047577,0.016728244721889496,0.020085107535123825,0.019355151802301407,0.01750442199409008,0.016490746289491653,0.017676793038845062,0.019575364887714386,0.01859193481504917,0.01794685423374176,0.018029632046818733,0.01762005127966404,0.01604577712714672,0.013247950002551079,0.014413218945264816,0.015142135322093964,0.017128098756074905,0.01781468279659748,0.0161750428378582,0.016902627423405647,0.01653026044368744,0.01644221693277359,0.016529005020856857,0.015514129772782326,0.01637519709765911,0.015044399537146091,0.014496398158371449,0.014448833651840687,0.01475281361490488,0.013185100629925728,0.013609716668725014,0.014951784163713455,0.017342757433652878,0.01591680571436882,0.01543849240988493,0.01654447242617607,0.01519796159118414,0.014465026557445526,0.013532400131225586,0.012467077933251858,
mse,0.09195110946893692,0.005535973701626062,0.0028877598233520985,0.001319944392889738,0.0016269722254946828,0.001317668124102056,0.001006288337521255,0.0006396759417839348,0.0006822344148531556,0.0008119772537611425,0.0007789460360072553,0.0005781124345958233,0.000538115797098726,0.0005289770197123289,0.0005539763951674104,0.0005628656363114715,0.0005013059708289802,0.0004473421722650528,0.0004680932324845344,0.0002919425314757973,0.00033935665851458907,0.0002468566526658833,0.0003078627632930875,0.00030552566749975085,0.0003503834013827145,0.00034968749969266355,0.0002381161175435409,0.00030000339029356837,0.00021824917348567396,0.00022956622706260532,0.00031353943631984293,0.0002203620388172567,0.00018495651602279395,0.00021662592189386487,0.00019469739345367998,0.00024238998594228178,0.00021866914175916463,0.000184125907253474,0.00020739230967592448,0.00018119819287676364,0.00017077424854505807,0.0001974007609533146,0.00014503454440273345,0.00011447002179920673,0.00011390867439331487,9.133302955888212e-05,0.00010065324022434652,0.000110170069092419,0.00013881351333111525,0.00013123280950821936,0.0001536696363473311,0.00014800131611991674,0.00011038816592190415,8.34711900097318e-05,0.0001087499622371979,0.00014221837045624852,0.0001482768711866811,0.0001246201863978058,0.00012154807336628437,0.0001062326628016308,8.813393651507795e-05,8.701785554876551e-05,0.00011461780377430841,0.00010891849524341524,9.109901293413714e-05,8.118715777527541e-05,9.243020031135529e-05,0.00010815051064128056,9.771984332473949e-05,9.029413922689855e-05,8.997444820124656e-05,8.985250315163285e-05,7.698254194110632e-05,5.3760497394250706e-05,6.336144724627957e-05,6.857998960185796e-05,8.312739373650402e-05,8.816698391456157e-05,7.634831854375079e-05,8.165404142346233e-05,7.860112236812711e-05,7.709288183832541e-05,7.607600855408236e-05,6.936446152394637e-05,7.705928874202073e-05,6.613305595237762e-05,6.226060213521123e-05,6.166582170408219e-05,6.337707600323483e-05,5.2283947297837585e-05,5.597109338850714e-05,6.596420280402526e-05,8.463482663501054e-05,7.1826929342933e-05,6.704272527713329e-05,7.644894503755495e-05,6.648650742135942e-05,6.086652501835488e-05,5.432348189060576e-05,4.730249202111736e-05,
mae,0.19842985272407532,0.057447649538517,0.042364686727523804,0.028697995468974113,0.03172162175178528,0.028852971270680428,0.02577929012477398,0.02008357085287571,0.020092643797397614,0.02213236875832081,0.022420695051550865,0.019041333347558975,0.017956264317035675,0.018237847834825516,0.018153218552470207,0.018565841019153595,0.017106540501117706,0.01659858226776123,0.017221873626112938,0.013177863322198391,0.014626392163336277,0.012186134234070778,0.013764869421720505,0.013396956957876682,0.015014766715466976,0.014709195122122765,0.011718806810677052,0.013070791959762573,0.011447081342339516,0.01182139664888382,0.01433652639389038,0.011814095079898834,0.010679563507437706,0.011774225160479546,0.01076958142220974,0.012308475561439991,0.011884784325957298,0.010732238180935383,0.011267637833952904,0.010425492189824581,0.010064602829515934,0.011201882734894753,0.009681337513029575,0.008321238681674004,0.008291195146739483,0.007474647834897041,0.007813974283635616,0.008131299167871475,0.009293395094573498,0.009064425714313984,0.009599113836884499,0.00946502760052681,0.008076622150838375,0.007093039341270924,0.008005437441170216,0.009466733783483505,0.009871955960988998,0.008978795260190964,0.008812843821942806,0.00827148649841547,0.007379262242466211,0.007146207615733147,0.00851693470031023,0.008273766376078129,0.007422181777656078,0.006996444892138243,0.007508048787713051,0.008431429043412209,0.007959323935210705,0.00759870745241642,0.007600471843034029,0.0075468928553164005,0.006786579266190529,0.005587907508015633,0.006107935216277838,0.006391271483153105,0.007206552661955357,0.007520296145230532,0.006858719512820244,0.0071578603237867355,0.007001981604844332,0.006974049378186464,0.006847022101283073,0.006651976611465216,0.007032288704067469,0.0064090401865541935,0.006137250456959009,0.006136742886155844,0.006306139286607504,0.005591887980699539,0.005679004825651646,0.006328179966658354,0.0073625813238322735,0.006682076957076788,0.006518866866827011,0.007071643602102995,0.006387140601873398,0.006157795898616314,0.005724649410694838,0.0052559711039066315,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 83107     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 83108     
=================================================================
Total params: 166,215
Trainable params: 166,215
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 83,107
Trainable params: 83,107
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 83,108
Trainable params: 83,108
Non-trainable params: 0
_________________________________________________________________
