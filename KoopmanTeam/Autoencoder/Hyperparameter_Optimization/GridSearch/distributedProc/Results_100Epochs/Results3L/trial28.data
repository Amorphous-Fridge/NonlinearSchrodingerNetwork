2021-06-26
loss,0.3173392415046692,0.13515108823776245,0.07315103709697723,0.06611281633377075,0.05863025039434433,0.07586703449487686,0.05669442564249039,0.054215941578149796,0.07073274999856949,0.06595200300216675,0.05243575945496559,0.0500115267932415,0.048802539706230164,0.044172145426273346,0.04569847509264946,0.04246190935373306,0.04267849028110504,0.04276229441165924,0.03732874244451523,0.03204215690493584,0.029614867642521858,0.024435129016637802,0.0339474231004715,0.03302529454231262,0.02953660674393177,0.027920415624976158,0.033685967326164246,0.03807618468999863,0.03837248682975769,0.038302116096019745,0.0333564355969429,0.029040811583399773,0.028886018320918083,0.03984609991312027,0.035766273736953735,0.03027249127626419,0.027081074193120003,0.02618769370019436,0.03464392572641373,0.03598206862807274,0.028733082115650177,0.027128048241138458,0.031092720106244087,0.027104567736387253,0.024434641003608704,0.023160262033343315,0.022083347663283348,0.024752678349614143,0.0341765433549881,0.027677049860358238,0.027898311614990234,0.033738087862730026,0.030936844646930695,0.029426317662000656,0.026791341602802277,0.02399813011288643,0.022405065596103668,0.02106933854520321,0.022056059911847115,0.02988157980144024,0.028530992567539215,0.02496773935854435,0.02284972369670868,0.021123962476849556,0.020890498533844948,0.028521878644824028,0.028018327429890633,0.02511122263967991,0.021353790536522865,0.020216045901179314,0.019077204167842865,0.022202681750059128,0.023143034428358078,0.021337458863854408,0.01991729624569416,0.018963519483804703,0.018783848732709885,0.024874575436115265,0.026711903512477875,0.02753041498363018,0.025122540071606636,0.022470111027359962,0.016108395531773567,0.01348581537604332,0.013632301241159439,0.013362233527004719,0.013173081912100315,0.012918523512780666,0.012996294535696507,0.012670980766415596,0.012870091013610363,0.01268122810870409,0.012631919234991074,0.012677159160375595,0.012646780349314213,0.012575370259582996,0.012581349350512028,0.014329061843454838,0.017756495624780655,0.022362904623150826,
mse,0.03992588073015213,0.006374826654791832,0.0016509431879967451,0.0013462582137435675,0.0009662972297519445,0.0016445842338725924,0.0009149592951871455,0.000847391493152827,0.001546188141219318,0.0012244150275364518,0.0007800438324920833,0.000701216806191951,0.0006784210563637316,0.0005587644409388304,0.0006013484089635313,0.0005051119369454682,0.0005275375442579389,0.000522127200383693,0.0003964521747548133,0.0003051805542781949,0.00027768246945925057,0.00018511958478484303,0.00033658716711215675,0.0002998356940224767,0.0002418081130599603,0.00022443212219513953,0.00035437275073491037,0.00040270734461955726,0.0004316882696002722,0.00042130262590944767,0.0003111775149591267,0.0002376791526330635,0.00024588097585365176,0.00043614977039396763,0.00036353335599415004,0.00026051633176393807,0.00020232159295119345,0.0001938504574354738,0.0003377437824383378,0.00035843870136886835,0.00024111037782859057,0.0002098880213452503,0.0002656814467627555,0.00020340981427580118,0.00016516399045940489,0.00015003947191871703,0.00013759963621851057,0.00018424027075525373,0.0003267474239692092,0.00021002795256208628,0.00022737588733434677,0.0003169672563672066,0.00027131583192385733,0.00023985141888260841,0.00019968788546975702,0.00016348814824596047,0.00014478559023700655,0.00012650887947529554,0.00014179138815961778,0.0002497638633940369,0.00022326337057165802,0.00017549219774082303,0.0001448479451937601,0.0001270783832296729,0.0001253735099453479,0.00022282882127910852,0.00021471548825502396,0.0001764534245012328,0.00013152752944733948,0.00011738433386199176,0.00010683075379347429,0.00014032277977094054,0.00014624698087573051,0.00012569909449666739,0.00011032334441551939,0.00010179911623708904,0.0001024233060888946,0.00017379609926138073,0.00019715240341611207,0.0002095663221552968,0.00017785068484954536,0.00014402024680748582,7.953598105814308e-05,5.584484460996464e-05,5.325525489752181e-05,5.111288919579238e-05,4.978995639248751e-05,4.7791563702048734e-05,4.7860638005658984e-05,4.614509816747159e-05,4.6916218707337976e-05,4.5304106606636196e-05,4.556652493192814e-05,4.570289092953317e-05,4.5604061597259715e-05,4.522437302512117e-05,4.6129189286148176e-05,6.348681199597195e-05,9.988001693272963e-05,0.00013969276915304363,
mae,0.13770996034145355,0.057917866855859756,0.03145815059542656,0.02855006419122219,0.025103764608502388,0.03270459547638893,0.02444157376885414,0.023402122780680656,0.030525632202625275,0.028619321063160896,0.022881999611854553,0.021928030997514725,0.020975658670067787,0.018885817378759384,0.019315168261528015,0.018010759726166725,0.018188435584306717,0.017934489995241165,0.015752386301755905,0.01377179753035307,0.01289542205631733,0.010517098940908909,0.014392541721463203,0.013705942779779434,0.011864730156958103,0.012171093374490738,0.014417443424463272,0.016244927421212196,0.015854842960834503,0.016881752759218216,0.013877111487090588,0.01231437362730503,0.012394020333886147,0.017254292964935303,0.015598355792462826,0.01344433892518282,0.012132969684898853,0.011417415924370289,0.014950183220207691,0.01574920117855072,0.01219211146235466,0.011485370807349682,0.013206303119659424,0.011476946994662285,0.009749643504619598,0.00912998616695404,0.008809461258351803,0.010631049051880836,0.014975574798882008,0.01140798069536686,0.01188691332936287,0.014660334214568138,0.013742557726800442,0.01276259496808052,0.011115951463580132,0.009710879065096378,0.009200329892337322,0.008699053898453712,0.009270302951335907,0.013059781864285469,0.01268031820654869,0.010691908188164234,0.009549961425364017,0.009015029296278954,0.008902912959456444,0.012570152059197426,0.012506268918514252,0.010683965869247913,0.00902213528752327,0.008864535950124264,0.008161584846675396,0.0095624178647995,0.010137096978724003,0.008812413550913334,0.007945986464619637,0.0076559120789170265,0.007922026328742504,0.010489851236343384,0.01142030954360962,0.012317260727286339,0.01101413369178772,0.009289203211665154,0.006886985152959824,0.005754619371145964,0.005903857760131359,0.005857763811945915,0.005727863404899836,0.005433851853013039,0.00552469864487648,0.005319205112755299,0.005545524880290031,0.00541630620136857,0.005425221286714077,0.005324745085090399,0.005415936931967735,0.005312168039381504,0.0053370194509625435,0.006111803464591503,0.007590143010020256,0.009403902105987072,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 12867     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 12868     
=================================================================
Total params: 25,735
Trainable params: 25,735
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 12,867
Trainable params: 12,867
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 12,868
Trainable params: 12,868
Non-trainable params: 0
_________________________________________________________________
