2021-06-26
loss,0.33077797293663025,0.22250127792358398,0.21870045363903046,0.19252897799015045,0.09414761513471603,0.06035358086228371,0.04668845236301422,0.039565183222293854,0.03583584353327751,0.03350619599223137,0.03150138258934021,0.030184974893927574,0.028918510302901268,0.02794957160949707,0.02695649117231369,0.02593412809073925,0.03407418727874756,0.042485613375902176,0.0354645811021328,0.031403638422489166,0.028782809153199196,0.027637816965579987,0.024635519832372665,0.022672021761536598,0.02221733331680298,0.021782685071229935,0.02131916768848896,0.020804984495043755,0.020524073392152786,0.020090408623218536,0.01982160285115242,0.01935649663209915,0.019241202622652054,0.01900363527238369,0.01883166842162609,0.01844887062907219,0.018259115517139435,0.01794970966875553,0.018080703914165497,0.01931159198284149,0.018660305067896843,0.019134514033794403,0.029135795310139656,0.019324060529470444,0.017941389232873917,0.017427263781428337,0.01730257086455822,0.017055153846740723,0.025437893345952034,0.02425728738307953,0.025570940226316452,0.02658217027783394,0.026477448642253876,0.03037230670452118,0.029469167813658714,0.027369601652026176,0.02550952136516571,0.0241928081959486,0.023060277104377747,0.022500958293676376,0.021681103855371475,0.02076091058552265,0.0201259758323431,0.01933155581355095,0.018324755132198334,0.017108317464590073,0.016106586903333664,0.015385777689516544,0.01492744404822588,0.014727954752743244,0.014500703662633896,0.014227122068405151,0.014207741245627403,0.014040222391486168,0.013935445807874203,0.013806160539388657,0.013694949448108673,0.013571059331297874,0.013481613248586655,0.013397743925452232,0.013427311554551125,0.013242927379906178,0.013211189769208431,0.013246054761111736,0.0132049061357975,0.013087375089526176,0.01310868188738823,0.012989409267902374,0.013006579130887985,0.012916769832372665,0.01286811102181673,0.012857736088335514,0.012773009948432446,0.012758227996528149,0.012639676220715046,0.012529736384749413,0.01257293950766325,0.01247577928006649,0.01247633807361126,0.012354668229818344,
mse,0.03834395483136177,0.018157370388507843,0.017865611240267754,0.013871928676962852,0.0028544911183416843,0.001153819845058024,0.0006812512874603271,0.0004934401949867606,0.00040166196413338184,0.00034989957930520177,0.000308963906718418,0.00028101223870180547,0.0002568634517956525,0.00024012202629819512,0.00022230451577343047,0.00020657693676184863,0.0003766945446841419,0.0005252374685369432,0.00036909442860633135,0.0002870623429771513,0.00024316800408996642,0.00022244967112783343,0.000178319271071814,0.00015247623377945274,0.00014546309830620885,0.00013855310680810362,0.0001321567251579836,0.0001260869175894186,0.0001223239814862609,0.00011641925084404647,0.00011468010779935867,0.00011016312782885507,0.00010670479241525754,0.00010362350440118462,0.0001013703367789276,9.852030052570626e-05,9.947129728971049e-05,9.97650931822136e-05,9.699451766209677e-05,0.00011068760068155825,9.949917875928804e-05,0.00011562208965187892,0.00023856887128204107,0.00011452767648734152,9.079359733732417e-05,8.817019261186942e-05,8.61027801875025e-05,8.688425441505387e-05,0.00019479631737340242,0.0001743391912896186,0.00018901051953434944,0.00020520504040177912,0.00020248832879588008,0.0002647796645760536,0.00024262331135105342,0.0002089310873998329,0.00018194239237345755,0.0001667459000600502,0.00014998669212218374,0.0001412063284078613,0.0001303240715060383,0.00011945502774324268,0.00011209867079742253,0.00010350492084398866,9.478475112700835e-05,8.545361197320744e-05,7.325434853555635e-05,6.742962432326749e-05,6.355360528687015e-05,6.1577491578646e-05,5.979620254947804e-05,5.783950837212615e-05,5.780561696155928e-05,5.6357719586230814e-05,5.546128886635415e-05,5.4566917242482305e-05,5.346884427126497e-05,5.252907067188062e-05,5.2151550335111097e-05,5.104664160171524e-05,5.118121043778956e-05,4.9924659833777696e-05,4.966972483089194e-05,4.980243829777464e-05,4.961555532645434e-05,4.851541598327458e-05,4.845331932301633e-05,4.8069163312902674e-05,4.802409603144042e-05,4.7102766984608024e-05,4.702248770627193e-05,4.682234794017859e-05,4.5618809963343665e-05,4.581334360409528e-05,4.509569043875672e-05,4.410825567902066e-05,4.4864442315883934e-05,4.438680116436444e-05,4.3589949200395495e-05,4.312733290134929e-05,
mae,0.14525851607322693,0.10274400562047958,0.10433434695005417,0.0889250859618187,0.04020651429891586,0.02540813758969307,0.019856225699186325,0.0169614776968956,0.015174987725913525,0.014278167858719826,0.013446134515106678,0.012857072055339813,0.012279447168111801,0.01189957745373249,0.011468973942101002,0.011037463322281837,0.014526966959238052,0.018455855548381805,0.015466321259737015,0.013485275208950043,0.012469557113945484,0.011953583918511868,0.010235981084406376,0.009358362294733524,0.009505766443908215,0.009276981465518475,0.009114271029829979,0.008902515284717083,0.008739815093576908,0.008554690517485142,0.00851714238524437,0.008197907358407974,0.008094212971627712,0.008115548640489578,0.008112732321023941,0.007944798097014427,0.007813401520252228,0.007682973053306341,0.007733191829174757,0.008259497582912445,0.007968866266310215,0.007981793023645878,0.011822721920907497,0.008234301581978798,0.007650530431419611,0.007427221164107323,0.007417493965476751,0.007351519074290991,0.010763644240796566,0.01019776239991188,0.010799204930663109,0.011321463622152805,0.011652656830847263,0.013183249160647392,0.012831718660891056,0.011681610718369484,0.010260016657412052,0.009849807247519493,0.009613570757210255,0.009617491625249386,0.009287608787417412,0.008869531564414501,0.008519274182617664,0.008261075243353844,0.00786866620182991,0.00734608294442296,0.007043430116027594,0.006780420430004597,0.0065850503742694855,0.006388085428625345,0.006283521186560392,0.006123867817223072,0.006169677246361971,0.006036665290594101,0.006065115798264742,0.006046425085514784,0.005960008129477501,0.005874150898307562,0.005834583193063736,0.005710352677851915,0.0057721370831131935,0.005641343537718058,0.005624894518405199,0.005681152455508709,0.005690906196832657,0.005591301247477531,0.00562438927590847,0.0055551594123244286,0.005618606694042683,0.0055408477783203125,0.005496900528669357,0.005544716492295265,0.005401344504207373,0.005486850161105394,0.005479329265654087,0.005356506910175085,0.005376377142965794,0.00532896863296628,0.005359933245927095,0.005318295210599899,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9643      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9644      
=================================================================
Total params: 19,287
Trainable params: 19,287
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 9,643
Trainable params: 9,643
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 9,644
Trainable params: 9,644
Non-trainable params: 0
_________________________________________________________________
