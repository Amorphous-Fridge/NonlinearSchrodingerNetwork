2021-06-26
loss,0.3440885841846466,0.1250235140323639,0.07136117666959763,0.05306779220700264,0.059830740094184875,0.04936527833342552,0.0412447452545166,0.036686815321445465,0.03621475771069527,0.050811171531677246,0.04300745576620102,0.036352887749671936,0.027659185230731964,0.022627420723438263,0.021560532972216606,0.020902888849377632,0.020378774031996727,0.020020605996251106,0.01962689310312271,0.01914440654218197,0.019088005647063255,0.01869075559079647,0.018449733033776283,0.018226994201540947,0.017975181341171265,0.017601562663912773,0.017437467351555824,0.017274197190999985,0.01698957197368145,0.016910254955291748,0.016681212931871414,0.016446655616164207,0.01624048501253128,0.01617792434990406,0.016072683036327362,0.015939893200993538,0.015685811638832092,0.015601017512381077,0.015593471936881542,0.015571419149637222,0.01530306413769722,0.015278363600373268,0.015147587284445763,0.014856799505650997,0.014809205196797848,0.014751378446817398,0.01482299529016018,0.014612490311264992,0.01451118104159832,0.0144793801009655,0.014271213673055172,0.014294019900262356,0.014136833138763905,0.014072719030082226,0.0139309735968709,0.013886887580156326,0.013775906525552273,0.01374869979918003,0.013639859855175018,0.013628332875669003,0.01360798254609108,0.013405638746917248,0.013429751619696617,0.013370121829211712,0.013180018402636051,0.013193607330322266,0.013070237822830677,0.013055660761892796,0.013013297691941261,0.012909643352031708,0.012866093777120113,0.012777400203049183,0.012722892686724663,0.01264574658125639,0.01262653712183237,0.012581284157931805,0.012541312724351883,0.012428026646375656,0.012452163733541965,0.012319241650402546,0.0122968889772892,0.01642322912812233,0.018189795315265656,0.019343173131346703,0.020405899733304977,0.0204825047403574,0.01799907721579075,0.01846787892282009,0.02054806426167488,0.020423509180545807,0.016799312084913254,0.01556421909481287,0.017701799049973488,0.017534764483571053,0.018258092924952507,0.020771875977516174,0.01947852410376072,0.018202053382992744,0.018577145412564278,0.018477194011211395,
mse,0.045761045068502426,0.005764210131019354,0.001544149243272841,0.0008255504071712494,0.0010409061796963215,0.0006950660608708858,0.0004865504160989076,0.00039446429582312703,0.00039998366264626384,0.0007662049029022455,0.0005351162981241941,0.00038278603460639715,0.00023710139794275165,0.00015308074944186956,0.00013798735744785517,0.00013017399760428816,0.0001237797987414524,0.00011941578122787178,0.00011361201177351177,0.00010952116281259805,0.00010731400834629312,0.00010409375681774691,9.989243699237704e-05,9.834992670221254e-05,9.53187482082285e-05,9.122178016696125e-05,8.864833216648549e-05,8.780552161624655e-05,8.484514546580613e-05,8.351601718459278e-05,8.09294797363691e-05,7.922711665742099e-05,7.74876243667677e-05,7.628302410012111e-05,7.465055387001485e-05,7.304334576474503e-05,7.133586768759415e-05,7.066554098855704e-05,7.200923573691398e-05,7.024317164905369e-05,6.799164839321747e-05,6.691338057862595e-05,6.595708691747859e-05,6.371198105625808e-05,6.344373105093837e-05,6.330316682578996e-05,6.335668876999989e-05,6.127625238150358e-05,6.011594086885452e-05,5.9575595514616e-05,5.894555215490982e-05,5.8273097238270566e-05,5.692792183253914e-05,5.6250490160891786e-05,5.5789510952308774e-05,5.5295280617428944e-05,5.3756019042339176e-05,5.39776956429705e-05,5.541428618016653e-05,5.320109994499944e-05,5.244285421213135e-05,5.174270336283371e-05,5.1315560995135456e-05,5.0361999456072226e-05,5.0628928875084966e-05,4.982494647265412e-05,4.894522135145962e-05,4.903323497273959e-05,4.844367504119873e-05,4.695063398685306e-05,4.7250996431102976e-05,4.6345321607077494e-05,4.586088107316755e-05,4.5980021241120994e-05,4.520122820395045e-05,4.462488504941575e-05,4.473593071452342e-05,4.3721942347474396e-05,4.394457573653199e-05,4.3293897761031985e-05,4.332543903728947e-05,8.567692566430196e-05,0.00010321621812181547,0.00011179925786564127,0.0001247741747647524,0.00011893865303136408,9.677751950221136e-05,0.00010297793778590858,0.00012334351777099073,0.00012158024037489668,8.890096069080755e-05,7.401421316899359e-05,9.610415145289153e-05,9.073381079360843e-05,0.0001014763765851967,0.00012004547170363367,0.00010530860890867189,9.53085909713991e-05,0.00010080522042699158,9.944685734808445e-05,
mae,0.149586483836174,0.055592432618141174,0.03025786206126213,0.022577717900276184,0.02611817605793476,0.021708045154809952,0.017759259790182114,0.015576380304992199,0.015360207296907902,0.02141929417848587,0.018428292125463486,0.015687504783272743,0.011793223209679127,0.009692211635410786,0.009268855676054955,0.008990388363599777,0.00876656174659729,0.008576294407248497,0.008375221863389015,0.008156578987836838,0.008190451189875603,0.008016246370971203,0.007862234488129616,0.007759782485663891,0.007697227410972118,0.007563440594822168,0.007430640514940023,0.007381245493888855,0.007329678628593683,0.007219940889626741,0.007149630691856146,0.0070311324670910835,0.006956618279218674,0.006899492349475622,0.006898765452206135,0.006839850451797247,0.006674313917756081,0.006676561664789915,0.00667179049924016,0.006705754436552525,0.006511666812002659,0.0065178596414625645,0.006446970161050558,0.006306497845798731,0.00632504653185606,0.0062980991788208485,0.006338873878121376,0.006272101309150457,0.006220098119229078,0.006238635163754225,0.006145948078483343,0.006118897348642349,0.006006600335240364,0.005983735900372267,0.006001472473144531,0.0059280358254909515,0.005861486308276653,0.005833216942846775,0.0058252220042049885,0.005818203091621399,0.005832107737660408,0.005708085838705301,0.00576734496280551,0.005696839652955532,0.005618832539767027,0.0056272088550031185,0.005574247799813747,0.00555195938795805,0.005567930173128843,0.005517449229955673,0.005495390389114618,0.005427462514489889,0.005406026262789965,0.005389992147684097,0.005377243738621473,0.005353881046175957,0.005343345925211906,0.005328187253326178,0.005354555323719978,0.005250715650618076,0.005247302819043398,0.006915469653904438,0.007747139781713486,0.008103268221020699,0.008637215942144394,0.008698717691004276,0.007608514279127121,0.007919147610664368,0.008661000058054924,0.008770337328314781,0.007208951748907566,0.006669540423899889,0.00758189195767045,0.007451376877725124,0.007880659773945808,0.0088384710252285,0.008271370083093643,0.007706627249717712,0.007901782169938087,0.00784280151128769,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 21075     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 21076     
=================================================================
Total params: 42,151
Trainable params: 42,151
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 21,075
Trainable params: 21,075
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 21,076
Trainable params: 21,076
Non-trainable params: 0
_________________________________________________________________
