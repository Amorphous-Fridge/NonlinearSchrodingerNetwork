2021-06-26
loss,0.6638846397399902,0.1104065328836441,0.07498358935117722,0.05919968709349632,0.058645233511924744,0.060206927359104156,0.055809926241636276,0.05155142769217491,0.04736216366291046,0.04209107533097267,0.03614749759435654,0.03994136303663254,0.04049315303564072,0.03793001174926758,0.0324975959956646,0.03241915628314018,0.034772839397192,0.029259836301207542,0.028425926342606544,0.03073864057660103,0.027930567041039467,0.02562171407043934,0.025349535048007965,0.027981605380773544,0.024644793942570686,0.019945751875638962,0.02552790381014347,0.025496792048215866,0.022598521783947945,0.024147452786564827,0.023147182539105415,0.023583946749567986,0.021753890439867973,0.022480124607682228,0.02239001914858818,0.022377463057637215,0.021975982934236526,0.020897982642054558,0.02201930433511734,0.021788647398352623,0.019375666975975037,0.019592374563217163,0.022898994386196136,0.020814845338463783,0.019459491595625877,0.01755506359040737,0.020933950319886208,0.01992521807551384,0.019444232806563377,0.01979915425181389,0.017312126234173775,0.017582930624485016,0.020080210641026497,0.0196104496717453,0.018345680087804794,0.017555756494402885,0.01932797022163868,0.017740419134497643,0.018147224560379982,0.017624197527766228,0.018748318776488304,0.017510337755084038,0.016961222514510155,0.017157305032014847,0.015885964035987854,0.015842415392398834,0.017062781378626823,0.01840871572494507,0.016824953258037567,0.01608802191913128,0.016038650646805763,0.01755628176033497,0.017504921182990074,0.014982149936258793,0.013317552395164967,0.015579787082970142,0.01653474196791649,0.017557162791490555,0.017313245683908463,0.015644961968064308,0.014730090275406837,0.016163062304258347,0.014729767106473446,0.016033772379159927,0.015740256756544113,0.014589467085897923,0.014779153279960155,0.015268037095665932,0.01466568186879158,0.014993497170507908,0.013350001536309719,0.014972057193517685,0.01351272314786911,0.01409192755818367,0.014576088637113571,0.014266756363213062,0.013034415431320667,0.012740817852318287,0.013665186241269112,0.01470945030450821,
mse,0.2834613621234894,0.0038874063175171614,0.0016743241576477885,0.001047006226144731,0.0010065712267532945,0.0010655777296051383,0.0009267427958548069,0.0008158801356330514,0.0006698840879835188,0.0005222236504778266,0.000412790133850649,0.00047527119750157,0.000482183531858027,0.00043814259697683156,0.00031239044619724154,0.0003101060865446925,0.00034189995494671166,0.0002537555410526693,0.00024298849166370928,0.000278867402812466,0.00022875239665154368,0.00020318507449701428,0.00019809747755061835,0.00023280654568225145,0.00017621097504161298,0.00012034989049425349,0.00018989281670656055,0.00018491162336431444,0.0001516332704341039,0.00017523473070468754,0.00015580702165607363,0.0001591552427271381,0.00013844524801243097,0.00014576382818631828,0.00014454068150371313,0.00014536188973579556,0.00013954759924672544,0.00012786552542820573,0.00014055302017368376,0.00013431193656288087,0.00011155597167089581,0.0001120957822422497,0.00014981614367570728,0.00012473292008507997,0.00011100451229140162,9.370029147248715e-05,0.00012493255781009793,0.00011436430941103026,0.00011271003313595429,0.0001131840399466455,8.812639862298965e-05,9.174217120744288e-05,0.00011543874279595912,0.00011188041389686987,9.786301234271377e-05,9.21493410714902e-05,0.00010815346468007192,9.250026778317988e-05,9.554071584716439e-05,8.912184421205893e-05,0.00010165516141569242,9.017281263368204e-05,8.412935130763799e-05,8.610685472376645e-05,7.558679499197751e-05,7.346606435021386e-05,8.543557487428188e-05,9.633920126361772e-05,8.263858762802556e-05,7.632808410562575e-05,7.540795195382088e-05,8.863294351613149e-05,8.846353011904284e-05,6.805493467254564e-05,5.5247721320483834e-05,7.305425242520869e-05,7.906525570433587e-05,8.83352113305591e-05,8.44297101139091e-05,7.306448969757184e-05,6.526770448544994e-05,7.583739352412522e-05,6.462379678850994e-05,7.575683412142098e-05,7.068987906677648e-05,6.386163295246661e-05,6.426894833566621e-05,6.814071821281686e-05,6.345513975247741e-05,6.631244468735531e-05,5.288900501909666e-05,6.623133231187239e-05,5.6294273235835135e-05,5.947174213360995e-05,6.172285065986216e-05,6.021735316608101e-05,5.1187056669732556e-05,5.0100275984732434e-05,5.461541149998084e-05,6.260626105358824e-05,
mae,0.28197064995765686,0.04693032428622246,0.03204748407006264,0.025231875479221344,0.024926630780100822,0.025418894365429878,0.02366052195429802,0.021753134205937386,0.020370054990053177,0.018049167469143867,0.015177223831415176,0.016914071515202522,0.01714145392179489,0.016190798953175545,0.013823275454342365,0.01363676879554987,0.014772024005651474,0.012524353340268135,0.012176155112683773,0.013090619817376137,0.011940057389438152,0.010971155017614365,0.010808584280312061,0.011908934451639652,0.010471939109265804,0.00845601037144661,0.010673128068447113,0.010738967917859554,0.009428436867892742,0.010315009392797947,0.009771420620381832,0.010026267729699612,0.009336432442069054,0.0093483105301857,0.009440410882234573,0.00949086807668209,0.00919819250702858,0.008761701174080372,0.00928646232932806,0.009140696376562119,0.008185130544006824,0.008340395987033844,0.009649558924138546,0.008856228552758694,0.008252240717411041,0.007470280397683382,0.0087664183229208,0.008553512394428253,0.008144823834300041,0.008334350772202015,0.0073609729297459126,0.007390628568828106,0.00854499265551567,0.008293538354337215,0.007728989701718092,0.007489493582397699,0.008159436285495758,0.007555573713034391,0.007690581493079662,0.007529658265411854,0.007906642742455006,0.007444486021995544,0.00713624432682991,0.007268994580954313,0.0067700715735554695,0.006734960246831179,0.0072904969565570354,0.007810581941157579,0.007167797069996595,0.0068442327901721,0.006834988482296467,0.0074304877780377865,0.00741548603400588,0.006339138839393854,0.005617521237581968,0.006639053113758564,0.007024075835943222,0.007459370885044336,0.0073013645596802235,0.006661440711468458,0.006276288535445929,0.006895534228533506,0.0062331464141607285,0.0067898863926529884,0.006615890190005302,0.006117277313023806,0.006210519000887871,0.006507201120257378,0.006238506641238928,0.00638944935053587,0.0056618875823915005,0.006331087555736303,0.005766899790614843,0.006033588666468859,0.006230356637388468,0.006002294830977917,0.005446682684123516,0.0054346187971532345,0.00577679043635726,0.006295985542237759,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 198787    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 198788    
=================================================================
Total params: 397,575
Trainable params: 397,575
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 198,787
Trainable params: 198,787
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 198,788
Trainable params: 198,788
Non-trainable params: 0
_________________________________________________________________
