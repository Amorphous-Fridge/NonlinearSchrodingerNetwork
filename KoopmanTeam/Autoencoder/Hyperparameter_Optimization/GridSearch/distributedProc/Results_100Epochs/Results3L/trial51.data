2021-06-26
loss,0.3893868625164032,0.23910272121429443,0.18519747257232666,0.12412331253290176,0.08235906809568405,0.10431081056594849,0.09545135498046875,0.07693599909543991,0.056012336164712906,0.06022441014647484,0.05785069987177849,0.06036132946610451,0.05270910635590553,0.05516030639410019,0.047479115426540375,0.03273966163396835,0.043485503643751144,0.04871450364589691,0.044949136674404144,0.038689352571964264,0.04769676551222801,0.04032967612147331,0.03845102712512016,0.041625622659921646,0.04363371804356575,0.038108326494693756,0.034788087010383606,0.033032532781362534,0.03332355245947838,0.03389331325888634,0.028733141720294952,0.029689839109778404,0.03611850365996361,0.024453407153487206,0.019338026642799377,0.018394242972135544,0.018130529671907425,0.01797781139612198,0.017814602702856064,0.01776190660893917,0.017600595951080322,0.017394209280610085,0.017540862783789635,0.017258979380130768,0.017052609473466873,0.016753194853663445,0.020262980833649635,0.023828359320759773,0.027852259576320648,0.02904132753610611,0.026260580867528915,0.022798161953687668,0.023820919916033745,0.025831717997789383,0.02870321087539196,0.025722621008753777,0.027178114280104637,0.024207746610045433,0.02288350835442543,0.022989027202129364,0.024482689797878265,0.02328949235379696,0.022109877318143845,0.024981839582324028,0.022568373009562492,0.019751030951738358,0.016969334334135056,0.01804168149828911,0.017663709819316864,0.019976869225502014,0.023893767967820168,0.022031838074326515,0.023735154420137405,0.022720184177160263,0.02107800543308258,0.019050434231758118,0.01752968318760395,0.01619996316730976,0.017665617167949677,0.022045623511075974,0.021707840263843536,0.02183607965707779,0.019420718774199486,0.018350251019001007,0.016822056844830513,0.015161034651100636,0.014350222423672676,0.015257391147315502,0.013783544301986694,0.020701613277196884,0.021502628922462463,0.01807573065161705,0.015034811571240425,0.017435306683182716,0.019107501953840256,0.020594486966729164,0.018018972128629684,0.016167374327778816,0.01812991127371788,0.017989158630371094,
mse,0.05446659028530121,0.019426679238677025,0.011917496100068092,0.004664750769734383,0.0019613816402852535,0.003197915619239211,0.0025589352007955313,0.0016797271091490984,0.0009138567838817835,0.0010254837106913328,0.0009664045064710081,0.0010229531908407807,0.0008021052344702184,0.0008629203075543046,0.0006868997006677091,0.00031869500526227057,0.0005568636115640402,0.0006710785091854632,0.0005890617612749338,0.0004376585711725056,0.0006303935660980642,0.0004546413547359407,0.0004169951134826988,0.00048302882350981236,0.0005209299852140248,0.00040742155397310853,0.00034123167279176414,0.0003089964156970382,0.0003175028832629323,0.00032897311029955745,0.00024021249555516988,0.0002641559694893658,0.0003817077085841447,0.0001883339718915522,0.0001034517481457442,9.415886597707868e-05,9.237733320333064e-05,9.083581244340166e-05,8.976535900728777e-05,8.689013338880613e-05,8.74223915161565e-05,8.56102051329799e-05,8.623188477940857e-05,8.204290497815236e-05,8.054214413277805e-05,7.836712757125497e-05,0.00012769264867529273,0.00017078978999052197,0.00022449895914178342,0.00023413257440552115,0.00019782896561082453,0.00015276246995199472,0.00016692574718035758,0.000184418517164886,0.00023063686967361718,0.00018734749755822122,0.00020549807231873274,0.00016911629063542932,0.00015066021296661347,0.00015165824152063578,0.00016448440146632493,0.00015331832400988787,0.00013659243995789438,0.0001716354163363576,0.00014136052050162107,0.00011414721666369587,8.660125604365021e-05,9.68339663813822e-05,9.264270192943513e-05,0.00011530108167789876,0.0001612880441825837,0.00013307710469234735,0.00015734817134216428,0.00014572386862710118,0.00012421104474924505,0.0001033287844620645,8.926667942432687e-05,7.714676758041605e-05,9.216713806381449e-05,0.0001364050986012444,0.0001314655673922971,0.00013358789146877825,0.00010433799616293982,9.423228038940579e-05,8.317356696352363e-05,7.014281436568126e-05,6.27135596005246e-05,6.908829527674243e-05,5.6839442549971864e-05,0.00012184771912870929,0.00013001835031900555,9.482823224971071e-05,6.840311107225716e-05,8.850658923620358e-05,9.909464279189706e-05,0.00011696810543071479,9.410033817403018e-05,7.635322981514037e-05,9.285061969421804e-05,8.97486534086056e-05,
mae,0.1609547734260559,0.10106505453586578,0.07940111309289932,0.052688825875520706,0.03493456915020943,0.04351014271378517,0.040732838213443756,0.03275352343916893,0.023943372070789337,0.02598346769809723,0.024304049089550972,0.025692181661725044,0.022839827463030815,0.023204755038022995,0.020122382789850235,0.013937813229858875,0.018444204702973366,0.0205859262496233,0.019256114959716797,0.016357410699129105,0.020497076213359833,0.017119869589805603,0.016414355486631393,0.017471715807914734,0.018354834988713264,0.01628563180565834,0.015062205493450165,0.014292668551206589,0.014243231154978275,0.014398095197975636,0.012180688790977001,0.012801490724086761,0.015088843181729317,0.010538926348090172,0.00816088356077671,0.007783722132444382,0.007680067792534828,0.0075918082147836685,0.007546272128820419,0.0075799208134412766,0.007456693798303604,0.007381426636129618,0.00745675154030323,0.007355889305472374,0.007294218987226486,0.007117934990674257,0.008595539256930351,0.010138852521777153,0.011898313648998737,0.012230155058205128,0.01113591343164444,0.009698496200144291,0.010073117911815643,0.01096407976001501,0.012385324575006962,0.010961020365357399,0.01165290828794241,0.010288318619132042,0.009607454761862755,0.009718907065689564,0.010486716404557228,0.009995140135288239,0.009339856915175915,0.01050578337162733,0.009491494856774807,0.00830735545605421,0.00717288488522172,0.007701409049332142,0.007509511895477772,0.0084784384816885,0.010117012076079845,0.009361905977129936,0.010112429969012737,0.009767359122633934,0.00874229334294796,0.00789540633559227,0.007444228045642376,0.006837236229330301,0.007521540392190218,0.009342938661575317,0.00933574978262186,0.00941231194883585,0.008105654269456863,0.007655059918761253,0.00713795842602849,0.006425961386412382,0.006155085749924183,0.006478248629719019,0.005834327545017004,0.008809727616608143,0.009021662175655365,0.007615691516548395,0.006430521607398987,0.00745234452188015,0.008192804642021656,0.00880217831581831,0.007789285387843847,0.0068697393871843815,0.007778854575008154,0.0076175411231815815,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 37827     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 37828     
=================================================================
Total params: 75,655
Trainable params: 75,655
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 37,827
Trainable params: 37,827
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 37,828
Trainable params: 37,828
Non-trainable params: 0
_________________________________________________________________
