2021-06-26
loss,0.4090763032436371,0.11777059733867645,0.06268710643053055,0.05032932758331299,0.04274163395166397,0.03656278923153877,0.032881613820791245,0.030814265832304955,0.029000572860240936,0.02776092290878296,0.026822533458471298,0.025840511545538902,0.025183994323015213,0.0244407057762146,0.02396794781088829,0.023435987532138824,0.02306308038532734,0.02259175106883049,0.022146333009004593,0.021913647651672363,0.021550070494413376,0.021148905158042908,0.02081066183745861,0.020598189905285835,0.020350132137537003,0.020259421318769455,0.019817817956209183,0.01968713104724884,0.019553815945982933,0.019366765394806862,0.019161878153681755,0.018893923610448837,0.018862884491682053,0.01855302043259144,0.018525689840316772,0.01835973747074604,0.018131118267774582,0.01804407685995102,0.017972560599446297,0.017834430560469627,0.017640668898820877,0.017584316432476044,0.0173527579754591,0.01736905425786972,0.017165809869766235,0.017098836600780487,0.01702192611992359,0.01701287552714348,0.01692831702530384,0.016814181581139565,0.01657751388847828,0.016556870192289352,0.016565486788749695,0.016446955502033234,0.016300318762660027,0.01633591204881668,0.01617223583161831,0.015957700088620186,0.01609792746603489,0.016084104776382446,0.015886548906564713,0.01583818346261978,0.015819696709513664,0.015652310103178024,0.015674538910388947,0.01568441465497017,0.015510504133999348,0.015512954443693161,0.015424326993525028,0.015307808294892311,0.015275876969099045,0.015232906676828861,0.015281406231224537,0.01519185770303011,0.015095850452780724,0.015019997023046017,0.015050658024847507,0.014961290173232555,0.014907567761838436,0.014807521365582943,0.014644634909927845,0.014691872522234917,0.014674701727926731,0.014578703790903091,0.01460433378815651,0.014609387144446373,0.014468989335000515,0.014444313012063503,0.014414890669286251,0.014400706626474857,0.014307736419141293,0.014343520626425743,0.014144091866910458,0.014184179715812206,0.014117121696472168,0.013977373018860817,0.014120128937065601,0.014070049859583378,0.013824217021465302,0.01390453614294529,
mse,0.07549351453781128,0.005248270463198423,0.0013803935144096613,0.0009127551456913352,0.0006358764949254692,0.0004433264257386327,0.0003455819678492844,0.00029781865305267274,0.00026190976495854557,0.00023874551698099822,0.00021999723685439676,0.00020327724632807076,0.00019187844009138644,0.00018008433107752353,0.00017287256196141243,0.0001649716286920011,0.00015771105245221406,0.00015132725820876658,0.00014546947204507887,0.0001415947626810521,0.00013734353706240654,0.00013128487626090646,0.00012705578410532326,0.00012387300375849009,0.00012057271669618785,0.0001195337317767553,0.00011433132749516517,0.000112220186565537,0.0001115257473429665,0.00010826926882145926,0.0001064789539668709,0.00010323676542611793,0.00010274682426825166,9.935101843439043e-05,9.853390656644478e-05,9.712389874039218e-05,9.459760622121394e-05,9.378565300721675e-05,9.290281013818458e-05,9.14126358111389e-05,8.92675670911558e-05,8.913149940781295e-05,8.63513705553487e-05,8.657725265948102e-05,8.420003723585978e-05,8.343716763192788e-05,8.25356473797001e-05,8.250863902503625e-05,8.185972546925768e-05,8.079761755652726e-05,7.807895599398762e-05,7.778575673000887e-05,7.8022618254181e-05,7.712152000749484e-05,7.571568858111277e-05,7.577912037959322e-05,7.442844798788428e-05,7.177397492341697e-05,7.372912659775466e-05,7.345723133767024e-05,7.18572482583113e-05,7.085494144121185e-05,7.1019479946699e-05,6.920113082742319e-05,6.927279173396528e-05,6.987488450249657e-05,6.78010328556411e-05,6.81074961903505e-05,6.750107422703877e-05,6.605699309147894e-05,6.604872760362923e-05,6.517906876979396e-05,6.604853842873126e-05,6.505894270958379e-05,6.399225094355643e-05,6.358847167575732e-05,6.366964225890115e-05,6.296358333202079e-05,6.264051626203582e-05,6.16375618847087e-05,5.994904859107919e-05,6.0476559156086296e-05,6.0400230722734705e-05,5.95838573644869e-05,5.9588444855762646e-05,5.993616287014447e-05,5.884734127903357e-05,5.84472763875965e-05,5.77842874918133e-05,5.820560181746259e-05,5.7369823480257764e-05,5.7591005315771326e-05,5.5963209888432175e-05,5.640065865009092e-05,5.561605576076545e-05,5.440199311124161e-05,5.6011584092630073e-05,5.5236312618944794e-05,5.316007445799187e-05,5.388939825934358e-05,
mae,0.17079389095306396,0.04983193427324295,0.027076996862888336,0.021590163931250572,0.018163852393627167,0.015490034595131874,0.013927447609603405,0.013056192547082901,0.012211992405354977,0.01179132703691721,0.011375635862350464,0.010962306521832943,0.010610384866595268,0.010358438827097416,0.010239562019705772,0.009946896694600582,0.009738682769238949,0.009553784504532814,0.00938356202095747,0.009271036833524704,0.009152792394161224,0.008967525325715542,0.008827686309814453,0.008737575262784958,0.008661406114697456,0.008489145897328854,0.0083283307030797,0.008387609384953976,0.008263731375336647,0.008209004066884518,0.008088869042694569,0.008020717650651932,0.007956713438034058,0.007873307913541794,0.007923257537186146,0.0077935452573001385,0.007658317685127258,0.007639740593731403,0.007565891370177269,0.00756270345300436,0.007506330031901598,0.007421555928885937,0.007331046275794506,0.007347716484218836,0.007197052240371704,0.007245444692671299,0.007204266730695963,0.00722990557551384,0.0071882582269608974,0.0070318859070539474,0.007105561438947916,0.007049256935715675,0.006959849502891302,0.006909789517521858,0.006861005909740925,0.006916344631463289,0.006775316782295704,0.006814103573560715,0.006812297739088535,0.006776050198823214,0.006665397901087999,0.006755826994776726,0.006712626200169325,0.006688294000923634,0.0067213671281933784,0.0065368046052753925,0.006609128788113594,0.006533209700137377,0.006531385704874992,0.0064297025091946125,0.006393659859895706,0.006547735538333654,0.0064291562885046005,0.006393349729478359,0.006429040804505348,0.006384530104696751,0.006405748892575502,0.006339021492749453,0.006303342524915934,0.006260312628000975,0.006259486544877291,0.006174000445753336,0.0061880131252110004,0.0061211902648210526,0.006225849501788616,0.006126409396529198,0.0061410353519022465,0.006156015209853649,0.006164789665490389,0.006048034876585007,0.006079660728573799,0.006021994166076183,0.005994256120175123,0.006026564631611109,0.005948479287326336,0.005985128227621317,0.005898126866668463,0.005911306943744421,0.005951035767793655,0.005913434084504843,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3347      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3348      
=================================================================
Total params: 6,695
Trainable params: 6,695
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 3,347
Trainable params: 3,347
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 3,348
Trainable params: 3,348
Non-trainable params: 0
_________________________________________________________________
