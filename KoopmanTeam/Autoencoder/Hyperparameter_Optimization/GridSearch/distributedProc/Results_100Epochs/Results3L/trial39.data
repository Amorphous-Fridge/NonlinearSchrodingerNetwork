2021-06-26
loss,0.40274596214294434,0.13558202981948853,0.10637593269348145,0.08633079379796982,0.07565221190452576,0.06548675894737244,0.060005560517311096,0.06080587953329086,0.04677276685833931,0.052202168852090836,0.05046222731471062,0.04457845538854599,0.04471367970108986,0.039359766989946365,0.03514045104384422,0.04778915271162987,0.03870858997106552,0.035741664469242096,0.038205672055482864,0.03680799528956413,0.032967664301395416,0.03439093381166458,0.03140387311577797,0.036685701459646225,0.031322333961725235,0.03704944625496864,0.03413090109825134,0.029199864715337753,0.026873594149947166,0.03354242444038391,0.03141025826334953,0.028469525277614594,0.03137315437197685,0.03252902999520302,0.02978026121854782,0.028923330828547478,0.028188204392790794,0.02855774573981762,0.027672603726387024,0.02589395083487034,0.023667171597480774,0.026058517396450043,0.025985274463891983,0.028962358832359314,0.02622086927294731,0.026306210085749626,0.024973414838314056,0.022945983335375786,0.021525373682379723,0.02173718996345997,0.021023008972406387,0.018226170912384987,0.02074592374265194,0.02189253270626068,0.0270439051091671,0.023529648780822754,0.022767601534724236,0.025851748883724213,0.023545164614915848,0.021794406697154045,0.019983207806944847,0.023155150935053825,0.021908847615122795,0.02329852804541588,0.019145386293530464,0.016987748444080353,0.017364639788866043,0.017748741433024406,0.017364555969834328,0.02340439334511757,0.01945445127785206,0.01754363439977169,0.02176855318248272,0.02169693633913994,0.023951511830091476,0.02084268257021904,0.020441744476556778,0.019790584221482277,0.018583398312330246,0.016843032091856003,0.01607595756649971,0.015471563674509525,0.01669181138277054,0.019447248429059982,0.02110045589506626,0.01882762834429741,0.020406415686011314,0.01843465119600296,0.01886431872844696,0.01958564668893814,0.018533840775489807,0.016166072338819504,0.013413897715508938,0.014209178276360035,0.015622878447175026,0.016553238034248352,0.0173984095454216,0.018475757911801338,0.018744641914963722,0.017609091475605965,
mse,0.06255317479372025,0.006065756548196077,0.003499266691505909,0.002188990358263254,0.0016744828317314386,0.001236528274603188,0.0010167884174734354,0.0010671111522242427,0.0006667607231065631,0.0007712404476478696,0.0007054893649183214,0.0005646644276566803,0.0005565081955865026,0.00044379394967108965,0.0003729927120730281,0.0006532783154398203,0.00042421845137141645,0.00037904069176875055,0.00041442830115556717,0.0003853018279187381,0.00031916252919472754,0.0003389914345461875,0.00030330728623084724,0.00037760488339699805,0.0002899171959143132,0.0003802878491114825,0.00033091771183535457,0.000247379532083869,0.00022258871467784047,0.0003126451338175684,0.0002767806581687182,0.00022741974680684507,0.0002776866313070059,0.00029137585079297423,0.0002507695753592998,0.00023872731253504753,0.0002217170549556613,0.00022951551363803446,0.00021516074775718153,0.00018634914886206388,0.00015992374392226338,0.0001943484676303342,0.00019020828767679632,0.00023054213670548052,0.00019786851771641523,0.0002011139877140522,0.00017711946566123515,0.00014567369362339377,0.0001308657811023295,0.0001400384644512087,0.00013555791520047933,9.958339796867222e-05,0.00013043171202298254,0.00014509363973047584,0.00020363027579151094,0.00016010923718567938,0.0001504005485912785,0.00018543984333518893,0.00015453026571776718,0.00013354791735764593,0.00011885093408636749,0.000156853609951213,0.00014044948329683393,0.00015167018864303827,0.00011074762005591765,9.20160673558712e-05,9.304663399234414e-05,9.589143883204088e-05,9.129164391197264e-05,0.00015140433970373124,0.00011014043411705643,9.3757153081242e-05,0.00013364739425014704,0.00013188614684622735,0.0001601347466930747,0.00012518034782260656,0.00011882017133757472,0.00011120958515675738,9.938698349287733e-05,8.529442129656672e-05,7.690391794312745e-05,7.035917951725423e-05,8.477774099446833e-05,0.00011128027836093679,0.00012368893658276647,0.00010200035467278212,0.0001180740146082826,9.679322829470038e-05,0.00010240341362077743,0.00010830938845174387,9.604583465261385e-05,7.757832645438612e-05,5.6301192671526223e-05,6.23592859483324e-05,7.619616371812299e-05,8.088636241154745e-05,8.794201858108863e-05,9.827777103055269e-05,9.840403799898922e-05,8.689075912116095e-05,
mae,0.17067711055278778,0.0572374165058136,0.04543379321694374,0.03671029210090637,0.03218670189380646,0.027816353365778923,0.025389689952135086,0.025660313665866852,0.019683606922626495,0.022350680083036423,0.021493785083293915,0.019026033580303192,0.019298337399959564,0.017360622063279152,0.014888981357216835,0.020560333505272865,0.015985608100891113,0.015061113983392715,0.01642734929919243,0.01520207617431879,0.013751232996582985,0.014560281299054623,0.01325345877557993,0.01595255918800831,0.013340388424694538,0.015591648407280445,0.014416640624403954,0.012468807399272919,0.01137217041105032,0.014265822246670723,0.013444564305245876,0.01197400689125061,0.012994677759706974,0.013490889221429825,0.012669989839196205,0.012175879441201687,0.011844751425087452,0.012111336924135685,0.011728459969162941,0.01101780403405428,0.010051905177533627,0.011101629585027695,0.011022805236279964,0.012188596650958061,0.011052693240344524,0.010999218560755253,0.010674145072698593,0.00981561467051506,0.009070344269275665,0.009264201857149601,0.008760415948927402,0.007786535192281008,0.00874996092170477,0.009365375153720379,0.011178156360983849,0.010017044842243195,0.009669455699622631,0.01091818232089281,0.009935394860804081,0.008993547409772873,0.008364595472812653,0.009758935309946537,0.009434911422431469,0.009861052967607975,0.008071407675743103,0.007272867951542139,0.007402915973216295,0.007471905555576086,0.0073770941235125065,0.009957185946404934,0.008222646079957485,0.007500233594328165,0.009244943968951702,0.009294550865888596,0.010023304261267185,0.00889730453491211,0.00876690074801445,0.008361251093447208,0.007933326065540314,0.007006674539297819,0.00671734381467104,0.0065104765817523,0.007090140599757433,0.008157907985150814,0.009049341082572937,0.007895739749073982,0.00873116496950388,0.007785062305629253,0.0079315435141325,0.008314572274684906,0.007581782527267933,0.006619104649871588,0.005709945689886808,0.006064720917493105,0.006690381560474634,0.007116456516087055,0.0074005890637636185,0.0077166371047496796,0.007894829846918583,0.007446012459695339,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 37715     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 37716     
=================================================================
Total params: 75,431
Trainable params: 75,431
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 37,715
Trainable params: 37,715
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 37,716
Trainable params: 37,716
Non-trainable params: 0
_________________________________________________________________
