2021-06-26
loss,0.3369832932949066,0.11345089226961136,0.05808618664741516,0.045741334557533264,0.054745789617300034,0.040325891226530075,0.03215876966714859,0.030168555676937103,0.028604038059711456,0.027330778539180756,0.026428701356053352,0.025832610204815865,0.026084041222929955,0.03650190308690071,0.038649559020996094,0.036495570093393326,0.03450740501284599,0.0347818024456501,0.035118065774440765,0.03051033429801464,0.028415856882929802,0.02691459469497204,0.02579835243523121,0.026423966512084007,0.03530978038907051,0.03195108100771904,0.03127726912498474,0.03083108924329281,0.026088014245033264,0.026417098939418793,0.025269659236073494,0.023683853447437286,0.02833724021911621,0.02596506103873253,0.0245252326130867,0.024123072624206543,0.022346988320350647,0.021184194833040237,0.02032223902642727,0.019722577184438705,0.018981073051691055,0.018686261028051376,0.018157146871089935,0.016085729002952576,0.015614894218742847,0.015180778689682484,0.014680163934826851,0.014297384768724442,0.01409708708524704,0.01408400759100914,0.01390058547258377,0.013763382099568844,0.013699361123144627,0.01357575785368681,0.01348904613405466,0.013327688910067081,0.013502356596291065,0.013279936276376247,0.013236799277365208,0.013165057636797428,0.013098998926579952,0.013084455393254757,0.012892949394881725,0.012931466102600098,0.012846369296312332,0.012854419648647308,0.012659653089940548,0.012788337655365467,0.012743649072945118,0.012754516676068306,0.0198277048766613,0.021657118573784828,0.01868794485926628,0.016721947118639946,0.014380046166479588,0.015405639074742794,0.019466564059257507,0.018921950832009315,0.022152772173285484,0.020644428208470345,0.019396135583519936,0.018511783331632614,0.0175172071903944,0.01655757427215576,0.015581082552671432,0.015272429212927818,0.01769825629889965,0.01784965954720974,0.01652080938220024,0.015352233313024044,0.015667352825403214,0.01696884073317051,0.017403051257133484,0.015276477672159672,0.015486589632928371,0.01461061742156744,0.02147921361029148,0.023188482969999313,0.02082003653049469,0.020265867933630943,
mse,0.043473199009895325,0.00462679099291563,0.0011295354925096035,0.0006830550846643746,0.0009381829877384007,0.0004947385750710964,0.00032226936309598386,0.00028038970776833594,0.0002472879132255912,0.0002238542219856754,0.0002104611339746043,0.00020038218644913286,0.00021273625316098332,0.0003900189767591655,0.00043694040505215526,0.00037644439726136625,0.00034944110666401684,0.00035260667209513485,0.0003457453567534685,0.00026424243696965277,0.00023217983834911138,0.00021038232080172747,0.00019605722627602518,0.00020869364379905164,0.0003689854347612709,0.0003019390278495848,0.0002784316020552069,0.0002702261845115572,0.00019624271953944117,0.0002013264747802168,0.0001831341942306608,0.00016388458607252687,0.00022964314848650247,0.00019235711079090834,0.00017470282909926027,0.00016376603161916137,0.00014444169937632978,0.0001304354955209419,0.00012136840086895972,0.00011488924792502075,0.00010786735219880939,0.00010855375876417384,0.00010505570389796048,7.827304943930358e-05,7.266464672284201e-05,6.772742926841602e-05,6.328271410893649e-05,6.024721005815081e-05,5.845184568897821e-05,5.820870501338504e-05,5.676788350683637e-05,5.529534973902628e-05,5.511029303306714e-05,5.375472392188385e-05,5.2764280553674325e-05,5.123752634972334e-05,5.285827137413435e-05,5.0906142860185355e-05,5.0409245886839926e-05,5.044781573815271e-05,5.0532249588286504e-05,4.9855349061544985e-05,4.8130470531759784e-05,4.870228804065846e-05,4.804387572221458e-05,4.7631285269744694e-05,4.7723762691020966e-05,4.827296652365476e-05,4.6807126636849716e-05,4.726199767901562e-05,0.0001182261694339104,0.00012836686801165342,9.897636482492089e-05,8.458423690171912e-05,6.339653191389516e-05,7.20781390555203e-05,0.00010718528210418299,0.00010325916082365438,0.00013571276213042438,0.00011782910587498918,0.00010593136539682746,9.806002344703302e-05,8.795856410870329e-05,7.895301678217947e-05,7.037477917037904e-05,7.125457341317087e-05,9.365369623992592e-05,9.249071445083246e-05,8.062382403295487e-05,7.136721251299605e-05,7.172312325565144e-05,8.312632417073473e-05,8.372220327146351e-05,6.903760368004441e-05,7.109112630132586e-05,6.520585156977177e-05,0.00013204518472775817,0.00015429146878886968,0.00012474495451897383,0.00011815442849183455,
mae,0.14628273248672485,0.05018805339932442,0.024975979700684547,0.01959921419620514,0.023445097729563713,0.01711677946150303,0.013911456800997257,0.0129884397611022,0.012269163504242897,0.011641217395663261,0.011377986520528793,0.011079199612140656,0.011135675944387913,0.015473822131752968,0.01606532372534275,0.015080238692462444,0.014522125944495201,0.014919156208634377,0.014867911115288734,0.012986361049115658,0.012112530879676342,0.011510941199958324,0.011084756813943386,0.011357367970049381,0.015090292319655418,0.013818220235407352,0.013480347581207752,0.01335152704268694,0.011334924958646297,0.011171788908541203,0.01065209973603487,0.00997287780046463,0.012120378203690052,0.010971087031066418,0.010464301332831383,0.009844292886555195,0.008999786339700222,0.008620649576187134,0.008362959139049053,0.008154191076755524,0.007873859256505966,0.007998896762728691,0.0077635119669139385,0.00684265187010169,0.006684739142656326,0.0064954739063978195,0.006288416218012571,0.00612650578841567,0.006008894648402929,0.006022488698363304,0.005913634318858385,0.005814530421048403,0.005836562719196081,0.0057658120058476925,0.005719137843698263,0.005642579402774572,0.005774976219981909,0.005643721669912338,0.005583897698670626,0.005631240084767342,0.005577043164521456,0.005621559452265501,0.0054847477003932,0.005535291973501444,0.0053862021304667,0.005530674010515213,0.005392072256654501,0.005426990333944559,0.005487518850713968,0.005445190705358982,0.008410001173615456,0.009288588538765907,0.007990561425685883,0.007178198080509901,0.006138681899756193,0.006567699369043112,0.008339159190654755,0.008142485283315182,0.00966717954725027,0.008773628622293472,0.008122522383928299,0.00775548629462719,0.007515419740229845,0.006960352882742882,0.006516674533486366,0.006521465722471476,0.007390043698251247,0.007436343468725681,0.006991260219365358,0.00649627111852169,0.006604216527193785,0.007226542104035616,0.00744652608409524,0.006474045105278492,0.006566237658262253,0.0062467302195727825,0.009117163717746735,0.009993265382945538,0.00897841714322567,0.008685553446412086,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 12915     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 12916     
=================================================================
Total params: 25,831
Trainable params: 25,831
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 12,915
Trainable params: 12,915
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 12,916
Trainable params: 12,916
Non-trainable params: 0
_________________________________________________________________
