2021-06-26
loss,0.40944957733154297,0.23261001706123352,0.20563507080078125,0.0974331945180893,0.05467457324266434,0.04080727696418762,0.03501707315444946,0.03151319921016693,0.028994567692279816,0.0275933425873518,0.026198972016572952,0.025187458842992783,0.024317961186170578,0.023779982700943947,0.022671561688184738,0.022285783663392067,0.021710986271500587,0.0214176494628191,0.020962204784154892,0.020538995042443275,0.020373640581965446,0.019996795803308487,0.01957612670958042,0.019490757957100868,0.019328676164150238,0.01897040568292141,0.018654147163033485,0.01861868053674698,0.01850038208067417,0.018221141770482063,0.018032845109701157,0.017909346148371696,0.01773492805659771,0.017551898956298828,0.017516357824206352,0.017382709309458733,0.01721012219786644,0.01714935339987278,0.01702570542693138,0.016937559470534325,0.016628514975309372,0.016720319166779518,0.01652504876255989,0.01637541502714157,0.0164418313652277,0.016270119696855545,0.01618575118482113,0.0161081925034523,0.0160373542457819,0.01597006991505623,0.015845423564314842,0.015770787373185158,0.01568293757736683,0.01572939194738865,0.015626564621925354,0.015472800470888615,0.015335435047745705,0.015265753492712975,0.01520109549164772,0.015235215425491333,0.015145203098654747,0.015114529989659786,0.015133471228182316,0.01490195281803608,0.014909995719790459,0.01476337295025587,0.014783160760998726,0.014649134129285812,0.014632943086326122,0.014640320092439651,0.01460878737270832,0.014483803883194923,0.014333274215459824,0.014458485879004002,0.01438545435667038,0.014284071512520313,0.014270391315221786,0.014230961911380291,0.01416610088199377,0.014137662947177887,0.014073904603719711,0.014078601263463497,0.013976278714835644,0.013974882662296295,0.013891492038965225,0.013853405602276325,0.013811673037707806,0.013717970810830593,0.013755747117102146,0.013667448423802853,0.013728393241763115,0.01359182596206665,0.013539225794374943,0.013573523610830307,0.013427822850644588,0.013593780808150768,0.013458430767059326,0.013357514515519142,0.013358939439058304,0.013354027643799782,
mse,0.057781971991062164,0.019134020432829857,0.015702230855822563,0.0036371364258229733,0.0010812135878950357,0.000569961266592145,0.0004084807587787509,0.0003262356040067971,0.00027576377033255994,0.00024538286379538476,0.00022002145124133676,0.00020175812824163586,0.00018831496709026396,0.00017739854229148477,0.00016103126108646393,0.00015642355720046908,0.00014698026643600315,0.00014241907047107816,0.00013631126785185188,0.0001299237337661907,0.0001278256968362257,0.00012229583808220923,0.00011706281657097861,0.00011606109910644591,0.00011335626913933083,0.00010906634270213544,0.00010527767881285399,0.00010449781257193536,0.00010286809265380725,9.980061440728605e-05,9.705642878543586e-05,9.568306268192828e-05,9.369965846417472e-05,9.175882587442175e-05,9.124237112700939e-05,8.943144348450005e-05,8.788156264927238e-05,8.713018905837089e-05,8.64408357301727e-05,8.521743438905105e-05,8.101019193418324e-05,8.182403689716011e-05,8.050747419474646e-05,7.861268386477605e-05,7.947078120196238e-05,7.757273851893842e-05,7.677679968765005e-05,7.645104778930545e-05,7.537120109191164e-05,7.434072904288769e-05,7.30902684153989e-05,7.21339019946754e-05,7.138171349652112e-05,7.188254676293582e-05,7.081602234393358e-05,6.951608520466834e-05,6.786942685721442e-05,6.713862967444584e-05,6.709708395646885e-05,6.683304673060775e-05,6.625694368267432e-05,6.57803684589453e-05,6.619605846935883e-05,6.338761886581779e-05,6.390291673596948e-05,6.300465611275285e-05,6.259189831325784e-05,6.165291415527463e-05,6.123074126662686e-05,6.126586231403053e-05,6.1296988860704e-05,5.9566016716416925e-05,5.840143057866953e-05,5.9979865909554064e-05,5.8701592934085056e-05,5.7983575970865786e-05,5.819836587761529e-05,5.79128936806228e-05,5.702912312699482e-05,5.710131154046394e-05,5.624831101158634e-05,5.621964737656526e-05,5.557228723773733e-05,5.5226042604772374e-05,5.4472697229357436e-05,5.447210787679069e-05,5.37780397280585e-05,5.3298277634894475e-05,5.3661478887079284e-05,5.291761044645682e-05,5.324286030372605e-05,5.19089080626145e-05,5.170572694623843e-05,5.2237170166336e-05,5.1007391448365524e-05,5.2155115554342046e-05,5.089229307486676e-05,5.0097885832656175e-05,5.008231892134063e-05,5.023176709073596e-05,
mae,0.17699700593948364,0.10782501846551895,0.09458235651254654,0.040305424481630325,0.023178834468126297,0.017369596287608147,0.015004868619143963,0.013362046331167221,0.012353452853858471,0.011836506426334381,0.011120054870843887,0.010646729730069637,0.010300952009856701,0.01017547957599163,0.009666593745350838,0.009382165968418121,0.009242299944162369,0.00906943716108799,0.008967094123363495,0.008669397793710232,0.008676869794726372,0.008527019992470741,0.008348904550075531,0.008205622434616089,0.00827814731746912,0.008085576817393303,0.007885824888944626,0.007810188923031092,0.007826385088264942,0.007788034155964851,0.007641186937689781,0.007676455192267895,0.007516358979046345,0.0074428049847483635,0.007446819916367531,0.007456442806869745,0.0072416807524859905,0.007358227856457233,0.007183479145169258,0.0071941036731004715,0.007007598876953125,0.007161418907344341,0.007049694191664457,0.006939044687896967,0.006924949120730162,0.006932384800165892,0.006895419210195541,0.006795670371502638,0.0067912507802248,0.006704724393785,0.006795523688197136,0.006614700425416231,0.006644157692790031,0.00670274393633008,0.006576810032129288,0.006673513446003199,0.006526661105453968,0.0065496996976435184,0.006426364183425903,0.00642955768853426,0.00641968846321106,0.006372973322868347,0.006460142321884632,0.006328605581074953,0.006335585843771696,0.0062152002938091755,0.0063028354197740555,0.00621049152687192,0.006218045484274626,0.00622133631259203,0.006169652566313744,0.006238322239369154,0.006132981739938259,0.006028009112924337,0.006104165222495794,0.006110265385359526,0.006051360163837671,0.005991462618112564,0.005947605241090059,0.005986995529383421,0.006052721757441759,0.0060685682110488415,0.005966645665466785,0.005871349945664406,0.0058319466188549995,0.00590674951672554,0.005806559696793556,0.005870212335139513,0.005905077327042818,0.005770126357674599,0.005852282512933016,0.005726256873458624,0.005788934417068958,0.005786112044006586,0.005694590043276548,0.005754719488322735,0.005765958223491907,0.005757044069468975,0.0057187615893781185,0.005710868164896965,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2795      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2796      
=================================================================
Total params: 5,591
Trainable params: 5,591
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 2,795
Trainable params: 2,795
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 2,796
Trainable params: 2,796
Non-trainable params: 0
_________________________________________________________________
