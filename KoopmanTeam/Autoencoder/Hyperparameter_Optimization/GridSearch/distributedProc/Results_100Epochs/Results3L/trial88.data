2021-06-26
loss,0.5217838883399963,0.12976640462875366,0.08303672820329666,0.06717799603939056,0.06540361791849136,0.05058726295828819,0.04632067680358887,0.05259975790977478,0.04865888133645058,0.036594171077013016,0.04469253867864609,0.0428989939391613,0.037476059049367905,0.03916293382644653,0.03236788138747215,0.03237767145037651,0.03459751978516579,0.033463284373283386,0.029644258320331573,0.030639154836535454,0.030613400042057037,0.02635638788342476,0.027145350351929665,0.024120161309838295,0.024182241410017014,0.022735560312867165,0.02317899465560913,0.02120412513613701,0.021428579464554787,0.022109288722276688,0.02404005080461502,0.024026477709412575,0.021515410393476486,0.02138637751340866,0.02052500657737255,0.017577355727553368,0.0191668588668108,0.01999802701175213,0.01926693506538868,0.01893267035484314,0.01747780852019787,0.015000654384493828,0.01586809568107128,0.021465327590703964,0.019866902381181717,0.019662808626890182,0.0193734522908926,0.01766795665025711,0.0160099845379591,0.017946943640708923,0.017714060842990875,0.01747048646211624,0.01781231351196766,0.01914498396217823,0.015674980357289314,0.017002055421471596,0.016694046556949615,0.01654164493083954,0.015563597902655602,0.01588238775730133,0.017892945557832718,0.01778320036828518,0.016308944672346115,0.016280483454465866,0.017029277980327606,0.017682673409581184,0.01570555754005909,0.014089132659137249,0.014941012486815453,0.014555568806827068,0.01694321632385254,0.016242433339357376,0.015902293846011162,0.01438103336840868,0.01571037620306015,0.01622123457491398,0.016275273635983467,0.014867707155644894,0.014484690502285957,0.013038725592195988,0.012152464129030704,0.01451248861849308,0.015710821375250816,0.014473222196102142,0.013850735500454903,0.014512015506625175,0.01423658151179552,0.014928959310054779,0.013257836923003197,0.012666592374444008,0.013109130784869194,0.014173082076013088,0.015746861696243286,0.014321787282824516,0.013869976624846458,0.014003336429595947,0.013831385411322117,0.014723124913871288,0.013798046857118607,0.012108949013054371,
mse,0.16373343765735626,0.005182121880352497,0.0020008457358926535,0.0013387535000219941,0.0012535646092146635,0.0007631179760210216,0.0006419122801162302,0.0007964859250932932,0.0006947916117496789,0.0004044678353238851,0.0005865188431926072,0.0005370984436012805,0.0004221585695631802,0.00044169515604153275,0.00031375684193335474,0.00031264551216736436,0.000349961657775566,0.00031840737210586667,0.0002593027020338923,0.0002697367744985968,0.00027024364680983126,0.0002063347346847877,0.00021749654843006283,0.0001713675883365795,0.0001729023497318849,0.0001520338119007647,0.00015846500173211098,0.0001318408758379519,0.00013356161070987582,0.00014343560906127095,0.0001619952527107671,0.000166412559337914,0.0001347536890534684,0.00013125014083925635,0.00012212498404551297,9.46873115026392e-05,0.00011345884558977559,0.00012108353257644922,0.00010695663513615727,0.00010324595496058464,9.156188752967864e-05,6.791007763240486e-05,7.658109825570136e-05,0.00012952797987964004,0.00011581165017560124,0.00011109932529507205,0.00010850792023120448,9.125625365413725e-05,7.795642886776477e-05,9.411750215804204e-05,9.038655844051391e-05,9.071603562915698e-05,9.332380432169884e-05,0.00010407250374555588,7.266220200108364e-05,8.699434692971408e-05,8.565590542275459e-05,8.189002255676314e-05,7.323961472138762e-05,7.445811206707731e-05,9.151757694780827e-05,9.004391904454678e-05,7.984887633938342e-05,7.933997403597459e-05,8.404185064136982e-05,8.841857925290242e-05,7.28784070815891e-05,6.103947089286521e-05,6.863375165266916e-05,6.459567521233112e-05,8.381906809518114e-05,7.669535261811689e-05,7.411411206703633e-05,6.226449477253482e-05,7.173365884227678e-05,7.660293340450153e-05,7.51267361920327e-05,6.59595025354065e-05,6.268188008107245e-05,5.1974249799968675e-05,4.6080142055870965e-05,6.174158625071868e-05,7.308166823349893e-05,6.129602115834132e-05,5.620798401650973e-05,6.154848961159587e-05,5.981207868899219e-05,6.555397703777999e-05,5.275614603306167e-05,4.7125282435445115e-05,5.1928116590715945e-05,6.0393736930564046e-05,7.192410703282803e-05,5.9127502026967704e-05,5.7488232414470986e-05,5.7764431403484195e-05,5.6912205764092505e-05,6.308026786427945e-05,5.552460424951278e-05,4.395062933326699e-05,
mae,0.2237485945224762,0.055559851229190826,0.03556084260344505,0.02838200144469738,0.027970638126134872,0.02141646295785904,0.01960150897502899,0.022526755928993225,0.020732851698994637,0.015630364418029785,0.01899135671555996,0.01820281520485878,0.01584913209080696,0.016441630199551582,0.013716202229261398,0.013689212501049042,0.014635082334280014,0.01417993288487196,0.012614109553396702,0.013009545393288136,0.013097860850393772,0.011123402044177055,0.011561588384211063,0.01047626044601202,0.010202816687524319,0.009650496765971184,0.009867352433502674,0.009028051979839802,0.009160115383565426,0.00924820639193058,0.010223567485809326,0.010124146938323975,0.009150054305791855,0.009135948494076729,0.008673476055264473,0.0073023270815610886,0.008094255812466145,0.008531834930181503,0.008152259513735771,0.008004785515367985,0.0074228765442967415,0.006436608266085386,0.006819113623350859,0.008922971785068512,0.008444295264780521,0.008403408341109753,0.008063483983278275,0.007416497450321913,0.006869479548186064,0.00759595213457942,0.007488884497433901,0.007415010128170252,0.00758775882422924,0.008124864660203457,0.006677595432847738,0.007233905605971813,0.007097960915416479,0.006972817238420248,0.006567260716110468,0.006755641661584377,0.00763052050024271,0.007515453267842531,0.006974094547331333,0.006823503412306309,0.007207674905657768,0.007439259439706802,0.0066932509653270245,0.00602839607745409,0.006299441680312157,0.006141065154224634,0.007242848165333271,0.0068525997921824455,0.006627116352319717,0.006039024796336889,0.006578440777957439,0.006834498606622219,0.006861060857772827,0.006240787450224161,0.006060954183340073,0.005477003287523985,0.005110176280140877,0.006196611560881138,0.006665505934506655,0.006199741270393133,0.005898948293179274,0.00614619255065918,0.00606325501576066,0.006376598030328751,0.005589093081653118,0.005358741153031588,0.005608309991657734,0.006018832325935364,0.006706159561872482,0.006097831763327122,0.005929664243012667,0.005916763562709093,0.00584807526320219,0.006210557650774717,0.005865088663995266,0.005160836037248373,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 165891    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 165892    
=================================================================
Total params: 331,783
Trainable params: 331,783
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 165,891
Trainable params: 165,891
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 165,892
Trainable params: 165,892
Non-trainable params: 0
_________________________________________________________________
