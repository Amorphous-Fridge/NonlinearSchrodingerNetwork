2021-06-26
loss,0.48132336139678955,0.11977334320545197,0.08707186579704285,0.07023885101079941,0.06361034512519836,0.05309545621275902,0.05408883094787598,0.047292619943618774,0.05250721424818039,0.04868467152118683,0.047718435525894165,0.04718140512704849,0.050130680203437805,0.04321301355957985,0.039040204137563705,0.040506552904844284,0.04071477800607681,0.03177371248602867,0.03589123114943504,0.031172676011919975,0.03763473033905029,0.031675081700086594,0.036136552691459656,0.03491631895303726,0.031496256589889526,0.03035489283502102,0.025960776954889297,0.03154435753822327,0.032220710068941116,0.0285909716039896,0.028845377266407013,0.026566633954644203,0.030013391748070717,0.027612030506134033,0.026114827021956444,0.025942362844944,0.026116279885172844,0.024609945714473724,0.02248465269804001,0.02497977204620838,0.025292640551924706,0.02211831510066986,0.01965065486729145,0.01757238432765007,0.019513888284564018,0.02264985628426075,0.020735854282975197,0.020298728719353676,0.020747488364577293,0.02170608565211296,0.02130879834294319,0.020142966881394386,0.01775539666414261,0.02167215384542942,0.020549943670630455,0.0202801413834095,0.01958707720041275,0.019221439957618713,0.01884644106030464,0.0172384325414896,0.015452547930181026,0.017001613974571228,0.018554799258708954,0.017162049189209938,0.01767548732459545,0.019729487597942352,0.018141958862543106,0.01781575009226799,0.01811227574944496,0.018052110448479652,0.017095984891057014,0.01728113926947117,0.016778476536273956,0.01627182401716709,0.016490792855620384,0.015833644196391106,0.016190867871046066,0.015937266871333122,0.016327062621712685,0.01569092459976673,0.016891779378056526,0.016538914293050766,0.016306087374687195,0.016320224851369858,0.01687953621149063,0.015113884583115578,0.0144444415345788,0.015395458787679672,0.014945111237466335,0.014219987206161022,0.014551588334143162,0.015095207840204239,0.016304869204759598,0.015416494570672512,0.015733890235424042,0.014171486720442772,0.01392087060958147,0.014597364701330662,0.014964626170694828,0.013784157112240791,
mse,0.09929598867893219,0.004401191603392363,0.0021967256907373667,0.001404210808686912,0.001213838579133153,0.0008321201894432306,0.0008977426332421601,0.0006528916419483721,0.000799730361904949,0.0006904328474774957,0.0006581036723218858,0.0006511958199553192,0.0007127180579118431,0.0005653802072629333,0.0004505931865423918,0.0004914653836749494,0.0004906017566099763,0.00029686896596103907,0.00038983378908596933,0.00029718794394284487,0.00042041842243634164,0.0002932747593149543,0.00037051289109513164,0.00036116933915764093,0.0002954997180495411,0.00027652227436192334,0.0002014972415054217,0.0002861405664589256,0.00029312714468687773,0.00023937347577884793,0.0002377791824983433,0.0002048746682703495,0.0002573780657257885,0.00021736742928624153,0.00019349291687831283,0.00019904192595276982,0.00019200039969291538,0.000175873952684924,0.00014964575530029833,0.00018608549726195633,0.00018138244922738522,0.000146093123476021,0.00011631403322098777,9.268781286664307e-05,0.00011474793427623808,0.00014676045975647867,0.00012848210462834686,0.00011986022582277656,0.00012777002120856196,0.00013554208271671087,0.0001295123656746,0.00012180053454358131,9.519131708657369e-05,0.00013240160478744656,0.00012242322554811835,0.00011669065133901313,0.00011057114170398563,0.00010389179806225002,9.966155630536377e-05,8.825809345580637e-05,7.283266313606873e-05,8.693485870026052e-05,9.939873416442424e-05,8.543490548618138e-05,8.87195419636555e-05,0.00011292548879282549,9.399951522937045e-05,9.058558498509228e-05,9.620243508834392e-05,9.29991074372083e-05,8.248251833720133e-05,8.439613156951964e-05,8.29520940897055e-05,7.805679342709482e-05,7.735268445685506e-05,7.383705087704584e-05,7.543893298134208e-05,7.39425522624515e-05,7.985333650140092e-05,7.340506999753416e-05,8.096495730569586e-05,7.87076642154716e-05,7.71652048570104e-05,7.553271279903129e-05,8.201062883017585e-05,6.797638343414292e-05,6.350177864078432e-05,6.795081571908668e-05,6.589357508346438e-05,5.9475089074112475e-05,6.33128292975016e-05,6.565977673744783e-05,7.564386032754555e-05,6.80997472954914e-05,7.19083400326781e-05,5.9333175158826634e-05,5.7954042858909816e-05,6.159199256217107e-05,6.522658804897219e-05,5.5833264923421666e-05,
mae,0.20373687148094177,0.04998227581381798,0.03692084550857544,0.02967723459005356,0.026871878653764725,0.022555017843842506,0.02287127822637558,0.0201612189412117,0.022299749776721,0.02066453918814659,0.020046865567564964,0.01996377855539322,0.021259881556034088,0.01829628273844719,0.016571132466197014,0.017201583832502365,0.017512153834104538,0.013588420115411282,0.015175186097621918,0.013296429067850113,0.01635250821709633,0.013358913362026215,0.015211210586130619,0.01480731088668108,0.013449604623019695,0.012789669446647167,0.01110974419862032,0.01323735248297453,0.013667757622897625,0.012018045410513878,0.012225688435137272,0.011339912191033363,0.012665207497775555,0.01165210735052824,0.011157858185470104,0.011011188849806786,0.010860523208975792,0.010306864976882935,0.009621573612093925,0.010512735694646835,0.010689974762499332,0.009274334646761417,0.008185877464711666,0.00748390331864357,0.00830071046948433,0.00963118951767683,0.008692787028849125,0.008626878261566162,0.00881039910018444,0.009187709540128708,0.008926792070269585,0.008491864427924156,0.007481673266738653,0.009142394177615643,0.008682521991431713,0.00850637350231409,0.00833312887698412,0.008078081533312798,0.00795527920126915,0.007321673445403576,0.0065603177063167095,0.007263875100761652,0.007886731997132301,0.007189469411969185,0.007485630922019482,0.00823451578617096,0.0076546077616512775,0.00748108047991991,0.007759714499115944,0.007645019330084324,0.0072997743263840675,0.007311925757676363,0.007086970377713442,0.006874737795442343,0.007001387421041727,0.006639273837208748,0.006874184589833021,0.006751513574272394,0.006946077570319176,0.0066426037810742855,0.00711972638964653,0.006936992984265089,0.006895991042256355,0.006906065158545971,0.007234918884932995,0.006476639304310083,0.006167054641991854,0.0065016127191483974,0.006316704209893942,0.006021648179739714,0.006174927577376366,0.00636993907392025,0.0068925959058105946,0.006367053370922804,0.006616411730647087,0.0059973751194775105,0.005921027157455683,0.006197219714522362,0.006329239811748266,0.00584800960496068,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 141123    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 141124    
=================================================================
Total params: 282,247
Trainable params: 282,247
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 141,123
Trainable params: 141,123
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 141,124
Trainable params: 141,124
Non-trainable params: 0
_________________________________________________________________
