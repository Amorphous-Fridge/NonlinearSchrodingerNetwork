2021-06-26
loss,0.3274845480918884,0.10731171816587448,0.04997319355607033,0.039444852620363235,0.03573588654398918,0.03372788056731224,0.04587554931640625,0.040232300758361816,0.03721421957015991,0.028169682249426842,0.026661064475774765,0.02565738372504711,0.024838147684931755,0.024159889668226242,0.023819440975785255,0.022652897983789444,0.032181769609451294,0.03185895085334778,0.03755145147442818,0.032475948333740234,0.027801513671875,0.026115961372852325,0.024759283289313316,0.024073200300335884,0.024986766278743744,0.03081711009144783,0.03488587960600853,0.037647295743227005,0.033990584313869476,0.029481666162610054,0.030845463275909424,0.02819734252989292,0.025311002507805824,0.022942733019590378,0.021958863362669945,0.028512699529528618,0.02493472769856453,0.02471763640642166,0.034824177622795105,0.03136957436800003,0.030451416969299316,0.025906605646014214,0.02420821413397789,0.021879836916923523,0.020319411531090736,0.021692665293812752,0.02619856595993042,0.02417183853685856,0.021766867488622665,0.020350007340312004,0.018678538501262665,0.0195070281624794,0.02336367405951023,0.0306884553283453,0.027833709493279457,0.02586388774216175,0.023234400898218155,0.021639617159962654,0.02023378573358059,0.019816089421510696,0.027550041675567627,0.024240661412477493,0.02218646928668022,0.01994180493056774,0.01873275451362133,0.019716741517186165,0.02114277519285679,0.02131894789636135,0.020343637093901634,0.0230936948210001,0.024977488443255424,0.02325027994811535,0.019794011488556862,0.018571756780147552,0.017880843952298164,0.01721145212650299,0.016757529228925705,0.016234351322054863,0.01581846922636032,0.015507496893405914,0.01520919892936945,0.01477599237114191,0.016058718785643578,0.02192021906375885,0.020031364634633064,0.025009233504533768,0.023064201697707176,0.02074960246682167,0.019248096272349358,0.018054138869047165,0.017014607787132263,0.016093524172902107,0.015398245304822922,0.014971031807363033,0.014498068951070309,0.014107530936598778,0.014099705033004284,0.013658863492310047,0.013133389875292778,0.012516848742961884,
mse,0.04031144455075264,0.004675767850130796,0.0007728360360488296,0.0004771241801790893,0.00038808339741081,0.00034494922147132456,0.0006373646901920438,0.00047544739209115505,0.0004301820299588144,0.00023318067542277277,0.00020774714357685298,0.00019080885977018625,0.0001789519446901977,0.00016773636161815375,0.00016297399997711182,0.00015371340850833803,0.00032398279290646315,0.00029554226784966886,0.0004111734451726079,0.0003056311106774956,0.0002231174148619175,0.00019729761697817594,0.00017865114205051214,0.0001677623949944973,0.00019139348296448588,0.0002777998161036521,0.00035419088089838624,0.00041260436410084367,0.00033167374203912914,0.00025488753453828394,0.00026801624335348606,0.00022763232118450105,0.000184308024472557,0.0001524581020930782,0.00013978577044326812,0.00022991496371105313,0.00018186838133260608,0.00018030313367489725,0.0003531464608386159,0.00028742733411490917,0.00027270326972939074,0.0001983465626835823,0.0001661847927607596,0.00013798759027849883,0.00011932227062061429,0.00013770721852779388,0.0001956030318979174,0.00017070515605155379,0.00013790969387628138,0.00011961583368247375,0.00010370447125751525,0.00011544532753759995,0.00016171349852811545,0.0002620277227833867,0.00022707786411046982,0.0001853484136518091,0.00014999134873505682,0.0001336799468845129,0.00012036053522024304,0.00011543677828740329,0.00022006945800967515,0.00016864175267983228,0.0001435379817849025,0.000117384763143491,0.00010555044718785211,0.00011460463429102674,0.00012617142056114972,0.00012885125761386007,0.0001220555350300856,0.00015338821685872972,0.00017834373284131289,0.00015401787823066115,0.00011313128197798505,9.954094275599346e-05,9.307095751864836e-05,8.58900384628214e-05,8.173555397661403e-05,7.648330938536674e-05,7.307047781068832e-05,6.976393342483789e-05,6.755599315511063e-05,6.313461199169978e-05,7.817203004378825e-05,0.00013900235353503376,0.00011505074508022517,0.0001764137705322355,0.00014915895008016378,0.00012016279652016237,0.00010378019214840606,9.262392995879054e-05,8.245529897976667e-05,7.37837326596491e-05,6.813213985878974e-05,6.451764784287661e-05,6.0521553677972406e-05,5.8183231885777786e-05,5.711596895707771e-05,5.529225745704025e-05,4.989425724488683e-05,4.597778752213344e-05,
mae,0.13905960321426392,0.04473807290196419,0.021297087892889977,0.016715429723262787,0.015208899974822998,0.014423498883843422,0.019733591005206108,0.017153525725007057,0.015932278707623482,0.012124302797019482,0.011380445212125778,0.010940803214907646,0.01064667385071516,0.010350964963436127,0.01001958828419447,0.00976656936109066,0.014008705504238605,0.013984093442559242,0.016236990690231323,0.013852412812411785,0.012122005224227905,0.011435923166573048,0.010792524553835392,0.010136093944311142,0.010589477606117725,0.01300759520381689,0.01500543113797903,0.016154488548636436,0.014339740388095379,0.012476231902837753,0.013001453131437302,0.011620846576988697,0.01086969580501318,0.00997783150523901,0.009331770241260529,0.01207880862057209,0.010717770084738731,0.010531162843108177,0.015490693971514702,0.013701505959033966,0.013646590523421764,0.01114133931696415,0.01020295824855566,0.009482115507125854,0.008892037905752659,0.009177946485579014,0.011337828822433949,0.010425424203276634,0.009207747876644135,0.00865407194942236,0.007868420332670212,0.008341974578797817,0.009815877303481102,0.013512153178453445,0.012357890605926514,0.011370868422091007,0.009792287833988667,0.009336698800325394,0.008605368435382843,0.008327236399054527,0.012032747268676758,0.010751733556389809,0.00993636716157198,0.008727657608687878,0.008135291747748852,0.00836399756371975,0.00907481461763382,0.00919372122734785,0.008859358727931976,0.009926043450832367,0.011110399849712849,0.010188459418714046,0.008441970683634281,0.007936614565551281,0.007672627456486225,0.007336022797971964,0.0071584247052669525,0.00698612816631794,0.006751602981239557,0.0066445134580135345,0.0064661819487810135,0.006238565314561129,0.006777629721909761,0.009383323602378368,0.00853604357689619,0.011082765646278858,0.010342799127101898,0.008791913278400898,0.008051060140132904,0.007523154839873314,0.007149474695324898,0.006723401136696339,0.006338115781545639,0.006155578885227442,0.006024033296853304,0.005844709929078817,0.005833738017827272,0.00576838618144393,0.005629148334264755,0.005378979258239269,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8595      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8596      
=================================================================
Total params: 17,191
Trainable params: 17,191
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 8,595
Trainable params: 8,595
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 8,596
Trainable params: 8,596
Non-trainable params: 0
_________________________________________________________________
