2021-06-26
loss,0.37055426836013794,0.1483854204416275,0.060946986079216,0.045081961899995804,0.03840744495391846,0.03543752804398537,0.032706402242183685,0.030503137037158012,0.029269592836499214,0.02801208198070526,0.027005121111869812,0.02619699388742447,0.02551298215985298,0.024832749739289284,0.024356715381145477,0.023782188072800636,0.02335183322429657,0.0229483749717474,0.022621825337409973,0.02235269546508789,0.021936211735010147,0.02175305038690567,0.021336669102311134,0.021036183461546898,0.020829906687140465,0.020439984276890755,0.02024080976843834,0.02017706073820591,0.019952310249209404,0.019625883549451828,0.019618261605501175,0.01933901384472847,0.019159996882081032,0.019020648673176765,0.018830444663763046,0.01871294155716896,0.01864088512957096,0.0184912271797657,0.018291955813765526,0.018091676756739616,0.018033094704151154,0.017924940213561058,0.017725717276334763,0.01760280877351761,0.017531588673591614,0.0174636822193861,0.01724952645599842,0.01708400622010231,0.017087895423173904,0.01701485738158226,0.016939444467425346,0.01681872457265854,0.016736723482608795,0.016616221517324448,0.01654084585607052,0.01638772524893284,0.016301335766911507,0.016381990164518356,0.01619378663599491,0.017926353961229324,0.029558515176177025,0.02430211752653122,0.02728075534105301,0.02548457868397236,0.026180583983659744,0.02742292732000351,0.025782179087400436,0.02401980198919773,0.02285701595246792,0.021954452618956566,0.020975178107619286,0.020319554954767227,0.019788913428783417,0.01932641677558422,0.018871428444981575,0.020535951480269432,0.02790519781410694,0.02467561699450016,0.022733960300683975,0.021374598145484924,0.02030610851943493,0.02917131595313549,0.03146940842270851,0.028680531308054924,0.026915855705738068,0.02562554180622101,0.02423020638525486,0.02301856502890587,0.02196018025279045,0.02103111892938614,0.02013499103486538,0.02030828967690468,0.022896597161889076,0.024758310988545418,0.02322879619896412,0.02108052559196949,0.019878730177879333,0.018794117495417595,0.018070997670292854,0.017437772825360298,
mse,0.056482844054698944,0.008577876724302769,0.0011995733948424459,0.0006306456634774804,0.00044881206122227013,0.00037745560985058546,0.00030855301884002984,0.00026739086024463177,0.00024522191961295903,0.00022296780662145466,0.00020679713634308428,0.00019302386499475688,0.00018217718752566725,0.00017197878332808614,0.00016475409211125225,0.00015687009727116674,0.00015107727085705847,0.00014694588026031852,0.00014232133980840445,0.00013758699060417712,0.0001327674399362877,0.00013014356954954565,0.00012481493467930704,0.00012040743604302406,0.00011927144805667922,0.00011407340207369998,0.00011187342170160264,0.00011129548511235043,0.00010908570402534679,0.00010543888492975384,0.00010494455636944622,0.00010202312842011452,9.985799988498911e-05,9.890153887681663e-05,9.690317529020831e-05,9.595512528903782e-05,9.474416583543643e-05,9.311194298788905e-05,9.109055827138945e-05,8.968823385657743e-05,8.866829739417881e-05,8.719699690118432e-05,8.523647557012737e-05,8.482663542963564e-05,8.392880408791825e-05,8.259328023996204e-05,8.05193922133185e-05,7.953694876050577e-05,8.00029156380333e-05,7.934232417028397e-05,7.855785952415317e-05,7.725075556663796e-05,7.616779475938529e-05,7.484313391614705e-05,7.442213245667517e-05,7.342892786255106e-05,7.246058521559462e-05,7.302370795514435e-05,7.186243601609021e-05,9.70795372268185e-05,0.00027814230998046696,0.0001775867713149637,0.00023256316490005702,0.00018949844525195658,0.00019382746540941298,0.00021194966393522918,0.00018418765102978796,0.0001601508993189782,0.00014195292897056788,0.00013094948371872306,0.00012100730964448303,0.00011398540664231405,0.00010851262049982324,0.00010356612619943917,0.00010046513489214703,0.00012569235695991665,0.0002106805914081633,0.00016545868129469454,0.0001427304814569652,0.00012661998334806412,0.00011547547182999551,0.0002475866349413991,0.00027377146761864424,0.00022712409554515034,0.00020095458603464067,0.00018145356443710625,0.00016147109272424132,0.00014505244325846434,0.0001333059772150591,0.00012296985369175673,0.00011479829117888585,0.00012032545782858506,0.00014644172915723175,0.00016709481133148074,0.00014709281094837934,0.0001231454953085631,0.00011015368363587186,9.821590356295928e-05,9.187799150822684e-05,8.57881095726043e-05,
mae,0.1546040177345276,0.058097247034311295,0.025602206587791443,0.019200041890144348,0.01633819192647934,0.01509652379900217,0.013933722861111164,0.013044093735516071,0.012486682273447514,0.012035906314849854,0.011556770652532578,0.011055533774197102,0.011004065163433552,0.010601337999105453,0.010378830134868622,0.010231295600533485,0.010029460303485394,0.009850552305579185,0.00965152122080326,0.00951775349676609,0.009330381639301777,0.00917983427643776,0.008963607251644135,0.008859582245349884,0.008803806267678738,0.00868559442460537,0.008494301699101925,0.008568699471652508,0.00850024726241827,0.008382193744182587,0.008319659158587456,0.008306477218866348,0.008213699795305729,0.008085004985332489,0.007870248518884182,0.00794909242540598,0.007908531464636326,0.007941503077745438,0.0077148014679551125,0.007685440126806498,0.007587571162730455,0.007648945320397615,0.007483858615159988,0.00747018912807107,0.007452445570379496,0.0073407916352152824,0.007382288575172424,0.007187255658209324,0.007272876333445311,0.0071992832235991955,0.007205628789961338,0.0070943329483270645,0.007078639697283506,0.007047063205391169,0.006979303900152445,0.0068524666130542755,0.00704466737806797,0.006949688773602247,0.006956119555979967,0.007486156187951565,0.012448055669665337,0.01041177287697792,0.011862760409712791,0.01059565506875515,0.011014452204108238,0.011655159294605255,0.010704982094466686,0.010065998882055283,0.00969244446605444,0.009265592321753502,0.008352029137313366,0.007960736751556396,0.00772217707708478,0.0075532360933721066,0.007686557248234749,0.008589053526520729,0.012062311172485352,0.010511565953493118,0.009662039577960968,0.00905492715537548,0.008591788820922375,0.011854245327413082,0.012300354428589344,0.010939818806946278,0.010116112418472767,0.009826205670833588,0.010311373509466648,0.010171255096793175,0.009411249309778214,0.008466362953186035,0.007834658958017826,0.008403683081269264,0.009612246416509151,0.009746188297867775,0.009150587022304535,0.009091556072235107,0.00854798685759306,0.008065113797783852,0.0073687611147761345,0.007012362591922283,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9699      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9700      
=================================================================
Total params: 19,399
Trainable params: 19,399
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 9,699
Trainable params: 9,699
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 9,700
Trainable params: 9,700
Non-trainable params: 0
_________________________________________________________________
