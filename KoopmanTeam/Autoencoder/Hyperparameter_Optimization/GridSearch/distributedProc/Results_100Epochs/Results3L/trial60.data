2021-06-26
loss,0.5313919186592102,0.1439194232225418,0.08906705677509308,0.07541222870349884,0.07645399868488312,0.05516280233860016,0.05671471729874611,0.06902137398719788,0.0573844388127327,0.04865477234125137,0.046342067420482635,0.04565741494297981,0.04600510001182556,0.04854997247457504,0.044135212898254395,0.04282312095165253,0.04330401495099068,0.0363316610455513,0.03375500068068504,0.02778461202979088,0.024845747277140617,0.024637358263134956,0.03629268333315849,0.027897872030735016,0.02997688204050064,0.04052748158574104,0.03700996935367584,0.03697703033685684,0.0354880690574646,0.03319951891899109,0.031356777995824814,0.030039198696613312,0.03083059936761856,0.028393372893333435,0.026073986664414406,0.030247824266552925,0.02927667647600174,0.025300713256001472,0.026668839156627655,0.031912662088871,0.024913862347602844,0.024754244834184647,0.02610289864242077,0.02303788810968399,0.023442430421710014,0.024365419521927834,0.027906237170100212,0.024090152233839035,0.02312937006354332,0.021459568291902542,0.019636113196611404,0.02048519067466259,0.026826638728380203,0.025352369993925095,0.025109443813562393,0.02356397919356823,0.023025166243314743,0.021683521568775177,0.021850205957889557,0.021117761731147766,0.0229001734405756,0.020561566576361656,0.01866696961224079,0.018421679735183716,0.021332569420337677,0.02016407437622547,0.022037094458937645,0.019021954387426376,0.01934979483485222,0.01763993874192238,0.019764909520745277,0.0193648561835289,0.01732676662504673,0.014702651649713516,0.015742776915431023,0.018205510452389717,0.018624866381287575,0.019019311293959618,0.01975950039923191,0.020547030493617058,0.0185717586427927,0.018270989879965782,0.015619801357388496,0.014140643179416656,0.012866638600826263,0.01580982841551304,0.0193435400724411,0.018211184069514275,0.017435288056731224,0.019901147112250328,0.016468487679958344,0.016956450417637825,0.01872890442609787,0.01770903170108795,0.01597767323255539,0.013891066424548626,0.015604143962264061,0.017830615863204002,0.01806943491101265,0.015846680849790573,
mse,0.12443023920059204,0.006855522282421589,0.0023274875711649656,0.0017503192648291588,0.0018354281783103943,0.0008939198451116681,0.0009294630726799369,0.0013926810352131724,0.0009729921002872288,0.0007041647331789136,0.0007311513181775808,0.0006336930673569441,0.0006458698771893978,0.0007115777698345482,0.0005763657973147929,0.0005570763605646789,0.0005671728285960853,0.00039474701043218374,0.0003402982256375253,0.0002229866513516754,0.00017681551980786026,0.00017965071310754865,0.00040121786878444254,0.0002346922701690346,0.0002761132491286844,0.00048559808055870235,0.000406740145990625,0.0004091483715455979,0.0003674108302220702,0.0003254699695389718,0.0002899628016166389,0.0002691479166969657,0.00029072343022562563,0.00024655810557305813,0.00020485879213083535,0.0002861696993932128,0.00024252936418633908,0.00019981127115897834,0.00021763797849416733,0.0002873254125006497,0.00017863020184449852,0.0001866440725279972,0.00021082450984977186,0.0001628911995794624,0.00016662190319038928,0.00017908209702000022,0.00022436212748289108,0.00016575664631091058,0.00015919817087706178,0.00014195346739143133,0.00011960082338191569,0.00013002513151150197,0.000213875639019534,0.00018373057537246495,0.0001783488696673885,0.00015763913688715547,0.0001499299833085388,0.00013351126108318567,0.00013684557052329183,0.00012894322571810335,0.00014860850933473557,0.0001242642174474895,0.00010411164839752018,0.00010188272426603362,0.00013387137732934207,0.0001191917690448463,0.00013637641677632928,0.00010516559996176511,0.00010832425323314965,9.190360287902877e-05,0.00011551973148016259,0.00011580981663428247,9.245491673937067e-05,6.976696022320539e-05,7.564351108158007e-05,9.687943384051323e-05,0.0001015680463751778,0.00010561935778241605,0.0001121956593124196,0.00011770243872888386,9.798334212973714e-05,9.634056186769158e-05,7.34450004529208e-05,6.305906572379172e-05,5.1754741434706375e-05,7.776793790981174e-05,0.00010688603651942685,9.689317084848881e-05,8.82040403666906e-05,0.00010979627404594794,8.132524089887738e-05,8.569215424358845e-05,9.8720847745426e-05,9.42590122576803e-05,7.68732643336989e-05,6.171000131871551e-05,7.281752186827362e-05,9.007738844957203e-05,8.972817886387929e-05,7.29758248780854e-05,
mae,0.2245728075504303,0.0617586150765419,0.03837720304727554,0.031737715005874634,0.03274695575237274,0.02359558828175068,0.024076387286186218,0.029952554032206535,0.0247418824583292,0.020997850224375725,0.020335901528596878,0.019566873088479042,0.019707493484020233,0.020914750173687935,0.018786288797855377,0.018396712839603424,0.01875145360827446,0.01556894276291132,0.014513672329485416,0.012085038237273693,0.010738794691860676,0.010503729805350304,0.015393678098917007,0.011977939866483212,0.012804245576262474,0.017520787194371223,0.015596199780702591,0.015885503962635994,0.015180562622845173,0.013911614194512367,0.013332949951291084,0.012843647040426731,0.013250615447759628,0.012236054986715317,0.011066884733736515,0.01308423187583685,0.01235204841941595,0.010874833911657333,0.011308200657367706,0.014022615738213062,0.010563915595412254,0.010471455752849579,0.011228363960981369,0.009814176708459854,0.009971173480153084,0.010444803163409233,0.011953162029385567,0.010322457179427147,0.009944983758032322,0.009221728891134262,0.008389370515942574,0.00887903943657875,0.011342390440404415,0.010825441218912601,0.010916457511484623,0.010079187341034412,0.009869485162198544,0.009099440649151802,0.009360291063785553,0.008969654329121113,0.009533784352242947,0.00871876161545515,0.007959161885082722,0.007806552108377218,0.00910567119717598,0.008655517362058163,0.009411310777068138,0.008097933605313301,0.008159649558365345,0.007387644611299038,0.008244568482041359,0.00820283591747284,0.007522851228713989,0.006324063055217266,0.00662078196182847,0.007683714851737022,0.007941819727420807,0.008113753981888294,0.008502411656081676,0.008613168261945248,0.00790888536721468,0.007752914447337389,0.006705099251121283,0.005960552021861076,0.005479814019054174,0.006725540850311518,0.008174696005880833,0.007715865503996611,0.007500852458178997,0.00866548903286457,0.00693472009152174,0.007193131372332573,0.007940702140331268,0.007384920492768288,0.006547609344124794,0.005940133240073919,0.0066130440682172775,0.007620858494192362,0.007747524417936802,0.006615178659558296,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 136747    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 136748    
=================================================================
Total params: 273,495
Trainable params: 273,495
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 136,747
Trainable params: 136,747
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 136,748
Trainable params: 136,748
Non-trainable params: 0
_________________________________________________________________
