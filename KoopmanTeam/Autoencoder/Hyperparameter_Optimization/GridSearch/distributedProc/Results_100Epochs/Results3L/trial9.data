2021-06-26
loss,0.40356385707855225,0.17003168165683746,0.07663792371749878,0.058254893869161606,0.04736539348959923,0.040805328637361526,0.03635508939623833,0.03390352800488472,0.03147456794977188,0.02966175600886345,0.02846626564860344,0.02749849110841751,0.02637912519276142,0.02562345750629902,0.02496943064033985,0.024542436003684998,0.023914624005556107,0.02367287129163742,0.023005757480859756,0.022597959265112877,0.02230219542980194,0.02200045809149742,0.021460993215441704,0.021289551630616188,0.021128468215465546,0.020888254046440125,0.020617861300706863,0.02038479782640934,0.020194925367832184,0.019907362759113312,0.019791461527347565,0.019381709396839142,0.01939399354159832,0.019145911559462547,0.018960217013955116,0.0188625305891037,0.01869088225066662,0.018617141991853714,0.01842675730586052,0.018291054293513298,0.0181325264275074,0.017927130684256554,0.017893731594085693,0.01771024987101555,0.0175811517983675,0.017530079931020737,0.01735078915953636,0.01720757782459259,0.01721629686653614,0.0170031376183033,0.017018504440784454,0.01689920760691166,0.01679922081530094,0.01660843938589096,0.016665613278746605,0.016520468518137932,0.016514962539076805,0.016344396397471428,0.01631730981171131,0.016347462311387062,0.016162298619747162,0.01601662114262581,0.016064681112766266,0.01594262756407261,0.015899455174803734,0.015804558992385864,0.015759970992803574,0.015718858689069748,0.015666943043470383,0.015574696473777294,0.015547418966889381,0.015408391132950783,0.015472532249987125,0.015329791232943535,0.01521425973623991,0.015218990854918957,0.015171480365097523,0.015195551328361034,0.015041395090520382,0.015071437694132328,0.014977609738707542,0.01489554438740015,0.014779831282794476,0.014789765700697899,0.014721597544848919,0.014657093212008476,0.01463052723556757,0.014639636501669884,0.014545181766152382,0.014470293186604977,0.014457112178206444,0.01441703550517559,0.014383050613105297,0.01426793448626995,0.014260968193411827,0.01433511171489954,0.014205758459866047,0.014163949526846409,0.014093867503106594,0.014045532792806625,
mse,0.06564490497112274,0.010327238589525223,0.002144558820873499,0.001215510768815875,0.0008014441118575633,0.0005705085932277143,0.00044221922871656716,0.00037246764986775815,0.00031685151043348014,0.0002796493354253471,0.00025523555814288557,0.00023610348580405116,0.00021726473642047495,0.00020361124188639224,0.00019501183123793453,0.00018611681298352778,0.00017679203301668167,0.00017335725715383887,0.0001638012909097597,0.000157117290655151,0.00015331324539147317,0.00014905986608937383,0.000142968405270949,0.00013951155415270478,0.00013646595471072942,0.00013397177099250257,0.00012972783588338643,0.00012725750275421888,0.00012436929682735354,0.00012108089140383527,0.00011917855590581894,0.00011448240547906607,0.00011406662088120356,0.00011143153824377805,0.00010837989248102531,0.00010737214324763045,0.00010546876728767529,0.00010455407027620822,0.00010216328519163653,0.00010098769416799769,9.869162022368982e-05,9.66443694778718e-05,9.613111615180969e-05,9.41662656259723e-05,9.28785593714565e-05,9.18171281227842e-05,8.962289575720206e-05,8.834376058075577e-05,8.870934834703803e-05,8.611448720330372e-05,8.68191200424917e-05,8.539440750610083e-05,8.40725188027136e-05,8.22988513391465e-05,8.246654033428058e-05,8.102726860670373e-05,8.095186785794795e-05,7.924593228381127e-05,7.911678403615952e-05,7.901631033746526e-05,7.754845137242228e-05,7.634125358890742e-05,7.64178839745e-05,7.526674016844481e-05,7.44066055631265e-05,7.40820833016187e-05,7.379522867267951e-05,7.283149170689285e-05,7.219962571980432e-05,7.16481008566916e-05,7.139093213481829e-05,7.00323362252675e-05,7.042584184091538e-05,6.898373976582661e-05,6.813197251176462e-05,6.79358490742743e-05,6.749780732207e-05,6.762262637494132e-05,6.63667669869028e-05,6.65480038151145e-05,6.576389569090679e-05,6.489496445283294e-05,6.423531885957345e-05,6.397952529368922e-05,6.357906386256218e-05,6.279083027038723e-05,6.261210364755243e-05,6.236406625248492e-05,6.16344332229346e-05,6.093155752751045e-05,6.107418448664248e-05,6.074427074054256e-05,6.0241967730689794e-05,5.921699266764335e-05,5.928202881477773e-05,5.963039075140841e-05,5.8775647630682215e-05,5.836548371007666e-05,5.7842549722408876e-05,5.725776281906292e-05,
mae,0.16577468812465668,0.06445353478193283,0.032023269683122635,0.024583762511610985,0.0197944063693285,0.017100686207413673,0.015300026163458824,0.014336276799440384,0.01331764180213213,0.012610712088644505,0.012086054310202599,0.011735853739082813,0.011279038153588772,0.01094912365078926,0.010635585524141788,0.010499874129891396,0.010197080671787262,0.010144087485969067,0.009865453466773033,0.00966804288327694,0.009529776871204376,0.009452888742089272,0.009257999248802662,0.009095698595046997,0.009077885188162327,0.00894547626376152,0.008889496326446533,0.008730987086892128,0.008672166615724564,0.008585892617702484,0.008441700600087643,0.008316772989928722,0.008325844071805477,0.00824859831482172,0.008092285133898258,0.008115440607070923,0.00804306659847498,0.00800730474293232,0.00789602380245924,0.007886859588325024,0.007765615358948708,0.007700643502175808,0.007671234663575888,0.007616113405674696,0.007581514306366444,0.007545988541096449,0.007422728929668665,0.007379796355962753,0.007411573547869921,0.007259402424097061,0.007392976898699999,0.00722628366202116,0.007185428868979216,0.007098476868122816,0.0071706403978168964,0.007114253006875515,0.007096726913005114,0.0069999475963413715,0.006990473717451096,0.007012265734374523,0.00693925004452467,0.006864633411169052,0.006909973453730345,0.006825774442404509,0.006858081091195345,0.006806487217545509,0.006766792386770248,0.006719555240124464,0.006702818907797337,0.0066946037113666534,0.006643515080213547,0.006581820081919432,0.006614002399146557,0.006569643039256334,0.006569449324160814,0.006501263473182917,0.006518404930830002,0.006522046867758036,0.006451017688959837,0.006481355056166649,0.006431021727621555,0.006364345550537109,0.006345801521092653,0.006341240834444761,0.006304451730102301,0.006252630148082972,0.0062774838879704475,0.00628134747967124,0.006269561592489481,0.006196149159222841,0.006148293148726225,0.006237952504307032,0.006128501147031784,0.006120143458247185,0.006110295187681913,0.006152186542749405,0.006086611654609442,0.006027159746736288,0.006042831111699343,0.0059602404944598675,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2259      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2260      
=================================================================
Total params: 4,519
Trainable params: 4,519
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 2,259
Trainable params: 2,259
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 2,260
Trainable params: 2,260
Non-trainable params: 0
_________________________________________________________________
