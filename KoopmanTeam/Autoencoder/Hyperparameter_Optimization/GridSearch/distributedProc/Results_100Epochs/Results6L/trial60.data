2021-06-26
loss,0.8726211786270142,0.2089887261390686,0.14136527478694916,0.11096459627151489,0.10928338021039963,0.09299011528491974,0.10332655906677246,0.08276417851448059,0.07400336116552353,0.06953894346952438,0.06410253793001175,0.07585794478654861,0.06913872808218002,0.06614870578050613,0.07199976593255997,0.05429340898990631,0.04848485440015793,0.053472619503736496,0.06718709319829941,0.05458984896540642,0.05360078439116478,0.04126063361763954,0.041194938123226166,0.04764186963438988,0.06226598098874092,0.056292902678251266,0.05307675525546074,0.04202883318066597,0.03943373262882233,0.03280157595872879,0.04289091005921364,0.05075393244624138,0.03991549089550972,0.032722536474466324,0.03804503008723259,0.03581457957625389,0.04280926659703255,0.04896382987499237,0.03661380708217621,0.02978266216814518,0.04736357554793358,0.02875782549381256,0.029041636735200882,0.03162526711821556,0.039739519357681274,0.04113457724452019,0.044643301516771317,0.0381503589451313,0.03872844576835632,0.033635396510362625,0.03615225479006767,0.03941315412521362,0.035941023379564285,0.03769591450691223,0.030095631256699562,0.039899542927742004,0.03724949434399605,0.03361988067626953,0.03233231231570244,0.028249073773622513,0.03842530399560928,0.0318039171397686,0.027329780161380768,0.023966072127223015,0.028698042035102844,0.03272637724876404,0.036627061665058136,0.036890916526317596,0.03464805334806442,0.03209605813026428,0.028921162709593773,0.029511364176869392,0.032494254410266876,0.031234776601195335,0.02329265885055065,0.03445792570710182,0.029883453622460365,0.03116595186293125,0.031244875863194466,0.029037319123744965,0.03269225358963013,0.02648451365530491,0.028860710561275482,0.027166331186890602,0.025596173480153084,0.026556799188256264,0.032695990055799484,0.025657787919044495,0.0342249795794487,0.02812659740447998,0.023629892617464066,0.02213682234287262,0.03206884488463402,0.028073977679014206,0.028601549565792084,0.0240353774279356,0.024610817432403564,0.021274728700518608,0.020709123462438583,0.020122306421399117,
mse,0.3791404366493225,0.013984586112201214,0.006147585343569517,0.003720109350979328,0.0036430838517844677,0.0026999404653906822,0.0032639228738844395,0.002199383918195963,0.0017387478146702051,0.0015477738343179226,0.0013681494165211916,0.001822006655856967,0.0014630826190114021,0.0013911478454247117,0.0016866178484633565,0.0009530574316158891,0.000747889862395823,0.000884124543517828,0.0013454487780109048,0.0009158487664535642,0.0008898541564121842,0.0005251580732874572,0.0005081520648673177,0.0006860659341327846,0.0011627775384113193,0.000914424832444638,0.0008178791613318026,0.0005288302781991661,0.0004777641734108329,0.0003319474926684052,0.000563484150916338,0.0007482339278794825,0.00048026026342995465,0.00032899194047786295,0.0004504999378696084,0.0003881633165292442,0.0005507844034582376,0.0007036597235128284,0.0004077523190062493,0.00027595111168920994,0.0006479693111032248,0.00025779419229365885,0.00025629435549490154,0.0003069542290177196,0.0004693975788541138,0.0005033614579588175,0.0005747062969021499,0.00043035062844865024,0.00044522088137455285,0.0003362678980920464,0.0003882671007886529,0.0004649251059163362,0.00038810836849734187,0.0004307493509259075,0.00027543827309273183,0.0004672070499509573,0.00040392467053607106,0.000330938259139657,0.0003050127124879509,0.00024463687441311777,0.00042630231473594904,0.0002971838694065809,0.00022996657935436815,0.00017545885930303484,0.00023776762827765197,0.0003174735466018319,0.00039177798316814005,0.00039803513209335506,0.0003487381327431649,0.0003215124015696347,0.00024887529434636235,0.0002606221241876483,0.000309169729007408,0.0002897700178436935,0.00016571502783335745,0.0003435724356677383,0.00025766887119971216,0.0002828928700182587,0.0002877855149563402,0.00024653805303387344,0.0003119813045486808,0.00020926713477820158,0.00024322699755430222,0.0002196107234340161,0.00019044529472012073,0.0002075307274935767,0.00031288512400351465,0.00020109837350901216,0.0003329477331135422,0.00023721791512798518,0.00017401704099029303,0.00015204850933514535,0.0002962448925245553,0.00023454804613720626,0.00023519920068793,0.0001721966254990548,0.00017802925140131265,0.0001372812403133139,0.00012894363317172974,0.000126414728583768,
mae,0.3673754036426544,0.09078166633844376,0.060271795839071274,0.04730825126171112,0.045908231288194656,0.03952878713607788,0.043945878744125366,0.03521232306957245,0.031314343214035034,0.029467325657606125,0.02717851847410202,0.03192758187651634,0.029533281922340393,0.027674725279211998,0.029694095253944397,0.023093467578291893,0.02048465423285961,0.0227060467004776,0.028757818043231964,0.023556962609291077,0.022675499320030212,0.017517978325486183,0.0174447912722826,0.02012817934155464,0.026442306116223335,0.023775767534971237,0.022840706631541252,0.01785562001168728,0.016725827008485794,0.01383933424949646,0.01829182729125023,0.021519696339964867,0.017007246613502502,0.013761150650680065,0.016128651797771454,0.01537125464528799,0.01817508600652218,0.02074873261153698,0.015449200756847858,0.01259214524179697,0.019981825724244118,0.012271707877516747,0.012365767732262611,0.013337991200387478,0.016840005293488503,0.017533760517835617,0.019254811108112335,0.015978524461388588,0.016581900417804718,0.014333640225231647,0.01539124920964241,0.01693509891629219,0.015479730442166328,0.016188548877835274,0.012840895913541317,0.016750840470194817,0.015656549483537674,0.014284669421613216,0.013543106615543365,0.012004172429442406,0.01624477095901966,0.013457969762384892,0.011518169194459915,0.010132737457752228,0.01238702517002821,0.013979407958686352,0.015590999275445938,0.015737704932689667,0.014609094709157944,0.013420657254755497,0.012396000325679779,0.012699950486421585,0.013945373706519604,0.013193679973483086,0.009870242327451706,0.015008833259344101,0.012618882581591606,0.013341022655367851,0.013399588875472546,0.012360217981040478,0.01397484540939331,0.011311698704957962,0.01237147580832243,0.011620216071605682,0.011049289256334305,0.011411874555051327,0.013736218214035034,0.010834593325853348,0.01435571163892746,0.011891917325556278,0.009911632165312767,0.009415734559297562,0.01355794444680214,0.012163716368377209,0.01220063678920269,0.01009707897901535,0.010549183934926987,0.009029453620314598,0.008767367340624332,0.00844772718846798,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 279915    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 279916    
=================================================================
Total params: 559,831
Trainable params: 559,831
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                8208      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 279,915
Trainable params: 279,915
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 279,916
Trainable params: 279,916
Non-trainable params: 0
_________________________________________________________________
