2021-06-26
loss,0.9456737637519836,0.35592764616012573,0.309058278799057,0.2573899030685425,0.2452058345079422,0.18219131231307983,0.14961421489715576,0.14314329624176025,0.1093667522072792,0.0761706754565239,0.0907798707485199,0.07281024754047394,0.07995734363794327,0.08251916617155075,0.08521881699562073,0.06545460969209671,0.06591036915779114,0.07104915380477905,0.05136483535170555,0.05220930650830269,0.06542403250932693,0.05667456239461899,0.055541858077049255,0.053389500826597214,0.04942943528294563,0.03959434852004051,0.055263496935367584,0.05575840175151825,0.05600510910153389,0.05262438952922821,0.04789292812347412,0.0373409278690815,0.03516443818807602,0.043177295476198196,0.03927815333008766,0.035952672362327576,0.049833234399557114,0.04128636047244072,0.044483575969934464,0.04483447223901749,0.04450701177120209,0.03377661854028702,0.03761470690369606,0.03075060434639454,0.03382151573896408,0.03463643789291382,0.04133913666009903,0.04110362008213997,0.04326014965772629,0.041954156011343,0.03421541675925255,0.03929494693875313,0.03570671007037163,0.03437136486172676,0.0366123728454113,0.03449206426739693,0.03439885005354881,0.036340970546007156,0.03705427795648575,0.036694373935461044,0.032280661165714264,0.03173157572746277,0.035725440829992294,0.031974200159311295,0.03071005269885063,0.029111871495842934,0.0278349407017231,0.03344938904047012,0.03128552436828613,0.033151064068078995,0.027422189712524414,0.030273251235485077,0.026985125616192818,0.030581064522266388,0.028184376657009125,0.02969220094382763,0.034537795931100845,0.028215067461133003,0.02766435779631138,0.029060738161206245,0.03093850426375866,0.031299691647291183,0.026437293738126755,0.027587616816163063,0.033121708780527115,0.027751324698328972,0.02998420037329197,0.032037414610385895,0.02901937998831272,0.02928847260773182,0.030390582978725433,0.02569732628762722,0.02521623857319355,0.032768331468105316,0.025158429518342018,0.021940411999821663,0.024748992174863815,0.02665192075073719,0.025895215570926666,0.026707548648118973,
mse,0.4018917381763458,0.03771231323480606,0.029118182137608528,0.02119285985827446,0.019092243164777756,0.01049376092851162,0.006805896759033203,0.005876138806343079,0.0035845134407281876,0.0017058785306289792,0.0025820303708314896,0.0015074261464178562,0.0018660345813259482,0.0019198725931346416,0.0021110319066792727,0.0012349009048193693,0.001255254028365016,0.0014585568569600582,0.0007528776186518371,0.0007846908993087709,0.001203426392748952,0.000922696606721729,0.0008712578564882278,0.0007979848305694759,0.0007199333049356937,0.00044317953870631754,0.0009104146156460047,0.0008620464941486716,0.000885477289557457,0.0007828868692740798,0.0006425660685636103,0.0004069656424690038,0.00036529501085169613,0.0005352189764380455,0.0004429605614859611,0.00036072012153454125,0.0006998101016506553,0.0004774842527695,0.0005638229195028543,0.0005731862620450556,0.0005527035682462156,0.00034372525988146663,0.00040237250505015254,0.0002757208130788058,0.0003123147180303931,0.00034479182795621455,0.0004822845512535423,0.0004800855240318924,0.000528114615008235,0.0004943048115819693,0.0003310742904432118,0.0004309654177632183,0.000357171957148239,0.00033677901956252754,0.0003788237227126956,0.00033806965802796185,0.0003318000235594809,0.00038166678859852254,0.00038714450784027576,0.00036994722904637456,0.0003020983131136745,0.0002944262814708054,0.00035629988997243345,0.0002877806546166539,0.0002636529679875821,0.0002467052254360169,0.0002229268866358325,0.000318812089972198,0.00027657311875373125,0.0003093245322816074,0.00021336262580007315,0.00025792288943193853,0.0002072722854791209,0.0002636610297486186,0.00022296512906905264,0.00025637741782702506,0.0003275314811617136,0.00022490952687803656,0.00021904589084442705,0.0002400174707872793,0.00027334640617482364,0.00027565250638872385,0.0001966024428838864,0.00021255157480482012,0.00030405158759094775,0.00022137569612823427,0.00025311255012638867,0.0002895198995247483,0.00023826429969631135,0.0002414668706478551,0.00025867988006211817,0.0001866565435193479,0.00017585826572030783,0.00030304380925372243,0.00018022573203779757,0.00014185428153723478,0.00017391532310284674,0.00020172599761281163,0.00018613167048897594,0.0002021023683482781,
mae,0.41160252690315247,0.15572239458560944,0.13529042899608612,0.11493070423603058,0.1052585318684578,0.07718872278928757,0.06278318166732788,0.060622356832027435,0.0465213917195797,0.03280933201313019,0.038938429206609726,0.030845532193779945,0.034199729561805725,0.03538358211517334,0.036581285297870636,0.028069673106074333,0.02812686190009117,0.0299688670784235,0.021802669391036034,0.022217750549316406,0.02748299203813076,0.024100245907902718,0.023312516510486603,0.022132474929094315,0.02100459858775139,0.01659468002617359,0.02385055273771286,0.02374029904603958,0.024143066257238388,0.022968214005231857,0.020409395918250084,0.01580558903515339,0.014786595478653908,0.018337629735469818,0.016593914479017258,0.015011224895715714,0.021022360771894455,0.0177769772708416,0.018682874739170074,0.019342325627803802,0.019010700285434723,0.013769084587693214,0.01582946628332138,0.012819269672036171,0.013821972534060478,0.014580929651856422,0.01779033988714218,0.017553655430674553,0.018841689452528954,0.018044834956526756,0.014663700945675373,0.0166931189596653,0.014672661200165749,0.015012122690677643,0.015823788940906525,0.014855103567242622,0.014696439728140831,0.015543435700237751,0.015510177239775658,0.01619536243379116,0.013317175209522247,0.013190784491598606,0.015383229590952396,0.013890470378100872,0.01278816256672144,0.012278041802346706,0.011821694672107697,0.01407229620963335,0.013085778802633286,0.014055129140615463,0.011368861421942711,0.012752988375723362,0.01144228596240282,0.012966898269951344,0.011844984255731106,0.012708588503301144,0.01500309631228447,0.01193058118224144,0.011774434708058834,0.01223472598940134,0.01344518456608057,0.013303237967193127,0.01132461428642273,0.011589134112000465,0.014256250113248825,0.012014091946184635,0.012988601811230183,0.013897031545639038,0.012367542833089828,0.012531986460089684,0.0128189567476511,0.010956346988677979,0.010111315175890923,0.014078675769269466,0.01050794217735529,0.009093964472413063,0.010599054396152496,0.011147433891892433,0.01096594799309969,0.01144501008093357,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 92403     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 92404     
=================================================================
Total params: 184,807
Trainable params: 184,807
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 92,403
Trainable params: 92,403
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 92,404
Trainable params: 92,404
Non-trainable params: 0
_________________________________________________________________
