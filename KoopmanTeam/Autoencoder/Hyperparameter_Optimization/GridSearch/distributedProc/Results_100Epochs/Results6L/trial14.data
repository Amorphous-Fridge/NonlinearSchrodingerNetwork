2021-06-26
loss,0.5731790065765381,0.2451743483543396,0.23316730558872223,0.18849538266658783,0.13832305371761322,0.16735051572322845,0.0890023410320282,0.1084076315164566,0.09355518966913223,0.10332333296537399,0.0947289913892746,0.08001325279474258,0.06975682824850082,0.07705263793468475,0.07740651816129684,0.06886760890483856,0.08113996684551239,0.0713418647646904,0.05116148293018341,0.03987099975347519,0.052700549364089966,0.06747081130743027,0.06057538092136383,0.05434982478618622,0.048078279942274094,0.051173221319913864,0.048444949090480804,0.05064346268773079,0.042414307594299316,0.042588695883750916,0.06189281493425369,0.05505325645208359,0.05997243523597717,0.048296332359313965,0.046866174787282944,0.047092512249946594,0.05114559084177017,0.04726604372262955,0.049468766897916794,0.044534243643283844,0.04674298316240311,0.04623756557703018,0.041572727262973785,0.043540313839912415,0.042496830224990845,0.03683144226670265,0.041906896978616714,0.040785327553749084,0.04191141948103905,0.04125809296965599,0.041822485625743866,0.03806925192475319,0.038346029818058014,0.03550388291478157,0.032243624329566956,0.029232406988739967,0.029528966173529625,0.03852145001292229,0.0433042012155056,0.03474442660808563,0.03173662722110748,0.029625602066516876,0.028037266805768013,0.02550366334617138,0.032663777470588684,0.04115910083055496,0.028041185811161995,0.02323978580534458,0.02947433665394783,0.03673873096704483,0.034293707460165024,0.03398871794342995,0.035252198576927185,0.03587440773844719,0.03392031043767929,0.03107464872300625,0.027401873841881752,0.025753594934940338,0.022893285378813744,0.029368478804826736,0.0333266407251358,0.029894515872001648,0.02566594071686268,0.02696884796023369,0.0344943031668663,0.034280672669410706,0.030248455703258514,0.02805907092988491,0.02624589391052723,0.024698693305253983,0.031531237065792084,0.03238726779818535,0.028370389714837074,0.029662029817700386,0.02546355314552784,0.023815978318452835,0.017439499497413635,0.021093692630529404,0.026613211259245872,0.023604612797498703,
mse,0.1550542265176773,0.019862597808241844,0.01855991780757904,0.012084530666470528,0.0061618671752512455,0.008718747645616531,0.0022727467585355043,0.00339385773986578,0.0025856667198240757,0.0030559322331100702,0.002615074859932065,0.0018753136973828077,0.0014111273922026157,0.0018151728436350822,0.0017773587023839355,0.0013630343601107597,0.001911986037157476,0.0014562663855031133,0.0007722418522462249,0.000460359500721097,0.0008277701563201845,0.0012879871064797044,0.001052713138051331,0.0008769051637500525,0.0006841029971837997,0.0007412367849610746,0.0006742560071870685,0.0007716573309153318,0.0005066482117399573,0.0005225670174695551,0.001112753408960998,0.0008507737657055259,0.0010444970102980733,0.000720075098797679,0.0006268628058023751,0.0006536467117257416,0.0007377073634415865,0.0006273434846661985,0.0007116348133422434,0.0005710569676011801,0.0006502948817797005,0.0006014221580699086,0.0004891430726274848,0.000535371305886656,0.0005238615558482707,0.0003987871459685266,0.0005000729579478502,0.00046425097389146686,0.0005120655987411737,0.0004913342418149114,0.0004871042910963297,0.00040752795757725835,0.0004056326288264245,0.00034470605896785855,0.00028792332159355283,0.0002416096831439063,0.00026175749371759593,0.000428771018050611,0.0005182517925277352,0.00034636302734725177,0.0002833187172655016,0.00024024545564316213,0.00021723067038692534,0.00019434421847108752,0.0003041113668587059,0.0005022260011173785,0.00024603871861472726,0.00015724063268862665,0.0002603982575237751,0.00037584174424409866,0.00033685818198136985,0.0003327559388708323,0.00034172963933087885,0.00036176323192194104,0.0003189790586475283,0.00027766620041802526,0.00020784710068255663,0.00018320564413443208,0.00015536970749963075,0.00026738413725979626,0.0003166663518641144,0.00025400693994015455,0.0001806829241104424,0.0002103618171531707,0.0003373330400791019,0.00032513600308448076,0.00025129321147687733,0.0002184557670261711,0.00019170255109202117,0.00017372073489241302,0.00028228742303326726,0.0003025999176315963,0.0002455019857734442,0.00025038578314706683,0.00017928193847183138,0.00016178643272724003,8.715713192941621e-05,0.00013250656775198877,0.00019633704505395144,0.00015970510139595717,
mae,0.24689458310604095,0.10350523889064789,0.09854289889335632,0.07904909551143646,0.06014721840620041,0.07363373786211014,0.037810083478689194,0.04589829966425896,0.0401935875415802,0.04485307261347771,0.0400482602417469,0.03422605246305466,0.029193801805377007,0.03141740337014198,0.032202813774347305,0.02932729572057724,0.034301768988370895,0.03089187853038311,0.02169995941221714,0.016905400902032852,0.022590499371290207,0.029094208031892776,0.025645537301898003,0.022390298545360565,0.020417049527168274,0.02195533737540245,0.020221274346113205,0.021236546337604523,0.017907582223415375,0.018031124025583267,0.02619989588856697,0.02368779666721821,0.024660201743245125,0.02041054330766201,0.019825298339128494,0.019589221104979515,0.021117698401212692,0.01985117234289646,0.020874489098787308,0.018776923418045044,0.019657541066408157,0.019777756184339523,0.017548177391290665,0.01869380474090576,0.017814146354794502,0.01564827375113964,0.017237428575754166,0.016850516200065613,0.017386816442012787,0.017499597743153572,0.017939284443855286,0.016742924228310585,0.01751072145998478,0.015736909583210945,0.013220518827438354,0.012606930918991566,0.012315133586525917,0.016538966447114944,0.017994064837694168,0.014533967711031437,0.01322046760469675,0.011758892796933651,0.011630849912762642,0.010875308886170387,0.013807551003992558,0.017202112823724747,0.011884734965860844,0.009767238050699234,0.012813669629395008,0.016000870615243912,0.015002372674643993,0.01464793086051941,0.015242394059896469,0.015225308015942574,0.014593345113098621,0.013329374603927135,0.011040433309972286,0.01039186492562294,0.009903269819915295,0.012450389564037323,0.014426667243242264,0.01265374943614006,0.010584365576505661,0.011312777176499367,0.014319087378680706,0.014247739687561989,0.013064883649349213,0.012217258103191853,0.011181894689798355,0.010455403476953506,0.013710140250623226,0.013375810347497463,0.011688480153679848,0.012375208549201488,0.01045644748955965,0.009949259459972382,0.007423038594424725,0.008865781128406525,0.011381899006664753,0.009902003221213818,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25779     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25780     
=================================================================
Total params: 51,559
Trainable params: 51,559
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 25,779
Trainable params: 25,779
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 25,780
Trainable params: 25,780
Non-trainable params: 0
_________________________________________________________________
