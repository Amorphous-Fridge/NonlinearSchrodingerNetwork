2021-06-26
loss,3.769767999649048,3.137831687927246,3.128298282623291,3.1295061111450195,3.128371477127075,3.12844181060791,3.128427743911743,3.128726005554199,3.1293702125549316,3.1286063194274902,3.128405809402466,3.128563642501831,3.128668785095215,3.1280605792999268,3.129070997238159,3.128944158554077,3.128485918045044,3.1285698413848877,3.1291370391845703,3.1307384967803955,3.1286933422088623,3.1287262439727783,3.1292378902435303,3.133784770965576,3.128491163253784,3.128619432449341,3.1281814575195312,3.1287648677825928,3.1317031383514404,3.129716396331787,3.1277823448181152,3.1277899742126465,3.1289408206939697,3.127685308456421,3.313566207885742,3.1458849906921387,3.1231284141540527,3.123745918273926,3.1227505207061768,3.122934341430664,3.123225688934326,3.122763156890869,3.1223809719085693,3.122730016708374,3.1225709915161133,3.1225216388702393,3.1228580474853516,3.1223528385162354,3.121919870376587,3.1220550537109375,3.1323461532592773,3.127612829208374,3.1631972789764404,3.1326563358306885,3.0099921226501465,0.9974901080131531,0.29523608088493347,0.22496698796749115,0.20061440765857697,0.1797163039445877,0.1657504290342331,0.17711955308914185,0.15173135697841644,0.14251822233200073,0.1373175084590912,0.13290385901927948,0.1308753490447998,0.12696050107479095,0.1254889816045761,0.12416642159223557,0.12234526872634888,0.11869756877422333,0.11776063591241837,0.11429332941770554,0.1136917695403099,0.11714822053909302,0.12018197774887085,0.12114553153514862,0.11811204254627228,0.08797546476125717,0.09831324219703674,0.07958441227674484,0.08980760723352432,0.09539172053337097,0.08954232186079025,0.07181566208600998,0.06289932131767273,0.05746791511774063,0.08001144230365753,0.05873601511120796,0.05687285587191582,0.05093775689601898,0.06367216259241104,0.07450205087661743,0.06719633936882019,0.0388825424015522,0.04387283697724342,0.03855355829000473,0.03928785398602486,0.05417289584875107,
mse,3.7458579540252686,2.4711530208587646,2.456294536590576,2.4581637382507324,2.4563651084899902,2.4565460681915283,2.4565117359161377,2.4569833278656006,2.457989454269409,2.456796884536743,2.4564461708068848,2.456718683242798,2.456892967224121,2.455960273742676,2.457496404647827,2.457289218902588,2.456569194793701,2.4567253589630127,2.4576449394226074,2.4601082801818848,2.4569215774536133,2.456963300704956,2.4577436447143555,2.4648489952087402,2.456606864929199,2.4567718505859375,2.456092596054077,2.457001209259033,2.4615683555603027,2.4585578441619873,2.455486536026001,2.4555060863494873,2.4573111534118652,2.455327272415161,2.7735517024993896,2.484050750732422,2.448060989379883,2.4490833282470703,2.447507858276367,2.4477732181549072,2.4482436180114746,2.447578191757202,2.4469399452209473,2.4475066661834717,2.4472150802612305,2.447145462036133,2.447678327560425,2.446852207183838,2.446263074874878,2.4464430809020996,2.463552236557007,2.4550724029541016,2.515714168548584,2.4630820751190186,2.2945477962493896,0.38351550698280334,0.026978613808751106,0.017145194113254547,0.013624480925500393,0.010839961469173431,0.009143128991127014,0.010618245229125023,0.007827810011804104,0.0070043508894741535,0.006536629982292652,0.006120926700532436,0.005927603226155043,0.005660851486027241,0.005512767471373081,0.005452638957649469,0.005266755819320679,0.0049733370542526245,0.004852683749049902,0.004521826282143593,0.004274921957403421,0.004397780634462833,0.0045182909816503525,0.004452321212738752,0.0042009116150438786,0.002362155122682452,0.0029284972697496414,0.0019067456014454365,0.0023931441828608513,0.0026342817582190037,0.002304015913978219,0.0014341393252834678,0.001097146887332201,0.0010419703321531415,0.001830996130593121,0.0010393054690212011,0.0009009672212414443,0.0007471159915439785,0.0011590267531573772,0.0015263007953763008,0.001278043957427144,0.0004311598604544997,0.0005607399507425725,0.00042109034257009625,0.0004429141408763826,0.0008253323030658066,
mae,1.709849238395691,1.1834349632263184,1.1557953357696533,1.1558650732040405,1.1552046537399292,1.1553784608840942,1.1553806066513062,1.155383825302124,1.1555562019348145,1.1552666425704956,1.1550796031951904,1.1549062728881836,1.1549042463302612,1.154753565788269,1.1547362804412842,1.1546406745910645,1.1540932655334473,1.1543552875518799,1.1559128761291504,1.1645549535751343,1.1542798280715942,1.1533656120300293,1.153653860092163,1.1707571744918823,1.1529457569122314,1.1516356468200684,1.1507916450500488,1.1518479585647583,1.1667672395706177,1.1567379236221313,1.1498517990112305,1.1485280990600586,1.1489182710647583,1.1499354839324951,1.361398458480835,1.193335771560669,1.1192922592163086,1.1134849786758423,1.1102757453918457,1.1085811853408813,1.107494831085205,1.1064668893814087,1.1056104898452759,1.1051533222198486,1.1046209335327148,1.1041669845581055,1.103929877281189,1.1034754514694214,1.1031203269958496,1.1030293703079224,1.1439709663391113,1.1492915153503418,1.225725531578064,1.1705043315887451,1.1221224069595337,0.4196684658527374,0.12755142152309418,0.09752143174409866,0.08622664213180542,0.0765826553106308,0.07047019153833389,0.07518644630908966,0.06384339928627014,0.05961054190993309,0.057251330465078354,0.055350493639707565,0.054435744881629944,0.05268673971295357,0.05222367122769356,0.05168231949210167,0.05099527910351753,0.04922810196876526,0.04898823797702789,0.047345079481601715,0.0476112924516201,0.049173351377248764,0.050244640558958054,0.05132101848721504,0.04983529448509216,0.03713347017765045,0.042277298867702484,0.03331681340932846,0.038788918405771255,0.04113776609301567,0.038716863840818405,0.029837792739272118,0.02627495303750038,0.024594834074378014,0.035076986998319626,0.025385191664099693,0.023987755179405212,0.021890804171562195,0.02728588879108429,0.03224927932024002,0.029244210571050644,0.016600048169493675,0.018870873376727104,0.01647753082215786,0.016699491068720818,0.022608578205108643,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 402979    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 402980    
=================================================================
Total params: 805,959
Trainable params: 805,959
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 402,979
Trainable params: 402,979
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 402,980
Trainable params: 402,980
Non-trainable params: 0
_________________________________________________________________
