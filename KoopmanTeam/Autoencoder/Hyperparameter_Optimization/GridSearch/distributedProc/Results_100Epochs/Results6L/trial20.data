2021-06-26
loss,0.5682896971702576,0.2155141830444336,0.21670813858509064,0.14076054096221924,0.11469868570566177,0.11500106006860733,0.09865286201238632,0.09350058436393738,0.09652233123779297,0.09717369824647903,0.10344628244638443,0.07240786403417587,0.07181458920240402,0.07597625255584717,0.09047317504882812,0.08246621489524841,0.08241172879934311,0.07103189080953598,0.07289203256368637,0.06929056346416473,0.05626074969768524,0.04597754031419754,0.06281841546297073,0.05096735432744026,0.042379818856716156,0.05158679559826851,0.04733792692422867,0.04742894321680069,0.058346956968307495,0.06311957538127899,0.051083751022815704,0.04621199145913124,0.04322699084877968,0.0373484306037426,0.04159651696681976,0.05227119103074074,0.040955863893032074,0.04482698813080788,0.03908705338835716,0.042180418968200684,0.05157291516661644,0.04449908435344696,0.03731393441557884,0.03383192420005798,0.033458009362220764,0.0367346815764904,0.048093248158693314,0.03954280912876129,0.03358510509133339,0.042440734803676605,0.03751080483198166,0.03230120614171028,0.035656534135341644,0.030922038480639458,0.02661530300974846,0.030250342562794685,0.03222047910094261,0.03943534940481186,0.03128695860505104,0.028794661164283752,0.03260898217558861,0.03940707817673683,0.033107053488492966,0.029603535309433937,0.027789006009697914,0.03601187467575073,0.028778212144970894,0.027277667075395584,0.031158283352851868,0.02929123491048813,0.02202686108648777,0.0271468386054039,0.03606101870536804,0.029469896107912064,0.019769718870520592,0.018450981006026268,0.017747309058904648,0.02447720617055893,0.028267178684473038,0.0270610973238945,0.029953643679618835,0.025963526219129562,0.02497723139822483,0.03286638855934143,0.026920197531580925,0.026552772149443626,0.024901721626520157,0.028531527146697044,0.030674993991851807,0.026776112616062164,0.02428479865193367,0.02747400850057602,0.02479339763522148,0.022482682019472122,0.021233774721622467,0.028592851012945175,0.024996954947710037,0.02645695209503174,0.023883182555437088,0.022499457001686096,
mse,0.15784598886966705,0.014787444844841957,0.01439831592142582,0.005825983826071024,0.0037495740689337254,0.0038981682155281305,0.0027400667313486338,0.0024433655198663473,0.002615062054246664,0.0028792587108910084,0.00307059264741838,0.0015396970557048917,0.0015085813356563449,0.0016046889359131455,0.0023765612859278917,0.0019509739940986037,0.0019269677577540278,0.0014051407342776656,0.0015627671964466572,0.0013610279420390725,0.0009011442307382822,0.0006166736129671335,0.0011527315946295857,0.0007399688474833965,0.0005055300425738096,0.0007517367484979331,0.0006320149987004697,0.0006434432580135763,0.000985528458841145,0.0010980546940118074,0.0007482932414859533,0.0006116751465015113,0.0005262237973511219,0.0003934570122510195,0.0004908913397230208,0.0007645894656889141,0.0005149231874383986,0.0005774081218987703,0.0004344447806943208,0.0005056021036580205,0.0007284816238097847,0.0005507271853275597,0.0003853037196677178,0.0003148367686662823,0.0003228833666071296,0.00038905031397007406,0.0006551143596880138,0.0004535734187811613,0.0003301871183793992,0.0005092870560474694,0.0003892296808771789,0.0002924830187112093,0.00036699537304230034,0.00027126987697556615,0.000205552380066365,0.00027016233070753515,0.00029536065994761884,0.00043675294728018343,0.0002771250146906823,0.00024151767138391733,0.0003019740979652852,0.0004290775686968118,0.00031060207402333617,0.000244395574554801,0.00022042979253455997,0.00036420172546058893,0.00022917547903489321,0.00021573113917838782,0.00027350554591976106,0.0002357418416067958,0.00014615604595746845,0.00021327142894733697,0.00035773904528468847,0.00024983801995404065,0.00011724414071068168,9.742492693476379e-05,8.835409971652552e-05,0.00017539237160235643,0.00022591289598494768,0.00020631328516174108,0.0002454706118442118,0.00018896785331889987,0.00018337577057536691,0.0003169173141941428,0.00020608985505532473,0.00019652531773317605,0.00017634402320254594,0.0002245260402560234,0.0002606039633974433,0.00019831843383144587,0.00016980427608359605,0.00020486653374973685,0.0001660393172642216,0.00013984425459057093,0.00012954194971825927,0.00023382542713079602,0.00017463114636484534,0.00019708176841959357,0.0001584638812346384,0.0001417219318682328,
mae,0.2405015230178833,0.09377269446849823,0.09052272140979767,0.05964542552828789,0.04838460311293602,0.04927006736397743,0.04138072952628136,0.040097564458847046,0.040582526475191116,0.040741220116615295,0.04441652446985245,0.03022562526166439,0.031025296077132225,0.03270508348941803,0.03867601230740547,0.034273143857717514,0.03580090403556824,0.029998773708939552,0.03121768683195114,0.030362164601683617,0.02456451952457428,0.019430721178650856,0.026742860674858093,0.02158818393945694,0.01809699274599552,0.021916769444942474,0.02050754614174366,0.020594287663698196,0.02378140203654766,0.02795209176838398,0.02218461036682129,0.019463814795017242,0.018614156171679497,0.015415549278259277,0.017644023522734642,0.022805817425251007,0.0177224762737751,0.019281016662716866,0.01682203635573387,0.018252873793244362,0.022504467517137527,0.01959478110074997,0.015197208151221275,0.014089899137616158,0.01438826322555542,0.016052959486842155,0.020558509975671768,0.016937296837568283,0.014197815209627151,0.017908170819282532,0.01583661511540413,0.013720694929361343,0.015173021703958511,0.013126347213983536,0.011301753111183643,0.013041616417467594,0.013693341985344887,0.016798697412014008,0.013519084081053734,0.012392289936542511,0.013969309628009796,0.01670733094215393,0.014469639398157597,0.012716298922896385,0.011864212341606617,0.015734689310193062,0.012549877166748047,0.01159598957747221,0.013384419493377209,0.01260284148156643,0.009396832436323166,0.011548677459359169,0.015551014803349972,0.012588316574692726,0.008441808633506298,0.0078304847702384,0.007554312236607075,0.009999617002904415,0.012157969176769257,0.011462317779660225,0.013023772276937962,0.011068006977438927,0.010757233947515488,0.014182556420564651,0.011244527995586395,0.01125381700694561,0.010444256477057934,0.012226557359099388,0.013242188841104507,0.01159648410975933,0.010345684364438057,0.011546299792826176,0.01035155076533556,0.009624475613236427,0.009155972860753536,0.012182577513158321,0.010599865578114986,0.011288288980722427,0.010336236096918583,0.00922855082899332,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 30707     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 30708     
=================================================================
Total params: 61,415
Trainable params: 61,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 30,707
Trainable params: 30,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 30,708
Trainable params: 30,708
Non-trainable params: 0
_________________________________________________________________
