2021-06-26
loss,1.496129035949707,0.24817036092281342,0.2352192997932434,0.17627325654029846,0.13030049204826355,0.19514057040214539,0.10793229937553406,0.10500642657279968,0.08906622231006622,0.10804364085197449,0.11229817569255829,0.08106497675180435,0.0839492529630661,0.09264674782752991,0.0733334869146347,0.07425732165575027,0.08400141447782516,0.07695413380861282,0.06630876660346985,0.07834362983703613,0.06662730872631073,0.04827916994690895,0.05474739149212837,0.06420378386974335,0.05425190553069115,0.06073718145489693,0.06135421618819237,0.05950561910867691,0.051974836736917496,0.058089729398489,0.05451769381761551,0.03844494745135307,0.05343141406774521,0.053761400282382965,0.05369904637336731,0.05344128981232643,0.04398231953382492,0.04406427964568138,0.0470060259103775,0.05040485039353371,0.04891973361372948,0.04988586902618408,0.03998269885778427,0.040163177996873856,0.04678865894675255,0.04513927549123764,0.03410860896110535,0.033854443579912186,0.04500190168619156,0.04537143558263779,0.04104432463645935,0.03645078092813492,0.04424624890089035,0.040823906660079956,0.03657609596848488,0.03354360908269882,0.030032088980078697,0.028650972992181778,0.03637448325753212,0.03463326394557953,0.03926660120487213,0.03879091888666153,0.03994987905025482,0.03249005228281021,0.03729764744639397,0.03381478786468506,0.029677070677280426,0.03976884484291077,0.04219608008861542,0.03809181973338127,0.030027030035853386,0.03845474123954773,0.033094968646764755,0.02782413177192211,0.03349509835243225,0.034907419234514236,0.027731023728847504,0.02737722545862198,0.029834838584065437,0.03808470070362091,0.040859293192625046,0.03246920928359032,0.03575819358229637,0.03397958353161812,0.030030854046344757,0.03638540953397751,0.036900151520967484,0.0333644337952137,0.029551543295383453,0.030904028564691544,0.03740565851330757,0.03387586772441864,0.0273947361856699,0.02274913340806961,0.02440798468887806,0.034673143178224564,0.03440658748149872,0.03047342039644718,0.028983475640416145,0.023663513362407684,
mse,1.146546483039856,0.019649894908070564,0.016063619405031204,0.009319370612502098,0.004895349964499474,0.011137443594634533,0.0032627196051180363,0.0032899260986596346,0.002187644597142935,0.003544214181602001,0.003752329619601369,0.0020762046333402395,0.002019517356529832,0.0024765138514339924,0.0015979547752067447,0.00161230459343642,0.0019985733088105917,0.0016748575726523995,0.0013022040948271751,0.0017600827850401402,0.0012516779825091362,0.000668016669806093,0.0008456462528556585,0.001196030993014574,0.0008518112590536475,0.0010653354693204165,0.0010483228834345937,0.0010018921457231045,0.0007699791458435357,0.0009278242941945791,0.0008646910428069532,0.00042216767906211317,0.0008221734897233546,0.0008113249205052853,0.0008184242760762572,0.0008066019508987665,0.0005271208938211203,0.0005495132645592093,0.0006261878297664225,0.0007117151981219649,0.0006710189627483487,0.00067235401365906,0.0004517298948485404,0.0004665553860832006,0.0006040715961717069,0.0005509124603122473,0.0003355910303071141,0.00032288252259604633,0.0005632113898172975,0.0005583902238868177,0.0004572864272631705,0.0003666672855615616,0.00053503637900576,0.0004614478093571961,0.0003737562510650605,0.00031404857872985303,0.0002570455544628203,0.0002359432983212173,0.00036616279976442456,0.00033684662776067853,0.00043872688547708094,0.0004215188091620803,0.00044470815919339657,0.0003042534226551652,0.00039300412754528224,0.0003132278216071427,0.0002605376939754933,0.00045402522664517164,0.00048151248483918607,0.0003952598199248314,0.0002546757459640503,0.0004164832935202867,0.0003094921703450382,0.0002235489955637604,0.0003161945496685803,0.00035479606594890356,0.00022086403623688966,0.00021238926274236292,0.00025177327916026115,0.0004009887343272567,0.00045419394155032933,0.00029782348428852856,0.00034822372253984213,0.000311642128508538,0.0002499032998457551,0.00037687725853174925,0.00037827366031706333,0.00030590369715355337,0.00024594730348326266,0.00026577914832159877,0.0003903380420524627,0.0003156768507324159,0.00021324514818843454,0.00014974252553656697,0.00017715152353048325,0.0003368081816006452,0.0003225526597816497,0.0002544083399698138,0.00023133248032536358,0.00016379695443902165,
mae,0.645789623260498,0.10411255806684494,0.09905104339122772,0.07516936212778091,0.05570473149418831,0.08029554039239883,0.04613560810685158,0.04501127824187279,0.03798138350248337,0.044592589139938354,0.04640315845608711,0.034320980310440063,0.035942308604717255,0.03885471820831299,0.030076075345277786,0.03157484158873558,0.035399653017520905,0.032764703035354614,0.02806129679083824,0.032336171716451645,0.0279703326523304,0.020514335483312607,0.02321721985936165,0.026664864271879196,0.02316865883767605,0.025760049000382423,0.026290712878108025,0.02540043368935585,0.02199690043926239,0.024646969512104988,0.022852497175335884,0.015963133424520493,0.022866826504468918,0.022476069629192352,0.022897891700267792,0.022422142326831818,0.01883023791015148,0.01876433566212654,0.019798142835497856,0.021420199424028397,0.02066466398537159,0.021258747205138206,0.017132259905338287,0.016943171620368958,0.01982615888118744,0.01883275806903839,0.014535822905600071,0.014333411119878292,0.01905127614736557,0.019707880914211273,0.01760530099272728,0.015563368797302246,0.018561063334345818,0.01791597530245781,0.015861334279179573,0.01428995281457901,0.012726450338959694,0.012161209248006344,0.01557138655334711,0.015104228630661964,0.016760850325226784,0.01638462021946907,0.01695293001830578,0.013536477461457253,0.01582016795873642,0.014712146483361721,0.012795623391866684,0.017019549384713173,0.018202167004346848,0.01641990803182125,0.012902684509754181,0.016438625752925873,0.014195021241903305,0.01190818939357996,0.014233972877264023,0.014839032664895058,0.011478557251393795,0.011618451215326786,0.012763209640979767,0.016290530562400818,0.017667459324002266,0.013906567357480526,0.015278985723853111,0.014816679060459137,0.012980136089026928,0.015480689704418182,0.015844175592064857,0.014398136176168919,0.012499311938881874,0.01368379034101963,0.01593051850795746,0.014445680193603039,0.011526587419211864,0.009531348012387753,0.010469275526702404,0.014911169186234474,0.014894017949700356,0.013312062248587608,0.012325167655944824,0.009845363907516003,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 368099    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 368100    
=================================================================
Total params: 736,199
Trainable params: 736,199
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 368,099
Trainable params: 368,099
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 368,100
Trainable params: 368,100
Non-trainable params: 0
_________________________________________________________________
