2021-06-26
loss,0.4855519235134125,0.16012531518936157,0.11699318140745163,0.11610957235097885,0.09404180198907852,0.07369430363178253,0.07221532613039017,0.0933937132358551,0.05846676230430603,0.0644097775220871,0.059510570019483566,0.08162762969732285,0.04977104067802429,0.04991992563009262,0.059716057032346725,0.07632448524236679,0.06839892268180847,0.0764613226056099,0.06820137798786163,0.06182984262704849,0.05593933165073395,0.046689003705978394,0.041577063500881195,0.04243503883481026,0.053838424384593964,0.054092422127723694,0.04887910187244415,0.05932795628905296,0.0533512644469738,0.050783924758434296,0.047578901052474976,0.037481050938367844,0.045217398554086685,0.05572979897260666,0.04978314787149429,0.045281294733285904,0.03810121491551399,0.05001027137041092,0.04626001790165901,0.04141845181584358,0.03492985665798187,0.036403678357601166,0.047386277467012405,0.04163171350955963,0.03887292742729187,0.04300624504685402,0.037674110382795334,0.03669120743870735,0.04044533893465996,0.03439103066921234,0.02506953291594982,0.03245716914534569,0.035040486603975296,0.04017971083521843,0.03778360038995743,0.035903893411159515,0.027823880314826965,0.035408325493335724,0.04183187335729599,0.03713567182421684,0.03332855924963951,0.03398341313004494,0.03185325860977173,0.02643057145178318,0.021022342145442963,0.021272696554660797,0.025791477411985397,0.031584881246089935,0.036386922001838684,0.038063906133174896,0.0357493981719017,0.03101225383579731,0.02109656110405922,0.01884722150862217,0.023172855377197266,0.03307686746120453,0.03146568313241005,0.027034129947423935,0.025903088971972466,0.030815623700618744,0.027793409302830696,0.028539396822452545,0.03868923336267471,0.03490285575389862,0.032813459634780884,0.029201306402683258,0.027496451511979103,0.024129824712872505,0.02609715424478054,0.03306169435381889,0.02938484586775303,0.02895745076239109,0.032259441912174225,0.026902342215180397,0.022882351651787758,0.03135653957724571,0.02659478969871998,0.025007538497447968,0.02264985628426075,0.024788279086351395,
mse,0.1164819747209549,0.007569469045847654,0.004099822137504816,0.0038721617311239243,0.0025502005591988564,0.0015591857954859734,0.0015652332222089171,0.0026336186565458775,0.0009977740701287985,0.0011978746624663472,0.0009948073420673609,0.002012490062043071,0.0007103141397237778,0.0007127613644115627,0.0011269355891272426,0.001707982737571001,0.001358719076961279,0.001673816586844623,0.0013050284469500184,0.0010524924146011472,0.0008518340182490647,0.0006142253405414522,0.000490665202960372,0.0005260093603283167,0.0008938928949646652,0.0008633405668660998,0.0007203152636066079,0.0010186464060097933,0.0008025094866752625,0.0007097758934833109,0.0006120158359408379,0.00040296741644851863,0.0006628864211961627,0.0008476764778606594,0.000686426879838109,0.0005632282118313015,0.0004252867365721613,0.0006964927888475358,0.0005895846989005804,0.0004713198868557811,0.00035377859603613615,0.000394155562389642,0.0006299705128185451,0.00048202165635302663,0.0004253302176948637,0.0005198571598157287,0.0004075084871146828,0.00038691109512001276,0.0004560436063911766,0.0003315824724268168,0.0001914008753374219,0.0003083574410993606,0.00036323320819064975,0.00046071739052422345,0.00039204899803735316,0.00035267957719042897,0.0002304482477484271,0.00037279832758940756,0.00047697630361653864,0.0003745265712495893,0.00030930456705391407,0.0003151874989271164,0.00027943780878558755,0.00020564293663483113,0.00012994726421311498,0.00013237399980425835,0.00019242802227381617,0.0003016184491571039,0.0003632446750998497,0.0003980434557888657,0.000352609931724146,0.00027199831674806774,0.0001385797222610563,0.00010037767788162455,0.0001649935293244198,0.00030358866206370294,0.00027434859657660127,0.0002116361865773797,0.00019262140267528594,0.00026313160196878016,0.00021699059288948774,0.00023534649517387152,0.0004084658285137266,0.0003335222718305886,0.0002913633070420474,0.00023636808327864856,0.00021325598936527967,0.00017185973410960287,0.00019557260384317487,0.0003014034009538591,0.00024253975425381213,0.0002396441122982651,0.00028191827004775405,0.00021097065473441035,0.00015614421863574535,0.00027287675766274333,0.00020258741278667003,0.00017805217066779733,0.00014991268108133227,0.00017491992912255228,
mae,0.20783406496047974,0.06880296021699905,0.050213370472192764,0.04989476501941681,0.04046855866909027,0.03149208053946495,0.031240325421094894,0.0406356081366539,0.025195859372615814,0.02758226916193962,0.025278758257627487,0.03457406163215637,0.021387919783592224,0.021235501393675804,0.025590229779481888,0.03218887001276016,0.02868904545903206,0.03342120721936226,0.02916084975004196,0.026925764977931976,0.024847697466611862,0.0199936144053936,0.017598548904061317,0.018037142232060432,0.02307068184018135,0.023251516744494438,0.02098788693547249,0.025311481207609177,0.02280246466398239,0.021713655441999435,0.020194916054606438,0.01605374738574028,0.019686931744217873,0.024372711777687073,0.02174994722008705,0.01928860694169998,0.01619613729417324,0.021254591643810272,0.0204432625323534,0.017606724053621292,0.014606461860239506,0.015711963176727295,0.020857717841863632,0.01794990338385105,0.01637289673089981,0.018318509683012962,0.015819065272808075,0.015511680394411087,0.017280230298638344,0.014982109889388084,0.010706284083425999,0.013705513440072536,0.014948372729122639,0.01696242392063141,0.015766456723213196,0.015361550264060497,0.012087217532098293,0.015128389932215214,0.018628813326358795,0.016566202044487,0.014593934640288353,0.014846695587038994,0.01382773369550705,0.010992531664669514,0.00901668332517147,0.009074426256120205,0.011093337088823318,0.013547442853450775,0.015993354842066765,0.01668282225728035,0.016026511788368225,0.013556079007685184,0.00905158556997776,0.008022677153348923,0.009993720799684525,0.014235727488994598,0.013807438313961029,0.011389358900487423,0.010916998609900475,0.013374201022088528,0.012288750149309635,0.011908178217709064,0.016917621716856956,0.01555139571428299,0.014545687474310398,0.012608793564140797,0.011592218652367592,0.010101151652634144,0.01116178184747696,0.014477989636361599,0.012665264308452606,0.012445764616131783,0.01444272417575121,0.011479880660772324,0.00978081114590168,0.013653689995408058,0.011293964460492134,0.010557098314166069,0.009526670910418034,0.01045975461602211,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 29867     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 29868     
=================================================================
Total params: 59,735
Trainable params: 59,735
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 29,867
Trainable params: 29,867
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 29,868
Trainable params: 29,868
Non-trainable params: 0
_________________________________________________________________
