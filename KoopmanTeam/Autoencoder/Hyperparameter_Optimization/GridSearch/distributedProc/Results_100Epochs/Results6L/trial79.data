2021-06-26
loss,1.8078818321228027,0.46126723289489746,0.4680946469306946,0.44647684693336487,0.3981325626373291,0.36329174041748047,0.351974755525589,0.3423437178134918,0.33886826038360596,0.3421325981616974,0.27908438444137573,0.21828170120716095,0.19718261063098907,0.2198147028684616,0.16815166175365448,0.16166619956493378,0.15305913984775543,0.13114811480045319,0.1255980134010315,0.12221909314393997,0.12186329811811447,0.11024007946252823,0.10956332087516785,0.09079083800315857,0.08465283364057541,0.09134875982999802,0.08900994062423706,0.08632057905197144,0.07963446527719498,0.07764020562171936,0.08438005298376083,0.07463947683572769,0.07908786088228226,0.07366710901260376,0.07527200877666473,0.06456363946199417,0.06532774120569229,0.06656093895435333,0.06575203686952591,0.06759627163410187,0.05896300822496414,0.06705083698034286,0.06299664825201035,0.059023674577474594,0.06426230072975159,0.06099174544215202,0.06567435711622238,0.052369389683008194,0.06129651889204979,0.061907120048999786,0.05330933257937431,0.051275063306093216,0.04869253188371658,0.056488286703825,0.047689780592918396,0.05208072066307068,0.055916234850883484,0.04996778443455696,0.054174426943063736,0.0460682138800621,0.05354008078575134,0.0581202358007431,0.05629440397024155,0.05381045863032341,0.0518355518579483,0.04433710128068924,0.049213603138923645,0.051583193242549896,0.04647574573755264,0.052914366126060486,0.05282406508922577,0.04066808521747589,0.045942019671201706,0.04341476038098335,0.04987218976020813,0.046173095703125,0.0490434393286705,0.052610330283641815,0.04970705136656761,0.037127599120140076,0.03884419426321983,0.041762687265872955,0.03899272531270981,0.046072207391262054,0.045415543019771576,0.04768189787864685,0.05151265114545822,0.03935305029153824,0.04120892658829689,0.041974615305662155,0.04396515712141991,0.03857709839940071,0.04618179798126221,0.04113112390041351,0.042093295603990555,0.04325471818447113,0.043548766523599625,0.03861311450600624,0.038164593279361725,0.03653314709663391,
mse,1.3611135482788086,0.05962292104959488,0.06111019104719162,0.05578837916254997,0.045359525829553604,0.038550965487957,0.0364689864218235,0.034695494920015335,0.033818282186985016,0.03530129790306091,0.023284535855054855,0.014906314201653004,0.012395497411489487,0.014684093184769154,0.008813428692519665,0.008120820857584476,0.007308624219149351,0.00550176203250885,0.005125119816511869,0.004882100038230419,0.004751601256430149,0.004093700088560581,0.00396354915574193,0.002880680374801159,0.002589557785540819,0.0028782240115106106,0.0027542621828615665,0.0025760671123862267,0.0022232194896787405,0.002142260316759348,0.0024305435363203287,0.002039097249507904,0.0021677210461348295,0.0019788159988820553,0.0019951111171394587,0.0015939207514747977,0.0016421854961663485,0.001680255401879549,0.00162745569832623,0.0016680913977324963,0.0013838220620527864,0.0016858052695170045,0.0014933310449123383,0.0013347096974030137,0.0014812143053859472,0.0014091810444369912,0.0016458445461466908,0.0011609793873503804,0.0013937531039118767,0.0014085547300055623,0.001139660133048892,0.0010633122874423862,0.0010021748021245003,0.0012910196091979742,0.0009617795585654676,0.0010681204730644822,0.001198517275042832,0.0010103172389790416,0.001129961689002812,0.0009058295981958508,0.0011138585396111012,0.0012723825639113784,0.00122052279766649,0.0011273468844592571,0.0010844676289707422,0.0008736276067793369,0.001005337806418538,0.001045167911797762,0.0009042985620908439,0.0010683056898415089,0.001097760978154838,0.000804965733550489,0.0008889900054782629,0.0008234923589043319,0.0009986889781430364,0.0009108851663768291,0.0009547689696773887,0.001085118856281042,0.0009637713665142655,0.0006683412357233465,0.0006959726451896131,0.0007670446648262441,0.000706181104760617,0.0009424433228559792,0.0008810079307295382,0.0009112862753681839,0.001001837314106524,0.000730614410713315,0.000794329505879432,0.0007444535149261355,0.0007876657764427364,0.0006995656294748187,0.0008993145893327892,0.0007348092622123659,0.000739480194170028,0.0007704507443122566,0.0007876849849708378,0.0006728667649440467,0.0006516433786600828,0.0006014168029651046,
mae,0.7685577869415283,0.2033669650554657,0.20491278171539307,0.19584129750728607,0.17193077504634857,0.15760977566242218,0.15267659723758698,0.14886030554771423,0.1462724655866623,0.14845457673072815,0.12066303938627243,0.09265102446079254,0.08337367326021194,0.09311124682426453,0.07093982398509979,0.06791805475950241,0.06481239944696426,0.055523648858070374,0.05342565476894379,0.051349278539419174,0.05163528770208359,0.04592408239841461,0.04711353778839111,0.03835321590304375,0.035826947540044785,0.03860727697610855,0.03797699138522148,0.035181134939193726,0.033465515822172165,0.032585568726062775,0.03567954897880554,0.03137952461838722,0.03358227014541626,0.031055349856615067,0.03153115138411522,0.027359554544091225,0.027317753061652184,0.02816362865269184,0.027310535311698914,0.028511546552181244,0.02471906505525112,0.028305916115641594,0.026763731613755226,0.02507784403860569,0.027333751320838928,0.025898275896906853,0.02740168385207653,0.021974241361021996,0.02553185261785984,0.02647855505347252,0.022433551028370857,0.021506020799279213,0.02038056217133999,0.023167090490460396,0.019976550713181496,0.021541662514209747,0.023648664355278015,0.021027324721217155,0.02295818366110325,0.0192718468606472,0.02229323424398899,0.024547288194298744,0.023878734558820724,0.02276577800512314,0.021750060841441154,0.01831107772886753,0.020757734775543213,0.021473098546266556,0.01956012099981308,0.022292980924248695,0.02235647477209568,0.0168707724660635,0.019527500495314598,0.018399979919195175,0.02136797457933426,0.019628917798399925,0.02065107598900795,0.022342683747410774,0.020897449925541878,0.01562088169157505,0.016451170668005943,0.01731473207473755,0.01655547134578228,0.01938394457101822,0.019053848460316658,0.020189188420772552,0.021666696295142174,0.01631586253643036,0.017473794519901276,0.01795489713549614,0.018295137211680412,0.016029244288802147,0.019454404711723328,0.017668897286057472,0.01783241145312786,0.018299663439393044,0.018522337079048157,0.016283486038446426,0.01593455858528614,0.015484954230487347,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 333219    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 333220    
=================================================================
Total params: 666,439
Trainable params: 666,439
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 333,219
Trainable params: 333,219
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 333,220
Trainable params: 333,220
Non-trainable params: 0
_________________________________________________________________
