2021-06-26
loss,0.5026221871376038,0.1456739753484726,0.07383082807064056,0.06104864925146103,0.05405539646744728,0.04932093247771263,0.04689360782504082,0.043900128453969955,0.042658377438783646,0.04024142399430275,0.03916008770465851,0.038065191358327866,0.037251655012369156,0.03598540648818016,0.03520018234848976,0.03459436446428299,0.03388066217303276,0.03325801342725754,0.03240210935473442,0.03261624649167061,0.031218400225043297,0.03127063810825348,0.030709682032465935,0.030543290078639984,0.030139189213514328,0.029409538954496384,0.028938904404640198,0.028901131823658943,0.028246315196156502,0.02794225886464119,0.027817673981189728,0.02729985862970352,0.02714783139526844,0.026833277195692062,0.026965072378516197,0.026400338858366013,0.025824476033449173,0.02587473951280117,0.025481298565864563,0.025575337931513786,0.025102119892835617,0.025145065039396286,0.024719368666410446,0.02470971830189228,0.024369122460484505,0.024268101900815964,0.035764265805482864,0.04334374517202377,0.03998424857854843,0.03505873307585716,0.030333764851093292,0.02643459476530552,0.03159622102975845,0.02961418405175209,0.03777129203081131,0.03680456429719925,0.03440975025296211,0.032801248133182526,0.03646009415388107,0.04017163813114166,0.04235303774476051,0.04031968116760254,0.03743242099881172,0.03537371754646301,0.03336585685610771,0.031168071553111076,0.029585909098386765,0.02838856913149357,0.027260813862085342,0.026401886716485023,0.025720946490764618,0.025048231706023216,0.024557121098041534,0.024097487330436707,0.023584987968206406,0.022578075528144836,0.02130710519850254,0.02094479650259018,0.020586518570780754,0.02006295695900917,0.019820932298898697,0.019494779407978058,0.019287994131445885,0.019017158076167107,0.01887732557952404,0.01864643767476082,0.018365921452641487,0.0184097308665514,0.018144940957427025,0.018076380714774132,0.01792074367403984,0.017835235223174095,0.017745045945048332,0.017537612468004227,0.017601927742362022,0.017430869862437248,0.0225670263171196,0.031211145222187042,0.028684115037322044,0.02657216228544712,
mse,0.1315309703350067,0.007630344480276108,0.00168110232334584,0.0010948836570605636,0.0008475477225147188,0.0006973210256546736,0.0006321201217360795,0.0005521870334632695,0.0005169431678950787,0.0004607834271155298,0.00044014607556164265,0.00041163741843774915,0.00039278127951547503,0.00036693355650641024,0.000351220543961972,0.00033839914249256253,0.00032243021996691823,0.0003111876139882952,0.0002940704289358109,0.00029860332142561674,0.0002743184450082481,0.00027358095394447446,0.00026433973107486963,0.0002707157691475004,0.0002568729396443814,0.0002414356858935207,0.00023763567151036114,0.00023207654885482043,0.0002248844102723524,0.00021836106316186488,0.0002148193889297545,0.0002082823048112914,0.00020570859487634152,0.00020026123092975467,0.00020324054639786482,0.0001936360786203295,0.00018597320013213903,0.00018572009867057204,0.00018113678379449993,0.0001826772786444053,0.00017637747805565596,0.00017530792683828622,0.00017009656585287303,0.00016985146794468164,0.00016535414033569396,0.00016789486107882112,0.000392939371522516,0.0005115746171213686,0.0004334351688157767,0.00033813834306783974,0.0002615399716887623,0.00020294860587455332,0.00030947395134717226,0.00025774608366191387,0.0004035690799355507,0.00037378116394393146,0.00032795124570839107,0.0002965579624287784,0.00039588476647622883,0.000485938013298437,0.000520654080901295,0.0004511758452281356,0.0003901716263499111,0.00035131341428495944,0.00031265278812497854,0.00027106842026114464,0.000245586852543056,0.00022651594190392643,0.00021040964929852635,0.00019846585928462446,0.00018852010543923825,0.00017943298735190183,0.0001724962203297764,0.0001657711691223085,0.00015939035802148283,0.00014807222760282457,0.00013291793584357947,0.00012492327368818223,0.00011908615852007642,0.00011275992437731475,0.00011093155626440421,0.00010712524090195075,0.00010437708260724321,0.00010207798914052546,0.0001002189310383983,9.804854926187545e-05,9.487699571764097e-05,9.537421283312142e-05,9.299986413680017e-05,9.24536507227458e-05,9.020463767228648e-05,8.946047455538064e-05,8.847555727697909e-05,8.671754039824009e-05,8.672135300002992e-05,8.589219214627519e-05,0.0001739934232318774,0.00027068061172030866,0.0002257010928587988,0.00019462961063254625,
mae,0.21575693786144257,0.061307843774557114,0.031609855592250824,0.026213862001895905,0.023303698748350143,0.021269522607326508,0.02029384672641754,0.01897357404232025,0.01842886209487915,0.017371512949466705,0.01684749871492386,0.016411637887358665,0.01610180176794529,0.015462823212146759,0.015087570063769817,0.014941269531846046,0.014662972651422024,0.014300675131380558,0.013988549821078777,0.014087308198213577,0.013458717614412308,0.013615994714200497,0.013188657350838184,0.013037473894655704,0.012924039736390114,0.012733781710267067,0.012437906116247177,0.012514311820268631,0.012121256440877914,0.012068594805896282,0.011982465162873268,0.011719686910510063,0.011702978983521461,0.011592669412493706,0.011621316894888878,0.011382012628018856,0.011149580590426922,0.011194250546395779,0.01103302463889122,0.011011013761162758,0.010775190778076649,0.010784878395497799,0.01067629549652338,0.010615724138915539,0.01052036415785551,0.01034881453961134,0.015392151661217213,0.018500005826354027,0.016613459214568138,0.015351853333413601,0.01317050214856863,0.011447016149759293,0.01342394482344389,0.012647057883441448,0.016106130555272102,0.01583145186305046,0.014864997938275337,0.01424903143197298,0.016049427911639214,0.017263837158679962,0.018318118527531624,0.017670881003141403,0.01633072830736637,0.015359766781330109,0.014792105183005333,0.013731594197452068,0.012901983223855495,0.0123368538916111,0.01179267093539238,0.01141937356442213,0.011102195829153061,0.010822025127708912,0.010578515939414501,0.010387344285845757,0.010137791745364666,0.009623280726373196,0.009226348251104355,0.00909899827092886,0.008943664841353893,0.00877660047262907,0.008563730865716934,0.008465694263577461,0.008370173163712025,0.008265244774520397,0.008225489407777786,0.008026523515582085,0.008002424612641335,0.007881210185587406,0.007852155715227127,0.007819444872438908,0.007758918218314648,0.007697513792663813,0.007612518034875393,0.007593152113258839,0.007652920670807362,0.007443960290402174,0.00955360196530819,0.01364376675337553,0.01277264952659607,0.011618508026003838,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 7803      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 7804      
=================================================================
Total params: 15,607
Trainable params: 15,607
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 7,803
Trainable params: 7,803
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 7,804
Trainable params: 7,804
Non-trainable params: 0
_________________________________________________________________
