2021-06-26
loss,3.206097364425659,0.6867207884788513,0.45565158128738403,0.4486784338951111,0.4457860291004181,0.44533562660217285,0.4466209411621094,0.44988560676574707,0.44531628489494324,0.44633856415748596,0.4684940278530121,0.48518335819244385,0.44175320863723755,0.45436978340148926,0.4449220597743988,0.4417264461517334,0.3724711239337921,0.2807321846485138,0.2430555373430252,0.2304123491048813,0.20363740622997284,0.1978893131017685,0.1395432949066162,0.127088263630867,0.10013515502214432,0.07856117933988571,0.07501175254583359,0.07251905649900436,0.06854590773582458,0.062445268034935,0.05792855843901634,0.06294883042573929,0.04945854842662811,0.054658837616443634,0.04697921872138977,0.055822305381298065,0.0611361488699913,0.048041339963674545,0.04704582691192627,0.048411235213279724,0.04399031773209572,0.045461464673280716,0.037215545773506165,0.03827361762523651,0.0346330888569355,0.03611564263701439,0.041045933961868286,0.04115908592939377,0.041732750833034515,0.03473601117730141,0.035547830164432526,0.03513486310839653,0.028009872883558273,0.0349414087831974,0.040870118886232376,0.03270384669303894,0.02365056797862053,0.03330492973327637,0.03140901029109955,0.034765325486660004,0.036000560969114304,0.03517870977520943,0.033614903688430786,0.030998006463050842,0.027475763112306595,0.028240496292710304,0.03659679740667343,0.0331340916454792,0.029172547161579132,0.02631610445678234,0.027211535722017288,0.03528682515025139,0.029224863275885582,0.02970258705317974,0.030366089195013046,0.02874964475631714,0.02125435322523117,0.027401691302657127,0.027017854154109955,0.02810126729309559,0.03232111036777496,0.02448451519012451,0.03084353357553482,0.025393448770046234,0.026647208258509636,0.027560824528336525,0.02895103208720684,0.027231214568018913,0.023627113550901413,0.0199794452637434,0.023616589605808258,0.027179954573512077,0.027165668085217476,0.022785235196352005,0.022040313109755516,0.02794136293232441,0.02553354576230049,0.025963211432099342,0.025265157222747803,0.02394879050552845,
mse,2.9763400554656982,0.1442420482635498,0.05817214027047157,0.05616743862628937,0.055392369627952576,0.0553257092833519,0.05559946596622467,0.05649028718471527,0.05530151352286339,0.05553746595978737,0.06286395341157913,0.06785010546445847,0.05495724827051163,0.058495212346315384,0.055111680179834366,0.05431578680872917,0.040783535689115524,0.02474655956029892,0.019954146817326546,0.017883799970149994,0.0135845597833395,0.01268587913364172,0.006041551940143108,0.004898163955658674,0.003043318632990122,0.0018478536512702703,0.0016805401537567377,0.0016501226928085089,0.0014146114699542522,0.0011905134888365865,0.0010377016151323915,0.0012212254805490375,0.000725691847037524,0.0009073601686395705,0.000667220854666084,0.0009241957450285554,0.0010675229132175446,0.0007177176885306835,0.0006570440600626171,0.0006773009081371129,0.0005637449212372303,0.0005999722052365541,0.0004168136802036315,0.00044675334356725216,0.0003722893015947193,0.0003944810596294701,0.0004910887219011784,0.0004816373693756759,0.000497153028845787,0.0003558823955245316,0.00036562010063789785,0.00036707057734020054,0.00023036496713757515,0.0003572111309040338,0.00048498064279556274,0.0003191244904883206,0.00017103743448387831,0.0003260280063841492,0.0002950495108962059,0.00035478040808811784,0.0003720928798429668,0.000353837909642607,0.00033044800511561334,0.0002816127671394497,0.0002226343785878271,0.0002396969503024593,0.0003787321620620787,0.00031638945802114904,0.00024559348821640015,0.00020592805230990052,0.00022166813141666353,0.00035630256752483547,0.0002526354801375419,0.00025626347633078694,0.00026725989300757647,0.00024226920504588634,0.0001372341503156349,0.00022356241242960095,0.00021410615590866655,0.00022768981580156833,0.00030199886532500386,0.0001771366805769503,0.0002753052394837141,0.00019260242697782815,0.00021047930931672454,0.00022296348470263183,0.00024258188204839826,0.00020918110385537148,0.0001594207133166492,0.0001229865156346932,0.00016549890278838575,0.00022359289869200438,0.00021434602967929095,0.00015316357894334942,0.0001427853130735457,0.00023476581554859877,0.00019428605446591973,0.00019819740555249155,0.00018657895270735025,0.00016771149239502847,
mae,1.5132126808166504,0.29429370164871216,0.201478973031044,0.19877856969833374,0.19773218035697937,0.19748523831367493,0.19811071455478668,0.1992204487323761,0.19746896624565125,0.19789336621761322,0.20670148730278015,0.21237409114837646,0.19533227384090424,0.2002556174993515,0.19738750159740448,0.19590894877910614,0.16327260434627533,0.12523145973682404,0.11198052763938904,0.1031145453453064,0.08762046694755554,0.08521676808595657,0.059670042246580124,0.053895629942417145,0.042904697358608246,0.033682044595479965,0.0319351963698864,0.03142256662249565,0.029288064688444138,0.02689741924405098,0.02469540759921074,0.02700396254658699,0.021176770329475403,0.023437144234776497,0.019904427230358124,0.024220971390604973,0.02648862823843956,0.020603496581315994,0.020034782588481903,0.0209488645195961,0.018714426085352898,0.019702287390828133,0.015799056738615036,0.016648810356855392,0.014939215034246445,0.01542888954281807,0.017783114686608315,0.017905177548527718,0.018013352528214455,0.014879008755087852,0.015464588068425655,0.01501807477325201,0.012044554576277733,0.014999760314822197,0.017589068040251732,0.013948354870080948,0.010140679776668549,0.014314827509224415,0.01348437275737524,0.015070820227265358,0.015543279238045216,0.015127246268093586,0.014614402316510677,0.013263460248708725,0.011812045238912106,0.0120780561119318,0.01564606837928295,0.01459900476038456,0.012436016462743282,0.011293641291558743,0.011626038700342178,0.01517765037715435,0.012453329749405384,0.012678946368396282,0.01296958327293396,0.01224196795374155,0.008987289853394032,0.011845138855278492,0.011576127260923386,0.012098712846636772,0.01375094149261713,0.010511470958590508,0.013200223445892334,0.010817253962159157,0.011438483372330666,0.011884761042892933,0.01246075052767992,0.011814805679023266,0.010131372138857841,0.008513753302395344,0.010156006552278996,0.011845226399600506,0.011586058884859085,0.009774369187653065,0.00940670631825924,0.01191224716603756,0.010939644649624825,0.011169853620231152,0.010739389806985855,0.01021425612270832,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 363275    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 363276    
=================================================================
Total params: 726,551
Trainable params: 726,551
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 363,275
Trainable params: 363,275
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 363,276
Trainable params: 363,276
Non-trainable params: 0
_________________________________________________________________
