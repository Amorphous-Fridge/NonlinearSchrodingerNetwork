2021-06-26
loss,1.062599778175354,0.2894305884838104,0.2581656575202942,0.24440917372703552,0.2271377593278885,0.21111483871936798,0.19934053719043732,0.1947048008441925,0.18753188848495483,0.18345701694488525,0.17786970734596252,0.17233267426490784,0.16625675559043884,0.16318722069263458,0.17208881676197052,0.15342621505260468,0.15584906935691833,0.1493101567029953,0.1256248503923416,0.11604506522417068,0.11107779294252396,0.08086573332548141,0.09227180480957031,0.09416914731264114,0.08993595093488693,0.08994968235492706,0.07872451096773148,0.08770056068897247,0.0769890695810318,0.05888332054018974,0.07348264008760452,0.06451161205768585,0.06055783852934837,0.059298135340213776,0.056003473699092865,0.05796490237116814,0.04646884277462959,0.04557042941451073,0.054148875176906586,0.052147794514894485,0.05254855751991272,0.045417670160532,0.04720543324947357,0.04901625216007233,0.05058688297867775,0.04730051010847092,0.03962177038192749,0.045237425714731216,0.03909193351864815,0.034444812685251236,0.03551043942570686,0.03887997567653656,0.04304717853665352,0.036150604486465454,0.03538474068045616,0.03813399374485016,0.03817728906869888,0.03676557540893555,0.03140806779265404,0.03683701157569885,0.035170458257198334,0.03382699936628342,0.035063665360212326,0.03450441733002663,0.03187938407063484,0.031307537108659744,0.0345090888440609,0.03090083599090576,0.03197731077671051,0.03075510263442993,0.03103223629295826,0.03347744420170784,0.034423619508743286,0.02755136415362358,0.029831215739250183,0.029201671481132507,0.029543094336986542,0.03129514306783676,0.032189659774303436,0.026762185618281364,0.030139591544866562,0.028268173336982727,0.027475474402308464,0.030639642849564552,0.029262667521834373,0.028122184798121452,0.030421867966651917,0.024653568863868713,0.023107172921299934,0.031467005610466,0.028425496071577072,0.02530442550778389,0.02672092244029045,0.028101272881031036,0.026450105011463165,0.02616928331553936,0.029703086242079735,0.02631360851228237,0.0244838148355484,0.02690543420612812,
mse,0.5544236898422241,0.025267820805311203,0.020803725346922874,0.01861313171684742,0.01630638912320137,0.014358218759298325,0.013083096593618393,0.012429560534656048,0.011604061350226402,0.011111356317996979,0.010516110807657242,0.009884887374937534,0.009172940626740456,0.008354616351425648,0.008897094987332821,0.007024976424872875,0.007044330704957247,0.006344963330775499,0.004458061419427395,0.0037950677797198296,0.00361732579767704,0.0018454256933182478,0.0024289449211210012,0.0025148249696940184,0.0024078399874269962,0.0022917063906788826,0.0017793216975405812,0.0021777718793600798,0.0016782869352027774,0.0010378018487244844,0.0014944332651793957,0.0011471810285001993,0.0010236625093966722,0.001004926860332489,0.0008640831802040339,0.0009774341015145183,0.0006105920765548944,0.0005810297443531454,0.0008387895068153739,0.0007729753269813955,0.0007587027503177524,0.0005723017384298146,0.0006211494910530746,0.0006744542042724788,0.0007147743599489331,0.0006129448884166777,0.0004504710086621344,0.0005659490707330406,0.0004283639427740127,0.00033565080957487226,0.00036033452488482,0.0004289390053600073,0.0005152369849383831,0.0003857396950479597,0.0003513575065881014,0.00039902195567265153,0.00041091200546361506,0.00037913158303126693,0.0002801312366500497,0.00039693008875474334,0.00035592057975009084,0.00031811767257750034,0.00034622845123521984,0.000326805398799479,0.00028061799821443856,0.00027581985341385007,0.00033108913339674473,0.0002708769461605698,0.00028217199724167585,0.0002709022373892367,0.0002724816440604627,0.00031667525763623416,0.00033169411472044885,0.0002165617042919621,0.0002503418072592467,0.0002429658779874444,0.00024582495098002255,0.0002725138620007783,0.0002944532607216388,0.00020558314281515777,0.0002504186995793134,0.0002231272665085271,0.00021307954739313573,0.0002592485398054123,0.00023800134658813477,0.00022809837537351996,0.0002552459773141891,0.00017427699640393257,0.00015941228775773197,0.00027429155306890607,0.00021947243658360094,0.0001828566164476797,0.00020667552598752081,0.00022351034567691386,0.00020174289238639176,0.00019849877571687102,0.00024790375027805567,0.00019977573538199067,0.00017486457363702357,0.00020766905799973756,
mae,0.43898558616638184,0.12454643100500107,0.11330586671829224,0.10605566948652267,0.09706080704927444,0.0895809531211853,0.08465219289064407,0.08280438184738159,0.07953479886054993,0.07807218283414841,0.0757860541343689,0.07380634546279907,0.07121289521455765,0.06952521204948425,0.07287468761205673,0.06535474956035614,0.06639474630355835,0.06296070665121078,0.05332731083035469,0.04895360395312309,0.048247162252664566,0.03451414406299591,0.039192792028188705,0.0396307073533535,0.03845962882041931,0.037702471017837524,0.03363931551575661,0.0371689610183239,0.03214438632130623,0.024886205792427063,0.03124774619936943,0.02758030593395233,0.02540281042456627,0.025537539273500443,0.023142261430621147,0.024669522419571877,0.019892731681466103,0.01946312189102173,0.023243596777319908,0.021660273894667625,0.02174394764006138,0.019497105851769447,0.019904810935258865,0.0210903137922287,0.02115882933139801,0.019853657111525536,0.017083806917071342,0.019279442727565765,0.017106520012021065,0.014843207783997059,0.015526320785284042,0.016079099848866463,0.017709355801343918,0.015254373662173748,0.014976868405938148,0.015833767130970955,0.01612490974366665,0.015787698328495026,0.013276240788400173,0.015320992097258568,0.014996903948485851,0.014304063282907009,0.01505564246326685,0.014684373512864113,0.013407595455646515,0.013259831815958023,0.014839377254247665,0.013172122649848461,0.01340178120881319,0.013121305964887142,0.013088788837194443,0.014442750252783298,0.014479339122772217,0.011738793924450874,0.012792718596756458,0.012462493032217026,0.012524016201496124,0.013397694565355778,0.013361037708818913,0.01142509188503027,0.012693071737885475,0.012077800929546356,0.011630374938249588,0.013282034546136856,0.012585526332259178,0.012036601081490517,0.01327885128557682,0.010380071587860584,0.009845396503806114,0.013510606251657009,0.012133046053349972,0.010638037696480751,0.011211078613996506,0.01218782551586628,0.011431863531470299,0.011091339401900768,0.012547675520181656,0.011068091727793217,0.010543341748416424,0.011340964585542679,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 144547    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 144548    
=================================================================
Total params: 289,095
Trainable params: 289,095
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 144,547
Trainable params: 144,547
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 144,548
Trainable params: 144,548
Non-trainable params: 0
_________________________________________________________________
