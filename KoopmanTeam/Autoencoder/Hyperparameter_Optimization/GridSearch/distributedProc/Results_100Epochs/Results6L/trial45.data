2021-06-26
loss,2.2655577659606934,2.2052338123321533,2.205130100250244,2.2055470943450928,2.2121589183807373,2.204772710800171,2.204148054122925,2.203735589981079,2.204068660736084,2.20474910736084,2.203413963317871,2.2035903930664062,2.2044003009796143,2.2043046951293945,2.2046608924865723,2.209063768386841,2.2046051025390625,2.2038557529449463,2.203956365585327,2.2040646076202393,2.2027571201324463,2.2038145065307617,2.203972101211548,2.2043368816375732,2.203371047973633,2.2035906314849854,2.0435125827789307,0.39022257924079895,0.35425254702568054,0.3525390625,0.34872299432754517,0.3418774902820587,0.3278023600578308,0.33827388286590576,0.3141249120235443,0.3092358708381653,0.30331265926361084,0.29924723505973816,0.29454588890075684,0.2921515703201294,0.2870658338069916,0.28707459568977356,0.27688300609588623,0.2828744351863861,0.27156826853752136,0.28100889921188354,0.26684054732322693,0.21644531190395355,0.17157989740371704,0.15555989742279053,0.1487729698419571,0.14370930194854736,0.14116691052913666,0.13725297152996063,0.13621169328689575,0.13311868906021118,0.13161715865135193,0.13049088418483734,0.1261102557182312,0.12531527876853943,0.12210416793823242,0.12086749821901321,0.1274496614933014,0.10478789359331131,0.08360255509614944,0.08613746613264084,0.08141203969717026,0.07471667975187302,0.08037492632865906,0.07321897894144058,0.07411351054906845,0.05416543781757355,0.06599370390176773,0.06149894744157791,0.05335351452231407,0.05741703882813454,0.06532540917396545,0.05164055526256561,0.05435829237103462,0.058871012181043625,0.04317799210548401,0.031958095729351044,0.0312443058937788,0.03769684210419655,0.04260105639696121,0.03935398906469345,0.043321914970874786,0.04314901679754257,0.03708963096141815,0.033561889082193375,0.039782747626304626,0.049259286373853683,0.03879888355731964,0.04745374247431755,0.04338803142309189,0.037515901029109955,0.033571138978004456,0.030854636803269386,0.03304846212267876,0.03752068430185318,
mse,1.3004860877990723,1.2297154664993286,1.229652762413025,1.230135440826416,1.2373692989349365,1.229303240776062,1.2286486625671387,1.22817862033844,1.2285335063934326,1.22929847240448,1.2277967929840088,1.2280640602111816,1.2289502620697021,1.2288403511047363,1.2291700839996338,1.2340772151947021,1.2291219234466553,1.2283085584640503,1.2284471988677979,1.2284995317459106,1.2270185947418213,1.228209137916565,1.2284154891967773,1.2288099527359009,1.2277307510375977,1.227900505065918,1.229772686958313,0.044286638498306274,0.037421274930238724,0.03730139508843422,0.036782022565603256,0.03535353019833565,0.032850440591573715,0.03447398543357849,0.030154770240187645,0.02905341424047947,0.028143681585788727,0.02745337039232254,0.026757918298244476,0.02632271684706211,0.02551320753991604,0.025384433567523956,0.023881569504737854,0.024811189621686935,0.023095719516277313,0.024322763085365295,0.02187538705766201,0.014877382665872574,0.00997876189649105,0.00839924719184637,0.007761373650282621,0.007322869263589382,0.007074220571666956,0.006702756509184837,0.006602440029382706,0.006318997126072645,0.006218823604285717,0.006073390133678913,0.005633570719510317,0.005472886376082897,0.005188389215618372,0.004844835959374905,0.004971718415617943,0.003596643218770623,0.0023457896895706654,0.002414490794762969,0.0020870298612862825,0.001802937244065106,0.0019966766703873873,0.0016671024495735765,0.0017229228978976607,0.0009204596281051636,0.0013375065755099058,0.0011257679434493184,0.0008537661051377654,0.0009821561397984624,0.0012713030446320772,0.0007712729275226593,0.0008582379668951035,0.0010129527654498816,0.0005947152967564762,0.00030878750840201974,0.0002903974964283407,0.0004234894295223057,0.0005228256923146546,0.0004579465021379292,0.0005769113777205348,0.0005271272966638207,0.0003877136914525181,0.00033367041032761335,0.00047122142859734595,0.0007061503129079938,0.0004266546748112887,0.0006415974930860102,0.0005460599204525352,0.0003971525002270937,0.00031390576623380184,0.00026450655423104763,0.0003236448101233691,0.0003946144424844533,
mae,0.7349595427513123,0.6041895151138306,0.6016225218772888,0.6024271249771118,0.6228272914886475,0.6010854840278625,0.5945612192153931,0.5932927131652832,0.5926439762115479,0.592540979385376,0.5918247103691101,0.5945169925689697,0.595125675201416,0.59431391954422,0.5968716144561768,0.6165950298309326,0.592248797416687,0.5911506414413452,0.5908743143081665,0.5906961560249329,0.5899726748466492,0.5904382467269897,0.5902014374732971,0.59029620885849,0.5918863415718079,0.5902136564254761,0.7238911986351013,0.1692080944776535,0.15601490437984467,0.15626659989356995,0.15516160428524017,0.15108515322208405,0.14329124987125397,0.14693152904510498,0.1378331333398819,0.13507333397865295,0.13229255378246307,0.13026957213878632,0.12814819812774658,0.12681788206100464,0.12455663830041885,0.12449559569358826,0.11996588855981827,0.12240532040596008,0.11800618469715118,0.12142684310674667,0.11524847894906998,0.09362923353910446,0.07339420914649963,0.06605348736047745,0.06296095252037048,0.0608135461807251,0.05933169275522232,0.05732924863696098,0.05666084215044975,0.05509233474731445,0.05430850014090538,0.0538683645427227,0.052091874182224274,0.05226512998342514,0.051064472645521164,0.05151122435927391,0.05458740144968033,0.04457175359129906,0.03547746315598488,0.03710319846868515,0.034954506903886795,0.03181976079940796,0.033950325101614,0.03118257224559784,0.03180535137653351,0.022989900782704353,0.02802836336195469,0.026215223595499992,0.022889019921422005,0.024175552651286125,0.02744869515299797,0.02207534946501255,0.02282019332051277,0.02485462836921215,0.01828649826347828,0.013562185689806938,0.013271177187561989,0.01607423648238182,0.018210656940937042,0.01680135540664196,0.018427414819598198,0.018641622737050056,0.01599118299782276,0.014174201525747776,0.017141425982117653,0.021034326404333115,0.016650330275297165,0.02016313560307026,0.01869252510368824,0.01623343676328659,0.014580662362277508,0.012780658900737762,0.013930082321166992,0.01592840813100338,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 103331    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 103332    
=================================================================
Total params: 206,663
Trainable params: 206,663
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 103,331
Trainable params: 103,331
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 103,332
Trainable params: 103,332
Non-trainable params: 0
_________________________________________________________________
