2021-06-26
loss,2.370145082473755,2.2122602462768555,2.205928325653076,2.203470468521118,2.4740309715270996,1.2492730617523193,0.3325066864490509,0.24284857511520386,0.1956002116203308,0.1939336210489273,0.11717003583908081,0.10979237407445908,0.1309502273797989,0.10703665018081665,0.1331457495689392,0.09542126953601837,0.08592027425765991,0.08300668001174927,0.07891296595335007,0.0938773825764656,0.11356966942548752,0.09587356448173523,0.07705098390579224,0.0646427795290947,0.04774578660726547,0.07154901325702667,0.057813216000795364,0.06569921970367432,0.06447857618331909,0.058407627046108246,0.05430394038558006,0.055657196789979935,0.08402292430400848,0.06913595646619797,0.06638661026954651,0.06468288600444794,0.05345144122838974,0.06271863728761673,0.0627378523349762,0.059958070516586304,0.057324767112731934,0.04778344929218292,0.04180668294429779,0.03917983919382095,0.055339887738227844,0.05360901728272438,0.06076210364699364,0.054845377802848816,0.046171244233846664,0.04000630974769592,0.036700569093227386,0.048393119126558304,0.04933871328830719,0.04479719325900078,0.04788564518094063,0.04256736859679222,0.0411953367292881,0.039528295397758484,0.059410352259874344,0.052155304700136185,0.0438278466463089,0.03820168599486351,0.038920771330595016,0.03745168074965477,0.03709503635764122,0.03678717464208603,0.05095260962843895,0.05338841304183006,0.04683157056570053,0.04220389947295189,0.0366254486143589,0.04897027462720871,0.049487579613924026,0.04459214583039284,0.040030431002378464,0.0343463271856308,0.0326370969414711,0.03789312765002251,0.043502964079380035,0.045336149632930756,0.047376204282045364,0.04113946855068207,0.036289941519498825,0.033670295029878616,0.03467649966478348,0.04084156081080437,0.0386810228228569,0.03828493505716324,0.037597887217998505,0.03246338292956352,0.03335258364677429,0.040788985788822174,0.04443216696381569,0.046403538435697556,0.040388889610767365,0.0325688011944294,0.036253493279218674,0.035163260996341705,0.0376472994685173,0.04646506905555725,
mse,1.4422821998596191,1.2371553182601929,1.2305512428283691,1.2278820276260376,1.6538947820663452,0.5482267141342163,0.03316229209303856,0.018816914409399033,0.011022858321666718,0.010803998447954655,0.0041807908564805984,0.0035545711871236563,0.0050183809362351894,0.003174283541738987,0.004902871325612068,0.0026390906423330307,0.002122211502864957,0.0018927000928670168,0.0017469321610406041,0.0024708479177206755,0.0037518173921853304,0.0027143678162246943,0.0016501296777278185,0.0012872256338596344,0.0006488073850050569,0.0014883577823638916,0.0009253399912267923,0.001208500238135457,0.0011452026665210724,0.0009581443737260997,0.0008336508763022721,0.0008994981180876493,0.001978990389034152,0.0013581769308075309,0.0012286908458918333,0.0011681282194331288,0.000831360521260649,0.00110975606366992,0.0010736980475485325,0.0009656635811552405,0.0008909914758987725,0.0006213980377651751,0.0004816028813365847,0.0004397195589262992,0.0008620797889307141,0.0007969767320901155,0.0010140335652977228,0.0008263300405815244,0.0005876461509615183,0.0004444528021849692,0.00038277622661553323,0.0006646233960054815,0.0007163185509853065,0.0005781687214039266,0.0006422512815333903,0.000503476127050817,0.0004696192918345332,0.0004614439094439149,0.0009657717309892178,0.0007283315062522888,0.0005377888446673751,0.0004088485147804022,0.00042740945355035365,0.00039475056109949946,0.00038172092172317207,0.00041436098399572074,0.0007608887390233576,0.000769197940826416,0.0005849036970175803,0.00048729684203863144,0.0003859194985125214,0.000665023981127888,0.0006659943610429764,0.0005345200188457966,0.0004386634682305157,0.00032889063004404306,0.00030387923470698297,0.00041129294550046325,0.000526553369127214,0.0005673067644238472,0.000612853851635009,0.0004589174350257963,0.00035791334812529385,0.0003039004805032164,0.00034615618642419577,0.00045984634198248386,0.000408320251153782,0.00039356749039143324,0.00040684978011995554,0.0002943459548987448,0.00031336609390564263,0.00045376981142908335,0.000556472223252058,0.0005799492355436087,0.0004528280987869948,0.0002970348868984729,0.0003638262569438666,0.0003389713237993419,0.0004002892237622291,0.0005784202949143946,
mae,0.8036896586418152,0.6156054139137268,0.6002060770988464,0.5987630486488342,0.8950458765029907,0.44031521677970886,0.14003008604049683,0.10441647469997406,0.08347074687480927,0.08311028778553009,0.049605730921030045,0.045931652188301086,0.05459752678871155,0.04538640007376671,0.05643133074045181,0.04048774763941765,0.03619607165455818,0.03532017767429352,0.0339961014688015,0.038749221712350845,0.04693378880620003,0.04062213376164436,0.03236919641494751,0.026431754231452942,0.020364411175251007,0.030977444723248482,0.02433900348842144,0.028274960815906525,0.02740217000246048,0.025668375194072723,0.022471465170383453,0.023744767531752586,0.035807158797979355,0.028942950069904327,0.027414729818701744,0.0268003661185503,0.022663071751594543,0.02720654010772705,0.026743466034531593,0.025547776371240616,0.024165470153093338,0.020741673186421394,0.01793743297457695,0.01673293299973011,0.02339923195540905,0.022854436188936234,0.02515985071659088,0.02277606539428234,0.019920697435736656,0.017770832404494286,0.015703916549682617,0.020537078380584717,0.021388523280620575,0.018613209947943687,0.020147133618593216,0.018330899998545647,0.01729498617351055,0.016770437359809875,0.025259824469685555,0.022257892414927483,0.017833612859249115,0.01598398946225643,0.016770370304584503,0.01614443212747574,0.01574857532978058,0.015208317898213863,0.021289469674229622,0.0223268773406744,0.020337563008069992,0.017789507284760475,0.015603896230459213,0.02039550617337227,0.020329810678958893,0.019497044384479523,0.016289228573441505,0.01441736426204443,0.013678801245987415,0.015808865427970886,0.01854279264807701,0.01991511695086956,0.01946735382080078,0.01784953661262989,0.016066566109657288,0.014717437326908112,0.014991980977356434,0.01720968633890152,0.01662295125424862,0.015982389450073242,0.015743905678391457,0.013723155483603477,0.014123369008302689,0.017455559223890305,0.018352026119828224,0.019584977999329567,0.017577113583683968,0.013897798024117947,0.015305481851100922,0.01470186561346054,0.016053324565291405,0.019345605745911598,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 121827    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 121828    
=================================================================
Total params: 243,655
Trainable params: 243,655
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 121,827
Trainable params: 121,827
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 121,828
Trainable params: 121,828
Non-trainable params: 0
_________________________________________________________________
