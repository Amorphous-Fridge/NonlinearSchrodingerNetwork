2021-06-26
loss,0.7674739360809326,0.26544228196144104,0.24776113033294678,0.24054878950119019,0.2340254783630371,0.2224445790052414,0.21342405676841736,0.20247513055801392,0.19478681683540344,0.18437767028808594,0.17031648755073547,0.190793976187706,0.15769685804843903,0.11580995470285416,0.11988358199596405,0.12526953220367432,0.08709489554166794,0.07211437076330185,0.07380418479442596,0.0887891873717308,0.06191312149167061,0.06146843731403351,0.07309500873088837,0.05367239564657211,0.05235574394464493,0.05822337791323662,0.06691533327102661,0.060160961002111435,0.05582677945494652,0.04868073761463165,0.03821462020277977,0.04956711456179619,0.0561726950109005,0.05142824351787567,0.05437113717198372,0.04869278892874718,0.040744829922914505,0.03849494829773903,0.035419922322034836,0.04676639661192894,0.03968043252825737,0.04257164150476456,0.042955413460731506,0.035588279366493225,0.030908815562725067,0.036157459020614624,0.044871166348457336,0.039838820695877075,0.033279526978731155,0.038655202835798264,0.03787862882018089,0.032978884875774384,0.033470429480075836,0.03777211531996727,0.0389212928712368,0.03669482097029686,0.032537929713726044,0.035930220037698746,0.030721331015229225,0.03438631817698479,0.029958905652165413,0.029384713619947433,0.032575588673353195,0.035564206540584564,0.0366593562066555,0.03527330234646797,0.03273436054587364,0.030119692906737328,0.02801431342959404,0.030212324112653732,0.031347230076789856,0.030586691573262215,0.03366175293922424,0.030861085280776024,0.030009381473064423,0.028593339025974274,0.02642381191253662,0.024530164897441864,0.0286260936409235,0.030848443508148193,0.028720097616314888,0.026790136471390724,0.02831205539405346,0.022522881627082825,0.028112215921282768,0.029539840295910835,0.026442382484674454,0.023943670094013214,0.021643133834004402,0.029727477580308914,0.028014469891786575,0.02435552515089512,0.02368033491075039,0.026531238108873367,0.025227973237633705,0.029878567904233932,0.02867920696735382,0.027392998337745667,0.027297599241137505,0.023619944229722023,
mse,0.27200716733932495,0.022236960008740425,0.02007441036403179,0.019106581807136536,0.018103400245308876,0.016565674915909767,0.01529501099139452,0.01394387986510992,0.012974156998097897,0.011561764404177666,0.009325502440333366,0.010944141075015068,0.007304765749722719,0.00401149271056056,0.004138439893722534,0.004415505100041628,0.0021235148888081312,0.0015016623074188828,0.0016085851239040494,0.002274951431900263,0.0010799190495163202,0.0010990671580657363,0.0015257427003234625,0.0008271059487015009,0.0007748712669126689,0.0009387217578478158,0.0012567476369440556,0.0010145470732823014,0.0008924403809942305,0.0006653100135736167,0.0004297161940485239,0.0007063779048621655,0.0009152663988061249,0.0007321208831854165,0.000813107646536082,0.0006816423847340047,0.0004598677624017,0.000408005784265697,0.0003573087160475552,0.0006185302045196295,0.00043994851876050234,0.0005056682857684791,0.0005159663269296288,0.00034739685361273587,0.000271572673227638,0.0003938713052775711,0.0005678820889443159,0.0004401789337862283,0.00031637813663110137,0.00043851722148247063,0.0004157822113484144,0.0003076144785154611,0.00031672645127400756,0.00040420846198685467,0.0004334250115789473,0.00037756984238512814,0.00030242849607020617,0.00036268241819925606,0.0002649415982887149,0.0003425131435506046,0.0002493291103746742,0.00024574651615694165,0.00030227607931010425,0.0003501298779156059,0.0003785626613534987,0.00034895192948170006,0.00030495814280584455,0.00026277973665855825,0.00022403286129701883,0.00026006787084043026,0.00027960730949416757,0.0002646515495143831,0.0003098882734775543,0.0002652337425388396,0.0002505259762983769,0.00022928784892428666,0.00019314922974444926,0.00017299936735071242,0.00023925263667479157,0.0002641537575982511,0.0002305351517861709,0.00020605143799912184,0.00022703416470903903,0.00014466425636783242,0.0002279426553286612,0.0002480013354215771,0.00019428679661359638,0.0001617199304746464,0.0001337051362497732,0.00024699847563169897,0.00022254431678447872,0.00016422146291006356,0.00015856313984841108,0.0002003410627366975,0.00018371881742496043,0.00024786413996480405,0.00022652291227132082,0.0002115738025167957,0.00020354373555164784,0.00015888616326265037,
mae,0.32509976625442505,0.11757636070251465,0.11001861840486526,0.1070883646607399,0.10334082692861557,0.0972430408000946,0.0923691913485527,0.08663108944892883,0.08284687995910645,0.07823216170072556,0.07246457785367966,0.08092597872018814,0.06528795510530472,0.0487857423722744,0.05012986809015274,0.053542327135801315,0.03651058301329613,0.030865631997585297,0.031742703169584274,0.03767383471131325,0.026065101847052574,0.026281600818037987,0.03182940185070038,0.02304433286190033,0.022547021508216858,0.0250378604978323,0.028587257489562035,0.026057198643684387,0.024565057829022408,0.020375557243824005,0.01643020659685135,0.02061905339360237,0.024298958480358124,0.02215251699090004,0.02404613047838211,0.021461622789502144,0.01747591607272625,0.01638367958366871,0.015171780250966549,0.02025989256799221,0.016700660809874535,0.018310319632291794,0.018172668293118477,0.01520509459078312,0.013435805216431618,0.015732623636722565,0.019293736666440964,0.017500774934887886,0.01425134390592575,0.016330789774656296,0.01656517945230007,0.013756648637354374,0.014405670575797558,0.016522260382771492,0.016962314024567604,0.01575547270476818,0.01405050978064537,0.015138941816985607,0.012942551635205746,0.014573072083294392,0.012564051896333694,0.012530907057225704,0.013830354437232018,0.015152816660702229,0.016144098713994026,0.015476575121283531,0.01427502278238535,0.012968138791620731,0.01168119814246893,0.01298768911510706,0.013148919679224491,0.012945720925927162,0.01458024512976408,0.013380497694015503,0.01253372523933649,0.01218001451343298,0.01113766711205244,0.010468454100191593,0.012234288267791271,0.01335485652089119,0.011882863007485867,0.011417337693274021,0.012250933796167374,0.009363127872347832,0.011713295243680477,0.012731362134218216,0.011255640536546707,0.010080171748995781,0.008961407467722893,0.012862341478466988,0.011975410394370556,0.010531315580010414,0.010043918155133724,0.01133489515632391,0.010629218071699142,0.01287315133959055,0.012174069881439209,0.011640983633697033,0.011778652667999268,0.009930174797773361,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 100595    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 100596    
=================================================================
Total params: 201,191
Trainable params: 201,191
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 100,595
Trainable params: 100,595
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 100,596
Trainable params: 100,596
Non-trainable params: 0
_________________________________________________________________
