2021-06-26
loss,0.7574074268341064,0.24267923831939697,0.23101545870304108,0.21753431856632233,0.1731564700603485,0.1225542426109314,0.12944553792476654,0.11745711416006088,0.10196727514266968,0.09801807254552841,0.10159558057785034,0.085616834461689,0.09771759063005447,0.09094797074794769,0.0812712088227272,0.0810086727142334,0.0748642086982727,0.0615643747150898,0.061585236340761185,0.07297230511903763,0.06120068579912186,0.06100605055689812,0.06478951126337051,0.0665053203701973,0.04509292170405388,0.05844571068882942,0.0590701624751091,0.047843798995018005,0.039860453456640244,0.04863246902823448,0.0470307394862175,0.04815838485956192,0.0518127903342247,0.039102572947740555,0.05255145579576492,0.051618240773677826,0.04710453376173973,0.04094467684626579,0.044711433351039886,0.04755224287509918,0.03564613685011864,0.032507747411727905,0.041275762021541595,0.04191349446773529,0.040078625082969666,0.04132645204663277,0.0437903068959713,0.039409153163433075,0.04037647694349289,0.03725684806704521,0.03471333906054497,0.0347847156226635,0.030758244916796684,0.03356565162539482,0.04440968483686447,0.03805926442146301,0.029599711298942566,0.02885819412767887,0.04053090885281563,0.034972455352544785,0.03153115510940552,0.028110690414905548,0.03224307671189308,0.03642056882381439,0.038832955062389374,0.035722099244594574,0.03633371740579605,0.033446840941905975,0.028704360127449036,0.033360227942466736,0.0317598432302475,0.029171710833907127,0.02739952877163887,0.030757583677768707,0.03144317492842674,0.025577740743756294,0.0236140675842762,0.031489647924900055,0.03043459914624691,0.024106569588184357,0.027809826657176018,0.02814493328332901,0.02646508440375328,0.03180984407663345,0.02686172164976597,0.026044854894280434,0.026783911511301994,0.031697794795036316,0.02754759043455124,0.025325581431388855,0.030790727585554123,0.024020688608288765,0.0261590164154768,0.02756381779909134,0.028387894853949547,0.029309671372175217,0.02862776257097721,0.0235751885920763,0.02732732705771923,0.02878677286207676,
mse,0.2455543726682663,0.019645964726805687,0.018051130697131157,0.015927832573652267,0.009019779972732067,0.0042389617301523685,0.004988528788089752,0.0038997239898890257,0.0029196268878877163,0.002879610750824213,0.0029151150956749916,0.002078136196359992,0.0027787936851382256,0.00228986912406981,0.0018016983522102237,0.0018255481263622642,0.0015519935404881835,0.0010569107253104448,0.001153762568719685,0.0015963652404025197,0.0010686925379559398,0.0010370488744229078,0.001249666791409254,0.0012231407454237342,0.0006024067988619208,0.0009984447387978435,0.0009765523718670011,0.000651415903121233,0.0004426002851687372,0.0006819417467340827,0.0006304132402874529,0.0006546940421685576,0.0007389198872260749,0.0004359851882327348,0.000781402864959091,0.0007365893688984215,0.0006267025601118803,0.000474879372632131,0.0005622858298011124,0.0006403529550880194,0.0003695792693179101,0.0003010762738995254,0.0004742666787933558,0.0004964715335518122,0.0004465271485969424,0.00048278915346600115,0.0005451778997667134,0.00042620309977792203,0.00045076743117533624,0.00038471288280561566,0.00033686793176457286,0.00034486743970774114,0.00026254067779518664,0.00032431192812509835,0.0005314921145327389,0.0003983253554906696,0.00025399454170838,0.00023011548910290003,0.00046492888941429555,0.0003469367802608758,0.0002778200141619891,0.00022142112720757723,0.00030202241032384336,0.0003783572174143046,0.0004141024255659431,0.00035898975329473615,0.00037185385008342564,0.00031553182634525,0.00023544294526800513,0.0003179131308570504,0.00027965428307652473,0.0002360198413953185,0.00021581101464107633,0.0002728996332734823,0.000275729107670486,0.0001830043620429933,0.000160510404384695,0.0002819077344611287,0.0002613578108139336,0.00016588809376116842,0.000217877677641809,0.00022286400781013072,0.00019913951109629124,0.0002833122853189707,0.00020038783259224147,0.00019149310537613928,0.0002037787635345012,0.0002841498935595155,0.0002126961189787835,0.00018330063903704286,0.0002681660698726773,0.0001660399284446612,0.00019265217997599393,0.00022118724882602692,0.00022241845726966858,0.00023615667305421084,0.0002422077814117074,0.00015879156126175076,0.00020784935622941703,0.00022952572908252478,
mae,0.3233506679534912,0.11011988669633865,0.1049085408449173,0.09763500839471817,0.0738920271396637,0.05228525027632713,0.05505523830652237,0.04932359606027603,0.04151272773742676,0.04120581969618797,0.04249630123376846,0.03590229153633118,0.039809320122003555,0.03736678883433342,0.033457666635513306,0.03494216501712799,0.0318530835211277,0.025123171508312225,0.025581179186701775,0.029963389039039612,0.02611391618847847,0.02649417705833912,0.02784784510731697,0.02873295731842518,0.019217021763324738,0.024651989340782166,0.025050701573491096,0.020301727578043938,0.017414970323443413,0.02083977870643139,0.019717639312148094,0.02053186483681202,0.02252301760017872,0.016665566712617874,0.022422021254897118,0.02209613285958767,0.020008521154522896,0.017660807818174362,0.01903327740728855,0.020412148907780647,0.015173954889178276,0.014113136567175388,0.017908895388245583,0.017697613686323166,0.01725977100431919,0.01746339537203312,0.018737001344561577,0.016679761931300163,0.017023814842104912,0.0159065593034029,0.014557098969817162,0.01476576179265976,0.01307342667132616,0.014302638359367847,0.017863435670733452,0.01616588979959488,0.012599191628396511,0.012436246499419212,0.016908379271626472,0.014755437150597572,0.013410532847046852,0.011943602934479713,0.0138549217954278,0.015202665701508522,0.015555329620838165,0.01475698035210371,0.015547658316791058,0.014137349091470242,0.012166568078100681,0.013863477855920792,0.013575322926044464,0.012092028744518757,0.011388076469302177,0.012822270393371582,0.013353202491998672,0.01089437399059534,0.009936759248375893,0.013564586639404297,0.01300830952823162,0.010260925628244877,0.011942392215132713,0.011738107539713383,0.011272778734564781,0.013449715450406075,0.011147504672408104,0.011012444272637367,0.011170740239322186,0.013297908008098602,0.011607707478106022,0.010724669322371483,0.012423424981534481,0.01002485677599907,0.011071222834289074,0.011600475758314133,0.01186184398829937,0.012665053829550743,0.01186384353786707,0.010132300667464733,0.011509912088513374,0.011758663691580296,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34803     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34804     
=================================================================
Total params: 69,607
Trainable params: 69,607
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 34,803
Trainable params: 34,803
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 34,804
Trainable params: 34,804
Non-trainable params: 0
_________________________________________________________________
