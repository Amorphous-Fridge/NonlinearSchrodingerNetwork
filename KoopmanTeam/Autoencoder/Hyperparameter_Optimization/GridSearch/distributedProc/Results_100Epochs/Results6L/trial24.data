2021-06-26
loss,0.6906251311302185,0.26489681005477905,0.16425998508930206,0.16888630390167236,0.11127806454896927,0.10960947722196579,0.09647545218467712,0.10273320227861404,0.09174931794404984,0.0916532576084137,0.06975800544023514,0.06766916066408157,0.07663023471832275,0.06918676942586899,0.06789541989564896,0.07380177080631256,0.06080383434891701,0.05839008837938309,0.06710290908813477,0.05172201991081238,0.05098055303096771,0.0668536126613617,0.060771550983190536,0.04867847263813019,0.04147228226065636,0.054476987570524216,0.05251495540142059,0.05475451052188873,0.05841926112771034,0.053568318486213684,0.047675665467977524,0.04209621250629425,0.0372624397277832,0.03483979403972626,0.03833432123064995,0.044631265103816986,0.046532440930604935,0.05105384811758995,0.04343521595001221,0.04406433925032616,0.04485497996211052,0.04373425990343094,0.03611540049314499,0.04165377467870712,0.03313316032290459,0.030483677983283997,0.037614502012729645,0.04272496700286865,0.04099395126104355,0.03885247930884361,0.03387746959924698,0.036546122282743454,0.030173763632774353,0.0319598950445652,0.033810459077358246,0.04102142155170441,0.03578512743115425,0.03500594198703766,0.03850644454360008,0.03954974189400673,0.035787735134363174,0.03222264349460602,0.026291046291589737,0.03169827535748482,0.030042530968785286,0.03200605511665344,0.03553197160363197,0.03064962662756443,0.03495744615793228,0.034237202256917953,0.033025965094566345,0.03370687738060951,0.029160592705011368,0.03190102428197861,0.027437720447778702,0.027957089245319366,0.0313417911529541,0.03298639506101608,0.03466278314590454,0.0296503733843565,0.03149902820587158,0.03058609738945961,0.03216632083058357,0.027628066018223763,0.026143839582800865,0.02588677406311035,0.03153644874691963,0.03029005043208599,0.029475901275873184,0.02769739180803299,0.03077554702758789,0.029730968177318573,0.027073100209236145,0.032227691262960434,0.030413394793868065,0.028164029121398926,0.02857932634651661,0.027861647307872772,0.026676476001739502,0.02379128523170948,
mse,0.19708415865898132,0.022337421774864197,0.008346172980964184,0.008276647888123989,0.003784005530178547,0.0032948411535471678,0.002686879364773631,0.0029611673671752214,0.00240388885140419,0.002335446886718273,0.0013886678498238325,0.001293334411457181,0.0016802173340693116,0.0013490361161530018,0.0012902289163321257,0.0014802874065935612,0.0010142107494175434,0.0009627932449802756,0.001451884862035513,0.0007901588105596602,0.0007449731347151101,0.001288197934627533,0.0010226122103631496,0.0006854475359432399,0.0004889417323283851,0.0008682829793542624,0.0007599108503200114,0.0008373214513994753,0.0009484500624239445,0.0007702375878579915,0.0006174254231154919,0.0004830881953239441,0.0003769062750507146,0.0003293946501798928,0.00042197515722364187,0.000569555617403239,0.0005961760762147605,0.0007287858170457184,0.0005240713944658637,0.0005488113383762538,0.0005607001949101686,0.0005392497987486422,0.0003718449152074754,0.0004930293653160334,0.00030509347561746836,0.0002708183310460299,0.0003985836810898036,0.0005371806910261512,0.00046181483776308596,0.0004206677549518645,0.0003208807611372322,0.00037202390376478434,0.0002695910516194999,0.00029086359427310526,0.0003361013950780034,0.0004740265430882573,0.00037453725235536695,0.00034815387334674597,0.00041136384243145585,0.0004268800839781761,0.000351809139829129,0.00029178650584071875,0.00021143784397281706,0.00029104953864589334,0.000264920323388651,0.00028981376090086997,0.00035030688741244376,0.000261844223132357,0.00034424432669766247,0.0003225739055778831,0.00030214281287044287,0.0003164601803291589,0.0002372078160988167,0.00027699273778125644,0.0002096787211485207,0.00022602954413741827,0.0002837000647559762,0.0003041239979211241,0.0003258531796745956,0.00024575184215791523,0.0002800078073050827,0.00026675849221646786,0.0002802422095555812,0.00021510684746317565,0.00019312671793159097,0.0001911644940264523,0.00027945649344474077,0.0002524603914935142,0.00024411146296188235,0.00021460381685756147,0.00026487268041819334,0.00024378807574976236,0.00020666327327489853,0.00028896520962007344,0.00025578218628652394,0.00022755622921977192,0.0002252888079965487,0.00022670246835332364,0.000197838744497858,0.00016018241876736283,
mae,0.2971116006374359,0.11039985716342926,0.06958725303411484,0.07419200241565704,0.047702606767416,0.04688918590545654,0.040996719151735306,0.04344233497977257,0.03911568596959114,0.03917676955461502,0.02949102222919464,0.028731780126690865,0.032778915017843246,0.029647693037986755,0.028821194544434547,0.031995080411434174,0.025555426254868507,0.024875300005078316,0.027532540261745453,0.021804071962833405,0.02151234820485115,0.028499919921159744,0.025804579257965088,0.020738065242767334,0.017352288588881493,0.022940125316381454,0.02258581668138504,0.02370252087712288,0.024782758206129074,0.022406043484807014,0.01983177289366722,0.017976494506001472,0.015880046412348747,0.015013152733445168,0.016050303354859352,0.018730012699961662,0.01942293345928192,0.021896591410040855,0.01870834268629551,0.019388025626540184,0.01956380531191826,0.018338439986109734,0.015286428853869438,0.017940277233719826,0.014431093819439411,0.01292560063302517,0.01593698188662529,0.01822086051106453,0.017376722767949104,0.016773344948887825,0.014265533536672592,0.01533516962081194,0.01304720714688301,0.013545957393944263,0.014430630020797253,0.01744811236858368,0.015623977407813072,0.01511287223547697,0.016118958592414856,0.016922827810049057,0.015756744891405106,0.014022324234247208,0.011035088449716568,0.013212558813393116,0.012859812006354332,0.013489068485796452,0.015154952183365822,0.012811466120183468,0.014721822924911976,0.015148171223700047,0.014448919333517551,0.014308815822005272,0.012276643887162209,0.01386734563857317,0.011412901803851128,0.011937273666262627,0.013523378409445286,0.014149529859423637,0.014936570078134537,0.012783050537109375,0.013221587054431438,0.013012574054300785,0.013878703117370605,0.012065264396369457,0.011038802564144135,0.011120663024485111,0.01322133094072342,0.013015777803957462,0.013071302324533463,0.012083809822797775,0.013375483453273773,0.013298813253641129,0.011601367965340614,0.014281258918344975,0.012792391702532768,0.01211540587246418,0.011829699389636517,0.011833489872515202,0.01139303669333458,0.009845594875514507,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 36451     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 36452     
=================================================================
Total params: 72,903
Trainable params: 72,903
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 36,451
Trainable params: 36,451
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 36,452
Trainable params: 36,452
Non-trainable params: 0
_________________________________________________________________
