2021-06-26
loss,1.3352043628692627,0.4305218458175659,0.37098991870880127,0.3652286231517792,0.36673828959465027,0.4192149043083191,0.35140860080718994,0.34901323914527893,0.3493063747882843,0.3450222909450531,0.33856886625289917,0.33222195506095886,0.35128188133239746,0.37830764055252075,0.32041341066360474,0.3081430494785309,0.2716425657272339,0.25638359785079956,0.21443939208984375,0.15856622159481049,0.11565141379833221,0.11290934681892395,0.09233096987009048,0.10395997017621994,0.09428899735212326,0.09670181572437286,0.08232589066028595,0.072318434715271,0.0755705013871193,0.06713782995939255,0.07189693301916122,0.062063269317150116,0.06472289562225342,0.06027374416589737,0.05889282375574112,0.06090107932686806,0.05936899036169052,0.05310184508562088,0.05706159025430679,0.052364055067300797,0.045186661183834076,0.049426738172769547,0.040785178542137146,0.048506785184144974,0.048360683023929596,0.0461697019636631,0.04195967689156532,0.04401038587093353,0.0390176959335804,0.04091294854879379,0.03588935360312462,0.03779985010623932,0.036217860877513885,0.04758045822381973,0.03829909861087799,0.03666695952415466,0.04201521724462509,0.039553217589855194,0.033991750329732895,0.0358855202794075,0.031223755329847336,0.03942950814962387,0.03609959036111832,0.041667863726615906,0.037615805864334106,0.03755625709891319,0.03394513577222824,0.03530852496623993,0.04007387533783913,0.03584626317024231,0.03210322558879852,0.033705294132232666,0.03367644175887108,0.030400769785046577,0.031667161732912064,0.034023821353912354,0.034044306725263596,0.032929692417383194,0.030949482694268227,0.03150513023138046,0.03261593356728554,0.03467142954468727,0.03657359629869461,0.029236676171422005,0.029697811231017113,0.03112265281379223,0.03337137773633003,0.02989867515861988,0.028590645641088486,0.03095710091292858,0.029977697879076004,0.029522418975830078,0.029391858726739883,0.033996157348155975,0.027951164171099663,0.027796702459454536,0.02888963744044304,0.03262219950556755,0.027619659900665283,0.028304539620876312,
mse,0.7515495419502258,0.05353036895394325,0.03989650309085846,0.03891564533114433,0.03942718356847763,0.05268622934818268,0.03694258630275726,0.036545637995004654,0.03650766238570213,0.035645999014377594,0.034322768449783325,0.032924339175224304,0.03689553588628769,0.04245487228035927,0.03099515475332737,0.02820425294339657,0.022735467180609703,0.020077800378203392,0.013974039815366268,0.007335924077779055,0.003968904726207256,0.0036824506241828203,0.0025693827774375677,0.0034837464336305857,0.0026843445375561714,0.002737282309681177,0.0019449475221335888,0.0015854975208640099,0.0017197738634422421,0.001358643639832735,0.0015774687053635716,0.0011366461403667927,0.0012152900453656912,0.0010450624395161867,0.0010807563085108995,0.0010781431337818503,0.0010357804130762815,0.0008362890221178532,0.0009423182928003371,0.0007974929176270962,0.0005848156870342791,0.0007069155690260231,0.0004899008781649172,0.0006895977421663702,0.0006809139158576727,0.0006278551882132888,0.0005167089984752238,0.0005634499830193818,0.0004465863457880914,0.0004931546864099801,0.00037570856511592865,0.0004193795030005276,0.00040088556124828756,0.0006444779573939741,0.00042656666482798755,0.00038845569361001253,0.0005158651620149612,0.000448180508101359,0.00033611696562729776,0.0003809434419963509,0.0002907772141043097,0.00044607033487409353,0.0003775681252591312,0.000496133288834244,0.00040812938823364675,0.00039490233757533133,0.0003360016562510282,0.0003673865576274693,0.0004558995715342462,0.0003742475819308311,0.00029806431848555803,0.00033125095069408417,0.00032766506774351,0.0002676119329407811,0.0002884086570702493,0.0003392813086975366,0.00033717535552568734,0.0003199388738721609,0.00028606667183339596,0.00028215936617925763,0.00030865860753692687,0.00033804558916017413,0.000373618007870391,0.00025026529328897595,0.0002614432305563241,0.00028689642203971744,0.0003202325024176389,0.00025672270567156374,0.0002412135509075597,0.00028488633688539267,0.00026226567570120096,0.00025616324273869395,0.00024927579215727746,0.0003283680707681924,0.00023079258971847594,0.00022343394812196493,0.00024394140928052366,0.0003022420860361308,0.00022234479547478259,0.00023436680203303695,
mae,0.5706313252449036,0.18827800452709198,0.16156691312789917,0.1591065376996994,0.1597132533788681,0.17813235521316528,0.15387821197509766,0.15299491584300995,0.15274645388126373,0.15034309029579163,0.14656591415405273,0.14333783090114594,0.15173335373401642,0.1636434942483902,0.13902100920677185,0.13199354708194733,0.11588391661643982,0.10978861153125763,0.09064186364412308,0.06739556789398193,0.04929248243570328,0.04780643805861473,0.03971882164478302,0.04467485100030899,0.0407581552863121,0.04219284653663635,0.03526127338409424,0.03118951804935932,0.03285357728600502,0.028839658945798874,0.030629901215434074,0.02664060890674591,0.027707619592547417,0.02545841783285141,0.025688571855425835,0.026237281039357185,0.025518091395497322,0.02265946939587593,0.024341313168406487,0.022488020360469818,0.019103441387414932,0.02126160077750683,0.017334096133708954,0.021026380360126495,0.02086898870766163,0.02002428099513054,0.017959417775273323,0.01862255111336708,0.016666917130351067,0.017357125878334045,0.015338138677179813,0.016040576621890068,0.015579117462038994,0.020702684298157692,0.01649579219520092,0.015594960190355778,0.01796644926071167,0.01679934188723564,0.014572186395525932,0.015254692174494267,0.013345688581466675,0.01684420555830002,0.015417229384183884,0.0179571695625782,0.016002511605620384,0.016235973685979843,0.01445738598704338,0.015028947964310646,0.01718844473361969,0.01537688821554184,0.013654018752276897,0.01437232457101345,0.014256839640438557,0.013077234849333763,0.013486628420650959,0.014613393694162369,0.014678987674415112,0.01413804292678833,0.013363254256546497,0.013448110781610012,0.014053037390112877,0.014797056093811989,0.01577475480735302,0.01251281052827835,0.012800881639122963,0.013515392318367958,0.014018485322594643,0.012903116643428802,0.012257485650479794,0.013162718154489994,0.012778213247656822,0.012682966887950897,0.012418899685144424,0.014607436954975128,0.011798640713095665,0.011702165938913822,0.012438497506082058,0.01403511967509985,0.011854341253638268,0.011922169476747513,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 532075    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 532076    
=================================================================
Total params: 1,064,151
Trainable params: 1,064,151
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 532,075
Trainable params: 532,075
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 532,076
Trainable params: 532,076
Non-trainable params: 0
_________________________________________________________________
