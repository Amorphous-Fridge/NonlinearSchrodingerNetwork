2021-06-26
loss,1.2753970623016357,0.36714571714401245,0.2886771559715271,0.2539946734905243,0.23699237406253815,0.21459472179412842,0.20603209733963013,0.1958872675895691,0.1803078055381775,0.17606818675994873,0.14966626465320587,0.12575286626815796,0.11801344901323318,0.12447097152471542,0.100086510181427,0.08806770294904709,0.07814719527959824,0.055904094129800797,0.05834165960550308,0.0625339150428772,0.05343283712863922,0.050431326031684875,0.049976177513599396,0.05740685760974884,0.044938020408153534,0.03933311253786087,0.03250286355614662,0.04353800788521767,0.05016999691724777,0.04083818942308426,0.03788477182388306,0.04270322620868683,0.042437583208084106,0.04336490109562874,0.03803898021578789,0.03401720151305199,0.040022868663072586,0.03836297243833542,0.036213468760252,0.03917951509356499,0.03173370286822319,0.027778083458542824,0.02933146245777607,0.03359334543347359,0.03883286565542221,0.030861325562000275,0.026740338653326035,0.02878468483686447,0.029679222032427788,0.026889724656939507,0.03419901058077812,0.03268170356750488,0.03288145363330841,0.026413926854729652,0.02668304182589054,0.03396167978644371,0.028143003582954407,0.028064358979463577,0.03363330662250519,0.02852904237806797,0.031605567783117294,0.025295622646808624,0.022754618898034096,0.024751737713813782,0.0334106981754303,0.02912931703031063,0.029019474983215332,0.026541614904999733,0.026870235800743103,0.02790137752890587,0.02419705130159855,0.023188292980194092,0.026483163237571716,0.024833068251609802,0.026573020964860916,0.027498483657836914,0.02265326678752899,0.025562411174178123,0.028562545776367188,0.028860123828053474,0.025550350546836853,0.024636080488562584,0.026702508330345154,0.026305045932531357,0.025125442072749138,0.02802371047437191,0.025740385055541992,0.024575145915150642,0.024626078084111214,0.02562722936272621,0.024481065571308136,0.022809647023677826,0.024824485182762146,0.023100905120372772,0.02651902846992016,0.0265252273529768,0.024932770058512688,0.019965307787060738,0.020190395414829254,0.022314591333270073,
mse,0.6557388305664062,0.038947027176618576,0.025106586515903473,0.02052375115454197,0.018275661394000053,0.015446502715349197,0.014166227541863918,0.012788849882781506,0.010552594438195229,0.009359415620565414,0.006773671135306358,0.004980878438800573,0.004201124422252178,0.0047606066800653934,0.002770467195659876,0.002156023634597659,0.0017386756371706724,0.0009548142552375793,0.000988823943771422,0.0011291912524029613,0.0008145709289237857,0.000751297629904002,0.0007099075592122972,0.0009496705024503171,0.0005650980747304857,0.0004363215994089842,0.00030081969453021884,0.0005502752028405666,0.0007031488348729908,0.0004846910887863487,0.0004185367142781615,0.0005186715861782432,0.0005124025628902018,0.0005172856035642326,0.0004065191315021366,0.0003210980794392526,0.0004537778440862894,0.00040310079930350184,0.0003651503939181566,0.0004183590644970536,0.000274995865765959,0.00021906870824750513,0.00024265052343253046,0.0003206422843504697,0.00042126962216570973,0.00026560784317553043,0.00020274754206184298,0.00023291289107874036,0.00024135198327712715,0.00020144906011410058,0.0003429973148740828,0.0002940106496680528,0.0003008843632414937,0.00019764872558880597,0.00020461229723878205,0.0003194448654539883,0.00022352358791977167,0.00022549084678757936,0.00032452790765091777,0.0002343084051972255,0.0002750491548795253,0.00017509709869045764,0.00015108119987417012,0.00017531809862703085,0.0003182777145411819,0.00023235342814587057,0.00023424983373843133,0.00019791261001955718,0.00020695323473773897,0.00022020857431925833,0.00016813883848953992,0.00015889696078374982,0.0001935238396981731,0.00017477816436439753,0.0002115107636200264,0.00021620035113301128,0.0001444752124371007,0.0001890454877866432,0.00022674258798360825,0.00023211556253954768,0.0001853424619184807,0.00017370660498272628,0.00019900259212590754,0.00019042161875404418,0.00017501039837952703,0.0002162968012271449,0.00018475690740160644,0.00017166110046673566,0.00017080454563256353,0.00018105411436408758,0.0001660482957959175,0.0001512778690084815,0.0001752259413478896,0.00015171471750363708,0.00019622869149316102,0.00019221710681449622,0.00016966726980172098,0.00011792918667197227,0.00012226855324115604,0.00014150964852888137,
mae,0.5309964418411255,0.15835784375667572,0.1222059354186058,0.10815484076738358,0.10230744630098343,0.0931471660733223,0.08950792253017426,0.08483516424894333,0.07805047184228897,0.07585271447896957,0.06422329694032669,0.053488560020923615,0.05081279203295708,0.053293563425540924,0.043808020651340485,0.03712361678481102,0.03324992209672928,0.024014033377170563,0.024754764512181282,0.026596495881676674,0.02292661927640438,0.021252665668725967,0.02159888483583927,0.025174854323267937,0.018966350704431534,0.01700562983751297,0.013895988464355469,0.018545951694250107,0.02194199152290821,0.017428701743483543,0.016190700232982635,0.018025558441877365,0.01803644932806492,0.01868022233247757,0.01684313453733921,0.0146523118019104,0.016677694395184517,0.016588903963565826,0.015632091090083122,0.01651831716299057,0.013530420139431953,0.01165832206606865,0.012493008747696877,0.014460078440606594,0.01669764146208763,0.013190049678087234,0.011341014876961708,0.012372883968055248,0.012578013353049755,0.011520368047058582,0.014570622704923153,0.013837677426636219,0.014336797408759594,0.011239412240684032,0.01140393503010273,0.014356065541505814,0.012006648816168308,0.01198746357113123,0.0146619388833642,0.012408334761857986,0.01356648188084364,0.01081202831119299,0.009671858511865139,0.010524407960474491,0.014367866329848766,0.012283092364668846,0.01253186073154211,0.011273008771240711,0.011411399580538273,0.012061398476362228,0.010309500619769096,0.009844613261520863,0.011372054927051067,0.010752367787063122,0.01128307729959488,0.011955001391470432,0.00966612622141838,0.010832357220351696,0.012152813374996185,0.012228532694280148,0.010809634812176228,0.01052528340369463,0.011372976005077362,0.01111055351793766,0.01067044585943222,0.012015298940241337,0.01087124552577734,0.010585172101855278,0.010476590134203434,0.010949849151074886,0.010530740953981876,0.009749560616910458,0.010709131136536598,0.009940016083419323,0.011244814842939377,0.01136274728924036,0.010774638503789902,0.008450118824839592,0.008554094471037388,0.009419027715921402,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 138195    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 138196    
=================================================================
Total params: 276,391
Trainable params: 276,391
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 138,195
Trainable params: 138,195
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 138,196
Trainable params: 138,196
Non-trainable params: 0
_________________________________________________________________
