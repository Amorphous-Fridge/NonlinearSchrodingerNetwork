2021-06-26
loss,0.6938729286193848,0.21604423224925995,0.19426345825195312,0.13061244785785675,0.11546285450458527,0.12530897557735443,0.12891046702861786,0.10247563570737839,0.09131938964128494,0.10850043594837189,0.09325245022773743,0.07141850143671036,0.07122765481472015,0.07388795167207718,0.07107003778219223,0.059149254113435745,0.05814870819449425,0.04874736815690994,0.06478777527809143,0.0661817118525505,0.053249090909957886,0.04844338446855545,0.04746103659272194,0.056255780160427094,0.04931323230266571,0.04226656258106232,0.045683640986680984,0.049492720514535904,0.03969306871294975,0.03745763376355171,0.037754762917757034,0.04801445081830025,0.04268032684922218,0.036062780767679214,0.03989860415458679,0.03868027776479721,0.038545574992895126,0.03994036838412285,0.032456137239933014,0.03265434876084328,0.03785513713955879,0.03466629609465599,0.03430433198809624,0.032010722905397415,0.03423452749848366,0.03214829042553902,0.03376391530036926,0.030470607802271843,0.02820785529911518,0.028899142518639565,0.02848321944475174,0.034718189388513565,0.027897968888282776,0.025481250137090683,0.030604101717472076,0.026771903038024902,0.03259412944316864,0.03134068846702576,0.029032893478870392,0.027548898011446,0.029731787741184235,0.028367390856146812,0.02781032584607601,0.02953960932791233,0.02405145950615406,0.02719181217253208,0.02659858763217926,0.02526959963142872,0.025121456012129784,0.022877532988786697,0.024484552443027496,0.024675803259015083,0.026812195777893066,0.023924484848976135,0.02541116066277027,0.024379152804613113,0.026667118072509766,0.024212565273046494,0.021988186985254288,0.025565316900610924,0.021920759230852127,0.02576160617172718,0.022531680762767792,0.019932499155402184,0.023172395303845406,0.02564740926027298,0.02223125472664833,0.023124760016798973,0.021879024803638458,0.021043673157691956,0.023094885051250458,0.022068314254283905,0.020727718248963356,0.021993154659867287,0.019329046830534935,0.022217219695448875,0.025620901957154274,0.023484045639634132,0.021085677668452263,0.02060502953827381,
mse,0.2395060509443283,0.014462408609688282,0.010852358303964138,0.004904496483504772,0.003718168940395117,0.004405975807458162,0.005160513333976269,0.0030822150874882936,0.0023886915296316147,0.003355305874720216,0.0024509630165994167,0.0014908446464687586,0.0014641557354480028,0.0015680709620937705,0.0014319145120680332,0.0009798501851037145,0.000994023634120822,0.0006669265567325056,0.0011857803910970688,0.0012106421636417508,0.000797905377112329,0.0006577931344509125,0.0006377158570103347,0.0009052730165421963,0.0006797875394113362,0.0005152291269041598,0.000574776902794838,0.0006728440057486296,0.0004427500534802675,0.00040443570469506085,0.00039787590503692627,0.0006414920790120959,0.0005023362464271486,0.0003629971179179847,0.0004524260002654046,0.0004209385078866035,0.00041712154052220285,0.00044375640572980046,0.00029823288787156343,0.0002971412905026227,0.00039465248119086027,0.0003341861010994762,0.00033126980997622013,0.0002880994288716465,0.0003279748489148915,0.0002841551322489977,0.00031915638828650117,0.00025384550099261105,0.00022604354307986796,0.00023518846137449145,0.00022629142040386796,0.00034357409458607435,0.00022006980725564063,0.0001841141056502238,0.0002583205932751298,0.00020006459089927375,0.00029410439310595393,0.00027431760099716485,0.00023096958466339856,0.00021364452550187707,0.0002487146412022412,0.00022643506235908717,0.00021553323313128203,0.00023666388005949557,0.0001685738388914615,0.0002123534504789859,0.0001968501164810732,0.00018216419266536832,0.00017737830057740211,0.00014996365644037724,0.0001704321475699544,0.00016846269136294723,0.00019697663083206862,0.00016186651191674173,0.00018058619752991945,0.00016429316019639373,0.00019746484758798033,0.00016228687309194356,0.00014081310655456036,0.00018553147674538195,0.0001346508361166343,0.00018380468827672303,0.00014335331798065454,0.00011344509402988479,0.00015392276691272855,0.00018330145394429564,0.00014059788372833282,0.00015038001583889127,0.00013381679309532046,0.00012571568368002772,0.0001477615296607837,0.00013713691441807896,0.00012277771020308137,0.00013583058898802847,0.00010917298641288653,0.0001395612198393792,0.00018048514903057367,0.00015212215657811612,0.0001256276882486418,0.00012265316036064178,
mae,0.30367711186408997,0.0920032188296318,0.08149167895317078,0.05525171384215355,0.0488053560256958,0.05175560340285301,0.05501525104045868,0.043139684945344925,0.03882388025522232,0.04679812863469124,0.03929532319307327,0.029603052884340286,0.030581491068005562,0.0315554179251194,0.030533812940120697,0.02474488504230976,0.025079801678657532,0.02094285562634468,0.027201728895306587,0.029002515599131584,0.022663068026304245,0.020348981022834778,0.02022969163954258,0.023898646235466003,0.02131182886660099,0.01804993487894535,0.019419679418206215,0.02103046327829361,0.0171060673892498,0.01590922474861145,0.016048870980739594,0.020557932555675507,0.018604502081871033,0.015466191805899143,0.017005477100610733,0.016390446573495865,0.01626312918961048,0.01721459999680519,0.013724722899496555,0.01403611060231924,0.016237644478678703,0.015034597367048264,0.014521878212690353,0.013481673784554005,0.014324283227324486,0.013808393850922585,0.01452698465436697,0.012756291776895523,0.012063494883477688,0.012289944104850292,0.012217584066092968,0.014665381982922554,0.011978748254477978,0.010762474499642849,0.012833612971007824,0.011529472656548023,0.013881348073482513,0.013442188501358032,0.012608237564563751,0.011761750094592571,0.012577589601278305,0.01191448699682951,0.011921074241399765,0.012387645430862904,0.010138050653040409,0.01155155524611473,0.011440099216997623,0.010698885656893253,0.010766923427581787,0.009658968076109886,0.010373212397098541,0.010630729608237743,0.011327285319566727,0.010328484699130058,0.010801252909004688,0.010289373807609081,0.011414307169616222,0.0104585075750947,0.009246265515685081,0.010996123775839806,0.009202167391777039,0.010882951319217682,0.00955861248075962,0.008390065282583237,0.009691059589385986,0.010788898915052414,0.009524684399366379,0.009749007411301136,0.009368491359055042,0.008934536948800087,0.009928829036653042,0.009255625307559967,0.00874386541545391,0.009502573870122433,0.008230616338551044,0.009396113455295563,0.011030595749616623,0.010107269510626793,0.009211192838847637,0.008712628856301308,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 102227    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 102228    
=================================================================
Total params: 204,455
Trainable params: 204,455
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 102,227
Trainable params: 102,227
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 102,228
Trainable params: 102,228
Non-trainable params: 0
_________________________________________________________________
