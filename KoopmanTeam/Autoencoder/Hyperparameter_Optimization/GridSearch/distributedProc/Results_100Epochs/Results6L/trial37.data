2021-06-26
loss,1.2211464643478394,0.3372500538825989,0.2760847210884094,0.25973790884017944,0.25486335158348083,0.2483568787574768,0.24665942788124084,0.24361591041088104,0.24117447435855865,0.24051950871944427,0.23821386694908142,0.23495769500732422,0.23217226564884186,0.23150211572647095,0.2269027680158615,0.2203444540500641,0.21664321422576904,0.20817379653453827,0.19913913309574127,0.19652500748634338,0.18886834383010864,0.16746366024017334,0.1550801694393158,0.16643086075782776,0.1553032100200653,0.18025125563144684,0.15525056421756744,0.15872105956077576,0.15910321474075317,0.13999556005001068,0.11455661058425903,0.12037000060081482,0.10657013952732086,0.1063198670744896,0.10961764305830002,0.09101922810077667,0.08343196660280228,0.07786380499601364,0.06423906981945038,0.06253410130739212,0.07120846956968307,0.08303254842758179,0.07024114578962326,0.06204349175095558,0.0723571702837944,0.076663076877594,0.06206360459327698,0.05618369206786156,0.05846032127737999,0.0662020668387413,0.06055772304534912,0.05078503116965294,0.05599214509129524,0.06051561236381531,0.05267499014735222,0.05588270723819733,0.05555994063615799,0.04091893136501312,0.04646112397313118,0.04443974420428276,0.04619790241122246,0.05338771641254425,0.04621158912777901,0.048113707453012466,0.042149242013692856,0.033847175538539886,0.0381622277200222,0.03914116322994232,0.0446084626019001,0.03624165430665016,0.03884555399417877,0.04145326092839241,0.04227282479405403,0.03288862109184265,0.041058748960494995,0.03869446739554405,0.034239448606967926,0.03916119039058685,0.0371687114238739,0.03986334428191185,0.037698790431022644,0.036847494542598724,0.03440588340163231,0.02791834995150566,0.03616493195295334,0.03321651369333267,0.028296945616602898,0.03653378784656525,0.032925084233284,0.0277894027531147,0.034459829330444336,0.036075666546821594,0.0276035163551569,0.024094104766845703,0.03540591895580292,0.03390832245349884,0.03038894571363926,0.03126310184597969,0.034605249762535095,0.030509019270539284,
mse,0.8140614032745361,0.03327476978302002,0.023605884984135628,0.02145254611968994,0.021004414185881615,0.020327305421233177,0.02019350603222847,0.019911807030439377,0.01964946836233139,0.019592786207795143,0.0193190760910511,0.018925877287983894,0.018625590950250626,0.018333518877625465,0.017760340124368668,0.016851989552378654,0.01615227200090885,0.014930197969079018,0.013756386935710907,0.013264378532767296,0.01233516726642847,0.010255932807922363,0.008820964954793453,0.009746325202286243,0.008395521901547909,0.01072396244853735,0.008055051788687706,0.008050747215747833,0.00788451824337244,0.006503491196781397,0.004486342892050743,0.004695977549999952,0.0036566643975675106,0.0035295006819069386,0.003928058315068483,0.00251385779120028,0.0021363478153944016,0.0019290430936962366,0.0012693193275481462,0.001214208547025919,0.0014911709586158395,0.002181514399126172,0.0014924837742000818,0.001211928203701973,0.0016320539871230721,0.0016822778852656484,0.001183834159746766,0.0009197830222547054,0.0010714891832321882,0.001280543627217412,0.0010462516220286489,0.0007719132117927074,0.000907431764062494,0.0010650164913386106,0.0008006755961105227,0.0008721295744180679,0.0008672538679093122,0.0004711551300715655,0.000621849438175559,0.000583140179514885,0.0005988662014715374,0.0008195500122383237,0.0006147457170300186,0.0006609371048398316,0.0005145370378158987,0.00036026485031470656,0.00041181151755154133,0.00044105909182690084,0.0005618827417492867,0.0003837508265860379,0.00044751260429620743,0.000496652617584914,0.0005046773585490882,0.00032010418362915516,0.00048120826249942183,0.0004145748680457473,0.0003287768631707877,0.00044936928316019475,0.0003976596053689718,0.0004421141347847879,0.00041135086212307215,0.00038268195930868387,0.000328721507685259,0.0002180831943405792,0.00037793457158841193,0.0003200181236024946,0.00023365262313745916,0.00037748500471934676,0.0002962207654491067,0.00021564516646321863,0.0003529211098793894,0.00036568165523931384,0.00021717665367759764,0.00017124024452641606,0.0003726232098415494,0.0003274909686297178,0.00026779805193655193,0.0002772131119854748,0.00033765711123123765,0.0002573740785010159,
mae,0.5307247638702393,0.14428192377090454,0.11690071225166321,0.11003977060317993,0.10772409290075302,0.10489222407341003,0.10461670905351639,0.10394425690174103,0.10290208458900452,0.10414572805166245,0.10349998623132706,0.10239481925964355,0.10176410526037216,0.1010386049747467,0.09867102652788162,0.09472905099391937,0.09250066429376602,0.08953194320201874,0.08640194684267044,0.0852394700050354,0.081509530544281,0.07229878753423691,0.06705541908740997,0.07171356678009033,0.0667097344994545,0.07732827961444855,0.06623667478561401,0.06851549446582794,0.06743261963129044,0.059730175882577896,0.048726607114076614,0.05149343982338905,0.046026360243558884,0.045376285910606384,0.04714272543787956,0.038641441613435745,0.03599051758646965,0.033603765070438385,0.02767585590481758,0.026341939345002174,0.030791066586971283,0.036013148725032806,0.03050392121076584,0.026584794744849205,0.03082123212516308,0.03288540989160538,0.02643006108701229,0.024254901334643364,0.02428259886801243,0.028039388358592987,0.026095731183886528,0.02200162410736084,0.023797646164894104,0.025354741141200066,0.02211376279592514,0.0234269667416811,0.0241306871175766,0.017339635640382767,0.019849838688969612,0.018900742754340172,0.01968991570174694,0.02258860133588314,0.020075712352991104,0.02001686580479145,0.0176229290664196,0.014233287423849106,0.01654895953834057,0.0166014414280653,0.019247284159064293,0.015681184828281403,0.016232436522841454,0.01750141754746437,0.018339473754167557,0.013962115161120892,0.016944361850619316,0.016750376671552658,0.014857083559036255,0.016327762976288795,0.01513801421970129,0.01652737706899643,0.016379322856664658,0.015714967623353004,0.014841202646493912,0.011905020102858543,0.015627987682819366,0.01402509305626154,0.012097056023776531,0.015052014961838722,0.014169232919812202,0.011897329241037369,0.014351786114275455,0.015283389016985893,0.012053769081830978,0.01015413273125887,0.014878452755510807,0.014507943764328957,0.013062560930848122,0.013293714262545109,0.01462889090180397,0.013134943321347237,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 100587    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 100588    
=================================================================
Total params: 201,175
Trainable params: 201,175
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 100,587
Trainable params: 100,587
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 100,588
Trainable params: 100,588
Non-trainable params: 0
_________________________________________________________________
