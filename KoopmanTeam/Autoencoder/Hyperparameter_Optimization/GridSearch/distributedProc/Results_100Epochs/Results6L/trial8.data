2021-06-26
loss,0.44807106256484985,0.23359109461307526,0.2120012640953064,0.16157948970794678,0.11548631638288498,0.08195611834526062,0.07423051446676254,0.06719177216291428,0.07733175158500671,0.07842545211315155,0.0865277349948883,0.0705338791012764,0.07142388075590134,0.05711342394351959,0.04847719520330429,0.041507620364427567,0.038033679127693176,0.035860322415828705,0.03537300229072571,0.05261487513780594,0.05208681896328926,0.05723786726593971,0.05558271333575249,0.04575703665614128,0.04104750603437424,0.038227375596761703,0.03598291054368019,0.031638216227293015,0.029198579490184784,0.030137186869978905,0.032539475709199905,0.0384310744702816,0.047620706260204315,0.048123110085725784,0.04078597202897072,0.03732491657137871,0.03485196456313133,0.029755761846899986,0.03225823864340782,0.030611231923103333,0.03453213721513748,0.0429677814245224,0.04526593163609505,0.030851559713482857,0.02237480692565441,0.022190680727362633,0.021976768970489502,0.02159246616065502,0.02151680923998356,0.021622473374009132,0.021840186789631844,0.021579887717962265,0.021371472626924515,0.021390177309513092,0.021215952932834625,0.02103242836892605,0.020890668034553528,0.020865533500909805,0.0206906795501709,0.020566429942846298,0.020633691921830177,0.020368196070194244,0.020410427823662758,0.02028583362698555,0.020212139934301376,0.020225757732987404,0.020120615139603615,0.01992771215736866,0.020025338977575302,0.019921479746699333,0.019779812544584274,0.01971292309463024,0.020802369341254234,0.022156918421387672,0.02413702942430973,0.033811576664447784,0.030286766588687897,0.028153998777270317,0.02287185937166214,0.0280752032995224,0.03063400834798813,0.036052118986845016,0.032664116472005844,0.029382813721895218,0.02700110897421837,0.02531520277261734,0.019823547452688217,0.019203193485736847,0.018589090555906296,0.018838999792933464,0.01811688020825386,0.018171772360801697,0.017766984179615974,0.017732225358486176,0.01769006997346878,0.01744268275797367,0.017454564571380615,0.017271388322114944,0.01723485440015793,0.01718020625412464,
mse,0.08745907992124557,0.018185671418905258,0.014840337447822094,0.008308260701596737,0.004136822652071714,0.0020458493381738663,0.0016630284953862429,0.0013837753795087337,0.0018437447724863887,0.0018259487114846706,0.0021783385891467333,0.0014772738795727491,0.0014767402317374945,0.0009455891558900476,0.000686522398609668,0.0005015799542888999,0.00041881666402332485,0.00036975197144784033,0.00036716219619847834,0.0008233956759795547,0.0007953255553729832,0.0009325607679784298,0.0008675464196130633,0.0005841152742505074,0.0004799024318344891,0.0004226599121466279,0.00037368395715020597,0.00029173208167776465,0.0002513157669454813,0.000266592571279034,0.0003109335957560688,0.0004563274560496211,0.0006547262310050428,0.0006407268228940666,0.00046163194929249585,0.0003923954500351101,0.0003494665725156665,0.00026497640646994114,0.00030404995777644217,0.00027340478845871985,0.0003430332290008664,0.0005250495742075145,0.0005882967379875481,0.00029888059361837804,0.00014375448517967016,0.00014032005856279284,0.00013675549416802824,0.00013236071390565485,0.00013222616689745337,0.00013641650730278343,0.0001354983396595344,0.0001312492386205122,0.000129925218061544,0.00012929133663419634,0.00012706634879577905,0.00012324933777563274,0.00012294831685721874,0.00012252971646375954,0.00011934692884096876,0.00011859522783197463,0.000118166150059551,0.00011665240890579298,0.00011603075836319476,0.00011463357077445835,0.0001165507928817533,0.00011652112152660266,0.00011357256153132766,0.00011611264199018478,0.00011406712292227894,0.00010968958667945117,0.00010955688776448369,0.0001111087403842248,0.00012887197954114527,0.00014880661910865456,0.00017780579219106585,0.00032209549681283534,0.00026155984960496426,0.00023725231585558504,0.0001584728597663343,0.00023491733008995652,0.00026947061996906996,0.0003742569242604077,0.00028966067475266755,0.0002383714308962226,0.00020289838721510023,0.00018741075473371893,0.00011663237819448113,0.00010449517867527902,0.00010438123717904091,0.00010215245129074901,9.464569302508608e-05,9.279382356908172e-05,8.958431862993166e-05,8.995991811389104e-05,8.775815513217822e-05,8.51877557579428e-05,8.523580618202686e-05,8.284677460324019e-05,8.285153307951987e-05,8.346891991095617e-05,
mae,0.19138650596141815,0.10446268320083618,0.09479022771120071,0.0694427639245987,0.04876057058572769,0.0352223701775074,0.03177224099636078,0.02813977748155594,0.03326473385095596,0.03298741206526756,0.03707778826355934,0.03007337637245655,0.03100314922630787,0.025123579427599907,0.02077392302453518,0.017357798293232918,0.015961116179823875,0.01526127103716135,0.015025355853140354,0.02233380638062954,0.022746969014406204,0.024310128763318062,0.023570409044623375,0.020322715863585472,0.01799709163606167,0.01642196625471115,0.015616102144122124,0.013451614417135715,0.012259512208402157,0.012641895562410355,0.013703489676117897,0.01637396030128002,0.019936930388212204,0.020708682015538216,0.01771443523466587,0.016363488510251045,0.015148493461310863,0.012554737739264965,0.013566182926297188,0.01306888833642006,0.014869919046759605,0.018275879323482513,0.018355583772063255,0.012776058167219162,0.009338592179119587,0.009284359402954578,0.00920729711651802,0.009216041304171085,0.009098583832383156,0.009054199792444706,0.009231346659362316,0.009211430326104164,0.009054737165570259,0.009082501754164696,0.008936038240790367,0.008988780900835991,0.008741328492760658,0.00888175331056118,0.008738655596971512,0.008868282660841942,0.008698626421391964,0.008690905757248402,0.008593253791332245,0.008582837879657745,0.00858562346547842,0.00864387396723032,0.008487444370985031,0.00839513074606657,0.008573450148105621,0.008450702764093876,0.008375348523259163,0.00844473298639059,0.008761928416788578,0.009533355012536049,0.010173571296036243,0.014182460494339466,0.012833721935749054,0.012018713168799877,0.009804598987102509,0.012088252231478691,0.01315036416053772,0.015247310511767864,0.014077420346438885,0.012913614511489868,0.011731645092368126,0.010805734433233738,0.00837112870067358,0.007933046668767929,0.007760584354400635,0.007942434400320053,0.007627815008163452,0.0075234305113554,0.007424124516546726,0.007473488338291645,0.007448120042681694,0.007257702294737101,0.007386584300547838,0.00730995275080204,0.0073215896263718605,0.0073510087095201015,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 21099     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 21100     
=================================================================
Total params: 42,199
Trainable params: 42,199
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 21,099
Trainable params: 21,099
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 21,100
Trainable params: 21,100
Non-trainable params: 0
_________________________________________________________________
