2021-06-26
loss,3.079718589782715,0.5979286432266235,0.3565158545970917,0.35014110803604126,0.35026559233665466,0.3536447286605835,0.3526586890220642,0.3497074544429779,0.32814180850982666,0.26160526275634766,0.24161672592163086,0.23919226229190826,0.2318793088197708,0.22857394814491272,0.22469455003738403,0.2211327701807022,0.22603395581245422,0.21831049025058746,0.214706689119339,0.2052489072084427,0.20576615631580353,0.1854609102010727,0.17604921758174896,0.1650649458169937,0.1504313349723816,0.11542794108390808,0.08862852305173874,0.09517862647771835,0.07810724526643753,0.07152943313121796,0.07089903950691223,0.06195676326751709,0.06305160373449326,0.0611262321472168,0.0543057955801487,0.05160657316446304,0.053010039031505585,0.04578377678990364,0.04698115959763527,0.05862143635749817,0.045840807259082794,0.04815332591533661,0.04933316260576248,0.044998642057180405,0.03859063237905502,0.03463583067059517,0.047288618981838226,0.036256447434425354,0.03793267905712128,0.04000915586948395,0.036511704325675964,0.03064100816845894,0.03000439889729023,0.03994151949882507,0.03691207244992256,0.036891184747219086,0.029812006279826164,0.02229384332895279,0.029386840760707855,0.03212514519691467,0.029016893357038498,0.026716290041804314,0.030649928376078606,0.03727509826421738,0.031757667660713196,0.030720466747879982,0.02716175466775894,0.024769162759184837,0.030741160735487938,0.029363157227635384,0.022054901346564293,0.024130694568157196,0.026579415425658226,0.025400487706065178,0.027488090097904205,0.031130507588386536,0.02835785783827305,0.025031793862581253,0.03179173544049263,0.029682084918022156,0.02788480743765831,0.02864358201622963,0.027170706540346146,0.02519312873482704,0.024825608357787132,0.02103707753121853,0.02469177544116974,0.02956519089639187,0.026008818298578262,0.01904820278286934,0.02533852308988571,0.02807886153459549,0.024310700595378876,0.028777269646525383,0.024337127804756165,0.022197924554347992,0.027747368440032005,0.02412410080432892,0.021085092797875404,0.01963203400373459,
mse,2.456070899963379,0.1181676834821701,0.03797066956758499,0.03694577515125275,0.03694182634353638,0.03742564842104912,0.0371614471077919,0.036616966128349304,0.03171456232666969,0.021761197596788406,0.019683415070176125,0.01944594830274582,0.018697110936045647,0.01845240779221058,0.01804124191403389,0.01762254536151886,0.017749357968568802,0.01666201837360859,0.015894003212451935,0.01454331073909998,0.013960534706711769,0.01157668512314558,0.010316180065274239,0.008819689974188805,0.007178323809057474,0.004085912834852934,0.0023801838979125023,0.002800793619826436,0.0018449953058734536,0.0015493760583922267,0.0014831925509497523,0.001162913627922535,0.0012005039025098085,0.0010629312600940466,0.0008697176235727966,0.0007892519352026284,0.0008078627288341522,0.0005996860563755035,0.0006265558185987175,0.0009932502871379256,0.0005992723163217306,0.0006632826989516616,0.0006977594457566738,0.0006039916188456118,0.0004229504556860775,0.00034406845225021243,0.0006401874125003815,0.0003799426194746047,0.0004150514432694763,0.0004554511106107384,0.0003741411492228508,0.00027179953758604825,0.000264837610302493,0.00044481546501629055,0.0003837698604911566,0.00039025332080200315,0.00025641819229349494,0.00015565157809760422,0.00025116800679825246,0.0002986157778650522,0.0002411182940704748,0.00020586677419487387,0.00027828713064081967,0.00038360312464646995,0.00029205239843577147,0.00026503580738790333,0.0002147745544789359,0.00018161720072384924,0.0002852213801816106,0.00026263153995387256,0.00014385177928488702,0.00017183195450343192,0.00020260756718926132,0.0001838163152569905,0.0002163640601793304,0.00027216237504035234,0.00022528205590788275,0.00018821070261765271,0.0002908662427216768,0.0002565538452472538,0.00021847816242370754,0.00023923242406453937,0.00020855687034782022,0.00018663211085367948,0.0001771790412021801,0.00013418789603747427,0.00017518448294140399,0.00024728599237278104,0.00019201678514946252,0.00011006431304849684,0.0001839095784816891,0.0002214100823039189,0.00017522426787763834,0.00023344764485955238,0.00016834348207339644,0.00014188388013280928,0.00022078037727624178,0.00016712436627130955,0.00013430611579678953,0.00011435910710133612,
mae,1.4123938083648682,0.25167134404182434,0.1539853811264038,0.15236689150333405,0.15267413854599,0.15422989428043365,0.1543450653553009,0.1533939689397812,0.1402834951877594,0.10746612399816513,0.10315187275409698,0.10435404628515244,0.09983586519956589,0.0993206575512886,0.09712960571050644,0.09549060463905334,0.09801288694143295,0.09373771399259567,0.09224292635917664,0.08806845545768738,0.0880294218659401,0.07940245419740677,0.07561709731817245,0.07116135954856873,0.06349679082632065,0.048686280846595764,0.037393759936094284,0.041791897267103195,0.033135708421468735,0.030758094042539597,0.0298765879124403,0.026618964970111847,0.02672552317380905,0.02585526742041111,0.023401305079460144,0.021696800366044044,0.022228272631764412,0.01929684914648533,0.020101433619856834,0.024999994784593582,0.01974708028137684,0.020678075030446053,0.021134555339813232,0.018878990784287453,0.01688840612769127,0.015054469928145409,0.02046184241771698,0.015564773231744766,0.016406865790486336,0.016950806602835655,0.015833908692002296,0.01286774780601263,0.012610014528036118,0.017095008864998817,0.015552295371890068,0.015583782456815243,0.012641064822673798,0.009476330131292343,0.012501453049480915,0.013833258301019669,0.012581598944962025,0.010946019552648067,0.012937418185174465,0.0161244198679924,0.013450712896883488,0.01325933076441288,0.01181335560977459,0.010407962836325169,0.013058248907327652,0.012417728081345558,0.009343098849058151,0.010193658992648125,0.011369028128683567,0.010871266014873981,0.011717659421265125,0.013240099884569645,0.01184023730456829,0.010635766200721264,0.013532957062125206,0.01286659762263298,0.011977137066423893,0.012077110819518566,0.01171032153069973,0.010819876566529274,0.010431081987917423,0.00899402517825365,0.010603450238704681,0.012614049017429352,0.011173832230269909,0.008120313286781311,0.010831352323293686,0.012027795426547527,0.01035286858677864,0.012567298486828804,0.010726358741521835,0.009267288260161877,0.01207193173468113,0.010476911440491676,0.008884484879672527,0.00828526820987463,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 296875    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 296876    
=================================================================
Total params: 593,751
Trainable params: 593,751
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 296,875
Trainable params: 296,875
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 296,876
Trainable params: 296,876
Non-trainable params: 0
_________________________________________________________________
