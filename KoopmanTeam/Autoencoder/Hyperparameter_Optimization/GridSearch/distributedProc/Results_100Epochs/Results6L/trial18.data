2021-06-26
loss,0.6238851547241211,0.2313278317451477,0.16209463775157928,0.16103653609752655,0.1292160451412201,0.125833660364151,0.10695327073335648,0.09484916925430298,0.08783230185508728,0.07535774260759354,0.07438728213310242,0.0714612826704979,0.07495158910751343,0.07794354110956192,0.08360221236944199,0.07098566740751266,0.058301735669374466,0.05322529375553131,0.06077338382601738,0.055020831525325775,0.04316285252571106,0.04731744900345802,0.03991811349987984,0.04528011754155159,0.048846758902072906,0.045611463487148285,0.03776780515909195,0.0417947880923748,0.042102228850126266,0.04306920990347862,0.05274660885334015,0.03642544150352478,0.04771171882748604,0.038941845297813416,0.04456005245447159,0.036934804171323776,0.03310590237379074,0.03978942334651947,0.04108968377113342,0.035896822810173035,0.02924087829887867,0.026148930191993713,0.02672553062438965,0.033569563180208206,0.04091310873627663,0.03671660274267197,0.037226952612400055,0.03097711130976677,0.027542728930711746,0.026296187192201614,0.02506203018128872,0.021767962723970413,0.03258765488862991,0.03538079187273979,0.035624269396066666,0.032417181879282,0.02868766523897648,0.03196307271718979,0.03063366562128067,0.02973272278904915,0.029902003705501556,0.03172744810581207,0.02938869409263134,0.022276122123003006,0.020930100232362747,0.018825439736247063,0.018392978236079216,0.018691634759306908,0.029375825077295303,0.02912268601357937,0.025187665596604347,0.025376927107572556,0.02507646754384041,0.029303625226020813,0.026288826018571854,0.023892629891633987,0.020190879702568054,0.029560409486293793,0.027827151119709015,0.02681385912001133,0.027915291488170624,0.027243461459875107,0.024541249498724937,0.022078175097703934,0.020660970360040665,0.018930584192276,0.027836211025714874,0.027405835688114166,0.026001954451203346,0.021530941128730774,0.020151281729340553,0.01735481061041355,0.01633591018617153,0.016223879531025887,0.023145928978919983,0.027412109076976776,0.025375433266162872,0.023645248264074326,0.023327909409999847,0.0250453632324934,
mse,0.2012428641319275,0.017700040712952614,0.007724105846136808,0.007670950144529343,0.004705394618213177,0.004735788330435753,0.0032337713055312634,0.002589508658275008,0.002272284822538495,0.0016767855267971754,0.0016337453853338957,0.0014678818406537175,0.0015828752657398582,0.0017923606792464852,0.0019741246942430735,0.0014534186339005828,0.0009629785199649632,0.0008083680877462029,0.0010446389205753803,0.0008669045637361705,0.0005268478998914361,0.0006604856462217867,0.00046401965664699674,0.0005861919489689171,0.0006789511535316706,0.0005882522673346102,0.0004117548814974725,0.0005075711524114013,0.0004968096036463976,0.0005173785611987114,0.000791949569247663,0.0004068467824254185,0.0006515526911243796,0.0004315538390073925,0.0005735392333008349,0.00038268594653345644,0.000311999669065699,0.0004576634964905679,0.00047710907529108226,0.00036170906969346106,0.00024479872081428766,0.0001970105222426355,0.00021845453011337668,0.0003336195950396359,0.0004692722577601671,0.0003774290671572089,0.0003831415669992566,0.0002815555199049413,0.0002164496690966189,0.0001992923062061891,0.0001864725345512852,0.00013896470773033798,0.0003116962325293571,0.00036115088732913136,0.00035680842120200396,0.0002895410289056599,0.00022991727746557444,0.0002936111995950341,0.00025869571254588664,0.0002606699417810887,0.0002651704417075962,0.0002819402143359184,0.0002465202705934644,0.00014504299906548113,0.00012813316425308585,0.00010339257278246805,9.404598677065223e-05,0.00010031608690042049,0.00024104921612888575,0.000235677624004893,0.0001813621784094721,0.00018723064567893744,0.00017931127513293177,0.0002379618090344593,0.00019582355162128806,0.00016273422806989402,0.00011775517486967146,0.00025158218340948224,0.0002133354137185961,0.00021149212261661887,0.0002174220426240936,0.00020727630180772394,0.00016803748439997435,0.00013959377247374505,0.00012237188639119267,0.00010468918480910361,0.00022389272635336965,0.000211717386264354,0.00018726391135714948,0.00013319955905899405,0.00011855862248921767,8.786365651758388e-05,7.808467489667237e-05,7.881778583396226e-05,0.0001522638922324404,0.00021171188564039767,0.0001801366888685152,0.00016436839359812438,0.00015468851779587567,0.00017435563495382667,
mae,0.26707977056503296,0.10360820591449738,0.07053887099027634,0.06743305176496506,0.053143568336963654,0.0541580393910408,0.04472634941339493,0.04052925482392311,0.0376753956079483,0.03208428621292114,0.032095909118652344,0.030089061707258224,0.03195052966475487,0.03347346931695938,0.03616473078727722,0.031177716329693794,0.024792606011033058,0.02285817824304104,0.026215553283691406,0.023437349125742912,0.018358612433075905,0.020024454221129417,0.017175840213894844,0.019402094185352325,0.02111605368554592,0.019457943737506866,0.015951842069625854,0.017726846039295197,0.017813844606280327,0.01840735413134098,0.02284063771367073,0.015663832426071167,0.020659413188695908,0.016855008900165558,0.0185328908264637,0.015452983789145947,0.014039707370102406,0.017170386388897896,0.017916852608323097,0.015370219945907593,0.01246373075991869,0.011067057028412819,0.011555596254765987,0.01445260364562273,0.017832530662417412,0.015768999233841896,0.0161599013954401,0.013163400813937187,0.011681240983307362,0.011165712960064411,0.010678338818252087,0.009254754520952702,0.013995949178934097,0.015271230600774288,0.015462619252502918,0.01386576984077692,0.012095329351723194,0.013616071082651615,0.013044575229287148,0.012625242583453655,0.01286504976451397,0.013524043373763561,0.012609404511749744,0.009445232339203358,0.008892964571714401,0.008041119202971458,0.007932293228805065,0.007993984967470169,0.012774313800036907,0.012386847287416458,0.010381528176367283,0.010742610320448875,0.01067530270665884,0.012723305262625217,0.011157423257827759,0.010145992040634155,0.008578547276556492,0.012857930734753609,0.011971300467848778,0.011379523202776909,0.011965334415435791,0.01148578617721796,0.010048526339232922,0.00914742797613144,0.008685996755957603,0.00804201140999794,0.01172194629907608,0.011794226244091988,0.011172162368893623,0.009233623743057251,0.008464441634714603,0.007474094163626432,0.0069807893596589565,0.0070024277083575726,0.009758537635207176,0.01195790059864521,0.010970085859298706,0.010169574990868568,0.00981250498443842,0.010872622951865196,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34251     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34252     
=================================================================
Total params: 68,503
Trainable params: 68,503
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 34,251
Trainable params: 34,251
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 34,252
Trainable params: 34,252
Non-trainable params: 0
_________________________________________________________________
