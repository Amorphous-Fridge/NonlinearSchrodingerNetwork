2021-06-26
loss,1.8516860008239746,0.39440804719924927,0.3003789186477661,0.24737241864204407,0.2354809045791626,0.22484515607357025,0.2120259404182434,0.20618988573551178,0.19335080683231354,0.1815118044614792,0.17119364440441132,0.16147471964359283,0.152691051363945,0.13417449593544006,0.11704418808221817,0.10115593671798706,0.12211605161428452,0.1022610068321228,0.07655305415391922,0.07093928009271622,0.07472789287567139,0.07881574332714081,0.07187817245721817,0.07006558030843735,0.0808371752500534,0.06543443351984024,0.06299722194671631,0.05720388516783714,0.048084281384944916,0.05249178409576416,0.044478967785835266,0.05078066885471344,0.044635042548179626,0.048595771193504333,0.04176609218120575,0.05415062606334686,0.0530405230820179,0.049590565264225006,0.043392159044742584,0.045115116983652115,0.03796025738120079,0.038009144365787506,0.045807767659425735,0.04146395996212959,0.03997946158051491,0.03952180966734886,0.03768301382660866,0.037481725215911865,0.04353071376681328,0.039786309003829956,0.037302177399396896,0.02795831859111786,0.028757547959685326,0.03486538678407669,0.03277161717414856,0.029065614566206932,0.035989098250865936,0.0387452207505703,0.03185432031750679,0.035309284925460815,0.034374453127384186,0.029635006561875343,0.03032008558511734,0.02769247069954872,0.03888005390763283,0.03115222603082657,0.032044705003499985,0.03475933521986008,0.03314796835184097,0.028440136462450027,0.02611180581152439,0.033767711371183395,0.036045778542757034,0.03320395573973656,0.030337875708937645,0.025749754160642624,0.03111361339688301,0.029743408784270287,0.03283281251788139,0.0308984462171793,0.03149459511041641,0.027507148683071136,0.03053361363708973,0.028016552329063416,0.02772679552435875,0.02689392864704132,0.03035280480980873,0.028293779119849205,0.02900724671781063,0.030459482222795486,0.025663401931524277,0.028618313372135162,0.026943456381559372,0.021355103701353073,0.01904122717678547,0.024210674688220024,0.02905363403260708,0.028026198968291283,0.024388622492551804,0.026023097336292267,
mse,1.1469281911849976,0.0448356568813324,0.02730826660990715,0.020093033090233803,0.017822135239839554,0.015875231474637985,0.01427584607154131,0.01348213478922844,0.01194552332162857,0.010616088286042213,0.009455230087041855,0.008347987197339535,0.007284647785127163,0.005558429751545191,0.004051854833960533,0.0031252794433385134,0.004625590518116951,0.0031166020780801773,0.0017491516191512346,0.0015847950708121061,0.0017100363038480282,0.0019316591788083315,0.0015709113795310259,0.0014681321335956454,0.0018786144210025668,0.001230875146575272,0.001205767155624926,0.0009532421245239675,0.0006803550641052425,0.000789834011811763,0.000599587569013238,0.0007451129495166242,0.0005797208286821842,0.000656146730761975,0.0005156752886250615,0.0008393536554649472,0.0007890801643952727,0.0007066859980113804,0.0005336554022505879,0.0005812784074805677,0.0004184804856777191,0.00041654915548861027,0.0006018277490511537,0.0004902508808299899,0.00045282841892912984,0.0004449322877917439,0.0004024642694275826,0.0004083094245288521,0.0005399215733632445,0.00045342871453613043,0.00040177773917093873,0.00023389003763440996,0.00024553464027121663,0.00034539683838374913,0.0003061479364987463,0.00024957486311905086,0.0003595724410843104,0.0004267613694537431,0.0002934783115051687,0.00036327564157545567,0.0003376133390702307,0.0002493482024874538,0.0002689696557354182,0.00022566845291294158,0.0004322125460021198,0.0002791543956845999,0.0002891322073992342,0.000345011503668502,0.0003115491126663983,0.0002309110132046044,0.0001996363716898486,0.0003192108415532857,0.00036506549804471433,0.0003101493348367512,0.000263160647591576,0.00019787326164077967,0.000275276368483901,0.00024786434369161725,0.0003095629217568785,0.00027151755057275295,0.00028117283363826573,0.00022003421327099204,0.00026345590595155954,0.00021938447025604546,0.00021837140957359225,0.00021195031877141446,0.0002643481711857021,0.0002250904799439013,0.00024358528025913984,0.00026279230951331556,0.00018740659288596362,0.00023114241776056588,0.00020063707779627293,0.0001338889851467684,0.00011127657489851117,0.0001717826526146382,0.00023533610510639846,0.00022152018209453672,0.00017706584185361862,0.00019411226094234735,
mae,0.7418956160545349,0.16845710575580597,0.1282956898212433,0.10473669320344925,0.09528136253356934,0.08853268623352051,0.08237757533788681,0.08139748871326447,0.07712060213088989,0.073423370718956,0.0708380937576294,0.06809484213590622,0.06515660136938095,0.05631839111447334,0.049584370106458664,0.043149545788764954,0.05223304405808449,0.044137414544820786,0.03211832419037819,0.03041638620197773,0.031475815922021866,0.03403332456946373,0.031098758801817894,0.029698457568883896,0.034436602145433426,0.027965588495135307,0.02632390521466732,0.02434084564447403,0.02062300406396389,0.022724106907844543,0.018621336668729782,0.0209493488073349,0.019002310931682587,0.020678065717220306,0.01761416159570217,0.022854942828416824,0.02209438383579254,0.020526790991425514,0.018370280042290688,0.019233716651797295,0.015776418149471283,0.01589766889810562,0.01934114843606949,0.01759081333875656,0.016475645825266838,0.01700376346707344,0.01582062803208828,0.015912257134914398,0.018299583345651627,0.016589302569627762,0.015126775950193405,0.01178895216435194,0.012234636582434177,0.014793488197028637,0.01394170057028532,0.012198611162602901,0.015333989635109901,0.016389913856983185,0.01345835905522108,0.01496825460344553,0.014477887190878391,0.012706982903182507,0.012735627591609955,0.01167217269539833,0.0158090740442276,0.012987145222723484,0.01358476746827364,0.014860223978757858,0.014078926295042038,0.011976540088653564,0.0109940180554986,0.014302917756140232,0.014866280369460583,0.014102774672210217,0.012660784646868706,0.010887819342315197,0.01299100648611784,0.012672326527535915,0.01380050741136074,0.012940768152475357,0.012972009368240833,0.01179836131632328,0.012905512936413288,0.011993122287094593,0.011888772249221802,0.011450034566223621,0.012830276042222977,0.012019757181406021,0.012060930952429771,0.012537641450762749,0.010945942252874374,0.01186168659478426,0.011299298144876957,0.009020005352795124,0.008018067106604576,0.009997648186981678,0.012149628251791,0.011849203146994114,0.010410014539957047,0.011040798388421535,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 135019    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 135020    
=================================================================
Total params: 270,039
Trainable params: 270,039
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 135,019
Trainable params: 135,019
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 135,020
Trainable params: 135,020
Non-trainable params: 0
_________________________________________________________________
