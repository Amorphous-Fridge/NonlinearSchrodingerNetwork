2021-06-26
loss,0.9013140201568604,0.34463757276535034,0.32331085205078125,0.276388943195343,0.26000502705574036,0.2414390593767166,0.2292289286851883,0.19880199432373047,0.18633291125297546,0.17909091711044312,0.14726229012012482,0.12697841227054596,0.11811553686857224,0.10738973319530487,0.10467682033777237,0.0834580808877945,0.09939044713973999,0.0895199105143547,0.07576315104961395,0.06809204816818237,0.06596165895462036,0.06189968064427376,0.062469419091939926,0.06275353580713272,0.0601540170609951,0.059718068689107895,0.04785091429948807,0.04696514457464218,0.04923640191555023,0.05086235702037811,0.04968283325433731,0.043296195566654205,0.03875591605901718,0.04604523256421089,0.04133520647883415,0.038801971822977066,0.0422019399702549,0.03779817745089531,0.03990515321493149,0.0350521095097065,0.03705833479762077,0.0437747947871685,0.03691635653376579,0.03471995145082474,0.03504469618201256,0.039864134043455124,0.03757820278406143,0.036305636167526245,0.03132789582014084,0.028992531821131706,0.033456578850746155,0.032132893800735474,0.03308049216866493,0.03173572197556496,0.0353267639875412,0.03076881170272827,0.029484860599040985,0.03036527708172798,0.029455620795488358,0.025450732558965683,0.02525574155151844,0.027621394023299217,0.02944253757596016,0.033434148877859116,0.032096706330776215,0.03249053284525871,0.03053726628422737,0.027581727132201195,0.030400846153497696,0.03133834898471832,0.02730683609843254,0.02799978293478489,0.026708316057920456,0.030415410175919533,0.028151724487543106,0.025221457704901695,0.026352534070611,0.02883088029921055,0.028402291238307953,0.027052752673625946,0.024742349982261658,0.024303162470459938,0.026855170726776123,0.02711600810289383,0.02512718178331852,0.02640327624976635,0.022004347294569016,0.02326110191643238,0.02699497528374195,0.029094591736793518,0.025477901101112366,0.026299433782696724,0.023441052064299583,0.023807764053344727,0.026172805577516556,0.024714281782507896,0.025189032778143883,0.02165096439421177,0.026228828355669975,0.025385769084095955,
mse,0.4760383367538452,0.03496013581752777,0.031249605119228363,0.02357582561671734,0.0214984230697155,0.019089767709374428,0.017146125435829163,0.012794201262295246,0.010418328456580639,0.009507197886705399,0.006122715305536985,0.004568454809486866,0.0041621169075369835,0.0033548460341989994,0.003145660273730755,0.0020523122511804104,0.002777314279228449,0.0022876376751810312,0.0016021037008613348,0.0013247743481770158,0.001217288663610816,0.0010809735395014286,0.0011208452051505446,0.0010764537146314979,0.0010260128183290362,0.0010197707451879978,0.0006554012070409954,0.0006258597131818533,0.0006877822452224791,0.0007251594797708094,0.0006814152584411204,0.0005348460399545729,0.00042889718315564096,0.0005999875720590353,0.00047505684779025614,0.0004196700465399772,0.0004925618413835764,0.0003970504621975124,0.00044640921987593174,0.0003510163223836571,0.0004028314433526248,0.0005312224384397268,0.0003814242372754961,0.00034316512756049633,0.00034887250512838364,0.00045459598186425865,0.0003926160861738026,0.0003709891461767256,0.00028036776348017156,0.000246299896389246,0.00032180725247599185,0.00029723855550400913,0.00031119928462430835,0.0002785398392006755,0.0003601087664719671,0.000275743892416358,0.0002490504994057119,0.00026562067796476185,0.00026101074763573706,0.00019092140428256243,0.0001814515853766352,0.00022117445769254118,0.00024653063155710697,0.0003129642573185265,0.00029455102048814297,0.00030134900589473546,0.00026540402905084193,0.0002160256408387795,0.0002565265167504549,0.0002783961535897106,0.0002069098991341889,0.00021993920381646603,0.00020571437198668718,0.00026282432372681797,0.00022508927213493735,0.00018306654237676412,0.00019908920512534678,0.00023548932222183794,0.0002304634399479255,0.00020385115931276232,0.00017663171456661075,0.00016980135114863515,0.0002079532278003171,0.00021104438928887248,0.00017986394232138991,0.00019573331519495696,0.0001393528946209699,0.00015975986025296152,0.0002115902170771733,0.000239571018028073,0.00018494477262720466,0.0001952946331584826,0.00015940997400321066,0.00015913182869553566,0.00019707920728251338,0.0001739121216814965,0.00018153486598748714,0.00013867624511476606,0.00019984858226962388,0.00018098679720424116,
mae,0.3830992579460144,0.14845356345176697,0.13800911605358124,0.11500102281570435,0.10966426134109497,0.10277416557073593,0.09769482910633087,0.08460821956396103,0.07919643819332123,0.07739223539829254,0.06166187301278114,0.053340762853622437,0.05019523203372955,0.045755334198474884,0.04396655037999153,0.035546623170375824,0.04172315448522568,0.03812253475189209,0.0324227511882782,0.02913609705865383,0.02793257310986519,0.025669103488326073,0.026372745633125305,0.02731367200613022,0.02565324306488037,0.02564615197479725,0.020513305440545082,0.019867248833179474,0.02086445316672325,0.022001827135682106,0.021457193419337273,0.018380405381321907,0.01662549376487732,0.019414376467466354,0.01762622408568859,0.01658310927450657,0.018156372010707855,0.016113340854644775,0.01702294871211052,0.014762652106583118,0.01573438011109829,0.01834728755056858,0.015653720125555992,0.014889057725667953,0.014998129568994045,0.01712554134428501,0.01637347787618637,0.015302282758057117,0.013202119618654251,0.01230344083160162,0.0142044173553586,0.013534877449274063,0.013958302326500416,0.013546166010200977,0.01534269005060196,0.013229741714894772,0.012544432654976845,0.012782705016434193,0.012495969422161579,0.010874868370592594,0.010894006118178368,0.011675131507217884,0.012481442652642727,0.014355383813381195,0.013812937773764133,0.014049199409782887,0.012788448482751846,0.011669368483126163,0.012855124659836292,0.013143425807356834,0.011438305489718914,0.01195763610303402,0.011344343423843384,0.013020182028412819,0.011963026598095894,0.010781606659293175,0.010984940454363823,0.012424924410879612,0.012576949782669544,0.01177248079329729,0.010573377832770348,0.010302301496267319,0.011334266513586044,0.011524531990289688,0.01082366332411766,0.011269853450357914,0.009511970914900303,0.009682407602667809,0.011657798662781715,0.012587602250277996,0.01089894026517868,0.011175129562616348,0.00994786061346531,0.01013226993381977,0.011067352257668972,0.010579664260149002,0.010773265734314919,0.009263732470571995,0.011182398535311222,0.01092876773327589,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 140323    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 140324    
=================================================================
Total params: 280,647
Trainable params: 280,647
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 140,323
Trainable params: 140,323
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 140,324
Trainable params: 140,324
Non-trainable params: 0
_________________________________________________________________
