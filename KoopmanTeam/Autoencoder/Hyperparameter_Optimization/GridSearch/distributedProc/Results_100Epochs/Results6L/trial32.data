2021-06-26
loss,0.8381415605545044,0.2282944619655609,0.1694141924381256,0.12141453474760056,0.10385874658823013,0.11386417597532272,0.11076463758945465,0.08366797119379044,0.08898820728063583,0.10996446758508682,0.0984358862042427,0.07621324062347412,0.07251638174057007,0.06451258808374405,0.06226310133934021,0.07761526852846146,0.0737580806016922,0.06606301665306091,0.04945336654782295,0.051588024944067,0.05209733173251152,0.04426322877407074,0.051146239042282104,0.0604831799864769,0.05299884453415871,0.04401354864239693,0.037717465311288834,0.05447183549404144,0.0370572954416275,0.04076402261853218,0.05026794597506523,0.047851186245679855,0.04297564923763275,0.03734860569238663,0.03362540900707245,0.037417393177747726,0.04267721623182297,0.037921372801065445,0.03352861851453781,0.048182398080825806,0.04505196213722229,0.03975984454154968,0.035672541707754135,0.03112507052719593,0.03260302543640137,0.0383235327899456,0.030877895653247833,0.030137967318296432,0.03492605686187744,0.038253411650657654,0.032690778374671936,0.029561510309576988,0.029287273064255714,0.03456754982471466,0.04257478192448616,0.036977119743824005,0.03257623314857483,0.03094412572681904,0.02848404459655285,0.024216024205088615,0.027125462889671326,0.029958348721265793,0.02791190706193447,0.03866364806890488,0.03246064484119415,0.02650177665054798,0.02863217145204544,0.02946089766919613,0.0392274409532547,0.03688209503889084,0.031810615211725235,0.02726837247610092,0.027459748089313507,0.028249938040971756,0.03512653335928917,0.03149033337831497,0.031434860080480576,0.027596106752753258,0.027980079874396324,0.0319792777299881,0.027819762006402016,0.030408596619963646,0.030625974759459496,0.030051779001951218,0.030098581686615944,0.025042489171028137,0.02752711996436119,0.022963905707001686,0.02135404758155346,0.024418065324425697,0.031007148325443268,0.0329020656645298,0.030314791947603226,0.024542294442653656,0.022878969088196754,0.02554316446185112,0.02453022450208664,0.022234531119465828,0.02417229861021042,0.027825916185975075,
mse,0.3334904611110687,0.017054814845323563,0.008797687478363514,0.004209639970213175,0.003066100412979722,0.003792251693084836,0.003407515352591872,0.001956717576831579,0.002175499452278018,0.003457117360085249,0.0027310543227940798,0.001669613877311349,0.0015123655321076512,0.001177681959234178,0.0011502132983878255,0.0017889962764456868,0.0015010355273261666,0.0012060723965987563,0.0007060684729367495,0.000776084081735462,0.0007675986853428185,0.0005525726010091603,0.0007783834589645267,0.0009989691898226738,0.0007872232235968113,0.0005593515816144645,0.0004221650888212025,0.000838932697661221,0.0004013864672742784,0.0004859545442741364,0.0007182394620031118,0.0006207774858921766,0.0005053039640188217,0.00039290133281610906,0.0003363433061167598,0.0004098355711903423,0.0004987551365047693,0.0003996805171482265,0.00032405543606728315,0.0006699951482005417,0.0005609894287772477,0.0004371129034552723,0.00034385532489977777,0.0002834566403180361,0.0003097823937423527,0.0004172954650130123,0.0002777896588668227,0.0002543786249589175,0.00035416119499132037,0.00041313801193609834,0.00030017580138519406,0.00024441699497401714,0.00024132675025612116,0.0003477190330158919,0.000501909467857331,0.0003794110962189734,0.00029940856620669365,0.00026771886041387916,0.0002241069305455312,0.0001639541587792337,0.000209338148124516,0.0002580580476205796,0.00021861660934519023,0.0004264354065526277,0.00028392774402163923,0.0002071418275590986,0.00023031163436826319,0.00024355508503504097,0.00042598822619765997,0.0003830032073892653,0.0002810586302075535,0.00021038044360466301,0.0002117681287927553,0.00022432385594584048,0.0003501060127746314,0.0002772197185549885,0.00029202349833212793,0.0002087716420646757,0.0002236926811747253,0.00028361676959320903,0.00021491826919373125,0.00026593581424094737,0.00026875577168539166,0.00025256723165512085,0.00025404870393685997,0.00017963875143323094,0.0002086751483147964,0.00015011991490609944,0.00013000851322431117,0.000171056148246862,0.0002766192192211747,0.0003014793328475207,0.00025654901401139796,0.0001703380112303421,0.00014956886298023164,0.00018697735504247248,0.00017374363960698247,0.00014321351773105562,0.00016360048903152347,0.00021955771080683917,
mae,0.3465684652328491,0.0971720889210701,0.07134921848773956,0.051929399371147156,0.04413687810301781,0.04900429770350456,0.04587545245885849,0.03522944822907448,0.03841044753789902,0.04790375381708145,0.04381595924496651,0.031373001635074615,0.029399802908301353,0.026327377185225487,0.026421694085001945,0.032935731112957,0.03161851316690445,0.0295126810669899,0.02082841470837593,0.02180960401892662,0.021755259484052658,0.018707789480686188,0.02234303019940853,0.02720336988568306,0.024312181398272514,0.01930326782166958,0.015871459618210793,0.023648029193282127,0.01591205783188343,0.017424708232283592,0.02211039327085018,0.02155473083257675,0.019004998728632927,0.015848025679588318,0.014050440862774849,0.016173221170902252,0.018245382234454155,0.016063585877418518,0.014480821788311005,0.01957424357533455,0.018549231812357903,0.016503168269991875,0.014964977279305458,0.013332877308130264,0.013995757326483727,0.0165820624679327,0.013038855977356434,0.012754211202263832,0.015265271998941898,0.016859205439686775,0.014224973507225513,0.012465110048651695,0.012531549669802189,0.014618742279708385,0.01905912347137928,0.01625361479818821,0.014265415258705616,0.01327845174819231,0.012239933013916016,0.010495837777853012,0.01159578189253807,0.012533037923276424,0.011662752367556095,0.016504358500242233,0.013649867847561836,0.011243841610848904,0.012221516110002995,0.012454393319785595,0.016749238595366478,0.015946494415402412,0.013612505048513412,0.011760367080569267,0.01176318060606718,0.01190563291311264,0.015187420882284641,0.013454006053507328,0.01376127079129219,0.011729451827704906,0.011706051416695118,0.013885959051549435,0.012115581892430782,0.012704539112746716,0.013084057718515396,0.012988383881747723,0.012736711651086807,0.01051998883485794,0.0119754858314991,0.009716173633933067,0.009047983214259148,0.010332923382520676,0.013415668159723282,0.014481356367468834,0.013557431288063526,0.010371262207627296,0.009746192954480648,0.010668064467608929,0.010517445392906666,0.009477699175477028,0.010432844050228596,0.011838287115097046,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 83379     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 83380     
=================================================================
Total params: 166,759
Trainable params: 166,759
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 83,379
Trainable params: 83,379
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 83,380
Trainable params: 83,380
Non-trainable params: 0
_________________________________________________________________
