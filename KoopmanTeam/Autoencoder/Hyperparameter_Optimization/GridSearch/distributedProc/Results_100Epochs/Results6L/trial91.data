2021-06-26
loss,2.6441357135772705,0.7838073968887329,0.3478688895702362,0.2940310537815094,0.32098662853240967,0.20923446118831635,0.1531439870595932,0.1838257610797882,0.13983787596225739,0.14687128365039825,0.11889740079641342,0.108403779566288,0.12437078356742859,0.12426692992448807,0.1295069456100464,0.12207876145839691,0.11096059530973434,0.10176624357700348,0.09902828186750412,0.08411084115505219,0.09284262359142303,0.09296141564846039,0.07334091514348984,0.07099474221467972,0.07066158950328827,0.08981988579034805,0.08126463741064072,0.07149793952703476,0.06669173389673233,0.05978775396943092,0.07713057100772858,0.06597428768873215,0.053160831332206726,0.0538373626768589,0.06750194728374481,0.06968719512224197,0.0691010057926178,0.05774058401584625,0.05668223276734352,0.06547582149505615,0.06256464123725891,0.052718501538038254,0.05236675217747688,0.05293163284659386,0.048698533326387405,0.06507255882024765,0.05686406046152115,0.05113367736339569,0.05265060439705849,0.05880879983305931,0.05719782039523125,0.03941376134753227,0.04914798215031624,0.046627044677734375,0.038033947348594666,0.05145042762160301,0.05478305742144585,0.046165380626916885,0.04434322193264961,0.05327839404344559,0.05512380599975586,0.04457949474453926,0.0428490936756134,0.043013833463191986,0.04241812229156494,0.04195801913738251,0.052449941635131836,0.05316530540585518,0.0500728115439415,0.04356995224952698,0.037233926355838776,0.03705569729208946,0.04340200498700142,0.04250450059771538,0.033547721803188324,0.03250613436102867,0.04644924774765968,0.05133878067135811,0.04443420097231865,0.04001706466078758,0.04977671056985855,0.0378255620598793,0.02859712578356266,0.04509750381112099,0.04665679484605789,0.03937707096338272,0.03233560174703598,0.03504422307014465,0.038452036678791046,0.0369112454354763,0.03331805393099785,0.03841812536120415,0.04953056201338768,0.04505251348018646,0.04278038814663887,0.04245692119002342,0.04377492889761925,0.03888503089547157,0.03699091449379921,0.03127294406294823,
mse,2.1101083755493164,0.22386932373046875,0.03641604632139206,0.02573483996093273,0.029301561415195465,0.012493971735239029,0.00661119818687439,0.009768091142177582,0.005591073073446751,0.006437106058001518,0.004034865647554398,0.003398612141609192,0.004288524854928255,0.004552270285785198,0.00488543976098299,0.00447055883705616,0.0034160674549639225,0.0028947487007826567,0.002833572681993246,0.0020119333639740944,0.002421947894617915,0.002390219597145915,0.0014893426559865475,0.001385522773489356,0.00145854358561337,0.0022560080979019403,0.0017893067561089993,0.001423967070877552,0.0012538960436359048,0.0010563721880316734,0.0016401804750785232,0.0012061863671988249,0.0008357814513146877,0.0008702195482328534,0.001297697308473289,0.0013471607817336917,0.001296382863074541,0.0009338464587926865,0.0008981837891042233,0.0011993171647191048,0.0010861954651772976,0.0007654158980585635,0.000770124199334532,0.0007725519826635718,0.0006653298623859882,0.001185680041089654,0.0009300922392867506,0.0007534819887951016,0.0008018044172786176,0.0009450119105167687,0.000886029505636543,0.00045697123277932405,0.0006990354740992188,0.0006027339259162545,0.0004002154746558517,0.0007465620874427259,0.0008214139379560947,0.0005963636795058846,0.0005622308235615492,0.0007728096097707748,0.0008248183876276016,0.000570811505895108,0.0005019407835789025,0.0005053189815953374,0.0005052471533417702,0.0004913243465125561,0.000769261852838099,0.0007706609321758151,0.0006833305233158171,0.0005271988338790834,0.0003878242278005928,0.0003868224157486111,0.0005234838463366032,0.000494469131808728,0.000320136925438419,0.0002959234989248216,0.0006177736795507371,0.000724793178960681,0.0005389557918533683,0.00045100715942680836,0.0006791127379983664,0.00040222573443315923,0.000244901399128139,0.0005650013918057084,0.0005793370655737817,0.0004273817758075893,0.0002967783366329968,0.0003418078413233161,0.0004120212106499821,0.00038799253525212407,0.0003097080043517053,0.0004258818516973406,0.0006839983980171382,0.0005556007381528616,0.0005033939378336072,0.0004979732329957187,0.0005203753826208413,0.00041785676148720086,0.0003739012172445655,0.00026942172553390265,
mae,0.9891766309738159,0.33755794167518616,0.15251600742340088,0.12865902483463287,0.13576099276542664,0.08908180892467499,0.06514236330986023,0.0777624100446701,0.06090439483523369,0.06334363669157028,0.05076579004526138,0.045461319386959076,0.053432196378707886,0.05406556650996208,0.05781972035765648,0.053563252091407776,0.04941742122173309,0.04356417804956436,0.043006639927625656,0.03495592251420021,0.04006834328174591,0.03998560085892677,0.030919885262846947,0.030028387904167175,0.030847810208797455,0.040738750249147415,0.03710460290312767,0.029923927038908005,0.028462616726756096,0.02556362934410572,0.03440972417593002,0.028479071334004402,0.02254275232553482,0.02314465492963791,0.028908489271998405,0.030116917565464973,0.030499611049890518,0.024286264553666115,0.023897981271147728,0.028271587565541267,0.02753783017396927,0.022546567022800446,0.022404339164495468,0.023607030510902405,0.021332917734980583,0.027830757200717926,0.02443566359579563,0.022048087790608406,0.022759871557354927,0.025493385270237923,0.02586602233350277,0.016150671988725662,0.02078775316476822,0.019860394299030304,0.016611527651548386,0.02239810861647129,0.024702975526452065,0.021483026444911957,0.01955549791455269,0.02292509749531746,0.023776894435286522,0.01883004419505596,0.01878460682928562,0.018569795414805412,0.017929334193468094,0.018245281651616096,0.022904064506292343,0.02353570982813835,0.021367330104112625,0.018631815910339355,0.01572970673441887,0.01532240305095911,0.01851062662899494,0.018966779112815857,0.014246013946831226,0.01392438169568777,0.02023555338382721,0.022285684943199158,0.018648944795131683,0.01714351959526539,0.021659627556800842,0.015890609472990036,0.012284509837627411,0.0197613462805748,0.02110069990158081,0.017188357189297676,0.013527147471904755,0.014904606156051159,0.016802377998828888,0.01569637842476368,0.014096259139478207,0.01632186584174633,0.02129720151424408,0.01931360736489296,0.018485616892576218,0.018532482907176018,0.019172456115484238,0.01710568554699421,0.0158401932567358,0.013550059869885445,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 400867    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 400868    
=================================================================
Total params: 801,735
Trainable params: 801,735
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 400,867
Trainable params: 400,867
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 400,868
Trainable params: 400,868
Non-trainable params: 0
_________________________________________________________________
