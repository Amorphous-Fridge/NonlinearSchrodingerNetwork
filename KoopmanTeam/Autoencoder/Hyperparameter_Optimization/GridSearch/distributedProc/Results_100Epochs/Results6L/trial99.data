2021-06-26
loss,2.531163215637207,2.0870327949523926,1.6842849254608154,0.5845698118209839,0.44503048062324524,0.4442872703075409,0.44464951753616333,0.4440572261810303,0.44417938590049744,0.4445532560348511,0.44421645998954773,0.44498130679130554,0.4440365731716156,0.44465941190719604,0.44487085938453674,0.44421371817588806,0.44472450017929077,0.44495293498039246,0.44475939869880676,0.4444841146469116,0.44461601972579956,0.44503894448280334,0.4446825385093689,0.44434306025505066,0.4445077180862427,0.44411441683769226,0.44434019923210144,0.4443834722042084,0.44451361894607544,0.4444016218185425,0.44468775391578674,0.4435107707977295,0.4441673755645752,0.44356265664100647,0.44431495666503906,0.4450257420539856,0.444176584482193,0.4445851147174835,0.444175124168396,0.44449013471603394,0.4447175860404968,0.4442436695098877,0.44503647089004517,0.44403544068336487,0.4448584020137787,0.4441301226615906,0.44463855028152466,0.4447682499885559,0.4440581500530243,0.4443005323410034,0.4441114664077759,0.44438302516937256,0.4447072148323059,0.44459545612335205,0.44483479857444763,0.44444048404693604,0.44418707489967346,0.4443318247795105,0.4446282684803009,0.4443904757499695,0.44416579604148865,0.4447469413280487,0.4439883530139923,0.4441382586956024,0.4443279206752777,0.4445922076702118,0.44474732875823975,0.44474244117736816,0.44454440474510193,0.44446036219596863,0.44445860385894775,0.44495689868927,0.44492343068122864,0.44490906596183777,0.4445885717868805,0.44467049837112427,0.44442909955978394,0.4443420469760895,0.4447568953037262,0.4444853663444519,0.44443753361701965,0.4448642432689667,0.4444180428981781,0.4445044994354248,0.44427430629730225,0.4449995160102844,0.4444809854030609,0.444711834192276,0.4451000690460205,0.44443732500076294,0.444607138633728,0.44440189003944397,0.4444148540496826,0.44476518034935,0.44488364458084106,0.44455280900001526,0.44412150979042053,0.44417667388916016,0.4441993832588196,0.4449951648712158,
mse,1.6960407495498657,1.102919101715088,0.7351903319358826,0.10375639796257019,0.05526250973343849,0.0549963042140007,0.05510621890425682,0.054961495101451874,0.05498562008142471,0.055082667618989944,0.05498267337679863,0.055125970393419266,0.05497264862060547,0.0551200769841671,0.05513114109635353,0.05498749390244484,0.055076077580451965,0.05514829605817795,0.05509151518344879,0.05504010617733002,0.05505821108818054,0.055197395384311676,0.05508583411574364,0.05501341447234154,0.055088143795728683,0.05498906224966049,0.055034976452589035,0.055050335824489594,0.05505022034049034,0.05504067987203598,0.05508866906166077,0.054868753999471664,0.054994821548461914,0.05484747886657715,0.055033501237630844,0.055152349174022675,0.05497697740793228,0.05507611110806465,0.05497659370303154,0.05505993217229843,0.055077098309993744,0.054985903203487396,0.055179890245199203,0.054959844797849655,0.05512019619345665,0.05498356744647026,0.05507871136069298,0.055123019963502884,0.05495275929570198,0.05501395836472511,0.05498356744647026,0.05500670522451401,0.055064816027879715,0.05509243905544281,0.055118147283792496,0.055035773664712906,0.05496050417423248,0.055018339306116104,0.05506059527397156,0.055020060390233994,0.054991062730550766,0.05508232116699219,0.054959431290626526,0.0549541711807251,0.05502912402153015,0.05510205402970314,0.055134132504463196,0.05508844554424286,0.055051978677511215,0.055044032633304596,0.05504274740815163,0.055137425661087036,0.055176157504320145,0.055148299783468246,0.0550689734518528,0.05507107079029083,0.055030837655067444,0.05499555170536041,0.05509425327181816,0.055074259638786316,0.055076781660318375,0.05511923134326935,0.05504078418016434,0.055049486458301544,0.05502568185329437,0.0551946796476841,0.055049195885658264,0.05509469658136368,0.05516025424003601,0.05502217262983322,0.05509266257286072,0.05499967187643051,0.05503736063838005,0.05510689690709114,0.05513230338692665,0.05505475029349327,0.054989222437143326,0.054983824491500854,0.05497385933995247,0.05517465993762016,
mae,0.9568748474121094,0.6651875972747803,0.555916428565979,0.24326767027378082,0.1973685771226883,0.1971302181482315,0.1971544623374939,0.19698427617549896,0.19705678522586823,0.1972579061985016,0.19707095623016357,0.19738300144672394,0.19696825742721558,0.19730320572853088,0.1973915547132492,0.19702252745628357,0.1972598433494568,0.1974201202392578,0.19734013080596924,0.19716577231884003,0.19724097847938538,0.19746918976306915,0.19733740389347076,0.19713526964187622,0.19725507497787476,0.19703680276870728,0.19714109599590302,0.197148859500885,0.19723206758499146,0.1972159892320633,0.19728244841098785,0.19672498106956482,0.1969955414533615,0.19673141837120056,0.19716711342334747,0.19745662808418274,0.19705204665660858,0.19725072383880615,0.19707293808460236,0.1972118318080902,0.1973312795162201,0.19704380631446838,0.1974644511938095,0.19695785641670227,0.19733870029449463,0.19701999425888062,0.19725777208805084,0.19730593264102936,0.19699081778526306,0.19707933068275452,0.19704486429691315,0.19712023437023163,0.19729237258434296,0.1973208487033844,0.19733218848705292,0.19717374444007874,0.19706369936466217,0.1971305012702942,0.19729024171829224,0.19714224338531494,0.1970537304878235,0.1973133534193039,0.1969815492630005,0.19706624746322632,0.19712303578853607,0.1972097009420395,0.19736291468143463,0.19734755158424377,0.19719845056533813,0.197164386510849,0.19718438386917114,0.19742991030216217,0.19746875762939453,0.19738039374351501,0.19721560180187225,0.1972857415676117,0.1971990019083023,0.19710908830165863,0.19731521606445312,0.19719535112380981,0.19721058011054993,0.1973808854818344,0.19718407094478607,0.19721822440624237,0.19705156981945038,0.1974242627620697,0.19715045392513275,0.19732032716274261,0.1974097043275833,0.19716671109199524,0.19724994897842407,0.1971137672662735,0.1971723884344101,0.19732262194156647,0.19736364483833313,0.19720138609409332,0.19705826044082642,0.1970137357711792,0.19710001349449158,0.1974753737449646,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 529995    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 529996    
=================================================================
Total params: 1,059,991
Trainable params: 1,059,991
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 529,995
Trainable params: 529,995
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 529,996
Trainable params: 529,996
Non-trainable params: 0
_________________________________________________________________
