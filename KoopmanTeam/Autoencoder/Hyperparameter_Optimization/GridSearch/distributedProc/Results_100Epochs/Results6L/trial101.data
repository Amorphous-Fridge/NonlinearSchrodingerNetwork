2021-06-26
loss,3.1891214847564697,2.257582902908325,2.237926959991455,2.277005910873413,2.2376434803009033,2.2374014854431152,2.2382454872131348,2.2376065254211426,2.237919569015503,2.2376549243927,2.238415002822876,2.2381393909454346,2.2376012802124023,2.2375404834747314,2.328033208847046,2.247941017150879,2.238300085067749,2.237611770629883,2.237102746963501,2.2370688915252686,2.2373125553131104,2.2387094497680664,2.2371034622192383,2.2376339435577393,2.237147808074951,2.237165689468384,2.237339735031128,2.26027774810791,0.5367569923400879,0.4452323615550995,0.44364219903945923,0.4443838596343994,0.4450904130935669,0.44471240043640137,0.4443037807941437,0.44422343373298645,0.4443225860595703,0.44442158937454224,0.4444613754749298,0.4448821544647217,0.44459986686706543,0.44511279463768005,0.4448099136352539,0.4449974000453949,0.4439217746257782,0.444161057472229,0.44471248984336853,0.44477683305740356,0.444676011800766,0.4451536238193512,0.4450518488883972,0.4449310600757599,0.44512704014778137,0.44527897238731384,0.44440510869026184,0.445011705160141,0.44479086995124817,0.44442418217658997,0.4442337453365326,0.4447856843471527,0.4446548819541931,0.44472724199295044,0.445786714553833,0.44458672404289246,0.44455382227897644,0.4443875551223755,0.44480597972869873,0.44433876872062683,0.44596219062805176,0.44525963068008423,0.4451175630092621,0.44472649693489075,0.4447547197341919,0.445232093334198,0.44550734758377075,0.4447525143623352,0.4444957375526428,0.44528302550315857,0.44427135586738586,0.4446415305137634,0.4443660080432892,0.4444841742515564,0.44496607780456543,0.44492068886756897,0.4444218873977661,0.44407856464385986,0.44513607025146484,0.44396087527275085,0.44482889771461487,0.445954829454422,0.4449611306190491,0.4446769952774048,0.444395512342453,0.4446154534816742,0.4440232217311859,0.44473719596862793,0.44373181462287903,0.44449687004089355,0.44520774483680725,0.4448038935661316,
mse,2.671118974685669,1.2873708009719849,1.2651150226593018,1.3106554746627808,1.2647600173950195,1.2645256519317627,1.2654062509536743,1.2647125720977783,1.2651188373565674,1.2647557258605957,1.2655829191207886,1.2652884721755981,1.264733910560608,1.2646820545196533,1.3709814548492432,1.2763668298721313,1.2654414176940918,1.2647113800048828,1.2641009092330933,1.2640935182571411,1.2643733024597168,1.26596200466156,1.264146327972412,1.2647583484649658,1.2641937732696533,1.2642278671264648,1.264407753944397,1.8045462369918823,0.08851786702871323,0.05526035279035568,0.054889269173145294,0.055036116391420364,0.05517135560512543,0.055085357278585434,0.05505113676190376,0.05499022454023361,0.05502775311470032,0.05505386367440224,0.0550607331097126,0.05515323579311371,0.05508439987897873,0.05518725886940956,0.05510992929339409,0.055190153419971466,0.05492093041539192,0.055022481828927994,0.05507814884185791,0.05513499304652214,0.05512508004903793,0.0552174374461174,0.05517630651593208,0.05517544597387314,0.05520274490118027,0.055265940725803375,0.05500997602939606,0.05517388880252838,0.055125173181295395,0.05508678779006004,0.05503722280263901,0.05511586740612984,0.055080533027648926,0.055128369480371475,0.05535120144486427,0.055087026208639145,0.055095382034778595,0.05504431575536728,0.055086784064769745,0.05504582077264786,0.055442072451114655,0.05525469407439232,0.05521202087402344,0.05514422804117203,0.055114708840847015,0.05528215318918228,0.05533437430858612,0.05511775612831116,0.055068545043468475,0.05524390563368797,0.05500934273004532,0.05508006736636162,0.055031027644872665,0.055045705288648605,0.0551563985645771,0.05511441081762314,0.05505916476249695,0.05496054142713547,0.05522916465997696,0.054926782846450806,0.05516304820775986,0.055408407002687454,0.0551505908370018,0.05514107272028923,0.055012140423059464,0.055088602006435394,0.05496714264154434,0.055101413279771805,0.05492425337433815,0.0550411194562912,0.055258024483919144,0.05514794960618019,
mae,1.421736478805542,0.7261940240859985,0.6980013847351074,0.7507692575454712,0.6990804076194763,0.6982420086860657,0.6982338428497314,0.6980956792831421,0.6982940435409546,0.6980394721031189,0.6984566450119019,0.6982258558273315,0.697940468788147,0.69800865650177,0.8120863437652588,0.7127638459205627,0.6984188556671143,0.6979354619979858,0.6981388926506042,0.6980227828025818,0.6983347535133362,0.6982806324958801,0.6978296041488647,0.6980381608009338,0.6978027820587158,0.6980233788490295,0.6977633833885193,0.9127202033996582,0.2345505654811859,0.1974782943725586,0.1968049257993698,0.19711194932460785,0.1973906308412552,0.19728992879390717,0.19707190990447998,0.19705484807491302,0.1970728039741516,0.19713550806045532,0.19709230959415436,0.1973162591457367,0.19724492728710175,0.19746893644332886,0.19726139307022095,0.19744281470775604,0.1969176083803177,0.19697755575180054,0.19727009534835815,0.19726862013339996,0.19727446138858795,0.19744764268398285,0.1974196434020996,0.1973244845867157,0.19742229580879211,0.19760049879550934,0.1970876306295395,0.19742351770401,0.19732548296451569,0.19714921712875366,0.19715255498886108,0.19728170335292816,0.19725705683231354,0.19732946157455444,0.19769389927387238,0.1972316950559616,0.19718727469444275,0.19710983335971832,0.1973182111978531,0.19714047014713287,0.19780287146568298,0.19757911562919617,0.19748863577842712,0.19729173183441162,0.19731588661670685,0.1974622756242752,0.19770988821983337,0.19727879762649536,0.1971919685602188,0.19756567478179932,0.19709712266921997,0.19720806181430817,0.19711828231811523,0.19719742238521576,0.19741521775722504,0.19738148152828217,0.19710028171539307,0.1968631148338318,0.19753435254096985,0.1968894600868225,0.19740456342697144,0.19785183668136597,0.19738322496414185,0.19729259610176086,0.19712603092193604,0.19718627631664276,0.19699759781360626,0.19727100431919098,0.19680090248584747,0.1971946656703949,0.1974521279335022,0.19728127121925354,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 466451    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 466452    
=================================================================
Total params: 932,903
Trainable params: 932,903
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 466,451
Trainable params: 466,451
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 466,452
Trainable params: 466,452
Non-trainable params: 0
_________________________________________________________________
