2021-06-26
loss,3.75830078125,2.5827245712280273,2.2376325130462646,2.2363758087158203,2.14505672454834,0.5672409534454346,0.44465819001197815,0.4247208535671234,0.3554556667804718,0.3355034291744232,0.3220258057117462,0.30151739716529846,0.26327598094940186,0.20868976414203644,0.17479047179222107,0.1562543362379074,0.14636391401290894,0.1329178512096405,0.10665757954120636,0.09795450419187546,0.09224604815244675,0.08022288233041763,0.0651940330862999,0.06065186858177185,0.07031318545341492,0.08668550848960876,0.06876584142446518,0.05490214005112648,0.05480998381972313,0.047810088843107224,0.04728923365473747,0.04698358476161957,0.055429648607969284,0.04929220303893089,0.06388090550899506,0.04350050538778305,0.04188583791255951,0.04215146228671074,0.044541530311107635,0.04503953084349632,0.05826824530959129,0.03464602306485176,0.043194666504859924,0.0441272035241127,0.05481117218732834,0.0341290608048439,0.03262428939342499,0.04483790323138237,0.04939638078212738,0.049621809273958206,0.03779296949505806,0.037866804748773575,0.03886650130152702,0.0466107614338398,0.041081614792346954,0.04260759428143501,0.038928598165512085,0.039592381566762924,0.035556986927986145,0.038966622203588486,0.03887525200843811,0.03789323940873146,0.03229504078626633,0.028533993288874626,0.04020944982767105,0.042304325848817825,0.03976525738835335,0.03711890056729317,0.028435371816158295,0.023264238610863686,0.02935023047029972,0.028404327109456062,0.035277631133794785,0.029307374730706215,0.03524735942482948,0.04147940129041672,0.040235571563243866,0.03831290453672409,0.033772360533475876,0.03018570877611637,0.02999667078256607,0.026894832029938698,0.026261193677783012,0.030381357297301292,0.0313311330974102,0.028704939410090446,0.039643097668886185,0.035290345549583435,0.027602016925811768,0.03731146082282066,0.03241506963968277,0.02666984498500824,0.034220535308122635,0.03322993591427803,0.029117396101355553,0.037548910826444626,0.03279711678624153,0.02834826149046421,0.03016946092247963,0.03602186590433121,
mse,3.581997871398926,1.7218406200408936,1.2647616863250732,1.2633239030838013,1.2011816501617432,0.10114636272192001,0.05511566251516342,0.05069831386208534,0.0376298613846302,0.034297481179237366,0.03150634840130806,0.027751468122005463,0.021910736337304115,0.014587906189262867,0.010323183611035347,0.008229784667491913,0.006937987171113491,0.005497719161212444,0.00350969354622066,0.0029072118923068047,0.002642497420310974,0.0019657236989587545,0.0013023912906646729,0.001085489522665739,0.001430387026630342,0.0022097351029515266,0.001366056501865387,0.0008928757742978632,0.0008928573224693537,0.0006786776939406991,0.0006477484712377191,0.0006494583212770522,0.0008717537857592106,0.0007125447154976428,0.001217692974023521,0.0005523588042706251,0.0005117153632454574,0.0005222797044552863,0.0005882004625163972,0.0006478673894889653,0.0009545008069835603,0.0003699899825733155,0.0005355011089704931,0.0005608619539998472,0.0008364567183889449,0.00036103586899116635,0.0003147968673147261,0.0005912275519222021,0.0006954835844226182,0.0006758869276382029,0.0004130005545448512,0.0004192397464066744,0.0004258649714756757,0.0006244624964892864,0.000473055406473577,0.0005101134302094579,0.000429040112067014,0.00045668878010474145,0.00036403388367034495,0.0004412779526319355,0.0004382715269457549,0.0004118058132007718,0.0003209281712770462,0.0002370606962358579,0.0004586229333654046,0.0005062826676294208,0.00044797337613999844,0.00039687156095169485,0.0002321226493222639,0.00015970323875080794,0.0002504006843082607,0.0002368720743106678,0.0003432710363995284,0.00025033362908288836,0.00036819500382989645,0.0004863292269874364,0.00045854647760279477,0.0004153394256718457,0.0003257500648032874,0.0002604577166493982,0.0002541238209232688,0.00020895333727821708,0.0002027407317655161,0.0002800140646286309,0.0002779565111268312,0.0002362028753850609,0.0004401643527671695,0.00035569342435337603,0.00021722646488342434,0.0003891747328452766,0.00028549606213346124,0.00020737027807626873,0.0003485646448098123,0.0003123007481917739,0.00023660784063395113,0.0003952700353693217,0.00030780734959989786,0.00023031322052702308,0.00025848307996056974,0.0003692308673635125,
mae,1.7091987133026123,0.9396046996116638,0.6984414458274841,0.697365403175354,0.7280283570289612,0.2438337206840515,0.1971568614244461,0.18652187287807465,0.15072080492973328,0.14291873574256897,0.1384444236755371,0.13010795414447784,0.11511120200157166,0.09071742743253708,0.0739128366112709,0.06639552861452103,0.0626988559961319,0.05689176544547081,0.045336052775382996,0.04157819598913193,0.039168208837509155,0.034381523728370667,0.027593223378062248,0.02554483152925968,0.02941349893808365,0.036179836839437485,0.02898162044584751,0.023235253989696503,0.023602794855833054,0.0201765988022089,0.020081061869859695,0.019839290529489517,0.023526770994067192,0.0206407830119133,0.026958076283335686,0.018467752262949944,0.017733946442604065,0.01762344315648079,0.01885531097650528,0.01913571171462536,0.024334220215678215,0.014737427234649658,0.01842476800084114,0.018620947375893593,0.023015828803181648,0.01474717166274786,0.01386220846325159,0.01884140819311142,0.021217208355665207,0.02059856243431568,0.015949616208672523,0.016081027686595917,0.016461869701743126,0.019306441769003868,0.017422227188944817,0.018081650137901306,0.016648750752210617,0.016980547457933426,0.01501057855784893,0.0165434330701828,0.016503242775797844,0.01612352766096592,0.013587147928774357,0.012133074924349785,0.017260026186704636,0.017599664628505707,0.01705426722764969,0.01587306708097458,0.012112446129322052,0.009853151626884937,0.012395977042615414,0.012006362900137901,0.0153404101729393,0.012385623529553413,0.014845512807369232,0.017620909959077835,0.017016448080539703,0.016015898436307907,0.014478250406682491,0.012619811110198498,0.012799887917935848,0.011262685991823673,0.011035527102649212,0.013196088373661041,0.013602332212030888,0.01214536651968956,0.0167145486921072,0.015012253075838089,0.011640986427664757,0.01588243432343006,0.014265422709286213,0.011180991306900978,0.014096179977059364,0.014236724004149437,0.012446573004126549,0.01573142223060131,0.013797149993479252,0.012164149433374405,0.01284803170710802,0.015267202630639076,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 314099    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 314100    
=================================================================
Total params: 628,199
Trainable params: 628,199
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 314,099
Trainable params: 314,099
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 314,100
Trainable params: 314,100
Non-trainable params: 0
_________________________________________________________________
