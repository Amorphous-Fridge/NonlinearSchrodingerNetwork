2021-06-26
loss,0.9233009219169617,0.2834659814834595,0.2348547875881195,0.2170674353837967,0.201476588845253,0.18945878744125366,0.18028363585472107,0.17302300035953522,0.16793236136436462,0.16556333005428314,0.16122253239154816,0.18070276081562042,0.171706885099411,0.15611669421195984,0.1463724970817566,0.14463792741298676,0.13290727138519287,0.13123492896556854,0.10938780009746552,0.10892588645219803,0.09832924604415894,0.09930917620658875,0.09621065855026245,0.0764094814658165,0.0641791969537735,0.07663074135780334,0.0719917044043541,0.07194150984287262,0.0540461391210556,0.04732454940676689,0.055065955966711044,0.05054071545600891,0.05347783491015434,0.0660429373383522,0.05469962954521179,0.04575354605913162,0.04141872748732567,0.04551559314131737,0.03562431037425995,0.03828781843185425,0.03773294761776924,0.04130396991968155,0.04208811745047569,0.04164469614624977,0.04063074290752411,0.04370780289173126,0.037172719836235046,0.0469881072640419,0.04158938303589821,0.04758680239319801,0.039527054876089096,0.03629925474524498,0.033271752297878265,0.03411996737122536,0.03378825634717941,0.032527294009923935,0.03454466909170151,0.037867698818445206,0.04126136004924774,0.03092360496520996,0.032178234308958054,0.03422834724187851,0.035987019538879395,0.03360047936439514,0.032628174871206284,0.03268784284591675,0.030004188418388367,0.02820727974176407,0.027241656556725502,0.030229371041059494,0.02626774273812771,0.01988977938890457,0.022509152069687843,0.032089486718177795,0.02819611318409443,0.026943787932395935,0.023177005350589752,0.026787947863340378,0.02987084910273552,0.03262864425778389,0.030744124203920364,0.033398378640413284,0.02515016868710518,0.024401884526014328,0.03149142116308212,0.031768158078193665,0.03162359446287155,0.02905092015862465,0.02356407791376114,0.024839185178279877,0.02744157984852791,0.021851176396012306,0.01995910331606865,0.03160475566983223,0.02682463824748993,0.02238299697637558,0.02120029926300049,0.025185324251651764,0.03227686509490013,0.026459526270627975,
mse,0.42173904180526733,0.024979572743177414,0.018181944265961647,0.01572467014193535,0.013715851120650768,0.01234559528529644,0.011203237809240818,0.010464437305927277,0.009868885390460491,0.009515919722616673,0.009147414937615395,0.01062832586467266,0.00978067610412836,0.008079336024820805,0.007200424559414387,0.006870641838759184,0.006195615045726299,0.005892141256481409,0.004332524258643389,0.004063230473548174,0.00329376757144928,0.003150052623823285,0.002868732437491417,0.0018486971966922283,0.0013455633306875825,0.0017437600763514638,0.0015692838933318853,0.0015813829377293587,0.0009080754243768752,0.0006946291541680694,0.0008903651614673436,0.0007661037379875779,0.0008642321336083114,0.001286908402107656,0.000876768259331584,0.0006096945144236088,0.0005333006847649813,0.000658215198200196,0.00039504311280325055,0.0004429273249115795,0.00043474731501191854,0.0005195991834625602,0.0005055343499407172,0.0005067952442914248,0.0004750021907966584,0.0005384121323004365,0.00040627041016705334,0.0006317219813354313,0.0004998153890483081,0.0006383971776813269,0.0004627927264664322,0.00036868228926323354,0.0003249536093790084,0.00035061981179751456,0.0003339419490657747,0.0003023282624781132,0.0003484244516585022,0.0004106416890863329,0.000482559553347528,0.00027883268194273114,0.00030207415693439543,0.0003313326742500067,0.00037173976306803524,0.00032474895124323666,0.00030928727937862277,0.0003053955442737788,0.00026727590011432767,0.00023514346685260534,0.00021487734920810908,0.00026117966626770794,0.00020505732391029596,0.00011914601782336831,0.00015200198686216027,0.0002994804526679218,0.0002318995975656435,0.000209009725949727,0.00016180446255020797,0.00021663379448000342,0.00026216162950731814,0.00029980367980897427,0.00027645673253573477,0.000318530248478055,0.00018723921675700694,0.0001802990591386333,0.00028402506723068655,0.00029227399500086904,0.00028517263126559556,0.00024337049399036914,0.0001628479512874037,0.00018537552386987954,0.00022169722069520503,0.00014544776058755815,0.00012143560888944194,0.00028653585468418896,0.00020644858886953443,0.00014541385462507606,0.00013217814557719976,0.00018729713337961584,0.0002949443587567657,0.00020139919070061296,
mae,0.3928332030773163,0.12060249596834183,0.09904664009809494,0.09187569469213486,0.08667566627264023,0.08169358968734741,0.07748106867074966,0.07425396144390106,0.07195567339658737,0.07070281356573105,0.06857863813638687,0.07761356979608536,0.07362068444490433,0.0664893090724945,0.06198260188102722,0.06118851155042648,0.05659143999218941,0.055426619946956635,0.04588477313518524,0.04615311324596405,0.04132140800356865,0.041789211332798004,0.040364570915699005,0.03229208663105965,0.026878299191594124,0.0324186235666275,0.03025517426431179,0.030425038188695908,0.02304721623659134,0.020095227286219597,0.023403294384479523,0.021426726132631302,0.022550737485289574,0.02861727774143219,0.022229798138141632,0.019425127655267715,0.017504550516605377,0.019246861338615417,0.014957554638385773,0.016114074736833572,0.01588294468820095,0.01730489730834961,0.017851252108812332,0.017519017681479454,0.01726585440337658,0.018318787217140198,0.01565227471292019,0.01965475268661976,0.01775616966187954,0.019739501178264618,0.01688339374959469,0.015111220069229603,0.013971724547445774,0.01423193421214819,0.014165477827191353,0.01364230364561081,0.014038139954209328,0.016005754470825195,0.016975805163383484,0.012755295261740685,0.013510205782949924,0.014559520408511162,0.01521985325962305,0.01441004779189825,0.01326794270426035,0.012959237210452557,0.012618019245564938,0.011735455133020878,0.011449409648776054,0.012723580934107304,0.01094028353691101,0.008413293398916721,0.0094393165782094,0.013064611703157425,0.011696730740368366,0.011435359716415405,0.009604066610336304,0.011337854899466038,0.012659361585974693,0.013998044654726982,0.012698317877948284,0.013621743768453598,0.010666055604815483,0.010224572382867336,0.013462148606777191,0.013261972926557064,0.012924155220389366,0.011985771358013153,0.009688292630016804,0.010357421822845936,0.011539164930582047,0.009142396971583366,0.008313595317304134,0.01285733561962843,0.011033735238015652,0.009254653938114643,0.008903038688004017,0.010613207705318928,0.013247840106487274,0.011009875684976578,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 288251    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 288252    
=================================================================
Total params: 576,503
Trainable params: 576,503
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 288,251
Trainable params: 288,251
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 288,252
Trainable params: 288,252
Non-trainable params: 0
_________________________________________________________________
