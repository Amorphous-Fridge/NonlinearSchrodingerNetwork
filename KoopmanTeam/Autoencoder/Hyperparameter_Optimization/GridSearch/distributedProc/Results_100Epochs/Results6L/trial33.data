2021-06-26
loss,0.620869517326355,0.23754046857357025,0.1930372267961502,0.14821551740169525,0.11620987951755524,0.09635135531425476,0.08851537853479385,0.08129500597715378,0.09919288009405136,0.09215812385082245,0.08720040321350098,0.07499372214078903,0.06990225613117218,0.05797024071216583,0.06104680523276329,0.05355525389313698,0.04892675578594208,0.0485287606716156,0.07065913826227188,0.05563469976186752,0.05718480050563812,0.056895337998867035,0.04778812453150749,0.052441034466028214,0.05156422033905983,0.045523982495069504,0.039444852620363235,0.04348326846957207,0.03888384997844696,0.049864765256643295,0.04092373326420784,0.03419477865099907,0.044746123254299164,0.0453583225607872,0.03990288823843002,0.03615214303135872,0.03293420374393463,0.03334565833210945,0.04512253776192665,0.04071167856454849,0.03435896709561348,0.033377617597579956,0.03153309226036072,0.030978333204984665,0.041188545525074005,0.034585919231176376,0.03258984163403511,0.028214462101459503,0.03126430884003639,0.035366181284189224,0.030823208391666412,0.035476475954055786,0.03228659927845001,0.029692940413951874,0.030003702268004417,0.02655332162976265,0.03185969218611717,0.033555079251527786,0.029141606763005257,0.02516682632267475,0.023676926270127296,0.026248281821608543,0.02755785547196865,0.026615425944328308,0.030202440917491913,0.035109471529722214,0.03156108036637306,0.030953608453273773,0.030057087540626526,0.02792087383568287,0.02644202671945095,0.025282295420765877,0.025719759985804558,0.025650115683674812,0.024647211655974388,0.027916382998228073,0.02984808012843132,0.029440762475132942,0.028069648891687393,0.025632396340370178,0.027001723647117615,0.02448652684688568,0.02086581289768219,0.025767752900719643,0.02923141047358513,0.02615003101527691,0.026516657322645187,0.022146182134747505,0.024817347526550293,0.023464174941182137,0.023766927421092987,0.02368171513080597,0.024926502257585526,0.029609978199005127,0.027424611151218414,0.023783380165696144,0.025233708322048187,0.02397945336997509,0.023925630375742912,0.022466206923127174,
mse,0.2065286487340927,0.019024090841412544,0.012231145985424519,0.007017314899712801,0.003940394148230553,0.0028292564675211906,0.002306875307112932,0.0020033898763358593,0.0028993594460189342,0.002447925740852952,0.0021862403955310583,0.001639657886698842,0.0014872318133711815,0.0009833549847826362,0.0010587443830445409,0.0008359469939023256,0.00070884422166273,0.0006872483063489199,0.0014111516065895557,0.000888604496140033,0.0009103287593461573,0.0009086807840503752,0.0006538812885992229,0.0007727299816906452,0.0007288395427167416,0.0005878554075025022,0.00045532878721132874,0.0005354152526706457,0.00042813000618480146,0.0006947918445803225,0.00047852471470832825,0.0003463311877567321,0.0005695582367479801,0.0005724301445297897,0.00045013875933364034,0.0003620551433414221,0.00030765729025006294,0.00034165586112067103,0.0005873907939530909,0.0004783382755704224,0.0003352662897668779,0.00032042968086898327,0.0002863951667677611,0.0002783983072731644,0.00046764584840275347,0.0003348267055116594,0.0003029287327080965,0.00023069157032296062,0.00027796856011264026,0.0003559850447345525,0.00027015875093638897,0.0003609093255363405,0.00029613313381560147,0.0002576537081040442,0.0002623754262458533,0.00021012005163356662,0.0002956760872621089,0.0003181945940013975,0.00024140372988767922,0.00018376759544480592,0.00016542425146326423,0.00019894806609954685,0.00021591948461718857,0.00020156841492280364,0.00026141133275814354,0.00033261769567616284,0.0002829010190907866,0.00027674713055603206,0.0002555527025833726,0.00022001922479830682,0.00019870931282639503,0.0001814486604416743,0.00018601333431433886,0.00018598948372527957,0.00017765672237146646,0.0002195080160163343,0.00024550023954361677,0.00024393698549829423,0.0002232474653283134,0.00018842265126295388,0.00020419928478077054,0.00016821832105051726,0.000128533472889103,0.00019572606834117323,0.00024250903516076505,0.00019431664259172976,0.0001964593684533611,0.00014280749019235373,0.00017566149472258985,0.0001605352881597355,0.00015775578503962606,0.00015930829977151006,0.0001776433055056259,0.00024204114743042737,0.00021477483096532524,0.00016458485333714634,0.0001797301520127803,0.00016079284250736237,0.00016208285524044186,0.0001446188980480656,
mae,0.2680583596229553,0.10843528062105179,0.08269629627466202,0.06354585289955139,0.04917241260409355,0.041473519057035446,0.03685995563864708,0.0352671779692173,0.043973203748464584,0.039267826825380325,0.036955151706933975,0.031662389636039734,0.02926994301378727,0.024833055213093758,0.025839803740382195,0.022713875398039818,0.020617973059415817,0.020543131977319717,0.03017354942858219,0.02404140681028366,0.02455153688788414,0.024006513878703117,0.020233744755387306,0.022491417825222015,0.022013939917087555,0.019022557884454727,0.016955263912677765,0.018222149461507797,0.016511937603354454,0.021203376352787018,0.017709385603666306,0.014862499199807644,0.01935957930982113,0.019285455346107483,0.017039775848388672,0.0161400455981493,0.014377537183463573,0.014289362356066704,0.019379595294594765,0.017762569710612297,0.014729554764926434,0.014055602252483368,0.013246782124042511,0.013361131772398949,0.01767057366669178,0.014995665289461613,0.013715221546590328,0.011689018458127975,0.013002238236367702,0.014710331335663795,0.013262293301522732,0.01493256725370884,0.013722125440835953,0.012573683634400368,0.012892942875623703,0.011146659031510353,0.013367346487939358,0.014623700641095638,0.012308030389249325,0.010709952563047409,0.010054084472358227,0.011198320426046848,0.011801003478467464,0.011311152949929237,0.012694226577877998,0.014713951386511326,0.013673525303602219,0.012818991206586361,0.012769217602908611,0.011730959638953209,0.01130980346351862,0.010614587925374508,0.0110178766772151,0.01077973935753107,0.010514690540730953,0.011790446937084198,0.012692924588918686,0.012380032800137997,0.0119674326851964,0.010881935246288776,0.011747343465685844,0.010528218932449818,0.008878008462488651,0.01118713989853859,0.012498842552304268,0.011173926293849945,0.01147544477134943,0.00945206731557846,0.010320975445210934,0.009774594567716122,0.01044795848429203,0.010231138207018375,0.010879202745854855,0.012576253153383732,0.011370589956641197,0.010080537758767605,0.010781390592455864,0.010237157344818115,0.010213599540293217,0.009629801847040653,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 83667     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 83668     
=================================================================
Total params: 167,335
Trainable params: 167,335
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 83,667
Trainable params: 83,667
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 83,668
Trainable params: 83,668
Non-trainable params: 0
_________________________________________________________________
