2021-06-26
loss,0.5042541027069092,0.3479233980178833,0.342702716588974,0.2609545588493347,0.2289547175168991,0.20652449131011963,0.14557351171970367,0.12256483733654022,0.090392105281353,0.0694182962179184,0.0807383805513382,0.06658819317817688,0.08112863451242447,0.08077079057693481,0.05065770074725151,0.06366869062185287,0.05401298403739929,0.053321585059165955,0.05924861878156662,0.05176433548331261,0.060772065073251724,0.046237848699092865,0.04914231225848198,0.0633787214756012,0.04441940784454346,0.04002108424901962,0.044349249452352524,0.03137511387467384,0.040491629391908646,0.04253043234348297,0.04579143598675728,0.051576633006334305,0.039711855351924896,0.045754946768283844,0.03618854656815529,0.04745851829648018,0.035943273454904556,0.02374655194580555,0.023797182366251945,0.02619774080812931,0.03853501006960869,0.03455963358283043,0.040490854531526566,0.04253612086176872,0.04058586061000824,0.034523434937000275,0.03695777431130409,0.0367361381649971,0.03255080804228783,0.039222847670316696,0.032992035150527954,0.03071206621825695,0.028115658089518547,0.028292454779148102,0.026509802788496017,0.026301037520170212,0.037887994199991226,0.03865010663866997,0.03537661209702492,0.034656137228012085,0.033779047429561615,0.02577577531337738,0.02178880199790001,0.019904501736164093,0.019451553001999855,0.02686954103410244,0.0326167531311512,0.03398119658231735,0.034811124205589294,0.029137171804904938,0.029697012156248093,0.031982921063899994,0.02958902157843113,0.033219292759895325,0.03151116520166397,0.02725961059331894,0.02260882593691349,0.031077958643436432,0.03221462666988373,0.029559405520558357,0.024264128878712654,0.021469516679644585,0.027482662349939346,0.027591533958911896,0.026289908215403557,0.0228309016674757,0.02578681893646717,0.027812303975224495,0.03235708177089691,0.03222397714853287,0.028723163530230522,0.026012707501649857,0.02785620652139187,0.029027264565229416,0.025159986689686775,0.017570016905665398,0.016548549756407738,0.020983345806598663,0.01906438171863556,0.01838517002761364,
mse,0.08920026570558548,0.03669334575533867,0.03584832698106766,0.02208857610821724,0.017711304128170013,0.012745345011353493,0.0063491035252809525,0.004476161673665047,0.0025379324797540903,0.0014797046314924955,0.0020965351723134518,0.001374086714349687,0.001941654714755714,0.001913906540721655,0.0007781441672705114,0.0011802848894149065,0.0008471847395412624,0.0008859509252943099,0.001048889011144638,0.0008280634647235274,0.0010789759689942002,0.0006359791732393205,0.0007310631335712969,0.0011119898408651352,0.0005878846859559417,0.0004884203663095832,0.0006082020699977875,0.0002848446602001786,0.0005094835651107132,0.0005329354316927493,0.0005933624343015254,0.0007492988370358944,0.0004556436324492097,0.0006026873597875237,0.00038916102494113147,0.0006428214255720377,0.00039982463931664824,0.00016123178647831082,0.00015967886429280043,0.00020893232431262732,0.0004112918395549059,0.000347103487001732,0.0004626713343895972,0.0005094199441373348,0.0004651613417081535,0.0003462771710474044,0.0003842904407065362,0.0003854423703160137,0.0002978225238621235,0.00042508181650191545,0.0003148217510897666,0.00026977481320500374,0.0002264677023049444,0.00023413174494635314,0.00020976117230020463,0.00020208679779898375,0.00041020382195711136,0.0004339338338468224,0.00035616836976259947,0.0003346335142850876,0.00031555179157294333,0.00020061158284079283,0.00014233053661882877,0.0001160545289167203,0.00011031093163182959,0.00020888735889457166,0.0002977499971166253,0.0003186716930940747,0.0003309474268462509,0.00024780246894806623,0.00024988470249809325,0.0002835395571310073,0.00024992594262585044,0.0003045993798878044,0.00027766215498559177,0.00021169123647268862,0.00015021591389086097,0.000279890198726207,0.00028346525505185127,0.00024504962493665516,0.00017071310139726847,0.00013241726264823228,0.0002262107445858419,0.00022031221305951476,0.0001938975474331528,0.00014553178334608674,0.00019500197959132493,0.0002235379652120173,0.000294165889499709,0.0002862296823877841,0.00022512100986205041,0.00019454389985185117,0.000217336171772331,0.00023725708888377994,0.00018008938059210777,9.311257599620149e-05,8.28468328109011e-05,0.00012729021545965225,0.00010705813474487513,9.881850564852357e-05,
mae,0.21683572232723236,0.15321965515613556,0.15218405425548553,0.10978789627552032,0.09829900413751602,0.0886598601937294,0.06133872643113136,0.052079442888498306,0.03813793510198593,0.029475346207618713,0.034482307732105255,0.02779650129377842,0.03355802223086357,0.03462367132306099,0.021325454115867615,0.02690129354596138,0.02193097025156021,0.02251589111983776,0.024725422263145447,0.022534316405653954,0.026308495551347733,0.019216949120163918,0.02094271406531334,0.02750512585043907,0.019134949892759323,0.016883093863725662,0.01867864839732647,0.013183152303099632,0.017321422696113586,0.01765133999288082,0.019594747573137283,0.021725859493017197,0.01713891327381134,0.019857637584209442,0.015250438824295998,0.019614433869719505,0.015646593645215034,0.010140124708414078,0.010138698853552341,0.010989386588335037,0.016036488115787506,0.01445360854268074,0.016997143626213074,0.01825493574142456,0.017143692821264267,0.014463425613939762,0.015442023053765297,0.015529020689427853,0.013734165579080582,0.016629209741950035,0.013688572682440281,0.013064776547253132,0.0121009461581707,0.011958467774093151,0.011174317449331284,0.010922260582447052,0.0156130101531744,0.016454612836241722,0.014857253059744835,0.014753230847418308,0.014302928000688553,0.01076947059482336,0.009339861571788788,0.008506761863827705,0.008416629396378994,0.0113211153075099,0.013668861240148544,0.014358852989971638,0.015183675102889538,0.012291091494262218,0.012657275423407555,0.013287477195262909,0.012274159118533134,0.01424633339047432,0.013492613099515438,0.011465455405414104,0.00963575392961502,0.012790393084287643,0.013988180086016655,0.013352805748581886,0.010139589197933674,0.009047594852745533,0.011791926808655262,0.011759375222027302,0.01104433462023735,0.009581529535353184,0.010861147195100784,0.011625674553215504,0.013660034164786339,0.01341559924185276,0.012551763094961643,0.011199483647942543,0.011768677271902561,0.012141240760684013,0.01034736167639494,0.007412131410092115,0.007012937217950821,0.008819402195513248,0.008036707527935505,0.007691281847655773,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 23291     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 23292     
=================================================================
Total params: 46,583
Trainable params: 46,583
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 23,291
Trainable params: 23,291
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 23,292
Trainable params: 23,292
Non-trainable params: 0
_________________________________________________________________
