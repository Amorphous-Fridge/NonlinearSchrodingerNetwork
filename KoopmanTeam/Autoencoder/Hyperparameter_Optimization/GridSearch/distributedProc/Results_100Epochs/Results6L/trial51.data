2021-06-26
loss,0.848767876625061,0.3643699586391449,0.3613567352294922,0.3556986153125763,0.34617847204208374,0.36064955592155457,0.2636980414390564,0.2474638819694519,0.21764910221099854,0.20548078417778015,0.20794053375720978,0.18786858022212982,0.17722177505493164,0.1758563369512558,0.18201498687267303,0.20197486877441406,0.17727233469486237,0.17181436717510223,0.17176838219165802,0.17244286835193634,0.15730342268943787,0.1677830070257187,0.1556408554315567,0.14358209073543549,0.1544819325208664,0.14794644713401794,0.152143195271492,0.14872144162654877,0.1529548466205597,0.14176174998283386,0.13980740308761597,0.14248615503311157,0.1327773928642273,0.1363070160150528,0.13165467977523804,0.13669666647911072,0.14431941509246826,0.13491004705429077,0.1298365443944931,0.12964454293251038,0.13576284050941467,0.14579924941062927,0.1341427117586136,0.11984895914793015,0.1294618844985962,0.1373470276594162,0.12266485393047333,0.11947831511497498,0.11682676523923874,0.10478731244802475,0.10326457023620605,0.09454154223203659,0.08710654079914093,0.09562063962221146,0.07986035943031311,0.08757809549570084,0.0817897766828537,0.08392507582902908,0.08153771609067917,0.08000645786523819,0.07035588473081589,0.06781557202339172,0.05846581608057022,0.07200244069099426,0.06987303495407104,0.05462614446878433,0.059277333319187164,0.05735901743173599,0.05881005898118019,0.05217643827199936,0.045970525592565536,0.04761723056435585,0.04687966778874397,0.04683387279510498,0.040003158152103424,0.05766013264656067,0.05097552761435509,0.04338111728429794,0.04104241728782654,0.034046608954668045,0.047997429966926575,0.037170592695474625,0.03586331382393837,0.037926625460386276,0.034962814301252365,0.0418563187122345,0.03633879870176315,0.040430959314107895,0.03859560936689377,0.031118836253881454,0.04116086661815643,0.037188638001680374,0.042316608130931854,0.03692975640296936,0.038249459117650986,0.03634590655565262,0.03144553303718567,0.029619725421071053,0.040148306638002396,0.03509821742773056,
mse,0.35847681760787964,0.038921549916267395,0.03818386048078537,0.037172120064496994,0.03547815605998039,0.03853470832109451,0.02157214842736721,0.019417494535446167,0.015696967020630836,0.01423878874629736,0.01422164123505354,0.012326818890869617,0.011234278790652752,0.010896359570324421,0.011208716779947281,0.013107639737427235,0.010626737028360367,0.010142603889107704,0.010199720971286297,0.010053821839392185,0.008871312253177166,0.009681401774287224,0.008689220063388348,0.007760282140225172,0.008552375249564648,0.007908990606665611,0.0082175862044096,0.007907576858997345,0.008286607451736927,0.007425280753523111,0.007156467530876398,0.007338440977036953,0.0066283829510211945,0.006863273214548826,0.006587773561477661,0.006846901960670948,0.0073124803602695465,0.006719718687236309,0.006310895550996065,0.006225524004548788,0.006542580667883158,0.007084394805133343,0.006393343675881624,0.00528717041015625,0.005628611426800489,0.006113660521805286,0.005085750017315149,0.0048004076816141605,0.004704203922301531,0.003778552170842886,0.0037404512986540794,0.003242106642574072,0.002868833253160119,0.0033696473110467196,0.0024856836535036564,0.0027462404686957598,0.002407117746770382,0.002457218011841178,0.0023902482353150845,0.0023554693907499313,0.0018872185610234737,0.0016487821703776717,0.0012442846782505512,0.0016550904838368297,0.0016282483702525496,0.0009682823438197374,0.0011189297074452043,0.0010713160736486316,0.0010779347503557801,0.000854687939863652,0.000707372440956533,0.0007015967858023942,0.0006698602228425443,0.0006534291314892471,0.0004967197892256081,0.0009985434589907527,0.000778860819991678,0.0005549697089008987,0.0004989775479771197,0.00035194019437767565,0.0006828560726717114,0.00040448998333886266,0.00038209822378121316,0.00042082942673005164,0.00036508802440948784,0.0005083975265733898,0.000389898574212566,0.0004954166361130774,0.00043182610534131527,0.0002934644289780408,0.0005125364987179637,0.000406917417421937,0.0005215391283854842,0.0003874608955811709,0.00041277569835074246,0.0003858094569295645,0.0002981818688567728,0.0002578283892944455,0.00045024201972410083,0.0003499711165204644,
mae,0.36608657240867615,0.1545862853527069,0.15439195930957794,0.1537202149629593,0.14917562901973724,0.15599490702152252,0.11214154213666916,0.10621745139360428,0.09265219420194626,0.0885053351521492,0.0893949568271637,0.08107855916023254,0.07645110785961151,0.07580528408288956,0.07828354090452194,0.08736895769834518,0.07571181654930115,0.07375159114599228,0.07340818643569946,0.07354782521724701,0.06702464818954468,0.07188323140144348,0.06614292412996292,0.0608326718211174,0.06574869900941849,0.06280531734228134,0.06440158188343048,0.06296569108963013,0.06457313895225525,0.05994854494929314,0.059276387095451355,0.06039021909236908,0.055698152631521225,0.05729292705655098,0.05550260841846466,0.057648658752441406,0.06123654544353485,0.0566987469792366,0.054265618324279785,0.054390568286180496,0.05723947659134865,0.061773091554641724,0.05639919638633728,0.04984863102436066,0.054351214319467545,0.05833438038825989,0.0519273616373539,0.05089181289076805,0.04926912859082222,0.044022463262081146,0.043487124145030975,0.03957381471991539,0.03702285513281822,0.04033448547124863,0.03337555378675461,0.03713291883468628,0.03442578762769699,0.03599206730723381,0.03422893211245537,0.0344216488301754,0.030074335634708405,0.029182331636548042,0.02497781440615654,0.03050064854323864,0.029686426743865013,0.023182790726423264,0.025049079209566116,0.024755820631980896,0.024640442803502083,0.021921858191490173,0.019358206540346146,0.020232653245329857,0.02000739797949791,0.019900955259799957,0.017017479985952377,0.02469039522111416,0.021763743832707405,0.018379531800746918,0.01738862693309784,0.014409178867936134,0.020741596817970276,0.015843801200389862,0.015215273015201092,0.015964966267347336,0.014857398346066475,0.01791015826165676,0.015380935743451118,0.01667369343340397,0.016331568360328674,0.013113796710968018,0.017460105940699577,0.01575523056089878,0.017578011378645897,0.015864353626966476,0.016007384285330772,0.01543432381004095,0.01335098035633564,0.012570548802614212,0.016722753643989563,0.014560066163539886,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 135027    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 135028    
=================================================================
Total params: 270,055
Trainable params: 270,055
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 135,027
Trainable params: 135,027
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 135,028
Trainable params: 135,028
Non-trainable params: 0
_________________________________________________________________
