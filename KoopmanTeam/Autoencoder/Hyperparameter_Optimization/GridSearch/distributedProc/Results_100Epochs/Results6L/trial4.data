2021-06-26
loss,0.42688819766044617,0.19172489643096924,0.12721432745456696,0.1057744026184082,0.08932988345623016,0.08615262806415558,0.09027011692523956,0.10218603163957596,0.07437116652727127,0.06257253885269165,0.06846605241298676,0.09202347695827484,0.07387213408946991,0.07099806517362595,0.06528967618942261,0.06120545044541359,0.058607615530490875,0.05283808335661888,0.07648499310016632,0.048264846205711365,0.04107976332306862,0.039826780557632446,0.03934764117002487,0.038081809878349304,0.037480663508176804,0.03690388426184654,0.0363256111741066,0.03553645312786102,0.035176847130060196,0.034545063972473145,0.03391231968998909,0.03343116492033005,0.03371746093034744,0.03291626274585724,0.03287136182188988,0.03201978653669357,0.031779590994119644,0.031427592039108276,0.03145013749599457,0.031019536778330803,0.04010937735438347,0.05052847042679787,0.05245700851082802,0.048081498593091965,0.04572014883160591,0.04330132156610489,0.038409825414419174,0.03929708153009415,0.042262326925992966,0.04116638004779816,0.039922770112752914,0.03805715590715408,0.03799526393413544,0.05497148633003235,0.052499670535326004,0.047390345484018326,0.04485386237502098,0.04224548861384392,0.040278397500514984,0.03806188330054283,0.03564176708459854,0.033094488084316254,0.031174734234809875,0.029526513069868088,0.02812887169420719,0.028061730787158012,0.03780943900346756,0.041651371866464615,0.03842436149716377,0.03649396449327469,0.034981437027454376,0.03353234380483627,0.032654713839292526,0.03177278861403465,0.030946308746933937,0.03358376771211624,0.03578706458210945,0.025457333773374557,0.02410578541457653,0.023230383172631264,0.022216666489839554,0.02201564610004425,0.02155326120555401,0.0212912205606699,0.02100702002644539,0.02105257473886013,0.02427813783288002,0.032890114933252335,0.020949656143784523,0.029116248711943626,0.03258795291185379,0.035122815519571304,0.03229507803916931,0.030964000150561333,0.029810447245836258,0.02892283722758293,0.0386122427880764,0.0402446985244751,0.0360771045088768,0.036392636597156525,
mse,0.08345524966716766,0.012272346764802933,0.0047789644449949265,0.003422772977501154,0.0024008522741496563,0.0022692554630339146,0.002624026732519269,0.003009807551279664,0.0016638757660984993,0.0011571532813832164,0.001436189515516162,0.0023917921353131533,0.0015954856062307954,0.0014230929082259536,0.001189669594168663,0.0010426458902657032,0.0009864778257906437,0.0008116107201203704,0.001740297069773078,0.0007211345946416259,0.0004950452712364495,0.00045741500798612833,0.00044431048445403576,0.000418367882957682,0.0004017598112113774,0.00038651895010843873,0.00037506953231059015,0.00035953125916421413,0.00034839543513953686,0.0003356844827067107,0.00032336480217054486,0.00031605380354449153,0.00032177194952964783,0.00030717570916749537,0.0003042552270926535,0.0002891876210924238,0.0002830676967278123,0.00027823107666336,0.00027827901067212224,0.0002713446447160095,0.0005141220754012465,0.0007604373386129737,0.0007748930365778506,0.0006634171586483717,0.000588009599596262,0.0005319446790963411,0.00042350005242042243,0.0004431873676367104,0.0005028519663028419,0.00047754737897776067,0.00044314522529020905,0.00042163970647379756,0.00040268138400278986,0.0008926750742830336,0.0007679962436668575,0.0006226995610632002,0.0005503499996848404,0.000491482496727258,0.00044960647937841713,0.00040260780951939523,0.00035384506918489933,0.00030727131525054574,0.00027308284188620746,0.0002455128123983741,0.00022322667064145207,0.00022988599084783345,0.0004375847929622978,0.0004690767964348197,0.00040190250729210675,0.0003648943966254592,0.00033656685263849795,0.00031121534993872046,0.0002960277197416872,0.0002808740537147969,0.00026695634005591273,0.0003373487270437181,0.000432768341852352,0.00018333207117393613,0.00016561977099627256,0.00015449099009856582,0.0001430727425031364,0.0001399972679791972,0.000132785746245645,0.00012810232874471694,0.0001242740108864382,0.00012458802666515112,0.00018066371558234096,0.00031977708567865193,0.00013135926565155387,0.0002549880591686815,0.00029907067073509097,0.00033507394255138934,0.0002820971712935716,0.00025986816035583615,0.00024167522497009486,0.00022827868815511465,0.0004359307058621198,0.00047834115684963763,0.0003739128587767482,0.00036547554191201925,
mae,0.17838844656944275,0.07993362098932266,0.05405620113015175,0.04485553875565529,0.03811967000365257,0.036960069090127945,0.038449786603450775,0.043822113424539566,0.03160768374800682,0.026445303112268448,0.028953634202480316,0.03938639909029007,0.03164936602115631,0.030705256387591362,0.028186781331896782,0.026284635066986084,0.024948211386799812,0.022831173613667488,0.0329599529504776,0.020609719678759575,0.01748534105718136,0.01681606099009514,0.016579529270529747,0.016082074493169785,0.015750674530863762,0.015549871139228344,0.015277343802154064,0.015017684549093246,0.01472189649939537,0.014568250626325607,0.014287613332271576,0.014124159701168537,0.01425351481884718,0.013952799141407013,0.013942756690084934,0.013523334637284279,0.01373218558728695,0.013449834659695625,0.013468479737639427,0.013095919974148273,0.016780076548457146,0.021906079724431038,0.022718653082847595,0.020550362765789032,0.019450567662715912,0.01853255368769169,0.016416437923908234,0.016614878550171852,0.017981622368097305,0.0174043457955122,0.016946764662861824,0.016121845692396164,0.016182539984583855,0.023985622450709343,0.022751959040760994,0.020609423518180847,0.01951211877167225,0.018278442323207855,0.017287515103816986,0.01658521592617035,0.01600085198879242,0.014801079407334328,0.013788044452667236,0.012875217013061047,0.01211843453347683,0.01190274115651846,0.016173336654901505,0.018266046419739723,0.01683111861348152,0.01591786928474903,0.015169067308306694,0.014524724334478378,0.014078058302402496,0.013565639033913612,0.013034445233643055,0.014231077395379543,0.015357065945863724,0.011262071318924427,0.010646088980138302,0.010213930159807205,0.00966325867921114,0.009617910720407963,0.009311828762292862,0.00915724877268076,0.008922887034714222,0.009013067930936813,0.01029756385833025,0.014006899669766426,0.008944525383412838,0.012365558184683323,0.01387412566691637,0.014990963973104954,0.01382903940975666,0.013245519250631332,0.012729087844491005,0.012255310080945492,0.01603792980313301,0.0179696474224329,0.01580149680376053,0.015944648534059525,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 8971      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 8972      
=================================================================
Total params: 17,943
Trainable params: 17,943
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 8,971
Trainable params: 8,971
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 8,972
Trainable params: 8,972
Non-trainable params: 0
_________________________________________________________________
