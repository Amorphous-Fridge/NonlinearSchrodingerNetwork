2021-06-26
loss,3.235398292541504,3.131904363632202,3.127262592315674,1.4320448637008667,0.29425904154777527,0.24967703223228455,0.24452970921993256,0.23762620985507965,0.21190257370471954,0.17363962531089783,0.13200688362121582,0.15136492252349854,0.11503641307353973,0.08853615075349808,0.07176963984966278,0.0685720443725586,0.06474967300891876,0.06118081510066986,0.05784187838435173,0.055004432797431946,0.05345477536320686,0.05715667083859444,0.058875445276498795,0.08518027514219284,0.07385437935590744,0.058311399072408676,0.042865946888923645,0.05153309926390648,0.04886883124709129,0.04500356316566467,0.04282032325863838,0.03560895845293999,0.06349322199821472,0.04428347945213318,0.03400544077157974,0.04058266058564186,0.03259137272834778,0.05183789134025574,0.05619440972805023,0.05115997791290283,0.030239129438996315,0.034326985478401184,0.041624102741479874,0.035653963685035706,0.028352726250886917,0.034923989325761795,0.04710131511092186,0.046806517988443375,0.05311788246035576,0.046475850045681,0.041798509657382965,0.0315215177834034,0.035380471497774124,0.032811474055051804,0.038429368287324905,0.04525502771139145,0.03865274786949158,0.04169932007789612,0.028967298567295074,0.0349748395383358,0.042912837117910385,0.04364272952079773,0.03977403789758682,0.02767828479409218,0.041820406913757324,0.04352877289056778,0.03935900330543518,0.036694616079330444,0.037681788206100464,0.037041813135147095,0.037180762737989426,0.03342517092823982,0.037116166204214096,0.03135494142770767,0.025821100920438766,0.03136296197772026,0.029064176604151726,0.023128673434257507,0.03693103417754173,0.03535275533795357,0.025859175249934196,0.036926258355379105,0.03584609180688858,0.03666692227125168,0.031294096261262894,0.02683369629085064,0.02830379642546177,0.029137510806322098,0.032209061086177826,0.03846422955393791,0.034548964351415634,0.02906961739063263,0.02873486466705799,0.028188303112983704,0.0302721094340086,0.035013798624277115,0.03567473590373993,0.029094533994793892,0.021736282855272293,0.020399587228894234,
mse,2.74318790435791,2.4615461826324463,2.454430341720581,0.8349762558937073,0.027115482836961746,0.02081996388733387,0.02011067233979702,0.019252698868513107,0.01516791619360447,0.009253062307834625,0.005117558408528566,0.007004363462328911,0.003844313556328416,0.002381581347435713,0.0015824144938960671,0.0014629666693508625,0.0012782752746716142,0.0011569245252758265,0.0010311354417353868,0.0009164238581433892,0.0008947529131546617,0.0009860341669991612,0.0011040838435292244,0.0020687663927674294,0.001535204704850912,0.001052830833941698,0.0005961366114206612,0.0008764980011619627,0.000762001727707684,0.0006275977357290685,0.0005637579597532749,0.00038502327515743673,0.0011670526582747698,0.0006099320598877966,0.00035914641921408474,0.0004917226615361869,0.00032909263973124325,0.0007953023305162787,0.0009336196817457676,0.0007753894315101206,0.0002841901732608676,0.00036491849459707737,0.00052318797679618,0.00040237774373963475,0.00024689233396202326,0.00039234678843058646,0.0006528041558340192,0.0006743593257851899,0.0008075019577518106,0.0006178473704494536,0.0005235305870883167,0.00030869501642882824,0.0003963295603170991,0.0003298390656709671,0.00044959047227166593,0.0005966472672298551,0.0004416888114064932,0.0005058981478214264,0.00027392050833441317,0.0003894107649102807,0.00054039346287027,0.0005484351422637701,0.0004648679168894887,0.0002379025681875646,0.0005210602539591491,0.0005314662121236324,0.00044817462912760675,0.00038949030567891896,0.0004232907376717776,0.0003998180909547955,0.0004022597277071327,0.0003407872573006898,0.0003967137890867889,0.0002997559786308557,0.0002019756066147238,0.0003001221048180014,0.0002596616977825761,0.00017121335258707404,0.00039877911331132054,0.0003700146044138819,0.0002183544565923512,0.0003967816010117531,0.00037189931026659906,0.00037902206531725824,0.00028707541059702635,0.0002214891283074394,0.00024669492268003523,0.0002556781400926411,0.00030897874967195094,0.0004182774282526225,0.0003443573659751564,0.0002576512051746249,0.00024436810053884983,0.00023557659005746245,0.00027648601098917425,0.000356379896402359,0.00035996257793158293,0.00024938781280070543,0.00014879871741868556,0.00013224169379100204,
mae,1.2548025846481323,1.1626932621002197,1.1493966579437256,0.5581263899803162,0.12728092074394226,0.10768924653530121,0.10505513846874237,0.10158883035182953,0.0920921117067337,0.07484641671180725,0.05658840015530586,0.06363306194543839,0.04894835129380226,0.03764623776078224,0.030667744576931,0.02933831512928009,0.02764110639691353,0.026128318160772324,0.024534858763217926,0.023490363731980324,0.022750047966837883,0.024597741663455963,0.025033047422766685,0.036445945501327515,0.03168405592441559,0.02488875202834606,0.018154483288526535,0.021913539618253708,0.021075591444969177,0.01926938258111477,0.018239207565784454,0.015085672028362751,0.026890065521001816,0.018765278160572052,0.014402142725884914,0.017404884099960327,0.013839220628142357,0.021836696192622185,0.02425333298742771,0.02201399952173233,0.01279862504452467,0.014688413590192795,0.01791144162416458,0.015276403166353703,0.011994822882115841,0.01509142853319645,0.02028401382267475,0.01975669339299202,0.022673621773719788,0.019640767946839333,0.01769065111875534,0.0134971272200346,0.014902603812515736,0.01396880391985178,0.016532018780708313,0.019472606480121613,0.01648559421300888,0.01791408099234104,0.012241902761161327,0.015074877999722958,0.018480991944670677,0.018660414963960648,0.016967125236988068,0.011698155663907528,0.0180363766849041,0.0186721570789814,0.016619093716144562,0.015732796862721443,0.016442226245999336,0.01569554954767227,0.016000136733055115,0.014087297953665257,0.015966258943080902,0.013399023562669754,0.01097113173455,0.0133577361702919,0.012438450939953327,0.009886336512863636,0.015733350068330765,0.01506761834025383,0.010949566029012203,0.015514682978391647,0.015285513363778591,0.015888484194874763,0.01370201911777258,0.011552499607205391,0.011975577101111412,0.012367875315248966,0.013931375928223133,0.016388801857829094,0.014685661531984806,0.01266565453261137,0.012282089330255985,0.011985783465206623,0.01293199136853218,0.014882896095514297,0.01490478590130806,0.012495960108935833,0.00919595267623663,0.00864503812044859,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 288251    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 288252    
=================================================================
Total params: 576,503
Trainable params: 576,503
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                8208      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 288,251
Trainable params: 288,251
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 288,252
Trainable params: 288,252
Non-trainable params: 0
_________________________________________________________________
