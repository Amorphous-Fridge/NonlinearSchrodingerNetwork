2021-06-26
loss,3.6344869136810303,2.173759937286377,0.49981871247291565,0.45074379444122314,0.34288185834884644,0.3346419632434845,0.3262828588485718,0.32549065351486206,0.3220553994178772,0.3145864009857178,0.3121007978916168,0.30525097250938416,0.2710293233394623,0.2192467451095581,0.19808784127235413,0.20002153515815735,0.17812572419643402,0.18560396134853363,0.19732189178466797,0.18430446088314056,0.1687546968460083,0.1444844752550125,0.12924818694591522,0.12263444066047668,0.09518902748823166,0.08822759985923767,0.09505688399076462,0.07342937588691711,0.08928737789392471,0.0755716934800148,0.07151608914136887,0.07059072703123093,0.08041156083345413,0.07119670510292053,0.06771021336317062,0.05227614939212799,0.04990190640091896,0.04558975249528885,0.049828339368104935,0.042385511100292206,0.0526818186044693,0.04703674837946892,0.05138855054974556,0.045732636004686356,0.03854775056242943,0.04406806454062462,0.051468461751937866,0.04693473502993584,0.039309319108724594,0.034840889275074005,0.04509113356471062,0.03993244096636772,0.03732873499393463,0.04265996813774109,0.04367106407880783,0.035563353449106216,0.04111311957240105,0.043971046805381775,0.03442090004682541,0.0342266783118248,0.04104321822524071,0.04156436771154404,0.03489627689123154,0.031040752306580544,0.03409392759203911,0.035789359360933304,0.04586289823055267,0.03786548972129822,0.035349391400814056,0.03221428766846657,0.030246881768107414,0.02954121306538582,0.03458785265684128,0.030210191383957863,0.0350240133702755,0.033392395824193954,0.03310711681842804,0.03823250159621239,0.03949590027332306,0.032075390219688416,0.034357134252786636,0.033812712877988815,0.02974223904311657,0.028973188251256943,0.03240581601858139,0.03430449590086937,0.031019553542137146,0.03341711685061455,0.03583001717925072,0.03044791705906391,0.02873857319355011,0.02833656780421734,0.03153051435947418,0.03187774121761322,0.026446469128131866,0.026927292346954346,0.035025302320718765,0.025672707706689835,0.026728110387921333,0.029098449274897575,
mse,3.9714713096618652,1.2836127281188965,0.07547347992658615,0.061358608305454254,0.03549610823392868,0.033970192074775696,0.032368697226047516,0.0319066196680069,0.03108486346900463,0.029731620103120804,0.029389185830950737,0.027960706502199173,0.022075297310948372,0.014775089919567108,0.012365839444100857,0.012557425536215305,0.010306932963430882,0.010786443017423153,0.011952688917517662,0.01011155266314745,0.008325394243001938,0.006119221914559603,0.004896657541394234,0.004587557632476091,0.002668587025254965,0.0022389295045286417,0.0026132133789360523,0.001574853202328086,0.0023995665833353996,0.0016991792945191264,0.0014843851095065475,0.0014311959967017174,0.0018959238659590483,0.001494857482612133,0.001311854226514697,0.0007774465484544635,0.0007294213282875717,0.0006198225310072303,0.0007121747476048768,0.0005264418432489038,0.0008395378827117383,0.0006533063133247197,0.0007794497068971395,0.0006230584112927318,0.0004325573972892016,0.0005631949752569199,0.0007633189670741558,0.0006356170633807778,0.00044635418453253806,0.0003559440665412694,0.0005845495616085827,0.0004577013896778226,0.00040659509249962866,0.0005271057598292828,0.0005523410509340465,0.0003777589008677751,0.0004886686219833791,0.0005674583371728659,0.0003504083724692464,0.00034797925036400557,0.00048588457866571844,0.0005047079757787287,0.00035631441278383136,0.0002843762922566384,0.00033703178633004427,0.00038598812534473836,0.0006439232965931296,0.000417770555941388,0.0003610158455558121,0.00030593210249207914,0.00027090104413218796,0.0002573939273133874,0.0003438839048612863,0.0002716448507271707,0.0003761973639484495,0.0003274373593740165,0.0003242667007725686,0.0004141146200709045,0.0004531955346465111,0.00030865787994116545,0.00034539977787062526,0.0003362606221344322,0.00025808371719904244,0.00025538678164593875,0.00032178816036321223,0.0003532978007569909,0.0002903765416704118,0.00032930809538811445,0.0003764787979889661,0.0002687511732801795,0.0002399520599283278,0.00023314770078286529,0.00029399082995951176,0.000298170605674386,0.00020927416335325688,0.000214220883208327,0.0003606091777328402,0.00019919505575671792,0.00021276736515574157,0.0002495297521818429,
mae,1.5825471878051758,0.8243298530578613,0.21656405925750732,0.19715920090675354,0.15019682049751282,0.1451832503080368,0.1401238888502121,0.13986892998218536,0.13883903622627258,0.135747492313385,0.1345333606004715,0.1311226785182953,0.11649343371391296,0.0936841070652008,0.08486446738243103,0.08574379980564117,0.07627905160188675,0.0797748789191246,0.08444565534591675,0.07908734679222107,0.07187074422836304,0.0613793283700943,0.055000387132167816,0.052933916449546814,0.04087972268462181,0.0378512367606163,0.040875133126974106,0.031230367720127106,0.038092028349637985,0.0321478396654129,0.030381863936781883,0.03046374022960663,0.03503011539578438,0.030217282474040985,0.028638049960136414,0.022368526086211205,0.021429643034934998,0.019417138770222664,0.02124772034585476,0.018084995448589325,0.02251075953245163,0.02014767937362194,0.0222257561981678,0.01963082142174244,0.0165173951536417,0.018789909780025482,0.021804995834827423,0.020301025360822678,0.016685200855135918,0.014902403578162193,0.019295286387205124,0.0170424934476614,0.015884077176451683,0.018107300624251366,0.018651578575372696,0.015308891423046589,0.017627442255616188,0.0188966765999794,0.01469370350241661,0.014527939260005951,0.01745312660932541,0.017871864140033722,0.014799857512116432,0.013231338001787663,0.014450861141085625,0.015403291210532188,0.019770989194512367,0.016161032021045685,0.015048372559249401,0.013664902187883854,0.012904826551675797,0.012547309510409832,0.014739645645022392,0.012872814200818539,0.015128287486732006,0.014180567115545273,0.014179123565554619,0.016413187608122826,0.016919730231165886,0.013712945394217968,0.014758405275642872,0.014428623951971531,0.012713207863271236,0.012275861576199532,0.01393792312592268,0.014717783778905869,0.01312881987541914,0.014296905137598515,0.015395645052194595,0.013033470138907433,0.012329675257205963,0.012130348943173885,0.013564521446824074,0.013576716184616089,0.011159632354974747,0.011486384086310863,0.015166282653808594,0.010887817479670048,0.011454190127551556,0.012450906448066235,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 532083    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 532084    
=================================================================
Total params: 1,064,167
Trainable params: 1,064,167
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 532,083
Trainable params: 532,083
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 532,084
Trainable params: 532,084
Non-trainable params: 0
_________________________________________________________________
