2021-06-26
loss,2.1849663257598877,1.0520055294036865,0.37279725074768066,0.3519536554813385,0.34593504667282104,0.32757365703582764,0.32852867245674133,0.3332141041755676,0.3404625356197357,0.3177100419998169,0.27915334701538086,0.2606610357761383,0.23391567170619965,0.21479374170303345,0.18058565258979797,0.1487346887588501,0.13648122549057007,0.11660093069076538,0.09523838013410568,0.08516021817922592,0.08612372726202011,0.08491206914186478,0.06606872379779816,0.062281712889671326,0.06883157789707184,0.059571657329797745,0.055170826613903046,0.05541013181209564,0.059184327721595764,0.05505753681063652,0.05070139467716217,0.05397302284836769,0.040343474596738815,0.04271460697054863,0.04286259785294533,0.05152398720383644,0.04290806129574776,0.04705185070633888,0.04623754322528839,0.04317033663392067,0.047714781016111374,0.0380500853061676,0.04396750405430794,0.04308412969112396,0.04015045613050461,0.03700443357229233,0.03363100066781044,0.03873703256249428,0.03804706409573555,0.03297095373272896,0.036305416375398636,0.044343795627355576,0.039253875613212585,0.034127216786146164,0.0372479185461998,0.03567452356219292,0.03611033782362938,0.03611651808023453,0.03709903731942177,0.03314046934247017,0.03758358955383301,0.03127549588680267,0.0315677747130394,0.03715168684720993,0.03180084377527237,0.029295455664396286,0.03143925219774246,0.02888955920934677,0.03155481442809105,0.03117857500910759,0.031286031007766724,0.02526746317744255,0.03343233838677406,0.03239249065518379,0.03182153403759003,0.030543716624379158,0.030755043029785156,0.026340186595916748,0.029635973274707794,0.026879625394940376,0.0253031924366951,0.027399754151701927,0.02682323008775711,0.029131419956684113,0.02371361292898655,0.030218567699193954,0.02932688035070896,0.028375037014484406,0.02880038507282734,0.025198636576533318,0.029934251680970192,0.02828541025519371,0.025914859026670456,0.026093337684869766,0.03005618043243885,0.02742418274283409,0.023350469768047333,0.025350680574774742,0.027523502707481384,0.02555006742477417,
mse,1.2744923830032349,0.3264358639717102,0.04102414473891258,0.03680809959769249,0.03546413779258728,0.03243086859583855,0.03241986408829689,0.033137496560811996,0.03477049246430397,0.030778612941503525,0.024715321138501167,0.021836791187524796,0.017350632697343826,0.014507480897009373,0.010563598945736885,0.007343100383877754,0.006054099183529615,0.004364540334790945,0.003022119402885437,0.0023407279513776302,0.0024005896411836147,0.0023450495209544897,0.0014130915515124798,0.0012780705001205206,0.001466119196265936,0.0010849623940885067,0.0009523542248643935,0.0009381548152305186,0.0011160901049152017,0.0009483074536547065,0.0008013092447072268,0.0009074226836673915,0.00048523995792493224,0.0005598812713287771,0.0005480794352479279,0.00078736332943663,0.0005573805538006127,0.0006632988806813955,0.0006307222647592425,0.0005659887683577836,0.000687976717017591,0.0004276268882676959,0.0005899935495108366,0.0005350314313545823,0.00047032651491463184,0.00041176725062541664,0.00034418367431499064,0.0004368627560324967,0.00042877753730863333,0.0003237329365219921,0.00039496083627454937,0.0005719047621823847,0.00045827467693015933,0.00034342045546509326,0.00041531643364578485,0.00038187901373021305,0.0003736918733920902,0.00037873376277275383,0.0004020801861770451,0.00032787176314741373,0.00041532967588864267,0.00028574265888892114,0.0002909986942540854,0.00040690458263270557,0.00029747490771114826,0.0002465587167534977,0.0002971412322949618,0.00024140540335793048,0.0002920148253906518,0.00029139043181203306,0.00028768341871909797,0.00019959319615736604,0.00032282862230204046,0.00030926373437978327,0.0003029719810001552,0.0002767010300885886,0.00028721289709210396,0.00020330979896243662,0.00026006539701484144,0.00021035199461039156,0.00019865889044012874,0.00022350843937601894,0.00021073513198643923,0.00026012741727754474,0.00016435548604931682,0.0002681930782273412,0.0002484935102984309,0.00022995662584435195,0.0002529703779146075,0.00018722956883721054,0.0002632805844768882,0.00024147106159944087,0.00019898227765224874,0.00019680277910083532,0.0002629288355819881,0.00021765631390735507,0.00016164200496859848,0.00018769409507513046,0.00022448686650022864,0.00018719916988629848,
mae,0.9197186231613159,0.40441280603408813,0.1641717404127121,0.15447193384170532,0.15082034468650818,0.14333844184875488,0.14373084902763367,0.1447632759809494,0.14795835316181183,0.13955260813236237,0.12398885935544968,0.11380700021982193,0.10025517642498016,0.09150665998458862,0.07711303979158401,0.06346460431814194,0.058066464960575104,0.050000425428152084,0.04091184213757515,0.03635299950838089,0.03671395778656006,0.03583431988954544,0.028139300644397736,0.02700955606997013,0.029373882338404655,0.025630582123994827,0.023607466369867325,0.023579420521855354,0.02520878054201603,0.02375783398747444,0.021406983956694603,0.022976268082857132,0.017146795988082886,0.018268832936882973,0.01818372868001461,0.02223866619169712,0.01795656979084015,0.020105557516217232,0.019562028348445892,0.018620366230607033,0.020511025562882423,0.01641443930566311,0.019085826352238655,0.018487313762307167,0.016985811293125153,0.015877075493335724,0.014340979047119617,0.0166372861713171,0.015926126390695572,0.01411417406052351,0.01549906749278307,0.0190749354660511,0.016663966700434685,0.014505919069051743,0.016048390418291092,0.015296662226319313,0.015519942156970501,0.015459973365068436,0.015832621604204178,0.01434087473899126,0.016272597014904022,0.013386250473558903,0.013477424159646034,0.015856275334954262,0.013493645936250687,0.012456743977963924,0.013496095314621925,0.012364060617983341,0.013530939817428589,0.013419722206890583,0.013488487340509892,0.010820753872394562,0.014348708093166351,0.01364925131201744,0.013873890973627567,0.013155382126569748,0.013136033900082111,0.011307232081890106,0.012893319129943848,0.011348494328558445,0.010791577398777008,0.011732334271073341,0.011515664868056774,0.012542660348117352,0.01022698637098074,0.013012620620429516,0.012619552202522755,0.01206082385033369,0.012285755947232246,0.010830002836883068,0.012848627753555775,0.011998954229056835,0.011139440350234509,0.011157379485666752,0.012991875410079956,0.011807589791715145,0.009891810826957226,0.01075602788478136,0.011841722764074802,0.010988881811499596,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 363275    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 363276    
=================================================================
Total params: 726,551
Trainable params: 726,551
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 363,275
Trainable params: 363,275
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 363,276
Trainable params: 363,276
Non-trainable params: 0
_________________________________________________________________
