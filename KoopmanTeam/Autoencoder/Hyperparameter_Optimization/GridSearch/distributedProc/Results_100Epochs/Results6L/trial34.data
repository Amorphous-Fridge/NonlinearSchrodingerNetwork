2021-06-26
loss,0.535778284072876,0.25106170773506165,0.24357149004936218,0.23821669816970825,0.23352089524269104,0.18516920506954193,0.17538972198963165,0.12017202377319336,0.13262583315372467,0.08718084543943405,0.08510914444923401,0.08158766478300095,0.06833115220069885,0.07001154869794846,0.05261802300810814,0.05371691659092903,0.05351000279188156,0.07371925562620163,0.058909863233566284,0.04992148280143738,0.0582093745470047,0.06516195088624954,0.04223350062966347,0.03744322061538696,0.03540812432765961,0.04439617693424225,0.03673585504293442,0.037959445267915726,0.04728582873940468,0.04697886109352112,0.037033308297395706,0.04546374827623367,0.04158712550997734,0.04772873967885971,0.03921797499060631,0.04765237867832184,0.041886039078235626,0.03893272578716278,0.03120054304599762,0.04136928915977478,0.0355406291782856,0.03796043246984482,0.04070513695478439,0.038373686373233795,0.03346376121044159,0.03564736619591713,0.02990010567009449,0.03385937213897705,0.027857020497322083,0.02662046253681183,0.03521083667874336,0.03499360382556915,0.03513023257255554,0.03631853312253952,0.03248203545808792,0.029443969950079918,0.03451763466000557,0.032549481838941574,0.029803119599819183,0.033257316797971725,0.029384519904851913,0.028759727254509926,0.028787782415747643,0.028842540457844734,0.03155888244509697,0.03217421472072601,0.027779974043369293,0.027164964005351067,0.026724912226200104,0.026968155056238174,0.03301660716533661,0.03132446110248566,0.027612023055553436,0.029655689373612404,0.026892254129052162,0.023334741592407227,0.02399633079767227,0.02569671720266342,0.030288074165582657,0.0275382399559021,0.022059880197048187,0.027582773938775063,0.02511020191013813,0.028992637991905212,0.02719350904226303,0.02416071854531765,0.025415485724806786,0.027704300358891487,0.026134604588150978,0.02533436380326748,0.021676145493984222,0.026073403656482697,0.027845334261655807,0.023917745798826218,0.022269384935498238,0.02262105792760849,0.02470635250210762,0.023376617580652237,0.02440103143453598,0.02566065825521946,
mse,0.12918974459171295,0.020674647763371468,0.01991409622132778,0.019282544031739235,0.017914671450853348,0.010182051919400692,0.009448868222534657,0.004367056302726269,0.00570267578586936,0.002213462721556425,0.002075617667287588,0.0019558784551918507,0.0013511698925867677,0.0014842483215034008,0.0007887766696512699,0.0007987237186171114,0.0008311716374009848,0.0015464234165847301,0.0009759029489941895,0.0007048352854326367,0.0009589721448719501,0.0011749423574656248,0.0005130204372107983,0.00040997250471264124,0.000360535632353276,0.000562567263841629,0.0003955719876103103,0.0004060147621203214,0.0006357734091579914,0.0006256226333789527,0.0003848954220302403,0.0005931541090831161,0.0005140264984220266,0.0006418392877094448,0.00042569314246065915,0.0006387808825820684,0.0005050507606938481,0.000433753157267347,0.00028103659860789776,0.0004887700197286904,0.0003509383532218635,0.00041100368252955377,0.00045921813580207527,0.00041160237742587924,0.0003186955291312188,0.0003618269693106413,0.0002701552293729037,0.000334534008288756,0.0002213410334661603,0.00021039646526332945,0.0003474622208159417,0.00034407529165036976,0.0003436206607148051,0.0003776872472371906,0.0002882405824493617,0.0002455255307722837,0.00035343042691238225,0.00030368511215783656,0.0002463718701619655,0.0003093569539487362,0.0002517538086976856,0.00023043826513458043,0.00023597067047376186,0.0002443125704303384,0.0002815211482811719,0.00029105989960953593,0.00021195922454353422,0.00020745830261148512,0.00019898213213309646,0.00021243041555862874,0.00030220590997487307,0.00026818373589776456,0.0002191675448557362,0.00024855969240888953,0.0002021309337578714,0.00015956095012370497,0.00016489530389662832,0.00019011920085176826,0.00026251672534272075,0.0002107355248881504,0.0001419633481418714,0.00021156966977287084,0.0001814915449358523,0.00023387718829326332,0.0002060588012682274,0.00016554968897253275,0.00018341784016229212,0.00021408087923191488,0.00019529121345840394,0.0001779613085091114,0.00013487138494383544,0.00019418793090153486,0.00021642095816787332,0.00016565027181059122,0.0001466018584324047,0.00014484781422652304,0.00017458898946642876,0.00015451043145731091,0.00016869007959030569,0.00018559169257059693,
mae,0.22333411872386932,0.10559640824794769,0.10092443227767944,0.09809783101081848,0.09780526161193848,0.07919745147228241,0.07581665366888046,0.051187772303819656,0.053642287850379944,0.03706761449575424,0.03521275147795677,0.03365085646510124,0.029140986502170563,0.030297324061393738,0.022304095327854156,0.02287108823657036,0.022542452439665794,0.03133299574255943,0.024576423689723015,0.02134748548269272,0.025404663756489754,0.02774149924516678,0.01788150519132614,0.01580728590488434,0.015009202994406223,0.018663689494132996,0.015492533333599567,0.01619994454085827,0.019922824576497078,0.0194507148116827,0.01569104939699173,0.019050516188144684,0.017789898440241814,0.0204081442207098,0.01683046668767929,0.02077302895486355,0.017601991072297096,0.016752637922763824,0.013194136321544647,0.01806834526360035,0.015309784561395645,0.015825336799025536,0.017409535124897957,0.016725320369005203,0.01432756707072258,0.015295350924134254,0.012637078762054443,0.014081205241382122,0.011723161675035954,0.011150007136166096,0.014841340482234955,0.014614259824156761,0.014840883202850819,0.01563851907849312,0.013156346045434475,0.011912154965102673,0.014755099080502987,0.013959336094558239,0.012138157151639462,0.014255369082093239,0.012533814646303654,0.012139040976762772,0.012080622836947441,0.012081533670425415,0.013598119840025902,0.014390958473086357,0.011246789246797562,0.011626648716628551,0.011305286549031734,0.011518070474267006,0.014197932556271553,0.01335134170949459,0.01158625166863203,0.012465933337807655,0.011271539144217968,0.009722406975924969,0.010183880105614662,0.010664070025086403,0.013210736215114594,0.011982998810708523,0.009407302364706993,0.01139279268682003,0.010488924570381641,0.012526137754321098,0.011031700298190117,0.009933278895914555,0.010827608406543732,0.011938094161450863,0.010991312563419342,0.010983651503920555,0.00913988146930933,0.01135601382702589,0.01190067920833826,0.01025365013629198,0.009159136563539505,0.009454082697629929,0.01016252301633358,0.009799683466553688,0.010332656092941761,0.010966631583869457,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 92403     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 92404     
=================================================================
Total params: 184,807
Trainable params: 184,807
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 92,403
Trainable params: 92,403
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 92,404
Trainable params: 92,404
Non-trainable params: 0
_________________________________________________________________
