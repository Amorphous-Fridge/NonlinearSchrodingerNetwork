2021-06-26
loss,2.8949079513549805,2.3168082237243652,2.2225987911224365,2.2140698432922363,2.2399649620056152,2.2181384563446045,2.2128281593322754,2.201366662979126,1.6210341453552246,0.5085610151290894,0.4139363169670105,0.4049764573574066,0.4036214053630829,0.4021933078765869,0.4014066755771637,0.3999287486076355,0.4044124484062195,0.3971298336982727,0.39527738094329834,0.3951586186885834,0.394062340259552,0.3971215784549713,0.3938179314136505,0.3909751772880554,0.3887981176376343,0.387632817029953,0.38520652055740356,0.3890726864337921,0.3843591809272766,0.3816145062446594,0.38051512837409973,0.37917017936706543,0.37753620743751526,0.37614044547080994,0.37436428666114807,0.37279683351516724,0.3720664083957672,0.36993733048439026,0.36866265535354614,0.3672429621219635,0.36896342039108276,0.36549216508865356,0.36115193367004395,0.3561036288738251,0.37493476271629333,0.360225647687912,0.3573167026042938,0.3521498143672943,0.3475706875324249,0.3802430331707001,0.3567858636379242,0.34950411319732666,0.4126506745815277,0.40100938081741333,0.3589741885662079,0.3573652505874634,0.3572043180465698,0.3563169836997986,0.35624945163726807,0.35561248660087585,0.3547326326370239,0.3551044762134552,0.35528650879859924,0.35517415404319763,0.3547208309173584,0.354386568069458,0.3538503348827362,0.3538004755973816,0.3555602729320526,0.3553438186645508,0.35394346714019775,0.3535822927951813,0.354157030582428,0.35431671142578125,0.3541303277015686,0.3538094758987427,0.35423678159713745,0.35321205854415894,0.3543718457221985,0.35458290576934814,0.35414305329322815,0.35377243161201477,0.35439571738243103,0.35381898283958435,0.3543929159641266,0.35365742444992065,0.3538724482059479,0.35814574360847473,0.3664890229701996,0.3535935580730438,0.35307562351226807,0.3542201519012451,0.3531889319419861,0.3535943329334259,0.35327067971229553,0.35428985953330994,0.35353004932403564,0.3532341718673706,0.3533342480659485,0.3535986840724945,
mse,2.1847939491271973,1.357823133468628,1.2485452890396118,1.2388646602630615,1.268225073814392,1.2433979511260986,1.2375859022140503,1.2251255512237549,0.7292703986167908,0.07844072580337524,0.047924257814884186,0.04607667028903961,0.04582330584526062,0.04550619423389435,0.04536045715212822,0.04510926827788353,0.0459207184612751,0.044537488371133804,0.04420516639947891,0.04415556788444519,0.043965235352516174,0.04448917880654335,0.0438850037753582,0.0433664545416832,0.04294637590646744,0.04272567853331566,0.04226265475153923,0.043153297156095505,0.042098112404346466,0.041646990925073624,0.041415177285671234,0.04119809716939926,0.0409049466252327,0.04065093398094177,0.04031688719987869,0.04007382690906525,0.03997546434402466,0.039614755660295486,0.03942175209522247,0.039191313087940216,0.039463650435209274,0.0389290489256382,0.03827564790844917,0.03815297782421112,0.04050847142934799,0.03809349611401558,0.037682708352804184,0.036931298673152924,0.036135271191596985,0.041724737733602524,0.03770817816257477,0.036692529916763306,0.053503770381212234,0.04609008878469467,0.037951238453388214,0.037705957889556885,0.03771163895726204,0.03757399693131447,0.037557680159807205,0.037484582513570786,0.03730417415499687,0.037407197058200836,0.037446584552526474,0.037455130368471146,0.03734508901834488,0.03731096163392067,0.03720494359731674,0.037224337458610535,0.03735821694135666,0.037431541830301285,0.037259142845869064,0.03718363493680954,0.0373031385242939,0.03734372556209564,0.037322141230106354,0.03722207248210907,0.03729494661092758,0.03712474927306175,0.0373757928609848,0.03736983984708786,0.037290092557668686,0.0372643917798996,0.03735211491584778,0.03726574778556824,0.037351008504629135,0.037209659814834595,0.03725946322083473,0.0380064956843853,0.03923558443784714,0.03725777566432953,0.037137314677238464,0.037376001477241516,0.037172287702560425,0.03722314536571503,0.03721785917878151,0.03736931458115578,0.03722481429576874,0.03722187131643295,0.03719198331236839,0.03726538270711899,
mae,1.188469648361206,0.7894370555877686,0.6546356081962585,0.62095046043396,0.676044225692749,0.6388460397720337,0.6178682446479797,0.6181865334510803,0.6109076142311096,0.21984216570854187,0.17948397994041443,0.17291203141212463,0.17233635485172272,0.17165055871009827,0.17122679948806763,0.1705128699541092,0.17335382103919983,0.16920220851898193,0.16839517652988434,0.16836205124855042,0.16792066395282745,0.16960656642913818,0.16801084578037262,0.16662684082984924,0.16569681465625763,0.1652691513299942,0.1641785204410553,0.16678716242313385,0.1640193611383438,0.16262947022914886,0.16243599355220795,0.16191357374191284,0.16128642857074738,0.1607648730278015,0.16013048589229584,0.15956024825572968,0.1593596339225769,0.15847793221473694,0.15809041261672974,0.15752054750919342,0.15940259397029877,0.15679889917373657,0.15508955717086792,0.15678168833255768,0.1621202975511551,0.15439172089099884,0.15271851420402527,0.15012632310390472,0.14871250092983246,0.16532351076602936,0.15326614677906036,0.15028302371501923,0.1771634817123413,0.17455902695655823,0.154335618019104,0.15366095304489136,0.15358538925647736,0.15326416492462158,0.15323570370674133,0.1529446840286255,0.15259994566440582,0.15273909270763397,0.15285524725914001,0.15282249450683594,0.15263786911964417,0.15247482061386108,0.15231311321258545,0.15234537422657013,0.15402723848819733,0.15306051075458527,0.15227346122264862,0.15215520560741425,0.15243077278137207,0.15252554416656494,0.1524798572063446,0.15237091481685638,0.15256640315055847,0.1520957201719284,0.15266497433185577,0.15275125205516815,0.15259723365306854,0.15248578786849976,0.15283642709255219,0.15261179208755493,0.1528531014919281,0.15260754525661469,0.1526879221200943,0.1545121818780899,0.15854862332344055,0.15258562564849854,0.1524135172367096,0.15296980738639832,0.15260398387908936,0.15287135541439056,0.15276925265789032,0.15327885746955872,0.1529330313205719,0.15287521481513977,0.15301071107387543,0.15315361320972443,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 463307    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 463308    
=================================================================
Total params: 926,615
Trainable params: 926,615
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 463,307
Trainable params: 463,307
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 463,308
Trainable params: 463,308
Non-trainable params: 0
_________________________________________________________________
