2021-06-26
loss,2.6154677867889404,0.5289170145988464,0.2403503805398941,0.23425020277500153,0.22890636324882507,0.21950310468673706,0.212478905916214,0.20639163255691528,0.1840105652809143,0.15283313393592834,0.14287690818309784,0.12628434598445892,0.11400211602449417,0.10139189660549164,0.10929852724075317,0.11094679683446884,0.10318291932344437,0.0954500287771225,0.06927265226840973,0.051649466156959534,0.05569582059979439,0.06776517629623413,0.056621003895998,0.06431525945663452,0.07752527296543121,0.06237150356173515,0.03754729405045509,0.03786661848425865,0.040333088487386703,0.05084269493818283,0.06344446539878845,0.06079744175076485,0.05534231290221214,0.03923925757408142,0.04424246400594711,0.05429777503013611,0.05325205251574516,0.046463534235954285,0.05536223575472832,0.04847705736756325,0.04235776886343956,0.04947609454393387,0.04753768444061279,0.04494268819689751,0.041404418647289276,0.04071503505110741,0.03496966511011124,0.04143849015235901,0.03597036749124527,0.03687823936343193,0.04140881076455116,0.03865888714790344,0.041613709181547165,0.04719536378979683,0.03752072528004646,0.03566683456301689,0.03322330489754677,0.038540903478860855,0.0332133024930954,0.04392966255545616,0.03969717398285866,0.03416154533624649,0.04086240381002426,0.04049522057175636,0.03572678938508034,0.029225172474980354,0.039696529507637024,0.03231975808739662,0.03283604234457016,0.035709403455257416,0.03791874274611473,0.032644569873809814,0.029021961614489555,0.03151997923851013,0.031038541346788406,0.029811067506670952,0.03311022371053696,0.03415991738438606,0.028284650295972824,0.03203437477350235,0.040518347173929214,0.03463895618915558,0.037621140480041504,0.03155823424458504,0.02614326775074005,0.028360987082123756,0.027771033346652985,0.02902786061167717,0.027156440541148186,0.027267348021268845,0.03152865171432495,0.03757127374410629,0.03486839681863785,0.032748397439718246,0.03328709676861763,0.029070112854242325,0.026676636189222336,0.02863251231610775,0.025302009657025337,0.031429722905159,
mse,2.027526378631592,0.10221635550260544,0.019646402448415756,0.019083546474575996,0.01841399073600769,0.017297619953751564,0.016224659979343414,0.01519016269594431,0.01113015878945589,0.0069083236157894135,0.005911798682063818,0.0046196249313652515,0.003741207765415311,0.002889587776735425,0.00363205187022686,0.0035165089648216963,0.0030214297585189342,0.002543193055316806,0.001403612783178687,0.0007354028639383614,0.0008993762894533575,0.0013118286151438951,0.0009073053952306509,0.0011762342182919383,0.001657789689488709,0.0011091510532423854,0.0004020655178464949,0.00041346781654283404,0.000472571438876912,0.0007228638278320432,0.0011205616174265742,0.0010476938914507627,0.0008524381555616856,0.0004430754343047738,0.0005751103744842112,0.0008030512253753841,0.0008085292647592723,0.0006058510625734925,0.0008551073260605335,0.0006661790539510548,0.0005048555321991444,0.0006895735277794302,0.0006468497449532151,0.0005756522878073156,0.00046939979074522853,0.0004713539674412459,0.00035107112489640713,0.0004881347413174808,0.00037746012094430625,0.00038974345079623163,0.0004783196491189301,0.00042670482071116567,0.0005061941337771714,0.0006113897543400526,0.0004008109390269965,0.0003767214366234839,0.00031058426247909665,0.0004282737791072577,0.00030589851667173207,0.0005324725061655045,0.0004379637539386749,0.0003383714356459677,0.0004935680190101266,0.00045597099233418703,0.00036031065974384546,0.0002575957332737744,0.0004382740589790046,0.000299981766147539,0.00029541586991399527,0.0003635127504821867,0.0004024515801575035,0.00030192648409865797,0.00023462022363673896,0.00027976257842965424,0.0002673775015864521,0.0002476500812917948,0.00030803433037362993,0.00035030313301831484,0.0002286466333316639,0.0002853040350601077,0.00045002668048255146,0.0003407633048482239,0.0003860793949570507,0.0002786251425277442,0.0001974094775505364,0.00022685082512907684,0.00021955472766421735,0.00024139108427334577,0.00021014473168179393,0.0002084434381686151,0.0002866356517188251,0.00039661224582232535,0.00033514545066282153,0.0003014742105733603,0.00030854754731990397,0.0002341909712413326,0.00020497696823440492,0.0002341539366170764,0.00018629081023391336,0.00027174782007932663,
mae,1.1149239540100098,0.22419078648090363,0.09961598366498947,0.09630724042654037,0.09616364538669586,0.099093496799469,0.09612976014614105,0.09134278446435928,0.08000314980745316,0.06535788625478745,0.061167992651462555,0.05390812084078789,0.04899803549051285,0.04220227152109146,0.046084221452474594,0.04714049771428108,0.04412718862295151,0.04033760726451874,0.029186611995100975,0.02198255993425846,0.023617563769221306,0.028320373967289925,0.02377801574766636,0.02745411917567253,0.032547883689403534,0.02687252126634121,0.016044296324253082,0.016047369688749313,0.016927573829889297,0.021568484604358673,0.026883583515882492,0.026072602719068527,0.023661646991968155,0.016854070127010345,0.018352217972278595,0.0233642365783453,0.022248173132538795,0.019756635650992393,0.023278161883354187,0.020625252276659012,0.018081463873386383,0.020588798448443413,0.020065972581505775,0.018834838643670082,0.017284391447901726,0.016962112858891487,0.014906507916748524,0.01770535297691822,0.015094592235982418,0.015488136559724808,0.01771625503897667,0.016322901472449303,0.017219476401805878,0.019824953749775887,0.01605754904448986,0.015322370454668999,0.014000295661389828,0.016373494639992714,0.014038356952369213,0.017993465065956116,0.01673382706940174,0.014980722218751907,0.01710386946797371,0.017027584835886955,0.015428631566464901,0.012263672426342964,0.016915835440158844,0.013578450307250023,0.014045309275388718,0.014610485173761845,0.015707697719335556,0.013753261417150497,0.012256410904228687,0.013271794654428959,0.013279449194669724,0.012368797324597836,0.013951735571026802,0.01443881168961525,0.012101934291422367,0.01324368454515934,0.016614122316241264,0.014385671354830265,0.015695441514253616,0.013128407299518585,0.0110185407102108,0.012043410912156105,0.011887306347489357,0.012403217144310474,0.011171780526638031,0.011475597508251667,0.0132259177044034,0.015542012639343739,0.014486965723335743,0.013736563734710217,0.013933255337178707,0.011038299649953842,0.010926173999905586,0.01174211036413908,0.010955704376101494,0.01319042220711708,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 314099    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 314100    
=================================================================
Total params: 628,199
Trainable params: 628,199
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 314,099
Trainable params: 314,099
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 314,100
Trainable params: 314,100
Non-trainable params: 0
_________________________________________________________________
