2021-06-26
loss,2.8429040908813477,2.2289087772369385,2.221362352371216,2.2208847999572754,2.2224206924438477,2.2045488357543945,1.6836544275283813,0.3866729736328125,0.3417072296142578,0.33260485529899597,0.31975722312927246,0.33308589458465576,0.30336177349090576,0.2605571448802948,0.2010597586631775,0.21331751346588135,0.1723707765340805,0.16962720453739166,0.1440834254026413,0.1344517320394516,0.12081705033779144,0.10133369266986847,0.10805966705083847,0.10056863725185394,0.0868023931980133,0.08179114013910294,0.0827939510345459,0.09049568325281143,0.06834306567907333,0.059919070452451706,0.059168219566345215,0.06077897548675537,0.0580437071621418,0.06226236745715141,0.07190373539924622,0.0607035830616951,0.05960327014327049,0.05390636622905731,0.05676233395934105,0.04651804268360138,0.05173654481768608,0.04806651175022125,0.05626727268099785,0.05206726863980293,0.043006010353565216,0.04014575853943825,0.040099456906318665,0.05123688653111458,0.05299825966358185,0.04279883950948715,0.045131415128707886,0.05151315778493881,0.040814269334077835,0.03486618399620056,0.034728556871414185,0.03889629244804382,0.04511529579758644,0.04958672448992729,0.03846380487084389,0.04370877891778946,0.04512582719326019,0.037478018552064896,0.03737726807594299,0.04030356556177139,0.042878199368715286,0.03314721956849098,0.0404876172542572,0.03598718345165253,0.0348474383354187,0.03470253944396973,0.03494516760110855,0.03272225335240364,0.03392864391207695,0.0401979498565197,0.03395730257034302,0.03632931783795357,0.03010951355099678,0.036913663148880005,0.03528248146176338,0.03172454237937927,0.03151107579469681,0.03321971744298935,0.03000389039516449,0.02944515459239483,0.03029727190732956,0.02883896417915821,0.030894681811332703,0.028766274452209473,0.029239380732178688,0.029772931709885597,0.032632965594530106,0.030947213992476463,0.02624102681875229,0.027837397530674934,0.03034259006381035,0.02816351130604744,0.030511390417814255,0.029022302478551865,0.025589797645807266,0.029881656169891357,
mse,2.1240639686584473,1.2554820775985718,1.247168779373169,1.2465993165969849,1.2483593225479126,1.255579948425293,0.9456356167793274,0.0442221537232399,0.03517173230648041,0.03349791839718819,0.03124448098242283,0.034642964601516724,0.02888234332203865,0.021496877074241638,0.013145720586180687,0.014217074029147625,0.009565693326294422,0.00925708282738924,0.006647911854088306,0.005249734967947006,0.004338801838457584,0.0029623229056596756,0.0032747709192335606,0.0029875680338591337,0.0021540354937314987,0.0018911710940301418,0.002053905511274934,0.0023165184538811445,0.0013489560224115849,0.0010736059630289674,0.0010488891275599599,0.0010383684420958161,0.0009492480894550681,0.0011388912098482251,0.001440343214198947,0.0010559135116636753,0.0010129254078492522,0.000825121533125639,0.0009320012759417295,0.0006042302120476961,0.0007470138953067362,0.0006828203331679106,0.0008930465555749834,0.0007778499275445938,0.0005143562448211014,0.00044888746924698353,0.00044814281864091754,0.0007242272840812802,0.0007839266327209771,0.0005132257356308401,0.0005789216957055032,0.0007299283752217889,0.00045576615957543254,0.0003452025121077895,0.00033583049662411213,0.0004233184445183724,0.0005719727487303317,0.0006612761062569916,0.00041161279659718275,0.0005422146059572697,0.0005510850460268557,0.0003948053054045886,0.0003936217981390655,0.0004587227012962103,0.0005215315031819046,0.00031229114392772317,0.0004525335389189422,0.00036381345125846565,0.0003440264845266938,0.0003309328749310225,0.0003344013821333647,0.00029473030008375645,0.00032362231286242604,0.0004394296556711197,0.0003242895763833076,0.00037153734592720866,0.0002546845353208482,0.00037075328873470426,0.0003426882321946323,0.00028424858464859426,0.0002734647423494607,0.00030254150624386966,0.00025645102141425014,0.0002441001997794956,0.0002568057971075177,0.00023729694657959044,0.0002640873135533184,0.00023057713406160474,0.0002354053722228855,0.00024234942975454032,0.00029181534773670137,0.0002594274701550603,0.00019476930901873857,0.00021320453379303217,0.0002501219278201461,0.00022091696155257523,0.00026495123165659606,0.00023817032342776656,0.00019005728245247155,0.0002547997864894569,
mae,1.1316760778427124,0.6740418076515198,0.6560518741607666,0.6549133062362671,0.6572934985160828,0.7503788471221924,0.6674191355705261,0.16322097182273865,0.1461511105298996,0.1410258412361145,0.137315034866333,0.14379099011421204,0.1313137412071228,0.11276363581418991,0.0858619287610054,0.09136626869440079,0.07340961694717407,0.07226462662220001,0.061421170830726624,0.0571151003241539,0.05186089128255844,0.04240047559142113,0.04638824611902237,0.041786931455135345,0.035879045724868774,0.03419528901576996,0.03590826690196991,0.038431938737630844,0.029277965426445007,0.025202760472893715,0.02512863650918007,0.025608183816075325,0.024814829230308533,0.02652517519891262,0.031000377610325813,0.02579290233552456,0.025645427405834198,0.022868162021040916,0.024352962151169777,0.020237911492586136,0.022304989397525787,0.02062629722058773,0.024208784103393555,0.022138498723506927,0.018491730093955994,0.017126277089118958,0.016719158738851547,0.02182159386575222,0.021990926936268806,0.018011534586548805,0.018956314772367477,0.021853966638445854,0.018427489325404167,0.015110766515135765,0.014805024489760399,0.016471000388264656,0.019252795726060867,0.022147558629512787,0.016141541302204132,0.018506145104765892,0.019772017374634743,0.016246214509010315,0.015841051936149597,0.017227821052074432,0.018076114356517792,0.014268744736909866,0.017480527982115746,0.01531991083174944,0.01463915966451168,0.014911237172782421,0.014533075504004955,0.014224404469132423,0.014501427300274372,0.017857471480965614,0.01473288144916296,0.015579787082970142,0.012837331742048264,0.015344573184847832,0.015296649187803268,0.013470885343849659,0.01347461435943842,0.01417865976691246,0.012484458275139332,0.01254309993237257,0.012804070487618446,0.012442529201507568,0.01315337885171175,0.01240291353315115,0.012289329431951046,0.01264064759016037,0.013909566216170788,0.012848103418946266,0.011083067394793034,0.01196296326816082,0.012894588522613049,0.01178455725312233,0.013275767676532269,0.012439025565981865,0.01092481054365635,0.01283971220254898,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 332131    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 332132    
=================================================================
Total params: 664,263
Trainable params: 664,263
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 332,131
Trainable params: 332,131
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 332,132
Trainable params: 332,132
Non-trainable params: 0
_________________________________________________________________
