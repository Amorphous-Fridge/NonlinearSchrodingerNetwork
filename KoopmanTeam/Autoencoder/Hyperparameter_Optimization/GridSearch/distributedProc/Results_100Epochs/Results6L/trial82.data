2021-06-26
loss,1.9760366678237915,0.6719256043434143,0.4092344641685486,0.3784240484237671,0.37550148367881775,0.3678293228149414,0.3655356168746948,0.360658198595047,0.3590446710586548,0.3498573303222656,0.3513191342353821,0.3408406376838684,0.3438072204589844,0.3402046263217926,0.32393723726272583,0.3011077046394348,0.2632843554019928,0.2532288432121277,0.2313515692949295,0.19202184677124023,0.1674077957868576,0.15804439783096313,0.11707422137260437,0.10852605849504471,0.09215933829545975,0.08340971916913986,0.085667684674263,0.07805130630731583,0.10139871388673782,0.07159189879894257,0.07252802699804306,0.0749548003077507,0.06660737842321396,0.07955969125032425,0.06032434478402138,0.06011725962162018,0.06956933438777924,0.05131753906607628,0.05086018145084381,0.049820128828287125,0.04867740720510483,0.059426430612802505,0.04628247395157814,0.054986320436000824,0.05174941569566727,0.03639668598771095,0.04361177980899811,0.04935923591256142,0.04453057795763016,0.044077612459659576,0.046115171164274216,0.0313444659113884,0.03610021620988846,0.04504471272230148,0.039894070476293564,0.037528377026319504,0.04255620390176773,0.04007519781589508,0.03399740904569626,0.03239758312702179,0.030115095898509026,0.03784031793475151,0.035738565027713776,0.03879624232649803,0.038292113691568375,0.030956245958805084,0.03273339197039604,0.035106267780065536,0.0328427329659462,0.03242843970656395,0.028093717992305756,0.032906729727983475,0.03031916543841362,0.02287691831588745,0.02642349898815155,0.030751602724194527,0.03356658294796944,0.031607672572135925,0.03411861136555672,0.029120657593011856,0.030437089502811432,0.02716752327978611,0.030144305899739265,0.02697671204805374,0.024209514260292053,0.023860052227973938,0.02888273447751999,0.02969219535589218,0.0274162907153368,0.030407700687646866,0.03077111765742302,0.02999229170382023,0.029907992109656334,0.02228708006441593,0.027123618870973587,0.023611096665263176,0.029036633670330048,0.026643235236406326,0.027212776243686676,0.025395339354872704,
mse,1.0851199626922607,0.15010200440883636,0.047568969428539276,0.04141506552696228,0.041047949343919754,0.03975997865200043,0.03939112275838852,0.038527924567461014,0.03823686018586159,0.036740776151418686,0.036825232207775116,0.03493853658437729,0.035393837839365005,0.03457111865282059,0.03136530891060829,0.026735153049230576,0.020792808383703232,0.020084116607904434,0.017662683501839638,0.012258614413440228,0.008543753065168858,0.007660613860934973,0.004254123196005821,0.0035662928130477667,0.002555863233283162,0.002093721879646182,0.0022339001297950745,0.0017863995162770152,0.003171113785356283,0.0015285862609744072,0.0015388864558190107,0.001701798988506198,0.0013221102999523282,0.001862154807895422,0.0010346939088776708,0.001047608908265829,0.0014078028034418821,0.0007636690279468894,0.0007641708361916244,0.0007324930047616363,0.0007098556961864233,0.0010170782916247845,0.0006245662807486951,0.0008622309542261064,0.0007698266999796033,0.00041663969750516117,0.0005669418023899198,0.0007092075538821518,0.0005554432282224298,0.0005627746577374637,0.0006075146375223994,0.00029268424259498715,0.0003800210834015161,0.0005802433588542044,0.00046056174323894083,0.0004047407128382474,0.0005075619556009769,0.0004531927115749568,0.00033219464239664376,0.0003072178806178272,0.0002704646612983197,0.0004058344929944724,0.00036278131301514804,0.00044151453766971827,0.00040988571709021926,0.00027682623476721346,0.0003061979659833014,0.00035077816573902965,0.0003079025191254914,0.0003153331344947219,0.00023610702191945165,0.00031023810151964426,0.00026506560971029103,0.00015846025780774653,0.0002135944669134915,0.00027635713922791183,0.00032226231996901333,0.00028917682357132435,0.0003300066164229065,0.0002462047850713134,0.0002659941092133522,0.00021424783335532993,0.0002705940278246999,0.00022013272973708808,0.0001784420746844262,0.00016807937936391681,0.0002483887365087867,0.0002539923880249262,0.0002155636320821941,0.0002652812981978059,0.0002725334488786757,0.0002544166927691549,0.0002524203446228057,0.00014606869081035256,0.0002152609231416136,0.00016560345829930156,0.00024139367451425642,0.00020306446822360158,0.0002159408322768286,0.0001876538444776088,
mae,0.7868604063987732,0.29046326875686646,0.17825819551944733,0.1654948741197586,0.16442406177520752,0.16166740655899048,0.1604277789592743,0.15851451456546783,0.15782566368579865,0.15396566689014435,0.15341530740261078,0.14873403310775757,0.1497802734375,0.14759181439876556,0.1390150487422943,0.12823402881622314,0.11153892427682877,0.10821468383073807,0.1002630963921547,0.08288588374853134,0.07091760635375977,0.06661877036094666,0.05009661987423897,0.0458679236471653,0.039518047124147415,0.03527238219976425,0.03628843277692795,0.03326060250401497,0.043666720390319824,0.030380889773368835,0.031024951487779617,0.0313015878200531,0.028150998055934906,0.03406452760100365,0.026051007211208344,0.025102335959672928,0.0295081976801157,0.021547220647335052,0.021673908457159996,0.021286703646183014,0.02079848013818264,0.025137722492218018,0.01972305029630661,0.02343784272670746,0.02199619822204113,0.01547959353774786,0.01863638497889042,0.02079974114894867,0.019519738852977753,0.018975965678691864,0.019398309290409088,0.01314191147685051,0.01517967227846384,0.01905740052461624,0.016911454498767853,0.016149137169122696,0.01801418513059616,0.017210770398378372,0.014406707137823105,0.01364840380847454,0.012818293645977974,0.015993231907486916,0.015253053978085518,0.016611373052001,0.01661120355129242,0.013359430246055126,0.013664014637470245,0.015001526102423668,0.013905511237680912,0.013820257969200611,0.012071629986166954,0.014085577800869942,0.012988504022359848,0.00977006834000349,0.011289059184491634,0.013245406560599804,0.014351094141602516,0.013363024219870567,0.014656811021268368,0.01234317198395729,0.012951071374118328,0.011483176611363888,0.0128520168364048,0.011686023324728012,0.010307125747203827,0.010184163227677345,0.012197925709187984,0.012614008970558643,0.011658803559839725,0.012901303358376026,0.013104775920510292,0.012698573060333729,0.012471792288124561,0.009442990645766258,0.011634784750640392,0.010071123018860817,0.012496977113187313,0.01132766529917717,0.011670192703604698,0.01079432014375925,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 396619    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 396620    
=================================================================
Total params: 793,239
Trainable params: 793,239
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 396,619
Trainable params: 396,619
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 396,620
Trainable params: 396,620
Non-trainable params: 0
_________________________________________________________________
