2021-06-26
loss,0.9357814788818359,0.3629174530506134,0.32646483182907104,0.2886987626552582,0.27592456340789795,0.2640315294265747,0.2548677325248718,0.23909854888916016,0.22888490557670593,0.23143188655376434,0.1781187206506729,0.18679016828536987,0.14009562134742737,0.13028083741664886,0.08953505754470825,0.1159319132566452,0.08727496862411499,0.08374136686325073,0.08255801349878311,0.0934939831495285,0.08780483156442642,0.06722111999988556,0.08141817152500153,0.0745745375752449,0.053332630544900894,0.06905189156532288,0.05821743980050087,0.04999298229813576,0.07013988494873047,0.06431541591882706,0.05849679559469223,0.048792850226163864,0.04151061549782753,0.05729084089398384,0.05126713588833809,0.046310171484947205,0.03912113979458809,0.037000007927417755,0.04054636135697365,0.048537515103816986,0.049086399376392365,0.05081140622496605,0.04727969318628311,0.04576597735285759,0.04087356477975845,0.03800646960735321,0.035211484879255295,0.034055937081575394,0.04371314123272896,0.04662506654858589,0.0430290549993515,0.03847288340330124,0.03762282431125641,0.03544984757900238,0.03575493022799492,0.03888522461056709,0.03200986236333847,0.0415414534509182,0.03926754370331764,0.03604171425104141,0.039752744138240814,0.038310155272483826,0.03460545837879181,0.03212875872850418,0.03270603343844414,0.037109244614839554,0.03996361419558525,0.03698604926466942,0.032856330275535583,0.030189495533704758,0.031021052971482277,0.03444568067789078,0.032026514410972595,0.03747893497347832,0.031232759356498718,0.03686898574233055,0.027934465557336807,0.03076343983411789,0.032685887068510056,0.033626969903707504,0.028959698975086212,0.02907535247504711,0.023757774382829666,0.03493683412671089,0.03312322869896889,0.02858521044254303,0.03219006955623627,0.027975354343652725,0.02432474121451378,0.033483490347862244,0.02909257262945175,0.03513064235448837,0.02957135997712612,0.028878413140773773,0.029974037781357765,0.025538494810461998,0.02873598039150238,0.02866225317120552,0.02675211988389492,0.02887260913848877,
mse,0.43608328700065613,0.0387246310710907,0.03162296116352081,0.025649238377809525,0.023810097947716713,0.02215941995382309,0.020951179787516594,0.018972543999552727,0.017122842371463776,0.01613333448767662,0.009579182602465153,0.010583761148154736,0.005991293583065271,0.005067393183708191,0.0022973008453845978,0.004194690380245447,0.0022383572068065405,0.0020552887581288815,0.0019441841868683696,0.002604783745482564,0.0023083167616277933,0.0013159895315766335,0.00188447383698076,0.0016010850667953491,0.0008231292013078928,0.0014129665214568377,0.0009600177872925997,0.0007260452839545906,0.0013770688092336059,0.0012186340754851699,0.0009788868483155966,0.0006924695335328579,0.000490072590764612,0.0009399244445376098,0.0007498536724597216,0.0006065598572604358,0.00044162344420328736,0.00039476845995523036,0.0004779853334184736,0.0006932701217010617,0.0006913559045642614,0.0007656269590370357,0.0006475064437836409,0.0006155971204861999,0.0004696553514804691,0.0004160881508141756,0.00036015271325595677,0.00034587629488669336,0.0005589336506091058,0.000637757417280227,0.0005311199929565191,0.00042481624404899776,0.00040442560566589236,0.00036168182850815356,0.00037405375041998923,0.0004423231293912977,0.0002971875946968794,0.0005196281126700342,0.0004536672786343843,0.00036927725886926055,0.0004544313997030258,0.0004379282472655177,0.00033858910319395363,0.0003018233401235193,0.00030898701515980065,0.000392074667615816,0.0004504383250605315,0.00037687711301259696,0.00030958597199060023,0.0002599697618279606,0.00027628260431811213,0.00034145190147683024,0.0002988782653119415,0.00039790960727259517,0.0002810186124406755,0.00038550159661099315,0.00022795288532506675,0.00026753442944027483,0.0003027821658179164,0.00032495203777216375,0.00024003151338547468,0.00024269026471301913,0.000165640507475473,0.00035283659235574305,0.0003166423412039876,0.00023825492826290429,0.0002988410706166178,0.0002282831264892593,0.000175311099155806,0.0003242758975829929,0.00024441760615445673,0.0003426054900046438,0.00025800056755542755,0.00023809818958397955,0.0002635536075104028,0.00018646020907908678,0.00024093163665384054,0.00022995212930254638,0.00020113441860303283,0.00023447438434232026,
mae,0.3924214243888855,0.15646129846572876,0.14167818427085876,0.12749077379703522,0.12233269959688187,0.1170874536037445,0.1134876161813736,0.10661666840314865,0.10066235810518265,0.0983508974313736,0.07603087276220322,0.07970846444368362,0.059522029012441635,0.05497297644615173,0.03855784982442856,0.0486510768532753,0.03730689361691475,0.03615473955869675,0.03533313050866127,0.03893647342920303,0.03795967251062393,0.02855466865003109,0.03460831940174103,0.031761039048433304,0.022674672305583954,0.029986366629600525,0.025180689990520477,0.021196968853473663,0.02998323179781437,0.027739040553569794,0.024544019252061844,0.02101191319525242,0.01776832714676857,0.024345533922314644,0.021959101781249046,0.02008696272969246,0.01677173376083374,0.015689397230744362,0.017165251076221466,0.02107294835150242,0.02095055766403675,0.021514086052775383,0.019776510074734688,0.01964719593524933,0.017430949956178665,0.016412878409028053,0.015084377489984035,0.01466075424104929,0.018688997253775597,0.019603559747338295,0.01801281049847603,0.01671566069126129,0.01602468080818653,0.01509437058120966,0.015381818637251854,0.016603432595729828,0.013572901487350464,0.017604388296604156,0.01674998551607132,0.015658240765333176,0.017236236482858658,0.015993136912584305,0.014760980382561684,0.013861604034900665,0.013715566135942936,0.015681585296988487,0.016927942633628845,0.015603501349687576,0.014165777713060379,0.013126891106367111,0.01343391090631485,0.014881369657814503,0.01356168370693922,0.016232561320066452,0.013328195549547672,0.015644395723938942,0.011834528297185898,0.013119015842676163,0.013759206980466843,0.014457927085459232,0.012389584444463253,0.012404915876686573,0.010124530643224716,0.014828047715127468,0.013967053033411503,0.012122361920773983,0.013785861432552338,0.011952679604291916,0.010392597876489162,0.014109885320067406,0.012586343102157116,0.015024765394628048,0.01241996418684721,0.012379825115203857,0.012754707597196102,0.010798809118568897,0.012165159918367863,0.01233885157853365,0.01136003714054823,0.012438172474503517,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 296883    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 296884    
=================================================================
Total params: 593,767
Trainable params: 593,767
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 296,883
Trainable params: 296,883
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 296,884
Trainable params: 296,884
Non-trainable params: 0
_________________________________________________________________
