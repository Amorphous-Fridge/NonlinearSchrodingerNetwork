2021-06-26
loss,2.449495315551758,2.2227840423583984,1.151687741279602,0.3685552179813385,0.36500468850135803,0.3035343885421753,0.24135322868824005,0.20113521814346313,0.18600620329380035,0.17740584909915924,0.18404392898082733,0.16158828139305115,0.15303535759449005,0.14030508697032928,0.11007513850927353,0.11218258738517761,0.09127087891101837,0.07476809620857239,0.0829201340675354,0.0814710333943367,0.07139446586370468,0.06236198917031288,0.05795963108539581,0.067559614777565,0.05383860692381859,0.06414992362260818,0.05489005148410797,0.04550217464566231,0.04757177457213402,0.04727659747004509,0.04971243068575859,0.04307505488395691,0.04352403059601784,0.043074849992990494,0.0455293171107769,0.03997395560145378,0.03550441935658455,0.036757778376340866,0.03821106627583504,0.03711327165365219,0.03583800792694092,0.038224540650844574,0.03564375266432762,0.03158180043101311,0.03243250399827957,0.033998385071754456,0.03281044587492943,0.028409218415617943,0.03038286603987217,0.028021307662129402,0.023301057517528534,0.030689572915434837,0.030512342229485512,0.034558333456516266,0.032162152230739594,0.02966643124818802,0.02773473411798477,0.02836211770772934,0.027538299560546875,0.02747669257223606,0.02877926640212536,0.027931323274970055,0.028009766712784767,0.026980852708220482,0.02684827521443367,0.026781491935253143,0.02280481904745102,0.0260538998991251,0.025938093662261963,0.029899105429649353,0.024287361651659012,0.02100169099867344,0.02496510185301304,0.026801807805895805,0.025808343663811684,0.023514948785305023,0.025480208918452263,0.02435658499598503,0.02271006628870964,0.02302636206150055,0.024473344907164574,0.02454359270632267,0.024526238441467285,0.02305322140455246,0.024782231077551842,0.024447603151202202,0.022753270342946053,0.023967497050762177,0.025473320856690407,0.02300533838570118,0.022297555580735207,0.02395610325038433,0.02038201503455639,0.02127537503838539,0.021480191498994827,0.024700473994016647,0.022331610321998596,0.021942323073744774,0.022109903395175934,0.021371731534600258,
mse,1.5486668348312378,1.2486237287521362,0.45052462816238403,0.04058386757969856,0.03956955298781395,0.02780698612332344,0.018653761595487595,0.013208111748099327,0.011388560757040977,0.010152973234653473,0.010377350263297558,0.007683768402785063,0.006872582249343395,0.005529469344764948,0.003369981423020363,0.0034964531660079956,0.0023328899405896664,0.0015755859203636646,0.0019279285334050655,0.0018891735235229135,0.0014561812859028578,0.0011217481223866343,0.0009754331549629569,0.0012798276729881763,0.0008341645589098334,0.0011710464023053646,0.0008466754225082695,0.0005929056787863374,0.0006456322153098881,0.000633340619970113,0.0006858626729808748,0.0005308702820912004,0.000557478575501591,0.0005210951785556972,0.0005755460006184876,0.000441762269474566,0.0003605192177928984,0.00038245803443714976,0.0004140782402828336,0.00039629891398362815,0.0003684921539388597,0.000410079606808722,0.0003546807274688035,0.00028484902577474713,0.00029688983340747654,0.00032265082700178027,0.0003031309461221099,0.00023389499983750284,0.000268947595031932,0.000225786046939902,0.00016070521087385714,0.0002728305698838085,0.00026529215392656624,0.00033764843828976154,0.00028563456726260483,0.00024669533013366163,0.0002185927878599614,0.00023154188238549978,0.0002189285442000255,0.00021768701844848692,0.00023631447402294725,0.00022107599943410605,0.00021932768868282437,0.00020799734920728952,0.00020482612308114767,0.0002056723606074229,0.00015158590395003557,0.0001958178327186033,0.0001975864142877981,0.0002493165375199169,0.00017098897660616785,0.00013077228504698724,0.00018372599151916802,0.0002021806431002915,0.00019514939049258828,0.00015815318329259753,0.00018863168952520937,0.0001714542886475101,0.00015109902597032487,0.00015386917220894247,0.00017537601524963975,0.00017369291163049638,0.00017174138338305056,0.00015282593085430562,0.00017713343549985439,0.00017378486518282443,0.00015034101670607924,0.00016449045506305993,0.00018563376215752214,0.00015299132792279124,0.0001477095065638423,0.00016148485883604735,0.00012253792374394834,0.0001342289469903335,0.00013363898324314505,0.00017577175458427519,0.00014613952953368425,0.000140585150802508,0.00014225220365915447,0.0001335346169071272,
mae,0.8908925652503967,0.6588791012763977,0.41529181599617004,0.16267246007919312,0.1579975038766861,0.13002018630504608,0.10254891216754913,0.08687812834978104,0.08033448457717896,0.07622405886650085,0.07892288267612457,0.06755432486534119,0.0660444051027298,0.059057921171188354,0.04754945635795593,0.04709857329726219,0.038598351180553436,0.03106292337179184,0.03522444888949394,0.034899089485406876,0.030501671135425568,0.02618117816746235,0.024616114795207977,0.028425149619579315,0.02299085631966591,0.027386358007788658,0.023148151114583015,0.019461747258901596,0.01982584223151207,0.020061587914824486,0.02136874757707119,0.01823652908205986,0.01851033791899681,0.018021604046225548,0.01956523023545742,0.017461709678173065,0.015160259790718555,0.015590709634125233,0.015877924859523773,0.01576286554336548,0.0152768325060606,0.016037428751587868,0.015375213697552681,0.013450698927044868,0.013861545361578465,0.014344421215355396,0.013777987100183964,0.011929201893508434,0.012731289491057396,0.011892378330230713,0.009878537617623806,0.013090556487441063,0.013047187589108944,0.01502540335059166,0.013874733820557594,0.01267572958022356,0.01186450943350792,0.012181967496871948,0.011628507636487484,0.011673319153487682,0.012334734201431274,0.011780486442148685,0.011981471441686153,0.011541469022631645,0.011406678706407547,0.011358190327882767,0.00964664202183485,0.01095522753894329,0.01098559983074665,0.012600506655871868,0.010374167002737522,0.008913587778806686,0.010622847825288773,0.011378662660717964,0.010783767327666283,0.010061075910925865,0.0108463354408741,0.010413135401904583,0.009647254832088947,0.00976734608411789,0.010387498885393143,0.010581593960523605,0.01054545771330595,0.009806979447603226,0.010579896159470081,0.010445424355566502,0.009571202099323273,0.010178852826356888,0.010867348872125149,0.009893994778394699,0.009503629058599472,0.010109604336321354,0.00863009411841631,0.009093527682125568,0.009246718138456345,0.010512538254261017,0.009587429463863373,0.009304961189627647,0.009375902824103832,0.009079597890377045,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 148803    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 148804    
=================================================================
Total params: 297,607
Trainable params: 297,607
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 148,803
Trainable params: 148,803
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 148,804
Trainable params: 148,804
Non-trainable params: 0
_________________________________________________________________
