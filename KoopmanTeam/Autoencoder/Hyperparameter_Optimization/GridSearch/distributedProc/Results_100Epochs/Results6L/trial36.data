2021-06-26
loss,0.7024527192115784,0.36877119541168213,0.29843536019325256,0.2626357972621918,0.24430827796459198,0.2379157394170761,0.23235073685646057,0.22710604965686798,0.22209441661834717,0.21477653086185455,0.18299250304698944,0.14063432812690735,0.11964108794927597,0.11945636570453644,0.10688012093305588,0.10083001106977463,0.0708712488412857,0.08819262683391571,0.06357318162918091,0.07493066042661667,0.0618436224758625,0.06691695004701614,0.04659753665328026,0.0697205439209938,0.059487227350473404,0.043651729822158813,0.04391225427389145,0.06154394522309303,0.043173667043447495,0.04391877353191376,0.04312792420387268,0.046673230826854706,0.0493517629802227,0.04800431430339813,0.04292827472090721,0.04162322357296944,0.03311119228601456,0.03538886085152626,0.04369058459997177,0.03904874250292778,0.043950896710157394,0.037276413291692734,0.029486767947673798,0.03864783048629761,0.039383552968502045,0.03171553462743759,0.0334184393286705,0.03265707567334175,0.03284109756350517,0.04033671319484711,0.034235142171382904,0.04072629287838936,0.03632735088467598,0.033592984080314636,0.03384539484977722,0.028124254196882248,0.034964997321367264,0.03381495922803879,0.02893287129700184,0.03130270540714264,0.03310972824692726,0.03336933255195618,0.03252056986093521,0.03121899999678135,0.02744738571345806,0.029586177319288254,0.03260330855846405,0.028810078278183937,0.029304735362529755,0.02578347735106945,0.022156689316034317,0.032542094588279724,0.029461707919836044,0.02722855657339096,0.02817494608461857,0.024922803044319153,0.023762833327054977,0.029374951496720314,0.029760051518678665,0.024714121595025063,0.024310464039444923,0.026344163343310356,0.02989574894309044,0.0295095294713974,0.026519937440752983,0.022044669836759567,0.020409666001796722,0.025458844378590584,0.028626637533307076,0.028327085077762604,0.026565052568912506,0.019810287281870842,0.022894002497196198,0.025770774111151695,0.025511985644698143,0.023463411256670952,0.02529091387987137,0.026302862912416458,0.024172363802790642,0.026003709062933922,
mse,0.21685653924942017,0.03938765823841095,0.027671286836266518,0.02222244255244732,0.02005920000374317,0.019431155174970627,0.018763301894068718,0.018070869147777557,0.01726440154016018,0.01533197145909071,0.01034974679350853,0.006150254048407078,0.004305037669837475,0.004636385478079319,0.003611290827393532,0.0031154907774180174,0.0016206461004912853,0.0022635594941675663,0.0012304047122597694,0.0017350157722830772,0.0011596382828429341,0.0013661470729857683,0.0006446175975725055,0.0013994509354233742,0.0010337100829929113,0.0005697851884178817,0.0005988029297441244,0.0010817727306857705,0.0005397740751504898,0.0005812636809423566,0.0005583455204032362,0.0006324353744275868,0.0007089375867508352,0.0006653944146819413,0.0005360805080272257,0.0005216995486989617,0.0003243188839405775,0.0003773408243432641,0.0005752122960984707,0.0004497904737945646,0.0005478034145198762,0.00041557580698281527,0.0002696336305234581,0.00043129545520059764,0.0004510694998316467,0.0003016883274540305,0.00033211937989108264,0.00031559012131765485,0.0003288798325229436,0.0004589041927829385,0.00034892582334578037,0.0004715033865068108,0.00037832013913430274,0.0003270070592407137,0.00033738958882167935,0.0002418317599222064,0.0003528091183397919,0.00033975153928622603,0.00025241312687285244,0.0002890507166739553,0.0003142376372125,0.0003220859507564455,0.0003029179642908275,0.0002825828269124031,0.00022440895554609597,0.0002545038878452033,0.0003024709003511816,0.0002400554221821949,0.000245183939114213,0.00019192640320397913,0.0001541073725093156,0.00030695481109432876,0.0002512235369067639,0.0002192616229876876,0.00022613018518313766,0.0001831067493185401,0.00017298985039815307,0.00025751491193659604,0.0002519358822610229,0.00017669818771537393,0.0001803819468477741,0.00020617291738744825,0.00025693749194033444,0.00024591380497440696,0.00019768057973124087,0.0001429705589544028,0.00012702053936664015,0.00019381979655008763,0.00023393493029288948,0.00023190090723801404,0.0002093520452035591,0.00011901216930709779,0.0001564393751323223,0.0001924819080159068,0.00019423924095463008,0.00015814948710612953,0.0001863664510892704,0.00019653505296446383,0.0001672884391155094,0.00019667651213239878,
mae,0.30558791756629944,0.16115158796310425,0.13251930475234985,0.1154308021068573,0.10950497537851334,0.10784655809402466,0.10589980334043503,0.1032819077372551,0.09994158893823624,0.09331123530864716,0.07845257967710495,0.05988803505897522,0.051085636019706726,0.051414936780929565,0.045695509761571884,0.04312547668814659,0.03021308220922947,0.037913743406534195,0.02699151821434498,0.03286348655819893,0.026248324662446976,0.028509998694062233,0.01979251764714718,0.02985328622162342,0.02515818551182747,0.018832780420780182,0.018651587888598442,0.026771552860736847,0.018345138058066368,0.01881192997097969,0.018315158784389496,0.02023545652627945,0.02142156846821308,0.02073342353105545,0.0185898095369339,0.017504166811704636,0.014121263287961483,0.015188800171017647,0.01870604231953621,0.016665009781718254,0.018737198784947395,0.016176234930753708,0.012429045513272285,0.016536934301257133,0.01695122756063938,0.01356724463403225,0.01421970222145319,0.013805175200104713,0.013960839249193668,0.017560381442308426,0.014543631114065647,0.017624089494347572,0.015538927167654037,0.014264324679970741,0.01405115146189928,0.012006363831460476,0.014993415214121342,0.014657511375844479,0.01222020760178566,0.01338984165340662,0.014325998723506927,0.01423954963684082,0.014098964631557465,0.013257013633847237,0.011741592548787594,0.012617707252502441,0.014025036245584488,0.012352949008345604,0.012520497664809227,0.010991900227963924,0.0094335051253438,0.014200360514223576,0.01264259684830904,0.011645205318927765,0.01204689871519804,0.010549886152148247,0.010278685949742794,0.012647363357245922,0.013023627921938896,0.010481714271008968,0.01041772123426199,0.011208654381334782,0.012961463071405888,0.013021502643823624,0.011337615549564362,0.009396811947226524,0.008713547140359879,0.010967632755637169,0.012507488951086998,0.012271459214389324,0.011338144540786743,0.008499872870743275,0.009726829826831818,0.010931921191513538,0.010462909005582333,0.010050845332443714,0.010878178291022778,0.011449233628809452,0.010439954698085785,0.011019041761755943,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 100043    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 100044    
=================================================================
Total params: 200,087
Trainable params: 200,087
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 100,043
Trainable params: 100,043
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 100,044
Trainable params: 100,044
Non-trainable params: 0
_________________________________________________________________
