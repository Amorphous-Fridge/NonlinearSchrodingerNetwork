2021-06-26
loss,0.5948856472969055,0.27734512090682983,0.2503179609775543,0.24179735779762268,0.23114162683486938,0.2224159836769104,0.21550993621349335,0.20999903976917267,0.20374040305614471,0.19579201936721802,0.18777528405189514,0.17950256168842316,0.16785219311714172,0.15970824658870697,0.17362675070762634,0.1649443507194519,0.1287456899881363,0.10818406194448471,0.11075089126825333,0.11825346946716309,0.1007319986820221,0.09000842273235321,0.0958399847149849,0.0902872085571289,0.07810723781585693,0.10485870391130447,0.09012225270271301,0.09079302102327347,0.10262724757194519,0.09039125591516495,0.07513852417469025,0.08466508984565735,0.08312034606933594,0.07447109371423721,0.06874831765890121,0.05690787360072136,0.0731450617313385,0.06648119539022446,0.06697069853544235,0.061292242258787155,0.06936860829591751,0.06548035889863968,0.0499470978975296,0.057300157845020294,0.06507982313632965,0.056914135813713074,0.05822864547371864,0.06055918708443642,0.05182082578539848,0.038933563977479935,0.04996955394744873,0.0447981059551239,0.03809470310807228,0.05133901163935661,0.04353895038366318,0.051400259137153625,0.0518675334751606,0.045303866267204285,0.03726096823811531,0.034926094114780426,0.050546690821647644,0.04416828230023384,0.037094417959451675,0.04264296963810921,0.042760010808706284,0.04140017181634903,0.029680704697966576,0.030177338048815727,0.026322048157453537,0.024939510971307755,0.024219639599323273,0.03166406229138374,0.03274136409163475,0.0358910858631134,0.04152301326394081,0.038054436445236206,0.03347914665937424,0.04023091867566109,0.03636397793889046,0.031811490654945374,0.0326005183160305,0.036338161677122116,0.0347403921186924,0.03109392151236534,0.03536215052008629,0.032587919384241104,0.027035968378186226,0.02880237065255642,0.030475396662950516,0.03203854709863663,0.03178059682250023,0.02855362370610237,0.030980192124843597,0.03035285696387291,0.02828441560268402,0.027095852419734,0.029241468757390976,0.025901973247528076,0.02294296771287918,0.03163289651274681,
mse,0.14713433384895325,0.023901667445898056,0.02028234675526619,0.01936257630586624,0.018081264570355415,0.016998015344142914,0.016002610325813293,0.01515238918364048,0.01417760830372572,0.013053239323198795,0.01195567473769188,0.010861195623874664,0.009505477733910084,0.008382240310311317,0.009502807632088661,0.008468453772366047,0.005533846560865641,0.004116099327802658,0.004139016382396221,0.004601748194545507,0.0032007417175918818,0.00254090060479939,0.0028614357579499483,0.0024418840184807777,0.0019046482630074024,0.0032464424148201942,0.0023790504783391953,0.00247048307210207,0.003042914904654026,0.002438192255795002,0.0016450088005512953,0.0021466566249728203,0.0020530708134174347,0.0016623937990516424,0.0014100230764597654,0.0009944611229002476,0.0015948287909850478,0.00133163807913661,0.0013005862710997462,0.0011104050790891051,0.001384380622766912,0.0012173012364655733,0.0007382234907709062,0.0009591681300662458,0.0012145328801125288,0.0009232749580405653,0.0009699982474558055,0.0010067634284496307,0.0007745184702798724,0.00045879613026045263,0.0007147387368604541,0.000570349395275116,0.0004190436447970569,0.0007589533342979848,0.0005411364836618304,0.0007597740041092038,0.0007384097552858293,0.0005779166240245104,0.00040003773756325245,0.0003567684907466173,0.000697400129865855,0.0005387102719396353,0.0003908933431375772,0.000529881042893976,0.0005071266205050051,0.00048325126408599317,0.00026194582460448146,0.00026867902488447726,0.0001999237429117784,0.0001752323587425053,0.00016968083218671381,0.0002844467817340046,0.00031530816340819,0.0003634823951870203,0.0005001327954232693,0.0003988981479778886,0.00031687726732343435,0.0004609264142345637,0.00036395277129486203,0.0002900702238548547,0.0003015030233655125,0.0003667637938633561,0.00032997247762978077,0.0002748439437709749,0.0003530450921971351,0.0002962883736472577,0.00021143315825611353,0.000237169602769427,0.00026055853231810033,0.0002867197326850146,0.0002875564678106457,0.00023143751604948193,0.00027105456683784723,0.00026539116515778005,0.00022724774316884577,0.00021278696658555418,0.00024177027808036655,0.00018768926383927464,0.00014894902415107936,0.0002920479455497116,
mae,0.25107014179229736,0.11931174248456955,0.10686130821704865,0.10413473844528198,0.10045738518238068,0.09730304032564163,0.09351058304309845,0.09063175320625305,0.08770574629306793,0.08386202901601791,0.08025360107421875,0.07640662789344788,0.07148563861846924,0.06844798475503922,0.0747951865196228,0.07176350802183151,0.05544808506965637,0.046399425715208054,0.04711035266518593,0.05082385241985321,0.04239644855260849,0.037980373948812485,0.04064935818314552,0.03842310234904289,0.03353329002857208,0.04441877827048302,0.038664206862449646,0.03843025118112564,0.04379911720752716,0.039295680820941925,0.03208688646554947,0.03580624237656593,0.036071643233299255,0.03232841566205025,0.029615318402647972,0.023710947483778,0.03136513754725456,0.02823697403073311,0.028707239776849747,0.026429476216435432,0.029427610337734222,0.028200356289744377,0.020731747150421143,0.024531174451112747,0.02814389020204544,0.024135388433933258,0.025011694058775902,0.025559192523360252,0.022032679989933968,0.01611030288040638,0.021221434697508812,0.018854904919862747,0.01617124117910862,0.022092171013355255,0.018763812258839607,0.022073889151215553,0.022220047190785408,0.01956416666507721,0.0154752591624856,0.014919552952051163,0.021466504782438278,0.01937829703092575,0.015834767371416092,0.018240494653582573,0.01864955946803093,0.017529617995023727,0.012628337368369102,0.012652445584535599,0.011162962764501572,0.010614179074764252,0.01035832054913044,0.013354701921343803,0.014020416885614395,0.015460748225450516,0.017471885308623314,0.016156887635588646,0.014284173026680946,0.017347000539302826,0.015507113188505173,0.013578692451119423,0.014003224670886993,0.015601514838635921,0.014950966462492943,0.01307939924299717,0.015406468883156776,0.014226073399186134,0.011466793715953827,0.012233709916472435,0.012919928878545761,0.01362234354019165,0.013836444355547428,0.012144332751631737,0.013286726549267769,0.012942803092300892,0.012023570947349072,0.01159931905567646,0.01261390931904316,0.011135002598166466,0.009667355567216873,0.01345223281532526,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 36435     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 36436     
=================================================================
Total params: 72,871
Trainable params: 72,871
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 36,435
Trainable params: 36,435
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 36,436
Trainable params: 36,436
Non-trainable params: 0
_________________________________________________________________
