2021-06-26
loss,0.31730416417121887,0.16986232995986938,0.11592847108840942,0.07802480459213257,0.05843605473637581,0.0487983264029026,0.03847386687994003,0.04189091548323631,0.03270217031240463,0.04119764268398285,0.03788767755031586,0.03260297700762749,0.03356431797146797,0.031899843364953995,0.030868567526340485,0.028225600719451904,0.02479814551770687,0.030938424170017242,0.029521264135837555,0.031604014337062836,0.029107071459293365,0.025312114506959915,0.024016423150897026,0.02640105038881302,0.027863936498761177,0.02565763145685196,0.026778066530823708,0.02588104084134102,0.024694494903087616,0.022134311497211456,0.019835053011775017,0.01994071528315544,0.025169849395751953,0.022655658423900604,0.02397182025015354,0.024484608322381973,0.021944276988506317,0.019510585814714432,0.01971881464123726,0.022754915058612823,0.023959800601005554,0.022922353819012642,0.020795032382011414,0.020789580419659615,0.022025151178240776,0.021151447668671608,0.019975991919636726,0.017850615084171295,0.01588638871908188,0.016230391338467598,0.018384749069809914,0.019768714904785156,0.019684750586748123,0.019243450835347176,0.017607323825359344,0.018140504136681557,0.020130397751927376,0.01986456662416458,0.017614124342799187,0.01674032025039196,0.015680259093642235,0.016313353553414345,0.014915852807462215,0.017887070775032043,0.017829211428761482,0.017089594155550003,0.018720382824540138,0.017208877950906754,0.015725204721093178,0.014669384807348251,0.014242252334952354,0.01643284410238266,0.016692720353603363,0.01773986406624317,0.015955453738570213,0.016256267204880714,0.017074357718229294,0.01571488194167614,0.015479713678359985,0.015169291757047176,0.016464540734887123,0.013843763619661331,0.013148042373359203,0.011309823021292686,0.010838275775313377,0.014605632051825523,0.016525696963071823,0.016084980219602585,0.016863534227013588,0.01571008376777172,0.015752339735627174,0.01494503952562809,0.014902322553098202,0.014536000788211823,0.013918845914304256,0.01336269173771143,0.01268832292407751,0.01290175411850214,0.014512307941913605,0.012774608097970486,
mse,0.036663901060819626,0.010718136094510555,0.003995165694504976,0.0018468888010829687,0.0010187400039285421,0.0007100019720382988,0.0004458415205590427,0.0005291449488140643,0.000320533465128392,0.0004879402695223689,0.00041114893974736333,0.0003067675861530006,0.00033046628232114017,0.00029524601995944977,0.0002790188300423324,0.00024240490165539086,0.00019003343186341226,0.00027709826827049255,0.0002516413514968008,0.0002783253730740398,0.0002445470599923283,0.00018994109996128827,0.00017838219355326146,0.00020112769561819732,0.00022372523380909115,0.00018969921802636236,0.0002080767444567755,0.00018929429643321782,0.00017457327339798212,0.0001503065723227337,0.00012197947216918692,0.0001251665671588853,0.00017480550741311163,0.0001502202940173447,0.00016812706599012017,0.0001669958292040974,0.00013785652117803693,0.00011322623322485015,0.00011743895447580144,0.0001494089374318719,0.00015772633196320385,0.00014625162293668836,0.00012235951726324856,0.00012497097486630082,0.00013557288912124932,0.00012599962064996362,0.00011317196913296357,9.771640179678798e-05,7.694971282035112e-05,8.059505489654839e-05,0.00010389518865849823,0.00011318661563564092,0.00010845183714991435,0.00010628961172187701,9.285563282901421e-05,9.46339569054544e-05,0.0001150479365605861,0.00011079438263550401,9.013240924105048e-05,8.175901166396216e-05,7.394566637231037e-05,8.390311268158257e-05,7.299913704628125e-05,9.157394379144534e-05,8.95507910172455e-05,8.744533988647163e-05,9.743058035383001e-05,8.424409315921366e-05,7.228843605844304e-05,6.500074232462794e-05,6.28162597422488e-05,8.052566408878192e-05,8.004131814232096e-05,8.71227020979859e-05,7.307689520530403e-05,7.664441363885999e-05,8.224912016885355e-05,7.212753553176299e-05,6.950416718609631e-05,6.764095451217145e-05,7.45027864468284e-05,5.8864261518465355e-05,5.384014002629556e-05,3.9949300116859376e-05,3.594394001993351e-05,6.456942355725914e-05,7.671894127270207e-05,7.188565359683707e-05,8.024690032470971e-05,7.053503941278905e-05,7.016649760771543e-05,6.400320853572339e-05,6.334578938549384e-05,6.0617763665504754e-05,5.604180114460178e-05,5.1695973525056615e-05,4.996818825020455e-05,5.111836799187586e-05,7.577524229418486e-05,5.0374736019875854e-05,
mae,0.14187760651111603,0.0753110721707344,0.04844387620687485,0.03322605788707733,0.025033636018633842,0.020595628768205643,0.016095811501145363,0.017787793651223183,0.013846708461642265,0.01747935824096203,0.016001926735043526,0.013863187283277512,0.014289959333837032,0.013506915420293808,0.013182281516492367,0.011905180290341377,0.01055315975099802,0.013117006048560143,0.012584365904331207,0.01365900132805109,0.012249959632754326,0.010731718502938747,0.01020654197782278,0.011216752231121063,0.011804556474089622,0.010923853144049644,0.011303490027785301,0.01083739846944809,0.010452031157910824,0.00933974888175726,0.008366557769477367,0.008443659171462059,0.010630249045789242,0.0093905134126544,0.010175934992730618,0.010314078070223331,0.009283018298447132,0.00823157001286745,0.008259391412138939,0.009695027023553848,0.010240601375699043,0.009768198244273663,0.008893630467355251,0.008852885104715824,0.009530472569167614,0.0090222442522645,0.008254332467913628,0.007291154470294714,0.006696744356304407,0.006876498460769653,0.007791473064571619,0.008333501406013966,0.008243344724178314,0.008168370462954044,0.007398201152682304,0.007708730176091194,0.008563578128814697,0.00831525307148695,0.007550729904323816,0.007165698334574699,0.006668125279247761,0.007025286089628935,0.006346104666590691,0.007677608169615269,0.007497504353523254,0.007279133424162865,0.007921525277197361,0.007129552308470011,0.006647580303251743,0.006336139515042305,0.00615732790902257,0.007001507095992565,0.007016139104962349,0.007488912902772427,0.006739126518368721,0.006984405685216188,0.00723645556718111,0.006708655972033739,0.006599402986466885,0.006417182739824057,0.0069226957857608795,0.005906993523240089,0.005586035083979368,0.004776818677783012,0.004654168616980314,0.006291367579251528,0.006962571293115616,0.006810096092522144,0.007242025341838598,0.006681262981146574,0.006600119639188051,0.006366059649735689,0.006327914074063301,0.006154811941087246,0.005893775261938572,0.005722528789192438,0.005383996292948723,0.005492882803082466,0.006126184947788715,0.005434839054942131,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 68611     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 68612     
=================================================================
Total params: 137,223
Trainable params: 137,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 512)               2560      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               65664     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 68,611
Trainable params: 68,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 2052      
=================================================================
Total params: 68,612
Trainable params: 68,612
Non-trainable params: 0
_________________________________________________________________
