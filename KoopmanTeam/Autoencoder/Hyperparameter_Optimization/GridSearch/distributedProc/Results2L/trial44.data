2021-06-26
loss,0.37408724427223206,0.11069025844335556,0.0783996731042862,0.051155366003513336,0.045568738132715225,0.044571809470653534,0.039617788046598434,0.044392574578523636,0.04059361293911934,0.041865795850753784,0.036421120166778564,0.04239509999752045,0.03632824867963791,0.03712555766105652,0.03264203667640686,0.03355458378791809,0.03669286146759987,0.02981559745967388,0.028534414246678352,0.03468625620007515,0.02916981652379036,0.029778307303786278,0.029075561091303825,0.03241322562098503,0.03047160804271698,0.024507608264684677,0.021780813112854958,0.02333051711320877,0.02865302376449108,0.028424246236681938,0.02619190886616707,0.022114261984825134,0.02352195419371128,0.02358567900955677,0.023178262636065483,0.023443548008799553,0.02397827059030533,0.024296164512634277,0.023019809275865555,0.02137262187898159,0.022637058049440384,0.021861955523490906,0.020483188331127167,0.021610351279377937,0.018487609922885895,0.020634043961763382,0.02078333869576454,0.021160535514354706,0.018625913187861443,0.019000034779310226,0.01707467995584011,0.015840863808989525,0.017152417451143265,0.016742181032896042,0.018144702538847923,0.01809859089553356,0.018450576812028885,0.0175656545907259,0.019230766221880913,0.019017182290554047,0.018995780497789383,0.01720929704606533,0.015772314742207527,0.015378058888018131,0.0166575126349926,0.017890090122818947,0.017531735822558403,0.016685282811522484,0.015377220697700977,0.015506130643188953,0.014178945682942867,0.017189105972647667,0.017086904495954514,0.017094433307647705,0.016397101804614067,0.015949197113513947,0.014123236760497093,0.013818102888762951,0.015059606172144413,0.015098576433956623,0.015753740444779396,0.0159116480499506,0.01498948223888874,0.01569400168955326,0.015850555151700974,0.015238404273986816,0.014374729245901108,0.014666210860013962,0.014835694804787636,0.015200665220618248,0.013383864425122738,0.012816941365599632,0.011050757020711899,0.012712452560663223,0.013926904648542404,0.014756539836525917,0.014216897077858448,0.014126972295343876,0.014003830030560493,0.014366159215569496,
mse,0.0555492639541626,0.004145000129938126,0.0018306529382243752,0.000782155548222363,0.0006090925890021026,0.0005735391168855131,0.00046832230873405933,0.0005962459254078567,0.0004783395561389625,0.0005154885584488511,0.00039369944715872407,0.0005286522791720927,0.0003866351908072829,0.00040255478234030306,0.00031807704363018274,0.0003299990785308182,0.000413701607612893,0.0002645398781169206,0.0002447293372824788,0.0003578379692044109,0.0002564959868323058,0.0002613374963402748,0.0002472134947311133,0.00031092928838916123,0.000267842406174168,0.00018185026419814676,0.0001423605572199449,0.00016497161414008588,0.00023594507365487516,0.0002266929514007643,0.0001954084145836532,0.0001497451594332233,0.00017001228115987033,0.00016526732360944152,0.0001567274157423526,0.00016264835721813142,0.00016548031999263912,0.00016731853247620165,0.0001509676658315584,0.00013617768127005547,0.0001472972653573379,0.00013381833559833467,0.00012436417455319315,0.00013770381337963045,0.00010498327173991129,0.00012453956878744066,0.00012528206571005285,0.0001231839560205117,0.00010408134403405711,0.00010761391604319215,8.827401325106621e-05,7.784857734804973e-05,9.023761231219396e-05,8.684127533342689e-05,0.00010062661749543622,9.815854718908668e-05,9.692833555163816e-05,9.116024011746049e-05,0.00010580986418062821,0.00010053978621726856,0.00010281211871188134,8.712062845006585e-05,7.538628415204585e-05,7.483123772544786e-05,8.376424375455827e-05,9.077761933440343e-05,8.738626638660207e-05,8.126739703584462e-05,7.181577529991046e-05,7.305372855626047e-05,6.163672514958307e-05,8.658978913445026e-05,8.346063987119123e-05,8.220316522056237e-05,7.466482202289626e-05,7.327702041948214e-05,6.055355697753839e-05,5.9162113757338375e-05,6.569199467776343e-05,6.806706369388849e-05,7.204448047559708e-05,7.38878661650233e-05,6.559438770636916e-05,6.943204789422452e-05,7.016775634838268e-05,6.916299753356725e-05,6.0642367316177115e-05,6.188955012476072e-05,6.340545951388776e-05,6.542320625158027e-05,5.512104326044209e-05,5.1137445552740246e-05,3.924035627278499e-05,4.990310480934568e-05,5.713465725420974e-05,6.042161476216279e-05,5.748084731749259e-05,5.6760109146125615e-05,5.583818710874766e-05,5.865656930836849e-05,
mae,0.1598455011844635,0.04674703627824783,0.03347410634160042,0.021786680445075035,0.019426129758358,0.019015038385987282,0.016932141035795212,0.01880686543881893,0.01728336326777935,0.017773019149899483,0.015521764755249023,0.01790390908718109,0.015529605560004711,0.015907445922493935,0.013854911550879478,0.014082356356084347,0.015554859302937984,0.012663733214139938,0.012144195847213268,0.014746993780136108,0.01249247882515192,0.012626699171960354,0.012354839593172073,0.013710631057620049,0.013043073005974293,0.010426853783428669,0.009313208982348442,0.0099707106128335,0.012091290205717087,0.01176808588206768,0.011159708723425865,0.009337433613836765,0.010164575651288033,0.01002854947000742,0.009884923696517944,0.009956377558410168,0.010142800398170948,0.010312242433428764,0.009648590348660946,0.008956710807979107,0.009581565856933594,0.009282431565225124,0.00866520032286644,0.00920969620347023,0.00796423014253378,0.00872605200856924,0.00880858302116394,0.008943012915551662,0.007910510525107384,0.008065983653068542,0.007278484757989645,0.006792681757360697,0.007260235492140055,0.007121135480701923,0.007573531474918127,0.007570276968181133,0.007890135981142521,0.0074268789030611515,0.00814508181065321,0.008098437450826168,0.007735258899629116,0.007248906884342432,0.006713532377034426,0.006513520609587431,0.0071395086124539375,0.0075532919727265835,0.007431803271174431,0.007062239106744528,0.006594508420675993,0.006440647877752781,0.006059561390429735,0.0072494689375162125,0.0071449740789830685,0.007210221141576767,0.007017153315246105,0.006675684358924627,0.005996824707835913,0.0057785785757005215,0.006384580861777067,0.006308646406978369,0.0067483787424862385,0.006725110579282045,0.006385460961610079,0.006654518190771341,0.006728005595505238,0.006459417287260294,0.006030860356986523,0.006238073576241732,0.006267317105084658,0.0064336019568145275,0.005629410967230797,0.00544370710849762,0.0046770693734288216,0.005359213333576918,0.005929457955062389,0.00622454471886158,0.005987228360027075,0.0060508353635668755,0.005927950143814087,0.006055918987840414,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 134659    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 134660    
=================================================================
Total params: 269,319
Trainable params: 269,319
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 512)               2560      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               131328    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 134,659
Trainable params: 134,659
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 2052      
=================================================================
Total params: 134,660
Trainable params: 134,660
Non-trainable params: 0
_________________________________________________________________
