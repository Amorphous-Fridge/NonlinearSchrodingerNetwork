2021-06-26
loss,0.31187161803245544,0.1305292695760727,0.054132018238306046,0.037145357578992844,0.033211421221494675,0.030357766896486282,0.027746926993131638,0.026516437530517578,0.02499213255941868,0.02432180941104889,0.023549528792500496,0.02270156890153885,0.022225357592105865,0.021741459146142006,0.021200012415647507,0.020812271162867546,0.020382052287459373,0.022481005638837814,0.030420301482081413,0.030251307412981987,0.03201739862561226,0.03045269288122654,0.027313435450196266,0.025704173371195793,0.024555038660764694,0.02359926514327526,0.023030493408441544,0.022004375234246254,0.020223798230290413,0.018984327092766762,0.018123246729373932,0.01746334880590439,0.016957197338342667,0.016670694574713707,0.01755237765610218,0.02297472395002842,0.020427241921424866,0.019290205091238022,0.0201724823564291,0.0261828750371933,0.023301862180233,0.02216828614473343,0.021232910454273224,0.020537523552775383,0.01998414844274521,0.01961894892156124,0.019618205726146698,0.018982263281941414,0.030016399919986725,0.030878407880663872,0.030700035393238068,0.02657267265021801,0.02339000068604946,0.021603474393486977,0.020322784781455994,0.019378473982214928,0.018681488931179047,0.01652393862605095,0.020079635083675385,0.02950877696275711,0.026580853387713432,0.026128342375159264,0.023187095299363136,0.018999740481376648,0.022405173629522324,0.0247898381203413,0.022363755851984024,0.020377088338136673,0.019202759489417076,0.018419284373521805,0.017849450930953026,0.017334669828414917,0.016911832615733147,0.016560135409235954,0.01623750850558281,0.01597015932202339,0.015789324417710304,0.018296929076313972,0.017768964171409607,0.026388229802250862,0.026046140119433403,0.0240643210709095,0.022609328851103783,0.020097678527235985,0.018650896847248077,0.017586644738912582,0.016848556697368622,0.016258612275123596,0.016507361084222794,0.0249521154910326,0.022440819069743156,0.021389413625001907,0.020551281049847603,0.018339715898036957,0.017433591187000275,0.016598355025053024,0.016062987968325615,0.015555665828287601,0.015174082480370998,0.01478438451886177,
mse,0.03573278337717056,0.006512622814625502,0.0009746982832439244,0.0004523410170804709,0.0003495413693599403,0.00028450728859752417,0.00024331772874575108,0.00021373950585257262,0.00018688541604205966,0.0001766959176165983,0.00016461969062220305,0.00015243970847222954,0.00014475049101747572,0.00013787008356302977,0.0001299785217270255,0.00012539004092104733,0.00012236386828590184,0.0001585359568707645,0.00027029632474295795,0.00025479833129793406,0.00029251797241158783,0.0002534907544031739,0.00020840046636294574,0.00018411120981909335,0.00016871704428922385,0.00015613298455718905,0.00014920863031875342,0.00013478922483045608,0.0001135720158345066,0.0001008832550724037,9.248804417438805e-05,8.598213753430173e-05,8.130509377224371e-05,7.930661377031356e-05,9.39297242439352e-05,0.00015423733566422015,0.00012400693958625197,0.00010869011020986363,0.0001222135906573385,0.00018471185467205942,0.000150047053466551,0.00013394409324973822,0.00012361622066237032,0.00011649147927528247,0.00011002339306287467,0.00010722570004872978,0.0001067572520696558,0.00010360535088693723,0.00025874815764836967,0.0002666109357960522,0.0002591657394077629,0.00019272702047601342,0.00014932516205590218,0.00012801654520444572,0.00011432757310103625,0.00010454221774125472,9.726668940857053e-05,8.296986925415695e-05,0.00012724123371299356,0.00024355204368475825,0.00020283965568523854,0.00019273001817055047,0.0001525349507573992,0.00010518784984014928,0.00014448046567849815,0.000170641447766684,0.00013847817899659276,0.00011401140363886952,0.00010115268378285691,9.37301228987053e-05,8.86293055373244e-05,8.346941467607394e-05,8.025020360946655e-05,7.700164860580117e-05,7.418885070364922e-05,7.125581032596529e-05,7.095711043803021e-05,9.669998689787462e-05,9.354763460578397e-05,0.0001968408323591575,0.00018959424050990492,0.00016395766579080373,0.00014139240374788642,0.00011262320185778663,9.5439150754828e-05,8.48587806103751e-05,7.818324229447171e-05,7.349705265369266e-05,7.874594302847981e-05,0.00017277925508096814,0.00014424925029743463,0.00013270173803903162,0.0001171242183772847,9.366799349663779e-05,8.378757047466934e-05,7.591560279252008e-05,7.136274507502094e-05,6.773573841201141e-05,6.426805339287966e-05,6.136922456789762e-05,
mae,0.1371946632862091,0.054278627038002014,0.022855930030345917,0.01577114872634411,0.014126804657280445,0.012913394719362259,0.011889852583408356,0.01120682805776596,0.010631702840328217,0.010348615236580372,0.010052266530692577,0.009678203612565994,0.009518812410533428,0.00922255776822567,0.008977644145488739,0.008850027807056904,0.008671879768371582,0.009701789356768131,0.013064634054899216,0.013279590755701065,0.013774270191788673,0.01333719864487648,0.011987477540969849,0.011227970011532307,0.010695477947592735,0.010265301913022995,0.010004788637161255,0.009560782462358475,0.008788702078163624,0.008256946690380573,0.007868443615734577,0.007560737896710634,0.007270974572747946,0.007111025042831898,0.007510434836149216,0.010420480743050575,0.009312496520578861,0.008387433364987373,0.00859297625720501,0.01126270741224289,0.01001560315489769,0.009568561799824238,0.009127947501838207,0.008907189592719078,0.008703270927071571,0.008463992737233639,0.008360210806131363,0.008043279871344566,0.012959754094481468,0.013611622154712677,0.013470185920596123,0.011806515045464039,0.01063818484544754,0.00980368908494711,0.009248092770576477,0.008791182190179825,0.008380800485610962,0.007061528507620096,0.00861232727766037,0.012572611682116985,0.01141672395169735,0.011835642158985138,0.010329748503863811,0.008215093985199928,0.00985416304320097,0.010466646403074265,0.009831929579377174,0.00923897884786129,0.008602466434240341,0.008214272558689117,0.007921871729195118,0.007660610601305962,0.007444099988788366,0.007301055360585451,0.007139098830521107,0.007017631083726883,0.006803518161177635,0.008105919696390629,0.007612226530909538,0.011632507666945457,0.011674918234348297,0.010781368240714073,0.010040122084319592,0.008908893913030624,0.008222553879022598,0.007711304817348719,0.007488044444471598,0.007248621433973312,0.007193026132881641,0.011085343547165394,0.0101036187261343,0.009346679784357548,0.008815210312604904,0.008137091062963009,0.007803491782397032,0.007384542841464281,0.007107479963451624,0.006841040216386318,0.006641467101871967,0.006472193636000156,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9091      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9092      
=================================================================
Total params: 18,183
Trainable params: 18,183
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 9,091
Trainable params: 9,091
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 9,092
Trainable params: 9,092
Non-trainable params: 0
_________________________________________________________________
