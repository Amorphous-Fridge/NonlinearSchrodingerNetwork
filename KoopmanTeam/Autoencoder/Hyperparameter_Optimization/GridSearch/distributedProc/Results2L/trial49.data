2021-06-26
loss,0.2971996068954468,0.11298045516014099,0.06072425842285156,0.05783558264374733,0.053455900400877,0.05125807225704193,0.04478020220994949,0.04290720075368881,0.03711351379752159,0.048809994012117386,0.036564797163009644,0.039753057062625885,0.034096136689186096,0.03205962851643562,0.029081666842103004,0.027465002611279488,0.025493735447525978,0.02202337235212326,0.025698652490973473,0.02764947898685932,0.027331167832016945,0.024921495467424393,0.023304123431444168,0.034018903970718384,0.02753526158630848,0.026159459725022316,0.027077728882431984,0.029103701934218407,0.02720361202955246,0.022967109456658363,0.020846569910645485,0.018696775659918785,0.022460713982582092,0.025350306183099747,0.02471861056983471,0.025783099234104156,0.02163264900445938,0.01976519078016281,0.018143439665436745,0.016478408128023148,0.014111391268670559,0.013225018046796322,0.012779271230101585,0.012693929485976696,0.012436674907803535,0.012384360656142235,0.012224343605339527,0.012137680314481258,0.012049823999404907,0.01194057334214449,0.011867605149745941,0.011734425090253353,0.011710355058312416,0.011710838414728642,0.011609976179897785,0.011584162712097168,0.014955065213143826,0.016626115888357162,0.017653828486800194,0.020867228507995605,0.018077408894896507,0.015902239829301834,0.015217437408864498,0.018833452835679054,0.02077343687415123,0.01942799985408783,0.01735924556851387,0.019531384110450745,0.01906002126634121,0.01828703097999096,0.017182394862174988,0.016076870262622833,0.01464309822767973,0.015063314698636532,0.016689354553818703,0.019662151113152504,0.017993513494729996,0.016542382538318634,0.01579025574028492,0.014005813747644424,0.014291826635599136,0.014878218062222004,0.016490722075104713,0.016060229390859604,0.016711415722966194,0.016189923509955406,0.017334334552288055,0.019471807405352592,0.017288794741034508,0.01597031019628048,0.015023796819150448,0.013887163251638412,0.0134183494374156,0.015034710988402367,0.016497399657964706,0.01682431437075138,0.014555811882019043,0.013417388312518597,0.01491551660001278,0.013979434967041016,
mse,0.0318155400454998,0.004416949115693569,0.0011653535766527057,0.0010700580896809697,0.0008724938379600644,0.0008067890303209424,0.0005931271007284522,0.0005269931280054152,0.00041465871618129313,0.0006955992430448532,0.00040243237162940204,0.00046171818394213915,0.00034698747913353145,0.0003004184109158814,0.00024346579448319972,0.00021844169532414526,0.0001907034748001024,0.0001418676838511601,0.00020957703236490488,0.00022591942979488522,0.00021154552814550698,0.00017353350995108485,0.00015439445269294083,0.0003370477934367955,0.00022904141223989427,0.00020081232651136816,0.00020832347217947245,0.00024743349058553576,0.00021899378043599427,0.00015238841297104955,0.00012621987843886018,0.00010717296390794218,0.00015342631377279758,0.00018017592083197087,0.00017789233243092895,0.00019521570357028395,0.00013470821431837976,0.00011186797200934961,9.624184167478234e-05,8.330188575200737e-05,5.9227309975540265e-05,5.248277375358157e-05,4.978030119673349e-05,4.816605360247195e-05,4.640589395421557e-05,4.596322833094746e-05,4.504890966927633e-05,4.492268999456428e-05,4.3226424168096855e-05,4.235859523760155e-05,4.159499076195061e-05,4.133549373364076e-05,4.054595410707407e-05,4.0759900002740324e-05,4.051643918501213e-05,4.0091978007694706e-05,7.190721953520551e-05,8.566370524931699e-05,9.51229376369156e-05,0.00011984282900812104,9.32052789721638e-05,7.740991713944823e-05,7.117373024811968e-05,0.00010053418372990564,0.00012231632717885077,0.00010929370182566345,9.242635132977739e-05,0.00010821282194228843,0.00010332455713069066,9.293691982747987e-05,8.368394628632814e-05,7.44979188311845e-05,6.562264024978504e-05,7.088965503498912e-05,8.355184399988502e-05,0.00010700325219659135,9.148169192485511e-05,7.730888319201767e-05,7.106691919034347e-05,6.0330410633469e-05,6.185590609675273e-05,6.760749965906143e-05,7.858297612983733e-05,7.635779911652207e-05,8.194844849640504e-05,7.356255082413554e-05,8.514103683410212e-05,0.0001062484661815688,8.706433436600491e-05,7.440269109793007e-05,6.527883670059964e-05,5.786789188277908e-05,5.5616899771848693e-05,6.612508877879009e-05,7.664146687602624e-05,7.964207179611549e-05,6.626763934036717e-05,5.4827978601679206e-05,6.602502980967984e-05,5.720658373320475e-05,
mae,0.1302252560853958,0.046817053109407425,0.025974586606025696,0.02479110285639763,0.022709405049681664,0.022059574723243713,0.019048569723963737,0.018334917724132538,0.015851009637117386,0.020802579820156097,0.01557114627212286,0.01678941398859024,0.01439102552831173,0.013692162930965424,0.01240625511854887,0.011881142854690552,0.010912543162703514,0.009341132827103138,0.010832705534994602,0.011540239676833153,0.01155977975577116,0.010747944004833698,0.010018465109169483,0.014364208094775677,0.011724632233381271,0.01110507920384407,0.011304502375423908,0.01215390209108591,0.01124622579663992,0.009725970216095448,0.008836445398628712,0.007957489229738712,0.00969717651605606,0.010815258137881756,0.01029807236045599,0.010661897249519825,0.009188014082610607,0.008362987078726292,0.007822340354323387,0.007078403141349554,0.0060201543383300304,0.005530436523258686,0.005390720907598734,0.00543729355558753,0.005265714600682259,0.005267402622848749,0.005151824560016394,0.005178066436201334,0.005138182546943426,0.005069027654826641,0.005059078335762024,0.005016995593905449,0.004963470622897148,0.005015178117901087,0.004974429029971361,0.0049370890483260155,0.0064196400344371796,0.007084059529006481,0.007497989106923342,0.0088657196611166,0.007728150114417076,0.0067795999348163605,0.006343854125589132,0.007903007790446281,0.00875606294721365,0.008302884176373482,0.007387460675090551,0.008306501433253288,0.008108383044600487,0.007644964382052422,0.0071428497321903706,0.006805530749261379,0.006310137454420328,0.0064511424861848354,0.0070861889980733395,0.00820297934114933,0.007500257343053818,0.007035898510366678,0.006698150187730789,0.005930100101977587,0.006070241332054138,0.006320806220173836,0.0070158070884644985,0.006869213189929724,0.007082308642566204,0.006910532247275114,0.007397608831524849,0.00810797419399023,0.00728117348626256,0.0068540568463504314,0.006484377197921276,0.005938808899372816,0.005693791899830103,0.0063692484982311726,0.00701084453612566,0.0071984147652983665,0.006179106887429953,0.005680524744093418,0.006309360731393099,0.006012488156557083,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 38019     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 38020     
=================================================================
Total params: 76,039
Trainable params: 76,039
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 1024)              5120      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                32800     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 38,019
Trainable params: 38,019
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 1024)              33792     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 4100      
=================================================================
Total params: 38,020
Trainable params: 38,020
Non-trainable params: 0
_________________________________________________________________
