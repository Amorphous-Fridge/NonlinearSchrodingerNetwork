2021-06-26
loss,0.2741241157054901,0.0792132019996643,0.04876755550503731,0.03651506081223488,0.029840020462870598,0.026470473036170006,0.024544768035411835,0.02299477346241474,0.022064581513404846,0.021163299679756165,0.020482167601585388,0.019876370206475258,0.019091328606009483,0.018918531015515327,0.01826426573097706,0.017832551151514053,0.017441175878047943,0.01716124266386032,0.016878338530659676,0.016565347090363503,0.016220325604081154,0.015957901254296303,0.015747718513011932,0.01556649710983038,0.01533900573849678,0.015170141123235226,0.014953041449189186,0.014795590192079544,0.014784686267375946,0.014459553174674511,0.01432066410779953,0.014211129397153854,0.013950803317129612,0.013944188132882118,0.013845694251358509,0.013692720793187618,0.013561751693487167,0.013409598730504513,0.013325542211532593,0.01321030966937542,0.012990121729671955,0.012903067283332348,0.023033306002616882,0.02177172712981701,0.02081434801220894,0.01951327919960022,0.01855740323662758,0.017734335735440254,0.017202945426106453,0.01669682189822197,0.016246791929006577,0.015944387763738632,0.015576842240989208,0.015152834355831146,0.019784916192293167,0.022862032055854797,0.02012811228632927,0.01873118430376053,0.01775500737130642,0.017047930508852005,0.016419457271695137,0.01596946269273758,0.015566578134894371,0.018756037577986717,0.024935200810432434,0.02173594757914543,0.020192276686429977,0.019132040441036224,0.0181975569576025,0.017586054280400276,0.017055317759513855,0.01644698530435562,0.01588721014559269,0.01534473616629839,0.014866410754621029,0.014431263320147991,0.014027153141796589,0.013591284863650799,0.013380318880081177,0.01617601327598095,0.017500177025794983,0.01614724099636078,0.015294399112462997,0.014823082834482193,0.014362943358719349,0.013570267707109451,0.0126807177439332,0.013663094490766525,0.01430382952094078,0.011250192299485207,0.010470866225659847,0.009992077946662903,0.00980054959654808,0.009508952498435974,0.00931454636156559,0.009196171537041664,0.009210880845785141,0.009125050157308578,0.009008384309709072,0.009083121083676815,
mse,0.031374868005514145,0.0022576453629881144,0.0008562481962144375,0.00047886677202768624,0.0003073351108469069,0.00023098671226762235,0.00019159296061843634,0.0001644015865167603,0.00015008893387857825,0.00013636543008033186,0.000126379425637424,0.0001178822640213184,0.00010860161273740232,0.00010567733988864347,9.87238745437935e-05,9.388233593199402e-05,8.926889131544158e-05,8.62233282532543e-05,8.321752829942852e-05,7.991064194357023e-05,7.634508074261248e-05,7.389843085547909e-05,7.206689042504877e-05,7.010516128502786e-05,6.791067426092923e-05,6.750460306648165e-05,6.44996325718239e-05,6.311797187663615e-05,6.287093856371939e-05,6.039878644514829e-05,5.9052323194919154e-05,5.785865869256668e-05,5.598908683168702e-05,5.563511876971461e-05,5.547210093936883e-05,5.362009324016981e-05,5.286417581373826e-05,5.1771941798506305e-05,5.092439096188173e-05,5.0444872613297775e-05,4.997716678190045e-05,4.930972136207856e-05,0.00017676682909950614,0.00013392796972766519,0.0001171371404780075,0.00010396492871223018,9.485740156378597e-05,8.770573185756803e-05,8.294838335132226e-05,7.871209527365863e-05,7.514537719544023e-05,7.228447793750092e-05,6.933823897270486e-05,6.592366116819903e-05,0.00011946311133215204,0.0001445556408725679,0.0001144538473454304,0.00010041126370197162,9.0025358076673e-05,8.327997056767344e-05,7.748421921860427e-05,7.293602538993582e-05,6.947362999198958e-05,0.00010988559370161965,0.00018088784418068826,0.00013422784104477614,0.00011681218893500045,0.00010597040818538517,9.649106505094096e-05,9.035657421918586e-05,8.535917731933296e-05,7.901411299826577e-05,7.28426020941697e-05,6.762724660802633e-05,6.313221820164472e-05,5.978740591672249e-05,5.6508077250327915e-05,5.3779072914039716e-05,5.305094236973673e-05,7.679493864998221e-05,8.538196561858058e-05,7.431874837493524e-05,6.722145189996809e-05,6.32751252851449e-05,5.9853085986105725e-05,5.421261448645964e-05,4.885412272415124e-05,5.47053205082193e-05,5.8101850299863145e-05,3.8963993574725464e-05,3.2392596040153876e-05,2.942533501482103e-05,2.7960873921983875e-05,2.6594230803311802e-05,2.5622104658395983e-05,2.4989871235447936e-05,2.4832408598740585e-05,2.4435170416836627e-05,2.4096949346130714e-05,2.4328728613909334e-05,
mae,0.11523130536079407,0.03345099091529846,0.021010247990489006,0.015537283383309841,0.012646074406802654,0.01125255599617958,0.010364596731960773,0.009764253161847591,0.009401645511388779,0.008976622484624386,0.008738597854971886,0.008414640091359615,0.008070982992649078,0.00804950576275587,0.007805514149367809,0.007619516924023628,0.007375551853328943,0.0073158335871994495,0.007218633312731981,0.007036196067929268,0.006830579601228237,0.006792264524847269,0.006726400926709175,0.006680128630250692,0.006548108067363501,0.006492071785032749,0.0063695842400193214,0.006294063292443752,0.006306794937700033,0.0061073992401361465,0.006108787842094898,0.006025714799761772,0.005981994792819023,0.005901877302676439,0.005967970006167889,0.0058952318504452705,0.005825038533657789,0.005701120477169752,0.005757204256951809,0.0056668673641979694,0.005470748990774155,0.005524184554815292,0.009900974109768867,0.00932006724178791,0.009493377059698105,0.008907312527298927,0.008441461250185966,0.008008959703147411,0.0077409385703504086,0.0074924286454916,0.007266286760568619,0.0070859529078006744,0.006897949613630772,0.006555612664669752,0.008547311648726463,0.009821752086281776,0.00865570642054081,0.008040652610361576,0.007613758556544781,0.007331398315727711,0.007021777797490358,0.006747725419700146,0.006477534305304289,0.00789011549204588,0.010662656277418137,0.009334871545433998,0.008680630475282669,0.008194124326109886,0.007732325699180365,0.007389521691948175,0.007114769890904427,0.006720249075442553,0.006323209032416344,0.006157826632261276,0.00603525061160326,0.005887089762836695,0.005707794800400734,0.005634131375700235,0.005571207031607628,0.006958785001188517,0.0077708447352051735,0.007104228716343641,0.006606615148484707,0.0062231384217739105,0.005884738638997078,0.005628627724945545,0.005389726255089045,0.005851255729794502,0.0060462974943220615,0.004805120173841715,0.004461931064724922,0.004261295311152935,0.004174667876213789,0.00407476956024766,0.003983795177191496,0.003923967480659485,0.003942748531699181,0.003901940304785967,0.003852641675621271,0.003931964281946421,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5203      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5204      
=================================================================
Total params: 10,407
Trainable params: 10,407
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 5,203
Trainable params: 5,203
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 5,204
Trainable params: 5,204
Non-trainable params: 0
_________________________________________________________________
