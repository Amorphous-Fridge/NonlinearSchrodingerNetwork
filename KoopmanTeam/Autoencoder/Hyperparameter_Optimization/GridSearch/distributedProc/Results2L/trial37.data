2021-06-26
loss,0.36232566833496094,0.10061938315629959,0.05797680467367172,0.049651723355054855,0.04451034590601921,0.048388902097940445,0.04356918856501579,0.039128199219703674,0.039936359971761703,0.0381816104054451,0.034791361540555954,0.03343157842755318,0.030255639925599098,0.03127796947956085,0.03913993760943413,0.033108510076999664,0.029494207352399826,0.02877330593764782,0.028312215581536293,0.031527917832136154,0.028452550992369652,0.028768250718712807,0.03050190396606922,0.02939004637300968,0.028228824958205223,0.02532726526260376,0.023918382823467255,0.024638663977384567,0.027014348655939102,0.024387851357460022,0.02469204179942608,0.026661941781640053,0.02296680025756359,0.021636493504047394,0.02234014682471752,0.021090509369969368,0.020791837945580482,0.021891728043556213,0.021351303905248642,0.01949259825050831,0.020642586052417755,0.021060071885585785,0.01933676190674305,0.018363628536462784,0.018009155988693237,0.01970921829342842,0.020378876477479935,0.01962140016257763,0.01744881458580494,0.016602160409092903,0.018346767872571945,0.01912529766559601,0.020487651228904724,0.018395977094769478,0.01651628315448761,0.015062813647091389,0.018428897485136986,0.01874510571360588,0.018688198179006577,0.017159536480903625,0.015955602750182152,0.014810651540756226,0.01438814401626587,0.015591675415635109,0.016052763909101486,0.017798490822315216,0.016168279573321342,0.014884239062666893,0.015021043829619884,0.016849543899297714,0.016063567250967026,0.015573812648653984,0.017152324318885803,0.017157956957817078,0.015615930780768394,0.013444997370243073,0.014119621366262436,0.015315763652324677,0.014773720875382423,0.01388300210237503,0.013080259785056114,0.012852665036916733,0.014483954757452011,0.015535500831902027,0.013892662711441517,0.013652549125254154,0.015363670885562897,0.017308276146650314,0.01581587642431259,0.014858323149383068,0.013989696279168129,0.01293046586215496,0.011926263570785522,0.01153521053493023,0.014805556274950504,0.014907271601259708,0.013863538391888142,0.013505494222044945,0.014140807092189789,0.013635337352752686,
mse,0.052357107400894165,0.0032273719552904367,0.0009959823219105601,0.0007468897383660078,0.0005903863930143416,0.0007378000882454216,0.000551703735254705,0.00045757528278045356,0.00047193936188705266,0.0004263286537025124,0.0003578515024855733,0.00032068626023828983,0.0002674204879440367,0.00029097480000928044,0.0004376009455882013,0.00031731280614621937,0.0002622170140966773,0.0002484607102815062,0.00023196391703095287,0.0002887144801206887,0.00024816111545078456,0.00024846597807481885,0.00030005082953721285,0.000252451776759699,0.0002325544919585809,0.0001917778718052432,0.00017115326772909611,0.0001798687007976696,0.000209086065297015,0.0001777470315573737,0.00018041388830170035,0.00019763255841098726,0.00015154910215642303,0.0001402239577146247,0.00014640881272498518,0.00013580302766058594,0.00013155741908121854,0.00014337911852635443,0.00013503117952495813,0.00011589022324187681,0.0001254678936675191,0.00012822472490370274,0.00011032438487745821,0.00010387200745753944,0.00010023736103903502,0.000114029498945456,0.00011913520575035363,0.0001103720351238735,8.958920807344839e-05,8.568247721996158e-05,0.00010530031431699172,0.00010748707427410409,0.00011718655150616542,9.605823288438842e-05,8.202766912290826e-05,7.178122905315831e-05,9.87186940619722e-05,9.837882680585608e-05,9.749597666086629e-05,8.338065526913851e-05,7.403625932056457e-05,6.50815709377639e-05,6.203633529366925e-05,7.498534978367388e-05,7.671692583244294e-05,8.933443314163014e-05,7.798473234288394e-05,6.611581920878962e-05,6.786808808101341e-05,8.040613465709612e-05,7.424207433359697e-05,7.114958134479821e-05,8.312150748679414e-05,8.34572347230278e-05,7.078726048348472e-05,5.592166417045519e-05,6.085626228014007e-05,6.705551641061902e-05,6.303088593995199e-05,5.7299774198327214e-05,5.20466455782298e-05,5.247025910648517e-05,6.308758747763932e-05,6.797584501327947e-05,5.756070822826587e-05,5.677201261278242e-05,6.932672840775922e-05,8.505327423335984e-05,7.313008973142132e-05,6.405948079191148e-05,5.6527493143221363e-05,4.988231376046315e-05,4.296968108974397e-05,4.0688635635888204e-05,6.320847023744136e-05,6.238085916265845e-05,5.5526994401589036e-05,5.355300527298823e-05,5.585435428656638e-05,5.2643394155893475e-05,
mae,0.1540013551712036,0.04274605214595795,0.024452608078718185,0.02119707316160202,0.01898966357111931,0.020634539425373077,0.01874309964478016,0.016713880002498627,0.017132598906755447,0.016068406403064728,0.014938290230929852,0.014258292503654957,0.012828094884753227,0.013251880183815956,0.01658342406153679,0.014037392102181911,0.012547500431537628,0.01227575447410345,0.012073136866092682,0.013386333361268044,0.011927987448871136,0.012110811658203602,0.012938753701746464,0.012470717541873455,0.01211197953671217,0.010705143213272095,0.010174471884965897,0.010357627645134926,0.011471293866634369,0.010383175686001778,0.0104511808604002,0.011318773031234741,0.009600206278264523,0.009288608096539974,0.009534860029816628,0.008931213989853859,0.008626583032310009,0.009179113432765007,0.009014120325446129,0.008234238252043724,0.008829922415316105,0.008717513643205166,0.008269383572041988,0.007795167621225119,0.007575640454888344,0.008280607871711254,0.008452254347503185,0.008345142006874084,0.007415164727717638,0.006964198313653469,0.007811902556568384,0.008248007856309414,0.008781890384852886,0.007826007902622223,0.006995316594839096,0.006505241617560387,0.007698814384639263,0.007933289743959904,0.007916200906038284,0.007308940403163433,0.006745413411408663,0.006275647319853306,0.006207642145454884,0.006625021807849407,0.00683214794844389,0.0075682117603719234,0.006791842635720968,0.006272939499467611,0.00642321165651083,0.007011956535279751,0.006759920157492161,0.0066046635620296,0.007297569420188665,0.007309194188565016,0.00661679869517684,0.005707672331482172,0.005980001296848059,0.006438082084059715,0.006334070581942797,0.005974635481834412,0.005619989708065987,0.005464872810989618,0.006153987254947424,0.006550829391926527,0.006014422047883272,0.005828294903039932,0.006587557028979063,0.007463373709470034,0.006701730657368898,0.006231552455574274,0.005927944090217352,0.005376707762479782,0.0049342261627316475,0.004766255151480436,0.006227018777281046,0.006390226073563099,0.00582075072452426,0.005773197393864393,0.006068916991353035,0.0058280485682189465,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 134403    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 134404    
=================================================================
Total params: 268,807
Trainable params: 268,807
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 1539      
=================================================================
Total params: 134,403
Trainable params: 134,403
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 512)               2048      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 134,404
Trainable params: 134,404
Non-trainable params: 0
_________________________________________________________________
