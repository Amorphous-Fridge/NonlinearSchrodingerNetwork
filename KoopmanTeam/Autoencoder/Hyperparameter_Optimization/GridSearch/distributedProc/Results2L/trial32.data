2021-06-26
loss,0.36484992504119873,0.16040875017642975,0.06762988120317459,0.04495866596698761,0.035886965692043304,0.031239472329616547,0.027076004073023796,0.02487584576010704,0.02338818460702896,0.02221590280532837,0.02158275619149208,0.020533442497253418,0.019937844946980476,0.019480925053358078,0.018761953338980675,0.018345074728131294,0.017906203866004944,0.017532091587781906,0.017083758488297462,0.01687689870595932,0.01660214550793171,0.01628078520298004,0.016041364520788193,0.015866169705986977,0.015586325898766518,0.015450051054358482,0.015188894234597683,0.015155878849327564,0.0147912772372365,0.019543275237083435,0.02009856142103672,0.023661741986870766,0.023421594873070717,0.021386737003922462,0.02018766477704048,0.01928713172674179,0.018492959439754486,0.017888961359858513,0.017420178279280663,0.017189448699355125,0.020687773823738098,0.02716691419482231,0.024150142446160316,0.02177422307431698,0.020399125292897224,0.01942022144794464,0.018519699573516846,0.017901282757520676,0.01732219196856022,0.016805274412035942,0.01705956645309925,0.02750502899289131,0.024034272879362106,0.022487781941890717,0.020265426486730576,0.01884077861905098,0.01789809763431549,0.01700836792588234,0.015526668168604374,0.014632689766585827,0.014088778756558895,0.014179924502968788,0.017527760937809944,0.020842252299189568,0.023432467132806778,0.018640529364347458,0.01936463825404644,0.018469372764229774,0.017139870673418045,0.01636643335223198,0.015914147719740868,0.015438481234014034,0.015139291062951088,0.01475986372679472,0.014494705013930798,0.014295598492026329,0.014068723656237125,0.014159759506583214,0.01807144656777382,0.02369077503681183,0.02193138748407364,0.020197832956910133,0.018837329000234604,0.017476849257946014,0.0166474562138319,0.01570006087422371,0.014448096975684166,0.013788278214633465,0.018860168755054474,0.020624108612537384,0.019209859892725945,0.018283745273947716,0.01735650934278965,0.016433462500572205,0.015869757160544395,0.015377935022115707,0.014977779239416122,0.01454932801425457,0.014261556789278984,0.014087158255279064,
mse,0.04798124358057976,0.009943226352334023,0.0016210322501137853,0.0007210107869468629,0.0004429091641213745,0.00031684647547081113,0.00023303554917220026,0.00019627647998277098,0.0001721434819046408,0.00015378191892523319,0.00014332137652672827,0.00012931189849041402,0.00012122879707021639,0.00011497250670799986,0.00010569825099082664,0.00010020031913882121,9.54478673520498e-05,9.104921628022566e-05,8.609027281636372e-05,8.393549069296569e-05,8.090402843663469e-05,7.777769496897236e-05,7.511402509408072e-05,7.315820403164253e-05,7.064581586746499e-05,6.911477248650044e-05,6.773375207558274e-05,6.726020365022123e-05,6.570640107383952e-05,0.00012920408335048705,0.0001267797633772716,0.00016697328828740865,0.00014981663844082505,0.00012564065400511026,0.00011323601211188361,0.00010333768295822665,9.564291394781321e-05,8.986061584437266e-05,8.516102388966829e-05,8.317875472130254e-05,0.00012625863018911332,0.00021545475465245545,0.00015762900875415653,0.0001312862295890227,0.0001167337759397924,0.00010607166041154414,9.674558532424271e-05,9.132656850852072e-05,8.577942935517058e-05,8.335613529197872e-05,9.209525887854397e-05,0.0002046139125013724,0.00015931963571347296,0.00013993700849823654,0.00011440851085353643,9.959193994291127e-05,9.129414684139192e-05,8.39123094920069e-05,7.393307896563783e-05,6.702494283672422e-05,6.169145490275696e-05,6.0739897890016437e-05,8.976874232757837e-05,0.0001227505854330957,0.00015577430895064026,0.00010045547969639301,0.00010679932165658101,9.40773606998846e-05,8.221589814638719e-05,7.496270700357854e-05,7.173930498538539e-05,6.790278712287545e-05,6.515630229841918e-05,6.223969830898568e-05,5.984009840176441e-05,5.843643884873018e-05,5.654022243106738e-05,5.795231481897645e-05,9.563550702296197e-05,0.00015275905025191605,0.00013406261859927326,0.00011238773004151881,9.95255759335123e-05,8.625700866105035e-05,7.790572271915153e-05,7.139897206798196e-05,6.3903491536621e-05,5.885459904675372e-05,0.00010328682401450351,0.000116225506644696,0.00010130730515811592,9.211493306793272e-05,8.340226486325264e-05,7.510121213272214e-05,6.993925489950925e-05,6.610710261156783e-05,6.2713967054151e-05,5.978397894068621e-05,5.751897697336972e-05,5.610871085082181e-05,
mae,0.15826046466827393,0.06885236501693726,0.029795341193675995,0.019603637978434563,0.015509294345974922,0.013348731212317944,0.011477320455014706,0.010538914240896702,0.00993805006146431,0.009457133710384369,0.009140126407146454,0.008804399520158768,0.008497016504406929,0.008269565179944038,0.0079807722941041,0.007805454544723034,0.007594325579702854,0.007420745678246021,0.007281662430614233,0.007215976715087891,0.007040547672659159,0.006978731602430344,0.006882539950311184,0.0067620486952364445,0.006674645934253931,0.006575226318091154,0.006358566228300333,0.0064712874591350555,0.006262084469199181,0.008703012019395828,0.008658078499138355,0.010405314154922962,0.010092399083077908,0.00915420614182949,0.008691799826920033,0.00828770361840725,0.007795916870236397,0.007430454716086388,0.007259264588356018,0.007244356907904148,0.008796663023531437,0.011696899309754372,0.010159825906157494,0.009149913676083088,0.008594509214162827,0.008082537911832333,0.007631242275238037,0.00732796685770154,0.007075079251080751,0.007090101949870586,0.007461134344339371,0.012414530850946903,0.011078224517405033,0.010337862186133862,0.008505288511514664,0.007800990715622902,0.0075173755176365376,0.00720394030213356,0.0070042964071035385,0.006623459979891777,0.006297467276453972,0.006140026263892651,0.007552688010036945,0.00904801394790411,0.010282806120812893,0.00794845912605524,0.008249223232269287,0.00824070069938898,0.007209756877273321,0.006818944122642279,0.006619351450353861,0.006436286959797144,0.006341385655105114,0.006174125242978334,0.006047500763088465,0.005942080169916153,0.005862480029463768,0.006016009487211704,0.007630435284227133,0.010595232248306274,0.009953025728464127,0.00853904988616705,0.0075047872960567474,0.007161989342421293,0.007334709633141756,0.007051626220345497,0.006479179952293634,0.006164376623928547,0.008142759092152119,0.009126413613557816,0.008527744561433792,0.007951414212584496,0.007371407933533192,0.007120372727513313,0.006876510567963123,0.006723711267113686,0.00657331058755517,0.006397683173418045,0.0062724570743739605,0.0061949254013597965,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5443      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5444      
=================================================================
Total params: 10,887
Trainable params: 10,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 256)               1280      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 5,443
Trainable params: 5,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 1028      
=================================================================
Total params: 5,444
Trainable params: 5,444
Non-trainable params: 0
_________________________________________________________________
