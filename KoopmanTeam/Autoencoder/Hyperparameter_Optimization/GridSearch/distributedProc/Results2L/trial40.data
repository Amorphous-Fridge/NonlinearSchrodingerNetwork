2021-06-26
loss,0.35940787196159363,0.10173239558935165,0.05363412946462631,0.03908782824873924,0.033458270132541656,0.03020649403333664,0.02823522500693798,0.026954764500260353,0.025950979441404343,0.024947360157966614,0.02404344640672207,0.023493750020861626,0.022688740864396095,0.022362161427736282,0.023690562695264816,0.02915893867611885,0.02862195298075676,0.03285720571875572,0.03156493976712227,0.028671227395534515,0.02678045816719532,0.025507064536213875,0.025738896802067757,0.03631851077079773,0.031109893694519997,0.02771908789873123,0.03572184965014458,0.03553041070699692,0.03199106827378273,0.02913232147693634,0.02555175870656967,0.023282203823328018,0.019428707659244537,0.018425384536385536,0.019298631697893143,0.02135184034705162,0.029627544805407524,0.028244342654943466,0.02558569423854351,0.023311810567975044,0.02193533442914486,0.020925629884004593,0.022013705223798752,0.031587470322847366,0.028018290176987648,0.026730893179774284,0.024793006479740143,0.022599151358008385,0.021370016038417816,0.020190618932247162,0.019514506682753563,0.01850336417555809,0.027848320081830025,0.026498042047023773,0.026195483282208443,0.02493324689567089,0.023019835352897644,0.021192319691181183,0.019874753430485725,0.01891130954027176,0.018237167969346046,0.017657475546002388,0.01717795990407467,0.01678980514407158,0.01643238216638565,0.016031071543693542,0.015876874327659607,0.020912116393446922,0.020933177322149277,0.018848475068807602,0.023587336763739586,0.02623959258198738,0.022170452401041985,0.02404162846505642,0.02274334244430065,0.020843947306275368,0.018547695130109787,0.017361251637339592,0.01667613536119461,0.016122769564390182,0.015571503899991512,0.015098095871508121,0.015270184725522995,0.021420583128929138,0.02077346295118332,0.017510803416371346,0.016514405608177185,0.017892418429255486,0.024125326424837112,0.0228311475366354,0.021272601559758186,0.0202933382242918,0.019066795706748962,0.01821187697350979,0.017389662563800812,0.016649631783366203,0.016772735863924026,0.021639786660671234,0.019967904314398766,0.01919129118323326,
mse,0.046926748007535934,0.0038487818092107773,0.0009971330873668194,0.0005104116862639785,0.0003540673351380974,0.000282597349723801,0.00024527835194021463,0.00022785158944316208,0.00020488350128289312,0.00018559057207312435,0.00017140613636001945,0.00016401548055000603,0.00015236342733260244,0.00014758569886907935,0.00018156366422772408,0.0002630963281262666,0.0002594378893263638,0.0003166336100548506,0.0002942091668955982,0.00023111475456971675,0.00020371955179143697,0.00018482012092135847,0.00019764609169214964,0.00037118690670467913,0.0002720217453315854,0.00021820839901920408,0.0003917893045581877,0.00036682974314317107,0.0002941397833637893,0.00024714769097045064,0.00018890108913183212,0.00016383122419938445,0.0001234076771652326,0.0001070619109668769,0.00011856708442792296,0.0001385535579174757,0.00024645659141242504,0.00022578133211936802,0.00018108671065419912,0.00015068532957229763,0.0001353901461698115,0.00012395982048474252,0.0001480684441048652,0.00028078933246433735,0.00021782437397632748,0.00020278444571886212,0.00017490705067757517,0.00014435953926295042,0.00013093835150357336,0.00011772232392104343,0.00010968268179567531,0.00010119939543073997,0.00022489948605652899,0.00019431646796874702,0.00019316811813041568,0.00017327336536254734,0.000147808255860582,0.00012577357119880617,0.00011134706437587738,0.000102618032542523,9.482912719249725e-05,8.919871470425278e-05,8.484408317599446e-05,8.148948836605996e-05,7.842478953534737e-05,7.4492119892966e-05,7.420702604576945e-05,0.0001277574774576351,0.00012860876449849457,0.0001111363890231587,0.00016252529167104512,0.00019218404486309737,0.00013956298062112182,0.00016053147555794567,0.0001446516835130751,0.0001242227153852582,0.00010050540731754154,8.585456089349464e-05,7.832986011635512e-05,7.420508336508647e-05,6.991981354076415e-05,6.673907046206295e-05,6.972412666073069e-05,0.00013038012548349798,0.00012176358723081648,9.407621837453917e-05,8.330290438607335e-05,9.755537757882848e-05,0.00015958229778334498,0.0001452404394512996,0.000126358907436952,0.00011450655438238755,0.00010259892587782815,9.369098552269861e-05,8.638074359623715e-05,8.076490485109389e-05,8.510867337463424e-05,0.0001284677564399317,0.00011209076910745353,0.00010113491589436308,
mae,0.1537320911884308,0.04266408085823059,0.023251201957464218,0.016706209629774094,0.014332642778754234,0.013027112931013107,0.012020012363791466,0.011430952697992325,0.011048018001019955,0.010633436031639576,0.010215368121862411,0.010165219195187092,0.009810510091483593,0.00959222111850977,0.010173371061682701,0.013436194509267807,0.012599319219589233,0.014951790682971478,0.013724023476243019,0.012989821843802929,0.012179669924080372,0.01161710824817419,0.011432596482336521,0.015317130833864212,0.012880896218121052,0.011673391796648502,0.01493131835013628,0.014436237514019012,0.013676346279680729,0.012371348217129707,0.010892067104578018,0.010155981406569481,0.008566688746213913,0.007865918800234795,0.008173312991857529,0.009465746581554413,0.01248097512871027,0.012189271859824657,0.01027579978108406,0.009219910018146038,0.008794823661446571,0.008549818769097328,0.009213392622768879,0.013488169759511948,0.012055677361786366,0.011338207870721817,0.010263255797326565,0.009395219385623932,0.009179980494081974,0.008811088278889656,0.008567359298467636,0.008015565574169159,0.011835948564112186,0.011457467451691628,0.011295783333480358,0.010855233296751976,0.009722038172185421,0.008499491959810257,0.008132916875183582,0.007683828938752413,0.0073854960501194,0.007164943031966686,0.006975788623094559,0.0068138414062559605,0.0066806660033762455,0.006567041389644146,0.006671485956758261,0.008507480844855309,0.0084147397428751,0.008376050740480423,0.00991400983184576,0.010941730812191963,0.009485495276749134,0.010295971296727657,0.009704390540719032,0.008734422735869884,0.007863037288188934,0.007199550978839397,0.0067322468385100365,0.006502527743577957,0.006297590676695108,0.00618743896484375,0.0063707465305924416,0.009124967269599438,0.008627829141914845,0.007898791693150997,0.007452512159943581,0.007694034371525049,0.010037442669272423,0.009864667430520058,0.0092394407838583,0.008508113212883472,0.007985848933458328,0.007673259358853102,0.007346165366470814,0.006852659396827221,0.006906750611960888,0.00914562027901411,0.008457472547888756,0.008167583495378494,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 10819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 10820     
=================================================================
Total params: 21,639
Trainable params: 21,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 512)               2560      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 10,819
Trainable params: 10,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 2052      
=================================================================
Total params: 10,820
Trainable params: 10,820
Non-trainable params: 0
_________________________________________________________________
