2021-06-26
loss,0.2716204524040222,0.0660616084933281,0.051446545869112015,0.04845711216330528,0.049107130616903305,0.040050655603408813,0.042531296610832214,0.039424605667591095,0.03660116344690323,0.036667753010988235,0.03792455047369003,0.0330018624663353,0.035563092678785324,0.032700128853321075,0.03167427331209183,0.034242235124111176,0.027576811611652374,0.026020605117082596,0.02325189672410488,0.02648947760462761,0.02924681268632412,0.028184251859784126,0.02416626363992691,0.024388549849390984,0.024534929543733597,0.024052072316408157,0.02418375201523304,0.02424682304263115,0.02455081418156624,0.024127911776304245,0.023028409108519554,0.021538715809583664,0.020275607705116272,0.01830166205763817,0.01979854144155979,0.021795688197016716,0.022005151957273483,0.02106846123933792,0.01889377273619175,0.020980913192033768,0.019503150135278702,0.0164804570376873,0.016953615471720695,0.020470228046178818,0.01920037716627121,0.017948409542441368,0.017929358407855034,0.019323067739605904,0.01765405759215355,0.016641849651932716,0.015383545309305191,0.01700446754693985,0.017777543514966965,0.0180680975317955,0.018911827355623245,0.01708896830677986,0.016930025070905685,0.017321962863206863,0.017541056498885155,0.017006484791636467,0.01662655547261238,0.01565495878458023,0.017501134425401688,0.017810571938753128,0.016664322465658188,0.01581636257469654,0.014598970301449299,0.013964122161269188,0.013950953260064125,0.01672237552702427,0.01526178140193224,0.014183049090206623,0.013313408941030502,0.01467001810669899,0.014978371560573578,0.014335335232317448,0.015583919361233711,0.0146593376994133,0.013163299299776554,0.012129801325500011,0.014944147318601608,0.014417006634175777,0.013597117736935616,0.013476289808750153,0.013392806984484196,0.015110081061720848,0.014914590865373611,0.014099586755037308,0.013903822749853134,0.014631005935370922,0.015630315989255905,0.014590075239539146,0.013682645745575428,0.012891807593405247,0.011633120477199554,0.011827750131487846,0.010665733367204666,0.013355571776628494,0.013735740445554256,0.013029870577156544,
mse,0.03923845663666725,0.001334832631982863,0.0007781028980389237,0.0006962584448046982,0.000704424805007875,0.00048118169070221484,0.0005346432444639504,0.00045765971299260855,0.0003910597297362983,0.00039929390186443925,0.00041939495713450015,0.00032934214686974883,0.00037158041959628463,0.0003163692308589816,0.00029522436670958996,0.00033015719964168966,0.0002277774183312431,0.00020490432507358491,0.00016603404947090894,0.00020797258184757084,0.00024116197891999036,0.00022432688274420798,0.00017485606076661497,0.0001825362560339272,0.00017797826149035245,0.0001671916979830712,0.0001698549895081669,0.00016957437037490308,0.0001697818370303139,0.00016335696273017675,0.00015551934484392405,0.0001348338701063767,0.00011833975440822542,0.00010605485294945538,0.00012135934230173007,0.00013663910795003176,0.00014091949560679495,0.00012453205999918282,0.00010693899093894288,0.00012623699149116874,0.00011441018432378769,8.439731755061075e-05,8.999749843496829e-05,0.00011789372365456074,0.00010597074287943542,9.589827823219821e-05,9.246049739886075e-05,0.00010550011938903481,8.737626194488257e-05,7.876539893914014e-05,6.947337533347309e-05,8.571946091251448e-05,9.13980693439953e-05,9.448506170883775e-05,0.00010226559243164957,8.302204514620826e-05,8.266387158073485e-05,8.769762644078583e-05,8.687067747814581e-05,8.295277075376362e-05,7.917652692412958e-05,7.317864219658077e-05,8.802823140285909e-05,9.100911120185629e-05,8.093797805486247e-05,7.210542389657348e-05,6.296236824709922e-05,5.858752047060989e-05,6.153979484224692e-05,7.893767178757116e-05,6.619618943659589e-05,5.683370545739308e-05,5.0595681386766955e-05,6.423139711841941e-05,6.662006489932537e-05,6.0805232351413e-05,6.848210614407435e-05,6.144328654045239e-05,5.298454925650731e-05,4.5681856136070564e-05,6.323427078314126e-05,6.053178003639914e-05,5.576410694629885e-05,5.515779776033014e-05,5.290603803587146e-05,6.502147880382836e-05,6.312194454949349e-05,5.6097895139828324e-05,5.582619633059949e-05,6.18321864749305e-05,7.044204539852217e-05,6.215457688085735e-05,5.381270602811128e-05,4.8153735406231135e-05,4.1931580199161544e-05,4.5247754314914346e-05,3.610564090195112e-05,5.240755126578733e-05,5.3472267609322444e-05,4.840511246584356e-05,
mae,0.11646411567926407,0.028198258951306343,0.02182069607079029,0.02058974653482437,0.020949505269527435,0.01705958880484104,0.01835431158542633,0.01685630902647972,0.01580107770860195,0.015595439821481705,0.0161480400711298,0.014098349958658218,0.015094633214175701,0.013963027857244015,0.013576384633779526,0.014710945077240467,0.011681139469146729,0.011113937944173813,0.009901139885187149,0.011310126632452011,0.012425963766872883,0.011853018775582314,0.010153986513614655,0.010359760373830795,0.0103842131793499,0.010152225382626057,0.010255582630634308,0.010258530266582966,0.010364226065576077,0.010371671989560127,0.00954675767570734,0.00903925858438015,0.008566497825086117,0.007746536284685135,0.008340009488165379,0.009273824281990528,0.009397887624800205,0.00887228548526764,0.007951607927680016,0.00886555016040802,0.008243980817496777,0.007038559764623642,0.007174310274422169,0.008762788958847523,0.00826978962868452,0.0076782358810305595,0.007612975779920816,0.008255339227616787,0.007422527763992548,0.006963649298995733,0.006532269064337015,0.0072774700820446014,0.007487607654184103,0.0075906310230493546,0.008082768879830837,0.007301662117242813,0.007140894420444965,0.007351282052695751,0.007489559706300497,0.007212343160063028,0.007055125664919615,0.006665882654488087,0.007466273847967386,0.007496535312384367,0.006956316065043211,0.006620173342525959,0.006201505195349455,0.005925747565925121,0.005976059008389711,0.007054438814520836,0.006480537820607424,0.0060329558327794075,0.005659541115164757,0.006268265191465616,0.006165477447211742,0.006156588904559612,0.006673125084489584,0.006101125385612249,0.005582309793680906,0.005115401931107044,0.006336241960525513,0.006118678953498602,0.005860229022800922,0.00571101950481534,0.005645612254738808,0.006320585031062365,0.00637529231607914,0.006018149666488171,0.005859960336238146,0.006314202677458525,0.00670348247513175,0.006216797046363354,0.005961222108453512,0.0055803353898227215,0.004987063352018595,0.005052092485129833,0.00459227105602622,0.005660642869770527,0.00578328687697649,0.005388734396547079,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 135811    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 135812    
=================================================================
Total params: 271,623
Trainable params: 271,623
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 1024)              132096    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 3075      
=================================================================
Total params: 135,811
Trainable params: 135,811
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 1024)              4096      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               131200    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 135,812
Trainable params: 135,812
Non-trainable params: 0
_________________________________________________________________
