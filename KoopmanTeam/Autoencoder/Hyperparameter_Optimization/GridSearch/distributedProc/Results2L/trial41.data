2021-06-26
loss,0.32901227474212646,0.1683080643415451,0.07479886710643768,0.061321429908275604,0.060060545802116394,0.043443579226732254,0.037713002413511276,0.03160115331411362,0.028381472453475,0.026251692324876785,0.025276508182287216,0.023814942687749863,0.02282583713531494,0.02193336747586727,0.021354490891098976,0.024106496945023537,0.034502193331718445,0.03298615291714668,0.028810324147343636,0.02592742256820202,0.035237010568380356,0.03206239640712738,0.02792133018374443,0.03214363753795624,0.028535880148410797,0.030951455235481262,0.028396541252732277,0.02626732736825943,0.024607665836811066,0.023298313841223717,0.026560308411717415,0.027042238041758537,0.024592280387878418,0.022216973826289177,0.020790353417396545,0.020573129877448082,0.019169874489307404,0.01720307767391205,0.01829574629664421,0.026262914761900902,0.026309454813599586,0.02391991764307022,0.024166064336895943,0.028554417192935944,0.023629453033208847,0.021658165380358696,0.02058599703013897,0.024560652673244476,0.02360108122229576,0.021987982094287872,0.02096356824040413,0.019944950938224792,0.019108088687062263,0.01864072121679783,0.01958349160850048,0.019071342423558235,0.021317122504115105,0.02833663299679756,0.02341049164533615,0.02106824330985546,0.019798757508397102,0.022245140746235847,0.023055989295244217,0.02044597640633583,0.022922661155462265,0.01956624910235405,0.018265925347805023,0.0171864815056324,0.01650973968207836,0.015956992283463478,0.015534644946455956,0.015087081119418144,0.016324929893016815,0.021021120250225067,0.019460808485746384,0.018970945850014687,0.02259496971964836,0.020921649411320686,0.019418926909565926,0.017631618306040764,0.0165543295443058,0.016500400379300117,0.015509158372879028,0.014759787358343601,0.01792827993631363,0.01792331039905548,0.016757719218730927,0.015970317646861076,0.015405149199068546,0.01447184756398201,0.013249225914478302,0.012408235110342503,0.01305584330111742,0.019189240410923958,0.019541136920452118,0.01690024323761463,0.015723304823040962,0.014887254685163498,0.01414498407393694,0.012733567506074905,
mse,0.03954271972179413,0.010586419142782688,0.0018999353051185608,0.0012609020341187716,0.0011203441536054015,0.0005672171828337014,0.00041629839688539505,0.0002919164835475385,0.00023595137463416904,0.00020276482973713428,0.00018592915148474276,0.00016557691560592502,0.00014920870307832956,0.00013760814908891916,0.00013232935452833772,0.00017858111823443323,0.00034858137951232493,0.00030463797156699,0.00022881923359818757,0.00019559916108846664,0.00035747623769566417,0.0002887419832404703,0.0002176006673835218,0.00029577899840660393,0.00023359553597401828,0.00026979620452038944,0.00022187581635080278,0.00018926843767985702,0.00016827501531224698,0.00015210304991342127,0.00020175508689135313,0.00019994784088339657,0.00016732099174987525,0.00014665407070424408,0.00012757610238622874,0.00012745399726554751,0.00011117985559394583,8.824323595035821e-05,0.00010025128722190857,0.00019101878569927067,0.0001872315042419359,0.00016087507538031787,0.00016869977116584778,0.00023049890296533704,0.00015485617041122168,0.0001300694711972028,0.00011989430640824139,0.0001644617150304839,0.00015028045163489878,0.00013382144970819354,0.00012032863742206246,0.00011055218055844307,9.994041465688497e-05,9.781050175661221e-05,0.00010527627455303445,0.00010132261377293617,0.00013889373803976923,0.00022356702538672835,0.00015451607760041952,0.00012318369408603758,0.00010843193740583956,0.00014412592281587422,0.00015134821296669543,0.00011950016778428108,0.00014678013394586742,0.00010409078822704032,9.165289520751685e-05,8.249229722423479e-05,7.634953362867236e-05,7.098808418959379e-05,6.653134914813563e-05,6.326056609395891e-05,7.530020229751244e-05,0.00012184776278445497,0.00010375204146839678,0.00010575962369330227,0.00014268177619669586,0.00012431610957719386,0.00010805783676914871,8.67179041961208e-05,7.748897041892633e-05,7.457048195647076e-05,6.65915067656897e-05,6.30423310212791e-05,8.961241837823763e-05,8.858769433572888e-05,7.825451029930264e-05,7.223237480502576e-05,6.605005182791501e-05,5.904697172809392e-05,5.263599086902104e-05,4.694607559940778e-05,5.3228777687763795e-05,0.0001023703080136329,0.00010598696826491505,8.229025843320414e-05,6.81733654346317e-05,6.261613452807069e-05,5.77391947444994e-05,4.9826478061731905e-05,
mae,0.14556260406970978,0.07266012579202652,0.031747616827487946,0.026093540713191032,0.02544243261218071,0.018549377098679543,0.015987453982234,0.013410164974629879,0.011981626972556114,0.011162780225276947,0.010663986206054688,0.01010045874863863,0.009681525640189648,0.00936705432832241,0.009060709737241268,0.010426526889204979,0.014487292617559433,0.013841279782354832,0.012213706970214844,0.011024165898561478,0.014919898472726345,0.013015912845730782,0.012108433991670609,0.013498230837285519,0.01211619097739458,0.013229181990027428,0.012287008576095104,0.011195920407772064,0.010532326996326447,0.009899884462356567,0.011409688740968704,0.011152934283018112,0.010377242229878902,0.009316847659647465,0.008839533664286137,0.009034741669893265,0.008411767892539501,0.007399553433060646,0.007781201507896185,0.011308955028653145,0.011348186992108822,0.010315129533410072,0.010237392038106918,0.012533498927950859,0.010284882970154285,0.00908628385514021,0.00865316390991211,0.010466874577105045,0.010137055069208145,0.009386989288032055,0.00887900497764349,0.00822563748806715,0.008025748655200005,0.007922312244772911,0.008313887752592564,0.00814860500395298,0.009075772948563099,0.012504092417657375,0.009826812893152237,0.008898762986063957,0.008571949787437916,0.009567794390022755,0.010000532492995262,0.008695821277797222,0.009934631176292896,0.008522503077983856,0.008132857270538807,0.007365863770246506,0.006861784029752016,0.006673583760857582,0.0064863478764891624,0.0062197353690862656,0.006875708699226379,0.008791941218078136,0.008263320662081242,0.007690038066357374,0.009699898771941662,0.008805721066892147,0.008176119066774845,0.007529017515480518,0.006973177194595337,0.007075367029756308,0.006616166792809963,0.0063024465925991535,0.007654222194105387,0.007701314054429531,0.0072832065634429455,0.007044546771794558,0.006767482962459326,0.006349120754748583,0.005690398160368204,0.005356035195291042,0.005547442007809877,0.008264180272817612,0.008356432430446148,0.007149821147322655,0.006856726482510567,0.0065017808228731155,0.006234290543943644,0.005476483143866062,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 19075     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 19076     
=================================================================
Total params: 38,151
Trainable params: 38,151
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 512)               2560      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 19,075
Trainable params: 19,075
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 2052      
=================================================================
Total params: 19,076
Trainable params: 19,076
Non-trainable params: 0
_________________________________________________________________
