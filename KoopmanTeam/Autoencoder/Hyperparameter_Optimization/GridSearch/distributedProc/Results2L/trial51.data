2021-06-26
loss,0.3915090262889862,0.13704656064510345,0.08185906708240509,0.053251102566719055,0.04936196655035019,0.04476097598671913,0.04250868409872055,0.038005270063877106,0.040305767208337784,0.036827508360147476,0.03199710696935654,0.040756918489933014,0.033017612993717194,0.03130723908543587,0.0343695804476738,0.031625669449567795,0.03131064027547836,0.03690769150853157,0.031201178207993507,0.028910746797919273,0.032180652022361755,0.030763600021600723,0.025245267897844315,0.028368933126330376,0.029671087861061096,0.028666209429502487,0.026127781718969345,0.02445383556187153,0.024178097024559975,0.024296430870890617,0.02339169941842556,0.021400300785899162,0.024314934387803078,0.02443888410925865,0.021443717181682587,0.022542990744113922,0.02268803119659424,0.02286345325410366,0.023292729631066322,0.02324654534459114,0.02216867171227932,0.021157970651984215,0.019259929656982422,0.017936859279870987,0.01789289154112339,0.018853547051548958,0.01937910169363022,0.021927986294031143,0.020315025001764297,0.019837452098727226,0.018115384504199028,0.017622509971261024,0.0168974120169878,0.01915915682911873,0.01865682378411293,0.016788532957434654,0.016359640285372734,0.01651863008737564,0.018039487302303314,0.01650962233543396,0.018151160329580307,0.018105296418070793,0.017386145889759064,0.016819246113300323,0.015281959436833858,0.015209648758172989,0.01615307107567787,0.01751483976840973,0.01772715337574482,0.016604796051979065,0.01642277091741562,0.016838178038597107,0.016125906258821487,0.01552403811365366,0.016312330961227417,0.016206888481974602,0.014900446869432926,0.014822092838585377,0.014163502492010593,0.015410647727549076,0.01507640816271305,0.015964915975928307,0.01492842473089695,0.014438040554523468,0.014839069917798042,0.01525968685746193,0.01536971889436245,0.015758845955133438,0.01465729158371687,0.01272774301469326,0.012612939812242985,0.015214699320495129,0.014369484037160873,0.012692011892795563,0.014379485510289669,0.015189805068075657,0.01391613855957985,0.013907849788665771,0.014278308488428593,0.014522633515298367,
mse,0.059030499309301376,0.006739296484738588,0.0021068137139081955,0.0008397605852223933,0.0007296973490156233,0.0005866528954356909,0.0005265598883852363,0.00043140887282788754,0.0004761856107506901,0.0004070779250469059,0.00030200384208001196,0.0004978500073775649,0.0003449175273999572,0.00029735619318671525,0.00034884799970313907,0.000294187746476382,0.00029459185316227376,0.0003930524690076709,0.00029604852898046374,0.00025603731046430767,0.0003023250319529325,0.00027078232960775495,0.00019525742391124368,0.0002401743404334411,0.0002525784948375076,0.00023223861353471875,0.00019970483845099807,0.00017495079373475164,0.00017182790907099843,0.00017674766422715038,0.00016665086150169373,0.00013834018318448216,0.00017370177374687046,0.00017470709281042218,0.00014310228289104998,0.00015245043323375285,0.00015383867139462382,0.0001562466350151226,0.00015586096560582519,0.00015190878184512258,0.00013884517829865217,0.00012715415505226701,0.00011117543908767402,9.942965698428452e-05,9.879965364234522e-05,0.00010932100121863186,0.00011554775119293481,0.00013916852185502648,0.00011854278272949159,0.00011272740812273696,9.995519940275699e-05,9.353944915346801e-05,8.76608319231309e-05,0.00010339633445255458,9.796186350286007e-05,8.400626393267885e-05,8.342056389665231e-05,8.271672413684428e-05,9.528646478429437e-05,8.196852286346257e-05,9.427222539670765e-05,9.163442882709205e-05,8.572195656597614e-05,8.161990263033658e-05,7.129232108127326e-05,6.910434603923932e-05,7.757090497761965e-05,8.676043944433331e-05,8.949327457230538e-05,7.936401379993185e-05,7.68222234910354e-05,7.956414629006758e-05,7.514437311328948e-05,7.025703962426633e-05,7.67364472267218e-05,7.319209544220939e-05,6.693442992400378e-05,6.683678657282144e-05,6.0302736528683454e-05,6.887040217407048e-05,6.56410411465913e-05,7.083525269990787e-05,6.47161141387187e-05,6.109617970651016e-05,6.565635703736916e-05,6.586481322301552e-05,6.746745930286124e-05,6.952235708013177e-05,6.219639180926606e-05,4.988156433682889e-05,5.1284627261338755e-05,6.494338595075533e-05,6.0559719713637605e-05,4.953282405040227e-05,5.960315320407972e-05,6.483947072410956e-05,5.5674678151262924e-05,5.76273123442661e-05,5.789387068944052e-05,5.881031393073499e-05,
mae,0.16606727242469788,0.060137562453746796,0.03495443984866142,0.02245057374238968,0.02095481939613819,0.019029295071959496,0.01803768239915371,0.016089502722024918,0.01705644093453884,0.015530968084931374,0.013519084081053734,0.017411408945918083,0.013814210891723633,0.013543636538088322,0.014746040105819702,0.013380139134824276,0.013288522139191628,0.01565874181687832,0.013167916797101498,0.012344983406364918,0.013719537295401096,0.012943308800458908,0.01068616472184658,0.012031312100589275,0.012589982710778713,0.012201442383229733,0.011082388460636139,0.010355805978178978,0.01028893981128931,0.010344918817281723,0.009877621196210384,0.009145674295723438,0.01036836113780737,0.010332289151847363,0.009070510976016521,0.009500297717750072,0.009616095572710037,0.009640011936426163,0.00993503537029028,0.009876969270408154,0.009378901682794094,0.008988655172288418,0.008010637015104294,0.007683461997658014,0.007461792789399624,0.0078111616894602776,0.008218050934374332,0.009369774721562862,0.008475947193801403,0.008329382166266441,0.007576629053801298,0.007496836129575968,0.007143237628042698,0.008026287890970707,0.007895130664110184,0.0070876069366931915,0.0069062598049640656,0.0070132906548678875,0.0076836454682052135,0.007087737321853638,0.007658510934561491,0.007631329819560051,0.0073610274121165276,0.0070627592504024506,0.006483856588602066,0.00655787717550993,0.006851726211607456,0.007311125285923481,0.007503822911530733,0.006984795909374952,0.0069025130942463875,0.007038730196654797,0.006811448372900486,0.006629954092204571,0.006921108812093735,0.006934653967618942,0.0063072796911001205,0.00629441486671567,0.006091867107897997,0.0065119918435812,0.006220851559191942,0.006634888239204884,0.006425874773412943,0.006132490001618862,0.006304219830781221,0.006447393912822008,0.006538165267556906,0.006705501116812229,0.006222556345164776,0.00534124206751585,0.0053598349913954735,0.00658210227265954,0.006078447215259075,0.005358524154871702,0.006031708791851997,0.006320285610854626,0.005870032124221325,0.005911721382290125,0.006048611830919981,0.00614169891923666,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 136707    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 136708    
=================================================================
Total params: 273,415
Trainable params: 273,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 1024)              5120      
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               131200    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 136,707
Trainable params: 136,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 1024)              132096    
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 4100      
=================================================================
Total params: 136,708
Trainable params: 136,708
Non-trainable params: 0
_________________________________________________________________
