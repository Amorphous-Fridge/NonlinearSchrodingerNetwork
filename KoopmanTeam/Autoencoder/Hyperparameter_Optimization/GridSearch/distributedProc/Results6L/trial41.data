2021-06-26
loss,0.7536583542823792,0.32355037331581116,0.26451030373573303,0.22326545417308807,0.18983691930770874,0.1730799823999405,0.1698983907699585,0.12872357666492462,0.10745351761579514,0.09195289760828018,0.09250123798847198,0.08936383575201035,0.07971607893705368,0.07704783231019974,0.06614983826875687,0.06834562867879868,0.08338601887226105,0.06430049240589142,0.05602554976940155,0.04741615429520607,0.060034025460481644,0.05747685581445694,0.06720654666423798,0.05522196739912033,0.04726969078183174,0.04551558941602707,0.04294276610016823,0.042302340269088745,0.049231208860874176,0.044457755982875824,0.04227391257882118,0.046894803643226624,0.0476408526301384,0.042998962104320526,0.04071822762489319,0.046720389276742935,0.05285155400633812,0.04039134457707405,0.038169361650943756,0.035494543612003326,0.037813376635313034,0.042368024587631226,0.03331251069903374,0.035991717129945755,0.03643767535686493,0.04534827545285225,0.04348985105752945,0.040455058217048645,0.03086984157562256,0.030985701829195023,0.0379519946873188,0.03996757045388222,0.03495878353714943,0.039584264159202576,0.03391217812895775,0.027315741404891014,0.02838355489075184,0.03500387445092201,0.0343814454972744,0.03250734880566597,0.03425395488739014,0.037474747747182846,0.03392601013183594,0.030134404078125954,0.03155858442187309,0.03019886277616024,0.027994856238365173,0.0373433381319046,0.031397536396980286,0.029676230624318123,0.028461311012506485,0.02756691910326481,0.031022941693663597,0.029800578951835632,0.030506696552038193,0.031080346554517746,0.031585220247507095,0.028597166761755943,0.029217004776000977,0.030808595940470695,0.029819315299391747,0.027166517451405525,0.030598480254411697,0.026965517550706863,0.024415526539087296,0.024426860734820366,0.02973228506743908,0.026519468054175377,0.028704097494482994,0.026549354195594788,0.023471452295780182,0.02545800246298313,0.029373759403824806,0.02620367519557476,0.02315249852836132,0.02626175805926323,0.025849241763353348,0.029343223199248314,0.026406722143292427,0.02729683555662632,
mse,0.26994264125823975,0.03133252263069153,0.021886639297008514,0.016111554577946663,0.011607501655817032,0.009115506894886494,0.008572042919695377,0.004924781154841185,0.003401803085580468,0.0024506940972059965,0.002585287904366851,0.0023115454241633415,0.001907947356812656,0.00169384537730366,0.0012765517458319664,0.0013477004831656814,0.0020142141729593277,0.0011775585589930415,0.00091214245185256,0.0006377985118888319,0.0010585017735138535,0.0009734680643305182,0.001245184219442308,0.0008615330443717539,0.0006497448193840683,0.000584147113841027,0.000528674223460257,0.0005412899190559983,0.0006857363623566926,0.0005576873663812876,0.0005156832048669457,0.0006135182920843363,0.000655671872664243,0.0005453720805235207,0.00047317511052824557,0.0006366758025251329,0.0007793672266416252,0.00044810178223997355,0.00039637924055568874,0.0003557833260856569,0.0004140264936722815,0.0005229043308645487,0.0003108425298705697,0.00036261018249206245,0.0003766647423617542,0.0005877877119928598,0.0005213754484429955,0.000463376403786242,0.0002728065592236817,0.00027614791179075837,0.00040062546031549573,0.0004475140303838998,0.0003545526706147939,0.000433959299698472,0.00031984932138584554,0.00021373160416260362,0.00023443442478310317,0.0003386031021364033,0.0003294548369012773,0.0003067524521611631,0.00033676758175715804,0.00038529737503267825,0.00032284168992191553,0.00025547074619680643,0.00028129437123425305,0.00025651039322838187,0.0002216901193605736,0.00038390548434108496,0.00028122105868533254,0.0002556128893047571,0.00023036665515974164,0.00021635642042383552,0.0002695204457268119,0.0002518343972042203,0.00026010541478171945,0.0002889205643441528,0.00027989374939352274,0.00022778360289521515,0.00023677128774579614,0.0002672565169632435,0.00024603979545645416,0.0002067854511551559,0.0002539372944738716,0.00019804130715783685,0.00016886243247427046,0.00017184809257742018,0.0002528651966713369,0.00020318751921877265,0.00022972762235440314,0.00019838927255477756,0.00016150661394931376,0.000185640252311714,0.00023950824106577784,0.0001908926642499864,0.0001520687947049737,0.0001888460828922689,0.00019601658277679235,0.00023861191584728658,0.0001967480784514919,0.00020925322314724326,
mae,0.3286125659942627,0.13944371044635773,0.1160702258348465,0.09510516375303268,0.07904055714607239,0.07324685901403427,0.07028752565383911,0.0549297109246254,0.04576966166496277,0.03967488184571266,0.03925547003746033,0.03808737173676491,0.03405745327472687,0.03227434307336807,0.028124738484621048,0.029076190665364265,0.035614095628261566,0.027478303760290146,0.023505600169301033,0.020224029198288918,0.025726793333888054,0.02430679090321064,0.028788739815354347,0.023617258295416832,0.019738614559173584,0.019496191293001175,0.018265152350068092,0.017775176092982292,0.021070055663585663,0.019048400223255157,0.017912885174155235,0.020070014521479607,0.020237185060977936,0.018344532698392868,0.01746881753206253,0.019643573090434074,0.021942080929875374,0.01700584590435028,0.01606733538210392,0.014905226416885853,0.015951601788401604,0.01790594309568405,0.014289366081357002,0.015298244543373585,0.015552772209048271,0.019304269924759865,0.018970465287566185,0.017119629308581352,0.013134387321770191,0.013286433182656765,0.016109611839056015,0.017248649150133133,0.014896470122039318,0.016929643228650093,0.014547363854944706,0.011644190177321434,0.012113426811993122,0.014583003707230091,0.014795873314142227,0.013856439851224422,0.014410044066607952,0.01598077453672886,0.014761933125555515,0.012824649922549725,0.013533545657992363,0.01299241092056036,0.011542201042175293,0.016229303553700447,0.013610227033495903,0.012622127309441566,0.012237902730703354,0.011622393503785133,0.013378791511058807,0.01259586215019226,0.012758850120007992,0.013162634335458279,0.013629590161144733,0.012256591580808163,0.012301081791520119,0.013233394362032413,0.012551490217447281,0.011437272652983665,0.013314497657120228,0.011620101518929005,0.010545858182013035,0.010239388793706894,0.012528064660727978,0.011265757493674755,0.012165372259914875,0.011493515223264694,0.009733918122947216,0.010753954760730267,0.012610171921551228,0.011228195391595364,0.009899272583425045,0.011061511933803558,0.011061329394578934,0.012143094092607498,0.011265349574387074,0.011242176406085491,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 101139    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 101140    
=================================================================
Total params: 202,279
Trainable params: 202,279
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 101,139
Trainable params: 101,139
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 101,140
Trainable params: 101,140
Non-trainable params: 0
_________________________________________________________________
