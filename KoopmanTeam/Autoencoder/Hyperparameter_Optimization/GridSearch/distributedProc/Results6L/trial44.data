2021-06-26
loss,0.7380632162094116,0.34667012095451355,0.28498509526252747,0.262500524520874,0.24386420845985413,0.23837138712406158,0.22743400931358337,0.217621847987175,0.2090156227350235,0.18723084032535553,0.18986597657203674,0.1407882571220398,0.11797010153532028,0.10728435218334198,0.12357080727815628,0.09128221869468689,0.08454319834709167,0.0942639634013176,0.08201128244400024,0.07257041335105896,0.08192388713359833,0.0605609305202961,0.06343279033899307,0.0783223956823349,0.0631655678153038,0.07603368908166885,0.07608282566070557,0.062238484621047974,0.04875336214900017,0.05107828229665756,0.04996267333626747,0.06364131718873978,0.05863749608397484,0.05419594421982765,0.04392970725893974,0.056379418820142746,0.05005035549402237,0.04610564559698105,0.047882746905088425,0.04554473236203194,0.04561929404735565,0.049725331366062164,0.03607213497161865,0.04123256728053093,0.04667707532644272,0.03456907346844673,0.03669968247413635,0.047141123563051224,0.04457889869809151,0.03953493759036064,0.0425899475812912,0.03406527638435364,0.037619736045598984,0.04308140277862549,0.037549737840890884,0.03097407892346382,0.038085468113422394,0.035172250121831894,0.03559616208076477,0.04073949158191681,0.03445640578866005,0.03637655824422836,0.03397519513964653,0.02969944290816784,0.029921192675828934,0.0398714542388916,0.03424326702952385,0.027201836928725243,0.037290483713150024,0.033785730600357056,0.03092590719461441,0.028109416365623474,0.02979143336415291,0.03131048008799553,0.033886801451444626,0.03074118308722973,0.0360635407269001,0.03295106068253517,0.029727613553404808,0.02840971015393734,0.028062239289283752,0.027725085616111755,0.027118707075715065,0.030734235420823097,0.031149972230196,0.030934901908040047,0.026686890050768852,0.03244993835687637,0.0315726138651371,0.02712821215391159,0.027249900624155998,0.029059845954179764,0.030767273157835007,0.02601982094347477,0.025127243250608444,0.02825409732758999,0.024910829961299896,0.02427266538143158,0.026776762679219246,0.02380370907485485,
mse,0.2511971592903137,0.03570391982793808,0.025256915017962456,0.022142481058835983,0.01992528885602951,0.01909416913986206,0.017558209598064423,0.015746839344501495,0.014361076056957245,0.010577201843261719,0.011025152169167995,0.005681540351361036,0.004106604028493166,0.0034025441855192184,0.004610743373632431,0.0024353673215955496,0.0020578557159751654,0.0024483457673341036,0.0019816881977021694,0.0015576964942738414,0.00193635537289083,0.0010419524041935802,0.0012163418577983975,0.0017346786335110664,0.0010967606212943792,0.0016155025223270059,0.001696899184025824,0.0010717894183471799,0.0006853132508695126,0.0007329077925533056,0.0007150023593567312,0.0011453372426331043,0.0009727944270707667,0.0008151280344463885,0.0005413162871263921,0.0008748244727030396,0.0006787965539842844,0.0005988712073303759,0.0006522168405354023,0.0005860720411874354,0.0005736055900342762,0.0007025694940239191,0.00036805219133384526,0.0004733186506200582,0.0005967023898847401,0.0003373630461283028,0.0004097659548278898,0.0006090709357522428,0.000541156274266541,0.00044250895734876394,0.0004957066266797483,0.0003278459480497986,0.00039520286372862756,0.0005139050772413611,0.0003878069401253015,0.0002674045681487769,0.0004118108772672713,0.00033634810824878514,0.0003647354315035045,0.0004532443708740175,0.00033135281410068274,0.00036643148632720113,0.00031931980629451573,0.0002511243219487369,0.0002695053699426353,0.00043433133396320045,0.0003251330053899437,0.00021136205759830773,0.0003817630058620125,0.00031273800414055586,0.000266635965090245,0.00022360598086379468,0.0002478248788975179,0.00027965131448581815,0.0003187387192156166,0.00026545851142145693,0.00035167363239452243,0.0002944383886642754,0.0002469065657351166,0.00022476547746919096,0.00021830109471920878,0.0002113236259901896,0.00020973426580894738,0.00026776231243275106,0.0002683362108655274,0.00026044424157589674,0.00019862354383803904,0.0002862606488633901,0.0002646723878569901,0.00020180904539301991,0.00021041379659436643,0.0002349241985939443,0.00025718699907884,0.00019102435908280313,0.00018065338372252882,0.00021562199981417507,0.00017362431390210986,0.00016499705088790506,0.00020451666205190122,0.0001563650439493358,
mae,0.3200281858444214,0.14935019612312317,0.11971665173768997,0.11181456595659256,0.10644739121198654,0.10318269580602646,0.09768221527338028,0.09233023971319199,0.08980724960565567,0.07986707985401154,0.08046742528676987,0.060672398656606674,0.05024993419647217,0.046005383133888245,0.05241662636399269,0.03894028067588806,0.03631718456745148,0.040301527827978134,0.0360589474439621,0.03077942132949829,0.03458819538354874,0.025639664381742477,0.027320075780153275,0.033564794808626175,0.028437087312340736,0.03345710039138794,0.03297092765569687,0.025668587535619736,0.020988376811146736,0.0215921588242054,0.02155599743127823,0.027472205460071564,0.02412223629653454,0.022743823006749153,0.0186332818120718,0.0239699836820364,0.021959679201245308,0.019509071484208107,0.020692095160484314,0.01935580000281334,0.019669098779559135,0.02176750637590885,0.015416583977639675,0.017180562019348145,0.020045630633831024,0.01483741495758295,0.015831049531698227,0.020514419302344322,0.018593309447169304,0.01690872572362423,0.018513575196266174,0.01458427868783474,0.016142630949616432,0.018677299842238426,0.016006948426365852,0.013381864875555038,0.016280973330140114,0.01506541296839714,0.015285325236618519,0.018121102824807167,0.014877518638968468,0.015413249842822552,0.014483444392681122,0.012760448269546032,0.012644313275814056,0.01735672913491726,0.013999797403812408,0.011517126113176346,0.016091056168079376,0.013279453851282597,0.012486414983868599,0.011959475465118885,0.012821812182664871,0.013552709482610226,0.014506232924759388,0.013219058513641357,0.015883110463619232,0.01463866513222456,0.012952872551977634,0.012082197703421116,0.011947466060519218,0.011903042905032635,0.011546259745955467,0.012597640976309776,0.013187369331717491,0.013112840242683887,0.011369353160262108,0.013825115747749805,0.014005240052938461,0.011580593883991241,0.011570997536182404,0.012256033718585968,0.01354819443076849,0.010983296670019627,0.010775918141007423,0.012200482189655304,0.010591289028525352,0.010312343016266823,0.01092129573225975,0.010010205209255219,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 102243    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 102244    
=================================================================
Total params: 204,487
Trainable params: 204,487
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 102,243
Trainable params: 102,243
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 102,244
Trainable params: 102,244
Non-trainable params: 0
_________________________________________________________________
