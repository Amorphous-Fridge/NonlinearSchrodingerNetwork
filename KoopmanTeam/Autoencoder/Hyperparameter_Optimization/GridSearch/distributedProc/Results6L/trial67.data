2021-06-26
loss,1.7218607664108276,0.3733893930912018,0.24749866127967834,0.23954622447490692,0.237563818693161,0.23137161135673523,0.2264849841594696,0.22584383189678192,0.223918154835701,0.21223238110542297,0.1630801409482956,0.13870671391487122,0.12517593801021576,0.10308486968278885,0.07948791980743408,0.08833732455968857,0.08889766037464142,0.06833093613386154,0.0666225478053093,0.08277133852243423,0.04966532066464424,0.045797958970069885,0.0731717050075531,0.05283067375421524,0.04199964180588722,0.058435872197151184,0.05083512142300606,0.04800253361463547,0.044025495648384094,0.0600401870906353,0.056806597858667374,0.04989689961075783,0.055228061974048615,0.04742831364274025,0.03734702244400978,0.04294567555189133,0.04837661236524582,0.04634789377450943,0.03869428485631943,0.03658775985240936,0.04192870482802391,0.03834753856062889,0.03511303290724754,0.02936614118516445,0.029086153954267502,0.04221200570464134,0.03621923550963402,0.03684183210134506,0.03577200323343277,0.04143119230866432,0.04137786850333214,0.03637125715613365,0.03284839540719986,0.04455946385860443,0.03882093355059624,0.03158107399940491,0.03562765195965767,0.03703131154179573,0.03627461940050125,0.03752819076180458,0.029401889070868492,0.02793049067258835,0.02971491403877735,0.03854624927043915,0.033421047031879425,0.037413015961647034,0.03278171643614769,0.024476436898112297,0.026289772242307663,0.027613000944256783,0.031133756041526794,0.033340197056531906,0.027198001742362976,0.029085321351885796,0.034367989748716354,0.03197131305932999,0.028451358899474144,0.03157033026218414,0.035291679203510284,0.03618254512548447,0.030400974676012993,0.028051182627677917,0.026440046727657318,0.036149706691503525,0.030750112608075142,0.027805522084236145,0.030345719307661057,0.03753364831209183,0.033660661429166794,0.028923364356160164,0.027000969275832176,0.024933451786637306,0.021083250641822815,0.028684651479125023,0.030430274084210396,0.028454191982746124,0.02051764540374279,0.025174058973789215,0.023320399224758148,0.024917349219322205,
mse,1.266639232635498,0.04113055765628815,0.02055095136165619,0.0195442084223032,0.019182465970516205,0.018373891711235046,0.017094815149903297,0.0158460084348917,0.014948737807571888,0.014845039695501328,0.008357993327081203,0.006089639849960804,0.005121314898133278,0.003279095282778144,0.0019261427223682404,0.0023932771291583776,0.002369459019973874,0.001366221928037703,0.0012811848428100348,0.0020511557813733816,0.0007400739123113453,0.0006256323540583253,0.0015319832600653172,0.000881832093000412,0.0005102415452711284,0.0010206635342910886,0.0007397330482490361,0.0006701437523588538,0.0005792198935523629,0.001034993794746697,0.0009359349496662617,0.0007318785646930337,0.0008565741591155529,0.0006343278218992054,0.00041364284697920084,0.0005350360879674554,0.0006665514665655792,0.0006044198526069522,0.000441154174041003,0.00038841189234517515,0.00049651472363621,0.0004151873290538788,0.0003533222188707441,0.0002621220191940665,0.00025194778572767973,0.0005307391402311623,0.00040626205736771226,0.00038629022310487926,0.00036365140113048255,0.00048668106319382787,0.0005117949331179261,0.00037455320125445724,0.0003106516960542649,0.0005706162774004042,0.00042911950731649995,0.0002926629676949233,0.00036662659840658307,0.000392437243135646,0.0003709934535436332,0.0003949097590520978,0.00025434172130189836,0.0002223562478320673,0.0002582581655588001,0.0004138014046475291,0.0003171651915181428,0.0004031528951600194,0.00031613203464075923,0.00017649053188506514,0.00020292634144425392,0.0002228924131486565,0.00028430265956558287,0.000317886850098148,0.00021990927052684128,0.0002456949732732028,0.0003373447398189455,0.0002918807731475681,0.000232588907238096,0.0002935184456873685,0.00035267844214104116,0.00037243106635287404,0.0002610939263831824,0.0002271943521918729,0.0002028268063440919,0.00037643793621100485,0.00026755049475468695,0.0002212804538430646,0.00026337653980590403,0.00040158696356229484,0.0003211994771845639,0.00024340924574062228,0.00020918191876262426,0.0001795271091395989,0.0001302680029766634,0.00023550713376607746,0.0002605215413495898,0.00023026589769870043,0.00012431525101419538,0.00018336102948524058,0.00015874386008363217,0.00017944269347935915,
mae,0.6848750114440918,0.16066031157970428,0.10597167164087296,0.10399886220693588,0.10337760299444199,0.10125820338726044,0.09832832962274551,0.09412604570388794,0.0942290723323822,0.09051444381475449,0.07028311491012573,0.05903569608926773,0.05380295589566231,0.04338807612657547,0.03381360322237015,0.03676818311214447,0.03746447712182999,0.028714733198285103,0.027512019500136375,0.036523476243019104,0.021396346390247345,0.019851110875606537,0.03150101751089096,0.022420162335038185,0.01791311986744404,0.023980963975191116,0.021150963380932808,0.019621223211288452,0.01859050616621971,0.02533349022269249,0.024152042344212532,0.02157229371368885,0.024151654914021492,0.020681191235780716,0.016057437285780907,0.018075251951813698,0.02120543271303177,0.019765537232160568,0.016574764624238014,0.0155927874147892,0.017856692895293236,0.01630594953894615,0.01415319461375475,0.012360687367618084,0.012410846538841724,0.01841030642390251,0.015438508242368698,0.015707239508628845,0.015170232392847538,0.017821650952100754,0.017635390162467957,0.015368997119367123,0.013856944628059864,0.019907314330339432,0.01614241674542427,0.013592961244285107,0.015256029553711414,0.01576795056462288,0.015370531007647514,0.01644214428961277,0.01244562491774559,0.011926481500267982,0.012668958865106106,0.016221703961491585,0.014027874916791916,0.01676982082426548,0.01377562154084444,0.010331976227462292,0.011071412824094296,0.011757541447877884,0.013092364184558392,0.014104518108069897,0.011667418293654919,0.01244623214006424,0.014911556616425514,0.013764693401753902,0.01203670259565115,0.013275980949401855,0.014996963553130627,0.015684155747294426,0.012824404053390026,0.011647836305201054,0.011064157821238041,0.015301917679607868,0.01307517010718584,0.011890769004821777,0.01240911241620779,0.0164189413189888,0.014812938868999481,0.012348953634500504,0.01126791164278984,0.010627765208482742,0.008886384777724743,0.012154931202530861,0.01271121483296156,0.012112908065319061,0.008666535839438438,0.010667000897228718,0.009929854422807693,0.010595228523015976,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 297171    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 297172    
=================================================================
Total params: 594,343
Trainable params: 594,343
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 297,171
Trainable params: 297,171
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 297,172
Trainable params: 297,172
Non-trainable params: 0
_________________________________________________________________
