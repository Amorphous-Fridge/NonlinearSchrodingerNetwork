2021-06-26
loss,1.3719029426574707,0.3602408468723297,0.2569836378097534,0.1960119754076004,0.1460552215576172,0.11527329683303833,0.10803690552711487,0.11884663254022598,0.12178876250982285,0.12418339401483536,0.10353651642799377,0.08914485573768616,0.07606682181358337,0.07980366051197052,0.08070449531078339,0.0914812758564949,0.08090965449810028,0.07772575318813324,0.07268290221691132,0.058724090456962585,0.0537482313811779,0.06764277815818787,0.056530460715293884,0.05779426917433739,0.05888805910944939,0.05643812566995621,0.05122598260641098,0.05145442113280296,0.05297427624464035,0.05532168969511986,0.04323606193065643,0.05094002187252045,0.04419903829693794,0.03719102218747139,0.03681444749236107,0.04367159307003021,0.04337551072239876,0.04959709942340851,0.04493672028183937,0.03890974819660187,0.03898721560835838,0.043307069689035416,0.045351944863796234,0.04076434671878815,0.039695266634225845,0.033865977078676224,0.039555586874485016,0.04339263588190079,0.0336681492626667,0.03674519434571266,0.043712176382541656,0.040503837168216705,0.037310391664505005,0.02798318676650524,0.03705531731247902,0.04187121242284775,0.03781159967184067,0.031887903809547424,0.03252111375331879,0.03718401864171028,0.03338649868965149,0.03832371532917023,0.0350617840886116,0.03557245433330536,0.03627205267548561,0.029485899955034256,0.037877172231674194,0.03422469645738602,0.029152560979127884,0.026685334742069244,0.03676179051399231,0.036138590425252914,0.032061122357845306,0.034909721463918686,0.03193361684679985,0.027194447815418243,0.025390785187482834,0.023558415472507477,0.033672261983156204,0.03283194452524185,0.029982203617691994,0.028361868113279343,0.03542449697852135,0.03234316408634186,0.0331047885119915,0.03173765540122986,0.027314120903611183,0.02856961451470852,0.029643280431628227,0.02732556127011776,0.03534811735153198,0.02716970443725586,0.026214545592665672,0.02504991926252842,0.030151590704917908,0.03178777918219566,0.03318347781896591,0.029272280633449554,0.022846458479762077,0.02436782605946064,
mse,0.7140055894851685,0.03813697770237923,0.019868839532136917,0.011534249410033226,0.006417698226869106,0.0038522984832525253,0.0034747652243822813,0.004531740210950375,0.004442516248673201,0.004432129207998514,0.0032661149743944407,0.002270757919177413,0.0016433653654530644,0.0018314473563805223,0.0019395367708057165,0.002428281120955944,0.0018451367504894733,0.001669348799623549,0.001501282211393118,0.0009843274019658566,0.0008180096046999097,0.0012775914510712028,0.0009106836514547467,0.0009428526391275227,0.0009861388243734837,0.0008923165732994676,0.0007524394895881414,0.0007380046881735325,0.0007840429898351431,0.0008362459484487772,0.0005447345320135355,0.0007317429990507662,0.0005563110462389886,0.0004034771700389683,0.00039722799556329846,0.0005340099451132119,0.0005344657110981643,0.0006785954465158284,0.0005763615481555462,0.0004317114071454853,0.0004326354246586561,0.000518985150847584,0.0005728195537813008,0.000463296368252486,0.0004413168935570866,0.0003300236421637237,0.00043507403461262584,0.0005457726656459272,0.0003409672062844038,0.00038005481474101543,0.0005266115185804665,0.0004585261922329664,0.0003862686862703413,0.00022345416073221713,0.00038531303289346397,0.0004921472282148898,0.000405972998123616,0.0002846958232112229,0.0003098523593507707,0.0003815811069216579,0.0003046661731787026,0.0004123101243749261,0.0003438133280724287,0.00036320911021903157,0.00035962648689746857,0.00024075887631624937,0.0003998492320533842,0.0003261883102823049,0.0002329283597646281,0.00021394543000496924,0.00037853390676900744,0.00036982668098062277,0.00028603768441826105,0.0003420864522922784,0.00028089515399187803,0.0002113881491823122,0.00018732156604528427,0.00017165884491987526,0.00032170244958251715,0.00030562796746380627,0.0002478688256815076,0.00022557942429557443,0.00034487005905248225,0.00030110825900919735,0.00030622692429460585,0.00027891830541193485,0.00021233504230622202,0.00023188075283542275,0.00024087003839667886,0.00021285319235175848,0.0003460213483776897,0.0002047395391855389,0.00019807720673270524,0.00017769054102245718,0.0002560568682383746,0.00028801432927139103,0.0002986854233313352,0.00023400977079290897,0.0001490625727456063,0.0001811328111216426,
mae,0.5663450956344604,0.1567848175764084,0.11128651350736618,0.08410291373729706,0.06261993944644928,0.04958982765674591,0.04690195247530937,0.0502195730805397,0.05249074473977089,0.053903546184301376,0.04475454241037369,0.03763098269701004,0.03221038356423378,0.034054502844810486,0.03522929549217224,0.03979227691888809,0.03470612317323685,0.033471688628196716,0.030973995104432106,0.02494664490222931,0.02282758802175522,0.02947695553302765,0.024434126913547516,0.024923181161284447,0.025274403393268585,0.024162234738469124,0.022056138142943382,0.022166993468999863,0.02275157906115055,0.023657046258449554,0.018415316939353943,0.02204766497015953,0.019031040370464325,0.015645086765289307,0.015763485804200172,0.01854744739830494,0.018543578684329987,0.021433359012007713,0.019354358315467834,0.016669807955622673,0.016597328707575798,0.018859749659895897,0.019617633894085884,0.017764318734407425,0.017008310183882713,0.014393367804586887,0.016974076628684998,0.018623381853103638,0.014362089335918427,0.01580233685672283,0.018775831907987595,0.01730659417808056,0.016129814088344574,0.011855952441692352,0.01595052145421505,0.017827512696385384,0.016202202066779137,0.01366141065955162,0.013872887007892132,0.015782171860337257,0.01423441618680954,0.0165579654276371,0.015042001381516457,0.015260616317391396,0.015729844570159912,0.012650169432163239,0.016359712928533554,0.014680778607726097,0.01283025462180376,0.01138613186776638,0.015580229461193085,0.015469917096197605,0.013808362185955048,0.014983942732214928,0.01366338599473238,0.011781659908592701,0.010750607587397099,0.010179126635193825,0.014378135092556477,0.013941237702965736,0.012863836251199245,0.012446897104382515,0.015214122831821442,0.014004269614815712,0.014299614354968071,0.013481518253684044,0.011613224633038044,0.01193747017532587,0.012732667848467827,0.011875034309923649,0.01504253875464201,0.011781517416238785,0.011160706169903278,0.010745488107204437,0.012781878933310509,0.01368052139878273,0.014268160797655582,0.012496644631028175,0.009604080580174923,0.010393648408353329,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 296587    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 296588    
=================================================================
Total params: 593,175
Trainable params: 593,175
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 296,587
Trainable params: 296,587
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 296,588
Trainable params: 296,588
Non-trainable params: 0
_________________________________________________________________
