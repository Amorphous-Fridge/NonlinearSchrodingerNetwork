2021-06-26
loss,0.5723661780357361,0.2362963706254959,0.22013811767101288,0.17429032921791077,0.1111941784620285,0.10496840626001358,0.13492131233215332,0.07871759682893753,0.08872141689062119,0.0868915542960167,0.06887008994817734,0.07946958392858505,0.08314848691225052,0.06612595915794373,0.05161939188838005,0.05337432026863098,0.06610505282878876,0.06671509146690369,0.05823252350091934,0.057360731065273285,0.05834237486124039,0.055402789264917374,0.03580993786454201,0.046568237245082855,0.04764905944466591,0.049003716558218,0.03977939859032631,0.03876069560647011,0.045268572866916656,0.03698154538869858,0.039818864315748215,0.0458260253071785,0.0445149689912796,0.044119883328676224,0.04119204357266426,0.03848728537559509,0.034795332700014114,0.036960870027542114,0.034106843173503876,0.03389313817024231,0.029732519760727882,0.03770517185330391,0.03939436748623848,0.03407135605812073,0.03378143161535263,0.030904032289981842,0.032406724989414215,0.03181840479373932,0.03409538418054581,0.032791439443826675,0.030315443873405457,0.031638529151678085,0.027719514444470406,0.0253387913107872,0.023324506357312202,0.02460055984556675,0.023722194135189056,0.030755579471588135,0.029576826840639114,0.027278626337647438,0.03003653511404991,0.027839677408337593,0.02927197515964508,0.024684226140379906,0.022612782195210457,0.023208795115351677,0.02811790257692337,0.028955452144145966,0.025196492671966553,0.022502100095152855,0.023282550275325775,0.026864739134907722,0.02449292689561844,0.027389395982027054,0.02479417622089386,0.021399294957518578,0.02139599248766899,0.01982722245156765,0.021811705082654953,0.02538621984422207,0.022766299545764923,0.020348308607935905,0.022398704662919044,0.021731821820139885,0.0189274363219738,0.016169022768735886,0.02437703125178814,0.02217177115380764,0.019798066467046738,0.023899409919977188,0.020545106381177902,0.023476019501686096,0.024119263514876366,0.020874567329883575,0.01921510510146618,0.017843857407569885,0.021944044157862663,0.021146176382899284,0.023829815909266472,0.021096324548125267,
mse,0.151503786444664,0.018540870398283005,0.014907137490808964,0.008427221328020096,0.003502687904983759,0.003119627945125103,0.005443474743515253,0.001742788590490818,0.002255789004266262,0.0021443183068186045,0.0012993401614949107,0.001803136896342039,0.0019472530111670494,0.0012595654698088765,0.0007697464316152036,0.000814672326669097,0.0012590005062520504,0.001255327370017767,0.0009587963577359915,0.0009125628275796771,0.0010006550000980496,0.0008476346847601235,0.00036661323974840343,0.0006323023699223995,0.0006643615779466927,0.0006494399858638644,0.00044774034176953137,0.0004266399482730776,0.0005636008572764695,0.00038513343315571547,0.0004550486337393522,0.0005941494018770754,0.0005538339028134942,0.0005494763026945293,0.00047573994379490614,0.0004180683463346213,0.00034799505374394357,0.0003733562771230936,0.0003310987667646259,0.00033078997512347996,0.00025020656175911427,0.00039884145371615887,0.00043236996862106025,0.0003156686434522271,0.00031448769732378423,0.0002595808473415673,0.0002943058789242059,0.00028414028929546475,0.000327296438626945,0.00029467736021615565,0.0002565777685958892,0.0002769020793493837,0.0002127154148183763,0.00018006029131356627,0.00015729776350781322,0.0001696927793091163,0.00015562301268801093,0.00027096361736766994,0.00024385792494285852,0.0002110690693370998,0.00025168145657517016,0.00021488979109562933,0.0002367176639381796,0.00016940046043600887,0.0001460024359403178,0.00015262381930369884,0.00022086776152718812,0.00023473560577258468,0.0001757695572450757,0.00014357484178617597,0.00015419424744322896,0.00020061025861650705,0.00017119823314715177,0.00020900661183986813,0.00016754113312344998,0.00012954295380041003,0.0001295896654482931,0.00011652182001853362,0.00013712704821955413,0.00017647925415076315,0.0001432110002497211,0.00011937096860492602,0.00014384544920176268,0.00013300594582688063,0.00010790127271320671,7.57964953663759e-05,0.00017099852266255766,0.0001387646043440327,0.00011604565952438861,0.00016236650117207319,0.00012050541408825666,0.00015479304420296103,0.00016068429977167398,0.00012123009946662933,0.00010553372703725472,9.139987378148362e-05,0.00013724506425205618,0.0001252801448572427,0.00015565483772661537,0.0001239223638549447,
mae,0.24690057337284088,0.10418817400932312,0.09365689009428024,0.07516901195049286,0.04778721183538437,0.0453435555100441,0.05803072825074196,0.03368421271443367,0.03741062805056572,0.03646625950932503,0.029326854273676872,0.03433137387037277,0.03621232137084007,0.028110027313232422,0.022043664008378983,0.022715747356414795,0.028120798990130424,0.0294578168541193,0.02535494975745678,0.025152498856186867,0.024546019732952118,0.023141497746109962,0.015035110525786877,0.019722258672118187,0.020659418776631355,0.02084398828446865,0.01669437438249588,0.016760796308517456,0.0191456601023674,0.015867389738559723,0.01691419444978237,0.019550463184714317,0.01891026832163334,0.018994463607668877,0.017447898164391518,0.01638672687113285,0.014646552503108978,0.015945302322506905,0.014627346768975258,0.01412863377481699,0.01258827093988657,0.015831293538212776,0.01654687337577343,0.014382310211658478,0.013986686244606972,0.012788794003427029,0.013721964322030544,0.01352013275027275,0.01467138808220625,0.013708461076021194,0.013014262542128563,0.013138320297002792,0.011233469471335411,0.010442785918712616,0.009894494898617268,0.010346081107854843,0.00997009314596653,0.013010096736252308,0.01293017715215683,0.011422487907111645,0.012814110144972801,0.011811320669949055,0.012349773198366165,0.010312318801879883,0.00932917557656765,0.009822680614888668,0.011980609968304634,0.011996157467365265,0.010798896662890911,0.009440758265554905,0.010081985965371132,0.011610538698732853,0.010559561662375927,0.011587723158299923,0.010616878047585487,0.008811199106276035,0.009032245725393295,0.008372430689632893,0.00923631526529789,0.010989857837557793,0.010052324272692204,0.008685324341058731,0.009474842809140682,0.009156662039458752,0.007997274398803711,0.006854125298559666,0.01042796578258276,0.009279112331569195,0.008273146115243435,0.01014886423945427,0.008595678023993969,0.010062595829367638,0.010356774553656578,0.008991550654172897,0.008126048371195793,0.00764094665646553,0.009279735386371613,0.008932667784392834,0.00999295711517334,0.008770556189119816,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 37539     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 37540     
=================================================================
Total params: 75,079
Trainable params: 75,079
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 37,539
Trainable params: 37,539
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 37,540
Trainable params: 37,540
Non-trainable params: 0
_________________________________________________________________
