2021-06-26
loss,2.3567898273468018,0.40423813462257385,0.27991288900375366,0.24683387577533722,0.23636791110038757,0.2212168276309967,0.21344199776649475,0.2027389109134674,0.20719283819198608,0.2049158662557602,0.18112677335739136,0.13528451323509216,0.12451904267072678,0.11489053070545197,0.11077581346035004,0.09952360391616821,0.09193587303161621,0.093578040599823,0.09022893011569977,0.0794248878955841,0.06868018209934235,0.08577284961938858,0.07035639137029648,0.06547034531831741,0.05542862415313721,0.05867825448513031,0.07554976642131805,0.06304461508989334,0.06114768609404564,0.06514925509691238,0.060852888971567154,0.05130728334188461,0.05002022162079811,0.05953957512974739,0.05464986711740494,0.059550024569034576,0.05069488659501076,0.058048516511917114,0.048719096928834915,0.04890074208378792,0.05406295880675316,0.05277761444449425,0.043762803077697754,0.046366576105356216,0.04507330060005188,0.04568472504615784,0.04705822467803955,0.04270528629422188,0.03647812083363533,0.03736599534749985,0.04198794439435005,0.0335049144923687,0.04484427347779274,0.0434185154736042,0.04221773147583008,0.03749558702111244,0.04005962982773781,0.03842388466000557,0.035334158688783646,0.03721104562282562,0.04344122111797333,0.04052107408642769,0.03881803900003433,0.038783423602581024,0.04427562654018402,0.03447187691926956,0.03965837135910988,0.04215693846344948,0.032908931374549866,0.03397146239876747,0.03689403086900711,0.036082781851291656,0.043038416653871536,0.041402701288461685,0.03268258273601532,0.036939822137355804,0.03689171001315117,0.03404194489121437,0.02812550961971283,0.032554350793361664,0.0388382188975811,0.03894372284412384,0.026976656168699265,0.030210765078663826,0.03851880878210068,0.03655985742807388,0.03545033559203148,0.03296317160129547,0.030291607603430748,0.03355814516544342,0.027460947632789612,0.03788553550839424,0.034498438239097595,0.03494095429778099,0.03532085195183754,0.02873971499502659,0.03247738257050514,0.029166020452976227,0.032865773886442184,0.03521978482604027,
mse,1.6316931247711182,0.04883524030447006,0.02412160113453865,0.019966578111052513,0.018393289297819138,0.01638447493314743,0.015171846374869347,0.013453559018671513,0.013689035549759865,0.013125820085406303,0.009796550497412682,0.005355768837034702,0.0045915637165308,0.003776316996663809,0.0037019005976617336,0.0031353577505797148,0.0024659992195665836,0.0025391001254320145,0.0023771594278514385,0.0016973450547084212,0.0013520247302949429,0.0021589642856270075,0.0013868792448192835,0.001184969674795866,0.0009063993929885328,0.0010333959944546223,0.001582243130542338,0.001150766620412469,0.0010313496459275484,0.0012107468210160732,0.0010329062351956964,0.0007389403763227165,0.0007374996785074472,0.0010113094467669725,0.0008365793037228286,0.0009919516742229462,0.0007210704497992992,0.0009348772582598031,0.0006515056011267006,0.0006832273793406785,0.0008182626916095614,0.0007651049527339637,0.0005547564360313118,0.0005944385193288326,0.0005545935709960759,0.0005779941566288471,0.0006120374309830368,0.0004953714669682086,0.0003751745680347085,0.0003946492215618491,0.00048355580656789243,0.0003260622906964272,0.0005814319010823965,0.0005262576160021126,0.0004842580237891525,0.0003888268838636577,0.000454474677098915,0.0004134455812163651,0.0003528764354996383,0.0004018254694528878,0.0005375327309593558,0.00046532589476555586,0.0004266858159098774,0.000422610086388886,0.0005329509149305522,0.00033809515298344195,0.00043536804150789976,0.0004910244606435299,0.00030336808413267136,0.0003254008188378066,0.0003913947439286858,0.0003600989293772727,0.0005215851706452668,0.00048567811609245837,0.00030738190980628133,0.0003825442399829626,0.0003797871177084744,0.0003189720446243882,0.0002280538174090907,0.0003066315839532763,0.0004227875033393502,0.0004147488216403872,0.0002140514407074079,0.0002780492650344968,0.0004108165157958865,0.0003789034963119775,0.00034126490936614573,0.0002954955562017858,0.0002582296438049525,0.00030862510902807117,0.00021515418484341353,0.00041260753641836345,0.0003277222567703575,0.000348628091160208,0.00034363128361292183,0.00023868514108471572,0.0003031092055607587,0.00024220698105636984,0.0003008040366694331,0.00033969763899222016,
mae,0.9924701452255249,0.17390228807926178,0.12119512259960175,0.10780446976423264,0.10324130207300186,0.09649958461523056,0.09268143028020859,0.08715111762285233,0.08904537558555603,0.08877087384462357,0.07792098820209503,0.05818280205130577,0.053671784698963165,0.04874147102236748,0.04675937816500664,0.04303503409028053,0.03951902315020561,0.04073125496506691,0.03869844600558281,0.03533155843615532,0.029866093769669533,0.03691597655415535,0.030392376706004143,0.02790582738816738,0.023206155747175217,0.02505393698811531,0.03225579857826233,0.027140960097312927,0.026482734829187393,0.027734506875276566,0.026627352461218834,0.02192879281938076,0.02108864299952984,0.02534104324877262,0.023400433361530304,0.025659315288066864,0.021594226360321045,0.024729259312152863,0.020958099514245987,0.02100364863872528,0.02283002808690071,0.022381817921996117,0.019065620377659798,0.02073105052113533,0.019959939643740654,0.02014988847076893,0.019876452162861824,0.018622593954205513,0.015459930524230003,0.015685129910707474,0.018364019691944122,0.01415337435901165,0.019427848979830742,0.018261700868606567,0.018223095685243607,0.01629575341939926,0.017083361744880676,0.016299307346343994,0.015110006555914879,0.015902912244200706,0.01917428709566593,0.0171110387891531,0.01628366857767105,0.016554439440369606,0.019144797697663307,0.014872975647449493,0.01699860394001007,0.01827109232544899,0.014135385863482952,0.014741740189492702,0.015935352072119713,0.015579071827232838,0.018610918894410133,0.018087483942508698,0.013943444937467575,0.015917716547846794,0.015538979321718216,0.014796469360589981,0.011839094571769238,0.013874256983399391,0.016885114833712578,0.01687922701239586,0.011573136784136295,0.012557831592857838,0.016758732497692108,0.015442265197634697,0.015264767222106457,0.014338289387524128,0.012862423434853554,0.014602333307266235,0.011887972243130207,0.01626935973763466,0.01509691122919321,0.01474818680435419,0.015321318060159683,0.012341490015387535,0.013880849815905094,0.012383393943309784,0.013886612839996815,0.015152080915868282,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 398739    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 398740    
=================================================================
Total params: 797,479
Trainable params: 797,479
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 398,739
Trainable params: 398,739
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 398,740
Trainable params: 398,740
Non-trainable params: 0
_________________________________________________________________
