2021-06-26
loss,2.3586266040802,0.6527854800224304,0.22579671442508698,0.12716935575008392,0.1009441688656807,0.1106555238366127,0.09338177740573883,0.08453278243541718,0.10296767204999924,0.062469858676195145,0.06802576780319214,0.054165247827768326,0.05354207381606102,0.056277383118867874,0.058530427515506744,0.07884135842323303,0.07081793993711472,0.06175309047102928,0.03900402411818504,0.05368118733167648,0.06200455129146576,0.05052981525659561,0.031748462468385696,0.047989193350076675,0.03977086395025253,0.04377231001853943,0.05001053214073181,0.03869650512933731,0.031108252704143524,0.0432746596634388,0.0398692786693573,0.04971887916326523,0.05051654949784279,0.041600655764341354,0.043206192553043365,0.03454073891043663,0.027844734489917755,0.036921534687280655,0.03915102779865265,0.038136016577482224,0.03533141314983368,0.029133832082152367,0.04279528930783272,0.04396842420101166,0.03819828853011131,0.02805813029408455,0.027224605903029442,0.030762027949094772,0.03694188967347145,0.0336511954665184,0.040244948118925095,0.03537255898118019,0.03104044683277607,0.02967015467584133,0.027587123215198517,0.024641919881105423,0.027607940137386322,0.0352756530046463,0.040868788957595825,0.03359632194042206,0.032466817647218704,0.03257347270846367,0.03211016580462456,0.03377239778637886,0.027370862662792206,0.025520168244838715,0.036302436143159866,0.03333774954080582,0.02584831230342388,0.023140735924243927,0.02134651131927967,0.028299842029809952,0.03307027369737625,0.030857032164931297,0.03525031730532646,0.03194344416260719,0.026469102129340172,0.03285990655422211,0.03251951187849045,0.028582317754626274,0.025173304602503777,0.02864939533174038,0.03416241705417633,0.032105304300785065,0.03022623062133789,0.02707464061677456,0.026445304974913597,0.023702077567577362,0.025133756920695305,0.03186153247952461,0.0308400746434927,0.03259199485182762,0.026159098371863365,0.02669908106327057,0.029355015605688095,0.03030751645565033,0.02995600551366806,0.03030874766409397,0.029584240168333054,0.02697312831878662,
mse,1.4435603618621826,0.18128550052642822,0.015959447249770164,0.004838608670979738,0.0030996494460850954,0.0038797890301793814,0.002636207267642021,0.002169167622923851,0.0031699046958237886,0.0011707486119121313,0.001398859778419137,0.0008766266983002424,0.0008768434636294842,0.0009593240101821721,0.001070693600922823,0.0019406594801694155,0.001390147372148931,0.0011007166467607021,0.0004738727293442935,0.0008711041300557554,0.001092701219022274,0.0007535121403634548,0.0003056372224818915,0.0006931910756975412,0.00048066445742733777,0.0005917157977819443,0.0007336031412705779,0.00045498856343328953,0.00029227687628008425,0.0005669421516358852,0.0004785291093867272,0.000729416380636394,0.0007127327262423933,0.0005075197550468147,0.0005361544899642467,0.0003771577321458608,0.00024776524514891207,0.00041053310269489884,0.00045655237045139074,0.0004417556629050523,0.00038659555139020085,0.00026188758783973753,0.0005553679075092077,0.0005608444334939122,0.00044503359822556376,0.0002425582497380674,0.0002263380738440901,0.00029634873499162495,0.00039759610081091523,0.0003351048508193344,0.00046275334898382425,0.00037264119600877166,0.0002951590868178755,0.00026437058113515377,0.00023674406111240387,0.00018221174832433462,0.0002282956411363557,0.00037580126081593335,0.00046445426414720714,0.00033937630360014737,0.0003104259667452425,0.0003095596912316978,0.0003078569134231657,0.0003378568508196622,0.00022747745970264077,0.00020130703342147171,0.0003808957990258932,0.00032165099401026964,0.00020585230959113687,0.00016480246267747134,0.00014043523697182536,0.00024481589207425714,0.0003234021132811904,0.0002784781972877681,0.00035929272416979074,0.0003039679431822151,0.00021764516714029014,0.0003208769194316119,0.00030171728576533496,0.00024078143178485334,0.00019534752937033772,0.0002448798040859401,0.0003399315755814314,0.0003050695813726634,0.00026897096540778875,0.00022746232571080327,0.00021054813987575471,0.00017265358474105597,0.0001852977293310687,0.00028794529498554766,0.00027350534219294786,0.00030379448435269296,0.00020067751756869256,0.00021602879860438406,0.00024909854982979596,0.00026334627182222903,0.00025774442474357784,0.0002594329707790166,0.00024675988242961466,0.00021631349227391183,
mae,0.8454014658927917,0.2515949308872223,0.09468510746955872,0.05415774881839752,0.043080419301986694,0.04774077981710434,0.03996296226978302,0.03634069114923477,0.04427549988031387,0.02661856822669506,0.029375409707427025,0.023314334452152252,0.02291305549442768,0.02396348863840103,0.025362558662891388,0.03375844657421112,0.03071235865354538,0.026486527174711227,0.016674116253852844,0.022919081151485443,0.02648681402206421,0.021785372868180275,0.013491461053490639,0.020707767456769943,0.0169579666107893,0.01896151714026928,0.021629715338349342,0.01633370667695999,0.0132965799421072,0.018510334193706512,0.017038920894265175,0.021387100219726562,0.021783189848065376,0.01782378740608692,0.018578561022877693,0.014760336838662624,0.011718065477907658,0.015538531355559826,0.016807544976472855,0.01642727293074131,0.01522101555019617,0.012399879284203053,0.018230009824037552,0.018959056586027145,0.01618821918964386,0.012041766196489334,0.01168354507535696,0.013319906778633595,0.015723779797554016,0.014269785955548286,0.017455535009503365,0.015397123992443085,0.013142301701009274,0.012447915971279144,0.011677307076752186,0.010575182735919952,0.011762830428779125,0.014893872663378716,0.01744525320827961,0.014247762970626354,0.013777071610093117,0.013986412435770035,0.013756930828094482,0.014280028641223907,0.011585363186895847,0.010863840579986572,0.015591499395668507,0.014243323355913162,0.01099503505975008,0.009955273009836674,0.00908602587878704,0.012056421488523483,0.014201214537024498,0.01314625609666109,0.015117598697543144,0.013725695200264454,0.011209727264940739,0.014053652063012123,0.014300435781478882,0.012232357636094093,0.010749738663434982,0.012248470447957516,0.014384628273546696,0.013762409798800945,0.012959790416061878,0.011607011780142784,0.011295149102807045,0.010019272565841675,0.010750031098723412,0.01363987848162651,0.01321481540799141,0.013790122233331203,0.011166808195412159,0.011519000865519047,0.012540995143353939,0.012927944771945477,0.012529212050139904,0.013076359406113625,0.012699072249233723,0.011564206331968307,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 118611    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 118612    
=================================================================
Total params: 237,223
Trainable params: 237,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 118,611
Trainable params: 118,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 118,612
Trainable params: 118,612
Non-trainable params: 0
_________________________________________________________________
