2021-06-26
loss,0.42079269886016846,0.11267702281475067,0.07888000458478928,0.06755311787128448,0.059682875871658325,0.05506879463791847,0.05125974118709564,0.04794657230377197,0.04608555883169174,0.0434037446975708,0.0423550084233284,0.04055587202310562,0.03977181389927864,0.0384683832526207,0.037425294518470764,0.036725856363773346,0.03577716648578644,0.03512919321656227,0.03432048484683037,0.03424326330423355,0.03384677320718765,0.032892461866140366,0.03265910595655441,0.032099153846502304,0.031207837164402008,0.03174838051199913,0.03190677613019943,0.030342137441039085,0.029954083263874054,0.029496127739548683,0.02907799929380417,0.028945401310920715,0.028408436104655266,0.02827584184706211,0.028028881177306175,0.02755846083164215,0.02774943597614765,0.027400601655244827,0.02709418721497059,0.026648765429854393,0.026249874383211136,0.02627822570502758,0.025951609015464783,0.025777118280529976,0.025483762845396996,0.025783173739910126,0.02524196356534958,0.025029286742210388,0.024970896542072296,0.025460897013545036,0.025574656203389168,0.02444092556834221,0.024688517674803734,0.02435329183936119,0.02401961386203766,0.023953072726726532,0.02368837408721447,0.02334260381758213,0.023343512788414955,0.02305106446146965,0.02279297634959221,0.023070139810442924,0.022860951721668243,0.02289784885942936,0.022862380370497704,0.022469639778137207,0.023065907880663872,0.02223103493452072,0.022404510527849197,0.021992361173033714,0.022384295240044594,0.022109054028987885,0.022039856761693954,0.02170218899846077,0.02160227857530117,0.021301718428730965,0.021128810942173004,0.02097153663635254,0.020995648577809334,0.02090398781001568,0.020758196711540222,0.020448291674256325,0.020572932437062263,0.020491942763328552,0.020389150828123093,0.02041321061551571,0.02016635239124298,0.019938750192523003,0.019761821255087852,0.020241182297468185,0.01978353224694729,0.019780540838837624,0.019659552723169327,0.01937914825975895,0.01947740465402603,0.019358670338988304,0.019464027136564255,0.01917712204158306,0.019025374203920364,0.01916476897895336,
mse,0.08909708261489868,0.0041366866789758205,0.0018915471155196428,0.0013795318081974983,0.001081216847524047,0.0009138812893070281,0.0007868153625167906,0.0006898590945638716,0.0006310000317171216,0.0005587073392234743,0.0005281342891976237,0.00048356366460211575,0.00046043991460464895,0.0004304168396629393,0.0004074506869073957,0.00039070178172551095,0.0003692446043714881,0.0003567010862752795,0.00034057843731716275,0.0003375501837581396,0.0003296388313174248,0.0003123655042145401,0.00030561673338524997,0.00029597841785289347,0.0002792394661810249,0.00029021056252531707,0.00029485978302545846,0.00026480763335712254,0.00025678554084151983,0.00024793471675366163,0.00024123767798300833,0.00023831393627915531,0.0002292189747095108,0.00022732115758117288,0.00022676034132018685,0.00021651083079632372,0.0002179197035729885,0.00021309981821104884,0.00020904013945255429,0.00020135841623414308,0.0001945813128259033,0.00019553594756871462,0.00019105452520307153,0.0001891074498416856,0.0001835906004998833,0.00018883401935454458,0.00018235883908346295,0.00017755653243511915,0.0001760217419359833,0.00018413901852909476,0.00018768444715533406,0.0001729058858472854,0.00017345929518342018,0.0001675413514021784,0.00016287747712340206,0.00016197841614484787,0.00015839077241253108,0.0001537591451779008,0.00015294233162421733,0.00014970044139772654,0.00014936640218365937,0.00015640626952517778,0.00014779811317566782,0.00014861045929137617,0.00014729092072229832,0.00014190726506058127,0.00015312392497435212,0.00014465017011389136,0.00014596091932617128,0.0001411724806530401,0.00014769757399335504,0.0001390659308526665,0.0001365138596156612,0.00013248578761704266,0.00013200238754507154,0.0001278948038816452,0.00012538852752186358,0.00012385436275508255,0.00012436164251994342,0.00012327228614594787,0.00012358662206679583,0.00011763445945689455,0.00011890763562405482,0.00011806913971668109,0.00011654377885861322,0.00011702553456416354,0.00011368653940735385,0.00011239782179472968,0.00011257703590672463,0.00011551949864951894,0.00010961567022604868,0.00010958257917081937,0.00010857803135877475,0.00010498439223738387,0.00010836646833922714,0.00010663876309990883,0.00010661182750482112,0.00010321829176973552,0.00010149872832698748,0.0001027358157443814,
mae,0.18526238203048706,0.047530725598335266,0.03319944813847542,0.028652949258685112,0.02525247633457184,0.023311343044042587,0.02170187421143055,0.020368855446577072,0.019616104662418365,0.01853601075708866,0.018084803596138954,0.017369847744703293,0.017020640894770622,0.0164030808955431,0.01605808176100254,0.01570926234126091,0.015353444963693619,0.014997080899775028,0.014812656678259373,0.014647116884589195,0.014568091370165348,0.01399601623415947,0.014064821414649487,0.01389983855187893,0.013450860045850277,0.01359893660992384,0.013707028701901436,0.0130267683416605,0.012750607915222645,0.012781628407537937,0.012387793511152267,0.01248115673661232,0.01217576488852501,0.01222831942141056,0.012041665613651276,0.011932139284908772,0.011934526264667511,0.011768617667257786,0.011656464077532291,0.011371200904250145,0.01132481824606657,0.011312229558825493,0.011190441437065601,0.010864670388400555,0.010897367261350155,0.011087375693023205,0.010878507047891617,0.010629246011376381,0.010758643969893456,0.010895561426877975,0.010906645096838474,0.010418201796710491,0.010646454989910126,0.010484183207154274,0.010289265774190426,0.010235578753054142,0.010168040171265602,0.009980570524930954,0.01002482883632183,0.009777541272342205,0.009805217385292053,0.009840763173997402,0.009767517447471619,0.009893476963043213,0.009863657876849174,0.009641775861382484,0.00986167136579752,0.00950321089476347,0.009602930396795273,0.009320328012108803,0.009470012038946152,0.009492658078670502,0.009459307417273521,0.009332089684903622,0.009243032895028591,0.0091722272336483,0.009115542285144329,0.00892773736268282,0.00897485762834549,0.009012973867356777,0.008877635933458805,0.008734620176255703,0.0088197011500597,0.008747391402721405,0.00880521535873413,0.008745812810957432,0.008610573597252369,0.008420910686254501,0.008532611653208733,0.008649344556033611,0.008456987328827381,0.008500386029481888,0.008378270082175732,0.00835543405264616,0.008310338482260704,0.0081455884501338,0.008342663757503033,0.00825655646622181,0.008260378614068031,0.008166199550032616,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 6635      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 6636      
=================================================================
Total params: 13,271
Trainable params: 13,271
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 6,635
Trainable params: 6,635
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 6,636
Trainable params: 6,636
Non-trainable params: 0
_________________________________________________________________
