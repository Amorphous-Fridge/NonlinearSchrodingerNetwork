2021-06-26
loss,0.565920889377594,0.23200391232967377,0.1556542068719864,0.11878855526447296,0.10326721519231796,0.09473862498998642,0.08806554973125458,0.08245062083005905,0.07546751946210861,0.07065385580062866,0.06757044047117233,0.06894020736217499,0.09278076142072678,0.05708452686667442,0.05457540601491928,0.07469967752695084,0.06069781631231308,0.05192648991942406,0.05336597561836243,0.056835681200027466,0.04843924939632416,0.07748588919639587,0.07321716099977493,0.06521283090114594,0.05607406049966812,0.046716105192899704,0.03806386888027191,0.03778011351823807,0.04758569598197937,0.05394485965371132,0.05203716456890106,0.04627275839447975,0.039270054548978806,0.0443195104598999,0.045662034302949905,0.045355383306741714,0.042913373559713364,0.03822120651602745,0.03335907310247421,0.0297368336468935,0.027406472712755203,0.03107023425400257,0.040928732603788376,0.04198111593723297,0.03235255926847458,0.03542532026767731,0.0400257334113121,0.03585624322295189,0.03414738550782204,0.03126823529601097,0.03500084951519966,0.03308328241109848,0.033674731850624084,0.0347105972468853,0.028797518461942673,0.027135485783219337,0.02651449479162693,0.032035257667303085,0.027598034590482712,0.029848573729395866,0.035256896167993546,0.029939327389001846,0.031249234452843666,0.028348078951239586,0.029113681986927986,0.03234568238258362,0.029045766219496727,0.025608686730265617,0.023243075236678123,0.02240925468504429,0.02761012874543667,0.03302918002009392,0.02978704683482647,0.025833701714873314,0.024328025057911873,0.02286696992814541,0.022346865385770798,0.027445506304502487,0.030876250937581062,0.026969047263264656,0.02926379255950451,0.025956900790333748,0.022952452301979065,0.023060975596308708,0.02511516399681568,0.022272517904639244,0.021211838349699974,0.026023872196674347,0.028393227607011795,0.024281062185764313,0.025852518156170845,0.026719145476818085,0.024272622540593147,0.024980925023555756,0.022686805576086044,0.02080409787595272,0.018098637461662292,0.015494771301746368,0.01482804398983717,0.014790444634854794,
mse,0.12734422087669373,0.016658108681440353,0.007047521416097879,0.004209414124488831,0.0032527365256100893,0.0027273413725197315,0.0023680543527007103,0.002072391100227833,0.0017652017995715141,0.0015565567882731557,0.0014079975662752986,0.0014600424328818917,0.002583094174042344,0.0010239187395200133,0.0009274972253479064,0.0016746281180530787,0.0010855497093871236,0.0008061453700065613,0.0008594191749580204,0.0009295849013142288,0.0006905535701662302,0.0017841483931988478,0.001520977821201086,0.0012113681295886636,0.0009136762237176299,0.0006373294163495302,0.00042398765799589455,0.000414892885601148,0.0006949080270715058,0.0008213513065129519,0.000758298730943352,0.0006141804624348879,0.0004466520913410932,0.0005694085848517716,0.000605157925747335,0.0005861104000359774,0.00051723892102018,0.00041464532841928303,0.0003159746411256492,0.0002568444760981947,0.00021856815146747977,0.000295048434054479,0.0004884453373961151,0.0005066869198344648,0.0003009699285030365,0.0003610394196584821,0.0004478569608181715,0.00037036032881587744,0.0003342956770211458,0.0002795714244712144,0.00034212361788377166,0.00031076138839125633,0.00031969789415597916,0.00034121520002372563,0.00023355692974291742,0.00021201958588790148,0.00020039468654431403,0.00028720597038045526,0.00021617203310597688,0.00025673958589322865,0.0003425260365474969,0.00025796398404054344,0.00027400918770581484,0.00023286511714104563,0.00024242671497631818,0.00028599868528544903,0.00023314538702834398,0.00018413164070807397,0.00015517897554673254,0.00014604919124394655,0.00022567460837308317,0.0003011584049090743,0.00024661229690536857,0.00018894317327067256,0.00016503941151313484,0.0001469368871767074,0.00014196876145433635,0.00021556504361797124,0.0002630880626384169,0.00020179632701911032,0.0002385215339018032,0.0001915872999234125,0.00015358194650616497,0.00015210190031211823,0.00017925472639035434,0.00013931645662523806,0.00012633210280910134,0.00019851265824399889,0.00022718793479725718,0.00016851337568368763,0.00019239619723521173,0.0002004910638788715,0.00016935057647060603,0.00017590107745490968,0.00014500408724416047,0.00012320534733589739,0.0001010753694572486,7.610386819578707e-05,6.493744876934215e-05,6.170722917886451e-05,
mae,0.238860085606575,0.09706892818212509,0.06437516957521439,0.04964625462889671,0.04357876256108284,0.039888687431812286,0.03730416297912598,0.03493298217654228,0.03209943324327469,0.03008781000971794,0.028645122423768044,0.02932535856962204,0.039176907390356064,0.02419946901500225,0.023042595013976097,0.03150087967514992,0.02593299001455307,0.022034620866179466,0.022512484341859818,0.024165397509932518,0.020658964291214943,0.033461347222328186,0.030558200553059578,0.027129800990223885,0.02352713793516159,0.019971748813986778,0.016212815418839455,0.016118191182613373,0.020370369777083397,0.022811129689216614,0.021991951391100883,0.019163498654961586,0.01640762761235237,0.018820755183696747,0.019244864583015442,0.019301094114780426,0.018109064549207687,0.01620311662554741,0.014461816288530827,0.012843248434364796,0.011761966161429882,0.01326271053403616,0.01749895140528679,0.01781538873910904,0.013877407647669315,0.015270374715328217,0.016884947195649147,0.015193348750472069,0.014550910331308842,0.01332741416990757,0.015010653994977474,0.014233368448913097,0.014453542418777943,0.014741010963916779,0.012266827747225761,0.01174144260585308,0.01153597328811884,0.01365299429744482,0.011926988139748573,0.012843829579651356,0.014917885884642601,0.012740795500576496,0.013364548794925213,0.012168553657829762,0.012534859590232372,0.013705586083233356,0.01240490097552538,0.011474850587546825,0.010237479582428932,0.00965902116149664,0.011930367909371853,0.01412956602871418,0.012849736958742142,0.011021149344742298,0.010394246317446232,0.009701107628643513,0.009423306211829185,0.01174190267920494,0.013158407062292099,0.011393286287784576,0.012272797524929047,0.01101907528936863,0.009658285416662693,0.00977143831551075,0.010731091722846031,0.009527068585157394,0.008968714624643326,0.01103084348142147,0.012178579345345497,0.010793576017022133,0.011167209595441818,0.011306418105959892,0.010263681411743164,0.010603377595543861,0.009665864519774914,0.008943714201450348,0.007678132504224777,0.0065835630521178246,0.006350539159029722,0.006303266156464815,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 74603     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 74604     
=================================================================
Total params: 149,207
Trainable params: 149,207
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 74,603
Trainable params: 74,603
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 74,604
Trainable params: 74,604
Non-trainable params: 0
_________________________________________________________________
