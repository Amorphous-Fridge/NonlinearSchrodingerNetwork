2021-06-26
loss,3.9140872955322266,3.4725759029388428,3.138266086578369,3.1295480728149414,2.517650842666626,0.989468514919281,0.35379138588905334,0.31838884949684143,0.22552013397216797,0.16788433492183685,0.16277188062667847,0.1347636580467224,0.13735082745552063,0.139031782746315,0.12574566900730133,0.10784516483545303,0.07961788773536682,0.09605882316827774,0.07186312973499298,0.06965898722410202,0.08260639011859894,0.07841640710830688,0.1045537069439888,0.07441374659538269,0.07058624923229218,0.06523974239826202,0.06440210342407227,0.08397941291332245,0.08694680035114288,0.05893167480826378,0.04822586104273796,0.06290412694215775,0.06338971108198166,0.07722582668066025,0.05909045785665512,0.05781785026192665,0.05686359852552414,0.058239106088876724,0.068999744951725,0.06370396912097931,0.06015707552433014,0.0613943487405777,0.056246981024742126,0.04821423441171646,0.04446948692202568,0.04480009526014328,0.046044837683439255,0.04962858557701111,0.046273183077573776,0.04402691498398781,0.05720210075378418,0.046662572771310806,0.052549973130226135,0.056469324976205826,0.044878751039505005,0.05453852564096451,0.04882894456386566,0.042730558663606644,0.036335576325654984,0.04770394414663315,0.05012685805559158,0.04939515143632889,0.04057875648140907,0.036653801798820496,0.03938470780849457,0.0372493751347065,0.039574481546878815,0.03535842522978783,0.05075480788946152,0.049461446702480316,0.04406958073377609,0.03593187406659126,0.03420841693878174,0.04041910171508789,0.04646661877632141,0.03781910985708237,0.03767501935362816,0.044599391520023346,0.03845416009426117,0.03556337580084801,0.031911034137010574,0.03710106760263443,0.03947604075074196,0.03535144776105881,0.03540030121803284,0.03649246692657471,0.031174130737781525,0.035657815635204315,0.03275640308856964,0.03891292214393616,0.04048748314380646,0.032203707844018936,0.040843792259693146,0.040160346776247025,0.034962233155965805,0.033146172761917114,0.0321342796087265,0.03941307216882706,0.0287834070622921,0.03117789328098297,
mse,3.9123668670654297,3.045006036758423,2.4714744091033936,2.4580559730529785,1.6344354152679443,0.37882840633392334,0.03724071383476257,0.030681896954774857,0.015866383910179138,0.008116423152387142,0.007739103864878416,0.005175292491912842,0.0053406935185194016,0.005690918769687414,0.004537222441285849,0.0033810713794082403,0.0017965591978281736,0.002735680667683482,0.0014824547106400132,0.0013859343016520143,0.001947443000972271,0.0017612794181331992,0.0030856099911034107,0.0015612650895491242,0.0013871638802811503,0.001346611650660634,0.0011916853254660964,0.0020422101952135563,0.002111574402078986,0.0010661620181053877,0.0006660587969236076,0.001129009062424302,0.0011178429704159498,0.001739257713779807,0.0009661958902142942,0.0009122528717853129,0.0009268054855056107,0.0009760534740053117,0.0013161762617528439,0.0011015399359166622,0.0009914496913552284,0.0010283314622938633,0.0008708440000191331,0.0006363983266055584,0.0005583833553828299,0.0005664415075443685,0.0005941512645222247,0.000705486920196563,0.0005906270234845579,0.000538968772161752,0.0009352505439892411,0.0006027179770171642,0.0008135732496157289,0.000915719021577388,0.000569131167139858,0.0008230771636590362,0.0006674277829006314,0.0005069358740001917,0.0003692027530632913,0.0006372726056724787,0.0007077343761920929,0.0006737267249263823,0.00045263697393238544,0.0003774985671043396,0.0004289877542760223,0.0003891606174875051,0.00042115963879041374,0.0003458874416537583,0.0007214639335870743,0.0006783956778235734,0.0005301969358697534,0.0003543727216310799,0.0003360754926688969,0.00046033819671720266,0.0005806188564747572,0.0004005157097708434,0.0003972537524532527,0.0005447463481687009,0.00041142001282423735,0.00035558477975428104,0.0002884648274630308,0.0003916127316188067,0.00043465857743285596,0.00034707653685472906,0.00035344972275197506,0.0003562076308298856,0.0002647851360961795,0.0003614370943978429,0.0002966164902318269,0.000435138150351122,0.0004617858212441206,0.0002924290602095425,0.0004629748291336,0.0004402951162774116,0.0003452990495134145,0.0003076776920352131,0.00028997482149861753,0.0004320549196563661,0.0002346023975405842,0.00027325667906552553,
mae,1.7848893404006958,1.491675853729248,1.186387300491333,1.1539980173110962,0.8574066758155823,0.4030013680458069,0.15235571563243866,0.1351664960384369,0.09441788494586945,0.07107551395893097,0.06779131293296814,0.057419303804636,0.05835782364010811,0.05975781008601189,0.05388479307293892,0.04608110338449478,0.033635661005973816,0.04051096737384796,0.030477002263069153,0.03012280911207199,0.035762887448072433,0.03455192223191261,0.0449332669377327,0.03147340565919876,0.02966517023742199,0.027549488469958305,0.027253160253167152,0.03615174815058708,0.03674602136015892,0.02535846270620823,0.020365633070468903,0.02647199109196663,0.028020061552524567,0.03268563374876976,0.025240112096071243,0.026539983227849007,0.023772258311510086,0.02493000030517578,0.02946563810110092,0.027490733191370964,0.025422217324376106,0.026551423594355583,0.023926110938191414,0.020177260041236877,0.018619075417518616,0.01912115514278412,0.019444437697529793,0.021206606179475784,0.020101506263017654,0.019199365749955177,0.024390149861574173,0.020208990201354027,0.022515611723065376,0.024057039991021156,0.019141297787427902,0.023493757471442223,0.020716357976198196,0.01799609698355198,0.015175944194197655,0.020131273195147514,0.02101997844874859,0.021293921396136284,0.016815638169646263,0.01574656181037426,0.01688498631119728,0.016283322125673294,0.01726624369621277,0.015200048685073853,0.021661605685949326,0.021816974505782127,0.01892232336103916,0.015599768608808517,0.01452910527586937,0.017137618735432625,0.020314432680606842,0.015705207362771034,0.01601179502904415,0.01940920017659664,0.016358109191060066,0.014983611181378365,0.013271903619170189,0.01585215888917446,0.01697581447660923,0.014796319417655468,0.015076820738613605,0.01632356457412243,0.013433342799544334,0.015010479837656021,0.013783157803118229,0.016293765977025032,0.017335643991827965,0.013783451169729233,0.017550623044371605,0.017149919643998146,0.014739375561475754,0.013970675878226757,0.013697118498384953,0.016837291419506073,0.012060868553817272,0.012997740879654884,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 368099    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 368100    
=================================================================
Total params: 736,199
Trainable params: 736,199
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 368,099
Trainable params: 368,099
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 368,100
Trainable params: 368,100
Non-trainable params: 0
_________________________________________________________________
