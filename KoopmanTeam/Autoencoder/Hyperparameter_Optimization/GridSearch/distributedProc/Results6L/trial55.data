2021-06-26
loss,0.9668936133384705,0.2879653871059418,0.304632306098938,0.20287078619003296,0.21769161522388458,0.17357821762561798,0.10795775055885315,0.11998806148767471,0.13654933869838715,0.11728517711162567,0.09155361354351044,0.08799418807029724,0.09545741975307465,0.08731283992528915,0.06387946009635925,0.08679141104221344,0.0759897381067276,0.0683283880352974,0.05822419002652168,0.05441106855869293,0.06678225845098495,0.08013150840997696,0.07430288195610046,0.0426306389272213,0.044044941663742065,0.05297233536839485,0.0586092434823513,0.06044389680027962,0.06645733118057251,0.0401248075067997,0.042450256645679474,0.06101837009191513,0.0535762794315815,0.048585131764411926,0.04929014667868614,0.04306497424840927,0.04790234565734863,0.04279536381363869,0.06436703354120255,0.06131618469953537,0.05125623568892479,0.04613183066248894,0.03642098978161812,0.03387216106057167,0.04639943689107895,0.04083244875073433,0.049365218728780746,0.03535383194684982,0.03532317653298378,0.047242335975170135,0.04982390254735947,0.038565851747989655,0.04032660648226738,0.04513804614543915,0.0505807064473629,0.04508122056722641,0.043178342282772064,0.04313557967543602,0.04274590313434601,0.03571874275803566,0.04191893711686134,0.03486977145075798,0.031205447390675545,0.034295596182346344,0.03427891060709953,0.03670866787433624,0.029509423300623894,0.04203244298696518,0.04410487785935402,0.04346553981304169,0.04016542434692383,0.03659723326563835,0.03218206763267517,0.034397006034851074,0.03848757594823837,0.034862253814935684,0.03757967799901962,0.036734439432621,0.03299615532159805,0.03198186680674553,0.032879479229450226,0.04154796153306961,0.04014143347740173,0.03396261855959892,0.0323718897998333,0.028029603883624077,0.03279940411448479,0.027812015265226364,0.02508566528558731,0.03177040442824364,0.0398266427218914,0.035236045718193054,0.029377110302448273,0.03175545856356621,0.03513270244002342,0.03332167863845825,0.032558873295784,0.024610714986920357,0.03029068000614643,0.02907969057559967,
mse,0.4656004309654236,0.025518961250782013,0.028091244399547577,0.01177043654024601,0.013796689920127392,0.008262017741799355,0.0031636999920010567,0.004166576080024242,0.0052109467796981335,0.0038442895747721195,0.002290896838530898,0.0023198332637548447,0.0026309627573937178,0.002238222863525152,0.0011140556307509542,0.002120628021657467,0.001578229945152998,0.0012661278015002608,0.0009334515780210495,0.0008339647320099175,0.0013317720731720328,0.0017298220191150904,0.0015331266913563013,0.0005116735701449215,0.0005489765317179263,0.0007797674625180662,0.0009303372353315353,0.0010551977902650833,0.001253889175131917,0.0004473444714676589,0.0005129387136548758,0.0010454595321789384,0.0007776589482091367,0.0006492353859357536,0.00069067144067958,0.0005161752342246473,0.0006454811082221568,0.0005532855866476893,0.0011687851510941982,0.001029735547490418,0.0007383352494798601,0.0006166661623865366,0.00036208078381605446,0.00032124153221957386,0.0006082721520215273,0.0004630789626389742,0.0006983734201639891,0.00034403830068185925,0.00034844473702833056,0.0006346164736896753,0.0007011433481238782,0.00040935236029326916,0.00045813489123247564,0.000587912043556571,0.000720599084161222,0.0005753511213697493,0.0005149546195752919,0.0005096759414300323,0.0005136250983923674,0.0003553183050826192,0.0004952513263560832,0.00034779193811118603,0.0002885580179281533,0.00034286332083866,0.0003312955377623439,0.00037359725683927536,0.0002478241513017565,0.0005101506249047816,0.0005364107200875878,0.000518045446369797,0.00045862566912546754,0.0003782729327213019,0.00029538103262893856,0.0003322961856611073,0.00041717023123055696,0.0003403240698389709,0.0003882427408825606,0.00038287907955236733,0.00030310655711218715,0.0002863620175048709,0.00030088447965681553,0.0004770568339154124,0.00044271856313571334,0.0003182782675139606,0.000281952612567693,0.00022217311197891831,0.0002942991559393704,0.00021665038366336375,0.0001756688579916954,0.000290328316623345,0.000434702931670472,0.00034258858067914844,0.00024100573500618339,0.0002839636872522533,0.00034785972093231976,0.00031794270034879446,0.0002949376648757607,0.0001737256534397602,0.0002564938913565129,0.00023657790734432638,
mae,0.38449588418006897,0.12090454250574112,0.13189536333084106,0.08617284893989563,0.09278181940317154,0.07580038160085678,0.04571728780865669,0.05183172598481178,0.05803242325782776,0.050379399210214615,0.03810836002230644,0.03671641647815704,0.04087168723344803,0.036742471158504486,0.027610860764980316,0.03754860535264015,0.03376706689596176,0.0314941368997097,0.02471107430756092,0.022868257015943527,0.027867024764418602,0.033849216997623444,0.031564582139253616,0.018030816689133644,0.018800759688019753,0.02262473851442337,0.024583645164966583,0.02533908374607563,0.028522677719593048,0.017059914767742157,0.018002545461058617,0.02560252696275711,0.02311641164124012,0.020276587456464767,0.020658910274505615,0.018315134570002556,0.020207829773426056,0.018351132050156593,0.02787875570356846,0.026165921241044998,0.02218472771346569,0.019183611497282982,0.015622086822986603,0.01441975124180317,0.01947053149342537,0.017225107178092003,0.02040114812552929,0.015091635286808014,0.014850441366434097,0.02013966254889965,0.02158842235803604,0.01649257354438305,0.017073046416044235,0.019517626613378525,0.021760912612080574,0.01923130825161934,0.018633782863616943,0.018303053453564644,0.018526697531342506,0.015197433531284332,0.018015265464782715,0.014613529667258263,0.01299255806952715,0.014265235513448715,0.014130362309515476,0.015696587041020393,0.01239483617246151,0.017813879996538162,0.01903747022151947,0.01837434619665146,0.017248930409550667,0.015815554186701775,0.013623607344925404,0.014582851901650429,0.016078580170869827,0.014959948137402534,0.015834879130125046,0.01548732165247202,0.0140761099755764,0.013776124455034733,0.013822585344314575,0.017877090722322464,0.017185112461447716,0.01408371888101101,0.014090430922806263,0.011748982593417168,0.014156337827444077,0.011941861361265182,0.010641580447554588,0.013477956876158714,0.016833985224366188,0.01472529862076044,0.012728857807815075,0.01371662225574255,0.01497799064964056,0.014118283055722713,0.013744138181209564,0.010382863692939281,0.013105384074151516,0.012343629263341427,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 138211    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 138212    
=================================================================
Total params: 276,423
Trainable params: 276,423
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 138,211
Trainable params: 138,211
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 138,212
Trainable params: 138,212
Non-trainable params: 0
_________________________________________________________________
