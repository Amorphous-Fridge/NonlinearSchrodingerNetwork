2021-06-26
loss,0.5696981549263,0.24884290993213654,0.2275451272726059,0.20719203352928162,0.1523204743862152,0.09877721965312958,0.08502424508333206,0.09324301779270172,0.05979515612125397,0.06403245776891708,0.059684038162231445,0.07361961901187897,0.0688856765627861,0.042821940034627914,0.04785926267504692,0.047885388135910034,0.04701721668243408,0.06450468301773071,0.05871778354048729,0.052231572568416595,0.04713106155395508,0.04166598618030548,0.04619671031832695,0.039960380643606186,0.03934292495250702,0.029324445873498917,0.027514386922121048,0.03483131155371666,0.042208682745695114,0.04866494610905647,0.039016906172037125,0.032413549721241,0.03633211925625801,0.03932696208357811,0.03811119869351387,0.03328382223844528,0.03531655669212341,0.03740041330456734,0.032705266028642654,0.039492737501859665,0.040650248527526855,0.025813406333327293,0.020140409469604492,0.021050063893198967,0.023567449301481247,0.029572267085313797,0.03252677619457245,0.032121725380420685,0.024215053766965866,0.024236435070633888,0.03063809871673584,0.030888758599758148,0.0357990562915802,0.03178925812244415,0.028257358819246292,0.030388858169317245,0.031179027631878853,0.02857179380953312,0.03230121731758118,0.029409468173980713,0.027043547481298447,0.026217786595225334,0.030609162524342537,0.031624745577573776,0.03399541974067688,0.030226653441786766,0.02485785074532032,0.020936181768774986,0.017535431310534477,0.027658767998218536,0.02852461487054825,0.02967544086277485,0.024789318442344666,0.02724718302488327,0.028517277911305428,0.02595713548362255,0.024429624900221825,0.027480464428663254,0.02780645526945591,0.023715129122138023,0.0271187424659729,0.022599203512072563,0.021828370168805122,0.021361220628023148,0.024080555886030197,0.021296055987477303,0.023645693436264992,0.028710486367344856,0.026412608101963997,0.0254703089594841,0.027454622089862823,0.026379123330116272,0.023278992623090744,0.02038736268877983,0.01916593126952648,0.01978890784084797,0.021498296409845352,0.024122100323438644,0.02177845872938633,0.017312515527009964,
mse,0.1594957709312439,0.02039305679500103,0.017981862649321556,0.01514847669750452,0.007244125474244356,0.002912377007305622,0.0021772717591375113,0.0026434147730469704,0.0010642926208674908,0.001227193628437817,0.0010401406325399876,0.0016310791252180934,0.0014116914244368672,0.0005401836824603379,0.0006730938912369311,0.0006821088027209044,0.0006817414541728795,0.0011830873554572463,0.0009557054145261645,0.0008014742052182555,0.0006493111723102629,0.0005091881612315774,0.0006173567962832749,0.0004722062440123409,0.00045353511814028025,0.0002507376775611192,0.00022211343457456678,0.000371164467651397,0.0004995535709895194,0.0006547734374180436,0.00044858711771667004,0.0003176879254169762,0.0003877884882967919,0.00045446102740243077,0.0004062666848767549,0.0003299106319900602,0.00035647378535941243,0.0003916471905540675,0.0003119913162663579,0.00044626957969740033,0.00045244127977639437,0.00020695952116511762,0.0001170875912066549,0.00013677860260941088,0.00017387332627549767,0.00026458525098860264,0.00030058706761337817,0.00030223908834159374,0.0001802954648155719,0.00017771721468307078,0.000277265120530501,0.000288466369966045,0.00035977046354673803,0.0002918241370934993,0.00023584107111673802,0.00026617926778271794,0.00027597020380198956,0.00023790968407411128,0.0002963695442304015,0.00024134453269653022,0.00020629219943657517,0.0002002344699576497,0.00026883999817073345,0.00028697861125692725,0.0003213493910152465,0.0002525802992749959,0.00018076632113661617,0.0001334341213805601,9.185117960441858e-05,0.0002283358626300469,0.0002311725402250886,0.0002472178894095123,0.00018148381786886603,0.00021445607126224786,0.0002323498047189787,0.00018931081285700202,0.00016957656771410257,0.00022183913097251207,0.00022600984084419906,0.00016224745195358992,0.00021131256653461605,0.0001473591837566346,0.00014061019464861602,0.00013673795911017805,0.00016767815395724028,0.0001363430346827954,0.00015919667202979326,0.00023258180590346456,0.00019938702462241054,0.00018630635167937726,0.00021291041048243642,0.00019330286886543036,0.00015352423361036927,0.00012179640907561406,0.00011015569907613099,0.00011627435014816001,0.00013681335258297622,0.00016580145165789872,0.00013601592218037695,8.912583871278912e-05,
mae,0.2425403594970703,0.10539184510707855,0.09618585556745529,0.08785289525985718,0.0647699236869812,0.0417322963476181,0.035804010927677155,0.038908228278160095,0.02516758441925049,0.027405736967921257,0.025203842669725418,0.03066001459956169,0.028611155226826668,0.018111949786543846,0.020010199397802353,0.020484985783696175,0.02005535550415516,0.02735489420592785,0.024922147393226624,0.022855807095766068,0.020344825461506844,0.01768968254327774,0.01970708929002285,0.016805825755000114,0.01671731285750866,0.012335054576396942,0.011646424420177937,0.014731346629559994,0.01798473298549652,0.02042657881975174,0.01584589295089245,0.013788163661956787,0.015454454347491264,0.016731753945350647,0.01626748964190483,0.014032368548214436,0.015000318177044392,0.01608780212700367,0.013948431238532066,0.016507228836417198,0.017235983163118362,0.010960346087813377,0.008562278933823109,0.008896272629499435,0.009977784007787704,0.012601055204868317,0.013835500925779343,0.013781432993710041,0.010294734500348568,0.01032128557562828,0.013074907474219799,0.01326579786837101,0.015142171643674374,0.013211878947913647,0.01189139112830162,0.012728530913591385,0.013404752127826214,0.01225077360868454,0.013845430687069893,0.012756336480379105,0.011522455140948296,0.011097266338765621,0.012826324440538883,0.013309752568602562,0.014684357680380344,0.012365826405584812,0.010286306962370872,0.008834981359541416,0.007415830623358488,0.011838549748063087,0.011876587755978107,0.012787134386599064,0.01056244969367981,0.011556400917470455,0.011964626610279083,0.011200254783034325,0.010595524683594704,0.011722386814653873,0.01196858286857605,0.010102330707013607,0.011250141076743603,0.009491922333836555,0.009174603037536144,0.008996318094432354,0.010254885070025921,0.008863014169037342,0.009869923815131187,0.012190263718366623,0.011407298967242241,0.010624945163726807,0.011551103554666042,0.011291624046862125,0.009962589479982853,0.008808368816971779,0.008100259117782116,0.008341728709638119,0.009070678614079952,0.010436242446303368,0.009336479939520359,0.0073167611844837666,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 78843     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 78844     
=================================================================
Total params: 157,687
Trainable params: 157,687
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 78,843
Trainable params: 78,843
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 78,844
Trainable params: 78,844
Non-trainable params: 0
_________________________________________________________________
