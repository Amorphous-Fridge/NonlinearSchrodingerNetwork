2021-06-26
loss,0.4214536249637604,0.23780840635299683,0.1898646205663681,0.11670064181089401,0.11013368517160416,0.06990782916545868,0.05728757381439209,0.053548213094472885,0.04949069395661354,0.04648676514625549,0.045885294675827026,0.04234074056148529,0.041325826197862625,0.04012690484523773,0.03890787065029144,0.03801342844963074,0.03874925523996353,0.035375021398067474,0.05390458181500435,0.05076251178979874,0.05707284435629845,0.05688561499118805,0.04444350674748421,0.03740859776735306,0.031890250742435455,0.03044849820435047,0.02995711751282215,0.03008611872792244,0.029023833572864532,0.02860352024435997,0.028323667123913765,0.028374282643198967,0.04292869567871094,0.052020736038684845,0.0352000817656517,0.033614858984947205,0.03203737363219261,0.030822739005088806,0.030299117788672447,0.029423153027892113,0.02942134626209736,0.028519360348582268,0.028593232855200768,0.04071078449487686,0.04495687037706375,0.025702986866235733,0.034919194877147675,0.0401129387319088,0.025896243751049042,0.03822748363018036,0.03680339828133583,0.03144633397459984,0.029151437804102898,0.027881570160388947,0.037356071174144745,0.04052206873893738,0.03707753121852875,0.035030871629714966,0.033042632043361664,0.030716322362422943,0.03957870975136757,0.04551790654659271,0.04218321666121483,0.03617281839251518,0.03215644508600235,0.03689669817686081,0.037053752690553665,0.03348679840564728,0.037952955812215805,0.033875420689582825,0.030072396621108055,0.02733078971505165,0.027329912409186363,0.03218816593289375,0.029995057731866837,0.028573350980877876,0.02723420411348343,0.02633664757013321,0.025684552267193794,0.025073731318116188,0.024554934352636337,0.0243937186896801,0.02380547486245632,0.023407747969031334,0.021987304091453552,0.02274690940976143,0.022680122405290604,0.023118771612644196,0.024761827662587166,0.021282684057950974,0.031364258378744125,0.031943436712026596,0.02907595783472061,0.030540119856595993,0.027569010853767395,0.025286927819252014,0.02403009682893753,0.02295171655714512,0.022192157804965973,0.03585544973611832,
mse,0.06759696453809738,0.019315999001264572,0.012383819557726383,0.004489918239414692,0.0037476716097444296,0.0015571225667372346,0.0010151208844035864,0.0008721238118596375,0.000736272195354104,0.000654372968710959,0.0006168484687805176,0.0005417498759925365,0.0004993014154024422,0.0004690151254180819,0.0004367681685835123,0.0004176981747150421,0.0004326542839407921,0.00036606835783459246,0.0010605721035972238,0.0007817723671905696,0.0009927937062457204,0.0009587323875166476,0.0005842188838869333,0.00041956338100135326,0.00029593982617370784,0.00026688759680837393,0.000257224339293316,0.0002581634616944939,0.0002400948287686333,0.00023186329053714871,0.00022926526435185224,0.0002309370756847784,0.0005617417627945542,0.0008601126028224826,0.0003564266371540725,0.00031943630892783403,0.00029130640905350447,0.00027188193053007126,0.00027003130526281893,0.00024419493274763227,0.0002469655591994524,0.0002308759285369888,0.00024248901172541082,0.0005249280948191881,0.0005984404706396163,0.00019346384215168655,0.0003881565935444087,0.0004589236923493445,0.00019969750428572297,0.0004521820228546858,0.00039171811658889055,0.0002753783483058214,0.00023921446700114757,0.0002209466474596411,0.0004179569077678025,0.000462047231849283,0.0003821989521384239,0.0003409076016396284,0.0003034474793821573,0.0002629972586873919,0.00048003572737798095,0.0006176319438964128,0.0005065852892585099,0.0003755937796086073,0.00029726841603405774,0.00039658285095356405,0.00040163894300349057,0.0003272606118116528,0.0004035412857774645,0.00032936930074356496,0.0002583382010925561,0.00021547405049204826,0.00021949858637526631,0.00029015724430792034,0.0002497962268535048,0.00022754559176973999,0.00020790328562725335,0.0001969490695046261,0.0001850583648774773,0.00017618386482354254,0.00017095656949095428,0.00016941620560828596,0.0001623326970729977,0.00015804459690116346,0.00014401509542949498,0.00015214167069643736,0.0001464855158701539,0.00015580626495648175,0.00018160216859541833,0.00013156174100004137,0.00031825798214413226,0.00028163930983282626,0.00024156000290531665,0.0002585168113000691,0.00021127804939169437,0.00017935801588464528,0.00016244595462922007,0.00014977877435740083,0.00014465775166172534,0.0003818024415522814,
mae,0.18103940784931183,0.1011444479227066,0.08474931865930557,0.04977021366357803,0.04647883027791977,0.029637064784765244,0.0243929885327816,0.02288155071437359,0.02086271345615387,0.019528500735759735,0.019387919455766678,0.01784536987543106,0.01745939627289772,0.016903672367334366,0.01641506515443325,0.016039786860346794,0.016434598714113235,0.01488772127777338,0.021994877606630325,0.020992711186408997,0.02390260249376297,0.024022269994020462,0.018612705171108246,0.015928393229842186,0.013871945440769196,0.013136377558112144,0.012965835630893707,0.012866158038377762,0.012324539013206959,0.012174065224826336,0.012017231434583664,0.01213260367512703,0.018307069316506386,0.022106068208813667,0.015099556185305119,0.014514023438096046,0.013864482752978802,0.013104133307933807,0.01299072615802288,0.012588150799274445,0.012635014951229095,0.012277067638933659,0.012246404774487019,0.017611728981137276,0.01948077790439129,0.010905413888394833,0.014738433063030243,0.01664961874485016,0.011031328700482845,0.016455577686429024,0.015727143734693527,0.013778025284409523,0.012745563872158527,0.012110126204788685,0.01592012122273445,0.018115485087037086,0.016566725447773933,0.01559428684413433,0.014151436276733875,0.01208027359098196,0.01715933345258236,0.019816137850284576,0.018332870677113533,0.015262681059539318,0.013628434389829636,0.015887636691331863,0.015730440616607666,0.01440760213881731,0.016551196575164795,0.014210352674126625,0.012743535451591015,0.011972205713391304,0.011627801693975925,0.013951833359897137,0.012962200678884983,0.012029695324599743,0.011198176071047783,0.010898423381149769,0.010330375283956528,0.010177552700042725,0.010296005755662918,0.010284011252224445,0.010294492356479168,0.009972208179533482,0.009198019281029701,0.009557905606925488,0.009381460957229137,0.009647518396377563,0.010466359555721283,0.008980456739664078,0.013781334273517132,0.013517295941710472,0.012278977781534195,0.012759613804519176,0.01165833231061697,0.01119101420044899,0.010500157251954079,0.009859218262135983,0.009530631825327873,0.015336130745708942,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 7803      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 7804      
=================================================================
Total params: 15,607
Trainable params: 15,607
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 7,803
Trainable params: 7,803
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 7,804
Trainable params: 7,804
Non-trainable params: 0
_________________________________________________________________
