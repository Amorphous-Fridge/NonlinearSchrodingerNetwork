2021-06-26
loss,2.9250307083129883,1.8044941425323486,0.6126497387886047,0.3574657142162323,0.28731879591941833,0.2804776430130005,0.24255232512950897,0.23273758590221405,0.2269628494977951,0.2194974720478058,0.21307043731212616,0.20994062721729279,0.20419429242610931,0.20102202892303467,0.19659417867660522,0.19011525809764862,0.17800064384937286,0.16404928267002106,0.10739091783761978,0.10390834510326385,0.09505479782819748,0.0825556293129921,0.08552490919828415,0.08288459479808807,0.07002853602170944,0.059416379779577255,0.0721750557422638,0.06849279999732971,0.05881250277161598,0.06008502095937729,0.063710056245327,0.06704814732074738,0.06302695721387863,0.05605591461062431,0.04978761821985245,0.04743940383195877,0.052147574722766876,0.05459427833557129,0.03624995797872543,0.05292760208249092,0.04163341596722603,0.05114300549030304,0.04344485327601433,0.04488295689225197,0.041644465178251266,0.04288711026310921,0.02788129821419716,0.03196147084236145,0.03569011390209198,0.04758845642209053,0.04568524286150932,0.04537374526262283,0.04036278277635574,0.03356889635324478,0.03481303155422211,0.03223451226949692,0.0388471819460392,0.03960242122411728,0.04115772619843483,0.03838846832513809,0.032064735889434814,0.032632071524858475,0.03790825232863426,0.03897872939705849,0.03503116965293884,0.03709844872355461,0.03599267452955246,0.030357273295521736,0.03182882443070412,0.03322852402925491,0.03634795919060707,0.03203383460640907,0.03525936231017113,0.03226226940751076,0.03112480789422989,0.035197895020246506,0.03263983130455017,0.02679670788347721,0.02614070102572441,0.0360356867313385,0.031554363667964935,0.03031986951828003,0.028605539351701736,0.03603733703494072,0.030178552493453026,0.03161223232746124,0.03430098667740822,0.032297778874635696,0.02813439629971981,0.022913236171007156,0.027445826679468155,0.03244290500879288,0.03073619306087494,0.0331466905772686,0.03172056004405022,0.03186780586838722,0.029225895181298256,0.02741721086204052,0.029290491715073586,0.02729000896215439,
mse,2.2901813983917236,0.8532629609107971,0.11957717686891556,0.03809422254562378,0.025312814861536026,0.02410927787423134,0.018748922273516655,0.01741107553243637,0.01671438291668892,0.015890736132860184,0.015156540088355541,0.014763304963707924,0.0141553720459342,0.013745324686169624,0.01324551086872816,0.012546263635158539,0.010885088704526424,0.008300203830003738,0.003731012111529708,0.003495005425065756,0.0029567512683570385,0.00210706633515656,0.002274681581184268,0.002138510812073946,0.0015781332040205598,0.0011433976469561458,0.0015992064727470279,0.0015883580781519413,0.0010917469626292586,0.0011470511090010405,0.0012644147500395775,0.0013597053475677967,0.0012126731453463435,0.0009646019316278398,0.0007728107739239931,0.0006715476047247648,0.000837557774502784,0.0009092328837141395,0.0004211539344396442,0.0008768622647039592,0.0005731137935072184,0.0007971477461978793,0.0005803590756841004,0.0006195316673256457,0.0005242959596216679,0.0005547504988498986,0.00025533774169161916,0.0003214708704035729,0.0003932717372663319,0.0006550257094204426,0.0006165825179778039,0.0006103191990405321,0.0004935687175020576,0.00034551267162896693,0.0003674959298223257,0.0003230201837141067,0.00048784620594233274,0.0004681538848672062,0.0005042215343564749,0.00044532876927405596,0.0003167558752465993,0.0003190410789102316,0.0004292984667699784,0.0004505379474721849,0.00037565655657090247,0.0004022985231131315,0.0004093150782864541,0.0002810693404171616,0.0003146013477817178,0.0003369353071320802,0.00039718285552226007,0.0003301669785287231,0.0003723051049746573,0.0003178142651449889,0.0002883456472773105,0.00036668378743343055,0.0003184952074661851,0.00022985607211012393,0.0002122073929058388,0.00038790874532423913,0.00030313103343360126,0.00027758872602134943,0.0002501721028238535,0.0003774707147385925,0.0002743730437941849,0.00029720738530158997,0.00035962945548817515,0.0003037874703295529,0.0002443355624563992,0.00016414285346399993,0.00022385446936823428,0.00030832868651486933,0.0002871254982892424,0.00032474182080477476,0.0002961574064102024,0.00030294861062429845,0.0002520847483538091,0.0002187897334806621,0.00026374959270469844,0.00022036427981220186,
mae,1.317312479019165,0.7301999926567078,0.2618648111820221,0.15328024327754974,0.12293506413698196,0.11930539458990097,0.10089530795812607,0.096132792532444,0.09331470727920532,0.08941813558340073,0.08691927790641785,0.08474234491586685,0.08312305808067322,0.08181212097406387,0.08001045137643814,0.07770362496376038,0.07451850175857544,0.06982951611280441,0.045645661652088165,0.0444784015417099,0.04081723093986511,0.03509848564863205,0.03622422739863396,0.034919846802949905,0.030041856691241264,0.025410857051610947,0.031137418001890182,0.029614238068461418,0.024878041818737984,0.025896914303302765,0.02709287591278553,0.028294632211327553,0.02636411041021347,0.02422141097486019,0.021555693820118904,0.020520208403468132,0.021924268454313278,0.023280588909983635,0.015301241539418697,0.022939369082450867,0.017831897363066673,0.02208520472049713,0.018705472350120544,0.01932721771299839,0.01764710806310177,0.018308408558368683,0.011877791956067085,0.013522543013095856,0.015141142532229424,0.02053373120725155,0.019489184021949768,0.01938202604651451,0.017425866797566414,0.014428063295781612,0.014869949780404568,0.01366264745593071,0.016603972762823105,0.016768384724855423,0.018155397847294807,0.016684353351593018,0.01378182414919138,0.014028018340468407,0.016182413324713707,0.016826540231704712,0.015073470771312714,0.015688041225075722,0.01530527975410223,0.013142899610102177,0.013226710259914398,0.014158525504171848,0.015686646103858948,0.0136676374822855,0.015177751891314983,0.013722983188927174,0.013270096853375435,0.01504727452993393,0.013826634734869003,0.01139947772026062,0.011186574585735798,0.015348311513662338,0.01342818234115839,0.013102620840072632,0.012370123527944088,0.0150462556630373,0.012816254049539566,0.01360997837036848,0.014696427620947361,0.013792040757834911,0.011977358721196651,0.009855711832642555,0.011752125807106495,0.013770079240202904,0.013173501938581467,0.014146218076348305,0.013619867153465748,0.013719205744564533,0.012466098181903362,0.011770644225180149,0.012615443207323551,0.011740629561245441,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 313259    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 313260    
=================================================================
Total params: 626,519
Trainable params: 626,519
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                16416     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 313,259
Trainable params: 313,259
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 313,260
Trainable params: 313,260
Non-trainable params: 0
_________________________________________________________________
