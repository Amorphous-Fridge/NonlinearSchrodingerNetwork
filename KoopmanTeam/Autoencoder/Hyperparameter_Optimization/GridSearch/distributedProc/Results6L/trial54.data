2021-06-26
loss,1.3090314865112305,0.3080461919307709,0.26473262906074524,0.22840765118598938,0.20252901315689087,0.1922873556613922,0.17963270843029022,0.155852809548378,0.19149726629257202,0.17567455768585205,0.14900872111320496,0.1172872856259346,0.14540404081344604,0.12977652251720428,0.10581404715776443,0.09610592573881149,0.08007819950580597,0.07893611490726471,0.09614858031272888,0.08204691112041473,0.06355402618646622,0.0694686770439148,0.0790315791964531,0.06513749808073044,0.06479369848966599,0.06514585018157959,0.06162609905004501,0.05187198519706726,0.05420413613319397,0.04746171832084656,0.04590323567390442,0.04617500677704811,0.05229878053069115,0.048604484647512436,0.06037566810846329,0.05271062254905701,0.043514203280210495,0.04680151119828224,0.050156060606241226,0.04239508509635925,0.03824814409017563,0.04571055993437767,0.046127647161483765,0.03722953051328659,0.0434206947684288,0.03298167139291763,0.03389277681708336,0.038351841270923615,0.03950101509690285,0.03912913426756859,0.034807395190000534,0.03410319611430168,0.03439721465110779,0.032289814203977585,0.03413953632116318,0.03313860297203064,0.039144162088632584,0.037609148770570755,0.029248537495732307,0.03026416338980198,0.02918284572660923,0.031380876898765564,0.03307411074638367,0.032532352954149246,0.029313359409570694,0.031995438039302826,0.034264177083969116,0.03227151930332184,0.02615303359925747,0.034604981541633606,0.03180151805281639,0.03421834483742714,0.030929772183299065,0.029832201078534126,0.0310625359416008,0.026961758732795715,0.02944783866405487,0.026572799310088158,0.02774115838110447,0.025958169251680374,0.030461842194199562,0.026660755276679993,0.02675783634185791,0.03244179114699364,0.03004169650375843,0.02440786361694336,0.026368293911218643,0.027883540838956833,0.024212324991822243,0.024076353758573532,0.027565225958824158,0.02899191342294216,0.029350150376558304,0.02690259739756584,0.02360914647579193,0.023592283949255943,0.0290667861700058,0.028363404795527458,0.030736496672034264,0.025060610845685005,
mse,0.7700256109237671,0.028029561042785645,0.021586842834949493,0.016808971762657166,0.013716034591197968,0.012391694821417332,0.010528317652642727,0.007400634698569775,0.011996796354651451,0.009132163599133492,0.006310654804110527,0.00401267921552062,0.006045373156666756,0.004690384957939386,0.003208711976185441,0.0025816739071160555,0.0018206737004220486,0.0018297209171578288,0.0025261936243623495,0.0019539333879947662,0.0011869898298755288,0.0013596446951851249,0.001713232253678143,0.001195416902191937,0.001181608298793435,0.0011756370076909661,0.0010814719134941697,0.0007573736365884542,0.0008212827378883958,0.0006413757218979299,0.0006113046547397971,0.0006151146371848881,0.0007617147057317197,0.0006631118012592196,0.0009995343862101436,0.0007538020727224648,0.0005400765221565962,0.0006137866294011474,0.000682100944686681,0.0004957247874699533,0.00040361768333241343,0.000590056530199945,0.00058844278100878,0.00039911441854201257,0.0005385788390412927,0.000314929784508422,0.0003261181409470737,0.0004087478155270219,0.00043298874516040087,0.00042290135752409697,0.00033797972719185054,0.00033396671642549336,0.00034392953966744244,0.0002973345690406859,0.00031934920116327703,0.00029900093795731664,0.0004195414949208498,0.00038906169356778264,0.0002447517472319305,0.0002566482580732554,0.00023818021873012185,0.0002792321902234107,0.000302885688142851,0.00029348605312407017,0.0002405908307991922,0.0002922668936662376,0.0003238685894757509,0.00028915487928315997,0.00020072731422260404,0.00033870377228595316,0.00028211381868459284,0.0003221696533728391,0.00026614160742610693,0.000253260659519583,0.00026451313169673085,0.00020344673248473555,0.0002504096191842109,0.00020208529895171523,0.00021010257478337735,0.0001868611725512892,0.00025699310936033726,0.00020021597447339445,0.00020627745834644884,0.00029239538707770407,0.0002485346340108663,0.0001699543063296005,0.0002014764177147299,0.0002128035412169993,0.00016779413272161037,0.0001710161886876449,0.00021641553030349314,0.00023237135610543191,0.0002380996011197567,0.0001987774739973247,0.00016081273497547954,0.00016356293053831905,0.00024566237698309124,0.00022393724066205323,0.00025927848764695227,0.00017778982874006033,
mae,0.5331822037696838,0.12911060452461243,0.11026321351528168,0.0972898006439209,0.08725196868181229,0.08151910454034805,0.0757046714425087,0.06616402417421341,0.08025754988193512,0.07419148087501526,0.062006063759326935,0.048683710396289825,0.06392713636159897,0.05682981386780739,0.04451945424079895,0.04077927768230438,0.033731114119291306,0.033378783613443375,0.04164036735892296,0.034677378833293915,0.02703416533768177,0.029084594920277596,0.03412552922964096,0.02716001123189926,0.027708003297448158,0.027605552226305008,0.026408972218632698,0.021910835057497025,0.023024218156933784,0.01985635608434677,0.019479867070913315,0.019375573843717575,0.022403659299016,0.020721234381198883,0.02532915584743023,0.022405916824936867,0.01808694750070572,0.01970510557293892,0.021366095170378685,0.01783532090485096,0.016348419710993767,0.01972714625298977,0.019890861585736275,0.015489315614104271,0.01817108504474163,0.013981821946799755,0.014260334894061089,0.01665794663131237,0.016847942024469376,0.016859568655490875,0.014919454231858253,0.014395516365766525,0.014645449817180634,0.014005441218614578,0.014724913984537125,0.014108373783528805,0.01676463708281517,0.016235332936048508,0.012515773996710777,0.012821704149246216,0.012290493585169315,0.013285127468407154,0.014083401300013065,0.013554701581597328,0.012391327880322933,0.013504858128726482,0.014767305925488472,0.013718490488827229,0.011108043603599072,0.014744013547897339,0.013527635484933853,0.014574731700122356,0.01315367128700018,0.01265745609998703,0.013471978716552258,0.011118496768176556,0.012525406666100025,0.011396356858313084,0.011935361661016941,0.011371097527444363,0.012874297797679901,0.011367958039045334,0.011401386000216007,0.013618665747344494,0.01294402964413166,0.010315405204892159,0.011179124005138874,0.011822683736681938,0.010293933562934399,0.010356579907238483,0.011736949905753136,0.012372629716992378,0.012500744313001633,0.011585734784603119,0.01012473925948143,0.010075870901346207,0.012411534786224365,0.012109944596886635,0.01290478091686964,0.010968147777020931,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 121827    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 121828    
=================================================================
Total params: 243,655
Trainable params: 243,655
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 121,827
Trainable params: 121,827
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 121,828
Trainable params: 121,828
Non-trainable params: 0
_________________________________________________________________
