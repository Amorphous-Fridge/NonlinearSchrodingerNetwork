2021-06-26
loss,2.6519014835357666,2.2115097045898438,1.2707611322402954,0.3601283133029938,0.30068451166152954,0.2552860975265503,0.25237613916397095,0.2361399084329605,0.24447332322597504,0.20789624750614166,0.17463211715221405,0.17828239500522614,0.13432297110557556,0.1080736368894577,0.0898599624633789,0.09817228466272354,0.0916876494884491,0.12607835233211517,0.08326397836208344,0.09313321858644485,0.11071965098381042,0.09582081437110901,0.08978863805532455,0.09191909432411194,0.07054189592599869,0.06733892858028412,0.07390069216489792,0.08331272751092911,0.0732445940375328,0.06827084720134735,0.05480022355914116,0.055616654455661774,0.06990458816289902,0.06277678906917572,0.061115507036447525,0.06444929540157318,0.06159660220146179,0.05042172968387604,0.05871091037988663,0.05658172443509102,0.059876155108213425,0.05038231983780861,0.05641941726207733,0.046967726200819016,0.04877805337309837,0.03810946270823479,0.039156608283519745,0.042218394577503204,0.04252994433045387,0.050057701766490936,0.037423767149448395,0.040315575897693634,0.052947983145713806,0.04402487725019455,0.04143007844686508,0.03738091140985489,0.033203355967998505,0.04565546661615372,0.0415436252951622,0.039076101034879684,0.04103153571486473,0.0438472256064415,0.03989265859127045,0.0398951955139637,0.038129400461912155,0.03866551071405411,0.03749749809503555,0.0441589318215847,0.03857447952032089,0.03668680042028427,0.03098253533244133,0.03875628858804703,0.038460709154605865,0.04085686802864075,0.037573765963315964,0.03183450549840927,0.0322427824139595,0.031524933874607086,0.031182635575532913,0.03855589032173157,0.039217401295900345,0.03623916953802109,0.03275856375694275,0.031216692179441452,0.03735903277993202,0.034014347940683365,0.0329144224524498,0.029506711289286613,0.02934049628674984,0.030507707968354225,0.03288905322551727,0.03729933500289917,0.03089207410812378,0.03048321232199669,0.03488660603761673,0.029355788603425026,0.030100960284471512,0.03651338070631027,0.0312154833227396,0.03218619525432587,
mse,2.620157480239868,1.2360230684280396,0.5741091370582581,0.0379021055996418,0.027512740343809128,0.020915037021040916,0.020634422078728676,0.017373183742165565,0.017500631511211395,0.012593269348144531,0.008971739560365677,0.00931678805500269,0.005045040976256132,0.0033675413578748703,0.002336333505809307,0.002683568513020873,0.002426488557830453,0.004702622536569834,0.001949600176885724,0.002448145067319274,0.003374639665707946,0.0026227084454149008,0.0023144488222897053,0.0023141137789934874,0.0014301097253337502,0.0012535761343315244,0.0016093176091089845,0.0019218580564484,0.0015209303237497807,0.0013080565258860588,0.0008473649504594505,0.0008667012443765998,0.0013562595704570413,0.0011270004324615002,0.001047903555445373,0.0011899343226104975,0.0010488572297617793,0.000716100912541151,0.0009456287953071296,0.0008833089959807694,0.0009959680028259754,0.0007095775217749178,0.0008707974338904023,0.000618434976786375,0.0006711568566970527,0.0004085262189619243,0.0004402452032081783,0.00051155686378479,0.0005133418017067015,0.0007178300875239074,0.0004086323897354305,0.0004676953249145299,0.0008006210555322468,0.000549619784578681,0.0004724981263279915,0.0003955853753723204,0.00031581029179506004,0.0005822184029966593,0.0004871938144788146,0.0004306838382035494,0.00046853910316713154,0.0005354902241379023,0.00043917287257499993,0.00045351951848715544,0.00041056799818761647,0.0004244232550263405,0.00039938584086485207,0.0005318825715221465,0.0004172931658104062,0.00038193733780644834,0.0002796558546833694,0.00040791428182274103,0.0004093576280865818,0.00045828777365386486,0.00039661824121139944,0.00028698399546556175,0.00029866519616916776,0.0002859084925148636,0.00027457260875962675,0.0004177298687864095,0.000430450338171795,0.0003687524003908038,0.000302062660921365,0.00027272128500044346,0.00039869509055279195,0.00034859447623603046,0.00030248676193878055,0.0002468074089847505,0.00025191230815835297,0.00026308250380679965,0.00030528297065757215,0.00037422668538056314,0.000272609933745116,0.00025624613044783473,0.00034821347799152136,0.00024959456641227007,0.0002542418078519404,0.00040283185080625117,0.00027512336964719,0.00030302396044135094,
mae,0.9561439752578735,0.6517443060874939,0.5030316710472107,0.15470626950263977,0.1297936588525772,0.11167866736650467,0.10989641398191452,0.10097542405128479,0.10384027659893036,0.08856816589832306,0.07480008155107498,0.07495362311601639,0.05768913775682449,0.04666266590356827,0.038797859102487564,0.041520312428474426,0.0390838086605072,0.055693257600069046,0.035543181002140045,0.040001627057790756,0.04823533073067665,0.041318055242300034,0.0392211377620697,0.03944223001599312,0.029815228655934334,0.028759974986314774,0.0314750038087368,0.03629450872540474,0.03185613453388214,0.03005504608154297,0.023157579824328423,0.023614585399627686,0.030777012929320335,0.02708524651825428,0.02602577954530716,0.027708502486348152,0.026419714093208313,0.021186990663409233,0.02548607997596264,0.02465687319636345,0.026139594614505768,0.02155238389968872,0.024068333208560944,0.020119063556194305,0.02099379152059555,0.016060370951890945,0.016597392037510872,0.017992565408349037,0.01834956556558609,0.021436793729662895,0.01566299796104431,0.017334604635834694,0.023021601140499115,0.018860992044210434,0.017588326707482338,0.015863753855228424,0.01415951270610094,0.019822804257273674,0.017609531059861183,0.016681814566254616,0.017395004630088806,0.018954452127218246,0.01729833334684372,0.017265500500798225,0.016501404345035553,0.016822466626763344,0.01603049784898758,0.01905824989080429,0.016627565026283264,0.0156516432762146,0.013286923989653587,0.017027869820594788,0.01659492217004299,0.017393283545970917,0.015929901972413063,0.013504957780241966,0.013649458065629005,0.013463938608765602,0.013347313739359379,0.016618818044662476,0.016732163727283478,0.015758026391267776,0.013963690958917141,0.013240412808954716,0.015991954132914543,0.014605491422116756,0.014130515977740288,0.012437666766345501,0.01246424950659275,0.012999436818063259,0.014152106828987598,0.01620820350944996,0.01337396539747715,0.01296971645206213,0.014799991622567177,0.0126215610653162,0.012783589772880077,0.015300313010811806,0.013226284645497799,0.013785022310912609,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 472739    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 472740    
=================================================================
Total params: 945,479
Trainable params: 945,479
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 472,739
Trainable params: 472,739
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 472,740
Trainable params: 472,740
Non-trainable params: 0
_________________________________________________________________
