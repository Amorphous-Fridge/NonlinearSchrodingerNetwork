2021-06-26
loss,0.9335953593254089,0.3952198028564453,0.3641289174556732,0.3528955578804016,0.3479226231575012,0.33088743686676025,0.3234533667564392,0.41299164295196533,0.37911292910575867,0.35613566637039185,0.35591182112693787,0.3546757996082306,0.3529818654060364,0.35187873244285583,0.3512280583381653,0.3403991460800171,0.33297979831695557,0.33094918727874756,0.32564103603363037,0.32066166400909424,0.32015877962112427,0.3139650523662567,0.30842113494873047,0.30379483103752136,0.3020702600479126,0.2980402112007141,0.29203295707702637,0.29316553473472595,0.28850990533828735,0.2844480872154236,0.2809606194496155,0.27942216396331787,0.270411878824234,0.2736634612083435,0.2582431137561798,0.2415727972984314,0.2442162185907364,0.23523159325122833,0.23515164852142334,0.23177094757556915,0.23132508993148804,0.22888261079788208,0.2292776256799698,0.22357703745365143,0.2238755077123642,0.22330017387866974,0.2122933268547058,0.21306249499320984,0.2007245570421219,0.19290202856063843,0.17944449186325073,0.15968354046344757,0.14559225738048553,0.14128315448760986,0.13935181498527527,0.13389216363430023,0.13260488212108612,0.1291382759809494,0.12837888300418854,0.1255696415901184,0.12312312424182892,0.1221710741519928,0.12002328783273697,0.11888222396373749,0.11763117462396622,0.11744656413793564,0.11577281355857849,0.11580228060483932,0.11586560308933258,0.1126890555024147,0.11178264766931534,0.1123703196644783,0.10939193516969681,0.11025996506214142,0.10852991044521332,0.10848882049322128,0.1077488362789154,0.10731683671474457,0.10762382298707962,0.1051441952586174,0.106597401201725,0.10362319648265839,0.10101120173931122,0.10023611783981323,0.09575721621513367,0.09251322597265244,0.0891638919711113,0.07705651968717575,0.07515500485897064,0.07165377587080002,0.07045202702283859,0.05540674552321434,0.0501345731317997,0.04617482051253319,0.04871849715709686,0.04577779769897461,0.03676896542310715,0.038314174860715866,0.05193586274981499,0.043697550892829895,
mse,0.46445176005363464,0.04494791477918625,0.03888655826449394,0.03711232542991638,0.0360361784696579,0.03278691694140434,0.03132736310362816,0.05550923943519592,0.04222288727760315,0.03758830949664116,0.03754960000514984,0.037298206239938736,0.036880385130643845,0.03642309829592705,0.03632495552301407,0.03432348370552063,0.03289628401398659,0.032671499997377396,0.03175283595919609,0.03096075728535652,0.0309528186917305,0.030101221054792404,0.029238848015666008,0.028466377407312393,0.028263049200177193,0.02763967029750347,0.026803629472851753,0.026904666796326637,0.02623298391699791,0.025660699233412743,0.025214627385139465,0.024898972362279892,0.02359711192548275,0.02385181374847889,0.02192324586212635,0.020010873675346375,0.02029973268508911,0.0194094181060791,0.01931668445467949,0.018789278343319893,0.01862129010260105,0.018298383802175522,0.018132604658603668,0.017498217523097992,0.017408248037099838,0.01717350445687771,0.016034867614507675,0.015689218416810036,0.013944488018751144,0.012426424771547318,0.010614757426083088,0.008607556112110615,0.007412665989249945,0.0069887381978333,0.006749421823769808,0.006358589045703411,0.0062584541738033295,0.0059908474795520306,0.0059012905694544315,0.005703876726329327,0.005540146958082914,0.005455919541418552,0.005327046383172274,0.005255663767457008,0.005137275438755751,0.005102095194160938,0.005015713162720203,0.004998604767024517,0.004988327156752348,0.004776330664753914,0.004716156050562859,0.004741635173559189,0.004563674330711365,0.0045954324305057526,0.004477551206946373,0.004470391198992729,0.004394702147692442,0.004369750153273344,0.004353631287813187,0.004196312744170427,0.004211106337606907,0.003940234892070293,0.0036498671397566795,0.003481428837403655,0.003150888718664646,0.002915707416832447,0.0026532132178545,0.0020195834804326296,0.0018424536101520061,0.001661292277276516,0.0015888784546405077,0.0009591425769031048,0.0007867433014325798,0.0006468354840762913,0.0007249016780406237,0.0006468567880801857,0.0004160029347985983,0.0004492983571253717,0.0007939023780636489,0.0005662720068357885,
mae,0.40429064631462097,0.17235179245471954,0.15927252173423767,0.1544596254825592,0.1520460844039917,0.14452162384986877,0.14062467217445374,0.1793370395898819,0.16706451773643494,0.15709584951400757,0.156865194439888,0.15591609477996826,0.1545008420944214,0.15367934107780457,0.15342234075069427,0.1488904505968094,0.14566320180892944,0.1448569893836975,0.14217150211334229,0.13953477144241333,0.13869692385196686,0.13532310724258423,0.13305522501468658,0.13114014267921448,0.13037513196468353,0.12853339314460754,0.12583652138710022,0.1262037307024002,0.12416139245033264,0.12221493571996689,0.12052113562822342,0.12000972777605057,0.11575177311897278,0.11716815084218979,0.11110834777355194,0.10539430379867554,0.10585373640060425,0.102205790579319,0.1025773361325264,0.10209815949201584,0.10207774490118027,0.10120216012001038,0.1011074036359787,0.098704032599926,0.09863875061273575,0.0976247787475586,0.09307575970888138,0.09277324378490448,0.08576877415180206,0.08153972029685974,0.075259730219841,0.06664498150348663,0.06044277176260948,0.05870620161294937,0.05792846530675888,0.05552157014608383,0.05496807396411896,0.05349172651767731,0.053248777985572815,0.05200843885540962,0.051121801137924194,0.05073358491063118,0.04985245689749718,0.04947146028280258,0.048989102244377136,0.04898947849869728,0.04824192076921463,0.048298921436071396,0.04842629283666611,0.047066591680049896,0.04664900153875351,0.04703916236758232,0.04572229087352753,0.04616999253630638,0.04544687643647194,0.045448675751686096,0.045107606798410416,0.04501958191394806,0.0450667105615139,0.04403916373848915,0.04478459060192108,0.043518662452697754,0.042393799871206284,0.04217071831226349,0.040198370814323425,0.03903469070792198,0.03777032345533371,0.032555438578128815,0.031982313841581345,0.030205784365534782,0.029671695083379745,0.023547114804387093,0.021279210224747658,0.019656699150800705,0.020635994151234627,0.019540635868906975,0.015570188872516155,0.016323938965797424,0.02211238443851471,0.01853388361632824,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 329931    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 329932    
=================================================================
Total params: 659,863
Trainable params: 659,863
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 329,931
Trainable params: 329,931
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 329,932
Trainable params: 329,932
Non-trainable params: 0
_________________________________________________________________
