2021-06-26
loss,2.6280252933502197,2.153475046157837,0.4810446798801422,0.19354282319545746,0.16149432957172394,0.18880265951156616,0.12666736543178558,0.14813125133514404,0.12184718996286392,0.12483173608779907,0.09938692301511765,0.08248800039291382,0.07664673030376434,0.07016846537590027,0.0651523768901825,0.08717898279428482,0.054911304265260696,0.07312221825122833,0.06676966696977615,0.07559053599834442,0.08766894042491913,0.06019023805856705,0.06561193615198135,0.07709908485412598,0.05512209236621857,0.05426333472132683,0.04847543686628342,0.07302572578191757,0.04756162315607071,0.04621104896068573,0.04630926996469498,0.04486066848039627,0.05536831542849541,0.04835823178291321,0.06566233187913895,0.06526315957307816,0.05999349430203438,0.05298696830868721,0.04922104999423027,0.04966479912400246,0.05640505254268646,0.05712226405739784,0.04907412827014923,0.054776906967163086,0.050038401037454605,0.05257543921470642,0.04557111859321594,0.037906888872385025,0.04058533161878586,0.04712178558111191,0.05017495155334473,0.03868890926241875,0.035143282264471054,0.05068378522992134,0.04791789501905441,0.04152824729681015,0.039456646889448166,0.04853431135416031,0.041995786130428314,0.03652864322066307,0.039322610944509506,0.04614023119211197,0.04275311529636383,0.045483533293008804,0.04068514332175255,0.04508798569440842,0.040391117334365845,0.04137744754552841,0.043259259313344955,0.034603092819452286,0.03438766300678253,0.03619088977575302,0.03826098144054413,0.044568661600351334,0.03956444188952446,0.039756059646606445,0.04166429489850998,0.03619523346424103,0.032936181873083115,0.0337124839425087,0.03197086602449417,0.029324239119887352,0.04393912851810455,0.04200930893421173,0.03823046013712883,0.037312429398298264,0.0392361581325531,0.03426457569003105,0.03341562673449516,0.033476486802101135,0.040732353925704956,0.03394903615117073,0.036177121102809906,0.03218098729848862,0.03387412801384926,0.03123336285352707,0.04027511179447174,0.036901794373989105,0.03240713104605675,0.039861444383859634,
mse,2.0835182666778564,1.195814609527588,0.08157077431678772,0.011106828227639198,0.007387480232864618,0.010887626558542252,0.0048138974234461784,0.006455563940107822,0.004344407934695482,0.004562670364975929,0.0028394097462296486,0.0020005442202091217,0.001683198381215334,0.0014530852204188704,0.0012470788788050413,0.00233233324252069,0.0008825678378343582,0.0015209238044917583,0.0013117861235514283,0.001653697807341814,0.0023081982508301735,0.0010570250451564789,0.0012950706295669079,0.0017138574039563537,0.0008807680569589138,0.0008437340147793293,0.0007285983883775771,0.0015455535613000393,0.0006619455525651574,0.0006288069998845458,0.0006188856204971671,0.0006229028222151101,0.0009406757308170199,0.0006579690962098539,0.0012267695274204016,0.001187184709124267,0.0009982783813029528,0.0007831891416572034,0.0006917534046806395,0.0007009602268226445,0.0008847975987009704,0.0009136830340139568,0.000685130013152957,0.0008238285081461072,0.0007102146046236157,0.0007517777848988771,0.0005633639520965517,0.00041061878437176347,0.00047115105553530157,0.0006507835350930691,0.0007127768476493657,0.0004264481831341982,0.00035280524753034115,0.0007162730325944722,0.0006311328615993261,0.0004782496835105121,0.0004522918607108295,0.000637889257632196,0.00047926019760780036,0.0003708865842781961,0.0004433080612216145,0.0005999868153594434,0.000522376096341759,0.0005718122120015323,0.00046048100921325386,0.0005536542739719152,0.00045067488099448383,0.0004788053047377616,0.0005203241598792374,0.00034557265462353826,0.0003425094182603061,0.0003573346184566617,0.0004112489987164736,0.0005367773701436818,0.00043108128011226654,0.00044089514994993806,0.00047419301699846983,0.00035742641193792224,0.00030645658262073994,0.00031031787511892617,0.000279457337455824,0.00024941135779954493,0.0005339093622751534,0.0004883437650278211,0.00040535948937758803,0.00039182949694804847,0.00043340626871213317,0.00033255736343562603,0.0003150718694087118,0.000322108156979084,0.0004570448072627187,0.00032886405824683607,0.00036023047869093716,0.00028072023997083306,0.0003227634006179869,0.00027895584935322404,0.00045944342855364084,0.0003748520102817565,0.00029351908597163856,0.00043866626219823956,
mae,1.0080941915512085,0.7789257764816284,0.2052430659532547,0.08262640982866287,0.06910236179828644,0.08161061257123947,0.054914508014917374,0.06486731022596359,0.05095973610877991,0.055568818002939224,0.04159446060657501,0.03554021194577217,0.03284481540322304,0.030254261568188667,0.028117526322603226,0.038905952125787735,0.022849829867482185,0.0311733428388834,0.02752869389951229,0.032155223190784454,0.03938721492886543,0.025822987779974937,0.02770828641951084,0.03450130298733711,0.02389751747250557,0.02269369177520275,0.02112681232392788,0.032186757773160934,0.019803272560238838,0.019861869513988495,0.01959022879600525,0.02007392607629299,0.024426503106951714,0.02020292915403843,0.029178902506828308,0.030358074232935905,0.028140252456068993,0.023023581132292747,0.02111032046377659,0.021283481270074844,0.02490725927054882,0.025642309337854385,0.021100401878356934,0.02522796392440796,0.021528789773583412,0.02444571815431118,0.01880909502506256,0.015863610431551933,0.017801713198423386,0.020768392831087112,0.02253909595310688,0.016164805740118027,0.014768140390515327,0.02324245125055313,0.02234346605837345,0.017823094502091408,0.017111826688051224,0.02165745012462139,0.018421191722154617,0.015404349192976952,0.016503872349858284,0.02068452164530754,0.019503436982631683,0.02093666046857834,0.017470095306634903,0.019902538508176804,0.01768793910741806,0.01814308390021324,0.019776884466409683,0.014482591301202774,0.014488783665001392,0.015239911153912544,0.016274534165859222,0.020782141014933586,0.017677713185548782,0.01757165789604187,0.019614364951848984,0.015667324885725975,0.013768160715699196,0.013494911603629589,0.013329815119504929,0.01247912086546421,0.019981088116765022,0.01946547068655491,0.016983799636363983,0.016476579010486603,0.01772172376513481,0.014764734543859959,0.014250583946704865,0.01447326224297285,0.018509017303586006,0.01468564011156559,0.015301890671253204,0.013522624038159847,0.014563214033842087,0.013559338636696339,0.018145043402910233,0.016116537153720856,0.013806086033582687,0.01817724108695984,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 400851    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 400852    
=================================================================
Total params: 801,703
Trainable params: 801,703
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 400,851
Trainable params: 400,851
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 400,852
Trainable params: 400,852
Non-trainable params: 0
_________________________________________________________________
