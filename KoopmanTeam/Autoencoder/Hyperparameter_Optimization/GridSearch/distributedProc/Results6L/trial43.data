2021-06-26
loss,1.1986665725708008,0.36251842975616455,0.3565509021282196,0.3542521297931671,0.3504621088504791,0.34720921516418457,0.34739649295806885,0.3400440514087677,0.3362094759941101,0.33109596371650696,0.3349081873893738,0.2574797570705414,0.22413572669029236,0.20316192507743835,0.1910116970539093,0.19408640265464783,0.19276027381420135,0.19392642378807068,0.18887896835803986,0.1358073204755783,0.1723918467760086,0.15596766769886017,0.1493385285139084,0.1440199613571167,0.12896567583084106,0.10719901323318481,0.10092375427484512,0.1180528923869133,0.11542975157499313,0.1072666347026825,0.11486320197582245,0.10503602027893066,0.10168009996414185,0.09219052642583847,0.08064761012792587,0.08403145521879196,0.09628885239362717,0.09270065277814865,0.09508295357227325,0.09440422803163528,0.08289055526256561,0.07054594159126282,0.08323730528354645,0.08198196440935135,0.08773082494735718,0.08227682113647461,0.08313751220703125,0.08544526994228363,0.08081886917352676,0.0835762619972229,0.07224883884191513,0.06574173271656036,0.05654889717698097,0.06392331421375275,0.06694958359003067,0.06253183633089066,0.07896146923303604,0.05445133522152901,0.06373245269060135,0.06429389119148254,0.07565510272979736,0.06685393303632736,0.062162745743989944,0.0662299245595932,0.059119466692209244,0.04996868968009949,0.06616304069757462,0.0514548160135746,0.04533424228429794,0.044008851051330566,0.050096455961465836,0.0615626759827137,0.0498817004263401,0.041147880256175995,0.04150865226984024,0.05448668822646141,0.0424327626824379,0.050828590989112854,0.048576343804597855,0.047308702021837234,0.033584531396627426,0.029318062588572502,0.039736997336149216,0.04180608689785004,0.04000873118638992,0.03487756475806236,0.04774393513798714,0.04570264741778374,0.03997873514890671,0.028416523709893227,0.036942046135663986,0.03774704411625862,0.0319480337202549,0.036204610019922256,0.0446983203291893,0.03273117169737816,0.03953475132584572,0.037930652499198914,0.030338604003190994,0.03150094300508499,
mse,0.7309561967849731,0.03888823837041855,0.03767100349068642,0.0371406190097332,0.03639224171638489,0.03574920818209648,0.035653773695230484,0.03429581597447395,0.03351626545190811,0.0325099378824234,0.0329749658703804,0.0200264360755682,0.015597107820212841,0.013372131623327732,0.012121016159653664,0.011969679966568947,0.012461595237255096,0.011982988566160202,0.011363644152879715,0.006415305193513632,0.009209569543600082,0.007888520136475563,0.00724392756819725,0.006840961519628763,0.005524823442101479,0.004223176743835211,0.0038115959614515305,0.004708853550255299,0.0045769731514155865,0.004076638724654913,0.004421042278409004,0.003974186722189188,0.0037059690803289413,0.0031774721574038267,0.0026113761123269796,0.0027704930398613214,0.003246116451919079,0.0030730918515473604,0.0032318702433258295,0.003201474901288748,0.002660709898918867,0.0020686527714133263,0.002588483039289713,0.0024929402861744165,0.002825179137289524,0.002504967851564288,0.0026190790813416243,0.0025311612989753485,0.0023410110734403133,0.0024689652491360903,0.0020331009291112423,0.0017540137050673366,0.0013974301982671022,0.0016183237312361598,0.001672978512942791,0.0015349697787314653,0.002132945694029331,0.0012386036105453968,0.0014751963317394257,0.0014402354136109352,0.0018367187585681677,0.0015380509430542588,0.0012634642189368606,0.0014080223627388477,0.001128294155932963,0.000752200314309448,0.0012906374176964164,0.0007624577847309411,0.0005935400258749723,0.0005514073418453336,0.0007092817686498165,0.0010582403047010303,0.0007202340639196336,0.0004924311651848257,0.0005173939280211926,0.0008315869490616024,0.0005169046926312149,0.0007170571479946375,0.0006546304211951792,0.0006231956067495048,0.00032554942299611866,0.0002492308267392218,0.0004559578374028206,0.0004786839708685875,0.00045762406080029905,0.00035276380367577076,0.0006287987343966961,0.0005790573195554316,0.0004339182050898671,0.00024379575916100293,0.0004046805261168629,0.0004107493441551924,0.00029297731816768646,0.00038446675171144307,0.0005493421340361238,0.00030982965836301446,0.0004400273901410401,0.0004002293280791491,0.00028327220934443176,0.00028267723973840475,
mae,0.5086798667907715,0.15895774960517883,0.1562342345714569,0.15440741181373596,0.15225377678871155,0.15009315311908722,0.14894795417785645,0.1461414396762848,0.1435709148645401,0.14133013784885406,0.1409270167350769,0.10915610939264297,0.09582588076591492,0.08749876916408539,0.08274737000465393,0.08331353217363358,0.0819394513964653,0.0834321603178978,0.0811801627278328,0.058231353759765625,0.07351160794496536,0.06640155613422394,0.06355457007884979,0.06138615682721138,0.05512256175279617,0.045825518667697906,0.04283154010772705,0.049411214888095856,0.04857661575078964,0.04555007070302963,0.04849035665392876,0.04480624198913574,0.042627815157175064,0.03936644643545151,0.03454321622848511,0.03540800139307976,0.040202803909778595,0.038525424897670746,0.04011433199048042,0.04025360196828842,0.03505688160657883,0.029486725106835365,0.034890349954366684,0.03398596867918968,0.03668145462870598,0.03499362990260124,0.03487172722816467,0.03634696453809738,0.034246768802404404,0.03533725440502167,0.03010409325361252,0.027169277891516685,0.023975849151611328,0.027421465143561363,0.028168097138404846,0.02641395293176174,0.033318016678094864,0.023387430235743523,0.02709084190428257,0.027011394500732422,0.03306330367922783,0.02803696319460869,0.026038389652967453,0.02881564199924469,0.02521071396768093,0.021243685856461525,0.028512990102171898,0.021972177550196648,0.019026169553399086,0.018735338002443314,0.021338148042559624,0.026529157534241676,0.02104988321661949,0.01711912639439106,0.01756506972014904,0.023145608603954315,0.017916344106197357,0.022539690136909485,0.020809512585401535,0.020114438608288765,0.014145921915769577,0.012443444691598415,0.016810568049550056,0.01774909533560276,0.017236538231372833,0.015172910876572132,0.020792152732610703,0.019477106630802155,0.016469424590468407,0.012146754190325737,0.015780948102474213,0.016320597380399704,0.013658052310347557,0.01563320867717266,0.01918947882950306,0.013712256215512753,0.017171049490571022,0.016030503436923027,0.012958002276718616,0.013275501318275928,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 118611    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 118612    
=================================================================
Total params: 237,223
Trainable params: 237,223
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 118,611
Trainable params: 118,611
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 118,612
Trainable params: 118,612
Non-trainable params: 0
_________________________________________________________________
