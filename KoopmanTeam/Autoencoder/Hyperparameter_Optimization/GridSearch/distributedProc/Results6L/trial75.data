2021-06-26
loss,0.9652552604675293,0.291299432516098,0.25877657532691956,0.2514115869998932,0.23635993897914886,0.22579286992549896,0.2157568484544754,0.2054237723350525,0.19343431293964386,0.18345989286899567,0.174473375082016,0.16836877167224884,0.17051881551742554,0.2078314572572708,0.17264938354492188,0.14280784130096436,0.14758643507957458,0.15011867880821228,0.15336863696575165,0.13526393473148346,0.11422184109687805,0.09716257452964783,0.11821552366018295,0.09481791406869888,0.10526196658611298,0.10442090779542923,0.10113083571195602,0.08951640129089355,0.07114391773939133,0.09421249479055405,0.07785199582576752,0.08013736456632614,0.07296394556760788,0.0780637338757515,0.06420759111642838,0.06670176237821579,0.06789457052946091,0.0748995766043663,0.06791336834430695,0.05599847808480263,0.05122532323002815,0.05700540915131569,0.06114668399095535,0.0609719380736351,0.060064688324928284,0.04990888759493828,0.055005431175231934,0.05422321707010269,0.037739887833595276,0.042415570467710495,0.04307037219405174,0.057877086102962494,0.051815975457429886,0.04642791673541069,0.03440681844949722,0.04170669615268707,0.04526406154036522,0.0474853552877903,0.049612659960985184,0.043772920966148376,0.04752993956208229,0.04362708702683449,0.04250730946660042,0.03469468653202057,0.04525486007332802,0.03631572425365448,0.03653795272111893,0.036840394139289856,0.04320495203137398,0.045506153255701065,0.04242217540740967,0.035686250776052475,0.034053023904561996,0.03925050422549248,0.03977897763252258,0.03755197301506996,0.04046883061528206,0.040111154317855835,0.038576554507017136,0.040116406977176666,0.03277415409684181,0.029755787923932076,0.03629150614142418,0.03584057837724686,0.0388355627655983,0.031158313155174255,0.031221050769090652,0.035599902272224426,0.0328543558716774,0.037536513060331345,0.0346679650247097,0.034795597195625305,0.027227284386754036,0.032949723303318024,0.02802318148314953,0.030416326597332954,0.03791875019669533,0.03242764621973038,0.02929849550127983,0.02426409162580967,
mse,0.5654621720314026,0.025594130158424377,0.02104068733751774,0.020075835287570953,0.01828353852033615,0.016878504306077957,0.015647320076823235,0.014399638399481773,0.01291901245713234,0.011756527237594128,0.010727666318416595,0.009923771023750305,0.009602898731827736,0.013909623958170414,0.009930494241416454,0.006857164669781923,0.007048770785331726,0.007136380299925804,0.00773297855630517,0.005980203859508038,0.004549931734800339,0.0034383959136903286,0.004829113371670246,0.0032308187801390886,0.003829791909083724,0.003667830489575863,0.0033397325314581394,0.0026226129848510027,0.0017905463464558125,0.0028368146158754826,0.0018665583338588476,0.0020545863080769777,0.00178948522079736,0.001854506554082036,0.001277429168112576,0.0013080360367894173,0.0014323198702186346,0.001666192663833499,0.001337675261311233,0.0009215112077072263,0.0008028069860301912,0.0009665898396633565,0.0011090690968558192,0.0010910261189565063,0.0010508513078093529,0.0007318655261769891,0.0008918204694055021,0.0008746519451960921,0.00044042934314347804,0.0005183053435757756,0.0005283185164444149,0.000945607724133879,0.0007726641488261521,0.0006263710092753172,0.00034315724042244256,0.0005175252445042133,0.0006017989944666624,0.0006507171783596277,0.000719166942872107,0.0005486166919581592,0.000648253655526787,0.0005554479430429637,0.0005396176711656153,0.00037057834560982883,0.000596844416577369,0.000411000510212034,0.0003912965185008943,0.0003847632324323058,0.0005311472923494875,0.0005855797207914293,0.0004962898092344403,0.0003626934776548296,0.00033250695560127497,0.00044161826372146606,0.0004493005108088255,0.0004144994309172034,0.00046131282579153776,0.0004449412226676941,0.00042541258153505623,0.0004481893847696483,0.00031236812355928123,0.000259261840255931,0.00039371344610117376,0.00036057474790140986,0.0004273943486623466,0.0002896670193877071,0.00029828850529156625,0.00035866897087544203,0.0003098820452578366,0.0003990266704931855,0.00034545804373919964,0.00034769062767736614,0.0002219022426288575,0.0003088140219915658,0.0002256802108604461,0.00026628930936567485,0.00040899612940847874,0.00031035603024065495,0.0002451686596032232,0.0001740863372106105,
mae,0.42109256982803345,0.12493149936199188,0.11041805148124695,0.10838253051042557,0.10203435271978378,0.0974593460559845,0.09301819652318954,0.08859451115131378,0.08379875868558884,0.0799269899725914,0.0758141353726387,0.07306650280952454,0.07355417311191559,0.08977072685956955,0.07425554096698761,0.06165574491024017,0.06355668604373932,0.06488585472106934,0.06619042903184891,0.05816439166665077,0.04921106994152069,0.041903506964445114,0.05054861679673195,0.04066576808691025,0.04575425013899803,0.045098062604665756,0.043671317398548126,0.0385274738073349,0.029999304562807083,0.03997160866856575,0.03343047946691513,0.03385813161730766,0.031174026429653168,0.033384572714567184,0.02736896462738514,0.029096903279423714,0.029002266004681587,0.032035715878009796,0.029326751828193665,0.02400071546435356,0.02158018760383129,0.024728428572416306,0.025876104831695557,0.026282062754034996,0.025708775967359543,0.021769030019640923,0.023116502910852432,0.02319682203233242,0.015803387388586998,0.01812753453850746,0.018605932593345642,0.024362243711948395,0.021634245291352272,0.020040404051542282,0.01447398029267788,0.018008388578891754,0.019399045035243034,0.020620927214622498,0.02103395015001297,0.01885814033448696,0.019734734669327736,0.01848992519080639,0.01803707331418991,0.01457135658711195,0.01884237676858902,0.015865549445152283,0.015756765380501747,0.01583336852490902,0.01826515607535839,0.019245797768235207,0.017564937472343445,0.01558725256472826,0.014326702803373337,0.016614457592368126,0.016727019101381302,0.01623903587460518,0.017292505130171776,0.01723058521747589,0.016219738870859146,0.017143046483397484,0.014347745105624199,0.012599297799170017,0.015430023893713951,0.01539349090307951,0.016345642507076263,0.013272782787680626,0.013525472953915596,0.015309952199459076,0.013950251042842865,0.01604960672557354,0.014937024563550949,0.014945092611014843,0.011584700085222721,0.01400348823517561,0.012090763077139854,0.012944478541612625,0.015896404162049294,0.013981279917061329,0.012482198886573315,0.010287553071975708,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 331027    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 331028    
=================================================================
Total params: 662,055
Trainable params: 662,055
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 331,027
Trainable params: 331,027
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 331,028
Trainable params: 331,028
Non-trainable params: 0
_________________________________________________________________
