2021-06-26
loss,0.47380968928337097,0.20453718304634094,0.11388946324586868,0.10440009832382202,0.09633655846118927,0.058515772223472595,0.0527246855199337,0.056531790643930435,0.04615769535303116,0.04278263449668884,0.040607552975416183,0.051472391933202744,0.04726706072688103,0.048505812883377075,0.04799414053559303,0.04387092590332031,0.05607490986585617,0.05606343597173691,0.03266105428338051,0.029243968427181244,0.028418218716979027,0.02801942080259323,0.02834341675043106,0.03446342051029205,0.038144733756780624,0.02704370766878128,0.02688697725534439,0.02656552754342556,0.025497496128082275,0.035954322665929794,0.034272607415914536,0.030404433608055115,0.03289042413234711,0.037153460085392,0.04315955191850662,0.03206167370080948,0.03104131668806076,0.02585795149207115,0.03183426707983017,0.023830939084291458,0.022892341017723083,0.022218234837055206,0.021746058017015457,0.021399447694420815,0.021018002182245255,0.020722366869449615,0.020528044551610947,0.02058771625161171,0.020808780565857887,0.026555592194199562,0.033473845571279526,0.03241764381527901,0.030996916815638542,0.027737176045775414,0.02349555306136608,0.02060406468808651,0.020135562866926193,0.01940329559147358,0.019355833530426025,0.0213118027895689,0.03294995799660683,0.031015396118164062,0.029087839648127556,0.02932092361152172,0.02512025274336338,0.01922472193837166,0.018217846751213074,0.017626868560910225,0.01791631616652012,0.017272504046559334,0.017578735947608948,0.017527885735034943,0.01739475503563881,0.017106909304857254,0.023387162014842033,0.027322618290781975,0.029262488707900047,0.026937808841466904,0.026198534294962883,0.024394571781158447,0.022373171523213387,0.021828770637512207,0.02684800885617733,0.021128304302692413,0.017087602987885475,0.016658704727888107,0.01612170785665512,0.015854375436902046,0.015698544681072235,0.015606271103024483,0.01568378508090973,0.015365364961326122,0.015333622694015503,0.015253055840730667,0.01523587480187416,0.019681017845869064,0.022268695756793022,0.024269651621580124,0.0273421760648489,0.02471141889691353,
mse,0.11930301785469055,0.013852461241185665,0.00456572650000453,0.0034147289115935564,0.00267802644520998,0.0010839488822966814,0.0008752139401622117,0.0009998214663937688,0.0006405349122360349,0.0005465652793645859,0.0004912076401524246,0.0008001964306458831,0.0006336519727483392,0.0007081707008183002,0.0007034204318188131,0.0005962616414763033,0.0008975860546343029,0.0009041030425578356,0.00032515660859644413,0.00025360618019476533,0.00023925672576297075,0.00022914860164746642,0.00024179957108572125,0.00035782394115813076,0.000430560321547091,0.00022244917636271566,0.0002115783136105165,0.00020405655959621072,0.00019189398153685033,0.0003969621320720762,0.00036227054079063237,0.00027762792888097465,0.0003195239696651697,0.00040020953747443855,0.0005312877474352717,0.00030048159533180296,0.0002799610374495387,0.00020178212434984744,0.0003026944468729198,0.0001701715955277905,0.00015178622561506927,0.00014247704530134797,0.00013543726527132094,0.00013127349666319788,0.00012651141150854528,0.0001259984856005758,0.0001273816596949473,0.00012483792670536786,0.00012465666804928333,0.00021486364130396396,0.0003220548969693482,0.00029898405773565173,0.0002650124370120466,0.00021118076983839273,0.00016259639232885092,0.0001254451781278476,0.00011622023885138333,0.00010804799239849672,0.00010781877062981948,0.00013844006753060967,0.0003173389413859695,0.00028603553073480725,0.00024917282280512154,0.00024425663286820054,0.00018171036208514124,0.00011091982742073014,9.742451220517978e-05,8.970052294898778e-05,9.177502215607092e-05,8.92285315785557e-05,9.062734170584008e-05,8.942661952460185e-05,8.663031621836126e-05,8.706186054041609e-05,0.00016495266754645854,0.00021637605095747858,0.00024000380653887987,0.00020685211347881705,0.00019380856247153133,0.00016376134590245783,0.00013990655133966357,0.00014847220154479146,0.00021506905613932759,0.00013676515663973987,8.47543342388235e-05,7.965991972014308e-05,7.474401354556903e-05,7.23598786862567e-05,7.1722999564372e-05,7.078429916873574e-05,7.038406329229474e-05,6.884733738843352e-05,6.942515756236389e-05,6.730226596118882e-05,6.774721259716898e-05,0.00011816126061603427,0.00015025370521470904,0.00017069964087568223,0.0002080932754324749,0.00016841210890561342,
mae,0.20565004646778107,0.08514419198036194,0.0474439300596714,0.043776802718639374,0.04028239846229553,0.024717992171645164,0.022297579795122147,0.024267444387078285,0.019471365958452225,0.018059706315398216,0.017162099480628967,0.021898973733186722,0.020154617726802826,0.020513739436864853,0.020543189719319344,0.018613779917359352,0.023900454863905907,0.023779766634106636,0.013789385557174683,0.01233044732362032,0.012053790502250195,0.011905751191079617,0.01208422426134348,0.01465083472430706,0.016178516671061516,0.011445572599768639,0.011480155400931835,0.011260750703513622,0.010827187448740005,0.015370038338005543,0.014481505379080772,0.012743447907269001,0.013902684673666954,0.01606949046254158,0.018073877319693565,0.013729112222790718,0.013260508887469769,0.010883953422307968,0.013563143089413643,0.010087491013109684,0.009653416462242603,0.009385189041495323,0.009245707653462887,0.00911281630396843,0.008985084481537342,0.008839103393256664,0.008688597939908504,0.008741202764213085,0.00885117705911398,0.011131370440125465,0.014192664995789528,0.013683662749826908,0.013597377575933933,0.012140672653913498,0.010114404372870922,0.008747980929911137,0.008544285781681538,0.008306777104735374,0.008241121657192707,0.009078269824385643,0.013952313922345638,0.013217232190072536,0.012666341848671436,0.012496289797127247,0.010731738060712814,0.008217263966798782,0.007674632128328085,0.007551167160272598,0.007596825249493122,0.007373434957116842,0.007488369941711426,0.0074387709610164165,0.007441312074661255,0.007226759102195501,0.01001073606312275,0.011660086922347546,0.012473378330469131,0.011543576605618,0.011270243674516678,0.010638583451509476,0.009846589528024197,0.00917801819741726,0.01180241908878088,0.00908983126282692,0.007259901612997055,0.007078115362673998,0.00685401726514101,0.006768478080630302,0.006695218849927187,0.006637509912252426,0.006689165718853474,0.006578612141311169,0.006539313122630119,0.006497351452708244,0.00652227271348238,0.008316636085510254,0.00957909133285284,0.010218425653874874,0.011606777086853981,0.0107322558760643,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 23291     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 23292     
=================================================================
Total params: 46,583
Trainable params: 46,583
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 23,291
Trainable params: 23,291
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 23,292
Trainable params: 23,292
Non-trainable params: 0
_________________________________________________________________
