2021-06-26
loss,0.4469200372695923,0.1220100000500679,0.06981532275676727,0.05840631574392319,0.05554083362221718,0.07216665893793106,0.04971471428871155,0.044578276574611664,0.04271677881479263,0.04064265638589859,0.038687583059072495,0.03728576749563217,0.035615336149930954,0.03433113172650337,0.03365299850702286,0.03323711082339287,0.032419152557849884,0.03209720924496651,0.031397271901369095,0.03137802705168724,0.030868209898471832,0.03025626204907894,0.029638735577464104,0.029567835852503777,0.028977708891034126,0.028719492256641388,0.02831471897661686,0.02816218137741089,0.02787000499665737,0.02789381332695484,0.027305645868182182,0.02754131332039833,0.026784155517816544,0.026727575808763504,0.026005759835243225,0.026055695489048958,0.026002541184425354,0.02587098814547062,0.025418555364012718,0.026732631027698517,0.0252479687333107,0.025089479982852936,0.024784989655017853,0.024638507515192032,0.024187758564949036,0.02471158467233181,0.024337947368621826,0.02397393435239792,0.023858439177274704,0.024108435958623886,0.0243141558021307,0.023991450667381287,0.023573534563183784,0.023362576961517334,0.02314053103327751,0.023585401475429535,0.024069366976618767,0.02261015586555004,0.024338945746421814,0.025791380554437637,0.025040529668331146,0.024386649951338768,0.023686254397034645,0.02270645834505558,0.02280719019472599,0.02236046828329563,0.02249457687139511,0.021932726725935936,0.021678362041711807,0.022217493504285812,0.021402599290013313,0.022066939622163773,0.021206878125667572,0.021023588255047798,0.021051974967122078,0.021406088024377823,0.021043404936790466,0.03961120545864105,0.03840673342347145,0.036190465092659,0.03546001762151718,0.03354187682271004,0.02970142289996147,0.027463145554065704,0.025786226615309715,0.024902760982513428,0.028270626440644264,0.035569772124290466,0.03386859968304634,0.033105745911598206,0.03891860321164131,0.03351639211177826,0.034479543566703796,0.031023690477013588,0.029067769646644592,0.027071459218859673,0.025604838505387306,0.024417471140623093,0.02349162846803665,0.02911072038114071,
mse,0.08956672996282578,0.005172834265977144,0.0015566832153126597,0.001039174385368824,0.0009525710484012961,0.001528397318907082,0.0007391067338176072,0.0005945125012658536,0.0005225607310421765,0.00046883520553819835,0.0004222990246489644,0.00038812047569081187,0.00035365967778488994,0.000328326306771487,0.00031411045347340405,0.0003047444624826312,0.0002889154711738229,0.00028357666451483965,0.00027295510517433286,0.0002740276977419853,0.00026098627131432295,0.00025026139337569475,0.00024038740957621485,0.00023884465917944908,0.000229868310270831,0.00022554783208761364,0.00022193269978743047,0.00021653682051692158,0.00021440901036839932,0.00021258792548906058,0.00020413468882907182,0.00020861232769675553,0.00019583817629609257,0.00019304489251226187,0.00018427854229230434,0.00018524167535360903,0.00018355614156462252,0.00018286060367245227,0.000176139990799129,0.00019613666518125683,0.0001732756063574925,0.00017209595534950495,0.00016832503024488688,0.00016544565733056515,0.00015878623526077718,0.00016794195107650012,0.00016093894373625517,0.00015683915989939123,0.00015478479326702654,0.00016067488468252122,0.0001624202122911811,0.0001571254979353398,0.0001515393960289657,0.00014902761904522777,0.00014506670413538814,0.00015297246864065528,0.0001591410837136209,0.00014411764277610928,0.00016201641119550914,0.00017911380564328283,0.00017066435248125345,0.00016399325977545232,0.00015337939839810133,0.0001403195201419294,0.00014249561354517937,0.0001379732566419989,0.000139887080877088,0.00013102323282510042,0.00012924984912388027,0.00013664063590113074,0.00012549490202218294,0.00013367756037041545,0.00012190955749247223,0.00012065231567248702,0.0001211046619573608,0.00012589893594849855,0.00012471048103179783,0.0005766469985246658,0.0004425358783919364,0.0003712854813784361,0.00035864164237864316,0.0003112672711722553,0.00024241166829597205,0.00020647264318540692,0.00018370711768511683,0.0001722253073239699,0.000243044676608406,0.0003515422286000103,0.00033016272936947644,0.00030586912180297077,0.0004369063244666904,0.0003137591411359608,0.0003374051593709737,0.0002684673818293959,0.00023670701193623245,0.00020530451729428023,0.00018370887846685946,0.00016719037375878543,0.00015353695198427886,0.00025852490216493607,
mae,0.1911362111568451,0.05187738314270973,0.029330508783459663,0.024486595764756203,0.023432141169905663,0.030725203454494476,0.020934753119945526,0.018753008916974068,0.018187956884503365,0.01715881936252117,0.016289716586470604,0.01577245071530342,0.014852907508611679,0.014149656519293785,0.014174800366163254,0.014066223986446857,0.013657527044415474,0.013612824492156506,0.013293133117258549,0.013394282199442387,0.013145060278475285,0.012835847213864326,0.012352182529866695,0.012492652051150799,0.012141703628003597,0.012068402022123337,0.012107369489967823,0.01180098857730627,0.0119045814499259,0.011864649131894112,0.011717531830072403,0.011696061119437218,0.011431220918893814,0.011488992720842361,0.011220205575227737,0.010976115241646767,0.01119961217045784,0.010847151279449463,0.010808250866830349,0.01134615857154131,0.010615577921271324,0.01080072857439518,0.010543057695031166,0.010254514403641224,0.010181877762079239,0.010482716374099255,0.01034536026418209,0.010226317681372166,0.01020946353673935,0.010237130336463451,0.010403646156191826,0.010168690234422684,0.009943542070686817,0.009977259673178196,0.009854435920715332,0.010042385198175907,0.010265796445310116,0.009524821303784847,0.01048729382455349,0.011033457703888416,0.01058060023933649,0.010407821275293827,0.010068747214972973,0.009796581231057644,0.009687399491667747,0.009502196684479713,0.009625334292650223,0.00926218368113041,0.0091317817568779,0.009357402101159096,0.00902119092643261,0.009405241347849369,0.008916113525629044,0.008965933695435524,0.008856062777340412,0.008951186202466488,0.008858640678226948,0.01725243404507637,0.01643744297325611,0.015394162386655807,0.015465452335774899,0.013133373111486435,0.011252365075051785,0.011770641431212425,0.011332197114825249,0.010953482240438461,0.012258409522473812,0.015276039950549603,0.014585951343178749,0.014292772859334946,0.017053918913006783,0.014441524632275105,0.014315742999315262,0.012989924289286137,0.012349512428045273,0.011600804515182972,0.010696039535105228,0.01016843318939209,0.010233580134809017,0.012587329372763634,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9267      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9268      
=================================================================
Total params: 18,535
Trainable params: 18,535
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 9,267
Trainable params: 9,267
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 9,268
Trainable params: 9,268
Non-trainable params: 0
_________________________________________________________________
