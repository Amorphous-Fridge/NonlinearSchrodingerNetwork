2021-06-26
loss,0.9523059725761414,0.30684220790863037,0.288593590259552,0.2736356854438782,0.26271048188209534,0.2545289695262909,0.2404475063085556,0.23589856922626495,0.23158468306064606,0.22636793553829193,0.22159823775291443,0.21116289496421814,0.20151165127754211,0.1941729336977005,0.1911771446466446,0.18588896095752716,0.1774856150150299,0.17892415821552277,0.1723451167345047,0.16616539657115936,0.16386154294013977,0.16008947789669037,0.1570429503917694,0.15600283443927765,0.15449188649654388,0.15454760193824768,0.14850495755672455,0.1463768631219864,0.15007181465625763,0.16424879431724548,0.1464933156967163,0.14510269463062286,0.13755391538143158,0.12524600327014923,0.12978120148181915,0.12369947135448456,0.11624132841825485,0.10792098939418793,0.1140051856637001,0.10310826450586319,0.10212403535842896,0.0969260185956955,0.11080338805913925,0.11178800463676453,0.09274686872959137,0.08681832253932953,0.08284769207239151,0.09499318897724152,0.10194581001996994,0.08988659083843231,0.09284847229719162,0.0892990306019783,0.07837599515914917,0.0806799829006195,0.0722639411687851,0.07618369162082672,0.06220260635018349,0.0643746554851532,0.06122975051403046,0.07033450901508331,0.06898902356624603,0.06820313632488251,0.07788499444723129,0.06357163935899734,0.06776507198810577,0.05729025974869728,0.062043026089668274,0.06122820824384689,0.05528358370065689,0.06584980338811874,0.06544004380702972,0.06732283532619476,0.06617284566164017,0.046966809779405594,0.04217115789651871,0.04041633754968643,0.048804521560668945,0.049195099622011185,0.05125579982995987,0.05683626979589462,0.04503704607486725,0.03947414830327034,0.05001548305153847,0.05313016474246979,0.05892254412174225,0.048258084803819656,0.04922694340348244,0.04546867311000824,0.04456578567624092,0.05206522345542908,0.05093347653746605,0.05497831851243973,0.041741758584976196,0.039324160665273666,0.0437658466398716,0.05338314175605774,0.05169933661818504,0.044908199459314346,0.04355192184448242,0.042104318737983704,
mse,0.43170490860939026,0.028293048962950706,0.025596125051379204,0.02345617115497589,0.022070350125432014,0.021089477464556694,0.019540997222065926,0.018784193322062492,0.01811385154724121,0.017201464623212814,0.016512028872966766,0.015151947736740112,0.01396596897393465,0.013029303401708603,0.012535636313259602,0.011804604902863503,0.010922964662313461,0.010715489275753498,0.010029112920165062,0.009410033002495766,0.009106874465942383,0.008744054473936558,0.008409622125327587,0.008270403370261192,0.008033208549022675,0.007951349951326847,0.007368248887360096,0.007091463077813387,0.007189129013568163,0.008513037115335464,0.007124181836843491,0.00687376456335187,0.006190463434904814,0.005312968045473099,0.0056386711075901985,0.005129863508045673,0.004632061347365379,0.004026845097541809,0.004457334987819195,0.0036129606887698174,0.003502804087474942,0.0032301011960953474,0.004109348636120558,0.004159890580922365,0.0030167249497026205,0.002699642674997449,0.002488932339474559,0.0030338054057210684,0.0034054378047585487,0.002769302111119032,0.0028745902236551046,0.0026951709296554327,0.0021857309620827436,0.002295195357874036,0.0019374709809198976,0.0020403657108545303,0.001470165210776031,0.0015429097693413496,0.0014415867626667023,0.001800414640456438,0.001724348170682788,0.0016453929711133242,0.0020571949426084757,0.001525484723970294,0.001616769121028483,0.0012567272642627358,0.0014661477180197835,0.0013766016345471144,0.0011504588183015585,0.0015709428116679192,0.001511277281679213,0.0015509097138419747,0.0015153794083744287,0.0009567964007146657,0.0008020714158192277,0.000725169840734452,0.000918284640647471,0.0008897435036487877,0.000947510008700192,0.0011051972396671772,0.0007941691437736154,0.0006605242961086333,0.0008925157599151134,0.000971894187387079,0.001197578152641654,0.0008601523004472256,0.0008665088680572808,0.0007833213312551379,0.0007477852050215006,0.0009206045651808381,0.0008785711252130568,0.0009932710090652108,0.0006537248264066875,0.0005786961410194635,0.0007045192760415375,0.000962716992944479,0.0008820148650556803,0.0006972480332478881,0.0006536181317642331,0.0006191555294208229,
mae,0.4128727614879608,0.1328260451555252,0.12198110669851303,0.11422760039567947,0.11022403836250305,0.10726380348205566,0.10102656483650208,0.09944538027048111,0.09877410531044006,0.09747631102800369,0.09582331031560898,0.09144680202007294,0.08714242279529572,0.0837421640753746,0.08214464783668518,0.07981761544942856,0.07633835077285767,0.07699990272521973,0.07400341331958771,0.07140008360147476,0.07008389383554459,0.0683387890458107,0.06693737208843231,0.06634083390235901,0.06564141064882278,0.0659274309873581,0.06326264142990112,0.06263238191604614,0.0640961155295372,0.0702841579914093,0.06263883411884308,0.06192132458090782,0.0587589293718338,0.0537555031478405,0.05551181361079216,0.0530678927898407,0.04978896304965019,0.04620291665196419,0.048711422830820084,0.04436212405562401,0.04373509809374809,0.04159689322113991,0.04756984859704971,0.048293743282556534,0.03973589837551117,0.03740816190838814,0.03546689823269844,0.040626410394907,0.044077154248952866,0.03894354775547981,0.04001438617706299,0.03872734680771828,0.03307807072997093,0.03454267606139183,0.031283702701330185,0.03268485888838768,0.02679096907377243,0.027561726048588753,0.026277143508195877,0.03025408275425434,0.029734551906585693,0.029170213267207146,0.03342603147029877,0.027395879849791527,0.029079487547278404,0.02474040351808071,0.026599068194627762,0.026485109701752663,0.023399895057082176,0.027948593720793724,0.028091445565223694,0.029138805344700813,0.028536712750792503,0.020147643983364105,0.01809207908809185,0.017353996634483337,0.020804965868592262,0.020996561273932457,0.02210063859820366,0.024446511641144753,0.019311686977744102,0.01688326522707939,0.021497251465916634,0.02304740995168686,0.025307564064860344,0.02043614163994789,0.020981652662158012,0.01951020024716854,0.019161583855748177,0.02225888893008232,0.021842826157808304,0.024130381643772125,0.017960865050554276,0.016985470429062843,0.018878713250160217,0.023117590695619583,0.022603994235396385,0.019505558535456657,0.01883675530552864,0.01813611201941967,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 83083     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 83084     
=================================================================
Total params: 166,167
Trainable params: 166,167
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 83,083
Trainable params: 83,083
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 83,084
Trainable params: 83,084
Non-trainable params: 0
_________________________________________________________________
