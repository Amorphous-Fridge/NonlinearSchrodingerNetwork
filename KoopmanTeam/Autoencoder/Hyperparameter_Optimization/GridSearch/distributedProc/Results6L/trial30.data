2021-06-26
loss,2.2378170490264893,0.7423264384269714,0.24120795726776123,0.19910436868667603,0.12332335114479065,0.15767022967338562,0.09455923736095428,0.1077364981174469,0.12051903456449509,0.0942387804389,0.08546710014343262,0.08933363854885101,0.06965378671884537,0.08129356056451797,0.06457870453596115,0.07383021712303162,0.08635244518518448,0.06449301540851593,0.06878504157066345,0.053607288748025894,0.0465473048388958,0.06749939918518066,0.05224158242344856,0.04911235347390175,0.0664980337023735,0.05718667432665825,0.04803023487329483,0.038662925362586975,0.03260080888867378,0.04867839440703392,0.05668795481324196,0.04835904762148857,0.04170513153076172,0.04196658730506897,0.04421442002058029,0.04480971768498421,0.0501704104244709,0.04430966451764107,0.03615843877196312,0.03178916871547699,0.03346746414899826,0.0460498109459877,0.04283381998538971,0.04169254004955292,0.042997926473617554,0.03454171121120453,0.0318027101457119,0.03853898122906685,0.030244622379541397,0.030113348737359047,0.03256669640541077,0.041069045662879944,0.04284458979964256,0.03712622821331024,0.03033473528921604,0.029482560232281685,0.037723954766988754,0.03497987613081932,0.02876647748053074,0.030502209439873695,0.038135502487421036,0.040052078664302826,0.03481445088982582,0.030334927141666412,0.03563082590699196,0.03376900032162666,0.03484305739402771,0.02917379140853882,0.026656057685613632,0.022704970091581345,0.03082503005862236,0.03543554246425629,0.03156328573822975,0.02567603811621666,0.025883929803967476,0.02308959700167179,0.030342459678649902,0.037424344569444656,0.03336518630385399,0.02898460626602173,0.02783561684191227,0.0222445297986269,0.023819701746106148,0.03737737610936165,0.033501893281936646,0.031546033918857574,0.028959548100829124,0.0262586809694767,0.02680782973766327,0.026374077424407005,0.029930539429187775,0.02906210348010063,0.022623881697654724,0.027164792641997337,0.01871691271662712,0.022245759144425392,0.023453643545508385,0.03044421225786209,0.027184555307030678,0.023601362481713295,
mse,1.2718180418014526,0.20948968827724457,0.019541196525096893,0.01287097204476595,0.0044615729711949825,0.007391451392322779,0.0026355283334851265,0.0034230886958539486,0.004380240570753813,0.0026776473969221115,0.002131456509232521,0.0023621798027306795,0.001388591481372714,0.001997571438550949,0.001161364489234984,0.0016184021951630712,0.0021082893945276737,0.0011572489747777581,0.0013260090490803123,0.0008000672096386552,0.0006027964409440756,0.0013954408932477236,0.0007980007212609053,0.0006866569747217,0.0012239654315635562,0.0009371560881845653,0.0006365416920743883,0.0004308939096517861,0.0003138842002954334,0.0007309202337637544,0.0008826059056445956,0.0006607332616113126,0.0004929954302497208,0.0004927399568259716,0.0005571464425884187,0.0005693579441867769,0.0006961481412872672,0.0005418022628873587,0.0003557876916602254,0.0002770526334643364,0.0003332391497679055,0.0005972827202640474,0.0005188221111893654,0.00048706200323067605,0.0005024508573114872,0.0003470232477411628,0.0002967287437058985,0.00041313510155305266,0.0002610929077491164,0.00025672928313724697,0.0003037560672964901,0.00048098922707140446,0.0005003245896659791,0.0003866298357024789,0.0002685276558622718,0.0002489983744453639,0.0004006757226306945,0.00034530553966760635,0.00023480971867684275,0.00026272618561051786,0.0004075931792613119,0.00043713286868296564,0.0003370729391463101,0.00026406292454339564,0.0003477241552900523,0.00032447074772790074,0.0003378204710315913,0.00023568600590806454,0.00019433075794950128,0.0001476291799917817,0.00028576471959240735,0.00035711098462343216,0.00028725661104544997,0.00019343654275871813,0.00018844807345885783,0.00015253276797011495,0.00025628783623687923,0.0003873019595630467,0.0003040771116502583,0.0002373002062086016,0.0002224447816843167,0.00014498218661174178,0.00016375233826693147,0.0003785435401368886,0.0003101599286310375,0.00027013610815629363,0.00023131344642024487,0.00019951103604398668,0.00020558566029649228,0.00020029347797390074,0.0002451030595693737,0.0002404054393991828,0.0001464637607568875,0.00021371955517679453,0.00010100665531354025,0.00014090450713410974,0.00015655138122383505,0.00025502772768959403,0.00020717277948278934,0.00016029314429033548,
mae,0.6984809637069702,0.30149662494659424,0.10010392218828201,0.08268312364816666,0.052322350442409515,0.0667824000120163,0.04014422744512558,0.04602394253015518,0.0509783998131752,0.0402684211730957,0.037023402750492096,0.03731422871351242,0.029926056042313576,0.034853700548410416,0.028545411303639412,0.031190533190965652,0.03609919920563698,0.027410952374339104,0.02861303836107254,0.023212037980556488,0.01994393765926361,0.028701748698949814,0.021563975140452385,0.020458724349737167,0.026729056611657143,0.024683108553290367,0.020166808739304543,0.016060499474406242,0.013737336732447147,0.019901221618056297,0.023202165961265564,0.020566683262586594,0.01787704788148403,0.018429262563586235,0.018502945080399513,0.019327301532030106,0.020186929032206535,0.0185878686606884,0.015730204060673714,0.013447361066937447,0.014201145619153976,0.01998455822467804,0.018396681174635887,0.01769913360476494,0.018192501738667488,0.014580545015633106,0.01320300716906786,0.01682629995048046,0.012678183615207672,0.012663628906011581,0.013953205198049545,0.016950462013483047,0.01702636480331421,0.01571229286491871,0.013129392638802528,0.012393752112984657,0.016097627580165863,0.014827514998614788,0.012313419952988625,0.013009078800678253,0.016155026853084564,0.016339723020792007,0.01513631921261549,0.013076633214950562,0.0149345388635993,0.014206672087311745,0.014756375923752785,0.012747206725180149,0.011817560531198978,0.009622984565794468,0.012945182621479034,0.014258570969104767,0.013281619176268578,0.010991862043738365,0.011017591692507267,0.009802497923374176,0.013017420656979084,0.015491430647671223,0.014170300215482712,0.012303540483117104,0.01188122108578682,0.009394923225045204,0.009993771091103554,0.014686757698655128,0.013205444440245628,0.012411472387611866,0.012016607448458672,0.01127132773399353,0.011512999422848225,0.011284077540040016,0.012250580824911594,0.01237694825977087,0.009501100517809391,0.01163286343216896,0.007940787822008133,0.00939258560538292,0.009925826452672482,0.01264740340411663,0.01172917801886797,0.010146093554794788,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 83371     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 83372     
=================================================================
Total params: 166,743
Trainable params: 166,743
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 83,371
Trainable params: 83,371
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 83,372
Trainable params: 83,372
Non-trainable params: 0
_________________________________________________________________
