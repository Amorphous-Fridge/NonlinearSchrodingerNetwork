2021-06-26
loss,0.5803136229515076,0.3083040416240692,0.25319305062294006,0.24776071310043335,0.24391359090805054,0.23413492739200592,0.2095867544412613,0.16455402970314026,0.11794951558113098,0.12390102446079254,0.11150289326906204,0.10727992653846741,0.1015477254986763,0.08604897558689117,0.09566293656826019,0.09553658217191696,0.08272837847471237,0.0673980787396431,0.06319001317024231,0.07286185026168823,0.0740489512681961,0.07330047339200974,0.06314317882061005,0.06367848068475723,0.05601474642753601,0.05427784100174904,0.05113133788108826,0.049316152930259705,0.04469909146428108,0.04004939645528793,0.03400944545865059,0.032351184636354446,0.04053667560219765,0.04909595474600792,0.04966966062784195,0.05008237063884735,0.043051861226558685,0.04333990067243576,0.04137124866247177,0.04657283425331116,0.03931234031915665,0.03487492725253105,0.04152052477002144,0.03392906114459038,0.03561383858323097,0.03524641692638397,0.035522911697626114,0.029149964451789856,0.03499651327729225,0.04199334606528282,0.03809773549437523,0.035798054188489914,0.03332296386361122,0.029524464160203934,0.03130823373794556,0.03376801311969757,0.03153102844953537,0.03369668126106262,0.03142712265253067,0.028472553938627243,0.02498822659254074,0.02276061475276947,0.02140391431748867,0.022334126755595207,0.0331699401140213,0.030462708324193954,0.02874526008963585,0.02739773690700531,0.029480967670679092,0.030783994123339653,0.03134752810001373,0.025618962943553925,0.025233104825019836,0.02955494076013565,0.02850339002907276,0.02839863859117031,0.025265997275710106,0.026189494878053665,0.02460428513586521,0.023992402479052544,0.02661207877099514,0.030697474256157875,0.028509778901934624,0.026712458580732346,0.025489551946520805,0.021977439522743225,0.01869763433933258,0.021170275285840034,0.023094868287444115,0.028750192373991013,0.025844616815447807,0.021935738623142242,0.02620454505085945,0.02384076826274395,0.024960169568657875,0.02326267957687378,0.02261696383357048,0.02103160321712494,0.022528914734721184,0.0267504770308733,
mse,0.13191287219524384,0.028486067429184914,0.02106468379497528,0.02042321488261223,0.01993619091808796,0.018616005778312683,0.013827430084347725,0.008301075547933578,0.0040901415050029755,0.004431052599102259,0.0037090322002768517,0.003314984031021595,0.00285727228038013,0.0021776841022074223,0.0026527189183980227,0.002600000472739339,0.0020221222657710314,0.0013868879759684205,0.0012064500479027629,0.0015089234802871943,0.0015457042027264833,0.0015074561815708876,0.0011029508896172047,0.001133255660533905,0.0008884799317456782,0.000821775640361011,0.0007281244033947587,0.0006700009689666331,0.0005718322354368865,0.0004561229725368321,0.000342261279001832,0.0003027789352927357,0.00048244025674648583,0.0006753712077625096,0.0007008871180005372,0.0006896036211401224,0.0005212772521190345,0.0005410637240856886,0.0004708332708105445,0.000584931462071836,0.00042971756192855537,0.00035561283584684134,0.000480551301734522,0.0003178102197125554,0.00035992416087538004,0.0003493876720312983,0.0003478522994555533,0.00024580987519584596,0.00034737130044959486,0.0004897064645774662,0.00039831327740103006,0.0003544877399690449,0.0003069782687816769,0.00025560049107298255,0.0002840030356310308,0.0003192764415871352,0.00028231993201188743,0.0003161225176881999,0.00027629209216684103,0.00022632810578215867,0.00017611995281185955,0.000147489583468996,0.0001358905283268541,0.0001533695904072374,0.00030934714595787227,0.00025926108355633914,0.00023770477855578065,0.00021634218865074217,0.00024535521515645087,0.00027690333081409335,0.00027174243587069213,0.00018384342547506094,0.0001832704001571983,0.0002574879617895931,0.00022894075664225966,0.00022223699488677084,0.00018261307559441775,0.0001976831117644906,0.0001756202254910022,0.00016399394371546805,0.00020530307665467262,0.00025573596940375865,0.0002218332956545055,0.00019674237410072237,0.00017907009168993682,0.00014167818881105632,0.0001075667969416827,0.00013331447553355247,0.00015495583647862077,0.00022785352484788746,0.0001853879221016541,0.00014010000450070947,0.0001901850337162614,0.00016074250743258744,0.0001695324172032997,0.0001492008741479367,0.000141912663821131,0.00012742812396027148,0.0001503054954810068,0.00019960044301114976,
mae,0.2520110011100769,0.1295454353094101,0.1058046892285347,0.10258673876523972,0.09987295418977737,0.09650519490242004,0.0878022313117981,0.06939556449651718,0.04960557445883751,0.052801672369241714,0.047650501132011414,0.04521474242210388,0.043413735926151276,0.03645450249314308,0.0408160462975502,0.04064605385065079,0.035571493208408356,0.028895968571305275,0.02677595056593418,0.03145851939916611,0.031227469444274902,0.031353916972875595,0.0269644632935524,0.026941349729895592,0.02376062422990799,0.022721240296959877,0.021635985001921654,0.020866241306066513,0.01916830986738205,0.017031323164701462,0.014531671069562435,0.013668220490217209,0.017334837466478348,0.021230150014162064,0.021210473030805588,0.021491866558790207,0.018690509721636772,0.01840919628739357,0.01778515614569187,0.02007209323346615,0.017090102657675743,0.014865844510495663,0.01781569793820381,0.014497591182589531,0.015229119919240475,0.015131134539842606,0.01535292249172926,0.012373401783406734,0.014875351451337337,0.018051359802484512,0.01638626866042614,0.01531375665217638,0.014112209901213646,0.012591686099767685,0.013427428901195526,0.014865896664559841,0.013746274635195732,0.014372428879141808,0.013435299508273602,0.012157520279288292,0.010380384512245655,0.009563121013343334,0.009136972948908806,0.009504636749625206,0.013955255970358849,0.013080302625894547,0.0121083315461874,0.011768464930355549,0.012712528929114342,0.013277031481266022,0.013687202706933022,0.011003966443240643,0.01075712125748396,0.01251299399882555,0.012256798334419727,0.012313591316342354,0.01076427660882473,0.011126638390123844,0.010677199810743332,0.010155865922570229,0.011291347444057465,0.01293334923684597,0.012035446241497993,0.011457657441496849,0.010931067168712616,0.009179866872727871,0.007884996943175793,0.008968068286776543,0.00994564127177,0.012241694144904613,0.010954205878078938,0.009259271435439587,0.011180880479514599,0.010110815986990929,0.010766788385808468,0.01010279729962349,0.009603403508663177,0.008853391744196415,0.009653918445110321,0.011334825307130814,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 34795     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 34796     
=================================================================
Total params: 69,591
Trainable params: 69,591
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 34,795
Trainable params: 34,795
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 34,796
Trainable params: 34,796
Non-trainable params: 0
_________________________________________________________________
