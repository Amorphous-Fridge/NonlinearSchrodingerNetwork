2021-06-26
loss,1.4668018817901611,0.2724763751029968,0.24347610771656036,0.23773211240768433,0.2337796539068222,0.2274780124425888,0.2242794781923294,0.2195228785276413,0.21536453068256378,0.2139090746641159,0.2037615329027176,0.1967456191778183,0.1885339319705963,0.18228131532669067,0.17304584383964539,0.17180076241493225,0.16945764422416687,0.16361984610557556,0.16134308278560638,0.15965719521045685,0.1565837264060974,0.1572386473417282,0.15466102957725525,0.15021349489688873,0.1455775797367096,0.16186898946762085,0.16259270906448364,0.13624142110347748,0.11465846747159958,0.1254093497991562,0.1069767102599144,0.11920400708913803,0.11468067765235901,0.08947228640317917,0.08117120712995529,0.08155399560928345,0.08271986991167068,0.0959266871213913,0.08896464109420776,0.07346954941749573,0.07464912533760071,0.06784945726394653,0.06280303746461868,0.06179579719901085,0.06665460020303726,0.07310043275356293,0.06799256056547165,0.06321708858013153,0.06078160181641579,0.05350698158144951,0.04792426899075508,0.05110228434205055,0.06959252059459686,0.06140756234526634,0.05471712723374367,0.04474405199289322,0.04860399663448334,0.05076678842306137,0.050059519708156586,0.03974113240838051,0.03949778527021408,0.04797042906284332,0.05233098939061165,0.04452243819832802,0.037698227912187576,0.03677663952112198,0.03776709735393524,0.038830146193504333,0.04909868165850639,0.04121384024620056,0.03382716700434685,0.03615783154964447,0.046347130089998245,0.038825489580631256,0.02987113781273365,0.041864536702632904,0.04306304454803467,0.03790579363703728,0.033857494592666626,0.034542281180620193,0.02988065406680107,0.028899164870381355,0.030168630182743073,0.037085019052028656,0.04184820130467415,0.036848366260528564,0.03248750418424606,0.034029241651296616,0.036478325724601746,0.036914292722940445,0.034185733646154404,0.0324225053191185,0.028835561126470566,0.026570411399006844,0.027767354622483253,0.029572417959570885,0.02673853561282158,0.03334343433380127,0.030379466712474823,0.023168377578258514,
mse,0.9810199737548828,0.023553568869829178,0.019926516339182854,0.019335506483912468,0.018722232431173325,0.017956718802452087,0.01750771701335907,0.016871212050318718,0.01627555675804615,0.015688130632042885,0.014332782477140427,0.013309996575117111,0.01231969241052866,0.011585789732635021,0.010649316012859344,0.010410061106085777,0.010122758336365223,0.009559279307723045,0.009307385422289371,0.009128003381192684,0.008829611353576183,0.008764510042965412,0.008550276979804039,0.008129112422466278,0.007362734526395798,0.008459817618131638,0.008739564567804337,0.006334426812827587,0.004718647804111242,0.0052597783505916595,0.004093932919204235,0.004599543288350105,0.004248904995620251,0.0026954656932502985,0.0022533037699759007,0.0021833376958966255,0.0021713776513934135,0.0027656210586428642,0.0024701175279915333,0.0016968853306025267,0.0017106238519772887,0.0014460484962910414,0.0012856717221438885,0.0012319061206653714,0.001348465564660728,0.0016070767305791378,0.0014015285996720195,0.001196533441543579,0.0011215663980692625,0.0009079221053980291,0.0007031550048850477,0.0007833670824766159,0.0013901941711083055,0.001071634702384472,0.000846085837110877,0.0005966660683043301,0.0006868114578537643,0.000734667235519737,0.0007337885326705873,0.0004949472495354712,0.00045671535190194845,0.0006589593249373138,0.0007861313060857356,0.0005744178779423237,0.00040528926183469594,0.0003993875870946795,0.00042062706779688597,0.00042778599890880287,0.0007140226662158966,0.0004829431709367782,0.00032676607952453196,0.00037318718386814,0.000616254226770252,0.0004229928890708834,0.00026600583805702627,0.0005021995166316628,0.0005317566683515906,0.0004161788965575397,0.00033422597334720194,0.00033280852949246764,0.0002506979799363762,0.0002458047529216856,0.0002711992710828781,0.00038889795541763306,0.000497502856887877,0.0003835555980913341,0.0003054610569961369,0.0003285919956397265,0.00037878009607084095,0.0003961297043133527,0.0003505450440570712,0.0003064080374315381,0.0002364332613069564,0.00020644602773245424,0.00022062472999095917,0.0002440183743601665,0.0001994166086660698,0.00033014907967299223,0.0002716740418691188,0.00015845410234760493,
mae,0.6316540241241455,0.11878901720046997,0.10643459111452103,0.10331042110919952,0.103814497590065,0.100313700735569,0.09749291092157364,0.0938771441578865,0.090908482670784,0.08951511979103088,0.08630639314651489,0.08296060562133789,0.07943461090326309,0.07686448842287064,0.07312340289354324,0.07265328615903854,0.07194335013628006,0.06958547234535217,0.06852526217699051,0.06801577657461166,0.06678758561611176,0.06684957444667816,0.06597192585468292,0.06412400305271149,0.061898134648799896,0.06858761608600616,0.06889718770980835,0.058026887476444244,0.04913743585348129,0.053783416748046875,0.045424990355968475,0.050060342997312546,0.049029525369405746,0.03826168179512024,0.03430825099349022,0.03441601246595383,0.03526248782873154,0.04064842313528061,0.037610992789268494,0.031194670125842094,0.03158508241176605,0.028834659606218338,0.026736048981547356,0.02614729478955269,0.028139784932136536,0.031136011704802513,0.029055653139948845,0.02706686221063137,0.02612529695034027,0.022634992375969887,0.020275048911571503,0.021591048687696457,0.030495116487145424,0.027749281376600266,0.02395850233733654,0.018753837794065475,0.020723678171634674,0.022217262536287308,0.02142006903886795,0.017010722309350967,0.0168955996632576,0.020380975678563118,0.02314915508031845,0.017714980989694595,0.01683155633509159,0.0156142832711339,0.015720807015895844,0.016423586755990982,0.02125154435634613,0.017833977937698364,0.01427972037345171,0.015442843548953533,0.0200666356831789,0.016061782836914062,0.012606360018253326,0.01780657470226288,0.018946779891848564,0.01584019511938095,0.014246848411858082,0.014658492058515549,0.012927519157528877,0.012014270760118961,0.012765730731189251,0.015817027539014816,0.017855539917945862,0.015810858458280563,0.013662955723702908,0.014356127008795738,0.015841837972402573,0.01589813642203808,0.014782126992940903,0.013330024667084217,0.012071565724909306,0.011318539269268513,0.011594841256737709,0.012597691267728806,0.01144833117723465,0.014001691713929176,0.012830915860831738,0.009828110225498676,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 91563     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 91564     
=================================================================
Total params: 183,127
Trainable params: 183,127
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 91,563
Trainable params: 91,563
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 91,564
Trainable params: 91,564
Non-trainable params: 0
_________________________________________________________________
