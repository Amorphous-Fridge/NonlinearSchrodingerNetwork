2021-06-26
loss,0.5481693148612976,0.15400342643260956,0.09601906687021255,0.09384890645742416,0.06930270791053772,0.06187496334314346,0.0574275441467762,0.054231833666563034,0.05447101220488548,0.0759553611278534,0.06759677827358246,0.07162252813577652,0.06483720242977142,0.06319025158882141,0.08984020352363586,0.0668628141283989,0.0795748308300972,0.07784652709960938,0.07005101442337036,0.06403064727783203,0.05711297690868378,0.05128208175301552,0.042959198355674744,0.04832625389099121,0.04674870893359184,0.03509899973869324,0.03370346501469612,0.0325654111802578,0.03174038976430893,0.03158311918377876,0.03135032579302788,0.030701391398906708,0.031016774475574493,0.030608143657445908,0.030934827402234077,0.045102640986442566,0.04359668865799904,0.04471836984157562,0.04801437258720398,0.0477336160838604,0.04375781491398811,0.03767525032162666,0.054752416908741,0.0585767924785614,0.0535937175154686,0.04857783764600754,0.04368230700492859,0.0409119576215744,0.03779657930135727,0.03532297909259796,0.033267006278038025,0.03181172534823418,0.040984317660331726,0.05077745392918587,0.051446978002786636,0.04234312102198601,0.02702029049396515,0.02617604285478592,0.02551005780696869,0.02511800080537796,0.024529464542865753,0.024204783141613007,0.024143502116203308,0.02388235367834568,0.023746857419610023,0.023496782407164574,0.023318173363804817,0.023410320281982422,0.02301645465195179,0.023076754063367844,0.023009246215224266,0.02277185209095478,0.022931501269340515,0.02285168133676052,0.02233428880572319,0.022855091840028763,0.022477805614471436,0.025045419111847878,0.0402337983250618,0.038120854645967484,0.03923414647579193,0.04353516176342964,0.04036814346909523,0.03671261668205261,0.03210587799549103,0.028563635423779488,0.025728652253746986,0.027034146711230278,0.040365446358919144,0.037685129791498184,0.03499099612236023,0.030814649537205696,0.02819141000509262,0.027052292600274086,0.024282138794660568,0.037467800080776215,0.03654279559850693,0.03141328692436218,0.029199980199337006,0.03223206847906113,
mse,0.1530972570180893,0.008439848199486732,0.0027125380001962185,0.002640692051500082,0.0013396622380241752,0.0010582157410681248,0.0009348465246148407,0.0008363364613614976,0.0009089921368286014,0.0016528012929484248,0.00130145950242877,0.0014263854827731848,0.0011577451368793845,0.0011644735932350159,0.002320340368896723,0.0013152435421943665,0.0017926895525306463,0.0016667863819748163,0.0013549854047596455,0.0011329021072015166,0.0008964387234300375,0.0007296400726772845,0.0005176618578843772,0.0007057687034830451,0.00062625139253214,0.0003391602367628366,0.00031102969660423696,0.00029044991242699325,0.0002741080243140459,0.00027152776601724327,0.0002672852424439043,0.000259624095633626,0.00026117608649656177,0.00025631458265706897,0.0002637963043525815,0.0006080000312067568,0.0005654223496094346,0.0005606418708339334,0.0006563388742506504,0.0006138281314633787,0.0005200439481996,0.0003912406100425869,0.0008753841975703835,0.0009705762495286763,0.0008000420057214797,0.0006467780331149697,0.0005217788275331259,0.00045691023115068674,0.00039711888530291617,0.00034776583197526634,0.0003059931914322078,0.00027961248997598886,0.0004910998395644128,0.0007076263427734375,0.0007381491595879197,0.0005445763817988336,0.00021209103579167277,0.00019563655951060355,0.00018068270583171397,0.00017114564252551645,0.00016334623796865344,0.00015858492406550795,0.0001575709175085649,0.00015381905541289598,0.00015213315782602876,0.00014906786964274943,0.00014648196520283818,0.0001478349295211956,0.00014259890303947031,0.00014368706615641713,0.00014248107618186623,0.00013918036711402237,0.00014206432388164103,0.0001406521478202194,0.000134023284772411,0.00014195533003658056,0.00013588224828708917,0.00017208278586622328,0.0004769667284563184,0.00041923223761841655,0.00043711066246032715,0.0005567268817685544,0.00044123243424110115,0.00036711993743665516,0.00028145627584308386,0.00022559154604095966,0.00018584722420200706,0.00021905210451222956,0.0004572932666633278,0.00039065684541128576,0.0003360339323990047,0.0002614142431411892,0.00021807788289152086,0.00020055269123986363,0.00017023264081217349,0.0003933645784854889,0.0003821940044872463,0.0002747280232142657,0.00024252431467175484,0.00028626021230593324,
mae,0.2324436604976654,0.06628905981779099,0.04062998667359352,0.03985048457980156,0.029515964910387993,0.026521766558289528,0.024500232189893723,0.02283291332423687,0.023224029690027237,0.032577402889728546,0.02915005199611187,0.030732203274965286,0.028433894738554955,0.026577167212963104,0.037790339440107346,0.028733499348163605,0.034171756356954575,0.034210361540317535,0.03125031664967537,0.02734396420419216,0.024950386956334114,0.02230030857026577,0.018489966168999672,0.020678885281085968,0.01997743919491768,0.015504573471844196,0.014976170845329762,0.014505577273666859,0.013701265677809715,0.013651853427290916,0.013434560038149357,0.012986226938664913,0.013331745751202106,0.013109451159834862,0.013219336047768593,0.01942785456776619,0.01870083622634411,0.019153563305735588,0.020760511979460716,0.020675869658589363,0.019056353718042374,0.016016116365790367,0.02401665225625038,0.02681322768330574,0.02474796772003174,0.021156253293156624,0.018643951043486595,0.016721129417419434,0.014398208819329739,0.013930623419582844,0.013794997707009315,0.013606076128780842,0.01674136146903038,0.021724507212638855,0.022978994995355606,0.018393486738204956,0.011472025886178017,0.011188034899532795,0.011186320334672928,0.011094042100012302,0.010762631893157959,0.010243721306324005,0.010442264378070831,0.010169118642807007,0.010132973082363605,0.009965687990188599,0.009977112524211407,0.010142561979591846,0.00996256060898304,0.009834185242652893,0.009864500723779202,0.009782099165022373,0.009799743071198463,0.009907813742756844,0.009581273421645164,0.009723993949592113,0.009663986973464489,0.01069237943738699,0.01719040237367153,0.016460144892334938,0.0160951130092144,0.019121533259749413,0.017541101202368736,0.014656208455562592,0.013561056926846504,0.01220737211406231,0.01092449203133583,0.011532030999660492,0.017425956204533577,0.016961900517344475,0.015698140487074852,0.013276135548949242,0.012162902392446995,0.01142765861004591,0.010348889045417309,0.01607084460556507,0.01603144221007824,0.013373259454965591,0.012493631802499294,0.01335960067808628,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9259      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9260      
=================================================================
Total params: 18,519
Trainable params: 18,519
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 9,259
Trainable params: 9,259
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 9,260
Trainable params: 9,260
Non-trainable params: 0
_________________________________________________________________
