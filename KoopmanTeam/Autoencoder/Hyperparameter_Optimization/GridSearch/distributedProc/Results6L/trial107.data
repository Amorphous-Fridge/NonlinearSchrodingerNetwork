2021-06-26
loss,2.5796923637390137,2.2381346225738525,2.0610158443450928,0.5134252309799194,0.44473373889923096,0.44468510150909424,0.4446060061454773,0.4448593556880951,0.44474491477012634,0.44498616456985474,0.4449045956134796,0.4439988434314728,0.4453987777233124,0.4455189108848572,0.44521644711494446,0.4449683129787445,0.4456668198108673,0.44485270977020264,0.4449518620967865,0.44528868794441223,0.44489285349845886,0.44538888335227966,0.4455389082431793,0.44464629888534546,0.4455561935901642,0.44531214237213135,0.44529613852500916,0.4449763000011444,0.44509774446487427,0.44485148787498474,0.4449101388454437,0.4457210302352905,0.4451492428779602,0.44580554962158203,0.4448796510696411,0.44534385204315186,0.44493454694747925,0.44518357515335083,0.44537609815597534,0.4451329708099365,0.4456344544887543,0.44543951749801636,0.44510048627853394,0.44540104269981384,0.4450789988040924,0.4447343349456787,0.4451928436756134,0.4455632269382477,0.444896399974823,0.4446691870689392,0.4448774755001068,0.44576942920684814,0.44476330280303955,0.44447776675224304,0.44450101256370544,0.4449465870857239,0.4446392357349396,0.44568467140197754,0.4445815980434418,0.4450939893722534,0.4444209039211273,0.4444788098335266,0.4444984793663025,0.44540300965309143,0.44441330432891846,0.44514229893684387,0.44525328278541565,0.44538792967796326,0.44499891996383667,0.44479137659072876,0.4449763000011444,0.4449181854724884,0.4445161819458008,0.4450303614139557,0.4455690383911133,0.4451879560947418,0.44520020484924316,0.4449387788772583,0.4445812702178955,0.44501417875289917,0.44480177760124207,0.4444737732410431,0.4450298547744751,0.44448429346084595,0.4456319510936737,0.44464433193206787,0.44510865211486816,0.4453963339328766,0.44491657614707947,0.44494426250457764,0.44513460993766785,0.44447818398475647,0.445182204246521,0.44431358575820923,0.44509395956993103,0.4447413980960846,0.4451409578323364,0.4449191391468048,0.44549059867858887,0.44506320357322693,
mse,1.7807345390319824,1.2652876377105713,1.1143566370010376,0.07811330258846283,0.05513625964522362,0.05512891709804535,0.05507437139749527,0.0551457405090332,0.0551278255879879,0.055149901658296585,0.055162325501441956,0.054986387491226196,0.055248845368623734,0.05530412495136261,0.05521893501281738,0.05518738180398941,0.055318403989076614,0.055134087800979614,0.055138178169727325,0.05523797869682312,0.05517897754907608,0.05524890869855881,0.05530261620879173,0.05510071665048599,0.055301498621702194,0.05522787198424339,0.05524185299873352,0.0551963672041893,0.05522138997912407,0.05518408119678497,0.05517555773258209,0.05534695088863373,0.055205024778842926,0.05534730479121208,0.05515448749065399,0.055264249444007874,0.05515202879905701,0.055224038660526276,0.05527351051568985,0.05523286387324333,0.055307697504758835,0.055278144776821136,0.055198196321725845,0.05526944249868393,0.05519793927669525,0.055144939571619034,0.055196646600961685,0.055267125368118286,0.055144838988780975,0.05509454756975174,0.05517525598406792,0.055347513407468796,0.05511631816625595,0.05505077540874481,0.055067431181669235,0.05517853423953056,0.05506942793726921,0.05533197522163391,0.05511319637298584,0.05517564341425896,0.05507109314203262,0.055051594972610474,0.055078569799661636,0.05526475980877876,0.0550452321767807,0.05520406737923622,0.05524543672800064,0.05527682602405548,0.055161360651254654,0.05512857064604759,0.055169928818941116,0.05513584613800049,0.0550706572830677,0.05519286170601845,0.05527597293257713,0.05523372069001198,0.05522109195590019,0.05515744164586067,0.055095791816711426,0.05520010367035866,0.05511638522148132,0.05507451668381691,0.055167414247989655,0.05507964268326759,0.055296268314123154,0.055117085576057434,0.05518574267625809,0.055270466953516006,0.05511745065450668,0.05515964329242706,0.05522254854440689,0.055049747228622437,0.055201493203639984,0.055022209882736206,0.05519779026508331,0.05512654781341553,0.05522115156054497,0.05515284091234207,0.055281076580286026,0.05519877374172211,
mae,0.980387270450592,0.6995144486427307,0.6867514252662659,0.22315415740013123,0.1972518414258957,0.1972377896308899,0.19725152850151062,0.1973780393600464,0.19725804030895233,0.19733212888240814,0.19731155037879944,0.1969268023967743,0.19751909375190735,0.197560653090477,0.1975114792585373,0.19734130799770355,0.19757065176963806,0.19728675484657288,0.19735369086265564,0.1974921077489853,0.19719994068145752,0.1974656730890274,0.1975952535867691,0.19714033603668213,0.19763502478599548,0.19743068516254425,0.19752980768680573,0.19732895493507385,0.19739633798599243,0.1972215473651886,0.19737842679023743,0.1976272165775299,0.19741682708263397,0.19763542711734772,0.19729068875312805,0.19752077758312225,0.19728972017765045,0.19746002554893494,0.19751638174057007,0.19733737409114838,0.19759979844093323,0.1975633054971695,0.19742025434970856,0.1975083351135254,0.19738352298736572,0.19723887741565704,0.1974668651819229,0.19761033356189728,0.19731813669204712,0.1971781700849533,0.19723661243915558,0.19770044088363647,0.19726991653442383,0.1971975564956665,0.1971372365951538,0.1973271518945694,0.19713088870048523,0.1976529061794281,0.1971946507692337,0.19735974073410034,0.19714152812957764,0.19710737466812134,0.19712352752685547,0.1975848376750946,0.19709521532058716,0.1974267065525055,0.19749696552753448,0.19752958416938782,0.19738736748695374,0.19728155434131622,0.19732436537742615,0.19732540845870972,0.19713039696216583,0.19750657677650452,0.19760575890541077,0.1974242627620697,0.19747714698314667,0.19731827080249786,0.1971791684627533,0.1973821073770523,0.19722619652748108,0.197169691324234,0.1973591297864914,0.1970806121826172,0.19761112332344055,0.19716809689998627,0.19740478694438934,0.19752201437950134,0.19730371236801147,0.1973341703414917,0.197416290640831,0.1971302181482315,0.19747032225131989,0.19709034264087677,0.19742988049983978,0.19722720980644226,0.19732868671417236,0.19728408753871918,0.19763940572738647,0.1974402815103531,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 542499    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 542500    
=================================================================
Total params: 1,084,999
Trainable params: 1,084,999
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 542,499
Trainable params: 542,499
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 542,500
Trainable params: 542,500
Non-trainable params: 0
_________________________________________________________________
