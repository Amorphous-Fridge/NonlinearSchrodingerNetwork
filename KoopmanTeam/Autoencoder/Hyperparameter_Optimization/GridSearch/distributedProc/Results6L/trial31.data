2021-06-26
loss,0.7529085278511047,0.2794327735900879,0.2565378248691559,0.24880681931972504,0.24500443041324615,0.24188606441020966,0.2415119707584381,0.23508864641189575,0.23096191883087158,0.22525674104690552,0.22423098981380463,0.22121697664260864,0.22015029191970825,0.21722978353500366,0.21238690614700317,0.207155242562294,0.20215171575546265,0.19689057767391205,0.19323356449604034,0.1910391002893448,0.1874307096004486,0.17976385354995728,0.17331023514270782,0.16671724617481232,0.16952337324619293,0.1440797597169876,0.14662548899650574,0.12227753549814224,0.12318456918001175,0.10476521402597427,0.10698157548904419,0.08001163601875305,0.06847568601369858,0.07377593964338303,0.06607620418071747,0.07979623228311539,0.05876182019710541,0.06224846839904785,0.05596728250384331,0.054671939462423325,0.056608304381370544,0.04838228225708008,0.05255287140607834,0.04981203377246857,0.041348546743392944,0.04047369584441185,0.04355277121067047,0.04143841564655304,0.03602021560072899,0.045417461544275284,0.051923394203186035,0.047531794756650925,0.03846122324466705,0.03247290477156639,0.03442177176475525,0.04025394469499588,0.0350494347512722,0.035989586263895035,0.04763243347406387,0.038136690855026245,0.03253098577260971,0.03565182536840439,0.037227388471364975,0.028890326619148254,0.04189455136656761,0.04055588319897652,0.0362151637673378,0.033843182027339935,0.033904995769262314,0.028054814785718918,0.025691969320178032,0.027127297595143318,0.03134510666131973,0.035699959844350815,0.037174057215452194,0.03302282840013504,0.028534406796097755,0.027689015492796898,0.023601341992616653,0.02086557075381279,0.020565981045365334,0.0235781017690897,0.02757767029106617,0.02696952410042286,0.027107346802949905,0.028436901047825813,0.032254159450531006,0.026435939595103264,0.02658192440867424,0.03166984021663666,0.019256575033068657,0.01902364380657673,0.019826561212539673,0.024688927456736565,0.027482280507683754,0.0302480086684227,0.03255467489361763,0.03380091115832329,0.026750417426228523,0.025202792137861252,
mse,0.28332236409187317,0.024194587022066116,0.021313412114977837,0.02054869383573532,0.02019447088241577,0.019828610122203827,0.01974177546799183,0.018993830308318138,0.018501149490475655,0.01780591905117035,0.01753849722445011,0.01715061254799366,0.016909204423427582,0.016588060185313225,0.015992332249879837,0.015336350537836552,0.014701375737786293,0.013993998989462852,0.013355057686567307,0.01286397222429514,0.012200876139104366,0.011309981346130371,0.010548778809607029,0.009519401006400585,0.009078685194253922,0.006736024748533964,0.00661309203132987,0.004625328350812197,0.004693328868597746,0.0034768006298691034,0.0033454573713243008,0.0019317187834531069,0.0014602714218199253,0.0016331837978214025,0.0012714761542156339,0.0018971828976646066,0.0010249788174405694,0.001142975059337914,0.0009175062878057361,0.0008936933591030538,0.0009441537549719214,0.0006761868135072291,0.0008404228719882667,0.0007233332726173103,0.0004869351105298847,0.0004684977466240525,0.0005636153509840369,0.00048812024760991335,0.00037747324677184224,0.0005860658129677176,0.0007952462765388191,0.0006356970407068729,0.0004170722095295787,0.00030266615794971585,0.00033745114342309535,0.00046520319301635027,0.00035312448744662106,0.00039466648013330996,0.0006323456182144582,0.00042938609840348363,0.0003073376137763262,0.0003557147865649313,0.0003966328513342887,0.0002428478328511119,0.0004858037573285401,0.000461441493825987,0.0003737851220648736,0.00032314169220626354,0.00032125975121743977,0.00023393273295369,0.0001936635235324502,0.00021616782760247588,0.0002769539423752576,0.0003579110198188573,0.00037985440576449037,0.0003118934982921928,0.00023571860219817609,0.00022018235176801682,0.0001629022735869512,0.00012511784734670073,0.00012139928730903193,0.00016488792607560754,0.0002199972077505663,0.0002095662639476359,0.0002064928994514048,0.00023380455968435854,0.00028737125103361905,0.00020227879576850682,0.0002167135098716244,0.00028126739198341966,0.00010875800944631919,0.00010359673615312204,0.00011494733189465478,0.00017846477567218244,0.00021989976812619716,0.0002577805717010051,0.0002948533510789275,0.00031961611239239573,0.00021082235616631806,0.00019601706298999488,
mae,0.3193386197090149,0.11785930395126343,0.10767702013254166,0.10474450886249542,0.10303782671689987,0.1016409620642662,0.10191542655229568,0.10109999775886536,0.10155785828828812,0.10185002535581589,0.1024293452501297,0.10145201534032822,0.10059152543544769,0.0988888144493103,0.09599553048610687,0.09293363243341446,0.08947684615850449,0.08571138232946396,0.08251465111970901,0.08092109858989716,0.07924163341522217,0.07616479694843292,0.07350527495145798,0.070639468729496,0.07233419269323349,0.06101664528250694,0.0620153434574604,0.05203615128993988,0.052715372294187546,0.043774962425231934,0.045914310961961746,0.03434082120656967,0.029552970081567764,0.03156881034374237,0.027907593175768852,0.03382834047079086,0.024848680943250656,0.026624031364917755,0.02316083200275898,0.023120000958442688,0.02422650344669819,0.02010807767510414,0.02273738384246826,0.02125939168035984,0.017480986192822456,0.01748797856271267,0.018689965829253197,0.017428943887352943,0.015090787783265114,0.01888234168291092,0.02249881438910961,0.020846962928771973,0.016847800463438034,0.013613513670861721,0.014580721035599709,0.01727638579905033,0.014752406626939774,0.015522262081503868,0.021154260262846947,0.016545705497264862,0.013606800697743893,0.015193742699921131,0.015661846846342087,0.012271051295101643,0.017889024689793587,0.01796053908765316,0.015565467067062855,0.0142639996483922,0.014505025930702686,0.011943026445806026,0.01071877684444189,0.011659231968224049,0.013464919291436672,0.015518996864557266,0.01653168722987175,0.014592302031815052,0.012106996960937977,0.011889982037246227,0.010050032287836075,0.008825570344924927,0.008786891587078571,0.01012630108743906,0.011867878027260303,0.011477343738079071,0.011397182010114193,0.012050993740558624,0.013853534124791622,0.011306613683700562,0.011459456756711006,0.013523340225219727,0.008253094740211964,0.008228271268308163,0.0084049291908741,0.010476776398718357,0.011803444474935532,0.013225126080214977,0.013623693957924843,0.01498993020504713,0.011562593281269073,0.01070432923734188,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 91563     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 91564     
=================================================================
Total params: 183,127
Trainable params: 183,127
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 91,563
Trainable params: 91,563
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 91,564
Trainable params: 91,564
Non-trainable params: 0
_________________________________________________________________
