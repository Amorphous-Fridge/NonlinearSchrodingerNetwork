2021-06-26
loss,0.39343562722206116,0.24059686064720154,0.2300974726676941,0.22337205708026886,0.21302179992198944,0.1471860259771347,0.13909940421581268,0.08322624117136002,0.09172715991735458,0.07056847214698792,0.07380550354719162,0.05214129388332367,0.04689817503094673,0.0443669855594635,0.042630720883607864,0.04088183492422104,0.03999578580260277,0.03912504017353058,0.03880878537893295,0.0372634157538414,0.0362192764878273,0.035914547741413116,0.03515978157520294,0.03478323295712471,0.03413383662700653,0.0341523252427578,0.03324350714683533,0.0327850803732872,0.03456246480345726,0.03327292576432228,0.05022679269313812,0.04920578375458717,0.05511258542537689,0.04595521464943886,0.039857957512140274,0.03735044598579407,0.04760049656033516,0.037973493337631226,0.03170062229037285,0.03160373866558075,0.033452216535806656,0.032123811542987823,0.031392887234687805,0.028289588168263435,0.02886618860065937,0.02817414328455925,0.027521399781107903,0.027528934180736542,0.027896160259842873,0.027048204094171524,0.026483410969376564,0.027565130963921547,0.02730676904320717,0.026880525052547455,0.026016412302851677,0.026205815374851227,0.025641154497861862,0.02694171480834484,0.025616314262151718,0.027021287009119987,0.026816468685865402,0.026052024215459824,0.04355165362358093,0.038867224007844925,0.05715363100171089,0.05044085904955864,0.044584497809410095,0.03813428804278374,0.03680075332522392,0.044139131903648376,0.04021220654249191,0.03620462119579315,0.03343615308403969,0.03175477311015129,0.030487654730677605,0.02910473383963108,0.03729475662112236,0.028273634612560272,0.035320479422807693,0.037677183747291565,0.03651847690343857,0.034954968839883804,0.03116619400680065,0.028972959145903587,0.047409698367118835,0.0437353141605854,0.04041704535484314,0.03987816721200943,0.03762897849082947,0.0354490764439106,0.03277597576379776,0.030314959585666656,0.028523527085781097,0.027117906138300896,0.026297347620129585,0.025466611608862877,0.024997370317578316,0.03942089527845383,0.03921298682689667,0.03669647127389908,
mse,0.05911024659872055,0.019830230623483658,0.018732160329818726,0.017947053536772728,0.016259459778666496,0.006946563255041838,0.005419197492301464,0.0021215295419096947,0.0024941861629486084,0.0014397912891581655,0.0015137633308768272,0.0007664588047191501,0.000620523001998663,0.0005516861565411091,0.0005027408478781581,0.0004663924628403038,0.0004428079118952155,0.0004243144067004323,0.0004184653516858816,0.00038816832238808274,0.0003619766212068498,0.00035351651604287326,0.00034055428113788366,0.0003318830276839435,0.0003205685061402619,0.0003200953942723572,0.0003015768015757203,0.00029544709832407534,0.0003295083297416568,0.000308409973513335,0.0007943803793750703,0.0007220315164886415,0.0008437998476438224,0.0005851226742379367,0.0004395910073071718,0.00039320107316598296,0.0006502680480480194,0.0004416471056174487,0.0002782633528113365,0.0002750827115960419,0.0003075611311942339,0.00028357424889691174,0.00027002152637578547,0.00021954906696919352,0.00022956327302381396,0.00023021400556899607,0.0002056848315987736,0.00020823614613618702,0.00021870594355277717,0.00020267313811928034,0.00019024626817554235,0.00021006475435569882,0.00021102820755913854,0.00019857019651681185,0.00018377223750576377,0.00018813187489286065,0.00017979246331378818,0.00020214483083691448,0.00018133941921405494,0.00020291056716814637,0.00019693453214131296,0.00018537721189204603,0.0005872189649380744,0.0004487282130867243,0.0009794335346668959,0.000846646202262491,0.0006088308873586357,0.00045806411071680486,0.00038925104308873415,0.0005845264531672001,0.0004645422741305083,0.0003565076331142336,0.0003067432844545692,0.0002751240972429514,0.00025372859090566635,0.00023066379071678966,0.0003994197759311646,0.00023604002490174025,0.00033919911948032677,0.0003922348842024803,0.00035971039324067533,0.00032782426569610834,0.00026387357502244413,0.00023019059153739363,0.0006656159530393779,0.000544011767487973,0.0004575724888127297,0.0004389810492284596,0.0003922000469174236,0.00034352202783338726,0.0002949655754491687,0.0002500414557289332,0.00022244798310566694,0.00020155217498540878,0.0001897319161798805,0.00017793424194678664,0.00017432848108001053,0.0004259372071828693,0.00042137582204304636,0.0003635594912339002,
mae,0.1672280728816986,0.10423259437084198,0.1056554913520813,0.10433673113584518,0.09839437156915665,0.06217946484684944,0.058809585869312286,0.034856367856264114,0.03902406245470047,0.029941754415631294,0.031394366174936295,0.02266833744943142,0.020450683310627937,0.019313916563987732,0.01830584742128849,0.0174751877784729,0.0171023141592741,0.016858654096722603,0.01661047153174877,0.015676043927669525,0.015572390519082546,0.015403056517243385,0.01494875643402338,0.014820429496467113,0.014799453318119049,0.014533527195453644,0.014232720248401165,0.01377667672932148,0.014633722603321075,0.014125043526291847,0.021286945790052414,0.021194512024521828,0.023401178419589996,0.02067401260137558,0.01752815768122673,0.016392365097999573,0.020331911742687225,0.01605692133307457,0.013785583898425102,0.01378600113093853,0.01452874019742012,0.013956258073449135,0.013460873626172543,0.012132992967963219,0.0124700628221035,0.012150202877819538,0.011882455088198185,0.011755951680243015,0.011891049332916737,0.011663701385259628,0.011255073361098766,0.011694713495671749,0.011570464819669724,0.011496367864310741,0.011272379197180271,0.011038676835596561,0.010930044576525688,0.011498513631522655,0.010828601196408272,0.011397991329431534,0.011357086710631847,0.011023108847439289,0.018772099167108536,0.01709425263106823,0.025675443932414055,0.02253035269677639,0.01873023994266987,0.016355598345398903,0.015664320439100266,0.01885584183037281,0.016920143738389015,0.01612141914665699,0.01501184981316328,0.01422226894646883,0.01340761873871088,0.012367907911539078,0.015780864283442497,0.012207074090838432,0.01488910336047411,0.016349561512470245,0.015913059934973717,0.015270871110260487,0.013333767652511597,0.012067406438291073,0.0209260955452919,0.019993647933006287,0.018052466213703156,0.017965344712138176,0.01699112541973591,0.015767408534884453,0.014340209774672985,0.012736533768475056,0.012088843621313572,0.01156330481171608,0.011205179616808891,0.010831048712134361,0.010696734301745892,0.016725638881325722,0.01764877699315548,0.016301032155752182,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 9555      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 9556      
=================================================================
Total params: 19,111
Trainable params: 19,111
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 9,555
Trainable params: 9,555
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 9,556
Trainable params: 9,556
Non-trainable params: 0
_________________________________________________________________
