2021-06-26
loss,2.2771761417388916,2.1838626861572266,1.5879141092300415,0.3519149124622345,0.227661594748497,0.15063850581645966,0.0924534797668457,0.08935479819774628,0.06858298927545547,0.07901369035243988,0.0734700933098793,0.08411476016044617,0.07123400270938873,0.053294289857149124,0.05967969447374344,0.059190958738327026,0.05310061573982239,0.048106346279382706,0.04417769983410835,0.03695114329457283,0.04709969460964203,0.05497973784804344,0.04663622006773949,0.04563581570982933,0.04123803600668907,0.037886716425418854,0.03672979399561882,0.03844854608178139,0.043696366250514984,0.045326124876737595,0.04363483563065529,0.04029614105820656,0.03466430678963661,0.03216836601495743,0.033454813063144684,0.03811640664935112,0.03938739746809006,0.035885848104953766,0.031004633754491806,0.02829991839826107,0.033902283757925034,0.04365745559334755,0.03917250409722328,0.03256993740797043,0.033124618232250214,0.03772260248661041,0.03423939645290375,0.030503278598189354,0.03522806987166405,0.03362594544887543,0.03384407237172127,0.03050198405981064,0.033278968185186386,0.03347018361091614,0.031364187598228455,0.032529208809137344,0.03064907155930996,0.030169028788805008,0.03159637749195099,0.032370712608098984,0.03032521717250347,0.028018847107887268,0.0322842113673687,0.027340266853570938,0.027052419260144234,0.028862036764621735,0.027755748480558395,0.026980170980095863,0.028893690556287766,0.030462658032774925,0.0231915470212698,0.024499230086803436,0.02571260742843151,0.02648358978331089,0.02741079032421112,0.025629863142967224,0.02383332885801792,0.03197930380702019,0.030018460005521774,0.028900615870952606,0.02654574066400528,0.025630084797739983,0.02249913290143013,0.024955784901976585,0.02861538901925087,0.029835760593414307,0.02728957124054432,0.024914562702178955,0.023855552077293396,0.022184142842888832,0.026158742606639862,0.028596781194210052,0.02443953976035118,0.022809524089097977,0.02385028824210167,0.029124662280082703,0.02442644163966179,0.023290086537599564,0.022251885384321213,0.020462505519390106,
mse,1.3226494789123535,1.2094459533691406,0.7305918335914612,0.037289734929800034,0.01669001393020153,0.006796365603804588,0.0025964302476495504,0.0023971362970769405,0.001406729919835925,0.0018889199709519744,0.0016032789135351777,0.0020318382885307074,0.0014750580303370953,0.0008528961334377527,0.001019896473735571,0.0010109141003340483,0.000804415438324213,0.0006578777101822197,0.000550802971702069,0.0003986633673775941,0.0006349728791974485,0.0008598579443059862,0.0006293625338003039,0.0006180225173011422,0.00047843944048509,0.00041696816333569586,0.0003971751721110195,0.00042871932964771986,0.0005442656693048775,0.0006008588243275881,0.0005605174810625613,0.0004483030643314123,0.0003392607031855732,0.00029520579846575856,0.00031811706139706075,0.00041331021930091083,0.0004500252252910286,0.00037423885078169405,0.00028489454416558146,0.0002352448063902557,0.0003354647778905928,0.0005474871722981334,0.00044253788655623794,0.0003084777563344687,0.00031502183992415667,0.0004016350721940398,0.0003373067593201995,0.000265894370386377,0.00036623270716518164,0.00031706521986052394,0.00033351097954437137,0.00026329662068746984,0.00031253680936060846,0.00032351689878851175,0.0002767899713944644,0.00030399064416997135,0.0002706890518311411,0.00025957287289202213,0.0002779803180601448,0.00029653526144102216,0.00027568620862439275,0.000224602670641616,0.0002939041587524116,0.00020540958212222904,0.00021466088946908712,0.00023451402375940233,0.00022004895436111838,0.00020353775471448898,0.000241939997067675,0.00027902773581445217,0.0001698957203188911,0.0001715524704195559,0.00019301968859508634,0.0002040727558778599,0.00021142218611203134,0.00018126770737580955,0.00016920798225328326,0.000296752987196669,0.00025615590857341886,0.00023805088130757213,0.00019540770153980702,0.00018329647718928754,0.00014758961333427578,0.00018102145986631513,0.00023027123825158924,0.0002491989580448717,0.00021370445028878748,0.00017597472469788045,0.00016192224575206637,0.00013885844964534044,0.00019966998661402613,0.00022993770835455507,0.00016813434194773436,0.00015064164472278208,0.0001603754353709519,0.00023922623950056732,0.00016380638408008963,0.00015280841034837067,0.0001450793497497216,0.0001249562919838354,
mae,0.8028658032417297,0.7069331407546997,0.6052951216697693,0.15194213390350342,0.09773454070091248,0.0622248612344265,0.03894183412194252,0.037245023995637894,0.028939956799149513,0.032649699598550797,0.030520249158143997,0.03561920300126076,0.029911858960986137,0.022300099954009056,0.024910282343626022,0.02518291398882866,0.022270068526268005,0.02068067342042923,0.018831497058272362,0.015703432261943817,0.020138375461101532,0.023451412096619606,0.01917870156466961,0.019513800740242004,0.01772407814860344,0.01628326252102852,0.01575338840484619,0.016679782420396805,0.01903492584824562,0.01967407390475273,0.018789110705256462,0.017483573406934738,0.015484286472201347,0.013874568045139313,0.014406229369342327,0.016189545392990112,0.01695866882801056,0.015249542891979218,0.013054344803094864,0.012076321057975292,0.01429391372948885,0.018678953871130943,0.01668228581547737,0.014012476429343224,0.014006209559738636,0.016089556738734245,0.014989354647696018,0.013036967255175114,0.015178115107119083,0.014431475661695004,0.014263611286878586,0.013081162236630917,0.013649575412273407,0.014003722928464413,0.013360362499952316,0.013766361400485039,0.012922166846692562,0.012955326586961746,0.013970952481031418,0.013688189908862114,0.013042759150266647,0.011935051530599594,0.013774705119431019,0.011672714725136757,0.011558277532458305,0.012411568313837051,0.011760915629565716,0.011445061303675175,0.012320568785071373,0.012973028235137463,0.009897192940115929,0.01033415924757719,0.010892982594668865,0.011214232072234154,0.011886297725141048,0.010935337282717228,0.010158313438296318,0.01388978585600853,0.012751663103699684,0.01251107919961214,0.011701426468789577,0.011135313659906387,0.009603774175047874,0.010620114393532276,0.012246907688677311,0.012732738628983498,0.011476886458694935,0.01057801116257906,0.010149269364774227,0.009311816655099392,0.010894618928432465,0.012293228879570961,0.010640320368111134,0.00969912763684988,0.01050654612481594,0.012569304555654526,0.010698564350605011,0.00991712138056755,0.009398724883794785,0.008712032809853554,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 117003    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 117004    
=================================================================
Total params: 234,007
Trainable params: 234,007
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 117,003
Trainable params: 117,003
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 117,004
Trainable params: 117,004
Non-trainable params: 0
_________________________________________________________________
