2021-06-26
loss,0.4824845492839813,0.23812144994735718,0.20744358003139496,0.1432947963476181,0.12961454689502716,0.06800450384616852,0.0862140953540802,0.06745991855859756,0.06094866618514061,0.053675007075071335,0.04986808821558952,0.04786155745387077,0.05861107259988785,0.051174335181713104,0.05452663078904152,0.043418169021606445,0.042104024440050125,0.054308414459228516,0.055890608578920364,0.04932300001382828,0.04674609750509262,0.04023073613643646,0.03695093095302582,0.03629721701145172,0.035999346524477005,0.04601479694247246,0.05449803173542023,0.05806908756494522,0.04595356062054634,0.03917650878429413,0.03476063907146454,0.041019853204488754,0.05515995994210243,0.05162298306822777,0.0458117350935936,0.04229884222149849,0.04213983193039894,0.03622050955891609,0.03119869902729988,0.02882317267358303,0.027904197573661804,0.02986404113471508,0.040656350553035736,0.04432729631662369,0.04325955733656883,0.03599727526307106,0.031947456300258636,0.029291938990354538,0.03898341581225395,0.041192732751369476,0.036208245903253555,0.030591316521167755,0.027218664065003395,0.025341784581542015,0.03282281383872032,0.03951530531048775,0.034562334418296814,0.03015768527984619,0.027491915971040726,0.03675892576575279,0.035697076469659805,0.03343367204070091,0.029362475499510765,0.025089552626013756,0.025085678324103355,0.030362330377101898,0.026686906814575195,0.0242416113615036,0.023062800988554955,0.023332323879003525,0.036081209778785706,0.03196913003921509,0.029470330104231834,0.0274795014411211,0.02522222511470318,0.023041458800435066,0.020967885851860046,0.021254239603877068,0.022534234449267387,0.025616157799959183,0.029416928067803383,0.034173816442489624,0.031181596219539642,0.028806986287236214,0.026986505836248398,0.025215627625584602,0.02305726520717144,0.021069491282105446,0.023129930719733238,0.030095089226961136,0.02800304815173149,0.025321578606963158,0.022917920723557472,0.026179546490311623,0.02312101610004902,0.01979789137840271,0.023398129269480705,0.028387198224663734,0.027003776282072067,0.02457568421959877,
mse,0.10935363173484802,0.01901889778673649,0.013026587665081024,0.005958652589470148,0.00486003328114748,0.001399764558300376,0.0021106069907546043,0.0013324795290827751,0.0010710019851103425,0.0008266443619504571,0.0007122928509488702,0.00067451864015311,0.0010201503755524755,0.0007803762564435601,0.0008595095714554191,0.0005460517131723464,0.0005126130999997258,0.0008600109140388668,0.0008877852815203369,0.0007102704839780927,0.0006311564357019961,0.00045500125270336866,0.0003892529057338834,0.0003775732184294611,0.00036862510023638606,0.0006671987939625978,0.0008215622510761023,0.0009324821294285357,0.0005803495878353715,0.00042388311703689396,0.00033947319025173783,0.0004854289873037487,0.0008837831555865705,0.0007406321237795055,0.0005754067678935826,0.0005144711467437446,0.0004920659121125937,0.0003584559599403292,0.00027127997600473464,0.00023407925618812442,0.0002215587010141462,0.0002645122876856476,0.0004649926850106567,0.0005391527083702385,0.0005126868491061032,0.0003571953857317567,0.0002895239449571818,0.0002484805590938777,0.0004484181117732078,0.00046582944924011827,0.0003608303959481418,0.0002555886749178171,0.0002065105945803225,0.00018083116447087377,0.0003199850907549262,0.00042859255336225033,0.00032795339939184487,0.00025503922370262444,0.0002170131920138374,0.0003817960969172418,0.0003482953179627657,0.0003052500542253256,0.0002416543138679117,0.00018108138465322554,0.0001841366320149973,0.00025581050431355834,0.00020129505719523877,0.0001722137094475329,0.0001558837539050728,0.00015955109847709537,0.00035761960316449404,0.00028145042597316206,0.0002381036611041054,0.00020778103498741984,0.0001791110262274742,0.00015213149890769273,0.00013012252748012543,0.00013068709813524038,0.00014928143355064094,0.00018281966913491488,0.00024288681743200868,0.00031930554541759193,0.00026492204051464796,0.00022777974663767964,0.000200590118765831,0.00017780836788006127,0.00015283543325494975,0.00013045848754700273,0.0001570684980833903,0.00024649107945151627,0.00021361563995014876,0.00017724215285852551,0.00015184510266408324,0.00018675730098038912,0.00014716456644237041,0.00011819317296613008,0.00015966971113812178,0.0002246640797238797,0.0001992608595173806,0.00016272766515612602,
mae,0.20757007598876953,0.10500892996788025,0.08878207951784134,0.061252616345882416,0.05458305403590202,0.028753245249390602,0.0368349589407444,0.02863621711730957,0.026098325848579407,0.022903790697455406,0.021146729588508606,0.020162977278232574,0.024712970480322838,0.021805845201015472,0.023244502022862434,0.018624434247612953,0.01818465068936348,0.02301928773522377,0.023750433698296547,0.021191604435443878,0.0198445376008749,0.017888862639665604,0.015957394614815712,0.015432871878147125,0.015369769185781479,0.02012157440185547,0.023147981613874435,0.025767894461750984,0.01933637261390686,0.016102319583296776,0.014283099211752415,0.017668908461928368,0.024157382547855377,0.022571800276637077,0.020063526928424835,0.017910875380039215,0.018000757321715355,0.015861008316278458,0.012896708212792873,0.012057318352162838,0.011886314488947392,0.012701979838311672,0.017256269231438637,0.019210297614336014,0.01942882128059864,0.016327405348420143,0.014391341246664524,0.01241410244256258,0.016699964180588722,0.017919015139341354,0.016061868518590927,0.013087940402328968,0.011304385960102081,0.010615281760692596,0.014212162233889103,0.017764132469892502,0.015523667447268963,0.013547923415899277,0.012259472161531448,0.015772541984915733,0.015713781118392944,0.014805796556174755,0.01301663275808096,0.010826069861650467,0.010640344582498074,0.01300831325352192,0.011296599172055721,0.009963513351976871,0.009529495611786842,0.009804163128137589,0.015598885715007782,0.013741514645516872,0.012967351824045181,0.011903258971869946,0.010659388266503811,0.009834391064941883,0.00885999295860529,0.008969674818217754,0.009581058286130428,0.010845116339623928,0.012788538821041584,0.015317359007894993,0.014137915335595608,0.012329502031207085,0.011168406344950199,0.010125299915671349,0.00951953511685133,0.008928066119551659,0.009874261915683746,0.012986275367438793,0.012242112308740616,0.011032100766897202,0.009974341839551926,0.011233260855078697,0.010100169107317924,0.008439780212938786,0.010141466744244099,0.012410726398229599,0.011798297986388206,0.011048268526792526,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25771     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25772     
=================================================================
Total params: 51,543
Trainable params: 51,543
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 25,771
Trainable params: 25,771
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 25,772
Trainable params: 25,772
Non-trainable params: 0
_________________________________________________________________
