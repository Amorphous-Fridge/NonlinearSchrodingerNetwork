2021-06-26
loss,3.418522357940674,2.2462568283081055,2.2207274436950684,2.220414400100708,2.2206621170043945,2.2203924655914307,2.2204458713531494,2.2192320823669434,2.217722177505493,2.219442367553711,2.1566355228424072,0.42861518263816833,0.3518444001674652,0.33767932653427124,0.3323242962360382,0.3130550682544708,0.3052195906639099,0.29717114567756653,0.29239726066589355,0.2863841652870178,0.2798044979572296,0.27497780323028564,0.26473018527030945,0.26697802543640137,0.27213025093078613,0.2632574141025543,0.26249533891677856,0.261197566986084,0.2508673071861267,0.24105730652809143,0.24700048565864563,0.2388174682855606,0.23788677155971527,0.23677074909210205,0.2306482493877411,0.23754921555519104,0.22677524387836456,0.21444816887378693,0.20121511816978455,0.17219427227973938,0.16297569870948792,0.15780764818191528,0.1485132873058319,0.14607442915439606,0.1419447362422943,0.13896168768405914,0.13506169617176056,0.1328323781490326,0.13008910417556763,0.12745718657970428,0.12707524001598358,0.12798413634300232,0.12445374578237534,0.1259475201368332,0.12092003226280212,0.1201697289943695,0.11925939470529556,0.11723970621824265,0.11549351364374161,0.11420144885778427,0.11624869704246521,0.11256903409957886,0.11235972493886948,0.10936672985553741,0.10753986239433289,0.10748185217380524,0.1101021021604538,0.11365675926208496,0.10500602424144745,0.10613610595464706,0.10490155965089798,0.10231120884418488,0.10560788959264755,0.10874877125024796,0.10174312442541122,0.1012982726097107,0.09986802190542221,0.10293716192245483,0.10553167015314102,0.10180577635765076,0.0995548665523529,0.098824642598629,0.10275530815124512,0.10084877908229828,0.09633905440568924,0.09792307019233704,0.09638629853725433,0.09726884216070175,0.0945749282836914,0.09513232856988907,0.09576628357172012,0.09512490034103394,0.0933709368109703,0.09452945739030838,0.09521491825580597,0.09343702346086502,0.09176801890134811,0.10124383866786957,0.09683143347501755,0.09837636351585388,
mse,3.319694757461548,1.274758219718933,1.2464057207107544,1.2461355924606323,1.246422290802002,1.2460505962371826,1.2461422681808472,1.2447962760925293,1.2430641651153564,1.245050072669983,1.3300710916519165,0.056746434420347214,0.0368298776447773,0.03459159657359123,0.03314412012696266,0.029891202226281166,0.028663968667387962,0.02719375304877758,0.026414282619953156,0.02539914660155773,0.024222979322075844,0.023380815982818604,0.021844755858182907,0.022136986255645752,0.02302723005414009,0.021497469395399094,0.02161496691405773,0.021324846893548965,0.019894689321517944,0.018505612388253212,0.01914246566593647,0.017983363941311836,0.017800547182559967,0.017643161118030548,0.016842080280184746,0.01755758747458458,0.01617889478802681,0.014184012077748775,0.012497787363827229,0.009584750980138779,0.008776555769145489,0.008300422690808773,0.007500790990889072,0.007283980026841164,0.006879076361656189,0.006603690795600414,0.006259796675294638,0.006102472078055143,0.005816085264086723,0.005610981490463018,0.005560937337577343,0.0056552523747086525,0.005356598645448685,0.005458652973175049,0.005143469665199518,0.005028958432376385,0.005004642065614462,0.0047935801558196545,0.004696787800639868,0.004595217294991016,0.004710585810244083,0.004487540572881699,0.004394236020743847,0.004250263795256615,0.004136153031140566,0.0041483440436422825,0.004248855169862509,0.004522825591266155,0.003966290038079023,0.004054949153214693,0.0039174058474600315,0.0037653138861060143,0.00398942269384861,0.004162379540503025,0.003798371646553278,0.0037421686574816704,0.003632836975157261,0.003931976854801178,0.004045193083584309,0.003832724876701832,0.0036201532930135727,0.003503213170915842,0.0037710287142544985,0.0036509099882096052,0.0033647639211267233,0.0034646932035684586,0.003336976282298565,0.0033566481433808804,0.00322341313585639,0.0032817733008414507,0.0033641646150499582,0.003279754426330328,0.003161155851557851,0.003183594672009349,0.003277289681136608,0.0031373563688248396,0.0030678617767989635,0.0034627765417099,0.0031661423854529858,0.00315324729308486,
mae,1.4622308015823364,0.7020784020423889,0.6554623246192932,0.6535325050354004,0.6526230573654175,0.6527178883552551,0.6528783440589905,0.6508942246437073,0.6500453352928162,0.6514825224876404,0.8245111703872681,0.18509802222251892,0.153972327709198,0.14711938798427582,0.14333133399486542,0.13430438935756683,0.13214467465877533,0.12956532835960388,0.12741129100322723,0.124407097697258,0.12120312452316284,0.11892744898796082,0.11447092145681381,0.11551090329885483,0.1177196279168129,0.11422184854745865,0.11401788890361786,0.1131134033203125,0.10882135480642319,0.10450908541679382,0.10706697404384613,0.10386701673269272,0.10335202515125275,0.10293684154748917,0.1005234345793724,0.10314017534255981,0.09819100052118301,0.09239350259304047,0.08628977835178375,0.07338918000459671,0.06903007626533508,0.0666089802980423,0.06228625774383545,0.060967620462179184,0.05919237062335014,0.05761775001883507,0.05577520281076431,0.05478373169898987,0.05360134690999985,0.052280642092227936,0.05249433219432831,0.05263920873403549,0.05126634240150452,0.05220729857683182,0.049823082983493805,0.0495014488697052,0.049324944615364075,0.04847694933414459,0.047705940902233124,0.047188423573970795,0.04826738312840462,0.04653574898838997,0.046227943152189255,0.04504657909274101,0.044295042753219604,0.04434811696410179,0.04583194851875305,0.04701968654990196,0.04316176474094391,0.04394514858722687,0.043345365673303604,0.04220268875360489,0.043887387961149216,0.045438095927238464,0.04210490733385086,0.04191460460424423,0.04140772297978401,0.04297268018126488,0.04428790882229805,0.0425143726170063,0.041399091482162476,0.04076877981424332,0.042807407677173615,0.04187812656164169,0.03974922001361847,0.04055807739496231,0.03972085565328598,0.04011344909667969,0.0387529581785202,0.039513878524303436,0.03981022909283638,0.03954978287220001,0.03847314044833183,0.0389811173081398,0.03951311856508255,0.038373399525880814,0.03803429752588272,0.04246799647808075,0.040683239698410034,0.04146891459822655,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 550819    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 550820    
=================================================================
Total params: 1,101,639
Trainable params: 1,101,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 550,819
Trainable params: 550,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 550,820
Trainable params: 550,820
Non-trainable params: 0
_________________________________________________________________
