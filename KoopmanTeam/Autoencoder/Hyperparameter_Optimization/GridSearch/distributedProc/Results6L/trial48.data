2021-06-26
loss,0.9761771559715271,0.23829513788223267,0.15874558687210083,0.14820018410682678,0.1115606278181076,0.08916053175926208,0.08417606353759766,0.09304885566234589,0.07934918254613876,0.08924330025911331,0.07721726596355438,0.064017653465271,0.07018713653087616,0.058240920305252075,0.06546507030725479,0.05497265234589577,0.05286850035190582,0.05180326849222183,0.052417367696762085,0.04365872964262962,0.05784561485052109,0.04676464945077896,0.04400118812918663,0.04279046133160591,0.04070604220032692,0.046779535710811615,0.04822657257318497,0.040416937321424484,0.03971067816019058,0.046042341738939285,0.037711385637521744,0.032954201102256775,0.03758824244141579,0.036684151738882065,0.03597560152411461,0.038293808698654175,0.03386258706450462,0.03653855249285698,0.037063512951135635,0.03236372396349907,0.02911844663321972,0.029665298759937286,0.0288926362991333,0.034491050988435745,0.036454807966947556,0.036124907433986664,0.03419790416955948,0.031994543969631195,0.03387627378106117,0.030075976625084877,0.034433215856552124,0.030322665348649025,0.034128881990909576,0.03586900979280472,0.03261294960975647,0.030021579936146736,0.02828996628522873,0.028696604073047638,0.028223490342497826,0.03175579383969307,0.03394005447626114,0.030605971813201904,0.029111575335264206,0.028362998738884926,0.026605995371937752,0.026666706427931786,0.030517663806676865,0.027424538508057594,0.02885022945702076,0.02117098867893219,0.024274401366710663,0.02556987851858139,0.028747491538524628,0.030488284304738045,0.028918486088514328,0.028552541509270668,0.030048225075006485,0.027365760877728462,0.026039566844701767,0.025374460965394974,0.029369087889790535,0.02538476698100567,0.024640271440148354,0.018385451287031174,0.0244702510535717,0.022581687197089195,0.026627350598573685,0.024903398007154465,0.023183584213256836,0.025057265534996986,0.02575903944671154,0.023935573175549507,0.025958361104130745,0.023083509877324104,0.02288208156824112,0.024770744144916534,0.027245547622442245,0.024223268032073975,0.027213124558329582,0.02313391864299774,
mse,0.43023014068603516,0.01734228804707527,0.0076446812599897385,0.006614725571125746,0.0037207186687737703,0.0023787873797118664,0.002102877013385296,0.002593902638182044,0.001827721600420773,0.00228521297685802,0.001768719987012446,0.0011851389426738024,0.0014043845003470778,0.0009809733601287007,0.0012285989942029119,0.0009133754065260291,0.0008217093418352306,0.0007820550817996264,0.0007784349727444351,0.0005614521214738488,0.0009468374191783369,0.0006392505019903183,0.0005570779903791845,0.0005088333855383098,0.00048122406587935984,0.0006252734456211329,0.00065991299925372,0.00046832376392558217,0.00045900032273493707,0.0005915519432164729,0.0004242914146743715,0.0003237214987166226,0.0004083645762875676,0.00039228395326063037,0.0003906136844307184,0.0004209822800476104,0.00033142341999337077,0.00038286123890429735,0.0003946489014197141,0.00030131632229313254,0.00025195462512783706,0.0002560313732828945,0.00024700918584130704,0.0003508543595671654,0.00039241201011464,0.00036902169813401997,0.00034384176251478493,0.00029348742100410163,0.000330791634041816,0.0002626467903610319,0.0003370855120010674,0.000266537768766284,0.0003319712704978883,0.00036087847547605634,0.0003028155188076198,0.00025801645824685693,0.00023054881603457034,0.00023853826860431582,0.00022733246441930532,0.00029392141732387245,0.00032559316605329514,0.00026498158695176244,0.000240524357650429,0.00022690345940645784,0.0002070514892693609,0.00020797854813281447,0.0002703497593756765,0.00021634565200656652,0.00023920024977996945,0.00013626414875034243,0.0001719677384244278,0.00019315896497573704,0.00024202896747738123,0.00026340826298110187,0.00023611959477420896,0.0002296244347235188,0.0002557171683292836,0.00021475725225172937,0.00019679739489220083,0.00019277319370303303,0.00024305505212396383,0.00018358974193688482,0.00017546050366945565,0.00010284013842465356,0.00017268111696466804,0.00014892785111442208,0.0001982867397600785,0.00018311334133613855,0.00015564421482849866,0.00018271396402269602,0.00019029514805879444,0.00016610701277386397,0.00019267895550001413,0.0001535383053123951,0.0001496258337283507,0.0001800858008209616,0.00021471477521117777,0.00017231624224223197,0.00021131528774276376,0.00015666541003156453,
mae,0.4109479784965515,0.10113044083118439,0.06696593761444092,0.06124842166900635,0.04850643500685692,0.03787790238857269,0.03600579500198364,0.03970709815621376,0.03346579149365425,0.03830555081367493,0.03231821954250336,0.02736213058233261,0.030089013278484344,0.02502421662211418,0.02798333577811718,0.02258121408522129,0.02222396433353424,0.02229810319840908,0.022631265223026276,0.0189274400472641,0.024482514709234238,0.019841380417346954,0.018436022102832794,0.018203094601631165,0.017477715387940407,0.019894465804100037,0.020860500633716583,0.017550909891724586,0.0167856365442276,0.01923389732837677,0.01616842672228813,0.013800992630422115,0.01603011041879654,0.015519483014941216,0.015387261286377907,0.016591090708971024,0.014424172230064869,0.015298288315534592,0.01612589880824089,0.013858722522854805,0.0124848373234272,0.012432600371539593,0.01232365146279335,0.014772423543035984,0.015422677621245384,0.015579622238874435,0.01452404260635376,0.013453297317028046,0.01437121257185936,0.012893122620880604,0.014789991080760956,0.013120464980602264,0.014567086473107338,0.015031643211841583,0.013330609537661076,0.012624267488718033,0.011936110444366932,0.012158018536865711,0.011956442147493362,0.013516603969037533,0.014650200493633747,0.01291506178677082,0.012232406996190548,0.011946468614041805,0.011326992884278297,0.011245300993323326,0.012921067886054516,0.01171815674751997,0.012227552942931652,0.008973740972578526,0.010304015129804611,0.010881524533033371,0.012045575305819511,0.012740355916321278,0.012168269604444504,0.011941906064748764,0.012967762537300587,0.011201908811926842,0.010797213762998581,0.010800724849104881,0.012608661316335201,0.010927479714155197,0.010410679504275322,0.007851963862776756,0.010248728096485138,0.009586132131516933,0.011274214833974838,0.010355238802731037,0.009910748340189457,0.010478773154318333,0.010793101042509079,0.010207649320363998,0.011026694439351559,0.009862643666565418,0.009740814566612244,0.01062460895627737,0.011452245526015759,0.010275350883603096,0.011923713609576225,0.009903385303914547,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 133963    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 133964    
=================================================================
Total params: 267,927
Trainable params: 267,927
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 133,963
Trainable params: 133,963
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 133,964
Trainable params: 133,964
Non-trainable params: 0
_________________________________________________________________
