2021-06-26
loss,2.6407504081726074,0.8717847466468811,0.3220628798007965,0.261106938123703,0.24833278357982635,0.2403986155986786,0.23505157232284546,0.2013571709394455,0.13325923681259155,0.1403685063123703,0.11576057225465775,0.11919615417718887,0.12271258234977722,0.12832529842853546,0.0774923712015152,0.08932662010192871,0.0849684327840805,0.08444415777921677,0.09181106835603714,0.06612233817577362,0.06927400827407837,0.06665558367967606,0.0813835933804512,0.07765819132328033,0.06474228203296661,0.06584164500236511,0.05969977751374245,0.09341535717248917,0.07583712786436081,0.0700019896030426,0.08854375779628754,0.07746241241693497,0.053152259439229965,0.048708897083997726,0.06814929842948914,0.07511425018310547,0.0573565773665905,0.05006164684891701,0.0424327552318573,0.05567515268921852,0.069362573325634,0.057131577283144,0.04204577952623367,0.037526924163103104,0.040474146604537964,0.04622482880949974,0.04410028085112572,0.04622675105929375,0.04077298194169998,0.0423944853246212,0.04050132632255554,0.048328302800655365,0.04156282916665077,0.0408276803791523,0.05496945232152939,0.06424853205680847,0.052067022770643234,0.03407624363899231,0.03538407012820244,0.03654489666223526,0.03813576325774193,0.03383976221084595,0.05285392329096794,0.057951707392930984,0.05270149186253548,0.03991897031664848,0.03966109827160835,0.03857927396893501,0.048356957733631134,0.05340595170855522,0.04524732008576393,0.04023868963122368,0.047431591898202896,0.0375562347471714,0.04674306884407997,0.04856378585100174,0.0386265404522419,0.03281082957983017,0.03469562530517578,0.030324654653668404,0.03389047086238861,0.04827653244137764,0.03972235321998596,0.047438401728868484,0.045467447489500046,0.03764807805418968,0.04524160549044609,0.03069554641842842,0.033878669142723083,0.0336628332734108,0.03932904079556465,0.040094032883644104,0.04433238506317139,0.0329224094748497,0.041607361286878586,0.0377560630440712,0.029644209891557693,0.04023868590593338,0.03992566093802452,0.037575580179691315,
mse,2.6625561714172363,0.24708421528339386,0.031336188316345215,0.021751107648015022,0.020416608080267906,0.019288932904601097,0.017897330224514008,0.01226997934281826,0.0052268593572080135,0.006261204369366169,0.003960023634135723,0.004234881605952978,0.0047527155838906765,0.004999970085918903,0.001688402029685676,0.0025135958567261696,0.0022079891059547663,0.002257058396935463,0.002610327210277319,0.001255962299183011,0.0013985632685944438,0.0013303946470841765,0.0018940626177936792,0.001723298104479909,0.0012621528003364801,0.0012773071648553014,0.001070312806405127,0.0025557666085660458,0.0017367122927680612,0.0014902673428878188,0.002182275988161564,0.0016932017169892788,0.0008893929189071059,0.0006971612456254661,0.0013544009998440742,0.0016032394487410784,0.000976250390522182,0.0007243486470542848,0.0005192101234570146,0.0009414088563062251,0.001311893342062831,0.0009702902752906084,0.0005144615424796939,0.0004131949390284717,0.00048513972433283925,0.000629061134532094,0.0005873493500985205,0.0006288842996582389,0.0004968514549545944,0.0005503695574589074,0.0005176007398404181,0.0007320123258978128,0.0004999982193112373,0.0005126413889229298,0.0008990290225483477,0.0011250234674662352,0.0007921513170003891,0.00034205717383883893,0.00036262013600207865,0.0003938656591344625,0.00042389967711642385,0.00032734760316088796,0.0008230208768509328,0.0009248078567907214,0.0007830593967810273,0.0004827375814784318,0.00046383938752114773,0.0004260351415723562,0.0006877573323436081,0.0007761511951684952,0.0005951717030256987,0.00047006786917336285,0.000626422290224582,0.00040627073030918837,0.0006205860408954322,0.0006461023003794253,0.0004351903626229614,0.00030949185020290315,0.00035071696038357913,0.0002728998370002955,0.00033982773311436176,0.0006587798125110567,0.0004667591711040586,0.0006280466914176941,0.0005743918591178954,0.0004105297557543963,0.0005624904297292233,0.00027693950687535107,0.00033008671016432345,0.00031917064916342497,0.0004463192308321595,0.00046050830860622227,0.0005340719362720847,0.00031035151914693415,0.0004956735065206885,0.00041608590981923044,0.0002569964271970093,0.0004494274326134473,0.0004520993970800191,0.00039888807805255055,
mae,0.9804477691650391,0.3723070025444031,0.1408134400844574,0.11457867920398712,0.11052312701940536,0.10776127874851227,0.10229184478521347,0.08677270263433456,0.05688672512769699,0.060140784829854965,0.049288149923086166,0.05020152032375336,0.05121443793177605,0.053052205592393875,0.03309532254934311,0.037897463887929916,0.03584541007876396,0.03579229488968849,0.03811407461762428,0.027884386479854584,0.02887015976011753,0.028178904205560684,0.03424058109521866,0.032522473484277725,0.02664007432758808,0.028003627434372902,0.024972615763545036,0.039725348353385925,0.031129349023103714,0.029864750802516937,0.03715901076793671,0.03221145644783974,0.022475730627775192,0.02084895595908165,0.02930254302918911,0.03070174902677536,0.024244390428066254,0.02100222371518612,0.017980504781007767,0.02397487871348858,0.029130354523658752,0.023831041529774666,0.017926568165421486,0.016121551394462585,0.017422927543520927,0.019664956256747246,0.018838755786418915,0.019565153867006302,0.017142420634627342,0.01812070421874523,0.01729494147002697,0.02061268873512745,0.017628390341997147,0.01745501346886158,0.023293495178222656,0.027200590819120407,0.022139897570014,0.014463327825069427,0.014973852783441544,0.015709618106484413,0.01625846140086651,0.014365614391863346,0.02207021415233612,0.024027733132243156,0.022705191746354103,0.01705237478017807,0.016945572569966316,0.016151215881109238,0.020864536985754967,0.02265995182096958,0.019153261557221413,0.017155691981315613,0.019881241023540497,0.01564478874206543,0.02003324218094349,0.020242972299456596,0.016411596909165382,0.013783510774374008,0.014715904369950294,0.012994025833904743,0.014296451583504677,0.020279662683606148,0.01723959669470787,0.020164044573903084,0.019986068829894066,0.016220200806856155,0.019658232107758522,0.013092604465782642,0.014479471370577812,0.01448127906769514,0.017033807933330536,0.017234010621905327,0.018365537747740746,0.014007613994181156,0.017514657229185104,0.016090666875243187,0.012735297903418541,0.017172690480947495,0.016562454402446747,0.016269154846668243,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 466451    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 466452    
=================================================================
Total params: 932,903
Trainable params: 932,903
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                4112      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 466,451
Trainable params: 466,451
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 466,452
Trainable params: 466,452
Non-trainable params: 0
_________________________________________________________________
