2021-06-26
loss,0.5331133008003235,0.13927732408046722,0.13326257467269897,0.1321929693222046,0.08687329292297363,0.07287126779556274,0.09581968933343887,0.08194321393966675,0.0777665451169014,0.07165378332138062,0.07457218319177628,0.1088889092206955,0.09832552075386047,0.08596321195363998,0.06371724605560303,0.06608624756336212,0.08383852988481522,0.07400009781122208,0.07033417373895645,0.061250071972608566,0.04562044143676758,0.045709799975156784,0.036737293004989624,0.05767673999071121,0.05980808660387993,0.049313779920339584,0.06100074201822281,0.06504932790994644,0.058297429233789444,0.0540679469704628,0.05067779868841171,0.056147195398807526,0.04836391285061836,0.03998814523220062,0.03860674053430557,0.05372513458132744,0.055772241204977036,0.050554413348436356,0.0456446073949337,0.04635326936841011,0.04567793756723404,0.045670285820961,0.04756345599889755,0.04170126095414162,0.04178856313228607,0.042121343314647675,0.03468440845608711,0.02835421822965145,0.03216026350855827,0.03473282977938652,0.030898142606019974,0.0294179730117321,0.03813249245285988,0.04129140079021454,0.03747176378965378,0.03812422603368759,0.052361421287059784,0.04776431620121002,0.04429657384753227,0.03745780140161514,0.03615662455558777,0.040508370846509933,0.037377964705228806,0.03212784230709076,0.035342246294021606,0.03757825493812561,0.043076567351818085,0.04175518453121185,0.03879951313138008,0.03431863710284233,0.031246662139892578,0.029002683237195015,0.03001389466226101,0.03812374547123909,0.04101225733757019,0.03768619894981384,0.03037860430777073,0.03316209837794304,0.032878533005714417,0.03396603465080261,0.03242696821689606,0.03590789809823036,0.035590384155511856,0.030486056581139565,0.029452605172991753,0.03146035596728325,0.03099723532795906,0.024916980415582657,0.036221038550138474,0.0351065956056118,0.03186604008078575,0.028966357931494713,0.026306916028261185,0.027352748438715935,0.032931022346019745,0.03564347326755524,0.0333489254117012,0.030219051986932755,0.026246439665555954,0.025816602632403374,
mse,0.14445653557777405,0.006006733980029821,0.005341811571270227,0.005342081654816866,0.0021292546298354864,0.0015534620033577085,0.0028000674210488796,0.001953292638063431,0.0017447448335587978,0.0013919747434556484,0.0015653957379981875,0.0033149314112961292,0.002725805388763547,0.0020771806593984365,0.001139689702540636,0.0012512804241850972,0.0019486130913719535,0.0014708238886669278,0.0013808381045237184,0.0010307565098628402,0.0006046867929399014,0.0006293649203144014,0.000381580728571862,0.0009929873049259186,0.0010066758841276169,0.0006949625676497817,0.0010180709650740027,0.0011561800492927432,0.0009022188023664057,0.0008324967930093408,0.0007036314345896244,0.0008679146412760019,0.0006301973480731249,0.0004442587378434837,0.0004487406404223293,0.0008175530238077044,0.0008464085985906422,0.0006864327006042004,0.0006009195931255817,0.0006007559131830931,0.000593616277910769,0.0005897868541069329,0.000627374101895839,0.0004803007177542895,0.0004908012924715877,0.0004978327197022736,0.00034391830558888614,0.0002337661135243252,0.00029249300132505596,0.0003256716881878674,0.00026938808150589466,0.000240429857512936,0.0004308229254093021,0.0004733119276352227,0.0003854071255773306,0.00041808738023974,0.0007606035214848816,0.0006411817739717662,0.00052827806212008,0.0004121936799492687,0.0003682198002934456,0.0004561732348520309,0.0003904997429344803,0.0002983414742629975,0.0003600494528654963,0.0003917125577572733,0.0005142670124769211,0.0004801903560291976,0.00040406003245152533,0.000322753272484988,0.000265730224782601,0.00022949062986299396,0.00025992540759034455,0.0004078024358022958,0.0004520373768173158,0.00038282398600131273,0.00026360416086390615,0.00030004550353623927,0.0003017665003426373,0.0003222798986826092,0.0003052700776606798,0.00035008214763365686,0.0003378847904969007,0.00026450373115949333,0.000240354856941849,0.0002825556439347565,0.000260785105638206,0.00018170673865824938,0.00036023769644089043,0.00033464658190496266,0.00027386940200813115,0.00023131539637688547,0.00019514838641043752,0.00021255190949887037,0.00030239831539802253,0.0003421148285269737,0.00030007242457941175,0.00025648565497249365,0.0001934083120431751,0.00018535561684984714,
mae,0.2269844114780426,0.05930093303322792,0.057710614055395126,0.05529647320508957,0.03760002553462982,0.031302038580179214,0.040193844586610794,0.03508281335234642,0.03311687335371971,0.030876826494932175,0.03178369626402855,0.04608556255698204,0.04286694526672363,0.03746858239173889,0.02752343937754631,0.028144769370555878,0.03711594268679619,0.03287595137953758,0.030562812462449074,0.027067864313721657,0.0193590447306633,0.019363785162568092,0.015431673265993595,0.023822497576475143,0.024474013596773148,0.02121541276574135,0.026575105264782906,0.028477061539888382,0.025859899818897247,0.022973276674747467,0.02223738469183445,0.024715177714824677,0.021912088617682457,0.017341261729598045,0.016457879915833473,0.022763323038816452,0.02436026558279991,0.022313592955470085,0.01978263445198536,0.019692925736308098,0.019613754004240036,0.0198281928896904,0.019643031060695648,0.017491592094302177,0.01763838902115822,0.017728211358189583,0.014895099215209484,0.012065823189914227,0.013527220115065575,0.014546450227499008,0.013198502361774445,0.012404030188918114,0.016048118472099304,0.017668217420578003,0.016090169548988342,0.016112765297293663,0.023367412388324738,0.021411173045635223,0.019026027992367744,0.015370800159871578,0.01514232624322176,0.01724761351943016,0.01553184725344181,0.013735917396843433,0.014950884506106377,0.015974251553416252,0.018982931971549988,0.018812794238328934,0.0160758625715971,0.012860831804573536,0.013277932070195675,0.012827062979340553,0.013068403117358685,0.016235923394560814,0.018228819593787193,0.01628516986966133,0.013140534982085228,0.014175105839967728,0.013928775675594807,0.014656809158623219,0.014013453386723995,0.015634672716259956,0.015719546005129814,0.012911885045468807,0.01258174143731594,0.0131609495729208,0.01314285397529602,0.010515737347304821,0.015948114916682243,0.015727972611784935,0.013917310163378716,0.013126539997756481,0.011478399857878685,0.011390957050025463,0.014097615145146847,0.015859579667448997,0.014865031465888023,0.013068077154457569,0.011081583797931671,0.010785503312945366,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 26067     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 26068     
=================================================================
Total params: 52,135
Trainable params: 52,135
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 26,067
Trainable params: 26,067
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 26,068
Trainable params: 26,068
Non-trainable params: 0
_________________________________________________________________
