2021-06-26
loss,2.754408836364746,0.3577205240726471,0.2432340830564499,0.23080602288246155,0.21140199899673462,0.2001204490661621,0.19247747957706451,0.18597032129764557,0.17769847810268402,0.1716337651014328,0.1649988889694214,0.1642119437456131,0.15851151943206787,0.15285862982273102,0.15980535745620728,0.16104382276535034,0.15098290145397186,0.14657652378082275,0.1468963623046875,0.14416751265525818,0.143132284283638,0.14244738221168518,0.1411801427602768,0.1396576166152954,0.13926579058170319,0.13822691142559052,0.13817143440246582,0.13651882112026215,0.1357191801071167,0.13440072536468506,0.13528229296207428,0.1328103393316269,0.1331268846988678,0.1351211816072464,0.13239021599292755,0.13125361502170563,0.1284731924533844,0.12896376848220825,0.1288587749004364,0.12688712775707245,0.12730062007904053,0.1291082501411438,0.1292732059955597,0.12819813191890717,0.1321207582950592,0.1368890404701233,0.1275915950536728,0.11785225570201874,0.11887431144714355,0.09959853440523148,0.10096791386604309,0.09841626137495041,0.08518164604902267,0.06818362325429916,0.06522457301616669,0.061437007039785385,0.06270317733287811,0.06052232161164284,0.06324086338281631,0.0653374195098877,0.06195825710892677,0.06443179398775101,0.05695708841085434,0.06293430924415588,0.0548105388879776,0.05341080576181412,0.04463231936097145,0.04543586075305939,0.04730258136987686,0.0451960451900959,0.054068904370069504,0.042597074061632156,0.04085260257124901,0.044322047382593155,0.03839137405157089,0.04103412106633186,0.050206150859594345,0.05044204741716385,0.04267466068267822,0.04148004949092865,0.0376475490629673,0.03510716184973717,0.04524224251508713,0.04065532609820366,0.04105775058269501,0.043615952134132385,0.039746835827827454,0.03942802548408508,0.03438381105661392,0.027285045012831688,0.02998070977628231,0.032759491354227066,0.034346286207437515,0.040860384702682495,0.030442144721746445,0.031856607645750046,0.03571232408285141,0.033705439418554306,0.040654443204402924,0.04106608405709267,
mse,2.2779412269592285,0.04056389257311821,0.0194576233625412,0.017851218581199646,0.015533877536654472,0.01396371703594923,0.012843051925301552,0.011928682215511799,0.011040644720196724,0.010283155366778374,0.009572319686412811,0.009294313378632069,0.008689996786415577,0.00815692450851202,0.00849850568920374,0.008896665647625923,0.007935287430882454,0.007504904177039862,0.0074863070622086525,0.00723029812797904,0.007104301825165749,0.0069992030039429665,0.0069049964658916,0.006785367615520954,0.006741795688867569,0.006650789175182581,0.006613565608859062,0.0064742304384708405,0.006437237374484539,0.006316206883639097,0.006388286128640175,0.006192509084939957,0.006197276059538126,0.006299636326730251,0.006127378437668085,0.006044105160981417,0.005820580292493105,0.00583156943321228,0.00580105884000659,0.0056457724422216415,0.005642315372824669,0.005717592313885689,0.005692201666533947,0.005550484638661146,0.005673421546816826,0.005980401765555143,0.005088621284812689,0.004211504943668842,0.004343132488429546,0.002940633101388812,0.0030516930855810642,0.002761394716799259,0.00217463169246912,0.001356547581963241,0.0012300818925723433,0.0011626920895650983,0.0011429771548137069,0.0011094514047726989,0.001144526875577867,0.0012671196600422263,0.0011296834563836455,0.0011843587271869183,0.0009161815978586674,0.0011317998869344592,0.0008638902800157666,0.0008039559470489621,0.0005769331473857164,0.0005887135630473495,0.0006456567207351327,0.0005756636965088546,0.0008296581218019128,0.0005175911355763674,0.00048743397928774357,0.0005598363350145519,0.0004210872284602374,0.0004796459979843348,0.0007424423238262534,0.0007081059156917036,0.0005173918325453997,0.0005009169690310955,0.0004279704880900681,0.00036746994010172784,0.0005785080138593912,0.0004712571972049773,0.0004871635464951396,0.0005270293913781643,0.0004441900528036058,0.0004306833434384316,0.00033289322163909674,0.0002222941257059574,0.00025567878037691116,0.00031356129329651594,0.00034185455297119915,0.00047699944116175175,0.0002691537083592266,0.00029345613438636065,0.00036309275310486555,0.0003218892961740494,0.00046681181993335485,0.0004676932585425675,
mae,1.1320827007293701,0.15194106101989746,0.10305415838956833,0.098121777176857,0.09046359360218048,0.08612415939569473,0.08267754316329956,0.07965882122516632,0.07592590898275375,0.07290167361497879,0.07004540413618088,0.06951930373907089,0.06700896471738815,0.06447228789329529,0.0673266127705574,0.0681610107421875,0.06363648176193237,0.06149760261178017,0.06155472248792648,0.06011102348566055,0.05965377017855644,0.059544239193201065,0.05894643813371658,0.058178167790174484,0.05815613642334938,0.057644568383693695,0.057540636509656906,0.05698675662279129,0.056520238518714905,0.055981069803237915,0.05645546317100525,0.05520694702863693,0.055339664220809937,0.05640591308474541,0.054992880672216415,0.05449819937348366,0.05362735688686371,0.05354246497154236,0.05362444743514061,0.05267785117030144,0.05300441384315491,0.053880199790000916,0.05391847714781761,0.0533854104578495,0.05522187799215317,0.057853732258081436,0.054190922528505325,0.04956742748618126,0.0499737374484539,0.041721243411302567,0.04301157966256142,0.042135242372751236,0.03731771931052208,0.029144976288080215,0.027741815894842148,0.026204364374279976,0.02658725716173649,0.025711961090564728,0.026481136679649353,0.027476022019982338,0.02664419822394848,0.027472030371427536,0.023954836651682854,0.027043765410780907,0.022900590673089027,0.022610725834965706,0.018804918974637985,0.01939479075372219,0.020167700946331024,0.019502831622958183,0.023270808160305023,0.018405158072710037,0.017379097640514374,0.019092611968517303,0.016376959159970284,0.017862509936094284,0.0221007838845253,0.02190922200679779,0.016969673335552216,0.01749638468027115,0.016060708090662956,0.014636039733886719,0.01913686841726303,0.017398549243807793,0.01767241396009922,0.019198697060346603,0.017073510214686394,0.01654241420328617,0.014781814999878407,0.011601860634982586,0.012735872529447079,0.013834169134497643,0.014506425708532333,0.016781335696578026,0.013032577000558376,0.013733949512243271,0.014531821012496948,0.014406060799956322,0.017176562920212746,0.017593415454030037,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 364883    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 364884    
=================================================================
Total params: 729,767
Trainable params: 729,767
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 364,883
Trainable params: 364,883
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 364,884
Trainable params: 364,884
Non-trainable params: 0
_________________________________________________________________
