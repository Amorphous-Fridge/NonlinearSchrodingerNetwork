2021-06-26
loss,1.9606719017028809,0.31535232067108154,0.24333183467388153,0.1745615005493164,0.20121604204177856,0.14791831374168396,0.157228484749794,0.16115523874759674,0.11314819008111954,0.12306057661771774,0.0993889793753624,0.11518027633428574,0.09706893563270569,0.08428879827260971,0.09293442964553833,0.08628381788730621,0.06589898467063904,0.0818675234913826,0.08764038980007172,0.09287344664335251,0.07270942628383636,0.053042203187942505,0.06559320539236069,0.05165153369307518,0.0858531966805458,0.06755189597606659,0.05729810148477554,0.05351567268371582,0.05623048171401024,0.07408785074949265,0.06169595569372177,0.06446440517902374,0.06396881490945816,0.05696500837802887,0.055085454136133194,0.05693700164556503,0.04481557011604309,0.04909056797623634,0.05477702245116234,0.05629663169384003,0.04873976856470108,0.05174684524536133,0.03670606017112732,0.04995947703719139,0.04272334277629852,0.03236294537782669,0.04461585357785225,0.05327991023659706,0.0481254942715168,0.04652222990989685,0.04418305307626724,0.048292212188243866,0.040560897439718246,0.030994907021522522,0.041883599013090134,0.03932301327586174,0.0372973307967186,0.041191816329956055,0.04328739270567894,0.04590938612818718,0.046503253281116486,0.03420514613389969,0.037120383232831955,0.041503384709358215,0.036862608045339584,0.03793325647711754,0.04756749048829079,0.043447304517030716,0.03946072235703468,0.04073350504040718,0.038066502660512924,0.03068367950618267,0.030363822355866432,0.0329815112054348,0.029420774430036545,0.0425722599029541,0.04252460598945618,0.033550914376974106,0.0288468599319458,0.033658672124147415,0.03206457942724228,0.03172121196985245,0.040446504950523376,0.03716360405087471,0.027158377692103386,0.038879189640283585,0.03618154674768448,0.03207580745220184,0.030050955712795258,0.030546151101589203,0.040914878249168396,0.037912193685770035,0.03361649811267853,0.029886161908507347,0.03048592619597912,0.03531178832054138,0.0371992364525795,0.02807832509279251,0.028422009199857712,0.024187887087464333,
mse,2.1356709003448486,0.032399702817201614,0.01680815778672695,0.00894150696694851,0.012224345467984676,0.006299461703747511,0.007638077717274427,0.0074018617160618305,0.003770909272134304,0.004544686060398817,0.002902552718296647,0.004042826592922211,0.002646795241162181,0.002054565353319049,0.0027967735659331083,0.0022805752232670784,0.0013047006214037538,0.0018969011725857854,0.0022496136371046305,0.002471319632604718,0.001495116506703198,0.0008063299464993179,0.0012574231950566173,0.0008263487834483385,0.002077628392726183,0.0013547331327572465,0.0009634058806113899,0.0008293392602354288,0.0009279527585022151,0.0015554017154499888,0.0010713424999266863,0.001182354404591024,0.001115300110541284,0.0009243408567272127,0.0008537223329767585,0.0008834968321025372,0.0005865087150596082,0.0007177732768468559,0.0008685661596246064,0.0009001083089970052,0.0006598292384296656,0.0007482522632926702,0.00041865056846290827,0.0007221634732559323,0.0005119582638144493,0.00030142563628032804,0.0005865677958354354,0.0007717337575741112,0.000662466511130333,0.0006061489111743867,0.0005620404845103621,0.000658348377328366,0.000474097061669454,0.0002863579720724374,0.0005477509112097323,0.0004459479823708534,0.00040711916517466307,0.00048656162107363343,0.0005480260006152093,0.0006054069963283837,0.0006004861206747591,0.00035533911432139575,0.0004165667050983757,0.0004897155449725688,0.00039711923454888165,0.000412494846386835,0.000623611151240766,0.0005144827300682664,0.00042807869613170624,0.0004642629355657846,0.00040419254219159484,0.00026631896616891026,0.0002662806073203683,0.00032381582423113286,0.0002519766567274928,0.0005122239235788584,0.0004893430159427226,0.00032473617466166615,0.0002441562828607857,0.00033399168751202524,0.00029702577739953995,0.00028769572963938117,0.00045722819049842656,0.0003926754288841039,0.00021770664898213,0.0004349126247689128,0.00037697498919442296,0.00029253828688524663,0.0002608513168524951,0.00027210722328163683,0.0004599284438882023,0.0003918555739801377,0.0003232153248973191,0.00026052407338283956,0.00026959989918395877,0.0003481423482298851,0.00038323429180309176,0.00022909963445272297,0.00023466598941013217,0.00016880023758858442,
mae,0.7745694518089294,0.13684962689876556,0.10385861992835999,0.07616596668958664,0.08355298638343811,0.06307283788919449,0.06872342526912689,0.07101838290691376,0.048385415226221085,0.05296188220381737,0.04260340332984924,0.050334203988313675,0.04145926982164383,0.0356486514210701,0.04126804322004318,0.038272563368082047,0.028897905722260475,0.03460399806499481,0.038144029676914215,0.04092492535710335,0.03123711422085762,0.0225028395652771,0.027249829843640327,0.022504549473524094,0.03869445621967316,0.030170686542987823,0.024547114968299866,0.022630972787737846,0.02385495975613594,0.03332333266735077,0.026595300063490868,0.02830403298139572,0.02914292737841606,0.024523800238966942,0.023588139563798904,0.024847012013196945,0.019158655777573586,0.02090311050415039,0.023301253095269203,0.025967642664909363,0.02102852053940296,0.022416576743125916,0.015469427220523357,0.021622877568006516,0.018240876495838165,0.013747656717896461,0.0193047896027565,0.024039581418037415,0.021663058549165726,0.020263081416487694,0.01859489642083645,0.021201588213443756,0.017216436564922333,0.013024852611124516,0.01818237453699112,0.01656459830701351,0.01591683179140091,0.017297090962529182,0.018595945090055466,0.019749179482460022,0.020570406690239906,0.014661197550594807,0.01578209362924099,0.017866766080260277,0.015498369932174683,0.016123490408062935,0.02207253687083721,0.01999937742948532,0.01698753796517849,0.018229849636554718,0.016401860862970352,0.013113169930875301,0.012777108699083328,0.014065560884773731,0.012425044551491737,0.01886437088251114,0.019950056448578835,0.014363579452037811,0.012373076751828194,0.014080220833420753,0.013739974237978458,0.013469483703374863,0.018022749572992325,0.016998620703816414,0.011623600497841835,0.017092633992433548,0.015329502522945404,0.01348926778882742,0.012857113033533096,0.01298344973474741,0.018764331936836243,0.017362838611006737,0.014399572275578976,0.01262472290545702,0.012808897532522678,0.015378178097307682,0.016663210466504097,0.011902975849807262,0.012071545235812664,0.010251922532916069,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 332115    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 332116    
=================================================================
Total params: 664,231
Trainable params: 664,231
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 332,115
Trainable params: 332,115
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 332,116
Trainable params: 332,116
Non-trainable params: 0
_________________________________________________________________
