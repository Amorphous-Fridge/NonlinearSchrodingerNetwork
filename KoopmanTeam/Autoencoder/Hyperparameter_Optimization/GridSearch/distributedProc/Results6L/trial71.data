2021-06-26
loss,3.48542857170105,0.880014181137085,0.3885149359703064,0.35518768429756165,0.3567683696746826,0.3563867509365082,0.35066792368888855,0.3524596393108368,0.3460117280483246,0.33894452452659607,0.3249799609184265,0.3156777322292328,0.2897622287273407,0.25513339042663574,0.2181779444217682,0.16055285930633545,0.12469910830259323,0.11020755022764206,0.09790120273828506,0.09744887053966522,0.07884039729833603,0.0641506016254425,0.07306007295846939,0.07824306190013885,0.06788213551044464,0.08618473261594772,0.07294504344463348,0.07569510489702225,0.0457809641957283,0.0568896159529686,0.0707361251115799,0.06132068485021591,0.05326814204454422,0.05059562996029854,0.044461313635110855,0.04556308686733246,0.053439415991306305,0.06035860627889633,0.05596121773123741,0.049601320177316666,0.049259379506111145,0.04135231673717499,0.045393336564302444,0.05169980227947235,0.03942310810089111,0.039800502359867096,0.05076790228486061,0.03867596015334129,0.03946223855018616,0.046790365129709244,0.03750620782375336,0.04206717386841774,0.045533373951911926,0.036608997732400894,0.0292446780949831,0.03762519732117653,0.04478703811764717,0.037662066519260406,0.03607175499200821,0.04142876714468002,0.038839105516672134,0.031118977814912796,0.029553130269050598,0.039012521505355835,0.034755151718854904,0.037281766533851624,0.03997382894158363,0.03378446400165558,0.04026157408952713,0.03678809851408005,0.030330322682857513,0.03209617733955383,0.03266676887869835,0.03930579498410225,0.03705690801143646,0.028910059481859207,0.035917676985263824,0.03661054000258446,0.02675328403711319,0.02835172414779663,0.02845524623990059,0.03338086977601051,0.036426007747650146,0.034302327781915665,0.028640585020184517,0.024982549250125885,0.0267043299973011,0.02964869886636734,0.03205755352973938,0.03541744872927666,0.03236014023423195,0.034123390913009644,0.03146277368068695,0.03264646232128143,0.02698877640068531,0.027475988492369652,0.03306146711111069,0.031014161184430122,0.03194403648376465,0.025580281391739845,
mse,3.202646493911743,0.296257883310318,0.044250912964344025,0.03779394552111626,0.03814476355910301,0.03819328919053078,0.0370219387114048,0.03721862658858299,0.03574031963944435,0.03421936184167862,0.03158348426222801,0.02958514168858528,0.02549133077263832,0.02040056698024273,0.014657456427812576,0.0077225626446306705,0.00453631766140461,0.003536866046488285,0.002860011998564005,0.0028498219326138496,0.0018020798452198505,0.0012225793907418847,0.0016503909137099981,0.001804427825845778,0.0014230379601940513,0.002147348364815116,0.0016093369340524077,0.001624419935978949,0.0006468535284511745,0.0010062057990580797,0.001421091379597783,0.0010896321618929505,0.0008282849448733032,0.0007641041884198785,0.0005706849624402821,0.0005991073558107018,0.0008701748447492719,0.0010121099185198545,0.000851430173497647,0.0006894870311953127,0.0006875813705846667,0.0005062286509200931,0.0005842983955517411,0.0007297402480617166,0.00045202934416010976,0.0004569121520034969,0.000715720234438777,0.0004383196064736694,0.0004484348464757204,0.0006180782220326364,0.0003985254734288901,0.0004988020518794656,0.0005714509170502424,0.0003827670880127698,0.00025686310254968703,0.000414464739151299,0.0005462554399855435,0.0003997379681095481,0.00038157706148922443,0.00047732345410622656,0.00042025584843941033,0.00028189097065478563,0.00025170392473228276,0.00043312483467161655,0.0003426921321079135,0.000404876540414989,0.00044627676834352314,0.0003259145887568593,0.00045437325024977326,0.0003719875530805439,0.00026287889340892434,0.0003005361068062484,0.0003042920143343508,0.0004306083428673446,0.00037851533852517605,0.00023786310339346528,0.0003621407086029649,0.0003659845096990466,0.00020821142243221402,0.00023150804918259382,0.00023233372485265136,0.00031598081113770604,0.0003695689083542675,0.0003306858125142753,0.0002404873666819185,0.00018262836965732276,0.0002040865656454116,0.00025059538893401623,0.0002967598265968263,0.0003503089537844062,0.0002980582939926535,0.0003193982411175966,0.0002787926350720227,0.0002905559667851776,0.00020922409021295607,0.00021973504044581205,0.0003011428634636104,0.0002666219952516258,0.00027617200976237655,0.00019052419520448893,
mae,1.5568187236785889,0.3877885341644287,0.1721087396144867,0.15745297074317932,0.15813642740249634,0.15767577290534973,0.15446482598781586,0.1541157215833664,0.15081794559955597,0.1474590301513672,0.14149272441864014,0.13679732382297516,0.12439372390508652,0.10989128798246384,0.09415140748023987,0.06807778030633926,0.053041428327560425,0.046574272215366364,0.0422220416367054,0.04182647541165352,0.03378820791840553,0.02785005420446396,0.03166498616337776,0.03363281488418579,0.028626279905438423,0.037347499281167984,0.03233513608574867,0.032432083040475845,0.01991201564669609,0.024578304961323738,0.030750615522265434,0.027133796364068985,0.023087766021490097,0.02202351577579975,0.01894751377403736,0.01955835148692131,0.02353290095925331,0.027622558176517487,0.025536032393574715,0.021858753636479378,0.021736901253461838,0.017723448574543,0.019328339025378227,0.023031406104564667,0.01661103218793869,0.016999894753098488,0.022885290905833244,0.01625126414000988,0.017004186287522316,0.020758509635925293,0.0157484021037817,0.018141454085707664,0.020563876256346703,0.015579445287585258,0.012495484203100204,0.016205256804823875,0.02030879817903042,0.016243768855929375,0.01561763882637024,0.01884262077510357,0.016503697261214256,0.013285878114402294,0.01258616428822279,0.016884544864296913,0.014659052714705467,0.016401199623942375,0.017926596105098724,0.014518329873681068,0.017996834591031075,0.016325408592820168,0.012906434945762157,0.013822095468640327,0.013649003580212593,0.017750078812241554,0.017101028934121132,0.012041517533361912,0.01583511382341385,0.016604013741016388,0.01140335202217102,0.012002871371805668,0.011866981163620949,0.014482025057077408,0.016189033165574074,0.014685721136629581,0.012403960339725018,0.01060839369893074,0.01148633286356926,0.012519576586782932,0.013919624499976635,0.01586342416703701,0.014006384648382664,0.015706729143857956,0.013561619445681572,0.014541282318532467,0.011441648937761784,0.011875966563820839,0.014400062151253223,0.013483744114637375,0.014418702572584152,0.010843848809599876,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 330475    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 330476    
=================================================================
Total params: 660,951
Trainable params: 660,951
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 330,475
Trainable params: 330,475
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 330,476
Trainable params: 330,476
Non-trainable params: 0
_________________________________________________________________
