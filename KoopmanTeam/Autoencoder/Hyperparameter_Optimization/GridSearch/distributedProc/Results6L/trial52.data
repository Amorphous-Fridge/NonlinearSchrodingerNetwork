2021-06-26
loss,1.395735740661621,0.3616477847099304,0.35358795523643494,0.34383654594421387,0.3168140649795532,0.2744753658771515,0.22251741588115692,0.2538381516933441,0.2236175388097763,0.20983725786209106,0.20228883624076843,0.1954672634601593,0.18870262801647186,0.17622694373130798,0.17405501008033752,0.16380800306797028,0.15822991728782654,0.16147084534168243,0.15662004053592682,0.14566390216350555,0.13425181806087494,0.11759866774082184,0.11858779937028885,0.09294787049293518,0.10089059174060822,0.0835188552737236,0.09339959919452667,0.10351864993572235,0.07835612446069717,0.07512563467025757,0.07413917779922485,0.07154624164104462,0.07410197705030441,0.047104835510253906,0.06822707504034042,0.0612364336848259,0.05226804316043854,0.051697712391614914,0.04454052820801735,0.03702479228377342,0.042213454842567444,0.03939718008041382,0.04935575649142265,0.047461606562137604,0.045961447060108185,0.04390137270092964,0.043037667870521545,0.050719305872917175,0.053144197911024094,0.04736435413360596,0.03826756030321121,0.04433152824640274,0.0374927744269371,0.035346027463674545,0.043703775852918625,0.030834419652819633,0.039216622710227966,0.03499956056475639,0.03651797026395798,0.03496740758419037,0.040946200489997864,0.03342466056346893,0.03095085546374321,0.035319484770298004,0.036267656832933426,0.031885191798210144,0.033392198383808136,0.03586931526660919,0.03070838190615177,0.0322713628411293,0.03148839622735977,0.03169114142656326,0.03340233489871025,0.03511425107717514,0.030521905049681664,0.027799945324659348,0.03017328307032585,0.028568632900714874,0.02812742255628109,0.03372185304760933,0.031210308894515038,0.027710435912013054,0.02789127640426159,0.032573312520980835,0.02880193293094635,0.032476454973220825,0.02617086097598076,0.03189318627119064,0.0262664295732975,0.02732851356267929,0.027182117104530334,0.02790888585150242,0.03044149838387966,0.02991451323032379,0.028118029236793518,0.02631552144885063,0.0273771733045578,0.02906055934727192,0.027652742341160774,0.023669814690947533,
mse,0.8986377716064453,0.03872120380401611,0.03726445510983467,0.03527785837650299,0.030046170577406883,0.023492131382226944,0.01631844975054264,0.021001605316996574,0.017121385782957077,0.01557946763932705,0.014481130987405777,0.013416264206171036,0.012309005483984947,0.010846973396837711,0.010486445389688015,0.00940040871500969,0.008522296324372292,0.00861887913197279,0.008386938832700253,0.00722438283264637,0.006189195904880762,0.004908613860607147,0.004824450239539146,0.003172394121065736,0.003534242743626237,0.0024851670023053885,0.002869846299290657,0.003501205239444971,0.00211514625698328,0.0018328423611819744,0.0018321063835173845,0.0016102544032037258,0.001694332342594862,0.0007589230663143098,0.001394930761307478,0.0012262905947864056,0.0008741547935642302,0.0008247510413639247,0.0006330166943371296,0.00044436953612603247,0.0005405808333307505,0.0004858200263697654,0.0007360245217569172,0.000707863480783999,0.0006165921804495156,0.0005854797200299799,0.0005552262300625443,0.0007480813073925674,0.0008154517272487283,0.0006371648632921278,0.00043981894850730896,0.0005740373162552714,0.0004101081285625696,0.0003705347771756351,0.0005665422650054097,0.00030136917484924197,0.00047841251944191754,0.00036046060267835855,0.00038706022314727306,0.00035432996810413897,0.0004707329790107906,0.00033505179453641176,0.00028881023172289133,0.0003623273514676839,0.0003734406200237572,0.000315304147079587,0.0003149865078739822,0.00037318881368264556,0.0002768329286482185,0.0002993911621160805,0.00028456971631385386,0.00029442738741636276,0.00031487573869526386,0.00034671343746595085,0.00028086730162613094,0.00022691229241900146,0.0002606104826554656,0.0002343670348636806,0.00022648532467428595,0.00031838941504247487,0.0002766268153209239,0.00021673401352018118,0.00022258995159063488,0.0002962593862321228,0.00023721229808870703,0.00029416006873361766,0.00019944467931054533,0.00028936032322235405,0.0001998485386138782,0.00021538902365136892,0.0002103846927639097,0.00022194033954292536,0.0002574877580627799,0.000252503901720047,0.00023037195205688477,0.00019767235789913684,0.00021561123139690608,0.00023708412481937557,0.00021937716519460082,0.00016535999020561576,
mae,0.6132221221923828,0.1575157791376114,0.15417833626270294,0.146294504404068,0.13187474012374878,0.11502023041248322,0.09466681629419327,0.11142240464687347,0.09673779457807541,0.08958885818719864,0.08474645763635635,0.08141493052244186,0.07905378937721252,0.0737728551030159,0.0732707679271698,0.06868876516819,0.06630484759807587,0.06762992590665817,0.06581104546785355,0.06116616353392601,0.05708586052060127,0.049295082688331604,0.05046938359737396,0.039326261729002,0.04247811436653137,0.03552701324224472,0.04016541317105293,0.044669609516859055,0.03385966643691063,0.031755972653627396,0.03148314356803894,0.030742991715669632,0.03174281865358353,0.02013876475393772,0.028864329680800438,0.025919439271092415,0.02172694355249405,0.022244445979595184,0.01900859735906124,0.01580919697880745,0.01786000281572342,0.01657528430223465,0.02121645025908947,0.020199833437800407,0.01938430592417717,0.018385889008641243,0.018435558304190636,0.02163763716816902,0.023051748052239418,0.021007154136896133,0.016023777425289154,0.019232794642448425,0.01581389829516411,0.01475537195801735,0.01865662820637226,0.013092497363686562,0.01695471815764904,0.014878587797284126,0.015452718362212181,0.01496448740363121,0.01771228201687336,0.01415956299751997,0.01326067466288805,0.015132793225347996,0.01573777385056019,0.013807139359414577,0.014036926440894604,0.015150509774684906,0.013119312934577465,0.013894646428525448,0.01345332246273756,0.013949859887361526,0.014228914864361286,0.015080482698976994,0.013115243054926395,0.011829397641122341,0.012823309749364853,0.012045289389789104,0.011992127634584904,0.014288105070590973,0.01345477718859911,0.011782664805650711,0.011639845557510853,0.013920902274549007,0.01214267686009407,0.014165711589157581,0.010998660698533058,0.0139750512316823,0.011060203425586224,0.011709583923220634,0.011470402590930462,0.012019005604088306,0.013082845136523247,0.012925446964800358,0.011812139302492142,0.011110757477581501,0.011634523048996925,0.012659952975809574,0.011662530712783337,0.010107599198818207,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 136083    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 136084    
=================================================================
Total params: 272,167
Trainable params: 272,167
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 136,083
Trainable params: 136,083
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 136,084
Trainable params: 136,084
Non-trainable params: 0
_________________________________________________________________
