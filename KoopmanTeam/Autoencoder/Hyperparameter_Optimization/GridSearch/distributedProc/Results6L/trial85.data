2021-06-26
loss,2.4916799068450928,2.2067668437957764,2.2040059566497803,2.24198842048645,2.2143611907958984,2.2046098709106445,2.2041022777557373,2.204040765762329,2.2033896446228027,2.2039568424224854,2.20395565032959,2.203321933746338,2.205613851547241,2.2036523818969727,2.206385850906372,2.203850507736206,2.2047057151794434,2.3057773113250732,2.2182517051696777,2.203982353210449,2.2010605335235596,2.2007694244384766,2.199620485305786,2.1995983123779297,2.1999523639678955,2.2006773948669434,2.199449062347412,2.199882745742798,2.2000927925109863,2.200087785720825,2.200216293334961,2.1997900009155273,2.1996877193450928,2.2008931636810303,2.199578046798706,2.2001562118530273,2.200573205947876,2.2012522220611572,2.200246810913086,2.2008378505706787,2.2008261680603027,2.1995208263397217,2.2000951766967773,2.199697971343994,2.199819564819336,2.2002713680267334,2.207712411880493,2.20070743560791,2.1994550228118896,2.2000632286071777,2.200751304626465,2.198957920074463,2.199554443359375,2.199235200881958,2.1998307704925537,2.1991147994995117,2.199234962463379,2.2002031803131104,2.2003896236419678,2.200401544570923,2.2001562118530273,2.198840856552124,2.1992452144622803,2.199965000152588,2.2000410556793213,2.1995115280151367,2.199368476867676,2.2004692554473877,2.198777675628662,2.1999635696411133,2.1999928951263428,2.2023262977600098,2.2288622856140137,2.20029616355896,2.2634897232055664,2.5564887523651123,0.4751141369342804,0.4446223974227905,0.44394177198410034,0.44438666105270386,0.4442177712917328,0.4442550241947174,0.444305956363678,0.4436301290988922,0.44425299763679504,0.44471877813339233,0.44472962617874146,0.4446990489959717,0.4441273510456085,0.44448235630989075,0.44474074244499207,0.4439564645290375,0.4440279006958008,0.444848895072937,0.4441783130168915,0.44406238198280334,0.4444636404514313,0.444026380777359,0.4444239139556885,0.44505682587623596,
mse,1.671623945236206,1.2313405275344849,1.2283930778503418,1.2713438272476196,1.2394331693649292,1.2291477918624878,1.2285964488983154,1.228548526763916,1.2277963161468506,1.2284687757492065,1.2284451723098755,1.2277190685272217,1.2302181720733643,1.2281124591827393,1.2310981750488281,1.2282941341400146,1.2292859554290771,1.346643090248108,1.2439061403274536,1.2284412384033203,1.2249847650527954,1.2246100902557373,1.2232966423034668,1.2232747077941895,1.2236015796661377,1.2244547605514526,1.2231051921844482,1.2235692739486694,1.223793387413025,1.2237663269042969,1.223915696144104,1.2234265804290771,1.223391056060791,1.2246949672698975,1.2232552766799927,1.2238585948944092,1.2243587970733643,1.2250419855117798,1.223995566368103,1.2246230840682983,1.2245677709579468,1.2231742143630981,1.2238171100616455,1.2234455347061157,1.2234746217727661,1.2240257263183594,1.2321052551269531,1.2244967222213745,1.223036527633667,1.2237656116485596,1.2245588302612305,1.2225420475006104,1.2232186794281006,1.2228986024856567,1.2235692739486694,1.2227593660354614,1.2228494882583618,1.2239564657211304,1.2240796089172363,1.2241060733795166,1.2238847017288208,1.2224153280258179,1.2228937149047852,1.223704218864441,1.223783016204834,1.2231589555740356,1.2230013608932495,1.2242251634597778,1.2223880290985107,1.223628044128418,1.2236871719360352,1.2262775897979736,1.2557399272918701,1.2240417003631592,1.423502802848816,2.2250843048095703,0.0628829076886177,0.05508580803871155,0.05493158474564552,0.05502839386463165,0.05498779937624931,0.05500398576259613,0.05500449985265732,0.054865479469299316,0.05499773100018501,0.055113792419433594,0.05510822683572769,0.05506959930062294,0.05497579649090767,0.05503411591053009,0.05507747828960419,0.0549502931535244,0.05495743826031685,0.05515525862574577,0.0549781508743763,0.054981131106615067,0.05504605174064636,0.05494127422571182,0.05500679835677147,0.05518753081560135,
mae,0.8725948929786682,0.6104704141616821,0.6006187200546265,0.6742712259292603,0.627770185470581,0.598606526851654,0.5963972806930542,0.5953603982925415,0.594261646270752,0.5941451787948608,0.5940144062042236,0.5934398770332336,0.6033351421356201,0.5924161076545715,0.6044294238090515,0.5945419073104858,0.5937029123306274,0.7604557871818542,0.6372344493865967,0.5957604050636292,0.5753991603851318,0.5611931085586548,0.5581473112106323,0.5573381185531616,0.5606706738471985,0.5550761222839355,0.5546638369560242,0.556887686252594,0.5591822266578674,0.5543550848960876,0.5598040223121643,0.5545980334281921,0.5546565055847168,0.5664756894111633,0.5538214445114136,0.5533549785614014,0.5587958693504333,0.5683239698410034,0.5541073083877563,0.5573837757110596,0.5537488460540771,0.560554563999176,0.5532104969024658,0.5533026456832886,0.560824990272522,0.5529900193214417,0.5987682342529297,0.5645163655281067,0.5551740527153015,0.5542629361152649,0.5540092587471008,0.5533115267753601,0.5532682538032532,0.5530250072479248,0.5530544519424438,0.5527583956718445,0.5527361631393433,0.5528661608695984,0.5528649687767029,0.553057074546814,0.5633270144462585,0.5529308915138245,0.552416980266571,0.5524929165840149,0.5524799227714539,0.558383584022522,0.5532882213592529,0.5526098012924194,0.557895839214325,0.5528063774108887,0.566102921962738,0.5637081861495972,0.6594864130020142,0.5620472431182861,0.580558180809021,1.0946147441864014,0.2078048288822174,0.19725392758846283,0.19688352942466736,0.19714020192623138,0.19705039262771606,0.1970822513103485,0.1970612108707428,0.1967935413122177,0.19707779586315155,0.19727613031864166,0.19735054671764374,0.1973002552986145,0.19706173241138458,0.19718492031097412,0.19722695648670197,0.19697313010692596,0.19699688255786896,0.19738897681236267,0.19703049957752228,0.1970561146736145,0.19715335965156555,0.1969795674085617,0.19719475507736206,0.19743801653385162,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 364883    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 364884    
=================================================================
Total params: 729,767
Trainable params: 729,767
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 364,883
Trainable params: 364,883
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 364,884
Trainable params: 364,884
Non-trainable params: 0
_________________________________________________________________
