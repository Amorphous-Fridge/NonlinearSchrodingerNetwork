2021-06-26
loss,0.6212579011917114,0.18374912440776825,0.12404114753007889,0.1352672278881073,0.11007840186357498,0.08927904814481735,0.09168056398630142,0.07741229981184006,0.09694444388151169,0.08412306010723114,0.09034581482410431,0.09003850817680359,0.08332858234643936,0.06353884935379028,0.058164194226264954,0.0645129457116127,0.05675072222948074,0.06474058330059052,0.07084084302186966,0.06811835616827011,0.05581475794315338,0.04745177924633026,0.056645046919584274,0.06168472394347191,0.05222584679722786,0.04355747252702713,0.045355282723903656,0.055333372205495834,0.051873043179512024,0.04152417182922363,0.04506075382232666,0.041248537600040436,0.050872884690761566,0.05543559044599533,0.04852522537112236,0.04215330630540848,0.03678557276725769,0.0330292284488678,0.03607173264026642,0.043164171278476715,0.05034584552049637,0.04802391678094864,0.041529249399900436,0.0356377512216568,0.031519364565610886,0.03826724365353584,0.037263624370098114,0.03186420723795891,0.031387656927108765,0.03125656768679619,0.028634218499064445,0.043764203786849976,0.03874567896127701,0.03605444356799126,0.038742002099752426,0.047619014978408813,0.04295136407017708,0.03641610965132713,0.03208816424012184,0.029347315430641174,0.03136799484491348,0.03832971304655075,0.034901250153779984,0.0322544239461422,0.03352031856775284,0.041250091046094894,0.03890936076641083,0.03262655809521675,0.030181944370269775,0.028516268357634544,0.0381622239947319,0.03957824409008026,0.03481267765164375,0.029797187075018883,0.03340097889304161,0.032135166227817535,0.025862159207463264,0.03341618925333023,0.03764289617538452,0.03484554588794708,0.031127827242016792,0.027840914204716682,0.026059621945023537,0.025823526084423065,0.03225914388895035,0.026697950437664986,0.02820669487118721,0.02795812301337719,0.03147152066230774,0.028406186029314995,0.03069252334535122,0.0349700003862381,0.03194057568907738,0.033593133091926575,0.031081242486834526,0.028605427592992783,0.026148393750190735,0.02459721267223358,0.033062711358070374,0.032453104853630066,
mse,0.17937690019607544,0.01153036579489708,0.004504283890128136,0.005246205721050501,0.0034405714832246304,0.002252981998026371,0.0023578782565891743,0.0017247536452487111,0.002809378784149885,0.002111412351951003,0.0023763214703649282,0.002258368767797947,0.0019204237032681704,0.001166422967799008,0.000983685371465981,0.001156610669568181,0.0008988622575998306,0.001278976909816265,0.0014039342058822513,0.001289933454245329,0.0008545283344574273,0.0006048117065802217,0.0009554245043545961,0.0010803230106830597,0.0007483693771064281,0.000512105820234865,0.0006121705519035459,0.0008837229106575251,0.000797647750005126,0.0005004439735785127,0.0005493185599334538,0.00048385289846919477,0.000723430362995714,0.0008461782126687467,0.0006687851273454726,0.0004942569648846984,0.0003757159283850342,0.00030457883258350194,0.0003826540778391063,0.0005305997910909355,0.0007066766265779734,0.0006495009874925017,0.0004804122436325997,0.00034678849624469876,0.0002816864871419966,0.00043685451964847744,0.00039985644980333745,0.00028354383539408445,0.00027856280212290585,0.00027158099692314863,0.00023430191504303366,0.0005275372532196343,0.0004056435136590153,0.0003580381453502923,0.00044355675345286727,0.0006211126456037164,0.0005139931454323232,0.000363504106644541,0.00027972529642283916,0.00023669037909712642,0.0003012733068317175,0.0004136872012168169,0.0003309566527605057,0.0002813729224726558,0.0003300347598269582,0.0004939543432556093,0.0004188978346064687,0.00028702858253382146,0.0002493450010661036,0.00022327573969960213,0.00042076900717802346,0.0004228584002703428,0.00033002669806592166,0.0002520116395317018,0.000315693614538759,0.00028704796568490565,0.00019117409829050303,0.0003163787769153714,0.0003842136648017913,0.0003298472729511559,0.00026078990777023137,0.0002100618730764836,0.0001862935023382306,0.00018629884289111942,0.0002898123930208385,0.0002027239534072578,0.00022748796618543565,0.00022265134612098336,0.0002778122143354267,0.000226748306886293,0.0002553568338043988,0.0003374756488483399,0.000275453960057348,0.00031049034441821277,0.00026264318148605525,0.00022302330762613565,0.00018606077355798334,0.0001684087183093652,0.0002995929098688066,0.00029764152714051306,
mae,0.2655998170375824,0.07587100565433502,0.05349678918719292,0.057402368634939194,0.04678056389093399,0.03806021809577942,0.03933420777320862,0.032696016132831573,0.04178295284509659,0.03528150916099548,0.03949258476495743,0.039437081664800644,0.03653224930167198,0.027230968698859215,0.024785030633211136,0.027852095663547516,0.024641767144203186,0.027746595442295074,0.03062579408288002,0.02974284440279007,0.02516968734562397,0.019836653023958206,0.02431284263730049,0.02713153511285782,0.02265244536101818,0.01882830448448658,0.01892869547009468,0.023920534178614616,0.022147439420223236,0.017525991424918175,0.019657494500279427,0.017140032723546028,0.02176247350871563,0.024140357971191406,0.02156292274594307,0.017940187826752663,0.016106905415654182,0.01414225623011589,0.015109224244952202,0.018574019894003868,0.021524114534258842,0.021385952830314636,0.018161499872803688,0.014718115329742432,0.013274496421217918,0.016437148675322533,0.015716688707470894,0.013423261232674122,0.013284556567668915,0.013147979974746704,0.012071052566170692,0.018783049657940865,0.016178423538804054,0.015612180344760418,0.01717294380068779,0.020799670368433,0.01890982687473297,0.015644315630197525,0.01284550316631794,0.012032721191644669,0.013506663031876087,0.016947273164987564,0.015504914335906506,0.013902779668569565,0.014536648988723755,0.017741026356816292,0.01725572533905506,0.014795598573982716,0.013924697414040565,0.012910201214253902,0.016010042279958725,0.017093949019908905,0.015394065529108047,0.012272690422832966,0.01388951763510704,0.013556896708905697,0.011127108708024025,0.014269722625613213,0.0164752509444952,0.015052735805511475,0.014008882455527782,0.012505196034908295,0.01125587709248066,0.011231638491153717,0.01378726027905941,0.011354710906744003,0.011888124980032444,0.011655794456601143,0.013317815028131008,0.011933350935578346,0.013165874406695366,0.015118789859116077,0.01381947472691536,0.014317181892693043,0.013930517248809338,0.012449846602976322,0.010821905918419361,0.010248390026390553,0.014104953035712242,0.014049096032977104,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 30707     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 30708     
=================================================================
Total params: 61,415
Trainable params: 61,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 30,707
Trainable params: 30,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 30,708
Trainable params: 30,708
Non-trainable params: 0
_________________________________________________________________
