2021-06-26
loss,2.310284376144409,1.1313577890396118,0.3736853003501892,0.3634198307991028,0.36185064911842346,0.3578955829143524,0.3561027944087982,0.3550741970539093,0.3555585443973541,0.3537212610244751,0.3519304394721985,0.3547247052192688,0.3531351387500763,0.3610200583934784,0.3522605001926422,0.34764736890792847,0.34576496481895447,0.3619229197502136,0.28359338641166687,0.24970866739749908,0.24090467393398285,0.23558278381824493,0.23242278397083282,0.22869527339935303,0.22310973703861237,0.21981121599674225,0.24603146314620972,0.22151370346546173,0.18821007013320923,0.16119861602783203,0.1089014932513237,0.09099763631820679,0.07459430396556854,0.07808329910039902,0.06398754566907883,0.07016249001026154,0.057149507105350494,0.05496983230113983,0.06040226295590401,0.06253120303153992,0.06906631588935852,0.07562845945358276,0.06258401274681091,0.053723860532045364,0.04791460186243057,0.04409246891736984,0.03839505836367607,0.048146720975637436,0.04769640788435936,0.04049454256892204,0.0398646742105484,0.04804664105176926,0.04571368172764778,0.04188030585646629,0.046373285353183746,0.03862820938229561,0.03851478174328804,0.03491761162877083,0.04103941097855568,0.036367956548929214,0.04504745453596115,0.056703221052885056,0.04853936284780502,0.03888418897986412,0.04164768382906914,0.03992408514022827,0.040945835411548615,0.033722903579473495,0.032885804772377014,0.04718216508626938,0.04464007541537285,0.0348551943898201,0.042161956429481506,0.03367133066058159,0.03704433515667915,0.03663893789052963,0.05168452113866806,0.03726266697049141,0.032979585230350494,0.03375972807407379,0.031851015985012054,0.040283240377902985,0.03774154931306839,0.03546363115310669,0.032388847321271896,0.028197431936860085,0.031829025596380234,0.029826946556568146,0.031031209975481033,0.03862066566944122,0.038106828927993774,0.0344221368432045,0.03105567768216133,0.03165251389145851,0.030332891270518303,0.03122183308005333,0.030775683000683784,0.027904288843274117,0.027389664202928543,0.026636244729161263,
mse,1.597764253616333,0.3778810501098633,0.04085850715637207,0.03882942721247673,0.038549359887838364,0.03793781250715256,0.03771422803401947,0.0375392809510231,0.03766007721424103,0.037415023893117905,0.03710588067770004,0.037542372941970825,0.037200313061475754,0.03842673450708389,0.03724166005849838,0.036560095846652985,0.036097507923841476,0.038051918148994446,0.024743108078837395,0.020514633506536484,0.019618885591626167,0.019128089770674706,0.018744926899671555,0.018027475103735924,0.017250752076506615,0.01628251001238823,0.01884005218744278,0.015628062188625336,0.0113953473046422,0.008175965398550034,0.0035488144494593143,0.002543690847232938,0.001704158028587699,0.001775943674147129,0.001200736965984106,0.0014799650525674224,0.0009735973435454071,0.0008772595319896936,0.0010819020681083202,0.001192603725939989,0.0013626080472022295,0.001670175464823842,0.001123864552937448,0.0008339445339515805,0.0006713204784318805,0.0005661903414875269,0.0004200345720164478,0.000675224291626364,0.0006481263553723693,0.00048166478518396616,0.000479963724501431,0.0006913297693245113,0.000643813400529325,0.0005162582965567708,0.0006823308067396283,0.00045804923865944147,0.0004379560414236039,0.00035015391767956316,0.0004952131421305239,0.0004051133873872459,0.0005944565054960549,0.0009236304322257638,0.0006820833659730852,0.0004570444580167532,0.0005106519674882293,0.00045748232514597476,0.00047579515376128256,0.00033845152938738465,0.0003244569234084338,0.0006319088279269636,0.0006093866541050375,0.0003710427845362574,0.0005092090577818453,0.0003351988270878792,0.00039321667281910777,0.00039590048254467547,0.0007617191295139492,0.000407332117902115,0.0003314831992611289,0.00033017504028975964,0.00029648380586877465,0.0004666945314966142,0.00042162014869973063,0.00036556157283484936,0.0003056841960642487,0.00024047726765275002,0.00029401510255411267,0.00026247400091961026,0.000290854019112885,0.0004455088055692613,0.0004138523945584893,0.0003319782845210284,0.00026997446548193693,0.0002824006078299135,0.0002635441778693348,0.00028182423557154834,0.0002715392329264432,0.0002293832367286086,0.0002165210753446445,0.0002055065706372261,
mae,0.8714561462402344,0.4787803590297699,0.16244779527187347,0.1579449623823166,0.1573205143213272,0.1560412049293518,0.1557304710149765,0.15561522543430328,0.15607503056526184,0.15565182268619537,0.1550663709640503,0.15599986910820007,0.15523330867290497,0.15787948668003082,0.1556309014558792,0.1540006846189499,0.1524527668952942,0.1552893966436386,0.12020127475261688,0.10313164442777634,0.09947838634252548,0.09728366881608963,0.09658633172512054,0.0964156836271286,0.09443791210651398,0.09336195141077042,0.10391835123300552,0.09387281537055969,0.07925330847501755,0.06877746433019638,0.046563051640987396,0.03830910101532936,0.031523630023002625,0.032884374260902405,0.02710629627108574,0.03006354533135891,0.024432098492980003,0.02350585162639618,0.025587504729628563,0.02641574665904045,0.029206793755292892,0.03256554901599884,0.02699798345565796,0.022933371365070343,0.020708730444312096,0.01883346401154995,0.016567561775445938,0.02050224132835865,0.020408084616065025,0.017072150483727455,0.017041001468896866,0.020413601770997047,0.019394565373659134,0.017703162506222725,0.0196931641548872,0.016709517687559128,0.01643773913383484,0.015012269839644432,0.017084136605262756,0.015732811763882637,0.018330717459321022,0.024166295304894447,0.021175015717744827,0.016518164426088333,0.01762322708964348,0.01676018349826336,0.017428932711482048,0.014485831372439861,0.013987679034471512,0.0202876515686512,0.018861791118979454,0.014875897206366062,0.017949631437659264,0.014224689453840256,0.015471811406314373,0.015392945148050785,0.022339608520269394,0.016063440591096878,0.01399549562484026,0.014363562688231468,0.013468441553413868,0.0164823979139328,0.016132283955812454,0.014878413639962673,0.013560047373175621,0.012117818929255009,0.013541442342102528,0.012704147957265377,0.013371745124459267,0.01639411970973015,0.016005419194698334,0.014188777655363083,0.013206418603658676,0.013285905122756958,0.012765455059707165,0.013278587721288204,0.012985575012862682,0.01189219206571579,0.011505234986543655,0.01134493201971054,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 397675    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 397676    
=================================================================
Total params: 795,351
Trainable params: 795,351
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 397,675
Trainable params: 397,675
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               66048     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 397,676
Trainable params: 397,676
Non-trainable params: 0
_________________________________________________________________
