2021-06-26
loss,2.897213935852051,2.224215507507324,2.2224810123443604,2.2185986042022705,2.2209062576293945,2.207043409347534,2.2056829929351807,2.206834316253662,2.205188274383545,2.251446485519409,2.2081382274627686,2.2046329975128174,2.2046072483062744,2.205815315246582,2.204702854156494,2.2038683891296387,2.2050435543060303,2.204974412918091,2.2044577598571777,2.204324245452881,2.2058463096618652,2.204303503036499,2.204893112182617,2.2046589851379395,2.2046594619750977,2.204399824142456,2.212534189224243,2.20432186126709,2.2320351600646973,2.8629496097564697,0.8518368601799011,0.44602513313293457,0.44452929496765137,0.4440578520298004,0.4444034695625305,0.44442108273506165,0.4439367651939392,0.44486525654792786,0.443930447101593,0.4446626901626587,0.44366905093193054,0.445339173078537,0.44474175572395325,0.4451359808444977,0.4449918866157532,0.43913936614990234,0.36334228515625,0.34982433915138245,0.34071671962738037,0.3337199091911316,0.32467159628868103,0.31907379627227783,0.3177327811717987,0.31069621443748474,0.30688634514808655,0.30150941014289856,0.2964724600315094,0.29660695791244507,0.2919444143772125,0.2878093421459198,0.2904212176799774,0.2831609845161438,0.27894309163093567,0.275375634431839,0.2749263644218445,0.27455398440361023,0.26977965235710144,0.2678138315677643,0.2662523686885834,0.26605096459388733,0.26411113142967224,0.2600780725479126,0.25114649534225464,0.2284514605998993,0.2058408409357071,0.1784769594669342,0.1650519222021103,0.154343843460083,0.15794755518436432,0.15399958193302155,0.1454632431268692,0.14315102994441986,0.13911043107509613,0.14667965471744537,0.13273736834526062,0.1256452202796936,0.12241847068071365,0.10962983965873718,0.10267550498247147,0.10429567098617554,0.09072108566761017,0.08570251613855362,0.09514262527227402,0.08771321922540665,0.06867288798093796,0.06507380306720734,0.06942453235387802,0.06422420591115952,0.06532958149909973,0.06864846497774124,
mse,2.233181953430176,1.2503421306610107,1.248468041419983,1.2441867589950562,1.246878981590271,1.2316569089889526,1.230229377746582,1.2315285205841064,1.2297186851501465,1.2812005281448364,1.232910394668579,1.2291691303253174,1.2291326522827148,1.2304160594940186,1.2292124032974243,1.2282482385635376,1.2295823097229004,1.229560375213623,1.2289384603500366,1.2287766933441162,1.2305095195770264,1.228833556175232,1.2294423580169678,1.2291651964187622,1.2291457653045654,1.228912115097046,1.2377736568450928,1.2288448810577393,1.2781493663787842,2.414440631866455,0.2869233787059784,0.05544811859726906,0.055045899003744125,0.054956842213869095,0.05505716800689697,0.05500330030918121,0.05494892969727516,0.05512520670890808,0.054930586367845535,0.055085767060518265,0.05483366176486015,0.05557789281010628,0.055106524378061295,0.05518340691924095,0.05516963079571724,0.054071079939603806,0.03898434713482857,0.03651178255677223,0.03464200720191002,0.033312175422906876,0.03190646693110466,0.03095598705112934,0.030617697164416313,0.02954380214214325,0.028956277295947075,0.028169605880975723,0.027444209903478622,0.027333440259099007,0.026614367961883545,0.02605804055929184,0.026279302313923836,0.025257820263504982,0.02465423196554184,0.024052999913692474,0.023989330977201462,0.02384134940803051,0.023230895400047302,0.022971000522375107,0.0226950291544199,0.02259785681962967,0.022223951295018196,0.02159961313009262,0.020202014595270157,0.016627633944153786,0.013798301108181477,0.010534738190472126,0.009194519370794296,0.008272704668343067,0.008553308434784412,0.008323350921273232,0.007446272298693657,0.007258963771164417,0.006911084055900574,0.007416992913931608,0.006454724818468094,0.005641849711537361,0.005595060531049967,0.0044085122644901276,0.003794632153585553,0.0038081069942563772,0.0029566464945673943,0.0027436381205916405,0.003126914147287607,0.0027144646737724543,0.0018675067694857717,0.001648450386710465,0.0018316409550607204,0.0015830625779926777,0.0016111400909721851,0.0017166963079944253,
mae,1.1482199430465698,0.6608642339706421,0.6536070108413696,0.6489830613136292,0.648784875869751,0.6092573404312134,0.6029415130615234,0.6107508540153503,0.6006762981414795,0.7082716226577759,0.6133723258972168,0.5994447469711304,0.5985432863235474,0.5982977151870728,0.5975989699363708,0.5969198346138,0.5970525145530701,0.5968481302261353,0.5973305106163025,0.5976398587226868,0.6036813259124756,0.5957079529762268,0.5959632396697998,0.596169650554657,0.597588300704956,0.5950196385383606,0.6241193413734436,0.5958332419395447,0.6158938407897949,1.1912380456924438,0.36405253410339355,0.1977350264787674,0.1971721649169922,0.1969590187072754,0.19714424014091492,0.1971171498298645,0.19689898192882538,0.19740574061870575,0.19687767326831818,0.19726209342479706,0.19676536321640015,0.19739504158496857,0.1972714215517044,0.19746063649654388,0.19743110239505768,0.1938927322626114,0.15488658845424652,0.14948849380016327,0.14609785377979279,0.14350226521492004,0.14023952186107635,0.13822415471076965,0.13795480132102966,0.13510094583034515,0.13335703313350677,0.13085012137889862,0.12850098311901093,0.12830375134944916,0.12620168924331665,0.12429991364479065,0.125343918800354,0.1220918595790863,0.12026947736740112,0.11856210976839066,0.11832945048809052,0.11801140010356903,0.1161249428987503,0.11521977186203003,0.11446762830018997,0.11444079130887985,0.1136794313788414,0.11182257533073425,0.10846536606550217,0.09874922782182693,0.08934309333562851,0.07728990167379379,0.0711507499217987,0.06628239899873734,0.06818298995494843,0.066342294216156,0.06275925785303116,0.06189639866352081,0.06032312288880348,0.06343510746955872,0.057393837720155716,0.05436563864350319,0.052608832716941833,0.046871643513441086,0.04374762624502182,0.044295717030763626,0.038519974797964096,0.03615845367312431,0.04082424193620682,0.037160810083150864,0.028984248638153076,0.027608979493379593,0.029451308771967888,0.02709093876183033,0.027550218626856804,0.02900162898004055,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 330483    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 330484    
=================================================================
Total params: 660,967
Trainable params: 660,967
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
encoding_layer_6 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 330,483
Trainable params: 330,483
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoding_layer_6 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 330,484
Trainable params: 330,484
Non-trainable params: 0
_________________________________________________________________
