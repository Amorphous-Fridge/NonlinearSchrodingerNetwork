2021-06-26
loss,0.4049966335296631,0.23111480474472046,0.2019789069890976,0.11404930800199509,0.1167672649025917,0.06816098839044571,0.05430503189563751,0.05014888197183609,0.04672171175479889,0.04393833503127098,0.04214358702301979,0.039883196353912354,0.038504570722579956,0.0366424098610878,0.03525751084089279,0.03405655547976494,0.03302137926220894,0.032178349792957306,0.03161165863275528,0.030822735279798508,0.030093083158135414,0.029650384560227394,0.029385780915617943,0.028594868257641792,0.02810097299516201,0.02774137444794178,0.027300791814923286,0.02667788416147232,0.026522373780608177,0.026152638718485832,0.025723863393068314,0.02547070011496544,0.025107020512223244,0.02507966198027134,0.024526912719011307,0.024418549612164497,0.023996487259864807,0.023855626583099365,0.023613836616277695,0.023393521085381508,0.023110294714570045,0.022973665967583656,0.022827738896012306,0.022538626566529274,0.0224425308406353,0.022198829799890518,0.02182329259812832,0.022066868841648102,0.021761750802397728,0.021452518180012703,0.021486641839146614,0.021332066506147385,0.021187545731663704,0.02092626877129078,0.020970012992620468,0.02077249251306057,0.020533040165901184,0.0205902811139822,0.02043699473142624,0.02036343514919281,0.020060954615473747,0.020053060725331306,0.019936511293053627,0.019834648817777634,0.019749265164136887,0.02003111131489277,0.025784289464354515,0.02778507024049759,0.025261297821998596,0.0330602265894413,0.02728044055402279,0.02440185844898224,0.022997183725237846,0.021818408742547035,0.021129406988620758,0.032016571611166,0.03658410906791687,0.03312387317419052,0.031025046482682228,0.029224328696727753,0.027863791212439537,0.026791486889123917,0.025700220838189125,0.0249093696475029,0.024037405848503113,0.023379480466246605,0.023285020142793655,0.023987196385860443,0.02810617908835411,0.03678120672702789,0.03354776278138161,0.03156133368611336,0.029726272448897362,0.027073364704847336,0.025110356509685516,0.023542482405900955,0.022432291880249977,0.02139664627611637,0.020425045862793922,0.01968175359070301,
mse,0.06874462962150574,0.018802858889102936,0.014801380224525928,0.004507913254201412,0.004404398612678051,0.001569456304423511,0.0010291060898452997,0.0008626338676549494,0.0007477067410945892,0.0006625726236961782,0.0005976703832857311,0.0005260850884951651,0.00048257113667204976,0.00043345580343157053,0.0003970088146161288,0.0003675873449537903,0.00034418085124343634,0.00032471519079990685,0.00030893870280124247,0.0002934460062533617,0.0002789525024127215,0.00026887503918260336,0.00026292444090358913,0.0002483183634467423,0.00024009145272430032,0.00023194127425085753,0.00022386322962120175,0.0002128755149897188,0.00021088225184939802,0.0002049352478934452,0.0001968527358258143,0.00019307252659928054,0.00018798222299665213,0.00018619160982780159,0.00017820460197981447,0.00017643682076595724,0.0001697036059340462,0.00016784363833721727,0.00016411133401561528,0.0001597229711478576,0.0001561579410918057,0.00015397061360999942,0.0001515570329502225,0.00014780362835153937,0.00014672659744974226,0.00014394769095815718,0.00014099500549491495,0.00014093848585616797,0.0001372264523524791,0.00013362262689042836,0.0001333384425379336,0.0001310702064074576,0.00012971842079423368,0.00012632789730560035,0.0001265513856196776,0.00012404238805174828,0.00012155259173596278,0.00012197322212159634,0.00012009438069071621,0.00011848903523059562,0.00011568149784579873,0.00011516471568029374,0.0001135796046582982,0.00011189767974428833,0.00011139419075334445,0.00012132427946198732,0.00020811258582398295,0.00023873751342762262,0.0002045843139057979,0.0003057782305404544,0.0002079261903418228,0.0001683413574937731,0.00015153407002799213,0.00013822464097756892,0.00013058284821454436,0.0002977610274683684,0.00037069219979457557,0.00030070720822550356,0.0002654598793014884,0.0002367234992561862,0.00021733305766247213,0.00020183941524010152,0.00018612522399052978,0.0001750024239299819,0.00016390028758905828,0.00015384831931442022,0.00015910064394120127,0.00017195084365084767,0.00023734066053293645,0.00036922452272847295,0.00030712620355188847,0.0002715488662943244,0.00024116114946082234,0.00020286499056965113,0.0001764521875884384,0.00015677972987759858,0.00014347834803629667,0.00013188317825552076,0.0001210674672620371,0.00011366925900802016,
mae,0.1713290810585022,0.09463218599557877,0.08372413367033005,0.04897906258702278,0.05027583986520767,0.029005639255046844,0.023181071504950523,0.021410353481769562,0.02000732719898224,0.01880730874836445,0.01808915100991726,0.01710338145494461,0.01654273271560669,0.015655210241675377,0.015060925856232643,0.014510626904666424,0.014087063260376453,0.01377967931330204,0.013539806939661503,0.013104722835123539,0.01280873455107212,0.012693755328655243,0.012533284723758698,0.012179198674857616,0.012005947530269623,0.011867664754390717,0.011604339815676212,0.01138926763087511,0.0113145150244236,0.011203426867723465,0.010941454209387302,0.010894116945564747,0.010688386857509613,0.010731500573456287,0.01050532329827547,0.010504589416086674,0.01029044296592474,0.010164499282836914,0.010152122937142849,0.009957809001207352,0.009912227280437946,0.009795456193387508,0.009765982627868652,0.009639383293688297,0.009678141213953495,0.009461385197937489,0.009285571984946728,0.009422993287444115,0.009360169060528278,0.0091897863894701,0.00922772753983736,0.00916542299091816,0.009130495600402355,0.008873308077454567,0.008946207351982594,0.008933406323194504,0.00881134532392025,0.008874960243701935,0.008756279945373535,0.008771493099629879,0.008576780557632446,0.008612904697656631,0.008391684852540493,0.008531171828508377,0.008465749211609364,0.00854543223977089,0.011216413229703903,0.01201965007930994,0.010805409401655197,0.013723994605243206,0.011482734233140945,0.010480605065822601,0.0100539680570364,0.009478420950472355,0.009037027135491371,0.013590053655207157,0.01632579416036606,0.014657826162874699,0.013672726228833199,0.01288994774222374,0.012091405689716339,0.011371406726539135,0.01077244896441698,0.010411080904304981,0.010037132538855076,0.009700201451778412,0.009875892661511898,0.0101735545322299,0.012033735401928425,0.016093650832772255,0.014673666097223759,0.013811355456709862,0.012870959006249905,0.012160868383944035,0.01103189866989851,0.010116169229149818,0.009404908865690231,0.008980907499790192,0.008738157339394093,0.008505545556545258,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3827      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3828      
=================================================================
Total params: 7,655
Trainable params: 7,655
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 3,827
Trainable params: 3,827
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 3,828
Trainable params: 3,828
Non-trainable params: 0
_________________________________________________________________
