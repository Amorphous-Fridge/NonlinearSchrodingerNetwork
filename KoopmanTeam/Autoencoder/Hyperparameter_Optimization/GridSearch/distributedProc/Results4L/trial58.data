2021-06-26
loss,0.9120715260505676,0.3304203152656555,0.27665242552757263,0.2656875550746918,0.25636929273605347,0.24902521073818207,0.2401641607284546,0.23270061612129211,0.22340980172157288,0.2158890664577484,0.21001142263412476,0.20323190093040466,0.20262697339057922,0.19162529706954956,0.18361862003803253,0.1755741834640503,0.17264677584171295,0.15608416497707367,0.13297955691814423,0.12431348115205765,0.0985550507903099,0.09823982417583466,0.07073010504245758,0.0778992623090744,0.07773826271295547,0.06298907101154327,0.058622393757104874,0.0646204724907875,0.0514133982360363,0.048893917351961136,0.045721814036369324,0.045284442603588104,0.04596726968884468,0.047582387924194336,0.04110090434551239,0.03870430588722229,0.03631303831934929,0.0378178134560585,0.03227987140417099,0.034077078104019165,0.02870609611272812,0.030220327898859978,0.02985047549009323,0.028993656858801842,0.027677422389388084,0.03068711794912815,0.025754665955901146,0.029228301718831062,0.0255905669182539,0.021630508825182915,0.024054814130067825,0.0259140245616436,0.025664931163191795,0.02436254546046257,0.018561266362667084,0.02100343443453312,0.024619286879897118,0.023984944447875023,0.023620735853910446,0.022187985479831696,0.021060669794678688,0.022524679079651833,0.02259087562561035,0.019732791930437088,0.018835222348570824,0.022546596825122833,0.02011311799287796,0.019760238006711006,0.018640829250216484,0.019489547237753868,0.02146471105515957,0.020880628377199173,0.01916780322790146,0.018546845763921738,0.020029596984386444,0.015721892938017845,0.017717091366648674,0.021319489926099777,0.019181564450263977,0.016336185857653618,0.01885618455708027,0.01954406499862671,0.017521845176815987,0.018767263740301132,0.018263285979628563,0.01914852485060692,0.017671089619398117,0.018035966902971268,0.017850669100880623,0.018314428627490997,0.01803264394402504,0.017691273242235184,0.01813330128788948,0.01715538650751114,0.016846058890223503,0.016141416504979134,0.016593627631664276,0.016506604850292206,0.01787470653653145,0.017511669546365738,
mse,0.37345460057258606,0.032739728689193726,0.023700358346104622,0.022323500365018845,0.02127581648528576,0.020308127626776695,0.019224248826503754,0.017980050295591354,0.016542969271540642,0.015484009869396687,0.014695640653371811,0.013786101713776588,0.013498191721737385,0.012300943955779076,0.011403384618461132,0.010441295802593231,0.009374812245368958,0.007398857269436121,0.005181370303034782,0.0044911871664226055,0.002860498381778598,0.0027986480854451656,0.001449288334697485,0.00174437346868217,0.0017188842175528407,0.001159665291197598,0.001001753844320774,0.0011958376271650195,0.0007476736791431904,0.0007012663991190493,0.0005922779673710465,0.0005882718251086771,0.000596865895204246,0.0006348820752464235,0.0004739566065836698,0.00043361817370168865,0.00037801035796292126,0.0003980795154348016,0.0003006895422004163,0.0003199175407644361,0.00023635377874597907,0.0002680318721104413,0.0002569517819210887,0.00023484112170990556,0.00021648334222845733,0.00026809528935700655,0.0001919230562634766,0.000245614442974329,0.00019582606910262257,0.0001379019522573799,0.0001675299135968089,0.00019024760695174336,0.0001862610806711018,0.0001675679231993854,0.00010186051804339513,0.00013278827827889472,0.00017041525279637426,0.0001620367111172527,0.00015458828420378268,0.0001422088680556044,0.00012741934915538877,0.00014642874884884804,0.00014034165360499173,0.00011204162001376972,0.00010399677557870746,0.00014582935546059161,0.00011767928663175553,0.0001149076342699118,0.0001039140042848885,0.00011089367035310715,0.00013143513933755457,0.00012413757212925702,0.00010490280692465603,0.00010047456453321502,0.00011709183308994398,7.571341848233715e-05,9.171392593998462e-05,0.00012737282668240368,0.00010500209464225918,7.793946861056611e-05,0.00010244560689898208,0.00011090148473158479,9.003952436614782e-05,0.00010081835353048518,9.8609940323513e-05,0.00010212460620095953,9.202738146996126e-05,9.527819202048704e-05,9.265589324058965e-05,9.640937787480652e-05,9.189573756884784e-05,9.108776430366561e-05,9.266231063520536e-05,8.640404121251777e-05,8.276195876533166e-05,7.717009430052713e-05,8.262877963716164e-05,8.070175681496039e-05,9.132775448961183e-05,8.847065328154713e-05,
mae,0.38967013359069824,0.1448451280593872,0.12244561314582825,0.11670416593551636,0.11226395517587662,0.10752636939287186,0.10503257811069489,0.10124862939119339,0.09683471918106079,0.09288883954286575,0.08968131244182587,0.0869213417172432,0.08590540289878845,0.08155350387096405,0.07835189253091812,0.07472854107618332,0.07231049984693527,0.06615038216114044,0.05701475590467453,0.053700946271419525,0.0417538657784462,0.04145123437047005,0.029859088361263275,0.03308681398630142,0.03331219032406807,0.02686040662229061,0.024739161133766174,0.027954155579209328,0.021721160039305687,0.021096711978316307,0.01942732371389866,0.019428305327892303,0.019149675965309143,0.020382123067975044,0.017574122175574303,0.01649579592049122,0.015452781692147255,0.01609215885400772,0.013788631185889244,0.014105038717389107,0.01147424802184105,0.012836848385632038,0.012528982944786549,0.012279749847948551,0.011771952733397484,0.012980662286281586,0.010784009471535683,0.012388854287564754,0.01085405983030796,0.009208863601088524,0.010000760667026043,0.011112687177956104,0.010770266875624657,0.01029597781598568,0.00788255874067545,0.008914551697671413,0.010404766537249088,0.010135023854672909,0.010094771161675453,0.009500717744231224,0.008975517004728317,0.009607771411538124,0.009815559722483158,0.008474416099488735,0.0079328129068017,0.009677696973085403,0.008355772122740746,0.008398613892495632,0.007914301007986069,0.008260643109679222,0.009159001521766186,0.008931795135140419,0.008101164363324642,0.00789107009768486,0.008512764237821102,0.006642505526542664,0.007462813053280115,0.008913365192711353,0.008141265250742435,0.006918753497302532,0.008056361228227615,0.008206147700548172,0.007502034772187471,0.007863775826990604,0.007685856893658638,0.008147009648382664,0.007523873820900917,0.00766874011605978,0.007572469301521778,0.007820919156074524,0.007588077802211046,0.007514826022088528,0.007775372825562954,0.007344468031078577,0.0071424623019993305,0.006820337846875191,0.006920835468918085,0.007028735242784023,0.007695922628045082,0.007473960053175688,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 181571    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 181572    
=================================================================
Total params: 363,143
Trainable params: 363,143
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 181,571
Trainable params: 181,571
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 181,572
Trainable params: 181,572
Non-trainable params: 0
_________________________________________________________________
