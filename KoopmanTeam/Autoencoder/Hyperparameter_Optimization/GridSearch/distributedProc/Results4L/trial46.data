2021-06-26
loss,0.5124273300170898,0.1044500321149826,0.10298898816108704,0.08453076332807541,0.09513358771800995,0.06850297749042511,0.08134707808494568,0.05594655126333237,0.05688617751002312,0.06677322089672089,0.049464188516139984,0.055420324206352234,0.054627999663352966,0.04395843669772148,0.044829707592725754,0.05334318056702614,0.043915919959545135,0.042646270245313644,0.040802646428346634,0.03758256137371063,0.040055014193058014,0.03792444244027138,0.03841414302587509,0.03786449879407883,0.03301480412483215,0.032906584441661835,0.034182701259851456,0.03773723542690277,0.027646632865071297,0.025421030819416046,0.02785535901784897,0.03230142965912819,0.031097056344151497,0.02551204524934292,0.030575906857848167,0.03048558533191681,0.02469700016081333,0.02902580238878727,0.02967202663421631,0.02944471687078476,0.025843314826488495,0.025990551337599754,0.027774658054113388,0.024659588932991028,0.0248817577958107,0.026963628828525543,0.023826468735933304,0.022465519607067108,0.021366450935602188,0.02313411422073841,0.0231710746884346,0.02395668439567089,0.022999513894319534,0.020293762907385826,0.018890397623181343,0.02424994669854641,0.021382011473178864,0.017910383641719818,0.015959907323122025,0.016238486394286156,0.019943736493587494,0.02280508726835251,0.02178880013525486,0.020320171490311623,0.02179606631398201,0.019710589200258255,0.018338801339268684,0.017728138715028763,0.01686454564332962,0.01951758936047554,0.018438443541526794,0.015959318727254868,0.014652695506811142,0.01303642988204956,0.014065024442970753,0.01498998049646616,0.01891428790986538,0.01892426423728466,0.018029028549790382,0.017135316506028175,0.015513453632593155,0.01624780148267746,0.015150435268878937,0.015612311661243439,0.019139716401696205,0.01801498420536518,0.016031524166464806,0.014762402512133121,0.012993638403713703,0.011921617202460766,0.013990772888064384,0.01815081387758255,0.019019216299057007,0.016578909009695053,0.016033515334129333,0.016347162425518036,0.015397462993860245,0.015563682653009892,0.013388755731284618,0.013403618708252907,
mse,0.14142653346061707,0.0032140484545379877,0.003224301850423217,0.002154403366148472,0.00265631265938282,0.0013867774978280067,0.0020455492194741964,0.0009458711137995124,0.0009714392363093793,0.0014096518279984593,0.0007368571823462844,0.0008841785020194948,0.0008642842876724899,0.0005704062059521675,0.0005993514787405729,0.0008209258085116744,0.0005695094587281346,0.000524277682416141,0.0004906280082650483,0.00041672270162962377,0.00046782888239249587,0.0004223292926326394,0.0004309886717237532,0.00041760873864404857,0.0003206303808838129,0.000315595418214798,0.0003425034519750625,0.00040162287768907845,0.00022974649618845433,0.00019138054631184787,0.00023075334320310503,0.00030112522654235363,0.00027224444784224033,0.00019652470655273646,0.0002679730823729187,0.0002657381119206548,0.00018368476594332606,0.00024348664737772197,0.0002517803222872317,0.00024672169820405543,0.00019679426623042673,0.00019473703287076205,0.0002169954386772588,0.0001746484194882214,0.00017983066209126264,0.0002093645161949098,0.0001653393410379067,0.00014663032197859138,0.0001339232112513855,0.00015160848852247,0.00016229639004450291,0.00016759440768510103,0.00014800392091274261,0.00012063843314535916,0.0001069168938556686,0.00016574862820561975,0.0001294524990953505,9.777965169632807e-05,7.622950215591118e-05,8.075775258475915e-05,0.0001174284698208794,0.00014539816766045988,0.00013321764708962291,0.00011716459994204342,0.00013233163917902857,0.00011079276009695604,9.71536646829918e-05,8.989615162136033e-05,8.189900108845904e-05,0.00011243420885875821,9.772197518032044e-05,7.73764040786773e-05,6.48055283818394e-05,4.962452294421382e-05,6.139808101579547e-05,6.876196130178869e-05,0.00010331004159525037,9.92666682577692e-05,9.191580465994775e-05,8.68571296450682e-05,7.254581578308716e-05,7.702828588662669e-05,6.980171747272834e-05,7.292951340787113e-05,0.00010156951611861587,8.936074300436303e-05,7.29581224732101e-05,6.29628702881746e-05,5.097089160699397e-05,4.3072690459666774e-05,5.980470814392902e-05,9.318454976892099e-05,9.910439257510006e-05,7.811787509126589e-05,7.649432518519461e-05,7.597238436574116e-05,7.12792607373558e-05,7.017178722890094e-05,5.413365215645172e-05,5.456856524688192e-05,
mae,0.2171664983034134,0.04440316557884216,0.043884459882974625,0.03626945987343788,0.04049716517329216,0.02884197235107422,0.03495260328054428,0.02382405288517475,0.024243459105491638,0.027847155928611755,0.021304311230778694,0.023438401520252228,0.02314281277358532,0.018590884283185005,0.019091226160526276,0.022692332044243813,0.018472226336598396,0.018039505928754807,0.017484867945313454,0.01583755388855934,0.016928615048527718,0.016182629391551018,0.01663932390511036,0.016359329223632812,0.013956805691123009,0.014069665223360062,0.01440203096717596,0.015934813767671585,0.011754543520510197,0.010830646380782127,0.011829936876893044,0.01378904189914465,0.013072362169623375,0.01076206099241972,0.012870630249381065,0.013032888062298298,0.010480199940502644,0.012402568012475967,0.012538764625787735,0.012536388821899891,0.010878538712859154,0.01117696613073349,0.0116819953545928,0.01043915469199419,0.010442522354424,0.011535278521478176,0.009927653707563877,0.009547769092023373,0.009147902950644493,0.009818127378821373,0.009816702455282211,0.010373570956289768,0.009862516075372696,0.00857014674693346,0.008000032976269722,0.010321409441530704,0.009119810536503792,0.007608364801853895,0.006802885327488184,0.006928466726094484,0.008529634214937687,0.009606736712157726,0.009382901713252068,0.008642341010272503,0.009288609027862549,0.008542297407984734,0.00787937082350254,0.007667308673262596,0.007156308740377426,0.008292607963085175,0.007869569584727287,0.006732234265655279,0.006155325565487146,0.005514098796993494,0.005984514486044645,0.006375312805175781,0.00809677317738533,0.008065734058618546,0.0075844149105250835,0.007292864378541708,0.0064829615876078606,0.006943490356206894,0.006276744417846203,0.006628596223890781,0.008098592981696129,0.007759233936667442,0.0067467414774000645,0.00629236688837409,0.0055875396355986595,0.005063341930508614,0.0059136878699064255,0.007638042792677879,0.008114596828818321,0.006830186117440462,0.006711351219564676,0.006926214788109064,0.006548695731908083,0.0065911393612623215,0.005688121542334557,0.005762625951319933,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 78547     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 78548     
=================================================================
Total params: 157,095
Trainable params: 157,095
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 78,547
Trainable params: 78,547
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 78,548
Trainable params: 78,548
Non-trainable params: 0
_________________________________________________________________
