2021-06-26
loss,0.29473188519477844,0.09393889456987381,0.06329865753650665,0.051055993884801865,0.045020557940006256,0.04199204966425896,0.04014948755502701,0.03797154501080513,0.036557260900735855,0.035520005971193314,0.03442738950252533,0.03380608931183815,0.03271790221333504,0.03204710781574249,0.03127196058630943,0.03087664395570755,0.030076978728175163,0.02987069822847843,0.029453180730342865,0.028913211077451706,0.028291739523410797,0.028048884123563766,0.02748485654592514,0.027456076815724373,0.026858191937208176,0.026582829654216766,0.026386752724647522,0.026055986061692238,0.025875229388475418,0.02546895481646061,0.025164984166622162,0.024996303021907806,0.024827562272548676,0.024548325687646866,0.024497058242559433,0.024191249161958694,0.02376081980764866,0.02362954430282116,0.023484645411372185,0.02344568818807602,0.023027243092656136,0.02292320691049099,0.022719424217939377,0.022560054436326027,0.02238578163087368,0.022215981036424637,0.02214367873966694,0.02185085602104664,0.02178063616156578,0.021569840610027313,0.02143716812133789,0.021319817751646042,0.021188337355852127,0.0209799911826849,0.020928556099534035,0.020760703831911087,0.02061745710670948,0.020472068339586258,0.020441079512238503,0.02031552977859974,0.02014593593776226,0.02018609084188938,0.019908646121621132,0.019793082028627396,0.019641093909740448,0.0197029747068882,0.01938876323401928,0.019229650497436523,0.019427286460995674,0.01926102675497532,0.01908726990222931,0.019124578684568405,0.018949493765830994,0.01882942020893097,0.018569128587841988,0.01863533817231655,0.01864573545753956,0.018432915210723877,0.018433677032589912,0.018341973423957825,0.018279079347848892,0.018045850098133087,0.01818830519914627,0.01807537116110325,0.017824506387114525,0.017880557104945183,0.017752040177583694,0.017717625945806503,0.017675653100013733,0.01743124984204769,0.017569484189152718,0.017387034371495247,0.01736435294151306,0.0174478217959404,0.0171971432864666,0.01729307882487774,0.017165109515190125,0.017107151448726654,0.017035162076354027,0.017001323401927948,
mse,0.037631675601005554,0.002948264591395855,0.0012576665030792356,0.0007975241751410067,0.0006161625497043133,0.0005334379966370761,0.0004835730360355228,0.00043361177085898817,0.00039846368599683046,0.0003760260296985507,0.00035304389894008636,0.000340678816428408,0.0003173135919496417,0.00030435810913331807,0.0002898940583691001,0.0002817249624058604,0.00026656544650904834,0.0002621735038701445,0.00025366549380123615,0.0002453023917041719,0.00023398116172757,0.00022988527780398726,0.00021916450350545347,0.0002198489528382197,0.00020964292343705893,0.00020569497428368777,0.00020224419131409377,0.00019645864085759968,0.0001938444038387388,0.0001873979199444875,0.00018432944489177316,0.0001810228277463466,0.00017709433450363576,0.00017231587844435126,0.00017226894851773977,0.00016843107005115598,0.00016192089242395014,0.00015974865527823567,0.00015772198094055057,0.00015752635954413563,0.000151650354382582,0.0001510872389189899,0.00014750787522643805,0.00014681348693557084,0.00014351746358443052,0.0001413263671565801,0.00013987346028443426,0.00013620720710605383,0.0001351614628219977,0.00013240688713267446,0.00013055889576207846,0.00012951249664183706,0.0001278578129131347,0.00012454495299607515,0.00012477116251830012,0.00012287002755329013,0.00012028394849039614,0.0001190764523926191,0.000119101743621286,0.0001174819772131741,0.00011520346743054688,0.00011577923578443006,0.0001119749213103205,0.00011216482380405068,0.00010953440505545586,0.0001106432537198998,0.00010814972483785823,0.00010451735579408705,0.00010700446728151292,0.00010532663873163983,0.00010348378418711945,0.00010336487321183085,0.00010161675163544714,0.00010049339471152052,9.900776785798371e-05,9.863308514468372e-05,9.844800661085173e-05,9.634839079808444e-05,9.601603960618377e-05,9.564233914716169e-05,9.430303907720372e-05,9.172871796181425e-05,9.360643161926419e-05,9.237536141881719e-05,8.988892659544945e-05,9.052246605278924e-05,8.947624155553058e-05,8.88402501004748e-05,8.827368583297357e-05,8.713420538697392e-05,8.782984514255077e-05,8.704445644980296e-05,8.507256279699504e-05,8.720669575268403e-05,8.361637446796522e-05,8.458733645966277e-05,8.428333967458457e-05,8.280714973807335e-05,8.227028592955321e-05,8.176454139174893e-05,
mae,0.1268276572227478,0.04049282521009445,0.02713080681860447,0.021807914599776268,0.019298888742923737,0.018008925020694733,0.017350047826766968,0.016263239085674286,0.015722382813692093,0.015215353108942509,0.01474641915410757,0.014558359049260616,0.013982015661895275,0.013710827566683292,0.013463543727993965,0.01329159364104271,0.012853283435106277,0.012846683152019978,0.01269166823476553,0.012442282401025295,0.01214219257235527,0.011956853792071342,0.011858227662742138,0.011828278191387653,0.011456367559731007,0.011458134278655052,0.01126533467322588,0.011169795878231525,0.011108151637017727,0.010806391015648842,0.010764330625534058,0.010682093910872936,0.01066854503005743,0.010551336221396923,0.010644365102052689,0.010448109358549118,0.010121972300112247,0.01007161382585764,0.010055423714220524,0.010204188525676727,0.009824314154684544,0.009743363596498966,0.00977433193475008,0.009742360562086105,0.009523633867502213,0.009453213773667812,0.009597796015441418,0.009294113144278526,0.009424570016562939,0.00929192453622818,0.009266221895813942,0.009036536328494549,0.009110928513109684,0.008954783901572227,0.008915101177990437,0.00884348712861538,0.008886125870049,0.008755888789892197,0.008680533617734909,0.00877363421022892,0.00867925863713026,0.00867395382374525,0.008446562103927135,0.008528737351298332,0.00850218627601862,0.008450368419289589,0.008391777984797955,0.008231274783611298,0.00830715149641037,0.008239924907684326,0.008203406818211079,0.008116638287901878,0.008050819858908653,0.008263649418950081,0.007998671382665634,0.008059295825660229,0.008034680970013142,0.007877178490161896,0.007784506771713495,0.007884717546403408,0.007870905101299286,0.007729609031230211,0.007818376645445824,0.007716682739555836,0.007620628923177719,0.00769915571436286,0.007628186140209436,0.007594042923301458,0.007756080478429794,0.0073699732311069965,0.007533754222095013,0.0074160462245345116,0.007429220248013735,0.00747730303555727,0.0073753343895077705,0.007405549753457308,0.007376161403954029,0.00741936918348074,0.007262613624334335,0.007304036524146795,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 5323      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 5324      
=================================================================
Total params: 10,647
Trainable params: 10,647
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 5,323
Trainable params: 5,323
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 5,324
Trainable params: 5,324
Non-trainable params: 0
_________________________________________________________________
