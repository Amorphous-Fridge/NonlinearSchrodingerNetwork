2021-06-26
loss,0.5419722199440002,0.244400754570961,0.2321804016828537,0.221901074051857,0.2129015028476715,0.19859477877616882,0.19302091002464294,0.18584325909614563,0.17909082770347595,0.17804297804832458,0.17349058389663696,0.15366902947425842,0.14242538809776306,0.12027747184038162,0.11083247512578964,0.07420361042022705,0.06845786422491074,0.05031769722700119,0.05932904779911041,0.052962690591812134,0.04825899749994278,0.03900505229830742,0.04057743027806282,0.040438078343868256,0.03739427775144577,0.04150988161563873,0.03436512500047684,0.03242763876914978,0.02983987145125866,0.03253917396068573,0.03346313163638115,0.02989957109093666,0.02766193449497223,0.02754310332238674,0.02859424613416195,0.02622813731431961,0.02800002321600914,0.026735203340649605,0.026749877259135246,0.023738021031022072,0.024817414581775665,0.023824820294976234,0.02485530450940132,0.02495635487139225,0.02350599505007267,0.019157614558935165,0.022356946021318436,0.02267777919769287,0.021976690739393234,0.020518692210316658,0.021999599412083626,0.02292524091899395,0.022315826267004013,0.018390899524092674,0.019799355417490005,0.022078894078731537,0.021596089005470276,0.020117266103625298,0.01989210769534111,0.01721862331032753,0.015734853222966194,0.020452456548810005,0.02129667066037655,0.01881035417318344,0.018777765333652496,0.02051657997071743,0.01743556559085846,0.01645970344543457,0.020073549821972847,0.019856084138154984,0.018068652600049973,0.018604055047035217,0.01960989087820053,0.019069606438279152,0.018587736412882805,0.01937914453446865,0.01687825471162796,0.01574084721505642,0.01735963299870491,0.017015747725963593,0.017308058217167854,0.016795944422483444,0.01678140088915825,0.017256945371627808,0.01836545020341873,0.014823384582996368,0.018055235967040062,0.017326606437563896,0.016010865569114685,0.016790280118584633,0.01666809804737568,0.018442096188664436,0.017530297860503197,0.016480274498462677,0.01589832454919815,0.01763805001974106,0.0177338644862175,0.01584870181977749,0.01608916185796261,0.01534566842019558,
mse,0.12722575664520264,0.01983628422021866,0.017898377031087875,0.01628333516418934,0.014985481277108192,0.01328965462744236,0.012519546784460545,0.011756423860788345,0.010967629961669445,0.0108102448284626,0.010215438902378082,0.007970120757818222,0.006000617519021034,0.004202885553240776,0.003590245731174946,0.0015964364865794778,0.0013436562148854136,0.0007417877786792815,0.0010176849318668246,0.0008023845148272812,0.0006635609897784889,0.00045652047265321016,0.0004955439362674952,0.00047385517973452806,0.0004196674271952361,0.00048737286124378443,0.0003440202272031456,0.00030626027728430927,0.00026298590819351375,0.00030520427390001714,0.00032135393121279776,0.000256052560871467,0.00022223590349312872,0.00022231800539884716,0.0002316925092600286,0.0002038532547885552,0.0002211320388596505,0.00020248342480044812,0.0002042600535787642,0.000168248254340142,0.00017753099382389337,0.0001662100839894265,0.00017467023280914873,0.00017468153964728117,0.000156955182319507,0.00010967520938720554,0.00014441512757912278,0.0001482501538703218,0.00013996870256960392,0.0001247694599442184,0.00014033695333637297,0.000149415252963081,0.00014025603013578802,0.00010168713197344914,0.00011768684635171667,0.00013743019371759146,0.00013406672223936766,0.0001182710548164323,0.00011500270920805633,8.960656123235822e-05,7.403155177598819e-05,0.00012574595166370273,0.00012921742745675147,0.00010428120731376112,0.00010340395238017663,0.00011936012015212327,8.973108924692497e-05,8.217541471822187e-05,0.00011593315139180049,0.00011034611816285178,9.719961235532537e-05,0.00010000806651078165,0.00010925615788437426,0.0001036444737110287,9.865086758509278e-05,0.00010592446778900921,8.330817217938602e-05,7.596276554977521e-05,8.939092367654666e-05,8.44653113745153e-05,8.898554369807243e-05,8.45536997076124e-05,8.348072151420638e-05,8.879083907231688e-05,9.665685502113774e-05,6.740147364325821e-05,9.684252290753648e-05,8.826787234283984e-05,7.644930155947804e-05,8.41225846670568e-05,8.280391921289265e-05,9.780833352124318e-05,8.828595309751108e-05,7.948162237880751e-05,7.578507211292163e-05,9.011403744807467e-05,8.94671757123433e-05,7.425021613016725e-05,7.716806430835277e-05,6.993577699176967e-05,
mae,0.2277323603630066,0.10954096913337708,0.10360846668481827,0.09640941023826599,0.09161993861198425,0.08398358523845673,0.08192845433950424,0.07854671031236649,0.0757334977388382,0.07569120079278946,0.07334141433238983,0.0652119591832161,0.0602598711848259,0.0507698729634285,0.0471649169921875,0.03161671757698059,0.029027407988905907,0.021212151274085045,0.02517346851527691,0.022228242829442024,0.02025606855750084,0.016626756638288498,0.01715780980885029,0.01719079166650772,0.015662532299757004,0.017601139843463898,0.014360104687511921,0.013623077422380447,0.012678253464400768,0.013814874924719334,0.014313345775008202,0.012772037647664547,0.01173312682658434,0.011720155365765095,0.01226747501641512,0.01113901473581791,0.01195437926799059,0.01136837713420391,0.011337148025631905,0.010024174116551876,0.01049695536494255,0.01014851313084364,0.01066313311457634,0.01046797726303339,0.00992643740028143,0.008166112005710602,0.009523330256342888,0.00955074280500412,0.00940148439258337,0.008685394190251827,0.009318401105701923,0.009588014334440231,0.009448088705539703,0.00785280205309391,0.008322200737893581,0.009380524978041649,0.009103692136704922,0.008695068769156933,0.008376307785511017,0.007216630037873983,0.006669448222965002,0.008739102631807327,0.00894614402204752,0.00806552916765213,0.008000963367521763,0.00860616099089384,0.007340588606894016,0.007007134612649679,0.008416292257606983,0.008403035812079906,0.007609540596604347,0.00798709411174059,0.008268751204013824,0.008074923418462276,0.00781993567943573,0.008216829039156437,0.007156767882406712,0.006699480582028627,0.00738166831433773,0.0072856624610722065,0.007400056347250938,0.007108503021299839,0.0071172695606946945,0.007256369572132826,0.007829925045371056,0.006343436893075705,0.007715743035078049,0.007404891774058342,0.006764957681298256,0.007087779231369495,0.0070393686182796955,0.007821773178875446,0.007413820829242468,0.006938102655112743,0.006807157304137945,0.007529782596975565,0.007522850763052702,0.006790665443986654,0.00688173295930028,0.0065375990234315395,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 116099    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 116100    
=================================================================
Total params: 232,199
Trainable params: 232,199
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 116,099
Trainable params: 116,099
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 116,100
Trainable params: 116,100
Non-trainable params: 0
_________________________________________________________________
