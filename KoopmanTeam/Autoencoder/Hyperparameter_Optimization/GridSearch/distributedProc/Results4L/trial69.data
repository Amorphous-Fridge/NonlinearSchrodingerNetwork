2021-06-26
loss,2.301262617111206,2.2216403484344482,2.220163106918335,2.2183990478515625,2.2105929851531982,2.272505283355713,0.8464842438697815,0.29297131299972534,0.22049343585968018,0.18837985396385193,0.19510485231876373,0.15397462248802185,0.09941422194242477,0.09106466174125671,0.12091854959726334,0.10097228735685349,0.09781492501497269,0.08729727566242218,0.06371123343706131,0.05285237357020378,0.0509849414229393,0.067640520632267,0.06148425489664078,0.057191699743270874,0.0558399073779583,0.07132001221179962,0.07392594963312149,0.06467337161302567,0.05997718870639801,0.05969374626874924,0.045959729701280594,0.03706251457333565,0.04158524051308632,0.05345015227794647,0.060796331614255905,0.046237677335739136,0.04675653576850891,0.04341355338692665,0.04560420662164688,0.05110487341880798,0.03754885122179985,0.04352472722530365,0.04364873096346855,0.04760053753852844,0.040472183376550674,0.036359816789627075,0.04086155444383621,0.03700992837548256,0.04481333866715431,0.039167847484350204,0.03966861590743065,0.03660815581679344,0.037120427936315536,0.03816636651754379,0.038658272475004196,0.036658648401498795,0.035804372280836105,0.03291366249322891,0.03366537019610405,0.0333528071641922,0.03904954716563225,0.03024863451719284,0.03175092861056328,0.029356298968195915,0.029460126534104347,0.03560914844274521,0.033171147108078,0.03311915323138237,0.032970525324344635,0.03260408341884613,0.03363511338829994,0.03186377137899399,0.03147297352552414,0.03223477303981781,0.0350167453289032,0.028806040063500404,0.03311752900481224,0.026479143649339676,0.02876502275466919,0.030868297442793846,0.02883865125477314,0.032010458409786224,0.031218135729432106,0.02950967848300934,0.02898341231048107,0.02729140780866146,0.024088909849524498,0.02103242464363575,0.029696015641093254,0.03208792954683304,0.029368015006184578,0.02690902166068554,0.027269411832094193,0.026033254340291023,0.02892296016216278,0.026480425149202347,0.02844669669866562,0.031004304066300392,0.025752656161785126,0.02418382465839386,
mse,1.3515498638153076,1.2473899126052856,1.2457650899887085,1.2438538074493408,1.2355529069900513,1.3629307746887207,0.337588906288147,0.026196734979748726,0.01453443244099617,0.010547582991421223,0.011129672639071941,0.007058524060994387,0.003074872540310025,0.002526721451431513,0.004154672380536795,0.0029172063805162907,0.002696976298466325,0.0021518850699067116,0.001276788068935275,0.0008760064956732094,0.0007994965417310596,0.001358648994937539,0.0011196521809324622,0.0009692166931927204,0.0009043501340784132,0.001424880581907928,0.0015139717143028975,0.00117706588935107,0.001006630714982748,0.0009918250143527985,0.0006169842672534287,0.0004050509596709162,0.0004932637675665319,0.0008278853492811322,0.0010109101422131062,0.0005999599234201014,0.0006290684686973691,0.0005234271520748734,0.0005821455270051956,0.0007297543343156576,0.00041616824455559254,0.0005323023069649935,0.0005311378045007586,0.0006265005213208497,0.000463541888166219,0.0003923684125766158,0.000478715926874429,0.00038427181425504386,0.000558936211746186,0.00042928371112793684,0.000446025631390512,0.00037218027864582837,0.00038480234798043966,0.00040612148586660624,0.00041425161180086434,0.00037152282311581075,0.00036704647936858237,0.00030962127493694425,0.0003231404407415539,0.00032144493889063597,0.0004351842508185655,0.0002645854838192463,0.0002753086155280471,0.00024167474475689232,0.00024772415054030716,0.0003601907519623637,0.0003166092501487583,0.0003004910540767014,0.00031198610668070614,0.00030358810909092426,0.0003177902544848621,0.0002821458620019257,0.0002828325377777219,0.00029455189360305667,0.0003349286562297493,0.00023664745094720274,0.00030889632762409747,0.0001975528575712815,0.00023945100838318467,0.0002631333190947771,0.00023274104751180857,0.00028721053968183696,0.00026737977168522775,0.00024333443434443325,0.00023104296997189522,0.00020691099052783102,0.00016801030142232776,0.00013194807979743928,0.00024838585522957146,0.0002869591407943517,0.0002440671087242663,0.000200774593395181,0.00020607459009625018,0.000195079279365018,0.00023288938973564655,0.00019442247867118567,0.00023229712678585202,0.000263590132817626,0.00018600467592477798,0.00016601075185462832,
mae,0.7679165005683899,0.6532511711120605,0.6523726582527161,0.6430585980415344,0.6239163875579834,0.6624259352684021,0.36209622025489807,0.12685273587703705,0.09283235669136047,0.0788113921880722,0.08431897312402725,0.06553453207015991,0.04323799908161163,0.03882960230112076,0.052308205515146255,0.042794812470674515,0.04219947010278702,0.03791595622897148,0.027525626122951508,0.022640559822320938,0.021922944113612175,0.029145020991563797,0.02611645497381687,0.024695055559277534,0.02352455072104931,0.030770709738135338,0.032068248838186264,0.02680705301463604,0.025611812248826027,0.02538999542593956,0.019707176834344864,0.015742776915431023,0.017794061452150345,0.022511709481477737,0.02600443921983242,0.01982078142464161,0.019945664331316948,0.018086276948451996,0.019325995817780495,0.022158188745379448,0.016223842278122902,0.01835682801902294,0.018653390929102898,0.02068863809108734,0.01735524646937847,0.015719110146164894,0.017559414729475975,0.01570499874651432,0.019450224936008453,0.01673002541065216,0.017367444932460785,0.015555048361420631,0.015867380425333977,0.01627783663570881,0.016572101041674614,0.015752749517560005,0.015470697544515133,0.013973775319755077,0.014016861096024513,0.01429540291428566,0.016937535256147385,0.012729883193969727,0.013463440351188183,0.012516425922513008,0.012695318087935448,0.015231763012707233,0.014233306981623173,0.013933058828115463,0.014283288270235062,0.014070209115743637,0.014721475541591644,0.0135950967669487,0.01291950698941946,0.013659757561981678,0.015242103487253189,0.012371111661195755,0.014463513158261776,0.011276022531092167,0.012097911909222603,0.01328739058226347,0.012461680918931961,0.013618402183055878,0.013564868830144405,0.012326565571129322,0.012305977754294872,0.011388106271624565,0.01016408484429121,0.008997034281492233,0.012764793820679188,0.013988184742629528,0.012598183006048203,0.011367266066372395,0.011554625816643238,0.011110036633908749,0.012201141566038132,0.01129500474780798,0.011781190522015095,0.01380036398768425,0.0109349200502038,0.010322297923266888,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 287955    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 287956    
=================================================================
Total params: 575,911
Trainable params: 575,911
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 287,955
Trainable params: 287,955
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 287,956
Trainable params: 287,956
Non-trainable params: 0
_________________________________________________________________
