2021-06-26
loss,0.3472546637058258,0.106633760035038,0.06583403795957565,0.057256270200014114,0.05431065708398819,0.07778933644294739,0.056692562997341156,0.04847417771816254,0.043956246227025986,0.04005466029047966,0.03501054272055626,0.03238745033740997,0.03081062249839306,0.02997971512377262,0.028888219967484474,0.028360052034258842,0.03197404742240906,0.04584044590592384,0.039097629487514496,0.03451167419552803,0.032031234353780746,0.030283937230706215,0.058948103338479996,0.044213052839040756,0.039985377341508865,0.03676240146160126,0.03442415967583656,0.03196433559060097,0.03496776893734932,0.04807783663272858,0.04341757297515869,0.03950466215610504,0.03664439544081688,0.03354353830218315,0.03147408738732338,0.029742401093244553,0.02829800173640251,0.02689683437347412,0.025909142568707466,0.02497098594903946,0.02436598390340805,0.023964455351233482,0.033243659883737564,0.03638479858636856,0.03221694007515907,0.029557039961218834,0.02750011719763279,0.025123441591858864,0.036399222910404205,0.037277016788721085,0.03348909690976143,0.03133603557944298,0.029282473027706146,0.02754102274775505,0.02574651874601841,0.024174213409423828,0.02243448793888092,0.02086521126329899,0.019962700083851814,0.019332926720380783,0.01838494837284088,0.027115412056446075,0.02977324090898037,0.029064971953630447,0.025470538064837456,0.02362322248518467,0.02239091880619526,0.021721916273236275,0.020983710885047913,0.020543955266475677,0.02033306285738945,0.02869170345366001,0.02762935310602188,0.025530032813549042,0.02404731698334217,0.023090709000825882,0.03473418205976486,0.031014205887913704,0.02851819433271885,0.026808710768818855,0.025224454700946808,0.023745520040392876,0.0220698993653059,0.020906493067741394,0.02018461935222149,0.019226549193263054,0.017775503918528557,0.02275710366666317,0.024139294400811195,0.021959569305181503,0.02212374657392502,0.02112186886370182,0.019620798528194427,0.0183008573949337,0.02198122814297676,0.021592669188976288,0.019685832783579826,0.018664533272385597,0.028586506843566895,0.026093481108546257,
mse,0.05623321235179901,0.0035570962354540825,0.0012957305880263448,0.0009540820028632879,0.000882151594851166,0.0017450483283028007,0.0009062986937351525,0.0006664253305643797,0.0005477494560182095,0.00048080217675305903,0.0003535547584760934,0.00030078820418566465,0.0002718756441026926,0.0002560810826253146,0.00023743716883473098,0.00022909030667506158,0.0003164741792716086,0.0005784660461358726,0.0004169238090980798,0.00032740196911618114,0.00028139640926383436,0.000254480546573177,0.0011924945283681154,0.0005428774747997522,0.00044457026524469256,0.0003800519625656307,0.0003340108960401267,0.0002878390369005501,0.0003616557514760643,0.000642535975202918,0.0005259442841634154,0.00043627331615425646,0.0003749353054445237,0.0003100128669757396,0.0002729620027821511,0.00024323011166416109,0.00022195951896719635,0.0002006797876674682,0.00018609339895192534,0.0001728572096908465,0.00016515962488483638,0.00015900289872661233,0.0003259582445025444,0.00036174050183035433,0.0002839638036675751,0.00024204047804232687,0.00021085616026539356,0.00017536833183839917,0.00039183508488349617,0.0003816791286226362,0.0003087014483753592,0.0002686205552890897,0.0002352216251892969,0.00020845474500674754,0.00018172955606132746,0.00016065633099060506,0.00013983076496515423,0.00012421104474924505,0.0001131017052102834,0.000105517559859436,9.758463420439512e-05,0.00020964084251318127,0.0002501903800293803,0.0002242383488919586,0.00017493366613052785,0.0001519176148576662,0.0001374648418277502,0.00013028547982685268,0.0001217976096086204,0.00011683090269798413,0.00011550365161383525,0.0002293016732437536,0.00020656570268329233,0.0001790696696843952,0.00015939919103402644,0.00014967916649766266,0.00033929236815311015,0.00026679167058318853,0.00022298205294646323,0.00019668547611217946,0.00017484831914771348,0.00015445826284121722,0.00013406146899797022,0.00012158755271229893,0.00011410989100113511,0.00010678537364583462,9.304037666879594e-05,0.00014584336895495653,0.00016107562987599522,0.00013532929006032646,0.0001360459136776626,0.00012179995246697217,0.00010639318497851491,9.543886699248105e-05,0.00013459967158269137,0.0001247700274689123,0.00010614839993650094,9.765107097337022e-05,0.00022614479530602694,0.00018291641026735306,
mae,0.1461649388074875,0.044847387820482254,0.027794988825917244,0.024266021326184273,0.022812798619270325,0.033272407948970795,0.02396734245121479,0.01997436210513115,0.018399283289909363,0.017249690368771553,0.015110553242266178,0.013962897472083569,0.01328822411596775,0.012892846949398518,0.0124178696423769,0.012081119231879711,0.013733911328017712,0.019277198240160942,0.017300479114055634,0.015197478234767914,0.013876601122319698,0.012831185013055801,0.025622989982366562,0.01905735768377781,0.0176309235394001,0.016184911131858826,0.014826254919171333,0.013586125336587429,0.014854219742119312,0.020380571484565735,0.017960142344236374,0.016381943598389626,0.015123548917472363,0.013885400258004665,0.01332106627523899,0.012882170267403126,0.012111875228583813,0.011061455123126507,0.010638285428285599,0.010282694362103939,0.010292011313140392,0.010023081675171852,0.014246073551476002,0.015331233851611614,0.01294037140905857,0.01178030576556921,0.01073434203863144,0.01058751717209816,0.015384173020720482,0.016108594834804535,0.014510362409055233,0.013737207278609276,0.012863732874393463,0.01173867005854845,0.01072020921856165,0.010262936353683472,0.009988898411393166,0.009098326787352562,0.008763173595070839,0.008518672548234463,0.00796976126730442,0.011944200843572617,0.013018239289522171,0.012081210501492023,0.010159101337194443,0.009462892077863216,0.008987599052488804,0.00877335760742426,0.008536289446055889,0.008527146652340889,0.00857532024383545,0.01243872381746769,0.012246830388903618,0.01136367954313755,0.010717098601162434,0.010019284673035145,0.014066344127058983,0.012683933600783348,0.011690527200698853,0.011004175059497356,0.010579725727438927,0.009981409646570683,0.009136050939559937,0.008848858065903187,0.00859733484685421,0.00817881803959608,0.007595074363052845,0.009686036966741085,0.010320651344954967,0.009363733232021332,0.009559792466461658,0.008897957392036915,0.008504047989845276,0.007852074690163136,0.009537295438349247,0.009292209520936012,0.00844893604516983,0.008002076297998428,0.012635885737836361,0.011850476264953613,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 7507      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 7508      
=================================================================
Total params: 15,015
Trainable params: 15,015
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 7,507
Trainable params: 7,507
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                4160      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 7,508
Trainable params: 7,508
Non-trainable params: 0
_________________________________________________________________
