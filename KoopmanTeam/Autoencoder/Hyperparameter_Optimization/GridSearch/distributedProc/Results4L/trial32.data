2021-06-26
loss,0.4214213490486145,0.15630289912223816,0.14030547440052032,0.10704034566879272,0.09212501347064972,0.06997577846050262,0.06928754597902298,0.06603680551052094,0.05500202625989914,0.054152585566043854,0.059483278542757034,0.05352926254272461,0.061237234622240067,0.05435623228549957,0.04376966506242752,0.04006894677877426,0.04753592610359192,0.04685407504439354,0.03852543234825134,0.03920760378241539,0.04234422370791435,0.03279060497879982,0.029136208817362785,0.036560285836458206,0.03855634853243828,0.04169392213225365,0.03869333118200302,0.033970676362514496,0.028984032571315765,0.031011812388896942,0.03776397928595543,0.02955581434071064,0.028785740956664085,0.02565154619514942,0.02711743861436844,0.027817502617836,0.032069314271211624,0.020145205780863762,0.03159174695611,0.028567980974912643,0.02957063913345337,0.03035510703921318,0.028399961069226265,0.031311169266700745,0.02618241496384144,0.02129608951508999,0.02120279334485531,0.025296293199062347,0.028581200167536736,0.028368286788463593,0.02866591140627861,0.022498006001114845,0.027853215113282204,0.02666419930756092,0.022277100011706352,0.022781046107411385,0.02141754701733589,0.02075142227113247,0.022316990420222282,0.022831926122307777,0.020762674510478973,0.017035607248544693,0.022070081904530525,0.02543880045413971,0.02498418278992176,0.02416006475687027,0.022610556334257126,0.02006935141980648,0.019528811797499657,0.02064831554889679,0.020692896097898483,0.020944567397236824,0.01990460976958275,0.02079728990793228,0.024092070758342743,0.021561214700341225,0.02045752853155136,0.01999969594180584,0.01985432207584381,0.018629560247063637,0.0195454154163599,0.016363589093089104,0.014932874590158463,0.014755155891180038,0.014005615375936031,0.013940512202680111,0.020518600940704346,0.02026261016726494,0.017764953896403313,0.01803613267838955,0.01738928258419037,0.0186774805188179,0.018466763198375702,0.01965181529521942,0.018772553652524948,0.020858876407146454,0.017475103959441185,0.01615685038268566,0.014857604168355465,0.017628991976380348,
mse,0.07839199155569077,0.00729562109336257,0.005574971437454224,0.0032193565275520086,0.0025662786792963743,0.0014379365602508187,0.0013397266156971455,0.0012726724380627275,0.0008588047348894179,0.0008487115264870226,0.0011034959461539984,0.0008200025768019259,0.0011632137466222048,0.0008603811729699373,0.0005518386606127024,0.000461284740595147,0.0006370194023475051,0.0006617328035645187,0.00041864882223308086,0.00043474804260767996,0.0005057569360360503,0.00031952265999279916,0.0002467108715791255,0.00037785994936712086,0.00042187556391581893,0.0004918582271784544,0.0004245781456120312,0.0003212442679796368,0.00024275250325445086,0.00028166346601210535,0.0003992233832832426,0.00024976718123070896,0.0002361243386985734,0.00019101703946944326,0.00021261534129735082,0.0002223140763817355,0.0002971852954942733,0.00011965297744609416,0.00028550770366564393,0.000235218700254336,0.00024165298964362592,0.00025667966110631824,0.00022873874695505947,0.00027719163335859776,0.0001932566228788346,0.00013402526383288205,0.00013276720710564405,0.0001822799094952643,0.00022584374528378248,0.0002341965737286955,0.00023478316143155098,0.00014614089741371572,0.0002146147016901523,0.00020533520728349686,0.00014239887241274118,0.00015120221360120922,0.00013295517419464886,0.0001241692079929635,0.00014600880967918783,0.0001488622947363183,0.00012582556519191712,8.633131074020639e-05,0.00013805011985823512,0.0001810576650314033,0.00017531710909679532,0.0001655215455684811,0.00014362628280650824,0.00011606108455453068,0.00010899308836087584,0.000116920709842816,0.00012094025441911072,0.00012182750651845708,0.00011432810424594209,0.00012369362229947,0.00016229836910497397,0.00013136665802448988,0.00011927828018087894,0.00011293296847725287,0.00011501954577397555,0.00010301099973730743,0.00010533501335885376,7.744033064227551e-05,6.75351548125036e-05,6.477933493442833e-05,5.98210099269636e-05,5.78059334657155e-05,0.00012154618161730468,0.00011468691809568554,9.029972716234624e-05,9.238423081114888e-05,9.098887676373124e-05,0.00010131648014066741,9.760657121660188e-05,0.00010719161218730733,9.92192726698704e-05,0.00012378794781398028,8.47589981276542e-05,7.38381568226032e-05,6.581833440577611e-05,8.874383638612926e-05,
mae,0.18290670216083527,0.0654151663184166,0.059688176959753036,0.04570172354578972,0.038694266229867935,0.029808616265654564,0.029420480132102966,0.0281817726790905,0.02306009829044342,0.02310699224472046,0.025492044165730476,0.02311583049595356,0.0265288595110178,0.022962244227528572,0.01885729841887951,0.017064997926354408,0.02027777209877968,0.020042631775140762,0.01624109596014023,0.016753267496824265,0.01802320033311844,0.013918984681367874,0.012272925116121769,0.015816396102309227,0.016324438154697418,0.017868267372250557,0.016464902088046074,0.014431893825531006,0.012112434953451157,0.013149995356798172,0.01587468758225441,0.012464585714042187,0.012140120379626751,0.010918477550148964,0.011428323574364185,0.011774223297834396,0.01367616280913353,0.008520330302417278,0.013694760389626026,0.012145084328949451,0.012543069198727608,0.012864373624324799,0.011991378851234913,0.013563519343733788,0.011133602820336819,0.009024670347571373,0.009041884914040565,0.010589051060378551,0.0120730921626091,0.01216364186257124,0.012267670594155788,0.009550219401717186,0.011858181096613407,0.011184551753103733,0.009512397460639477,0.00977467093616724,0.009052472189068794,0.00881409365683794,0.009539383463561535,0.009590218774974346,0.008806074969470501,0.007262031547725201,0.009457733482122421,0.010725072585046291,0.010670573450624943,0.010401270352303982,0.009594965726137161,0.008519084192812443,0.008288802579045296,0.008656054735183716,0.008927244693040848,0.009008551016449928,0.008443448692560196,0.008796988055109978,0.010260563343763351,0.009093177504837513,0.008831040002405643,0.008468830958008766,0.008499029092490673,0.007913590408861637,0.008179201744496822,0.006869073957204819,0.006355862133204937,0.006337480619549751,0.005984864663332701,0.0059303040616214275,0.008682481944561005,0.008618618361651897,0.007367400452494621,0.007641736418008804,0.0074548558332026005,0.0079801669344306,0.007862547412514687,0.008268766105175018,0.007978967390954494,0.009021352045238018,0.00751606235280633,0.0069678667932748795,0.00628711748868227,0.007557779084891081,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 29379     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 29380     
=================================================================
Total params: 58,759
Trainable params: 58,759
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 29,379
Trainable params: 29,379
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 29,380
Trainable params: 29,380
Non-trainable params: 0
_________________________________________________________________
