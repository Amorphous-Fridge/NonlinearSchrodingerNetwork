2021-06-26
loss,0.4659912884235382,0.2629249393939972,0.1600361466407776,0.13312438130378723,0.0793347954750061,0.059617623686790466,0.05154005438089371,0.046744707971811295,0.044089432805776596,0.04155806452035904,0.04542752727866173,0.05291226506233215,0.05996152013540268,0.052784644067287445,0.046367060393095016,0.050129394978284836,0.059842899441719055,0.05959651619195938,0.05429062992334366,0.030540114268660545,0.033103086054325104,0.04669453948736191,0.04617907851934433,0.044926274567842484,0.04183736816048622,0.043807078152894974,0.03991425409913063,0.04332096502184868,0.04374372586607933,0.04053904861211777,0.03824787586927414,0.03634636476635933,0.03446260094642639,0.03160519525408745,0.027904877439141273,0.02498825639486313,0.023275889456272125,0.0257879588752985,0.03848657011985779,0.03541986644268036,0.03325463458895683,0.03172668069601059,0.03036884032189846,0.02858404815196991,0.027906673029065132,0.039095669984817505,0.03436262905597687,0.031056556850671768,0.028839534148573875,0.028209710493683815,0.02769104391336441,0.026906007900834084,0.02803761512041092,0.03209858760237694,0.029254280030727386,0.02762252278625965,0.026328956708312035,0.023934025317430496,0.02172984927892685,0.02069946937263012,0.01899063028395176,0.016414843499660492,0.0160220880061388,0.016169436275959015,0.015825467184185982,0.015926698222756386,0.015800638124346733,0.01575486920773983,0.015432888641953468,0.015578820370137691,0.015342812985181808,0.015256727114319801,0.01511052343994379,0.015135006979107857,0.015022370964288712,0.014846401289105415,0.014788861386477947,0.014754273928701878,0.01468261331319809,0.014584733173251152,0.014481958001852036,0.014428840018808842,0.0143507719039917,0.014163737185299397,0.014150158502161503,0.014146688394248486,0.014210508204996586,0.014096604660153389,0.014068827964365482,0.013941236771643162,0.013902905397117138,0.016579387709498405,0.023088626563549042,0.022304575890302658,0.023482773452997208,0.024175286293029785,0.022380592301487923,0.021275080740451813,0.019856423139572144,0.01852678693830967,
mse,0.07935214787721634,0.02234625071287155,0.009221557527780533,0.005458431784063578,0.001868269988335669,0.0011182344751432538,0.0008244498167186975,0.0006693400209769607,0.0005781317013315856,0.000509678793605417,0.0006243711104616523,0.0008641063468530774,0.0009940906893461943,0.0007823691703379154,0.0006189752602949739,0.0007074106251820922,0.0010442960774526,0.001021283445879817,0.0008523592841811478,0.0002894510980695486,0.0003527539665810764,0.0006150742410682142,0.0006137483287602663,0.0006053996621631086,0.0005141794099472463,0.0005661261384375393,0.00044885941315442324,0.0005505222361534834,0.0005383736570365727,0.0004663927829824388,0.0004169124295003712,0.0003827553882729262,0.00034564477391541004,0.0002948215405922383,0.00023017310013528913,0.00018439248378854245,0.0001612505438970402,0.00020319392206147313,0.0004200312541797757,0.0003493520198389888,0.00031348521588370204,0.0002874752099160105,0.00026509573217481375,0.00023362597858067602,0.00022887729573994875,0.0004257429682184011,0.0003321353578940034,0.00027233458240516484,0.00024017378746066242,0.00022380519658327103,0.00022067144163884223,0.0002034898498095572,0.0002280749031342566,0.00028313026996329427,0.00023984139261301607,0.00021727319108322263,0.00020094375940971076,0.00016569969011470675,0.0001413952122675255,0.00012573714775498956,0.00010627827577991411,8.078505925368518e-05,7.552737224614248e-05,7.512286538258195e-05,7.347354403464124e-05,7.362801989074796e-05,7.189790630945936e-05,7.136151543818414e-05,6.868909258628264e-05,6.90080996719189e-05,6.789351027691737e-05,6.672356539638713e-05,6.56888514640741e-05,6.547517114086077e-05,6.43180901533924e-05,6.25125685473904e-05,6.28726847935468e-05,6.292872421909124e-05,6.15098251728341e-05,6.090702663641423e-05,5.984853851259686e-05,5.919999966863543e-05,5.8362373238196597e-05,5.7737212046049535e-05,5.7378016208531335e-05,5.878850424778648e-05,5.698292443412356e-05,5.683234485331923e-05,5.644228804158047e-05,5.549191337195225e-05,5.527557004825212e-05,8.816791523713619e-05,0.00015129432722460479,0.0001393575221300125,0.00015952868852764368,0.00016485458763781935,0.0001408457465004176,0.00012969480303581804,0.00011498120875330642,0.00010187277803197503,
mae,0.1996571123600006,0.11886575818061829,0.07036629319190979,0.05683305114507675,0.0339343436062336,0.02541789971292019,0.02223381958901882,0.020005984231829643,0.018894223496317863,0.017893856391310692,0.019459940493106842,0.02238784357905388,0.025832457467913628,0.022732147946953773,0.01943305879831314,0.02122265286743641,0.026032475754618645,0.02614257112145424,0.023997996002435684,0.013125077821314335,0.013958685100078583,0.02029687911272049,0.019967805594205856,0.019334375858306885,0.017605548724532127,0.019078576937317848,0.017582213506102562,0.018915332853794098,0.018660224974155426,0.01707254722714424,0.015884069725871086,0.015089772641658783,0.014835339039564133,0.013955716975033283,0.011947430670261383,0.010417976416647434,0.00972241722047329,0.010954547673463821,0.016343744471669197,0.0145409582182765,0.01352123823016882,0.012880300171673298,0.012478278949856758,0.012312501668930054,0.011733039282262325,0.017400452867150307,0.015272906981408596,0.01357484795153141,0.012284751050174236,0.012009206227958202,0.01236974447965622,0.011919207870960236,0.011940530501306057,0.013863780535757542,0.012399574741721153,0.011471348814666271,0.011418047361075878,0.010329830460250378,0.009122636169195175,0.008800630457699299,0.008044140413403511,0.007043255493044853,0.006976810749620199,0.006927472539246082,0.006814656313508749,0.0068353996612131596,0.006776167079806328,0.006769052240997553,0.006627651397138834,0.006654909811913967,0.006574873812496662,0.0065550426952540874,0.0064656613394618034,0.006426181644201279,0.006402137689292431,0.006398205179721117,0.006333448458462954,0.006289954297244549,0.006269093137234449,0.0061186267994344234,0.006117792334407568,0.006137926131486893,0.006091543473303318,0.00604501087218523,0.00604547094553709,0.005959002301096916,0.0060953861102461815,0.006073289085179567,0.005959380883723497,0.00591664295643568,0.005921063479036093,0.007028436288237572,0.010112776421010494,0.009469529613852501,0.009868023917078972,0.010811549611389637,0.009944694116711617,0.009134668856859207,0.008602454327046871,0.008046659640967846,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 18763     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 18764     
=================================================================
Total params: 37,527
Trainable params: 37,527
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 18,763
Trainable params: 18,763
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 18,764
Trainable params: 18,764
Non-trainable params: 0
_________________________________________________________________
