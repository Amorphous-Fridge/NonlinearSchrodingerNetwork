2021-06-26
loss,0.9689121842384338,0.14095036685466766,0.09861781448125839,0.09888900816440582,0.08125080913305283,0.05979136377573013,0.05618206039071083,0.039734650403261185,0.04522348940372467,0.04019256681203842,0.035349152982234955,0.03754214197397232,0.03359192982316017,0.028276851400732994,0.027403738349676132,0.034254804253578186,0.02824222482740879,0.023676330223679543,0.025061344727873802,0.02697935327887535,0.025164436548948288,0.02532849833369255,0.025872360914945602,0.026028836145997047,0.022907033562660217,0.025392694398760796,0.020736848935484886,0.024722406640648842,0.023561866953969002,0.02082919515669346,0.022647609934210777,0.022431960329413414,0.02191159874200821,0.023807059973478317,0.021172530949115753,0.021981587633490562,0.01977059803903103,0.02209317497909069,0.021309826523065567,0.01885121501982212,0.0178328026086092,0.01803097315132618,0.023203520104289055,0.02297152951359749,0.022002696990966797,0.020078830420970917,0.021469704806804657,0.01865481212735176,0.021759137511253357,0.018539702519774437,0.01954069547355175,0.021481789648532867,0.021474938839673996,0.0207148976624012,0.020977776497602463,0.019598722457885742,0.017795588821172714,0.021428514271974564,0.020999884232878685,0.0210754182189703,0.018829308450222015,0.019384827464818954,0.01963975839316845,0.019303493201732635,0.018665475770831108,0.018750665709376335,0.018351497128605843,0.017922019585967064,0.019303621724247932,0.019068773835897446,0.01841125451028347,0.018798843026161194,0.019533678889274597,0.01772703230381012,0.017534876242280006,0.017924942076206207,0.019080396741628647,0.016749566420912743,0.017224855720996857,0.018341487273573875,0.01781453751027584,0.016870828345417976,0.018205704167485237,0.018817437812685966,0.01630384847521782,0.016698282212018967,0.01764216274023056,0.01836511120200157,0.018692610785365105,0.01791226491332054,0.017409540712833405,0.01621042564511299,0.018087001517415047,0.018412144854664803,0.015977878123521805,0.016031377017498016,0.017559295520186424,0.01746273599565029,0.015888670459389687,0.016094258055090904,
mse,0.6115305423736572,0.005893863271921873,0.002878261497244239,0.0030156078282743692,0.001970086945220828,0.0010518654016777873,0.0009095162968151271,0.0004563274560496211,0.0005954978405497968,0.0004775907436851412,0.00036967534106224775,0.00040665443520992994,0.0003248759312555194,0.0002348116395296529,0.00022214584168978035,0.0003279481315985322,0.0002306441165274009,0.00016872078413143754,0.00018846669991035014,0.00021121621830388904,0.00018711594748310745,0.00018561094475444406,0.0001993608893826604,0.00019076325406786054,0.00015284755500033498,0.00019098226039204746,0.00012772261106874794,0.00017577283142600209,0.0001643848663661629,0.0001288941130042076,0.00015336860087700188,0.00014735989680048078,0.00014360925706569105,0.00016344778123311698,0.00013524357927963138,0.00014524179277941585,0.00011925231956411153,0.00014113416546024382,0.00013505906099453568,0.00010877875320147723,9.515485726296902e-05,9.820541163207963e-05,0.00015611281560268253,0.00015062594320625067,0.00013871277042198926,0.00012079629232175648,0.0001353646075585857,0.00010439706238685176,0.0001404417271260172,0.00010301786824129522,0.00011453146726125851,0.00013675422815140337,0.00013439853501040488,0.00012609416444320232,0.00012823032739106566,0.00011482727131806314,9.696056804386899e-05,0.0001333923573838547,0.0001279584685107693,0.00012780301040038466,0.0001049934871844016,0.00011169165372848511,0.0001143380141002126,0.00010996272612828761,0.00010327103518648073,0.0001067547345883213,0.00010238511458737776,9.542415500618517e-05,0.00010951192962238565,0.00010736218973761424,9.89604159258306e-05,0.00010502429358894005,0.00011239261220907792,9.219926869263873e-05,9.397684334544465e-05,9.590425179339945e-05,0.00010494521848158911,8.179693395504728e-05,8.948171307565644e-05,0.00010202428529737517,9.487156785326079e-05,8.728112879907712e-05,9.792763739824295e-05,0.00010216762166237459,8.07312098913826e-05,8.520657866029069e-05,9.708667494123802e-05,0.00010086878319270909,0.00010470384586369619,9.275777119910344e-05,9.319165837951005e-05,7.857492164475843e-05,9.32752518565394e-05,0.00010020291665568948,7.822840416338295e-05,7.815975550329313e-05,9.125941141974181e-05,9.063916513696313e-05,7.663859287276864e-05,7.76996384956874e-05,
mae,0.408952534198761,0.06006113067269325,0.04167492315173149,0.042024191468954086,0.033893778920173645,0.025764891877770424,0.02392147108912468,0.016848532482981682,0.01940031535923481,0.017129624262452126,0.015061447396874428,0.015999063849449158,0.014477488584816456,0.011923620477318764,0.011654051952064037,0.014379279688000679,0.011824149638414383,0.010032343678176403,0.010608460754156113,0.011361129581928253,0.010595733299851418,0.01065395213663578,0.010888461954891682,0.010864206589758396,0.009650214575231075,0.01076020859181881,0.008772703818976879,0.010538971051573753,0.00992538407444954,0.00881075020879507,0.00962507538497448,0.009513424709439278,0.009263054467737675,0.010176250711083412,0.009077990427613258,0.009463706985116005,0.00830296240746975,0.009390846826136112,0.008989009074866772,0.007964123040437698,0.00758478045463562,0.007669035345315933,0.009905549697577953,0.009661111980676651,0.009458054788410664,0.008483123034238815,0.009150759316980839,0.007929511368274689,0.009179863147437572,0.00786938052624464,0.008275357075035572,0.009110725484788418,0.009207786060869694,0.008737079799175262,0.008853972889482975,0.008256296627223492,0.007559916935861111,0.009151059202849865,0.008817514404654503,0.008856259286403656,0.00796979758888483,0.008238249458372593,0.008350503630936146,0.008230294100940228,0.007941951975226402,0.008011274971067905,0.007824436761438847,0.007628947496414185,0.008211338892579079,0.00808023288846016,0.007870092056691647,0.008048351854085922,0.008285636082291603,0.007511333096772432,0.007415699772536755,0.007595809642225504,0.00795961543917656,0.007121089845895767,0.007261279039084911,0.007738098502159119,0.007498607039451599,0.007139833178371191,0.007721781264990568,0.008046734146773815,0.006980536971241236,0.0071896896697580814,0.007504796609282494,0.007878701202571392,0.008079346269369125,0.007593941874802113,0.0074188606813549995,0.006804184522479773,0.007608137559145689,0.007783032488077879,0.006809258833527565,0.006821438670158386,0.007445992901921272,0.007283033803105354,0.006690452806651592,0.00681261857971549,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 231299    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 231300    
=================================================================
Total params: 462,599
Trainable params: 462,599
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 231,299
Trainable params: 231,299
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 231,300
Trainable params: 231,300
Non-trainable params: 0
_________________________________________________________________
