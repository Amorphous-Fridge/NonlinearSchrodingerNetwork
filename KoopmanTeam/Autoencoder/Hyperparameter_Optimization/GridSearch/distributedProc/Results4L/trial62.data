2021-06-26
loss,0.8675695061683655,0.23597751557826996,0.152686208486557,0.13356146216392517,0.11517371237277985,0.09941299259662628,0.10380993783473969,0.09074702858924866,0.08606340736150742,0.07000625878572464,0.06775522977113724,0.0727560818195343,0.06098923087120056,0.06104009598493576,0.05969489738345146,0.05032831057906151,0.05581355467438698,0.04515489935874939,0.044272683560848236,0.05066513642668724,0.04679148644208908,0.043926943093538284,0.04477353021502495,0.042383212596178055,0.036753252148628235,0.034445252269506454,0.03145413100719452,0.03663173317909241,0.03767704218626022,0.032025787979364395,0.03177833557128906,0.0320834182202816,0.033251773566007614,0.027615299448370934,0.02488419972360134,0.027755385264754295,0.02577139064669609,0.027236495167016983,0.026283934712409973,0.02865840494632721,0.025860914960503578,0.025104990229010582,0.02409275807440281,0.026555290445685387,0.023120881989598274,0.019583571702241898,0.020654592663049698,0.023001473397016525,0.024681463837623596,0.023682691156864166,0.02109168842434883,0.01976184919476509,0.020660150796175003,0.02219720557332039,0.024031639099121094,0.021905628964304924,0.020533185452222824,0.020120389759540558,0.01853945665061474,0.017191534861922264,0.022547299042344093,0.020587796345353127,0.020312685519456863,0.01767571084201336,0.01717129535973072,0.020519878715276718,0.020037775859236717,0.019428139552474022,0.01838482730090618,0.018329812213778496,0.018237076699733734,0.01683918386697769,0.018937645480036736,0.01801803894340992,0.01905534602701664,0.01788611337542534,0.01768827624619007,0.017847463488578796,0.015510087832808495,0.01857651025056839,0.016796501353383064,0.015855850651860237,0.017204806208610535,0.017573686316609383,0.01616944745182991,0.01757480762898922,0.016922617331147194,0.018747620284557343,0.017197296023368835,0.01547968853265047,0.014627523720264435,0.015368490479886532,0.01308763399720192,0.01427946612238884,0.018164940178394318,0.01474912092089653,0.013172861188650131,0.01537325605750084,0.016027260571718216,0.016969775781035423,
mse,0.40711989998817444,0.016672644764184952,0.00681282440200448,0.005306444130837917,0.003952598199248314,0.002869442105293274,0.0031587264966219664,0.0023987973108887672,0.0020939656533300877,0.0014299919130280614,0.001318075810559094,0.001510176109150052,0.001041066600009799,0.001080147922039032,0.0010687479516491294,0.0007328587234951556,0.0009002305450849235,0.0005878843949176371,0.0005579888238571584,0.0007620900869369507,0.0006403691368177533,0.0005371880251914263,0.0005670077516697347,0.0005018837982788682,0.00039572175592184067,0.0003392691141925752,0.00028479238972067833,0.0003821725840680301,0.0003984883660450578,0.0002851194003596902,0.0002882293192669749,0.0002891110198106617,0.0003150163101963699,0.00021720622316934168,0.00019194978813175112,0.0002181641903007403,0.0001923566305777058,0.00021524036128539592,0.00019657396478578448,0.00022774813987780362,0.0001927243429236114,0.00017922185361385345,0.00016791241068858653,0.00019737015827558935,0.00015041729784570634,0.00011440092930570245,0.00012688050628639758,0.00015236121544148773,0.00017361734353471547,0.0001576254580868408,0.0001293072127737105,0.00011580210411921144,0.0001231255882885307,0.0001394156424794346,0.00016105003305710852,0.00013344024773687124,0.00012003369920421392,0.00011743569484679028,0.00010119078797288239,8.845714182825759e-05,0.00014747833483852446,0.00012092173710698262,0.00011689442908391356,9.194172162096947e-05,8.744966180529445e-05,0.00011840216757263988,0.00011274472490185872,0.00010810731328092515,9.69696047832258e-05,9.686239354778081e-05,9.688801219454035e-05,8.226794307120144e-05,0.0001033612061291933,9.319069067714736e-05,0.00010244891018373892,9.121961193159223e-05,9.113653504755348e-05,9.096650319406763e-05,7.126280252123252e-05,9.71167246461846e-05,8.109182817861438e-05,7.444449875038117e-05,8.657758007757366e-05,8.698844612808898e-05,7.47780068195425e-05,8.893405902199447e-05,8.156509284162894e-05,9.641108772484586e-05,8.337805775227025e-05,6.955808203201741e-05,6.330850737867877e-05,7.000799087109044e-05,5.223051266511902e-05,6.195391324581578e-05,9.213151497533545e-05,6.434472015826032e-05,5.4125335736898705e-05,7.078679482219741e-05,7.376498251687735e-05,8.398142381338403e-05,
mae,0.37608566880226135,0.10112875699996948,0.06429072469472885,0.05682109296321869,0.04956068471074104,0.04201960936188698,0.04404443874955177,0.038728710263967514,0.03546500205993652,0.029421191662549973,0.028571097180247307,0.03118426539003849,0.02596473880112171,0.02592606097459793,0.025613028556108475,0.021172087639570236,0.02380521222949028,0.018956216052174568,0.01896510273218155,0.021371208131313324,0.020056068897247314,0.018600476905703545,0.019299637526273727,0.017814522609114647,0.015524949878454208,0.014694216661155224,0.013379408977925777,0.015370995737612247,0.016021747142076492,0.013496504165232182,0.013568581081926823,0.013679318130016327,0.014199580997228622,0.01142268255352974,0.010629633441567421,0.011619888246059418,0.0109078548848629,0.011540837585926056,0.011163873597979546,0.011920894496142864,0.010858399793505669,0.010648885741829872,0.010317479260265827,0.011508137919008732,0.009832830168306828,0.008363320492208004,0.008819074369966984,0.009751327335834503,0.010482010431587696,0.010176246054470539,0.008929680101573467,0.008341941982507706,0.008737670257687569,0.009452207945287228,0.010120022110641003,0.00929239485412836,0.008749593049287796,0.0084306038916111,0.007774790748953819,0.007358986884355545,0.00955317635089159,0.008873814716935158,0.008565867319703102,0.00755884125828743,0.007274883333593607,0.008665092289447784,0.008500459603965282,0.008210668340325356,0.007784085348248482,0.007761567365378141,0.007601550780236721,0.007086517289280891,0.008056982420384884,0.007619850803166628,0.007980754598975182,0.0075669120997190475,0.007405654992908239,0.007570933550596237,0.006558284163475037,0.007829451933503151,0.007032075896859169,0.00673258351162076,0.0073315538465976715,0.007419056259095669,0.006874549202620983,0.007375285495072603,0.007096888963133097,0.007994748651981354,0.007248710375279188,0.0063723609782755375,0.006131193600594997,0.006476385053247213,0.005519496276974678,0.006118504796177149,0.007694886531680822,0.006258159410208464,0.005550716072320938,0.00646871468052268,0.006737751420587301,0.007275632116943598,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 156707    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 156708    
=================================================================
Total params: 313,415
Trainable params: 313,415
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               16896     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 156,707
Trainable params: 156,707
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                16416     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 156,708
Trainable params: 156,708
Non-trainable params: 0
_________________________________________________________________
