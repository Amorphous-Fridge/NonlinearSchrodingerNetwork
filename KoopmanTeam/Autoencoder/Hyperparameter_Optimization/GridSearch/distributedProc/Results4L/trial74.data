2021-06-26
loss,2.6458394527435303,2.227165937423706,2.221168279647827,2.221043586730957,2.224850654602051,2.221465587615967,2.211691379547119,2.256718158721924,2.206421136856079,2.2015380859375,2.2029943466186523,2.200094699859619,2.200646162033081,2.200054407119751,2.200704574584961,2.1999731063842773,2.200061798095703,2.2007527351379395,2.201982259750366,2.2008140087127686,2.200582981109619,2.2002999782562256,2.2001116275787354,2.2004263401031494,2.2004387378692627,2.2004013061523438,2.2106235027313232,2.2047035694122314,2.200194835662842,2.1999754905700684,2.1994595527648926,2.2010152339935303,2.1992080211639404,2.200315475463867,2.1992969512939453,2.199946641921997,2.200551748275757,2.199502468109131,2.2008609771728516,2.200862169265747,2.200082302093506,2.2004079818725586,2.2024810314178467,2.1995203495025635,2.20052170753479,2.199563503265381,2.202667474746704,2.1996567249298096,2.6669089794158936,1.0397143363952637,0.4464370608329773,0.44519057869911194,0.44546276330947876,0.44512447714805603,0.44485169649124146,0.4455600380897522,0.44450491666793823,0.4466307461261749,0.44523972272872925,0.4445417821407318,0.4449950158596039,0.4456941485404968,0.44550609588623047,0.4454571604728699,0.44494590163230896,0.44444647431373596,0.44547969102859497,0.4452016055583954,0.44562965631484985,0.44574296474456787,0.44514700770378113,0.4449235200881958,0.4454942047595978,0.44592562317848206,0.44456803798675537,0.4453304708003998,0.44567611813545227,0.44538944959640503,0.44519752264022827,0.4455093443393707,0.445671945810318,0.4450126886367798,0.44647547602653503,0.4446432590484619,0.4442282021045685,0.4447561502456665,0.4456115663051605,0.4446675479412079,0.4449315667152405,0.4451022446155548,0.4451695382595062,0.4458426237106323,0.4449802339076996,0.4454173743724823,0.44512635469436646,0.4450632929801941,0.44550734758377075,0.4461544454097748,0.4450218975543976,0.44580116868019104,
mse,1.9069695472717285,1.2532625198364258,1.246945858001709,1.2468879222869873,1.2523516416549683,1.2472543716430664,1.2366806268692017,1.2877793312072754,1.2309192419052124,1.2254955768585205,1.2270323038101196,1.2238192558288574,1.2243835926055908,1.2237035036087036,1.2245036363601685,1.2236261367797852,1.2237650156021118,1.2245396375656128,1.2259324789047241,1.2245975732803345,1.22431218624115,1.2240283489227295,1.223779320716858,1.2241754531860352,1.2241662740707397,1.2241202592849731,1.2352747917175293,1.228999376296997,1.2239495515823364,1.223729133605957,1.2231141328811646,1.2247936725616455,1.2228522300720215,1.2240697145462036,1.2229201793670654,1.2236502170562744,1.2243355512619019,1.2231695652008057,1.2246642112731934,1.224682331085205,1.2238086462020874,1.2241095304489136,1.226431131362915,1.223212718963623,1.2242683172225952,1.2232006788253784,1.2265996932983398,1.223315715789795,1.8744343519210815,0.41500788927078247,0.05555008724331856,0.05519254505634308,0.0553123764693737,0.055225443094968796,0.055131055414676666,0.05535130575299263,0.05510604754090309,0.05553896725177765,0.05522768571972847,0.055087193846702576,0.055189333856105804,0.055311158299446106,0.05533371493220329,0.05532452091574669,0.05519482120871544,0.055100783705711365,0.05531574413180351,0.05525919422507286,0.05533687025308609,0.055391956120729446,0.055226996541023254,0.0551929697394371,0.05530676245689392,0.05538375675678253,0.055072396993637085,0.05525246635079384,0.05531063675880432,0.055264320224523544,0.05520820617675781,0.055284470319747925,0.055343955755233765,0.05519077926874161,0.055566225200891495,0.05506804957985878,0.05503139644861221,0.05515718087553978,0.05536721646785736,0.05511707440018654,0.05515551194548607,0.05521899089217186,0.05525470897555351,0.055389925837516785,0.055214036256074905,0.05531422048807144,0.05522840470075607,0.05518878996372223,0.055319204926490784,0.05545773357152939,0.05518100783228874,0.05537852272391319,
mae,1.0111790895462036,0.6707438826560974,0.6545469760894775,0.6537932753562927,0.6667823791503906,0.6552059054374695,0.6235189437866211,0.7044209241867065,0.6050647497177124,0.5792482495307922,0.5842105746269226,0.5606288909912109,0.5567066073417664,0.5617789626121521,0.5620275735855103,0.5583210587501526,0.5601913332939148,0.5635432600975037,0.5690896511077881,0.5571320056915283,0.5756537318229675,0.5608983635902405,0.5596094727516174,0.5637937784194946,0.5634337067604065,0.561157763004303,0.6071550250053406,0.5961552262306213,0.5593347549438477,0.5546203851699829,0.553571879863739,0.553413987159729,0.5526891946792603,0.5700075626373291,0.553778886795044,0.5539886355400085,0.5565852522850037,0.5522796511650085,0.5617661476135254,0.5540200471878052,0.552767276763916,0.5679845809936523,0.5750995874404907,0.5591782927513123,0.5536949038505554,0.5568042993545532,0.5818971991539001,0.5559428334236145,0.9826135039329529,0.3852675259113312,0.19782967865467072,0.19742870330810547,0.19756768643856049,0.19747698307037354,0.19725145399570465,0.19746385514736176,0.19713158905506134,0.19803518056869507,0.19754578173160553,0.1970815509557724,0.19738611578941345,0.19774717092514038,0.19762450456619263,0.19753780961036682,0.1973937600851059,0.19710662961006165,0.19754299521446228,0.1974639743566513,0.19763536751270294,0.19768458604812622,0.197430819272995,0.19727885723114014,0.19761060178279877,0.19773060083389282,0.19720780849456787,0.1975245326757431,0.19767500460147858,0.19748954474925995,0.19744278490543365,0.19766569137573242,0.1977108120918274,0.19741788506507874,0.19796638190746307,0.19719475507736206,0.19695806503295898,0.1972026228904724,0.19752010703086853,0.19721867144107819,0.19736455380916595,0.1973859667778015,0.19738082587718964,0.1977355182170868,0.19735783338546753,0.1975693702697754,0.19734697043895721,0.19732266664505005,0.19760890305042267,0.19786493480205536,0.19746710360050201,0.1977224349975586,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 329283    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 329284    
=================================================================
Total params: 658,567
Trainable params: 658,567
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 329,283
Trainable params: 329,283
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               33280     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                32832     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 329,284
Trainable params: 329,284
Non-trainable params: 0
_________________________________________________________________
