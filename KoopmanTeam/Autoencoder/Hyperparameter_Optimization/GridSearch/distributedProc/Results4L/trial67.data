2021-06-26
loss,2.3697354793548584,1.108469843864441,0.26319098472595215,0.24078628420829773,0.23856079578399658,0.22053098678588867,0.15232792496681213,0.1352706104516983,0.10551674664020538,0.08840656280517578,0.08983349800109863,0.10422100126743317,0.08253038674592972,0.08043865859508514,0.06806271523237228,0.05975863337516785,0.06873586028814316,0.06326106190681458,0.05133473873138428,0.05154700577259064,0.05201268568634987,0.05707298591732979,0.054325081408023834,0.04493527114391327,0.04862488433718681,0.04909124970436096,0.04113861918449402,0.04843192175030708,0.04241878539323807,0.03723449259996414,0.0447690449655056,0.036758799105882645,0.04622916877269745,0.04283342510461807,0.03201822191476822,0.035981956869363785,0.042360130697488785,0.04312937334179878,0.039371930062770844,0.041084419935941696,0.03788444399833679,0.034294720739126205,0.0348031148314476,0.03485281765460968,0.032499924302101135,0.03535711392760277,0.03428283706307411,0.036350082606077194,0.03162655979394913,0.03382967412471771,0.029773565009236336,0.03339274972677231,0.036198604851961136,0.03146861121058464,0.031615063548088074,0.03086317703127861,0.03357720002532005,0.03275284171104431,0.0310878437012434,0.029867740347981453,0.03147518262267113,0.030231688171625137,0.028607668355107307,0.027418944984674454,0.028051655739545822,0.03322805091738701,0.02739516645669937,0.029029235243797302,0.027156857773661613,0.026399927213788033,0.02794719859957695,0.024116791784763336,0.027446696534752846,0.030114784836769104,0.030996890738606453,0.02718089148402214,0.024652063846588135,0.022740645334124565,0.026077575981616974,0.027430450543761253,0.029877662658691406,0.02724253013730049,0.026765460148453712,0.025934642180800438,0.027235643938183784,0.02523782104253769,0.02277323231101036,0.02790430746972561,0.024235758930444717,0.02270643226802349,0.025452837347984314,0.02500448003411293,0.023122837767004967,0.022231275215744972,0.026887260377407074,0.02787322923541069,0.025867359712719917,0.022798283025622368,0.023912617936730385,0.02330196462571621,
mse,1.4504311084747314,0.4548313021659851,0.022576577961444855,0.01982072927057743,0.019566364586353302,0.016596270725131035,0.006990006659179926,0.005681903567165136,0.0032246552873402834,0.0022267247550189495,0.002367488807067275,0.0032294648699462414,0.0020176663529127836,0.0018453855300322175,0.0013808783842250705,0.0010304824681952596,0.0013164138654246926,0.0011674909619614482,0.0007918370538391173,0.0007806289358995855,0.0007909241830930114,0.0009218771010637283,0.0008629520307295024,0.0006045149057172239,0.0006761226686649024,0.000708309409674257,0.0004927677800878882,0.0006645249086432159,0.000523979018907994,0.0004011133569292724,0.0005659336457028985,0.0003934064006898552,0.0006024351459927857,0.0005298426258377731,0.0002981483703479171,0.00037540477933362126,0.0004984136903658509,0.0005315104499459267,0.00044056252227164805,0.0004773440305143595,0.0004132113535888493,0.0003380710550118238,0.0003497192228678614,0.00033743909443728626,0.0002985058235935867,0.0003558597236406058,0.00033649985562078655,0.0003682988171931356,0.00028115606983192265,0.00031233372283168137,0.0002489004982635379,0.00032420549541711807,0.000369637185940519,0.0002863708941731602,0.0002878274826798588,0.0002713864960242063,0.00032495998311787844,0.00030440452974289656,0.00027664334629662335,0.00025582543457858264,0.0002738875919021666,0.0002553459780756384,0.0002376754564465955,0.0002140469296136871,0.00022212268959265202,0.00030777070787735283,0.00021821618429385126,0.00024135997227858752,0.00021058494166936725,0.00019639692618511617,0.00022023532073944807,0.00016934073937591165,0.00021593383280560374,0.00025797809939831495,0.0002634738339111209,0.00020538670651149005,0.00016974260506685823,0.0001468527625547722,0.00020284611673559994,0.00021361831750255078,0.0002477953094057739,0.0002134663227479905,0.0002069595648208633,0.00019223893468733877,0.00021068312344141304,0.00017789378762245178,0.0001486932742409408,0.0002222310722572729,0.00016504332597833127,0.00014653187827207148,0.000180398827069439,0.00017606859910301864,0.00015099735173862427,0.00014466368884313852,0.00020069604215677828,0.0002244996721856296,0.00019248250464443117,0.00014876399654895067,0.0001569011656101793,0.00015314255142584443,
mae,0.8473884463310242,0.39269518852233887,0.11635719239711761,0.10869735479354858,0.10774475336074829,0.09794609248638153,0.06484988331794739,0.05837143957614899,0.04521689563989639,0.037545718252658844,0.038551293313503265,0.04546104744076729,0.03534217178821564,0.03364773094654083,0.02879604883491993,0.025256209075450897,0.029625333845615387,0.027552202343940735,0.0215180441737175,0.021420791745185852,0.02207898534834385,0.02411467954516411,0.02375779114663601,0.019654996693134308,0.020789476111531258,0.021193204447627068,0.017367657274007797,0.021151341497898102,0.018407726660370827,0.016116563230752945,0.018934471532702446,0.015379924327135086,0.020112138241529465,0.01739366538822651,0.013435369357466698,0.015047375112771988,0.018112411722540855,0.01790935918688774,0.0167109202593565,0.017394021153450012,0.015917371958494186,0.014162259176373482,0.014380318112671375,0.014794629998505116,0.013985777273774147,0.015205916948616505,0.01464318297803402,0.015298359096050262,0.01345840934664011,0.014660321176052094,0.012928711250424385,0.014248576946556568,0.015690166503190994,0.013398770242929459,0.013367367908358574,0.013323201797902584,0.013839942403137684,0.013398613780736923,0.012796883471310139,0.012883741408586502,0.013533716090023518,0.01212792657315731,0.012316204607486725,0.011515723541378975,0.01176855806261301,0.013817882165312767,0.011427005752921104,0.012533740140497684,0.011362871155142784,0.011144718155264854,0.011541379615664482,0.01022891141474247,0.011499404907226562,0.012798935174942017,0.012227174825966358,0.011264806613326073,0.010577419772744179,0.009537979029119015,0.011048763059079647,0.011743277311325073,0.012719065882265568,0.011273747310042381,0.011438722722232342,0.010992210358381271,0.011629357002675533,0.010386803187429905,0.009602990001440048,0.011680342257022858,0.010375222191214561,0.009681707248091698,0.010850059799849987,0.01067977026104927,0.009728260338306427,0.009473053738474846,0.011570452712476254,0.01186353899538517,0.010824129916727543,0.009631943888962269,0.00974645558744669,0.009795676916837692,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 275571    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 275572    
=================================================================
Total params: 551,143
Trainable params: 551,143
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 275,571
Trainable params: 275,571
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 275,572
Trainable params: 275,572
Non-trainable params: 0
_________________________________________________________________
