2021-06-26
loss,0.45054569840431213,0.15937815606594086,0.09224209189414978,0.09359534084796906,0.07978782802820206,0.08011013269424438,0.05792434141039848,0.05409465357661247,0.05095311254262924,0.056268032640218735,0.049575742334127426,0.06428713351488113,0.06321350485086441,0.0585022009909153,0.05897282063961029,0.07532849907875061,0.06273926049470901,0.04678909853100777,0.04286013916134834,0.03969712555408478,0.03812510147690773,0.0350518636405468,0.035375092178583145,0.03441939502954483,0.04664342477917671,0.05904896557331085,0.046169500797986984,0.04928005859255791,0.044846273958683014,0.034711334854364395,0.0262177512049675,0.025314895436167717,0.02491041272878647,0.024600230157375336,0.02427743375301361,0.0238075852394104,0.023494133725762367,0.02317841723561287,0.022872114554047585,0.022778593003749847,0.02227427065372467,0.022132551297545433,0.02184433676302433,0.02148718573153019,0.0215085931122303,0.02115461602807045,0.020734891295433044,0.020717507228255272,0.020607002079486847,0.020280666649341583,0.020117156207561493,0.01994537003338337,0.019658762961626053,0.019567502662539482,0.019750146195292473,0.019410492852330208,0.019032400101423264,0.01881914585828781,0.01865820400416851,0.018521331250667572,0.01837100088596344,0.01818312145769596,0.018081866204738617,0.01801537349820137,0.017759772017598152,0.017594551667571068,0.01743330806493759,0.0172668918967247,0.01726582646369934,0.017055694013834,0.017024213448166847,0.01693384349346161,0.01667221635580063,0.016793863847851753,0.01880795508623123,0.016805920749902725,0.016434166580438614,0.01630396954715252,0.016065824776887894,0.01600813679397106,0.015885330736637115,0.015810681506991386,0.01568412035703659,0.0155002661049366,0.015460117720067501,0.01545132789760828,0.015285669825971127,0.015077845193445683,0.015061451122164726,0.015063065104186535,0.014827868901193142,0.014812811277806759,0.014831244014203548,0.014615675434470177,0.01460028626024723,0.014495739713311195,0.014425735920667648,0.014403820037841797,0.014237353578209877,0.014158623293042183,
mse,0.0783856064081192,0.008332655765116215,0.002519348170608282,0.0026052924804389477,0.0018764114938676357,0.0020333898719400167,0.0009849811904132366,0.0008441587560810149,0.0007397420704364777,0.0009649416315369308,0.0006993971765041351,0.0012970895040780306,0.001217182376421988,0.0010418581077829003,0.0010363840265199542,0.001630014507099986,0.001161131076514721,0.0006523776683025062,0.0005377119523473084,0.0004622500273399055,0.0004222671268507838,0.00035285393823869526,0.00036007919698022306,0.000339678575983271,0.0006666258559562266,0.0010313339298591018,0.0006267892313189805,0.0007034052978269756,0.0005762189393863082,0.0003660429210867733,0.00020276896248105913,0.00018464401364326477,0.00017824061797000468,0.00017368562112096697,0.00016848095401655883,0.0001611432380741462,0.0001573733752593398,0.00015259241627063602,0.00014989075134508312,0.00014949101023375988,0.00014055347128305584,0.00013843168562743813,0.00013565743574872613,0.00013130687875673175,0.00013178205699659884,0.00012746307766065001,0.00012307713041082025,0.00012204765516798943,0.00012054832768626511,0.0001161701075034216,0.00011493093916215003,0.0001123973197536543,0.00011096888192696497,0.00011175188410561532,0.00011143174197059125,0.00010721613944042474,0.00010265011951560155,0.00010025986557593569,9.88683823379688e-05,9.747299191076308e-05,9.558231249684468e-05,9.324707207269967e-05,9.349444007966667e-05,9.478986612521112e-05,8.989610068965703e-05,8.789815183263272e-05,8.611920929979533e-05,8.49061252665706e-05,8.732434071134776e-05,8.310678094858304e-05,8.235553104896098e-05,8.27107869554311e-05,7.977662608027458e-05,8.176330447895452e-05,0.0001082119342754595,8.193006942747161e-05,7.604267739225179e-05,7.508457929361612e-05,7.363451004493982e-05,7.28770173736848e-05,7.210212788777426e-05,7.132563041523099e-05,6.97284413035959e-05,6.947132351342589e-05,6.913980178069323e-05,6.762980774510652e-05,6.60767691442743e-05,6.514233245979995e-05,6.464801117544994e-05,6.448139174608514e-05,6.234535248950124e-05,6.388670590240508e-05,6.331873737508431e-05,6.167877290863544e-05,6.080757884774357e-05,6.056896017980762e-05,5.902514749323018e-05,5.9215464716544375e-05,5.7569915952626616e-05,5.7166987971868366e-05,
mae,0.1895523965358734,0.06725694239139557,0.03909243643283844,0.039658043533563614,0.03401574119925499,0.03474017232656479,0.025064783170819283,0.023191384971141815,0.021860240027308464,0.0242612287402153,0.02096184343099594,0.02738846279680729,0.027029184624552727,0.024614160880446434,0.025072818621993065,0.03281943127512932,0.026515353471040726,0.02005145512521267,0.018707621842622757,0.01693117432296276,0.016350774094462395,0.015057926997542381,0.015055567026138306,0.014742203988134861,0.020151281729340553,0.025210971012711525,0.019777243956923485,0.02116939052939415,0.0193235594779253,0.014639063738286495,0.011262479238212109,0.010776608251035213,0.010714220814406872,0.010588561184704304,0.010369814932346344,0.010111919604241848,0.010130149312317371,0.00986238569021225,0.00981782004237175,0.009808635339140892,0.009554947726428509,0.009419089183211327,0.009368390776216984,0.009168042801320553,0.00917105097323656,0.008951886557042599,0.008843788877129555,0.008768057450652122,0.008797931484878063,0.008606472983956337,0.008647941052913666,0.00841822661459446,0.00838317722082138,0.008378876373171806,0.008410305716097355,0.008245788514614105,0.007966214790940285,0.008000743575394154,0.007884597405791283,0.0079108951613307,0.007891650311648846,0.007780875079333782,0.007732260972261429,0.007662809453904629,0.007443649228662252,0.0075157941319048405,0.007236476056277752,0.007221809588372707,0.007287806831300259,0.007230485789477825,0.00725976936519146,0.007103060372173786,0.007053154520690441,0.007170546799898148,0.008007255382835865,0.007065712008625269,0.006986592896282673,0.006955528166145086,0.006754021160304546,0.006724329199641943,0.006789373233914375,0.006691058166325092,0.0066681718453764915,0.006610622629523277,0.0065625859424471855,0.006528145167976618,0.006460541859269142,0.006419667042791843,0.006431692745536566,0.006382179446518421,0.006264217663556337,0.0062592714093625546,0.006293209735304117,0.006259407848119736,0.006178417708724737,0.006158358417451382,0.006159362383186817,0.0060752443969249725,0.006051026750355959,0.005995811428874731,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 36299     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 36300     
=================================================================
Total params: 72,599
Trainable params: 72,599
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 36,299
Trainable params: 36,299
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 36,300
Trainable params: 36,300
Non-trainable params: 0
_________________________________________________________________
