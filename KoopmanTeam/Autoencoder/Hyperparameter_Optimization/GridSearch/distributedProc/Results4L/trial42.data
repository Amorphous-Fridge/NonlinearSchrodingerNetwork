2021-06-26
loss,0.4497641623020172,0.18967264890670776,0.11828569322824478,0.1144518181681633,0.08902797847986221,0.06392202526330948,0.0507589727640152,0.055872172117233276,0.06076129525899887,0.05945665389299393,0.05516725406050682,0.06366641074419022,0.060708656907081604,0.054374657571315765,0.04892480745911598,0.045667629688978195,0.04244973137974739,0.041004423052072525,0.04379815235733986,0.046630874276161194,0.037074796855449677,0.03160487860441208,0.039893463253974915,0.038527730852365494,0.04243054986000061,0.041380319744348526,0.03360969200730324,0.03402915596961975,0.03556681051850319,0.039906930178403854,0.036454927176237106,0.03032536990940571,0.02993728220462799,0.03315330669283867,0.025837736204266548,0.01972128450870514,0.019399438053369522,0.019112342968583107,0.01890430971980095,0.018809594213962555,0.018693482503294945,0.01876240223646164,0.01852235198020935,0.018285488709807396,0.018344616517424583,0.017981382086873055,0.018080908805131912,0.018040718510746956,0.017723804339766502,0.017726916819810867,0.017373424023389816,0.017363784834742546,0.017109567299485207,0.01704885996878147,0.016985299065709114,0.01692151464521885,0.016750091686844826,0.016517849639058113,0.016556523740291595,0.01643422432243824,0.016385169699788094,0.01624617725610733,0.016231920570135117,0.015976525843143463,0.015969883650541306,0.015747668221592903,0.015828652307391167,0.015576967038214207,0.015530710108578205,0.015546037815511227,0.015251572243869305,0.015333542600274086,0.02300899289548397,0.024508832022547722,0.026018386706709862,0.025340721011161804,0.023830370977520943,0.024887442588806152,0.024534137919545174,0.024755217134952545,0.02233720012009144,0.02240235172212124,0.021884538233280182,0.02104238048195839,0.022764787077903748,0.023463357239961624,0.02250467613339424,0.020886898040771484,0.019864900037646294,0.01890774816274643,0.018150612711906433,0.017617709934711456,0.01692190393805504,0.0168460663408041,0.018015936017036438,0.015996484085917473,0.021827273070812225,0.02191872149705887,0.02157635986804962,0.021393854171037674,
mse,0.08253541588783264,0.01303163543343544,0.004413507878780365,0.004014470148831606,0.002374874660745263,0.001278828363865614,0.0008088717004284263,0.000964410079177469,0.0011058398522436619,0.0010613593040034175,0.0009055517730303109,0.0011719951871782541,0.0010681938147172332,0.000857329519931227,0.0006767562008462846,0.0006098278099671006,0.0005522123537957668,0.0004935227334499359,0.0005540982238017023,0.0006295786006376147,0.000423779827542603,0.00030649136169813573,0.0004697725235018879,0.0004400117031764239,0.0005180513835512102,0.0004884263616986573,0.0003324075078126043,0.00033462478313595057,0.0003653984167613089,0.0004578221996780485,0.0003906305937562138,0.00027357248472981155,0.00027634380967356265,0.0003211248549632728,0.0002094084775308147,0.00011850563168991357,0.00011300435289740562,0.00010803337499964982,0.00010550989100011066,0.00010375327110523358,0.00010309432400390506,0.00010329924407415092,9.958771261153743e-05,9.734486229717731e-05,9.837556717684492e-05,9.45332067203708e-05,9.513561963103712e-05,9.439430141355842e-05,9.110798418987542e-05,9.062467142939568e-05,8.776516915531829e-05,8.708250970812514e-05,8.400671504205093e-05,8.500529656885192e-05,8.324716327479109e-05,8.30854187370278e-05,8.070932381087914e-05,7.965395343489945e-05,7.963272946653888e-05,7.857016316847876e-05,7.884052320150658e-05,7.482965884264559e-05,7.548412395408377e-05,7.317159906961024e-05,7.268529589055106e-05,7.191238546511158e-05,7.171723700594157e-05,6.965598731767386e-05,6.952829426154494e-05,6.928455695742741e-05,6.663825479336083e-05,6.779375689802691e-05,0.00016596126079093665,0.00017715034482534975,0.00019564454851206392,0.0001797413278836757,0.0001650146150495857,0.00017660539015196264,0.00017071330512408167,0.000170946674188599,0.00014332476712297648,0.00014529071631841362,0.00013729615602642298,0.00013467179087456316,0.00015534971316810697,0.00015337952936533839,0.000142866832902655,0.0001255971728824079,0.00011330868437653407,0.00010163015394937247,9.33091068873182e-05,8.791893924353644e-05,8.256064757006243e-05,8.522021380485967e-05,0.00010187608859268948,8.223942131735384e-05,0.0001402240013703704,0.0001379278110107407,0.00013280485291033983,0.00013047103129792958,
mae,0.1917594075202942,0.0851646363735199,0.05122722312808037,0.048621293157339096,0.037157755345106125,0.02700960822403431,0.021615639328956604,0.02369121089577675,0.02586613968014717,0.02527690678834915,0.023477230221033096,0.027331793680787086,0.026153864338994026,0.023443859070539474,0.021252349019050598,0.019451865926384926,0.018064023926854134,0.017207300290465355,0.018366921693086624,0.019810305908322334,0.015713268890976906,0.013363990001380444,0.01680239476263523,0.01636572927236557,0.018019190058112144,0.017698299139738083,0.014221503399312496,0.014454475603997707,0.014852390624582767,0.01701907254755497,0.01561045553535223,0.012699045240879059,0.012742250226438046,0.014032550156116486,0.010951058939099312,0.008325761184096336,0.008179488591849804,0.008074400015175343,0.008035071194171906,0.007898051291704178,0.007892404682934284,0.00795751716941595,0.007917164824903011,0.007684206590056419,0.007766407914459705,0.007593316957354546,0.007637660950422287,0.0076543474569916725,0.007489650044590235,0.007470338139683008,0.007303659804165363,0.007323250640183687,0.007191401906311512,0.007186546456068754,0.007175886072218418,0.007142543792724609,0.006996733136475086,0.006960324011743069,0.007018093951046467,0.006926389876753092,0.006978711578994989,0.006852535996586084,0.006886005867272615,0.006711393129080534,0.0067544663324952126,0.006681005470454693,0.006663128267973661,0.006648049224168062,0.006589942146092653,0.006531614810228348,0.0064679766073822975,0.006493827793747187,0.009842957369983196,0.010314119048416615,0.01109981443732977,0.010540354996919632,0.01020045019686222,0.010404815897345543,0.010340025648474693,0.010392062366008759,0.009512812830507755,0.009609036147594452,0.009301346726715565,0.008873822167515755,0.009747757576406002,0.009912674315273762,0.009262355975806713,0.008699245750904083,0.008401310071349144,0.007811805233359337,0.007336527109146118,0.007165186572819948,0.006819963455200195,0.007027641404420137,0.0076337591744959354,0.00678567448630929,0.00923127681016922,0.009200060740113258,0.008794170804321766,0.009059255942702293,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 70219     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 70220     
=================================================================
Total params: 140,439
Trainable params: 140,439
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 70,219
Trainable params: 70,219
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 70,220
Trainable params: 70,220
Non-trainable params: 0
_________________________________________________________________
