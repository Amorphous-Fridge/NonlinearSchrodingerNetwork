2021-06-26
loss,0.39228343963623047,0.12444531172513962,0.09608921408653259,0.0759674608707428,0.06186299026012421,0.07014334946870804,0.07354976236820221,0.06779573112726212,0.054643068462610245,0.046748265624046326,0.04027656465768814,0.03938686102628708,0.050774943083524704,0.04642307758331299,0.06451395153999329,0.056836213916540146,0.053964100778102875,0.04859931394457817,0.04637682065367699,0.040720485150814056,0.04454369097948074,0.04357503354549408,0.04176674038171768,0.03985854983329773,0.04195643961429596,0.04337717220187187,0.048988863825798035,0.040493763983249664,0.03138500452041626,0.03642306476831436,0.038663119077682495,0.0403553731739521,0.04165671393275261,0.03312516584992409,0.03479236736893654,0.030410384759306908,0.04263610765337944,0.03619352728128433,0.03335587680339813,0.03806108608841896,0.031662717461586,0.03207278624176979,0.02921680174767971,0.028862113133072853,0.029050393030047417,0.028811097145080566,0.03568290174007416,0.03319589048624039,0.03243203088641167,0.03362593054771423,0.031116802245378494,0.028551464900374413,0.027078401297330856,0.02584674209356308,0.024705233052372932,0.021449055522680283,0.01840090937912464,0.018157942220568657,0.01769757643342018,0.017402509227395058,0.01735243946313858,0.017197802662849426,0.016955522820353508,0.016992585733532906,0.016925843432545662,0.01670992560684681,0.016779271885752678,0.016730528324842453,0.01662759855389595,0.016495516523718834,0.016354955732822418,0.016428621485829353,0.016318803653120995,0.016178740188479424,0.016070321202278137,0.016067013144493103,0.015955181792378426,0.015898140147328377,0.015848442912101746,0.015647821128368378,0.015697984024882317,0.015599630773067474,0.015484409406781197,0.015306499786674976,0.015300319530069828,0.015256437472999096,0.01510608196258545,0.015113008208572865,0.01503839623183012,0.015002594329416752,0.01485434453934431,0.014761856757104397,0.014838922768831253,0.014659805223345757,0.014554675668478012,0.01451028324663639,0.014425692148506641,0.01426311768591404,0.014541005715727806,0.014434478245675564,
mse,0.06515614688396454,0.005466442555189133,0.002628156216815114,0.0016771280206739902,0.0011043777922168374,0.0014553116634488106,0.0015478678978979588,0.0013743933523073792,0.0008409464498981833,0.0006370519986376166,0.0004668038454838097,0.00043467633076943457,0.0007733135716989636,0.000628036679700017,0.0011720969341695309,0.0009086861391551793,0.0008129765628837049,0.0006681159138679504,0.0006018573767505586,0.00046040944289416075,0.0005542181897908449,0.0005300045595504344,0.00048183862236328423,0.00044683163287118077,0.00050169019959867,0.0005229777307249606,0.000676872965414077,0.0004552632453851402,0.00029110367177054286,0.0003739790990948677,0.00042464167927391827,0.00045387513819150627,0.0004874769365414977,0.000317503436235711,0.000339475431246683,0.0002624281623866409,0.0005182690802030265,0.0003666396951302886,0.00031375428079627454,0.0004073853779118508,0.00029283942421898246,0.0002823412942234427,0.00024065544130280614,0.00023419801436830312,0.0002354440075578168,0.00023659995349589735,0.00035527627915143967,0.00030757253989577293,0.0002958865079563111,0.0003119014436379075,0.0002680486941244453,0.0002282037166878581,0.0002051967749139294,0.00018724321853369474,0.0001724679459584877,0.0001348881924059242,9.528215014142916e-05,9.110552491620183e-05,8.682365296408534e-05,8.490951586281881e-05,8.374232857022434e-05,8.188232459360734e-05,8.012457692530006e-05,8.02989088697359e-05,7.92035207268782e-05,7.768625800963491e-05,7.790598465362564e-05,7.733427628409117e-05,7.614129572175443e-05,7.498030026908964e-05,7.487922994187102e-05,7.498737977584824e-05,7.39429597160779e-05,7.284372259164229e-05,7.153800834203139e-05,7.206332520581782e-05,7.060248753987253e-05,6.984737410675734e-05,6.89549560775049e-05,6.804580334573984e-05,6.762199336662889e-05,6.682222010567784e-05,6.60625591990538e-05,6.521485192934051e-05,6.507627404062077e-05,6.420873978640884e-05,6.32369119557552e-05,6.377574754878879e-05,6.20768842054531e-05,6.205910176504403e-05,6.054385448805988e-05,6.049895819160156e-05,6.0467467847047374e-05,5.935571971349418e-05,5.855309791513719e-05,5.812078597955406e-05,5.74697223783005e-05,5.7656718126963824e-05,6.037240382283926e-05,5.7167853810824454e-05,
mae,0.1657516360282898,0.0520128533244133,0.041146114468574524,0.032341159880161285,0.026197629049420357,0.029820675030350685,0.03147539868950844,0.029035774990916252,0.0234385896474123,0.019966131076216698,0.01689702644944191,0.016605345532298088,0.02185010351240635,0.020115025341510773,0.02764873579144478,0.023971516638994217,0.022861644625663757,0.02057882770895958,0.019767723977565765,0.017550049349665642,0.018736571073532104,0.018458928912878036,0.01766306720674038,0.017159853130578995,0.017969248816370964,0.018544673919677734,0.02030087076127529,0.01738610304892063,0.013507435098290443,0.015743358060717583,0.016156090423464775,0.017154647037386894,0.01731400191783905,0.01424561720341444,0.015002173371613026,0.01309678889811039,0.017888715490698814,0.015726177021861076,0.013985279016196728,0.016084881499409676,0.01336777675896883,0.01396976038813591,0.012598501518368721,0.012222448363900185,0.0122826574370265,0.01220889762043953,0.015193458646535873,0.013917628675699234,0.01350152213126421,0.013950234279036522,0.013113669119775295,0.012399123050272465,0.011666245758533478,0.011132297106087208,0.010612914338707924,0.009149888530373573,0.0078088934533298016,0.0076441895216703415,0.007433820981532335,0.007370324339717627,0.0073758261278271675,0.007243698928505182,0.007190188858658075,0.007276242598891258,0.0071983723901212215,0.007090659346431494,0.007179892621934414,0.007133221719413996,0.007024938240647316,0.006969107314944267,0.006966413464397192,0.00697401212528348,0.006943436339497566,0.006827179808169603,0.006729592569172382,0.006826846394687891,0.0067761242389678955,0.0066811274737119675,0.006703833118081093,0.006634368095546961,0.006588631309568882,0.0066028740257024765,0.006540443282574415,0.006480819545686245,0.006468144245445728,0.006441404111683369,0.006403106264770031,0.006387846544384956,0.0063940961845219135,0.00634236354380846,0.006310603115707636,0.006252680439502001,0.006265963427722454,0.006200297269970179,0.006167130079120398,0.006133807823061943,0.006117362529039383,0.006051188334822655,0.006115276366472244,0.006091692019253969,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 14819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 14820     
=================================================================
Total params: 29,639
Trainable params: 29,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 14,819
Trainable params: 14,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 14,820
Trainable params: 14,820
Non-trainable params: 0
_________________________________________________________________
