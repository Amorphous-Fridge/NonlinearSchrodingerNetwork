2021-06-26
loss,0.5767236351966858,0.207947239279747,0.15491023659706116,0.11576876044273376,0.07999526709318161,0.08803068846464157,0.089421346783638,0.07395792007446289,0.0678906962275505,0.06641759723424911,0.06858476996421814,0.0600702278316021,0.042136408388614655,0.04580666869878769,0.04000343754887581,0.037537816911935806,0.04339335113763809,0.04521980881690979,0.04173683002591133,0.03779875114560127,0.04026077315211296,0.03275439143180847,0.037966642528772354,0.03642904385924339,0.03769123926758766,0.030639970675110817,0.026433980092406273,0.034794315695762634,0.03537115827202797,0.033400412648916245,0.031039630994200706,0.02824542671442032,0.02888532355427742,0.026460804045200348,0.031648650765419006,0.02629249170422554,0.025495707988739014,0.02839900180697441,0.024026522412896156,0.0251949280500412,0.02435566671192646,0.026196597144007683,0.024370497092604637,0.025091348215937614,0.022553054615855217,0.023469381034374237,0.026322495192289352,0.02420121431350708,0.023005478084087372,0.022070737555623055,0.0216259453445673,0.022249389439821243,0.0227494053542614,0.020380835980176926,0.019201388582587242,0.016711892560124397,0.015570785850286484,0.015504044480621815,0.01895478181540966,0.021333234384655952,0.01916901208460331,0.018810313194990158,0.01777232252061367,0.02265254035592079,0.018919896334409714,0.016602853313088417,0.019560275599360466,0.020802786573767662,0.01892850361764431,0.01862119510769844,0.018574152141809464,0.01781877689063549,0.016818521544337273,0.01951488107442856,0.01866009086370468,0.01703631319105625,0.016424087807536125,0.01761968620121479,0.018613941967487335,0.017036521807312965,0.01767648197710514,0.018936192616820335,0.016464771702885628,0.014906691387295723,0.016518503427505493,0.01637658290565014,0.01670387201011181,0.017470525577664375,0.016620006412267685,0.014594516716897488,0.013606199063360691,0.015119585208594799,0.01742495410144329,0.016558082774281502,0.017356866970658302,0.015127785503864288,0.016421977430582047,0.018208710476756096,0.01570122316479683,0.013631347566843033,
mse,0.13845163583755493,0.013919414021074772,0.007048059720546007,0.003755618119612336,0.001861641532741487,0.0022291340865194798,0.0023581974674016237,0.00170794571749866,0.0013004844076931477,0.0012636050814762712,0.001413834746927023,0.0010105707915499806,0.0005123834125697613,0.0006043452303856611,0.0004597278602886945,0.0004077425110153854,0.0005632219254039228,0.0006125499494373798,0.0004913777811452746,0.00041875202441588044,0.0004903471563011408,0.00032069560256786644,0.00040414062095806,0.0003760084218811244,0.0004090742440894246,0.0002776092733256519,0.00020189078350085765,0.0003536228905431926,0.0003489280352368951,0.00031326652970165014,0.0002701144840102643,0.0002270642144139856,0.00024253610172308981,0.0002055801305687055,0.00029013986932113767,0.0002030189207289368,0.00019042115309275687,0.000227280383114703,0.00016706805035937577,0.0001813563285395503,0.0001729834038997069,0.0001959404326044023,0.00017214991385117173,0.00018521699530538172,0.0001457928738091141,0.0001560843229526654,0.0001954979234142229,0.00016406318172812462,0.00015193333092611283,0.00014390992873813957,0.0001338648289674893,0.00014016612840350717,0.00014646895579062402,0.00011970190098509192,0.00011111838830402121,8.343842637259513e-05,7.162366091506556e-05,7.252479554153979e-05,0.00010928414849331602,0.00012625299859791994,0.00010512913286220282,0.00010215523070655763,9.435112588107586e-05,0.0001418954780092463,0.00010216821829089895,8.298802276840433e-05,0.00011162456212332472,0.00012235752365086228,9.959191083908081e-05,9.74232389125973e-05,0.00010138309880858287,9.285748819820583e-05,8.203979814425111e-05,0.00010916469909716398,9.956350550055504e-05,8.553219231544062e-05,7.845291111152619e-05,9.071215754374862e-05,9.797752136364579e-05,8.46715847728774e-05,9.014317765831947e-05,0.00010281485447194427,7.952802116051316e-05,6.767036393284798e-05,8.000098750926554e-05,7.839815953047946e-05,8.085403533186764e-05,8.817965863272548e-05,7.968105637701228e-05,6.53528913971968e-05,5.711987614631653e-05,6.906881026225165e-05,8.730878471396863e-05,7.761490269331262e-05,8.7935637566261e-05,6.981597834965214e-05,7.721310248598456e-05,9.270398004446179e-05,7.258304685819894e-05,5.697236701962538e-05,
mae,0.24433916807174683,0.08730688691139221,0.06395700573921204,0.04787240922451019,0.03398538753390312,0.03706260770559311,0.037577997893095016,0.03164665773510933,0.028693879023194313,0.028257232159376144,0.02878483384847641,0.024878723546862602,0.017794368788599968,0.01958196796476841,0.016982771456241608,0.015724800527095795,0.018452556803822517,0.019312607124447823,0.017836684361100197,0.016047649085521698,0.01743629388511181,0.013951686210930347,0.016203610226511955,0.015578093938529491,0.015854759141802788,0.012931845150887966,0.011161599308252335,0.014906773343682289,0.015089900232851505,0.014223678968846798,0.013179865665733814,0.012026653625071049,0.012176201678812504,0.011273796670138836,0.013418197631835938,0.011058751493692398,0.010942796245217323,0.012017234228551388,0.01023951917886734,0.010667298920452595,0.0103905713185668,0.011141516268253326,0.010430541820824146,0.010592997074127197,0.009581385180354118,0.009802378714084625,0.011154559440910816,0.010272934101521969,0.00980822741985321,0.009506890550255775,0.009256595745682716,0.009530634619295597,0.009634828194975853,0.008685888722538948,0.008057331666350365,0.007024229969829321,0.006681850180029869,0.006606229115277529,0.008111503906548023,0.00910750962793827,0.008209440857172012,0.007929900661110878,0.0075238896533846855,0.00956313218921423,0.008080520667135715,0.007052334025502205,0.008280235342681408,0.008839018642902374,0.007903543300926685,0.007938675582408905,0.007815178483724594,0.00759588647633791,0.007146725431084633,0.00829047616571188,0.007885592058300972,0.007332991808652878,0.006949922069907188,0.007530233822762966,0.00785301998257637,0.007236497476696968,0.0074736918322741985,0.007993831299245358,0.006979714147746563,0.006356432568281889,0.0070065599866211414,0.006944967433810234,0.0070604439824819565,0.007460042368620634,0.0070873284712433815,0.006235388573259115,0.005799440201371908,0.0063828821294009686,0.007431733421981335,0.006944239605218172,0.007440602872520685,0.006468864157795906,0.006957535166293383,0.007622973527759314,0.0066295587457716465,0.005759621970355511,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 58307     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 58308     
=================================================================
Total params: 116,615
Trainable params: 116,615
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 58,307
Trainable params: 58,307
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 58,308
Trainable params: 58,308
Non-trainable params: 0
_________________________________________________________________
