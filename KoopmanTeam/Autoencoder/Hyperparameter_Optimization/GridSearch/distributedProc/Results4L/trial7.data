2021-06-26
loss,0.3993538022041321,0.12615340948104858,0.07324192672967911,0.05824362859129906,0.04957342520356178,0.04415792599320412,0.04009734094142914,0.03795795142650604,0.036452166736125946,0.034586887806653976,0.03326941654086113,0.0325273759663105,0.031076617538928986,0.03037104383111,0.02949068695306778,0.029142549261450768,0.028353095054626465,0.02776625007390976,0.027248185127973557,0.026733890175819397,0.026161491870880127,0.025868108496069908,0.025544069707393646,0.025054963305592537,0.02481374517083168,0.024589987471699715,0.02392185665667057,0.023940417915582657,0.02355939894914627,0.023475443944334984,0.023299477994441986,0.0229532141238451,0.02277805656194687,0.02253076620399952,0.022307010367512703,0.022196395322680473,0.022027311846613884,0.021866045892238617,0.021696681156754494,0.02168857492506504,0.0211735051125288,0.021268954500555992,0.021133992820978165,0.02104981616139412,0.02073933556675911,0.020895065739750862,0.020584700629115105,0.020647644996643066,0.020296087488532066,0.020377499982714653,0.020195247605443,0.020194731652736664,0.020039277151226997,0.019878290593624115,0.019716821610927582,0.019875839352607727,0.019566601142287254,0.019491270184516907,0.019536932930350304,0.019464438781142235,0.019279927015304565,0.01932450756430626,0.019208861514925957,0.01916745863854885,0.0190267451107502,0.018967492505908012,0.018856128677725792,0.018879327923059464,0.018715545535087585,0.018794259056448936,0.01862621121108532,0.018684806302189827,0.018511837348341942,0.018610922619700432,0.018320778384804726,0.018482258543372154,0.018346844241023064,0.01823928952217102,0.018299415707588196,0.01819687895476818,0.018231460824608803,0.018127314746379852,0.0180025864392519,0.01784909889101982,0.017943626269698143,0.0178951695561409,0.017877094447612762,0.017673274502158165,0.01770910434424877,0.01770554482936859,0.017602836713194847,0.017615078017115593,0.017518600448966026,0.01748870313167572,0.01746075227856636,0.017381221055984497,0.01730547659099102,0.01727541722357273,0.017240088433027267,0.017280127853155136,
mse,0.06851329654455185,0.00556730292737484,0.0017237215070053935,0.0010693457443267107,0.000772490631788969,0.0006127425003796816,0.0005059653776697814,0.00044429072295315564,0.0004047003749292344,0.0003625033423304558,0.0003336546942591667,0.0003154982696287334,0.0002875185164157301,0.0002731115964706987,0.00025801235460676253,0.0002502384886611253,0.00023499316012021154,0.00022587095736525953,0.00021607876988127828,0.00020803548977710307,0.0001983169058803469,0.0001933971216203645,0.00018848030595108867,0.0001808297383831814,0.000176772300619632,0.0001747346541378647,0.0001652193459449336,0.000164085126016289,0.00015931876259855926,0.00015845941379666328,0.00015556110884062946,0.00015065434854477644,0.00014821768854744732,0.00014496667427010834,0.0001415353617630899,0.00014078227104619145,0.0001383687340421602,0.00013664703874383122,0.0001338099391432479,0.00013483480142895132,0.00012665815302170813,0.00012882845476269722,0.00012689692084677517,0.0001262541045434773,0.00012141256593167782,0.00012487644562497735,0.00012008092016912997,0.00012129608512623236,0.00011700997856678441,0.00011765989620471373,0.00011597497359616682,0.00011604343308135867,0.00011379281204426661,0.00011216203711228445,0.00011023139813914895,0.00011163647286593914,0.00010854375432245433,0.00010755701077869162,0.00010823849879670888,0.00010753987589851022,0.00010498294432181865,0.00010600148380035535,0.00010498044866835698,0.00010400731844129041,0.00010274475789628923,0.00010223581193713471,0.00010019132605521008,0.00010046333773061633,9.925254562404007e-05,9.98713803710416e-05,9.828366455622017e-05,9.887626220006496e-05,9.745109855430201e-05,9.748665615916252e-05,9.446749754715711e-05,9.66667357715778e-05,9.51095498749055e-05,9.367966413265094e-05,9.477983257966116e-05,9.336914081359282e-05,9.383096039528027e-05,9.327295992989093e-05,9.118373418459669e-05,8.983320731204003e-05,9.179328480968252e-05,9.004183812066913e-05,8.985077147372067e-05,8.855710620991886e-05,8.811726002022624e-05,8.903091656975448e-05,8.666396024636924e-05,8.742111822357401e-05,8.66175105329603e-05,8.585369505453855e-05,8.632786921225488e-05,8.54713871376589e-05,8.420329686487094e-05,8.430679008597508e-05,8.352639997610822e-05,8.422000973951072e-05,
mae,0.17322306334972382,0.05428849160671234,0.03127679601311684,0.024864330887794495,0.021154729649424553,0.01888679713010788,0.01706968992948532,0.01618862897157669,0.015536441467702389,0.014780576340854168,0.014139379374682903,0.013897007331252098,0.013271838426589966,0.01296852808445692,0.012551123276352882,0.012355882674455643,0.01204537134617567,0.011795452795922756,0.011531860567629337,0.011439201422035694,0.01107837539166212,0.01103140041232109,0.01091168075799942,0.010579326190054417,0.010552360676229,0.010389306582510471,0.010124054737389088,0.010125972330570221,0.009965779259800911,0.010006023570895195,0.00987817533314228,0.009699027985334396,0.009696105495095253,0.009520132094621658,0.009483388625085354,0.00937595684081316,0.00942286103963852,0.009255817160010338,0.009269846603274345,0.009116395376622677,0.009011256508529186,0.009053301066160202,0.009002257138490677,0.008869227021932602,0.00878723245114088,0.008745050057768822,0.008789761923253536,0.008755076676607132,0.008596239611506462,0.008645297028124332,0.008561475202441216,0.008601677604019642,0.008484553545713425,0.008480962365865707,0.008303503505885601,0.008462232537567616,0.008287890814244747,0.008142857812345028,0.008313149213790894,0.008212154731154442,0.008186650462448597,0.008171566762030125,0.008077518083155155,0.008142326958477497,0.008127348497509956,0.008092478848993778,0.008066144771873951,0.007961542345583439,0.007955696433782578,0.007946645841002464,0.007990418933331966,0.007986605167388916,0.007663805969059467,0.00790458545088768,0.007782650645822287,0.00781305879354477,0.007809106260538101,0.0077686975710093975,0.007718871347606182,0.007650715298950672,0.007679940667003393,0.0077001964673399925,0.007613199297338724,0.007583468686789274,0.007651409134268761,0.00756028899922967,0.0075498116202652454,0.007537584286183119,0.0074958764016628265,0.007567190565168858,0.007429756689816713,0.0074983579106628895,0.007451008073985577,0.00741158239543438,0.007407829165458679,0.0074224043637514114,0.007369579281657934,0.00723835127428174,0.007265911903232336,0.007354049012064934,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 2987      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 2988      
=================================================================
Total params: 5,975
Trainable params: 5,975
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 520       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 2,987
Trainable params: 2,987
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                576       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 264       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 2,988
Trainable params: 2,988
Non-trainable params: 0
_________________________________________________________________
