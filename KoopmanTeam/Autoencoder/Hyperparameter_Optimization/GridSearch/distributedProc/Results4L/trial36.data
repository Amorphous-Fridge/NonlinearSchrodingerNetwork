2021-06-26
loss,0.6287577152252197,0.24490943551063538,0.23093582689762115,0.1536482274532318,0.1267760694026947,0.10756903886795044,0.08843540400266647,0.09670083969831467,0.08414170891046524,0.08158159255981445,0.07412675768136978,0.06832855939865112,0.0670403465628624,0.06814847886562347,0.061317455023527145,0.05854343995451927,0.05004718154668808,0.047775764018297195,0.05330150946974754,0.048714324831962585,0.04920753091573715,0.04608026519417763,0.03976432979106903,0.044251132756471634,0.045557450503110886,0.04457957297563553,0.03640172630548477,0.03982924297451973,0.04479588568210602,0.03687962889671326,0.03641839325428009,0.03641858696937561,0.03598678484559059,0.034679338335990906,0.030265584588050842,0.03213292732834816,0.0329466387629509,0.03011586144566536,0.028498850762844086,0.0271266158670187,0.031147507950663567,0.03141637146472931,0.030615312978625298,0.02740401215851307,0.02184239774942398,0.021746661514043808,0.03121975250542164,0.03183610737323761,0.030140401795506477,0.026953179389238358,0.024821888655424118,0.026452742516994476,0.026221491396427155,0.026421822607517242,0.027787381783127785,0.02805483527481556,0.025434229522943497,0.02487315982580185,0.024442700669169426,0.023016300052404404,0.02757069282233715,0.025403868407011032,0.023457810282707214,0.024524623528122902,0.022875310853123665,0.023419015109539032,0.0224769227206707,0.02277408540248871,0.022253599017858505,0.0225876085460186,0.022571953013539314,0.022019321098923683,0.020140105858445168,0.021510252729058266,0.02375034987926483,0.021307270973920822,0.02131904661655426,0.02119564078748226,0.02145642228424549,0.0222102552652359,0.021611323580145836,0.018727654591202736,0.019556831568479538,0.021040840074419975,0.020363716408610344,0.0199771448969841,0.01993827521800995,0.020544404163956642,0.019477074965834618,0.018178902566432953,0.018166247755289078,0.020160214975476265,0.01965206116437912,0.020276973024010658,0.019132860004901886,0.017070656642317772,0.018491199240088463,0.01812598668038845,0.017801793292164803,0.019010568037629128,
mse,0.17377565801143646,0.02023189142346382,0.018574006855487823,0.007905304431915283,0.004600773565471172,0.003587837563827634,0.002345777116715908,0.0027147745713591576,0.0019970443099737167,0.0019583527464419603,0.0015755813801661134,0.00133498664945364,0.0012623146176338196,0.001307474565692246,0.0010514335008338094,0.0009499755688011646,0.0007162883994169533,0.0006684320978820324,0.00083419174188748,0.0006746365106664598,0.000678175245411694,0.0006245793192647398,0.00047244885354302824,0.0005664097261615098,0.000594564713537693,0.0005481208208948374,0.0003691227757371962,0.00046636778279207647,0.0005616341368295252,0.00039349187863990664,0.0003749676398001611,0.00037009056541137397,0.0003726095601450652,0.00033448904287070036,0.0002657856675796211,0.00029273214749991894,0.0003044861659873277,0.00025669558090157807,0.00024259983911179006,0.00021742410899605602,0.0002798042551148683,0.00027518943534232676,0.0002637521829456091,0.00021983782062307,0.00014216310228221118,0.0001411100965924561,0.0002758454065769911,0.0002883609849959612,0.0002564881870057434,0.00020854758622590452,0.00018688669661059976,0.00021000798733439296,0.00019604475528467447,0.00019936432363465428,0.00021916833065915853,0.00022101732611190528,0.00018059714057017118,0.00017749100516084582,0.00017253596161026508,0.0001538093783892691,0.00021292488963808864,0.00018478126730769873,0.00015938180149532855,0.00016888687969185412,0.00014981783169787377,0.00015535895363427699,0.00014680242747999728,0.0001499940117355436,0.00014239178563002497,0.00014518763055093586,0.000144427758641541,0.0001376940927002579,0.00011645503400359303,0.00013285171007737517,0.00015655942843295634,0.00013089878484606743,0.00013112624583300203,0.00012797377712558955,0.0001263876911252737,0.00013638159725815058,0.00012907566269859672,0.00010238354298053309,0.00011383782839402556,0.0001251276262337342,0.0001168850067188032,0.00011339838965795934,0.00011265519424341619,0.00011710189573932439,0.00010993485193466768,9.889889770420268e-05,9.484651673119515e-05,0.00011350882414262742,0.00010905382077908143,0.00011412632011342794,0.00010190535977017134,8.471710316371173e-05,9.617245086701587e-05,9.319910896010697e-05,9.091386891668662e-05,0.00010124934487976134,
mae,0.2636754512786865,0.10346037894487381,0.09870318323373795,0.0650118887424469,0.05401409789919853,0.045345891267061234,0.038020625710487366,0.04057948291301727,0.03525567054748535,0.03346025198698044,0.03180563822388649,0.02960927225649357,0.028763823211193085,0.029106764122843742,0.025414304807782173,0.02508792094886303,0.02144770883023739,0.020432747900485992,0.022853631526231766,0.020851407200098038,0.021446634083986282,0.019886063411831856,0.01691814512014389,0.018698396161198616,0.018939165398478508,0.018885131925344467,0.01542915590107441,0.016889620572328568,0.019338808953762054,0.015552436001598835,0.015401897020637989,0.015191742219030857,0.015385537408292294,0.015046106651425362,0.01305360347032547,0.013531980104744434,0.013970497064292431,0.012571606785058975,0.012101075612008572,0.011606000363826752,0.013181534595787525,0.013325775973498821,0.012940090149641037,0.011612496338784695,0.009250491857528687,0.009292961098253727,0.01333829015493393,0.013299362733960152,0.012630429118871689,0.011476622894406319,0.010515375062823296,0.011273300275206566,0.011071909219026566,0.011298716999590397,0.011764266528189182,0.012078908272087574,0.010726114735007286,0.010462821461260319,0.01027501467615366,0.009730609133839607,0.01158627588301897,0.01071245688945055,0.00988069549202919,0.010359490290284157,0.009732313454151154,0.009761364199221134,0.009384840726852417,0.009453337639570236,0.009423303417861462,0.00957814697176218,0.009575732052326202,0.009382054209709167,0.008527899160981178,0.00909487996250391,0.01012302003800869,0.009107759222388268,0.008925873786211014,0.008881187066435814,0.009155570529401302,0.009440252557396889,0.009092596359550953,0.007905359379947186,0.008345106616616249,0.009003911167383194,0.008554473519325256,0.008371781557798386,0.00851728767156601,0.008632216602563858,0.008130177855491638,0.007686080411076546,0.007726730313152075,0.008411962538957596,0.008325106464326382,0.008567716926336288,0.00807361863553524,0.007142474874854088,0.007870106026530266,0.007572997361421585,0.007586827967315912,0.007939738221466541,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 45731     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 45732     
=================================================================
Total params: 91,463
Trainable params: 91,463
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 45,731
Trainable params: 45,731
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 45,732
Trainable params: 45,732
Non-trainable params: 0
_________________________________________________________________
