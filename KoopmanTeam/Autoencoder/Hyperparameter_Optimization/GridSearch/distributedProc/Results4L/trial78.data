2021-06-26
loss,2.8711328506469727,2.2430357933044434,2.237977981567383,2.2385103702545166,2.238180160522461,2.238675117492676,2.2385311126708984,2.237567901611328,2.2363576889038086,2.238269567489624,2.2389743328094482,2.237445592880249,2.238374948501587,2.2388222217559814,2.2387070655822754,2.238234758377075,2.2387633323669434,2.2432241439819336,2.238152265548706,2.2375593185424805,2.2377843856811523,2.2385447025299072,2.237962245941162,2.237273693084717,2.238072156906128,2.2371370792388916,2.2384724617004395,2.238466501235962,2.4750449657440186,3.1289777755737305,2.2412307262420654,2.237517833709717,2.237924575805664,2.2378876209259033,2.237827777862549,2.236921548843384,2.23664927482605,2.3700320720672607,2.2543463706970215,2.238966226577759,2.23710560798645,2.237518548965454,2.237020492553711,2.2375104427337646,2.238236427307129,2.238682508468628,2.238006591796875,2.2372231483459473,2.236711025238037,2.258152961730957,2.2426810264587402,2.2375357151031494,2.2377915382385254,2.237328290939331,2.2377593517303467,2.2366573810577393,2.237901210784912,2.2363100051879883,2.435560941696167,2.3351242542266846,2.2382538318634033,2.2377216815948486,2.237642526626587,2.237976312637329,2.2381198406219482,2.2379891872406006,2.236731767654419,2.237173318862915,2.23768949508667,2.237452507019043,2.237541675567627,2.2376506328582764,2.2384190559387207,2.4150705337524414,3.8648221492767334,3.8365838527679443,3.8360462188720703,3.8360345363616943,3.835211753845215,3.500795602798462,3.1436846256256104,3.1411406993865967,3.1400976181030273,3.1395678520202637,3.1399993896484375,3.141049861907959,3.140169620513916,3.140878200531006,3.1404919624328613,3.14072847366333,3.140718698501587,3.139894485473633,3.1400556564331055,3.1397693157196045,3.1404387950897217,3.1405246257781982,3.1412601470947266,3.139484167098999,3.1406235694885254,3.1396563053131104,
mse,2.2105751037597656,1.2708184719085693,1.2650957107543945,1.2657043933868408,1.2653604745864868,1.2659330368041992,1.265709638595581,1.2646502256393433,1.2633212804794312,1.2655104398727417,1.2662501335144043,1.264522910118103,1.2655590772628784,1.2661124467849731,1.2659326791763306,1.2653872966766357,1.2661210298538208,1.2711584568023682,1.265385389328003,1.2646387815475464,1.2649041414260864,1.2657485008239746,1.2651097774505615,1.2643020153045654,1.2652316093444824,1.2642385959625244,1.2656689882278442,1.2657021284103394,1.982812523841858,3.016265630722046,1.268829584121704,1.2645750045776367,1.2650558948516846,1.265006184577942,1.264939546585083,1.2639501094818115,1.263646125793457,1.4563602209091187,1.2837071418762207,1.2661892175674438,1.2641633749008179,1.2646174430847168,1.2641303539276123,1.2646456956863403,1.2654238939285278,1.2660657167434692,1.265120029449463,1.264237642288208,1.2637947797775269,1.2883511781692505,1.2704445123672485,1.264643907546997,1.2649003267288208,1.2643636465072632,1.2648544311523438,1.2636446952819824,1.2650115489959717,1.263293743133545,1.5151547193527222,1.3806750774383545,1.26543390750885,1.2647829055786133,1.2647367715835571,1.265150785446167,1.2653239965438843,1.2651413679122925,1.2636914253234863,1.2642213106155396,1.2648062705993652,1.2645856142044067,1.2646377086639404,1.264737606048584,1.265588641166687,1.5443856716156006,3.744262933731079,3.6849822998046875,3.683941602706909,3.6839208602905273,3.6823809146881104,3.095043659210205,2.480029821395874,2.475898027420044,2.474299430847168,2.473529577255249,2.474177598953247,2.4758527278900146,2.4744374752044678,2.4754648208618164,2.4749672412872314,2.4752936363220215,2.4752554893493652,2.4740493297576904,2.4742588996887207,2.4738214015960693,2.474884510040283,2.474933385848999,2.4761481285095215,2.4734010696411133,2.475170850753784,2.473707914352417,
mae,1.2062911987304688,0.7061737179756165,0.6980809569358826,0.6982781887054443,0.6981140971183777,0.6985319256782532,0.6982718110084534,0.6983508467674255,0.6979779601097107,0.6983651518821716,0.6989667415618896,0.698028028011322,0.6988842487335205,0.6989291906356812,0.6993247866630554,0.6986972093582153,0.6986051797866821,0.7047683596611023,0.6984516978263855,0.6981480121612549,0.6982449889183044,0.6985020637512207,0.6983305215835571,0.6982587575912476,0.6982664465904236,0.6980063915252686,0.6984868049621582,0.6983559131622314,0.7988908886909485,1.2639832496643066,0.7041652202606201,0.6978697776794434,0.6980955600738525,0.6981596946716309,0.6979801654815674,0.6973445415496826,0.6966582536697388,0.8589962720870972,0.723277747631073,0.6983034014701843,0.6978843808174133,0.6980144381523132,0.6977778077125549,0.6981160640716553,0.6980149149894714,0.6982868909835815,0.6979514956474304,0.6976922750473022,0.6970466375350952,0.7232785820960999,0.7046911716461182,0.6979634165763855,0.697884202003479,0.6978874802589417,0.6978439092636108,0.6978653073310852,0.6978519558906555,0.6975075602531433,0.8754609823226929,0.8102906942367554,0.698758602142334,0.6980994939804077,0.6978868246078491,0.6983464956283569,0.6981890201568604,0.6978166103363037,0.697801947593689,0.6978636384010315,0.698017954826355,0.6976242661476135,0.6979609727859497,0.6981059908866882,0.6982362270355225,0.8467071652412415,1.7637921571731567,1.6997510194778442,1.6991647481918335,1.6990747451782227,1.6988404989242554,1.4922699928283691,1.2061035633087158,1.1988240480422974,1.1984074115753174,1.198338270187378,1.198459267616272,1.1988869905471802,1.1986387968063354,1.1986899375915527,1.198760747909546,1.1985896825790405,1.1986777782440186,1.198602557182312,1.1984943151474,1.1983582973480225,1.198621153831482,1.19862961769104,1.1988892555236816,1.1984447240829468,1.1989349126815796,1.1984199285507202,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 461443    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 461444    
=================================================================
Total params: 922,887
Trainable params: 922,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 128)               640       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               66048     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 256)               131328    
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 771       
=================================================================
Total params: 461,443
Trainable params: 461,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 256)               1024      
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               262656    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 128)               65664     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 516       
=================================================================
Total params: 461,444
Trainable params: 461,444
Non-trainable params: 0
_________________________________________________________________
