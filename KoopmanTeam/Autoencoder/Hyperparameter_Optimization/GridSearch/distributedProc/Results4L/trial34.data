2021-06-26
loss,0.4320603609085083,0.2152879685163498,0.11794223636388779,0.11408155411481857,0.08273046463727951,0.07865353673696518,0.07310833036899567,0.09195093810558319,0.06457409262657166,0.08176343142986298,0.06723972409963608,0.0638033077120781,0.0580623634159565,0.0673929750919342,0.06361670792102814,0.04869624599814415,0.050347279757261276,0.054917171597480774,0.05488001927733421,0.05191608890891075,0.06255937367677689,0.058402568101882935,0.05175129324197769,0.04993193969130516,0.051067184656858444,0.04839497059583664,0.04153010994195938,0.04663080349564552,0.035775210708379745,0.03579371050000191,0.0430772602558136,0.043358854949474335,0.03730063512921333,0.034121815115213394,0.046314943581819534,0.043563973158597946,0.036869071424007416,0.03667714446783066,0.029257183894515038,0.029770836234092712,0.02797139808535576,0.028378495946526527,0.032885126769542694,0.043923042714595795,0.0382387638092041,0.03425129875540733,0.036047182977199554,0.03345907852053642,0.02978324703872204,0.02677077241241932,0.024790501222014427,0.032753318548202515,0.03173914551734924,0.030167676508426666,0.034001339226961136,0.03619607165455818,0.029298538342118263,0.02652517519891262,0.02394784614443779,0.022948749363422394,0.03156968578696251,0.03325292468070984,0.031169326975941658,0.028670266270637512,0.026201611384749413,0.02409195713698864,0.019963210448622704,0.020307524129748344,0.02037223055958748,0.025619449093937874,0.029527366161346436,0.030738994479179382,0.025274060666561127,0.02611379139125347,0.024900060147047043,0.023821771144866943,0.02451314777135849,0.025992639362812042,0.02783677540719509,0.02696818858385086,0.025209002196788788,0.025849919766187668,0.022387351840734482,0.026081986725330353,0.026926174759864807,0.02452588826417923,0.02243643067777157,0.021310295909643173,0.02012620121240616,0.01917354017496109,0.01861364208161831,0.018034150823950768,0.017593786120414734,0.01714642159640789,0.01693931594491005,0.016661977395415306,0.016686642542481422,0.02186615951359272,0.026376774534583092,0.024073654785752296,
mse,0.06391909718513489,0.015294492244720459,0.004215983673930168,0.0038989544846117496,0.0020112202037125826,0.0017996904207393527,0.0015354770002886653,0.0024451548233628273,0.0012227015104144812,0.0019217990338802338,0.0013055210001766682,0.001118550542742014,0.0010016110027208924,0.0013858894817531109,0.0011899858945980668,0.0007251218194141984,0.0007198762032203376,0.0008678385056555271,0.0008579904679208994,0.0008171785157173872,0.0011784980306401849,0.0010107833659276366,0.0007688559708185494,0.0007138984510675073,0.0007578429067507386,0.000681730336509645,0.0004869477706961334,0.0006312379264272749,0.0003851179499179125,0.0003701593668665737,0.0005457765073515475,0.0005174076068215072,0.0003850947832688689,0.0003285116399638355,0.0006147389649413526,0.0005357970949262381,0.0003826879255939275,0.0003842191363219172,0.00025918762548826635,0.00026382505893707275,0.00023555774532724172,0.0002339161146664992,0.0003232299641240388,0.0005413988837972283,0.0004190985346212983,0.000347472436260432,0.0003649108111858368,0.0003213382151443511,0.0002520546840969473,0.00020339970069471747,0.00017602424486540258,0.0003290586464572698,0.0002846231509465724,0.00025731674395501614,0.00032742376788519323,0.00036623061168938875,0.0002421484823571518,0.00019739833078347147,0.0001639916154090315,0.0001531329471617937,0.00029360136250033975,0.000304320827126503,0.000278834777418524,0.00023222707386594266,0.000203016767045483,0.00017190998187288642,0.00012099916057195514,0.00012290553422644734,0.00012371108459774405,0.0001878715556813404,0.00025065819500014186,0.00026696492568589747,0.00018094677943736315,0.00019451022672001272,0.00017880489758681506,0.00016296714602503926,0.0001734579709591344,0.0001858885952970013,0.00021960817684885114,0.00021035621466580778,0.00018184390501119196,0.00018522082245908678,0.00013962466618977487,0.00019592251919675618,0.0002006426511798054,0.00016759175923652947,0.00014251454558689147,0.0001279628195334226,0.00011502769484650344,0.00010654337529558688,9.946728096110746e-05,9.378549293614924e-05,8.933686331147328e-05,8.558551780879498e-05,8.285188960144296e-05,8.493412315146998e-05,8.388751302845776e-05,0.00013780349399894476,0.00019655344658531249,0.0001665730815147981,
mae,0.18702158331871033,0.09471476823091507,0.050094038248062134,0.048582978546619415,0.034930624067783356,0.03343962877988815,0.03110974282026291,0.03912409767508507,0.027412353083491325,0.03562106937170029,0.028634294867515564,0.02727273665368557,0.024488918483257294,0.02960345521569252,0.027093086391687393,0.020751260221004486,0.02138356678187847,0.02357296273112297,0.023845922201871872,0.022067520767450333,0.026869626715779305,0.025533903390169144,0.022277332842350006,0.021808216348290443,0.022579224780201912,0.02061750926077366,0.01763748563826084,0.01998411864042282,0.015244325622916222,0.015251033008098602,0.018460504710674286,0.01834300346672535,0.01548758614808321,0.014327030628919601,0.01976540870964527,0.01860952563583851,0.01567292958498001,0.015823595225811005,0.012503910809755325,0.012668125331401825,0.011858615092933178,0.012006033211946487,0.013885008171200752,0.019211020320653915,0.017244920134544373,0.014908325858414173,0.01570410467684269,0.014586422592401505,0.012652512639760971,0.011412633582949638,0.010560940951108932,0.013943462632596493,0.013293348252773285,0.012897510081529617,0.01464965008199215,0.015614782460033894,0.012259278446435928,0.010932853445410728,0.009941717609763145,0.009706693701446056,0.013527086935937405,0.014696359634399414,0.013400391675531864,0.012528598308563232,0.01108297985047102,0.01020989939570427,0.00854242779314518,0.008659987710416317,0.008625821210443974,0.010904014110565186,0.012496846728026867,0.013215665705502033,0.010659940540790558,0.011122239753603935,0.010575800202786922,0.010020924732089043,0.010437270626425743,0.010782160796225071,0.0117185665294528,0.011523021385073662,0.010939660482108593,0.010695028118789196,0.00943710282444954,0.011005234904587269,0.011567474342882633,0.010527266189455986,0.00953630730509758,0.009048388339579105,0.008528878912329674,0.00797641184180975,0.007725343108177185,0.007515266537666321,0.007303553633391857,0.0071449303068220615,0.007086189929395914,0.007101512514054775,0.0070587205700576305,0.009301919490098953,0.011359822005033493,0.010310846380889416,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 36299     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 36300     
=================================================================
Total params: 72,599
Trainable params: 72,599
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               1152      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 36,299
Trainable params: 36,299
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 1032      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 36,300
Trainable params: 36,300
Non-trainable params: 0
_________________________________________________________________
