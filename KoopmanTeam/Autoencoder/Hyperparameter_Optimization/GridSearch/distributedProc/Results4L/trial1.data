2021-06-26
loss,0.45362263917922974,0.2552778720855713,0.17207130789756775,0.09700291603803635,0.0729251354932785,0.0556858628988266,0.043474987149238586,0.037714142352342606,0.03444116190075874,0.03190586715936661,0.029352407902479172,0.028040096163749695,0.02682456560432911,0.02594226412475109,0.025148730725049973,0.02400418557226658,0.023581676185131073,0.02294144406914711,0.02233569696545601,0.021869465708732605,0.0214742012321949,0.021095551550388336,0.02071724645793438,0.02038613334298134,0.020004592835903168,0.01992201991379261,0.019559156149625778,0.01926526241004467,0.019054269418120384,0.019002314656972885,0.018835848197340965,0.018567215651273727,0.018422938883304596,0.018234843388199806,0.017816442996263504,0.01788134127855301,0.01768708974123001,0.017565125599503517,0.01741291768848896,0.017354873940348625,0.017231032252311707,0.017015941441059113,0.01681005209684372,0.016860274598002434,0.016744008287787437,0.01661054790019989,0.016340065747499466,0.01638205535709858,0.01632133685052395,0.015998974442481995,0.016065530478954315,0.01600555330514908,0.01587178185582161,0.01566246710717678,0.015627626329660416,0.015374468639492989,0.015572857111692429,0.015610435046255589,0.01526481844484806,0.015305260196328163,0.015216810628771782,0.014998828992247581,0.014958939515054226,0.014965301379561424,0.014808292500674725,0.014782534912228584,0.014587264508008957,0.014774912968277931,0.014623918570578098,0.014594032429158688,0.01433581206947565,0.014457127079367638,0.014330422505736351,0.014309011399745941,0.014236764051020145,0.014175396412611008,0.014079376123845577,0.01403435505926609,0.014051681384444237,0.014008506201207638,0.014015104621648788,0.013724756427109241,0.013874662108719349,0.013597059063613415,0.013786889612674713,0.013539204373955727,0.01365597452968359,0.013598245568573475,0.013567495159804821,0.013397539965808392,0.013447574339807034,0.013382894918322563,0.013335521332919598,0.013238825835287571,0.013250697404146194,0.013203595764935017,0.013112126849591732,0.012923069298267365,0.013109629042446613,0.012945775873959064,
mse,0.0809033140540123,0.02166060172021389,0.010634353384375572,0.0031645954586565495,0.001784538384526968,0.0010460695484653115,0.0006296753999777138,0.0004724538011942059,0.000388400221709162,0.0003301252727396786,0.0002800671791192144,0.00025285358424298465,0.0002304240333614871,0.00021433437359519303,0.00019970595894847065,0.00018283288227394223,0.00017500072135590017,0.00016479790792800486,0.00015657911717426032,0.000149495477671735,0.00014328397810459137,0.00013879207835998386,0.00013355586270336062,0.00012939308362547308,0.00012476783012971282,0.0001231999631272629,0.00011880409874720499,0.00011510271724546328,0.00011264728527748957,0.00011182590969838202,0.00010950258001685143,0.00010654891229933128,0.00010524204844841734,0.0001026690733851865,9.87205930869095e-05,9.886458428809419e-05,9.66649895417504e-05,9.526075882604346e-05,9.401215356774628e-05,9.312840847996995e-05,9.150659752776846e-05,8.955587691161782e-05,8.739391341805458e-05,8.800716750556603e-05,8.655655983602628e-05,8.51919612614438e-05,8.270345279015601e-05,8.288933167932555e-05,8.216642163461074e-05,7.928677223389968e-05,7.98806722741574e-05,7.90791746112518e-05,7.79198162490502e-05,7.589758024550974e-05,7.552315219072625e-05,7.329732761718333e-05,7.497447950299829e-05,7.513247692259029e-05,7.211369666038081e-05,7.246632594615221e-05,7.161889516282827e-05,6.952059629838914e-05,6.917766586411744e-05,6.928513903403655e-05,6.812420906499028e-05,6.732124893460423e-05,6.587945244973525e-05,6.75018600304611e-05,6.602494249818847e-05,6.576575106009841e-05,6.374399526976049e-05,6.462201417889446e-05,6.358212704071775e-05,6.317233055597171e-05,6.278244109125808e-05,6.231613224372268e-05,6.127046071924269e-05,6.0983653384028e-05,6.088840018492192e-05,6.066973219276406e-05,6.058292638044804e-05,5.8410485507920384e-05,5.93286931689363e-05,5.718355896533467e-05,5.878081719856709e-05,5.647455691359937e-05,5.7437973737251014e-05,5.695508298231289e-05,5.679592504748143e-05,5.5651209549978375e-05,5.5832038924563676e-05,5.536906246561557e-05,5.479129322338849e-05,5.411297388491221e-05,5.410115409176797e-05,5.377002162276767e-05,5.2996674639871344e-05,5.155048711458221e-05,5.3009669500170276e-05,5.151177174411714e-05,
mae,0.19311948120594025,0.11476032435894012,0.07540110498666763,0.04153803735971451,0.03116113878786564,0.023604966700077057,0.018465494737029076,0.01602988690137863,0.014633149839937687,0.013546377420425415,0.012472213245928288,0.0119088776409626,0.011401116847991943,0.01103532686829567,0.010693591088056564,0.010205927304923534,0.01003479678183794,0.009762216359376907,0.00951378047466278,0.009316198527812958,0.00914415717124939,0.0089871259406209,0.008834248408675194,0.008691411465406418,0.00853180792182684,0.008502197451889515,0.008345377631485462,0.008219592273235321,0.008136496879160404,0.0081058070063591,0.008041230030357838,0.007932435721158981,0.007863900624215603,0.007784300949424505,0.007603761740028858,0.007639174349606037,0.007546132430434227,0.00749551597982645,0.007428439799696207,0.007412011735141277,0.00735407043248415,0.00726008415222168,0.007163579575717449,0.007199141196906567,0.007147667929530144,0.007090805098414421,0.0069653745740652084,0.006986434571444988,0.006953188218176365,0.0068170554004609585,0.006848709657788277,0.0068314578384160995,0.006769591476768255,0.006675533019006252,0.006657746620476246,0.006541007664054632,0.006643456872552633,0.006651801988482475,0.006511973682790995,0.006525593809783459,0.006488099228590727,0.0063819075003266335,0.006371683906763792,0.006382362451404333,0.006298794876784086,0.006291281431913376,0.006211882457137108,0.0062951380386948586,0.00622841902077198,0.0062174187041819096,0.006104524713009596,0.00615565525367856,0.006099924445152283,0.006093097850680351,0.006059674546122551,0.006037072744220495,0.005990946665406227,0.0059732007794082165,0.0059781549498438835,0.005969115998595953,0.005975556559860706,0.005838113371282816,0.005906532518565655,0.005791186820715666,0.00587590504437685,0.0057569025084376335,0.005807256326079369,0.00579033000394702,0.005776087753474712,0.00570600014179945,0.005725321359932423,0.00570162246003747,0.005677370820194483,0.005637276917695999,0.005638205911964178,0.005625344347208738,0.005591524764895439,0.0054989284835755825,0.005586396437138319,0.005508117843419313,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 1019      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1020      
=================================================================
Total params: 2,039
Trainable params: 2,039
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 264       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 1,019
Trainable params: 1,019
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                288       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 16)                528       
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 1,020
Trainable params: 1,020
Non-trainable params: 0
_________________________________________________________________
