2021-06-26
loss,0.34073519706726074,0.10891635715961456,0.10524946451187134,0.08699420094490051,0.06860644370317459,0.0695730522274971,0.07855860888957977,0.06418097764253616,0.06351544708013535,0.06094317138195038,0.050907477736473083,0.04723702371120453,0.045812346041202545,0.03832563757896423,0.0336996428668499,0.04387986660003662,0.04405023902654648,0.042235713452100754,0.038871463388204575,0.04315085709095001,0.038779038935899734,0.03716803714632988,0.03563923016190529,0.035684529691934586,0.03912479057908058,0.03472091257572174,0.03580569848418236,0.031181881204247475,0.026615995913743973,0.02858302742242813,0.034335337579250336,0.03143727406859398,0.03047066368162632,0.03506369888782501,0.03269233927130699,0.030076168477535248,0.027453841641545296,0.03100811317563057,0.02933485247194767,0.025676853954792023,0.021320119500160217,0.02147664502263069,0.02852955274283886,0.030518831685185432,0.028452403843402863,0.027993028983473778,0.026023203507065773,0.019222045317292213,0.018779190257191658,0.021015910431742668,0.025560513138771057,0.026844613254070282,0.024114105850458145,0.02517387457191944,0.026660291478037834,0.023634927347302437,0.022316686809062958,0.026469700038433075,0.024496106430888176,0.023147935047745705,0.02200065553188324,0.023094289004802704,0.025665760040283203,0.022005720064044,0.01872383803129196,0.020783327519893646,0.023551277816295624,0.021026046946644783,0.022928955033421516,0.0216054804623127,0.020914679393172264,0.021603131666779518,0.022549884393811226,0.020990734919905663,0.01972961239516735,0.020860323682427406,0.020844994112849236,0.02250651642680168,0.019534267485141754,0.015852810814976692,0.015784746035933495,0.014317338354885578,0.01339583657681942,0.014441728591918945,0.01756156235933304,0.019770538434386253,0.02127222716808319,0.02062024362385273,0.018311727792024612,0.018540548160672188,0.01977257803082466,0.020053841173648834,0.018938396126031876,0.01889892853796482,0.019164400175213814,0.01733764074742794,0.015290590934455395,0.014260062016546726,0.013936469331383705,0.019116006791591644,
mse,0.05577695742249489,0.0033755877520889044,0.003356947796419263,0.002200681483373046,0.001351629849523306,0.0013861939078196883,0.0017661479068920016,0.001194441574625671,0.0011518712854012847,0.0010848199017345905,0.000724928395356983,0.0006352080381475389,0.0005832582828588784,0.0004073180607520044,0.0003272996982559562,0.0005610492662526667,0.0005566462059505284,0.0005071579944342375,0.00043502156040631235,0.0005242438055574894,0.0004276141116861254,0.00039441869012080133,0.00036397433723323047,0.0003594549489207566,0.0004323023313190788,0.0003460585721768439,0.00036127271596342325,0.00027577203582040966,0.0002075042575597763,0.00023906251590233296,0.00033394855563528836,0.00028052684501744807,0.00026608063490130007,0.0003440470318309963,0.00031243867124430835,0.0002546901523601264,0.00021604899666272104,0.0002707992971409112,0.00024064505123533309,0.0001933926105266437,0.00013739833957515657,0.0001382722402922809,0.00023029504518490285,0.0002686208754312247,0.00022649380844086409,0.00021761999232694507,0.00019335452816449106,0.00010850476974155754,0.00010720176942413673,0.000131535081891343,0.00019561497902031988,0.00020241532183717936,0.00016767326451372355,0.00017978651158045977,0.0002010341122513637,0.00016084572416730225,0.00014702366024721414,0.00019804653129540384,0.00016760830476414412,0.0001520903897471726,0.0001410741388099268,0.00015513240941800177,0.00018266124243382365,0.0001408091193297878,0.00010585285781417042,0.00012806899030692875,0.00015344255371019244,0.00012660017819143832,0.00014634944091085345,0.00013092342123854905,0.0001266776816919446,0.0001332845858996734,0.00014242797624319792,0.00012300966773182154,0.00011109835759270936,0.00012627991964109242,0.0001239921257365495,0.00014057941734790802,0.00011113963410025463,7.532431482104585e-05,7.645068399142474e-05,6.176654278533533e-05,5.114584564580582e-05,6.2694882217329e-05,9.084369958145544e-05,0.00011069040920119733,0.00012677564518526196,0.0001193349453387782,9.879549907054752e-05,9.75903749349527e-05,0.00010845813812920824,0.00011402484960854053,9.978754678741097e-05,0.00010238929826300591,0.00010335171828046441,8.713172428542748e-05,6.981998012633994e-05,6.0561247664736584e-05,5.929567851126194e-05,0.00010372979886597022,
mae,0.1444869190454483,0.04595595970749855,0.044336386024951935,0.03622344508767128,0.028936315327882767,0.029905661940574646,0.032916683703660965,0.027267958968877792,0.026625555008649826,0.025221802294254303,0.02168240025639534,0.020127473399043083,0.019604375585913658,0.01597931794822216,0.014345747418701649,0.018450867384672165,0.018622202798724174,0.017807504162192345,0.016584135591983795,0.018367920070886612,0.01646726205945015,0.015895379707217216,0.015294155105948448,0.015092569403350353,0.01665714755654335,0.014723515138030052,0.015209448523819447,0.013253932818770409,0.011240370571613312,0.012089227326214314,0.01490070205181837,0.013309777714312077,0.012926267459988594,0.014790363609790802,0.013780682347714901,0.012819903902709484,0.011619716882705688,0.013139884918928146,0.012379813008010387,0.01087331771850586,0.009114070795476437,0.009166195057332516,0.012264814227819443,0.01289441715925932,0.012027572840452194,0.011918739415705204,0.011089031584560871,0.008119739592075348,0.00796534400433302,0.008930576033890247,0.010806976817548275,0.01131904125213623,0.010194781236350536,0.01077114325016737,0.011556587181985378,0.010047603398561478,0.009471219964325428,0.01110632624477148,0.010431434027850628,0.009908217005431652,0.009305578656494617,0.009893259033560753,0.010844223201274872,0.009294732473790646,0.007952035404741764,0.008794010616838932,0.009790843352675438,0.008952867239713669,0.009814772754907608,0.009050508961081505,0.008953333832323551,0.00926206074655056,0.00959952361881733,0.008881290443241596,0.008351863361895084,0.008787227794528008,0.008848881348967552,0.009493423625826836,0.008260244503617287,0.006795236840844154,0.006709642242640257,0.006043003872036934,0.005712590180337429,0.006116341799497604,0.007413699757307768,0.008385987021028996,0.008995937183499336,0.00878847111016512,0.00782800279557705,0.00783474463969469,0.008426416665315628,0.008487870916724205,0.008047373965382576,0.008007030002772808,0.008051215671002865,0.0072775776498019695,0.006293823942542076,0.005958856549113989,0.005872332490980625,0.00805487297475338,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 39443     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 39444     
=================================================================
Total params: 78,887
Trainable params: 78,887
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 39,443
Trainable params: 39,443
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 39,444
Trainable params: 39,444
Non-trainable params: 0
_________________________________________________________________
