2021-06-26
loss,0.5349337458610535,0.2411198616027832,0.23270410299301147,0.21739666163921356,0.16871018707752228,0.1183265969157219,0.09549485146999359,0.08238805085420609,0.07854471355676651,0.060799069702625275,0.0633821114897728,0.06937894225120544,0.05846259742975235,0.06171097233891487,0.04973285272717476,0.05164911225438118,0.04871317371726036,0.04952818900346756,0.04599746689200401,0.04520976170897484,0.040812063962221146,0.048090387135744095,0.04106076806783676,0.04261467978358269,0.03831148520112038,0.03938063979148865,0.040881361812353134,0.04072063788771629,0.03200408071279526,0.027121469378471375,0.035171523690223694,0.034037280827760696,0.036122240126132965,0.035455238074064255,0.028660526499152184,0.02911766804754734,0.03239661827683449,0.030222851783037186,0.029593760147690773,0.03135759010910988,0.03384960815310478,0.026523571461439133,0.023181283846497536,0.020307261496782303,0.019331583753228188,0.01890520006418228,0.020102178677916527,0.0257347971200943,0.026299357414245605,0.02421627938747406,0.026807846501469612,0.02453618496656418,0.02593647874891758,0.03063931316137314,0.028211107477545738,0.01989693008363247,0.02032439224421978,0.020138375461101532,0.020293431356549263,0.02746269851922989,0.022938914597034454,0.029214730486273766,0.026293952018022537,0.02355935610830784,0.026134049519896507,0.023066913709044456,0.02307974360883236,0.025439174845814705,0.02385043352842331,0.025165030732750893,0.026172766461968422,0.024116747081279755,0.021343937143683434,0.020893225446343422,0.017239276319742203,0.01627468504011631,0.02320803888142109,0.025325190275907516,0.022856710478663445,0.021214324980974197,0.019248951226472855,0.01999717764556408,0.02403346076607704,0.024360494688153267,0.022796032950282097,0.02121545560657978,0.021803416311740875,0.020194141194224358,0.02223348058760166,0.020715055987238884,0.017188090831041336,0.016955841332674026,0.020640142261981964,0.02237885631620884,0.019953027367591858,0.020352553576231003,0.020377371460199356,0.01965438202023506,0.02093832939863205,0.021748432889580727,
mse,0.13008883595466614,0.019930070266127586,0.018998419865965843,0.016674064099788666,0.009033208712935448,0.0040511502884328365,0.0026490637101233006,0.0020358790643513203,0.0017972167115658522,0.001091143349185586,0.0011985130840912461,0.0014127771137282252,0.0010356915881857276,0.0011244345223531127,0.0007367294747382402,0.0007960867369547486,0.0007051479769870639,0.0007293593953363597,0.0006162221543490887,0.000598041049670428,0.0004945443943142891,0.0006828478653915226,0.000500507012475282,0.0005320732016116381,0.00043060968164354563,0.0004504105309024453,0.0004985904088243842,0.0004784126067534089,0.00030726336990483105,0.00022543632076121867,0.00036142003955319524,0.000344546017004177,0.00038919481448829174,0.0003644564712885767,0.00025082501815631986,0.00026339967735111713,0.00031409409712068737,0.00026688992511481047,0.000254594226134941,0.0002854604972526431,0.00032683496829122305,0.00021069883950985968,0.00016651133773848414,0.00012871857325080782,0.00011184007598785684,0.00010645559086697176,0.00012423403677530587,0.00020303299243096262,0.0002031133626587689,0.0001718411804176867,0.00021040691353846341,0.00018255115719512105,0.00019964617968071252,0.000269734940957278,0.00023100564430933446,0.0001258885022252798,0.00013225612929090858,0.00012706895358860493,0.00012991113180760294,0.00021964799088891596,0.00015568282105959952,0.00024550085072405636,0.00020326925732661039,0.00016620357928331941,0.00020311847038101405,0.00015793317288625985,0.00015875296958256513,0.00018548355728853494,0.00016655192303005606,0.00018819454999174923,0.00019705489103216678,0.00016911774582695216,0.000136019749334082,0.00012892995437141508,9.60586330620572e-05,8.296781015815213e-05,0.00015960348537191749,0.00018214239389635623,0.00015256987535394728,0.0001301696029258892,0.00011067068408010527,0.00012123083433834836,0.0001672530925134197,0.0001726474001770839,0.0001493792951805517,0.00013296506949700415,0.00013851275434717536,0.00012167376553406939,0.00014084270515013486,0.0001243540464201942,9.12547402549535e-05,9.089029481401667e-05,0.00012505265476647764,0.0001422528875991702,0.00011705632641678676,0.0001236858661286533,0.00012039356806781143,0.00011711832485161722,0.0001264448364963755,0.00013739477435592562,
mae,0.23191310465335846,0.09941138327121735,0.09818680584430695,0.09558063745498657,0.07102148234844208,0.050180330872535706,0.040112629532814026,0.03500133380293846,0.033886950463056564,0.025802507996559143,0.026630325242877007,0.029358617961406708,0.02450360730290413,0.026208607479929924,0.02072608284652233,0.022041378542780876,0.020537830889225006,0.02121765911579132,0.01943439431488514,0.019042285159230232,0.017181338742375374,0.020700758323073387,0.017446808516979218,0.01813131384551525,0.016335370019078255,0.01658143475651741,0.01744905672967434,0.017232785001397133,0.013696403242647648,0.011573168449103832,0.014859107322990894,0.014548594132065773,0.015370531007647514,0.015147923491895199,0.012122878804802895,0.0123392129316926,0.013764292933046818,0.012726872228085995,0.012358579784631729,0.013441593386232853,0.01457207091152668,0.011123640462756157,0.00981899630278349,0.008646659553050995,0.008261749520897865,0.00810158159583807,0.008586865849792957,0.010814791545271873,0.010914614424109459,0.01000172272324562,0.011371196247637272,0.010363290086388588,0.011028899811208248,0.013212560676038265,0.011680403724312782,0.008487973362207413,0.008606025017797947,0.00854230485856533,0.0085788918659091,0.011670906096696854,0.00968207698315382,0.012329540215432644,0.01116431225091219,0.009862732142210007,0.011082658544182777,0.009723514318466187,0.009771899320185184,0.01071114744991064,0.010099879465997219,0.010782020166516304,0.011206201277673244,0.010324614122509956,0.009038934484124184,0.008828410878777504,0.00734631298109889,0.006904859561473131,0.009829112328588963,0.010923892259597778,0.009554911404848099,0.008979922160506248,0.008189847692847252,0.008572347462177277,0.010196131654083729,0.010352827608585358,0.009794481098651886,0.008972026407718658,0.009310021996498108,0.008658318780362606,0.009422311559319496,0.008696713484823704,0.007194155361503363,0.007138718850910664,0.00875325407832861,0.009501810185611248,0.008394500240683556,0.008807717822492123,0.008518066257238388,0.008300075307488441,0.00889355968683958,0.009389826096594334,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 138059    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 138060    
=================================================================
Total params: 276,119
Trainable params: 276,119
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 2056      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 138,059
Trainable params: 138,059
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 4104      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 138,060
Trainable params: 138,060
Non-trainable params: 0
_________________________________________________________________
