2021-06-26
loss,0.5524376630783081,0.24852216243743896,0.2368650585412979,0.19889108836650848,0.1392820179462433,0.1099083349108696,0.12051491439342499,0.09411320090293884,0.08366455137729645,0.08571284264326096,0.07597675174474716,0.06372839212417603,0.05637457221746445,0.05934228003025055,0.06343705207109451,0.062371935695409775,0.052243586629629135,0.04672599211335182,0.047290049493312836,0.056457292288541794,0.046340905129909515,0.04474189877510071,0.04104110598564148,0.03783867880702019,0.03398559242486954,0.04301666095852852,0.03705235570669174,0.03690940514206886,0.03989071026444435,0.03479137644171715,0.03608393296599388,0.030911987647414207,0.02617461048066616,0.023837929591536522,0.035898689180612564,0.030849041417241096,0.032812152057886124,0.025545861572027206,0.03230562061071396,0.0313524454832077,0.025573933497071266,0.025117941200733185,0.029044976457953453,0.029399849474430084,0.022463945671916008,0.023202411830425262,0.02578757517039776,0.028400057926774025,0.028142178431153297,0.025925347581505775,0.026184355840086937,0.023723043501377106,0.022104885429143906,0.02047727070748806,0.01912539079785347,0.018140049651265144,0.01839534007012844,0.016983037814497948,0.023702766746282578,0.021568426862359047,0.020294439047574997,0.02013884112238884,0.018727006390690804,0.017743827775120735,0.0186469629406929,0.02324010618031025,0.022303033620119095,0.02025469020009041,0.020530669018626213,0.02308688871562481,0.0208524651825428,0.01876543089747429,0.022826988250017166,0.017404945567250252,0.019421162083745003,0.020506776869297028,0.017290951684117317,0.018604611977934837,0.019299009814858437,0.01818237639963627,0.017906852066516876,0.017296962440013885,0.017486093565821648,0.01657228171825409,0.01768580824136734,0.01785457693040371,0.01612192392349243,0.014482752420008183,0.013448141515254974,0.013239829801023006,0.013551782816648483,0.012690083123743534,0.013614221476018429,0.012182959355413914,0.01443428173661232,0.017234493046998978,0.018095148727297783,0.018529746681451797,0.017529072239995003,0.015591594390571117,
mse,0.13053222000598907,0.02044869214296341,0.01911376789212227,0.013281761668622494,0.00580200320109725,0.003437659703195095,0.004160606302320957,0.002522501163184643,0.002032723044976592,0.002123070415109396,0.00165851681958884,0.0011379136703908443,0.000919639365747571,0.0010268914047628641,0.0011307410895824432,0.0011140743736177683,0.0007848857203498483,0.0006376649253070354,0.0006420469144359231,0.0009204425732605159,0.0006274584447965026,0.000564039044547826,0.00047916159383021295,0.0004112604365218431,0.0003332041669636965,0.0005201131571084261,0.00039155164267867804,0.0003934709820896387,0.0004542758397292346,0.0003413102531339973,0.0003629349230322987,0.0002665442880243063,0.0001997907820623368,0.00017299698083661497,0.0003547437081579119,0.00026686693308874965,0.000304400862660259,0.00019191984029021114,0.00029227655613794923,0.000290075404336676,0.00019195400818716735,0.00018418827676214278,0.00023511770996265113,0.000240400418988429,0.00014778878539800644,0.00015812332276254892,0.000190655147889629,0.00022494731820188463,0.0002238389861304313,0.00018631867715157568,0.00019203520787414163,0.00015697962953709066,0.00013611397298518568,0.0001197183519252576,0.00010788420331664383,9.693192259874195e-05,0.00010098417260451242,8.710996189620346e-05,0.00015911944501567632,0.0001351543760392815,0.0001205742300953716,0.00011864583211718127,0.00010410512913949788,9.180282359011471e-05,0.00010515949543332681,0.00016078744374681264,0.00013795329141430557,0.00011698588059516624,0.00012087184586562216,0.00015204434748739004,0.00012243086530361325,0.0001037160400301218,0.00014822764205746353,8.86789639480412e-05,0.00010750161163741723,0.00011695339344441891,8.85001354617998e-05,9.85823935479857e-05,0.00010541689698584378,9.520370804239064e-05,9.164759103441611e-05,8.631820674054325e-05,8.704486390342936e-05,7.92097271187231e-05,9.017789125209674e-05,9.326162398792803e-05,7.699763955315575e-05,6.388966721715406e-05,5.4081705457065254e-05,5.331479769665748e-05,5.528929614229128e-05,4.7635923692723736e-05,5.498974132933654e-05,4.331826130510308e-05,6.114294228609651e-05,8.488951425533742e-05,9.029717330122367e-05,9.558491728967056e-05,8.492769848089665e-05,7.020709745120257e-05,
mae,0.23024040460586548,0.10315850377082825,0.09867595881223679,0.08448231965303421,0.059915944933891296,0.046491578221321106,0.051002539694309235,0.04063265770673752,0.03616632521152496,0.036834295839071274,0.03218024969100952,0.02700612135231495,0.02417563647031784,0.02549193799495697,0.027091195806860924,0.027042651548981667,0.021845877170562744,0.019881881773471832,0.020323563367128372,0.02438095584511757,0.019801193848252296,0.019332803785800934,0.01740766502916813,0.016103282570838928,0.014489212073385715,0.017995959147810936,0.015536714345216751,0.015629520639777184,0.017121480777859688,0.014876488596200943,0.015252803452312946,0.01290951482951641,0.011171803809702396,0.010100104846060276,0.01542192604392767,0.013486129231750965,0.013707113452255726,0.010901707224547863,0.01374388299882412,0.013259167782962322,0.010862474329769611,0.01067693717777729,0.012458227574825287,0.012675288133323193,0.009423429146409035,0.009911086410284042,0.010925445705652237,0.012148474343121052,0.011805214919149876,0.011011812835931778,0.011213290505111217,0.01009436696767807,0.009485765360295773,0.008825150318443775,0.008214687928557396,0.007713485974818468,0.007841450162231922,0.007156687323004007,0.01007162593305111,0.009064204059541225,0.008629899471998215,0.0085280267521739,0.00799290370196104,0.007500631269067526,0.007846948690712452,0.009840532205998898,0.00963780377060175,0.00864472147077322,0.008676332421600819,0.009627816267311573,0.008691336959600449,0.007848176173865795,0.009558976627886295,0.007392881438136101,0.00821747537702322,0.008854302577674389,0.007405306212604046,0.007955595850944519,0.008160047233104706,0.0076172444969415665,0.007669184356927872,0.007358588743954897,0.007374187931418419,0.006979239638894796,0.007426450960338116,0.007555246818810701,0.0068371836096048355,0.0061459774151444435,0.005738049279898405,0.005625654943287373,0.005778191611170769,0.005347994156181812,0.0057824356481432915,0.005132721737027168,0.00611821748316288,0.007289812434464693,0.007592859212309122,0.007869716733694077,0.007367057725787163,0.006353029981255531,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 45731     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 45732     
=================================================================
Total params: 91,463
Trainable params: 91,463
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               8448      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               32896     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 45,731
Trainable params: 45,731
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                8224      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 45,732
Trainable params: 45,732
Non-trainable params: 0
_________________________________________________________________
