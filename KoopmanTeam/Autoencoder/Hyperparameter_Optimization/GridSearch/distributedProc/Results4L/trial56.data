2021-06-26
loss,0.5709382891654968,0.2255370020866394,0.16234038770198822,0.12053851783275604,0.1093079075217247,0.08004403114318848,0.07639121264219284,0.09803163260221481,0.06197471171617508,0.06011362001299858,0.05464087799191475,0.05564192309975624,0.05832711607217789,0.06177153438329697,0.04653891548514366,0.04781990498304367,0.050317052751779556,0.047471120953559875,0.037611525505781174,0.03757830709218979,0.036650072783231735,0.0355200469493866,0.04164549335837364,0.033828482031822205,0.03638642653822899,0.039287272840738297,0.03629647195339203,0.034724634140729904,0.030779626220464706,0.031055878847837448,0.03232590854167938,0.03100055456161499,0.029800115153193474,0.03141893446445465,0.02791886031627655,0.026994340121746063,0.028155189007520676,0.02980133146047592,0.027392948046326637,0.02748962864279747,0.02539663575589657,0.022741613909602165,0.028061680495738983,0.02840295061469078,0.024720104411244392,0.020549898967146873,0.021287236362695694,0.021982405334711075,0.02528901770710945,0.01965981535613537,0.022603247314691544,0.023904483765363693,0.022101595997810364,0.023435797542333603,0.023740725591778755,0.023818690329790115,0.022795023396611214,0.020113928243517876,0.02056472934782505,0.021827291697263718,0.024170244112610817,0.02242957055568695,0.019925471395254135,0.018237054347991943,0.02090824581682682,0.019668277353048325,0.019823022186756134,0.017502648755908012,0.021777866408228874,0.019433287903666496,0.019138624891638756,0.017976414412260056,0.016473833471536636,0.01668739877641201,0.02242163009941578,0.022321224212646484,0.019187742844223976,0.016807762905955315,0.015252054668962955,0.017211051657795906,0.01715567708015442,0.018818296492099762,0.018449729308485985,0.01837782748043537,0.017002001404762268,0.019430184736847878,0.01876644976437092,0.017703449353575706,0.01753009855747223,0.017749805003404617,0.013865282759070396,0.014718935824930668,0.01710161752998829,0.017557566985487938,0.019127409905195236,0.017646033316850662,0.01613438129425049,0.015744000673294067,0.01618284545838833,0.016532041132450104,
mse,0.16155800223350525,0.017017703503370285,0.00857700314372778,0.004230936523526907,0.0034673905465751886,0.0018960110610350966,0.0016723810695111752,0.0027925027534365654,0.0011680033057928085,0.0010601310059428215,0.000861937238369137,0.0008945739828050137,0.0010005204239860177,0.0010970293078571558,0.0006345193833112717,0.000669251021463424,0.0007156911306083202,0.0006402365979738533,0.0004161008109804243,0.0004190290637779981,0.00038788304664194584,0.0003694004553835839,0.0005241816979832947,0.00034213633625768125,0.0003893242101185024,0.0004450786509551108,0.0003831499197985977,0.0003635086468420923,0.00028418778674677014,0.0002903449931181967,0.00030099545256234705,0.00028469617245718837,0.00026290674577467144,0.000288914394332096,0.00022623460972681642,0.00021608520182780921,0.00023087160661816597,0.0002555550017859787,0.00022182879911269993,0.00021928554633632302,0.00018396814994048327,0.00015484170580748469,0.00022546638501808047,0.00022315001115202904,0.00017373870650772005,0.00012616108870133758,0.00013389741070568562,0.00014326490054372698,0.00018480588914826512,0.00012070263619534671,0.000152839464135468,0.00016437098383903503,0.00014081285917200148,0.00015954897389747202,0.00015670993889216334,0.00016052453429438174,0.00015117555449251086,0.00011725239164661616,0.00012243208766449243,0.00013769765791948885,0.00016423116903752089,0.00013989211583975703,0.00011425461707403883,0.00010105301771545783,0.0001279589778278023,0.00011514505604282022,0.00011486334551591426,9.105533536057919e-05,0.00013450885307975113,0.00010651210322976112,0.00010496360482648015,9.489006333751604e-05,8.120498387143016e-05,8.388658170588315e-05,0.00014303496573120356,0.00013670769112650305,0.00010166739230044186,8.249967504525557e-05,7.05947240930982e-05,8.703778439667076e-05,8.630113006802276e-05,0.00010195681534241885,9.692785533843562e-05,9.658878843765706e-05,8.491812332067639e-05,0.00010558616486378014,9.950340609066188e-05,8.945555600803345e-05,8.849175355862826e-05,9.12102113943547e-05,5.9105710533913225e-05,6.62087113596499e-05,8.473572233924642e-05,8.876557694748044e-05,0.00010300643043592572,8.795961912255734e-05,7.561927486676723e-05,7.235731754917651e-05,7.543771789642051e-05,7.885510422056541e-05,
mae,0.2468823790550232,0.09499479085206985,0.0683043971657753,0.05191298946738243,0.04681255295872688,0.03368065133690834,0.0323294959962368,0.04170215502381325,0.026282185688614845,0.025268692523241043,0.023068921640515327,0.02356964908540249,0.024424750357866287,0.026476066559553146,0.019779110327363014,0.02033224143087864,0.021490849554538727,0.01996006816625595,0.015979163348674774,0.015978559851646423,0.015682920813560486,0.014957239851355553,0.017508720979094505,0.014384763315320015,0.015664782375097275,0.016708126291632652,0.015337014570832253,0.014840292744338512,0.01325204223394394,0.013161062262952328,0.013918756507337093,0.013210432603955269,0.012554305605590343,0.013701044023036957,0.011901263147592545,0.011411943472921848,0.01209614984691143,0.012870472855865955,0.011856642551720142,0.011677682399749756,0.010756786912679672,0.00958235189318657,0.011967277154326439,0.012248673476278782,0.010442285798490047,0.008693674579262733,0.009047528728842735,0.009275552816689014,0.010788578540086746,0.008393554948270321,0.009601647034287453,0.010237903334200382,0.009318445809185505,0.01007099635899067,0.010233148001134396,0.010093080811202526,0.00967390276491642,0.008544611744582653,0.00870807096362114,0.009346885606646538,0.010432693175971508,0.009539654478430748,0.008344180881977081,0.007841858081519604,0.00879682693630457,0.008209891617298126,0.008381374180316925,0.007452787831425667,0.009258287958800793,0.008194852620363235,0.008101931773126125,0.007522300351411104,0.006969756912440062,0.00711540412157774,0.009368998929858208,0.009485825896263123,0.008195101283490658,0.007175392936915159,0.006519664544612169,0.007148530334234238,0.007216170430183411,0.008078092709183693,0.007867441512644291,0.007662755437195301,0.007085882592946291,0.008242523297667503,0.007920781150460243,0.007560343015938997,0.007401800248771906,0.007471435237675905,0.005915599875152111,0.0062352800741791725,0.007237870711833239,0.007534350734204054,0.008201459422707558,0.007506234105676413,0.006925061345100403,0.006699924357235432,0.006864418275654316,0.007056811358779669,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 144275    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 144276    
=================================================================
Total params: 288,551
Trainable params: 288,551
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               4352      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                8208      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 144,275
Trainable params: 144,275
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               8704      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                4112      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 144,276
Trainable params: 144,276
Non-trainable params: 0
_________________________________________________________________
