2021-06-26
loss,0.3415566384792328,0.11893609166145325,0.061666492372751236,0.052202530205249786,0.06044219061732292,0.06496286392211914,0.050831034779548645,0.043674275279045105,0.03961995989084244,0.035598352551460266,0.0388297475874424,0.040918637067079544,0.04580821096897125,0.04378613829612732,0.04645993560552597,0.03978903591632843,0.04632103443145752,0.04919222742319107,0.038285862654447556,0.03374319523572922,0.03128046914935112,0.03021274134516716,0.029894329607486725,0.028705215081572533,0.04256502538919449,0.03552127256989479,0.03274556249380112,0.04059383273124695,0.04065600037574768,0.03395015001296997,0.029334764927625656,0.026646986603736877,0.027623599395155907,0.04253636300563812,0.03850230202078819,0.03644578158855438,0.03118898719549179,0.02953239530324936,0.027337176725268364,0.03522350639104843,0.03410675376653671,0.02907755598425865,0.031217198818922043,0.032419171184301376,0.031136974692344666,0.023280933499336243,0.021437089890241623,0.02081962861120701,0.017710203304886818,0.017113028094172478,0.016815749928355217,0.016700219362974167,0.01650015078485012,0.01654789410531521,0.016474317759275436,0.01631787419319153,0.01613156497478485,0.016133837401866913,0.016042813658714294,0.01596314273774624,0.0159856416285038,0.01568816415965557,0.015864675864577293,0.015619717538356781,0.01563892886042595,0.0156825203448534,0.015509954653680325,0.015424516052007675,0.015330962836742401,0.015282150357961655,0.015273124910891056,0.015039938502013683,0.015138739719986916,0.014929789118468761,0.014960273168981075,0.014872069470584393,0.014751540496945381,0.014659992419183254,0.014493541792035103,0.014642388559877872,0.014524814672768116,0.014441780745983124,0.014438220299780369,0.014378932304680347,0.014329569414258003,0.014246269129216671,0.014048639684915543,0.014052828773856163,0.013860943727195263,0.014432810246944427,0.01640249229967594,0.0244734026491642,0.023262133821845055,0.023639876395463943,0.02228712849318981,0.021165601909160614,0.02008654922246933,0.019100148230791092,0.01827746257185936,0.017545685172080994,
mse,0.04899848625063896,0.005078192334622145,0.0011657655704766512,0.0008315850864164531,0.0011097013484686613,0.0012062840396538377,0.0007323316531255841,0.0005717318272218108,0.00046055379789322615,0.00037541004712693393,0.0004503674863371998,0.0005082174902781844,0.000597445759922266,0.0005761244683526456,0.0006357918027788401,0.00046214324538595974,0.0006248268764466047,0.0006852691876702011,0.0004175156354904175,0.0003147242241539061,0.0002722647332120687,0.0002575440739747137,0.0002570590586401522,0.0002454670029692352,0.000528487900737673,0.0003697307547554374,0.00030637768213637173,0.0004704713064711541,0.00047793961130082607,0.0003315187932457775,0.00023865647381171584,0.00020217405108269304,0.00022434821585193276,0.0005419882945716381,0.00043465697672218084,0.00038223963929340243,0.0002779660280793905,0.00024576106807217,0.00020613547530956566,0.00036743993405252695,0.00033115866244770586,0.00023827049881219864,0.0002863926347345114,0.0003006797924172133,0.0002892005431931466,0.00016039727779570967,0.00013732101069763303,0.0001291856897296384,9.045923798112199e-05,8.395300392294303e-05,8.101169805740938e-05,7.973745232447982e-05,7.78963731136173e-05,7.7937358582858e-05,7.653123611817136e-05,7.512495358241722e-05,7.381443720078096e-05,7.31078689568676e-05,7.253813237184659e-05,7.142304093576968e-05,7.209821342257783e-05,7.028345862636343e-05,7.005056249909103e-05,6.872286758152768e-05,6.936671707080677e-05,6.93906404194422e-05,6.758835661457852e-05,6.6578017140273e-05,6.578474130947143e-05,6.52034068480134e-05,6.492107786471024e-05,6.274801853578538e-05,6.40644648228772e-05,6.24689637334086e-05,6.238826608750969e-05,6.172291614348069e-05,6.0294441937003285e-05,6.021974695613608e-05,6.027579365763813e-05,6.089692760724574e-05,5.9654241340467706e-05,5.872409383300692e-05,5.861587851541117e-05,5.72423632547725e-05,5.742654684581794e-05,5.623133256449364e-05,5.5011900258250535e-05,5.4959185945335776e-05,5.478215098264627e-05,6.208936974871904e-05,8.339744817931205e-05,0.00017423916142433882,0.00015407716273330152,0.00015800965775270015,0.0001366704673273489,0.00012349315511528403,0.00011143417214043438,0.00010173401824431494,9.388133912580088e-05,8.726643136469647e-05,
mae,0.14307674765586853,0.049715276807546616,0.0257719736546278,0.021797170862555504,0.025568466633558273,0.02741776779294014,0.02166103385388851,0.01831784099340439,0.016419023275375366,0.014747394248843193,0.01646514981985092,0.017339877784252167,0.01940007507801056,0.018489375710487366,0.019650248810648918,0.016825193539261818,0.019831085577607155,0.02041766606271267,0.01626286283135414,0.014016476459801197,0.013196243904531002,0.012973491102457047,0.012775293551385403,0.01198812946677208,0.017662622034549713,0.015034053474664688,0.013977344147861004,0.017290960997343063,0.016662223264575005,0.014079234562814236,0.01234452798962593,0.011198325082659721,0.011551205068826675,0.017813140526413918,0.01576487347483635,0.014838251285254955,0.013232635334134102,0.01232572179287672,0.011324466206133366,0.01443436834961176,0.013845506124198437,0.012250436469912529,0.013172720558941364,0.013246987946331501,0.01254215370863676,0.01003344263881445,0.009031591936945915,0.008817460387945175,0.00728874746710062,0.007022110745310783,0.0069966185837984085,0.006907226052135229,0.006881828419864178,0.0069702016189694405,0.0068565309047698975,0.006794958841055632,0.0068169706501066685,0.006751509848982096,0.0068231443874537945,0.006743418052792549,0.006738152354955673,0.006671113893389702,0.006675754673779011,0.006629167124629021,0.006611292250454426,0.00663123419508338,0.006459742784500122,0.006453058682382107,0.006537105422466993,0.006429878529161215,0.006379596423357725,0.00640883669257164,0.006361793726682663,0.006291159428656101,0.006314842030405998,0.00624554418027401,0.006237284746021032,0.00620876532047987,0.006123745813965797,0.0061666034162044525,0.0060693989507853985,0.006124458741396666,0.006109178066253662,0.006063698325306177,0.005996763240545988,0.005952340550720692,0.005970461294054985,0.005963343195617199,0.005879991687834263,0.006088850554078817,0.006933312863111496,0.010288509540259838,0.009765817783772945,0.010099407285451889,0.009656455367803574,0.009166544303297997,0.008714310824871063,0.008244271390140057,0.007879567332565784,0.007458141539245844,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 11603     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 11604     
=================================================================
Total params: 23,207
Trainable params: 23,207
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               2176      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 11,603
Trainable params: 11,603
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                2064      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 11,604
Trainable params: 11,604
Non-trainable params: 0
_________________________________________________________________
