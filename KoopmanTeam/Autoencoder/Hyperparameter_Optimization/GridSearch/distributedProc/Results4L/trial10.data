2021-06-26
loss,0.3748873770236969,0.11262921243906021,0.059414397925138474,0.047789763659238815,0.04219280183315277,0.03882943093776703,0.03637721762061119,0.03488533943891525,0.03342790901660919,0.032134491950273514,0.03076600283384323,0.030355578288435936,0.029406793415546417,0.02855805866420269,0.02798299491405487,0.027537651360034943,0.027171265333890915,0.026603316888213158,0.02619791030883789,0.02594839408993721,0.025527402758598328,0.02489795722067356,0.0246865376830101,0.02416825294494629,0.023988815024495125,0.023696796968579292,0.023264311254024506,0.02313649095594883,0.02288333885371685,0.022719066590070724,0.022377774119377136,0.022238563746213913,0.022133946418762207,0.0218069888651371,0.02169923484325409,0.02178879827260971,0.021267931908369064,0.02111310511827469,0.021077916026115417,0.021014735102653503,0.020810969173908234,0.02057690918445587,0.0202977005392313,0.02035195380449295,0.020231027156114578,0.019974254071712494,0.01997769996523857,0.01961580105125904,0.019612053409218788,0.019661789759993553,0.019417155534029007,0.019384045153856277,0.019280336797237396,0.019224664196372032,0.019101236015558243,0.018876083195209503,0.018807988613843918,0.018695028498768806,0.0187604408711195,0.018570516258478165,0.018453853204846382,0.01840992644429207,0.01839311234652996,0.018235735595226288,0.018206186592578888,0.01807836815714836,0.01802956871688366,0.01788436621427536,0.01791359670460224,0.017749618738889694,0.017713598906993866,0.017733722925186157,0.017611714079976082,0.017488710582256317,0.017393000423908234,0.017388565465807915,0.017334282398223877,0.01720917783677578,0.01718856766819954,0.017022984102368355,0.017061801627278328,0.01698213256895542,0.0169163029640913,0.01681174524128437,0.01683896780014038,0.016737522557377815,0.01673906482756138,0.016601745039224625,0.016575198620557785,0.016473906114697456,0.01653837040066719,0.01638168841600418,0.01643378473818302,0.016280516982078552,0.016193460673093796,0.016215883195400238,0.01614963263273239,0.01605420745909214,0.01605071686208248,0.015945104882121086,
mse,0.06067754328250885,0.0048134163953363895,0.0012298970250412822,0.0007470898563042283,0.0005655251443386078,0.0004751627566292882,0.00040946778608486056,0.0003701126261148602,0.0003367267781868577,0.0003094259591307491,0.0002828082942869514,0.00027317367494106293,0.00025619202642701566,0.00024058205599430948,0.0002308386901859194,0.00022238680685404688,0.00021575023129116744,0.00020707110525108874,0.0002000319364015013,0.0001976247294805944,0.0001890581042971462,0.00017967287567444146,0.0001759267906891182,0.0001687374315224588,0.0001664010196691379,0.0001618733658688143,0.00015563950000796467,0.00015377390081994236,0.0001503250387031585,0.0001481823856011033,0.0001433558645658195,0.00014183078019414097,0.00014036936045158654,0.000135424270411022,0.00013523527013603598,0.00013675283116754144,0.00013160583330318332,0.0001272591616725549,0.00012559584865812212,0.00012608057295437902,0.00012292727478779852,0.00011986573372269049,0.00011644755431916565,0.00011681519390549511,0.00011589711357373744,0.00011233484110562131,0.00011241810716455802,0.0001081898735719733,0.00010837388254003599,0.00010932043369393796,0.00010603339615045115,0.00010551639570621774,0.00010439848847454414,0.00010395233402960002,0.00010206953447777778,0.00010003674105973914,9.898272401187569e-05,9.815054363571107e-05,9.928517101798207e-05,9.645315731177106e-05,9.519876766717061e-05,9.593438153387979e-05,9.510250674793497e-05,9.260283695766702e-05,9.278810466639698e-05,9.101179603021592e-05,9.058428986463696e-05,8.915048965718597e-05,9.061992022907361e-05,8.75677724252455e-05,8.78814171301201e-05,8.756944589549676e-05,8.618386345915496e-05,8.521732524968684e-05,8.425017585977912e-05,8.46565599204041e-05,8.344948582816869e-05,8.215616253437474e-05,8.24649614514783e-05,8.027817966649309e-05,8.072526543401182e-05,8.012607577256858e-05,7.956993067637086e-05,7.83849973231554e-05,7.895080489106476e-05,7.775977428536862e-05,7.844586070859805e-05,7.626610749866813e-05,7.602084224345163e-05,7.562452810816467e-05,7.551470480393618e-05,7.479126361431554e-05,7.474862650269642e-05,7.309988723136485e-05,7.288469350896776e-05,7.303615711862221e-05,7.219623512355611e-05,7.144027040340006e-05,7.118817302398384e-05,7.038918556645513e-05,
mae,0.16162468492984772,0.04766380414366722,0.025172004476189613,0.02034236118197441,0.01797766238451004,0.016540277749300003,0.015527394600212574,0.014866670593619347,0.014277989976108074,0.013783292844891548,0.013192419894039631,0.013000531122088432,0.012587112374603748,0.012218721210956573,0.011905326507985592,0.011784588918089867,0.011633208952844143,0.011314891278743744,0.011195250786840916,0.011082443408668041,0.011029750108718872,0.010670006275177002,0.010614119470119476,0.010386431589722633,0.010224418714642525,0.010168500244617462,0.00989514123648405,0.009977741166949272,0.009825761429965496,0.009749269112944603,0.009647468104958534,0.009490984492003918,0.00940757431089878,0.009409080259501934,0.009212702512741089,0.00933623593300581,0.00920295063406229,0.009026734158396721,0.009037444368004799,0.008919531479477882,0.008961746469140053,0.008779439143836498,0.008702503517270088,0.008787338621914387,0.00867320504039526,0.008518841117620468,0.008606591261923313,0.008435160852968693,0.008420980535447598,0.00848371908068657,0.008373459801077843,0.008345006965100765,0.008309937082231045,0.00817230623215437,0.008253132924437523,0.008059356361627579,0.008094914257526398,0.008016419596970081,0.008093615993857384,0.007939442060887814,0.007917124778032303,0.007750102784484625,0.007913842797279358,0.007844862528145313,0.0077963825315237045,0.007815558463335037,0.00783362053334713,0.007599400822073221,0.007606711238622665,0.007624340709298849,0.007686488796025515,0.007541835308074951,0.007555370219051838,0.0074617741629481316,0.0074950759299099445,0.007474783807992935,0.0074007040821015835,0.007383919321000576,0.007302175275981426,0.007320352364331484,0.00739521998912096,0.007335692178457975,0.007237705402076244,0.007202835753560066,0.00722003448754549,0.007204714231193066,0.00715184211730957,0.007153116632252932,0.007164863403886557,0.006923345383256674,0.007118095178157091,0.007013231050223112,0.007037789095193148,0.007041386794298887,0.006913250312209129,0.006953607313334942,0.006996338255703449,0.006877204403281212,0.006906790658831596,0.006864011753350496,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 3827      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 3828      
=================================================================
Total params: 7,655
Trainable params: 7,655
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                2080      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 3,827
Trainable params: 3,827
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 3,828
Trainable params: 3,828
Non-trainable params: 0
_________________________________________________________________
