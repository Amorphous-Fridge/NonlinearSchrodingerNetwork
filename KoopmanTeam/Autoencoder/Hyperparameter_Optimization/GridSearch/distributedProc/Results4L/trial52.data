2021-06-26
loss,2.3589730262756348,2.2026729583740234,2.199643611907959,2.199796438217163,2.2007384300231934,2.2002620697021484,2.200713872909546,2.2010257244110107,2.200786590576172,2.200925588607788,2.200319290161133,2.204617500305176,2.2004923820495605,2.200453996658325,2.1993892192840576,2.199723482131958,2.198662281036377,2.3555991649627686,1.2350592613220215,0.44922056794166565,0.44489502906799316,0.4441606104373932,0.4443911015987396,0.4445951581001282,0.4445458948612213,0.44509756565093994,0.44446852803230286,0.44515132904052734,0.4441429078578949,0.4439508318901062,0.44514888525009155,0.4447234272956848,0.44489794969558716,0.44447654485702515,0.44504985213279724,0.44511014223098755,0.4426000714302063,0.44806647300720215,0.44502493739128113,0.4452800750732422,0.4448753297328949,0.4447348713874817,0.46604180335998535,0.44547736644744873,0.44463181495666504,0.44473302364349365,0.4450013339519501,0.4445677697658539,0.44568297266960144,0.44469788670539856,0.4443461298942566,0.4440268278121948,0.4447037875652313,0.44478434324264526,0.44449305534362793,0.4446913003921509,0.44482365250587463,0.4452465772628784,0.4450126588344574,0.4453073740005493,0.4445759952068329,0.44487887620925903,0.44498732686042786,0.44546717405319214,0.44464170932769775,0.44433388113975525,0.44459420442581177,0.445012629032135,0.4441150724887848,0.44527506828308105,0.4447777569293976,0.44458991289138794,0.4446110129356384,0.445264995098114,0.44363918900489807,0.4447149336338043,0.44414666295051575,0.44483810663223267,0.44500720500946045,0.44481971859931946,0.44511640071868896,0.4444633722305298,0.44478267431259155,0.44447457790374756,0.4454176425933838,0.4447824954986572,0.4448866546154022,0.44478538632392883,0.4450587332248688,0.4445051848888397,0.4446174204349518,0.44479477405548096,0.4453469514846802,0.4452844262123108,0.44427239894866943,0.44437941908836365,0.44447121024131775,0.4454086720943451,0.44384685158729553,0.44450196623802185,
mse,1.432991623878479,1.2267191410064697,1.2232964038848877,1.2234771251678467,1.224499225616455,1.2240030765533447,1.2244725227355957,1.224860429763794,1.2246274948120117,1.2247358560562134,1.2240476608276367,1.2287852764129639,1.2243051528930664,1.2242729663848877,1.2230476140975952,1.2233517169952393,1.2222896814346313,1.4221587181091309,0.5695475935935974,0.056268226355314255,0.05516665056347847,0.05501210317015648,0.055042728781700134,0.055097904056310654,0.055083781480789185,0.055156100541353226,0.05504044517874718,0.055218879133462906,0.054978083819150925,0.05495413392782211,0.05520579218864441,0.055110953748226166,0.055127110332250595,0.055037789046764374,0.05515093356370926,0.05515376478433609,0.055802784860134125,0.05597484111785889,0.055185552686452866,0.05522727593779564,0.055139604955911636,0.05512848496437073,0.06184694170951843,0.05530893802642822,0.05508465692400932,0.055148959159851074,0.05518000200390816,0.05510558560490608,0.05535098537802696,0.055119019001722336,0.05504303798079491,0.05495272949337959,0.05510739982128143,0.05515236407518387,0.0550784207880497,0.05510469898581505,0.055117107927799225,0.05523082613945007,0.055192578583955765,0.05525156855583191,0.055071860551834106,0.05514257773756981,0.05515746772289276,0.05530213192105293,0.0550880990922451,0.05505508929491043,0.05509158968925476,0.055204033851623535,0.054991982877254486,0.0552191399037838,0.055118393152952194,0.055086471140384674,0.05505847558379173,0.05524250864982605,0.05489666014909744,0.05511273443698883,0.05498769134283066,0.05514875054359436,0.05520317703485489,0.05510123074054718,0.05518729239702225,0.055048827081918716,0.05513624846935272,0.05505707114934921,0.05525161325931549,0.05509968101978302,0.055164884775877,0.055129993706941605,0.05519523471593857,0.05504905804991722,0.05508125200867653,0.055135443806648254,0.05525858327746391,0.05526239797472954,0.055001530796289444,0.055059973150491714,0.05505916476249695,0.05526910349726677,0.054896071553230286,0.0550653450191021,
mae,0.8138597011566162,0.5848050117492676,0.561880886554718,0.5580962896347046,0.5567710399627686,0.5556641817092896,0.5551913976669312,0.577299177646637,0.5571900010108948,0.5545507073402405,0.5541914105415344,0.5875179171562195,0.563235878944397,0.5547081828117371,0.5536844730377197,0.5534870028495789,0.5532495379447937,0.7803239226341248,0.47760123014450073,0.19891855120658875,0.19728101789951324,0.19703249633312225,0.19713060557842255,0.1972455382347107,0.1971501111984253,0.1974056214094162,0.19716762006282806,0.1974797248840332,0.1970510482788086,0.19690613448619843,0.19742918014526367,0.19727210700511932,0.19730737805366516,0.19716057181358337,0.19734469056129456,0.19743819534778595,0.19517605006694794,0.1984061747789383,0.19736696779727936,0.1974669247865677,0.19735300540924072,0.19715406000614166,0.20542824268341064,0.19759464263916016,0.19718283414840698,0.19724096357822418,0.19741812348365784,0.19713887572288513,0.197683185338974,0.19721229374408722,0.19701892137527466,0.196902796626091,0.19727464020252228,0.19731898605823517,0.1972108632326126,0.19726796448230743,0.19726449251174927,0.19748607277870178,0.19741468131542206,0.1975734382867813,0.19719688594341278,0.19732265174388885,0.19738033413887024,0.1976270228624344,0.19721850752830505,0.19706468284130096,0.19714435935020447,0.19743429124355316,0.19699227809906006,0.19748865067958832,0.19735601544380188,0.1972385197877884,0.19718244671821594,0.1974855661392212,0.19680427014827728,0.19724853336811066,0.19701650738716125,0.19732266664505005,0.19740711152553558,0.1973017454147339,0.1974361091852188,0.19715602695941925,0.19731904566287994,0.1971001774072647,0.1975363940000534,0.19724586606025696,0.19729185104370117,0.19727353751659393,0.19739404320716858,0.1971932053565979,0.19728565216064453,0.19733844697475433,0.1975833922624588,0.19753018021583557,0.19701723754405975,0.19712044298648834,0.19716741144657135,0.1975240558385849,0.19684593379497528,0.19715985655784607,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 116035    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 116036    
=================================================================
Total params: 232,071
Trainable params: 232,071
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 64)                320       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 128)               32896     
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 387       
=================================================================
Total params: 116,035
Trainable params: 116,035
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 128)               512       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 256)               33024     
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               65792     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 260       
=================================================================
Total params: 116,036
Trainable params: 116,036
Non-trainable params: 0
_________________________________________________________________
