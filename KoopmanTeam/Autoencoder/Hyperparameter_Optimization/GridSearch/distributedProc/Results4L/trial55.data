2021-06-26
loss,2.563303232192993,2.0536720752716064,0.4764428734779358,0.13403502106666565,0.09962236136198044,0.07959941774606705,0.07901415973901749,0.0827593058347702,0.08780868351459503,0.07568813860416412,0.06506809592247009,0.06525557488203049,0.058729346841573715,0.04655472934246063,0.03530513495206833,0.0324275977909565,0.03167920187115669,0.029968544840812683,0.02945036254823208,0.02864156663417816,0.028358355164527893,0.027660401538014412,0.027243493124842644,0.026484454050660133,0.02621498890221119,0.025400731712579727,0.027755407616496086,0.042253464460372925,0.039550114423036575,0.03834521025419235,0.03746308013796806,0.03637150302529335,0.035967692732810974,0.0327809676527977,0.03693711385130882,0.03636088967323303,0.030991658568382263,0.026476074010133743,0.02468506246805191,0.03384709730744362,0.029516203328967094,0.0300043486058712,0.02683536522090435,0.028180982917547226,0.030581431463360786,0.029506102204322815,0.02895268052816391,0.029775824397802353,0.030433274805545807,0.025524131953716278,0.023993808776140213,0.022223150357604027,0.02025572769343853,0.01845448464155197,0.019255496561527252,0.026291806250810623,0.02796681597828865,0.026008816435933113,0.023426471278071404,0.021060585975646973,0.01947135105729103,0.01855025440454483,0.023679271340370178,0.02909100614488125,0.02861124835908413,0.02560894936323166,0.02335197478532791,0.021709466353058815,0.025576883926987648,0.023084962740540504,0.02157885767519474,0.019674306735396385,0.018261022865772247,0.017192505300045013,0.0174342580139637,0.025958262383937836,0.024594981223344803,0.021975787356495857,0.02245270274579525,0.022749243304133415,0.023260880261659622,0.02401163801550865,0.021293945610523224,0.019502216950058937,0.017374461516737938,0.01621094159781933,0.015649311244487762,0.0172404907643795,0.0179685540497303,0.021022863686084747,0.019697606563568115,0.023529309779405594,0.02246028184890747,0.020177418366074562,0.019050562754273415,0.01768549345433712,0.01559534203261137,0.013900093734264374,0.016783256083726883,0.01979208178818226,
mse,1.7250151634216309,1.0757591724395752,0.10688226670026779,0.005586251150816679,0.0029807761311531067,0.0018583820201456547,0.0018982923356816173,0.0020386292599141598,0.002213368657976389,0.0017083644634112716,0.0012708640424534678,0.0012169091496616602,0.0009936807909980416,0.0006542302435263991,0.00038994368514977396,0.0003210170834790915,0.00029639608692377806,0.00026351536507718265,0.0002558936830610037,0.00024225172819569707,0.00023718824377283454,0.00022615923080593348,0.00021586734510492533,0.00020682919421233237,0.00020195191609673202,0.00018748448928818107,0.0002496039669495076,0.0005322216311469674,0.0004553120525088161,0.0004281693836674094,0.00040553216240368783,0.0003983394708484411,0.0003930250823032111,0.0003183776861988008,0.00039753748569637537,0.00037323046126402915,0.0002834569604601711,0.0002151557127945125,0.00018386221199762076,0.00034052133560180664,0.00025197540526278317,0.0002672252303455025,0.00022817769786342978,0.00023000729561317712,0.00027767513529397547,0.0002544414601288736,0.0002443118719384074,0.00025849961093626916,0.00025918727624230087,0.0001851466513471678,0.00016439658065792173,0.0001422462082700804,0.0001202304192702286,0.00010308124910807237,0.00011666680802591145,0.00020780746126547456,0.00022254478244576603,0.00019571695884224027,0.00016122996748890728,0.00013327010674402118,0.0001141236352850683,0.00010514282621443272,0.00016787204367574304,0.00023961914121173322,0.0002250915567856282,0.00018710159929469228,0.00016143108950927854,0.00014234530681278557,0.00018485802866052836,0.0001533399918116629,0.00013483490329235792,0.0001108371652662754,9.553968993714079e-05,8.529289334546775e-05,9.315587521996349e-05,0.00019778084242716432,0.00017459969967603683,0.00014213286340236664,0.0001514125760877505,0.00015109460218809545,0.00015520365559495986,0.0001607942976988852,0.00013201132242102176,0.0001116721541620791,9.20256570680067e-05,8.062838605837896e-05,7.533199823228642e-05,9.111165127251297e-05,0.00010016125452239066,0.00012697727652266622,0.00011447684664744884,0.0001572555338498205,0.0001428572868462652,0.0001175554352812469,0.00010522295633563772,9.178723121294752e-05,7.60887996875681e-05,6.108840898377821e-05,8.526528108632192e-05,0.00011024913692381233,
mae,0.970187246799469,0.6065002679824829,0.18940667808055878,0.057662319391965866,0.04240342602133751,0.0337861105799675,0.03378860652446747,0.034899745136499405,0.03747355937957764,0.032555509358644485,0.027981001883745193,0.028024688363075256,0.025088466703891754,0.019906383007764816,0.015038052573800087,0.01385781541466713,0.013595818541944027,0.012758459895849228,0.012503919191658497,0.012237650342285633,0.012028110213577747,0.01187832746654749,0.011581385508179665,0.011315803974866867,0.011145944707095623,0.010789606720209122,0.01181845460087061,0.01752789318561554,0.016798080876469612,0.015995530411601067,0.016036653891205788,0.015496578998863697,0.015506957657635212,0.013893203809857368,0.016044843941926956,0.015752844512462616,0.013176691718399525,0.011080989614129066,0.010379631072282791,0.014362554997205734,0.012457411736249924,0.012698992155492306,0.011550962924957275,0.011873075738549232,0.013238687068223953,0.012576514855027199,0.01239573210477829,0.01275563146919012,0.013160090893507004,0.010656877420842648,0.010004311800003052,0.009420075453817844,0.00859396904706955,0.007865438237786293,0.008208622224628925,0.011168424971401691,0.011887887492775917,0.010957445949316025,0.009840232320129871,0.008703701198101044,0.007967721670866013,0.007804143242537975,0.010028836317360401,0.01255493238568306,0.01249335054308176,0.011019766330718994,0.009954061359167099,0.009193949401378632,0.01079643052071333,0.009958051145076752,0.00923051219433546,0.008299320004880428,0.007584292907267809,0.007187042385339737,0.007425182964652777,0.011052832938730717,0.010244246572256088,0.009328869171440601,0.009579721838235855,0.00950470007956028,0.00987757183611393,0.010346675291657448,0.009058686904609203,0.008165701292455196,0.0073819225654006,0.006823386065661907,0.006584819406270981,0.007295849267393351,0.007592301350086927,0.00904280785471201,0.008353076875209808,0.010109057649970055,0.009507563896477222,0.008405567146837711,0.007998030632734299,0.007463319227099419,0.006662691943347454,0.00590035505592823,0.007166373077780008,0.008405099622905254,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 138059    
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 138060    
=================================================================
Total params: 276,119
Trainable params: 276,119
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 256)               2304      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 512)               131584    
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 8)                 4104      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 27        
=================================================================
Total params: 138,059
Trainable params: 138,059
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 32        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 512)               4608      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               131328    
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 8)                 2056      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 138,060
Trainable params: 138,060
Non-trainable params: 0
_________________________________________________________________
