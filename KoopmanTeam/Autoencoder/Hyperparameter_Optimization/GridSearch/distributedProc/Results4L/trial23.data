2021-06-26
loss,0.3257948160171509,0.08513781428337097,0.08211714029312134,0.06686710566282272,0.058573249727487564,0.060036800801754,0.0656353235244751,0.053946081548929214,0.07267400622367859,0.062453582882881165,0.05107380822300911,0.043067920953035355,0.044712066650390625,0.05237792432308197,0.04401697590947151,0.048473063856363297,0.04273223504424095,0.04240776225924492,0.0360560305416584,0.03351742401719093,0.030941970646381378,0.028297509998083115,0.037573445588350296,0.03324823081493378,0.03617390990257263,0.0417589470744133,0.03967711329460144,0.03472714126110077,0.031376730650663376,0.02906292863190174,0.02798701822757721,0.02206435427069664,0.02172008715569973,0.02084992080926895,0.02002701535820961,0.019673680886626244,0.019296346232295036,0.019056884571909904,0.01885581575334072,0.018704956397414207,0.018499070778489113,0.018373681232333183,0.01824306882917881,0.018162976950407028,0.018109411001205444,0.01795121654868126,0.017898911610245705,0.017721742391586304,0.017628345638513565,0.017535515129566193,0.017424171790480614,0.017249030992388725,0.017094600945711136,0.01710868626832962,0.01699916645884514,0.016890084370970726,0.01673433743417263,0.016615260392427444,0.016605688259005547,0.016403160989284515,0.016405826434493065,0.01630365662276745,0.016206398606300354,0.016169440001249313,0.015987833961844444,0.01813580095767975,0.027045095339417458,0.02764197066426277,0.026524286717176437,0.025202548131346703,0.02810337021946907,0.024571560323238373,0.02342071570456028,0.027196679264307022,0.024055464193224907,0.02388520911335945,0.02288726158440113,0.02244354411959648,0.0200644563883543,0.018407531082630157,0.025651872158050537,0.024754729121923447,0.02294451929628849,0.023077042773365974,0.0241375844925642,0.022060992196202278,0.02080008015036583,0.02236413210630417,0.02370324544608593,0.021687887609004974,0.020537858828902245,0.019478023052215576,0.018248222768306732,0.01816261000931263,0.01852320320904255,0.015493913553655148,0.016434114426374435,0.022312410175800323,0.021495811641216278,0.021020619198679924,
mse,0.04663987085223198,0.0022361529991030693,0.00197491399012506,0.0012575633591040969,0.0009671753505244851,0.0010738982819020748,0.0011836076155304909,0.000807412841822952,0.0015290060546249151,0.0010861130431294441,0.0007376775029115379,0.0005269471439532936,0.0005589643260464072,0.000801204121671617,0.000540237408131361,0.0006627809489145875,0.0005168782663531601,0.0005093479994684458,0.00036425836151465774,0.0003050730156246573,0.0002654686977621168,0.00022836055723018944,0.00039645470678806305,0.0003030982334166765,0.00037987116957083344,0.0004915507743135095,0.000440091680502519,0.00033209973480552435,0.00027065470931120217,0.0002325440727872774,0.00022341131989378482,0.0001418959000147879,0.00013407795631792396,0.00012143730418756604,0.00011081831326009706,0.00010763961472548544,0.00010297105473000556,0.00010110061703016981,9.890622459352016e-05,9.705872071208432e-05,9.42031474551186e-05,9.293801849707961e-05,9.192545985570177e-05,9.116489673033357e-05,9.021312143886462e-05,8.912699559004977e-05,8.75172481755726e-05,8.638401777716354e-05,8.509128383593634e-05,8.463809353997931e-05,8.324130612891167e-05,8.158801210811362e-05,8.094323129625991e-05,8.015304774744436e-05,7.939968054415658e-05,7.880778866820037e-05,7.677402027184144e-05,7.570798334199935e-05,7.545409607701004e-05,7.423273927997798e-05,7.335318514378741e-05,7.310151704587042e-05,7.226529851322994e-05,7.1824157203082e-05,7.135045598261058e-05,0.00010129550355486572,0.00021803815616294742,0.00020916826906614006,0.00019168975995853543,0.00018100017041433603,0.00021530229423660785,0.00017494354688096792,0.00015728404105175287,0.00020567301544360816,0.00016410961688961834,0.00015769380843266845,0.00014703076158184558,0.00013934439630247653,0.00011705468205036595,9.998841414926574e-05,0.00018047142657451332,0.00017098995158448815,0.00014373894373420626,0.00014882907271385193,0.00015809638716746122,0.00013420516916085035,0.00012012335355393589,0.00013835408026352525,0.00015296430501621217,0.0001306046760873869,0.00011763921065721661,0.00010601806570775807,9.313309419667348e-05,9.32936163735576e-05,9.68936801655218e-05,7.337715942412615e-05,7.932632433949038e-05,0.00014124248991720378,0.00012879677524324507,0.00012112189142499119,
mae,0.13617034256458282,0.03586297482252121,0.03486541286110878,0.028029436245560646,0.025098338723182678,0.02552713081240654,0.02824253961443901,0.023117687553167343,0.03147260472178459,0.027560852468013763,0.022120483219623566,0.018569638952612877,0.019151393324136734,0.02243052050471306,0.01860630512237549,0.021005673334002495,0.018440134823322296,0.0183687936514616,0.01585572212934494,0.01483495905995369,0.013381741009652615,0.012164819054305553,0.01609530672430992,0.014748224057257175,0.015572753734886646,0.017891477793455124,0.01742306351661682,0.014865715056657791,0.013538416475057602,0.012482363730669022,0.011916670016944408,0.009416879154741764,0.009290022775530815,0.008858419954776764,0.008565203286707401,0.00845390185713768,0.008229639381170273,0.008184718899428844,0.008081158623099327,0.008009389974176884,0.007828839123249054,0.0077791837975382805,0.007721824571490288,0.007752532139420509,0.007695287000387907,0.007659104652702808,0.007629305124282837,0.007569098379462957,0.007438665255904198,0.007480040192604065,0.007346668280661106,0.007418713998049498,0.007304338272660971,0.007279955316334963,0.007209345232695341,0.007156859617680311,0.007101098075509071,0.007020368706434965,0.007100401911884546,0.00707040773704648,0.006996260490268469,0.006955331657081842,0.00695301778614521,0.006816266104578972,0.006863238289952278,0.007756713777780533,0.011478475295007229,0.011788819916546345,0.011490903794765472,0.010619418695569038,0.012422028928995132,0.01078040525317192,0.010058148764073849,0.011364209465682507,0.010234120301902294,0.01000037882477045,0.00969872809946537,0.009115319699048996,0.00852912850677967,0.00784294493496418,0.010798501782119274,0.01048003789037466,0.009826691821217537,0.009917395189404488,0.01034202054142952,0.00903218612074852,0.008519084192812443,0.009328493848443031,0.009686443023383617,0.008982078172266483,0.008762837387621403,0.008258791640400887,0.007697481662034988,0.007671070750802755,0.007912741973996162,0.006588671822100878,0.007056413684040308,0.009487849660217762,0.009214408695697784,0.008944012224674225,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 14819     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 14820     
=================================================================
Total params: 29,639
Trainable params: 29,639
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 64)                8256      
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                2080      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 14,819
Trainable params: 14,819
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                2112      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 14,820
Trainable params: 14,820
Non-trainable params: 0
_________________________________________________________________
