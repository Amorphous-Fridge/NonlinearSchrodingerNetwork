2021-06-26
loss,0.42883700132369995,0.09913583844900131,0.0716855525970459,0.10248913615942001,0.09017682075500488,0.07336598634719849,0.07919124513864517,0.0673646628856659,0.07898891717195511,0.06226273626089096,0.053151316940784454,0.054441072046756744,0.06583590060472488,0.05927064269781113,0.051217641681432724,0.050402864813804626,0.06004800274968147,0.05548925697803497,0.050598520785570145,0.0384405255317688,0.04642152786254883,0.050636082887649536,0.03981367126107216,0.04156780242919922,0.04689697176218033,0.04137754067778587,0.04058823734521866,0.039801012724637985,0.039559897035360336,0.04076512157917023,0.03739671781659126,0.03382609039545059,0.03760288655757904,0.03281475603580475,0.032019417732954025,0.031577225774526596,0.033678386360406876,0.03712739422917366,0.02784622833132744,0.025139445438981056,0.028480911627411842,0.029685940593481064,0.03331252187490463,0.03197010979056358,0.031682275235652924,0.0288882777094841,0.023553194478154182,0.025307022035121918,0.027710461989045143,0.025438981130719185,0.0310780331492424,0.028237678110599518,0.025031598284840584,0.0236151572316885,0.022147584706544876,0.022014841437339783,0.021187221631407738,0.027492806315422058,0.027334902435541153,0.027940897271037102,0.025076698511838913,0.028438255190849304,0.024008603766560555,0.02248837798833847,0.025375664234161377,0.024995839223265648,0.020113768056035042,0.022285843268036842,0.021871335804462433,0.0231460053473711,0.02397342212498188,0.021456636488437653,0.018569771200418472,0.017392847687005997,0.02432674914598465,0.022661447525024414,0.022749366238713264,0.021291635930538177,0.019370412454009056,0.020204542204737663,0.022038226947188377,0.023038189858198166,0.02050633728504181,0.019739430397748947,0.018436172977089882,0.019753534346818924,0.018619947135448456,0.017657341435551643,0.018190773203969002,0.02007352188229561,0.0177292600274086,0.019400492310523987,0.019084250554442406,0.018192186951637268,0.01866861991584301,0.019033463671803474,0.017053430899977684,0.016987867653369904,0.016905881464481354,0.01651845872402191,
mse,0.09500538557767868,0.0029120787512511015,0.0014588977210223675,0.0031443294137716293,0.002344297245144844,0.00152949383482337,0.0018095666309818625,0.0012625317322090268,0.0018495392287150025,0.0011126500321552157,0.0008035595528781414,0.0008346904651261866,0.0012452797964215279,0.0010170768946409225,0.0007265108870342374,0.0007196387741714716,0.0010274192318320274,0.0008626630296930671,0.0007469851989299059,0.0004322422028053552,0.000614002114161849,0.0007272232323884964,0.0004454492882359773,0.000503121002111584,0.0006426398176699877,0.00048789643915370107,0.0004658076213672757,0.0004457146569620818,0.0004411998379509896,0.0004639318212866783,0.00038834186852909625,0.0003355510998517275,0.0004095222393516451,0.00030678886105306447,0.00029297833680175245,0.0002824155963025987,0.0003246143751312047,0.00038931131712161005,0.00022652831103187054,0.0001873238943517208,0.0002300784399267286,0.00024586007930338383,0.0003120927431154996,0.0002912098716478795,0.00028491002740338445,0.00023272648104466498,0.00016397419676650316,0.0001856704766396433,0.0002127888728864491,0.00018577894661575556,0.0002700970508158207,0.0002242718474008143,0.000174118802533485,0.00015855081437621266,0.00014023999392520636,0.00013944783131591976,0.0001322161842836067,0.00020930697792209685,0.00021219777408987284,0.00021526556520257145,0.00017784068768378347,0.00022335507674142718,0.0001651463535381481,0.00014487018052022904,0.00018176611047238111,0.00017482475959695876,0.00012008007615804672,0.00014020895469002426,0.00013835520076099783,0.00015229875862132758,0.00015867945330683142,0.00013184433919377625,0.00010086874681292102,9.248300193576142e-05,0.0001669239136390388,0.00014291465049609542,0.00014494774222839624,0.00012739749217871577,0.00010636961087584496,0.00011452136823209003,0.00013647791638504714,0.0001511625450802967,0.00011956725211348385,0.00011128813639516011,9.810228948481381e-05,0.00010923456284217536,9.791392949409783e-05,9.19644080568105e-05,9.710720041766763e-05,0.00011383911623852327,9.16783174034208e-05,0.0001062430819729343,0.00010176605428569019,9.376908565172926e-05,9.805672016227618e-05,0.00010212021879851818,8.389254071516916e-05,8.449320739600807e-05,8.304313087137416e-05,7.995060877874494e-05,
mae,0.18528883159160614,0.04241786152124405,0.0303622055798769,0.043284062296152115,0.03837776929140091,0.03122412972152233,0.03329164907336235,0.028889384120702744,0.03421644866466522,0.02623298391699791,0.02251439169049263,0.0228816457092762,0.02823331579566002,0.025378990918397903,0.021875634789466858,0.021335242316126823,0.025801358744502068,0.023475879803299904,0.021333474665880203,0.016330529004335403,0.019708378240466118,0.02162182331085205,0.01681855320930481,0.017562974244356155,0.019984224811196327,0.017395012080669403,0.017321670427918434,0.01704530045390129,0.017036205157637596,0.017245693132281303,0.01588399149477482,0.014465132728219032,0.016008909791707993,0.013997577130794525,0.013491207733750343,0.013464686460793018,0.014293184503912926,0.016179652884602547,0.011613279581069946,0.010784361511468887,0.011902554892003536,0.012401334010064602,0.014267263002693653,0.013288388028740883,0.013382797129452229,0.012107152491807938,0.009908831678330898,0.010684783570468426,0.011581496335566044,0.010739702731370926,0.013151518069207668,0.012139282189309597,0.010170090943574905,0.009793638251721859,0.009380369447171688,0.009346564300358295,0.00894350279122591,0.011661726981401443,0.011510921642184258,0.011859002523124218,0.010597994551062584,0.01189243420958519,0.010080844163894653,0.00946132093667984,0.010872744023799896,0.010712835937738419,0.008570034056901932,0.009366375394165516,0.009268652647733688,0.009789437986910343,0.010236505419015884,0.009098428301513195,0.007882852107286453,0.007438711356371641,0.010558558627963066,0.009693174622952938,0.00947657786309719,0.009134012274444103,0.008339114487171173,0.0084447106346488,0.00931988563388586,0.009721887297928333,0.008681894280016422,0.008406474255025387,0.007788533344864845,0.008422681130468845,0.007912703789770603,0.0074891080148518085,0.007672471459954977,0.008620684035122395,0.007520362269133329,0.008302989415824413,0.008180337026715279,0.007798107340931892,0.00788266584277153,0.00812501274049282,0.007217319216579199,0.007147204130887985,0.007111940532922745,0.007005427964031696,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 29347     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 29348     
=================================================================
Total params: 58,695
Trainable params: 58,695
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                8256      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 195       
=================================================================
Total params: 29,347
Trainable params: 29,347
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 64)                256       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               8320      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 29,348
Trainable params: 29,348
Non-trainable params: 0
_________________________________________________________________
