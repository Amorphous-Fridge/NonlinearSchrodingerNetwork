2021-06-26
loss,0.37954428791999817,0.09619306772947311,0.07300618290901184,0.09120044857263565,0.0976274237036705,0.07457741349935532,0.0737944021821022,0.05298526585102081,0.059818144887685776,0.0647711381316185,0.07441240549087524,0.05491615831851959,0.053585171699523926,0.06725496053695679,0.06049094349145889,0.05278917774558067,0.052791155874729156,0.059158630669116974,0.05620900169014931,0.05309068039059639,0.05063923820853233,0.0471368208527565,0.047188032418489456,0.044625043869018555,0.03692300617694855,0.03457809239625931,0.03435487300157547,0.043954070657491684,0.04067708179354668,0.04288133606314659,0.04639667645096779,0.038855958729982376,0.03847210481762886,0.042464036494493484,0.04148092120885849,0.03847121447324753,0.033991724252700806,0.03421439602971077,0.029676547273993492,0.036267079412937164,0.0398133248090744,0.03924911096692085,0.03368866443634033,0.03447088971734047,0.03743426874279976,0.030372576788067818,0.03412463515996933,0.03329944610595703,0.02898908406496048,0.029280126094818115,0.02999405935406685,0.03476070985198021,0.03153817355632782,0.029491882771253586,0.025778327137231827,0.023263607174158096,0.02190108597278595,0.02673637866973877,0.028778238222002983,0.02846675179898739,0.028052356094121933,0.024885494261980057,0.028593426570296288,0.03226200491189957,0.03063538484275341,0.026012832298874855,0.024168629199266434,0.021697336807847023,0.017811356112360954,0.02362295426428318,0.027227163314819336,0.031219396740198135,0.02923009544610977,0.025769352912902832,0.023136192932724953,0.02058839052915573,0.0274331197142601,0.026024973019957542,0.027977952733635902,0.024745095521211624,0.022617902606725693,0.02396181970834732,0.02554987743496895,0.02443605661392212,0.026131587103009224,0.022945968434214592,0.020393867045640945,0.01946260966360569,0.022641295567154884,0.02327633462846279,0.02095397189259529,0.019555702805519104,0.017117956653237343,0.015539802610874176,0.017345568165183067,0.018262648954987526,0.0210986640304327,0.022830449044704437,0.020239444449543953,0.01905732974410057,
mse,0.06500769406557083,0.0028047405648976564,0.0015521370805799961,0.002476482419297099,0.002696688286960125,0.001567566068843007,0.001600113813765347,0.0008310098201036453,0.0010308491764590144,0.0012123147025704384,0.0015667818952351809,0.0008722111815586686,0.0008394058677367866,0.0013165198033675551,0.001033388078212738,0.0007782022003084421,0.0007871878333389759,0.0009700485970824957,0.0008973835501819849,0.0007710790378041565,0.0007230389746837318,0.0006304513663053513,0.000634599186014384,0.000586869427934289,0.00040113728027790785,0.00035496140480972826,0.0003451632219366729,0.0005327134858816862,0.0004534386389423162,0.0005257984739728272,0.0006042696768417954,0.0004137434880249202,0.00041906750993803144,0.00049393973313272,0.0004798942827619612,0.0004095525946468115,0.0003274519694969058,0.00032838768674992025,0.0002498874382581562,0.0003750033210963011,0.0004471238062251359,0.0004240663256496191,0.00031881078029982746,0.00034965865779668093,0.0003846754552796483,0.00026162603171542287,0.0003247561980970204,0.0003082347975578159,0.0002442638506181538,0.0002430935564916581,0.000250546436291188,0.0003366123419255018,0.0002833255275618285,0.00023842975497245789,0.00018984290363732725,0.00015549303498119116,0.00013697094982489944,0.0002101505669998005,0.00022534406161867082,0.00022460705076809973,0.00021940057922620326,0.00017844111425802112,0.00023157712712418288,0.00029131805058568716,0.0002623515611048788,0.0001847113890107721,0.00016171571041923016,0.00013542285887524486,9.31088361539878e-05,0.00016310684441123158,0.00020569797197822481,0.0002663000486791134,0.00023291082470677793,0.0001851083361543715,0.00015088162035681307,0.00012227673141751438,0.00021070502407383174,0.00018771506438497454,0.00021920200379099697,0.00017319289327133447,0.00014868493599351496,0.00016000958567019552,0.00018362421542406082,0.00016890151891857386,0.00018703572277445346,0.00014834231114946306,0.0001200666738441214,0.00010874561121454462,0.00014328972611110657,0.0001505689724581316,0.0001237711840076372,0.0001070035359589383,8.891856123227626e-05,7.095387991284952e-05,9.049096115631983e-05,9.811040217755362e-05,0.000126206548884511,0.00014485717110801488,0.00011385582183720544,0.00010258418478770182,
mae,0.1618005633354187,0.04094119369983673,0.030938677489757538,0.03855463117361069,0.04134168103337288,0.03211568668484688,0.030270559713244438,0.02264445088803768,0.025432519614696503,0.026614893227815628,0.0320357121527195,0.022609563544392586,0.02266235090792179,0.028674891218543053,0.025578832253813744,0.02251407317817211,0.02247440814971924,0.025220513343811035,0.023813709616661072,0.0227194856852293,0.022059381008148193,0.0200885608792305,0.020586032420396805,0.018775558099150658,0.015846973285079002,0.014588331803679466,0.014251948334276676,0.01842959225177765,0.016880439594388008,0.017714548856019974,0.01954125612974167,0.01624716818332672,0.016496596857905388,0.018033472821116447,0.01816597767174244,0.01628369279205799,0.014273887500166893,0.014329054392874241,0.012571923434734344,0.0156331118196249,0.017239483073353767,0.016524046659469604,0.014080402441322803,0.01478649489581585,0.016251645982265472,0.012768239714205265,0.014524240046739578,0.01408524438738823,0.012431261129677296,0.012611164711415768,0.012554721906781197,0.01442400086671114,0.013419478200376034,0.012870078906416893,0.011138428002595901,0.010243332013487816,0.009576115757226944,0.01136704534292221,0.012133103795349598,0.011917319148778915,0.011880041100084782,0.010559066198766232,0.012282744981348515,0.013692090287804604,0.013014061376452446,0.011138570494949818,0.01034221425652504,0.009122705087065697,0.007603388279676437,0.009759544394910336,0.01169636007398367,0.013380657881498337,0.012584853917360306,0.010987861081957817,0.00976886972784996,0.00886549986898899,0.011728432029485703,0.011285785585641861,0.012377955950796604,0.010170464403927326,0.00925638061016798,0.010072117671370506,0.010873530991375446,0.010529775172472,0.010996991768479347,0.0099205132573843,0.00863691046833992,0.008073711767792702,0.009723195806145668,0.009552656672894955,0.008972891606390476,0.008297925814986229,0.007233939599245787,0.006630278192460537,0.0073647163808345795,0.007806002628058195,0.008757109753787518,0.009590083733201027,0.008674907498061657,0.008067423477768898,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 25123     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 25124     
=================================================================
Total params: 50,247
Trainable params: 50,247
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 32)                160       
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 99        
=================================================================
Total params: 25,123
Trainable params: 25,123
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 32)                128       
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 128)               4224      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 128)               16512     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 32)                4128      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 132       
=================================================================
Total params: 25,124
Trainable params: 25,124
Non-trainable params: 0
_________________________________________________________________
