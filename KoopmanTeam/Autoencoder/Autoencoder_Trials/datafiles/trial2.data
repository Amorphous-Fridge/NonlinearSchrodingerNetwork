2021-06-13
loss,18.391460418701172,11.116523742675781,9.338208198547363,8.617945671081543,8.471911430358887,8.139533042907715,6.9897308349609375,6.2434515953063965,6.121857166290283,6.068533420562744,6.001997470855713,5.955554962158203,5.868933200836182,5.813085556030273,5.7780232429504395,5.698109149932861,5.667230129241943,5.5860114097595215,5.493450164794922,5.451409816741943,5.377264976501465,5.285196304321289,5.225863456726074,5.145148277282715,5.073678493499756,5.017623424530029,4.961594104766846,4.93546724319458,4.921835422515869,4.857375144958496,4.759991645812988,4.713038921356201,4.652383327484131,4.511138916015625,4.3146653175354,4.115850448608398,4.117747783660889,3.999634027481079,4.108036994934082,3.9526453018188477,3.9012699127197266,3.813131093978882,3.779522657394409,3.8788928985595703,3.869645118713379,3.778202533721924,3.7407538890838623,3.828406572341919,3.7465906143188477,3.6808111667633057,3.7057723999023438,3.6364235877990723,3.7612783908843994,3.660623073577881,3.6798360347747803,3.6087393760681152,3.6875686645507812,3.821657657623291,3.810504674911499,3.7062511444091797,3.6299798488616943,3.768986701965332,3.9069855213165283,3.7139554023742676,3.567253828048706,3.5230705738067627,3.518998384475708,3.515122652053833,3.5381524562835693,3.5550527572631836,3.5295162200927734,3.5523955821990967,3.687941789627075,3.7831408977508545,3.663905382156372,3.5587074756622314,3.50553560256958,3.5453872680664062,3.5838871002197266,3.5939996242523193,3.6322858333587646,3.6639842987060547,3.5173964500427246,3.5043036937713623,3.4744739532470703,3.4760074615478516,3.439089775085449,3.4215641021728516,3.4426944255828857,3.4058949947357178,3.4116384983062744,3.444674015045166,3.4803571701049805,3.4499523639678955,3.5305886268615723,3.4847869873046875,3.4636528491973877,3.681396245956421,3.685330390930176,3.4998855590820312,3.4282259941101074,3.386770009994507,3.352451801300049,3.4236087799072266,3.46208119392395,3.534165143966675,3.471181631088257,3.4100916385650635,3.3803675174713135,3.408548593521118,3.3977084159851074,3.38800048828125,3.3984525203704834,3.3337044715881348,3.3173227310180664,3.309969425201416,3.353485345840454,3.343329429626465,3.358035087585449,3.3480451107025146,3.355241298675537,3.298501491546631,3.3540725708007812,3.3394417762756348,3.26638126373291,3.311250686645508,3.2772738933563232,3.2680351734161377,3.2856431007385254,3.2801969051361084,3.2873785495758057,3.2615723609924316,3.315596342086792,3.336433172225952,3.219419002532959,3.229471206665039,3.309873342514038,3.2930309772491455,3.3979129791259766,3.4306812286376953,3.2836813926696777,3.220308542251587,3.2640700340270996,3.2856295108795166,3.2268848419189453,3.1861934661865234,3.1665008068084717,3.1615967750549316,3.205723762512207,3.191138982772827,3.22525691986084,3.1618599891662598,3.098113775253296,3.1324191093444824,3.083838701248169,3.092398166656494,3.0921998023986816,3.07454252243042,3.0728061199188232,3.1047027111053467,3.0965416431427,3.1538846492767334,3.108820915222168,3.263150930404663,3.2037158012390137,3.275703191757202,3.143303632736206,3.0872559547424316,3.0100274085998535,2.9871325492858887,3.0195534229278564,3.051107883453369,3.0379281044006348,3.0057034492492676,3.0347626209259033,3.0543863773345947,3.0182693004608154,3.0213401317596436,2.947718620300293,2.9677863121032715,3.049246311187744,3.0525054931640625,2.957282781600952,2.9287636280059814,2.9241058826446533,2.943418502807617,3.0635154247283936,3.067464828491211,3.136173725128174,3.191685438156128,3.0556344985961914,2.9623939990997314,3.026108741760254,2.935495376586914,2.9464776515960693,3.069345712661743,3.0466601848602295,3.0205228328704834,2.9859437942504883,2.929379940032959,2.9553873538970947,2.9199531078338623,2.9363348484039307,2.941535234451294,2.9216134548187256,2.919471502304077,3.103743076324463,3.0553231239318848,2.998915433883667,2.9905478954315186,3.0221474170684814,2.944206953048706,2.9893693923950195,2.9898300170898438,2.9009833335876465,3.010281562805176,2.880618095397949,2.9490880966186523,2.9718544483184814,2.927091121673584,2.8828656673431396,2.8761751651763916,2.8165688514709473,2.846693992614746,2.876633882522583,2.8429348468780518,2.884728193283081,2.8690264225006104,2.9491469860076904,2.7838094234466553,2.8483333587646484,2.7982699871063232,2.874601125717163,2.7913143634796143,2.8094592094421387,2.8292298316955566,2.983654737472534,2.9404358863830566,3.0116848945617676,2.9517548084259033,2.9115331172943115,2.896367073059082,2.9207162857055664,2.9674301147460938,2.9838249683380127,2.922605276107788,2.831270217895508,2.806096076965332,2.905912160873413,2.8655669689178467,2.8315951824188232,2.8706958293914795,2.8062925338745117,2.7881760597229004,2.8318865299224854,2.7276556491851807,2.7857754230499268,2.8173351287841797,2.711474895477295,2.7986090183258057,2.7658896446228027,2.7418289184570312,2.754676103591919,2.7263095378875732,2.8167736530303955,2.7850701808929443,2.7650835514068604,2.851478338241577,2.927694320678711,2.9780328273773193,3.0553741455078125,2.885220527648926,2.9034006595611572,2.8399341106414795,2.9078409671783447,2.989081382751465,2.941082239151001,3.0383191108703613,3.0383193492889404,2.9329826831817627,2.888784885406494,2.8081247806549072,2.820344924926758,2.7735304832458496,2.7821218967437744,2.8098034858703613,2.793985605239868,2.9010252952575684,2.7141611576080322,2.7415261268615723,2.756464958190918,2.7239792346954346,2.700510263442993,2.8765125274658203,2.83292293548584,3.085705518722534,2.889885902404785,2.8445310592651367,2.8949642181396484,2.8727505207061768,2.819512367248535,2.728243827819824,2.7286429405212402,2.7614336013793945,2.812967538833618,2.794463872909546,2.759530544281006,2.6837172508239746,2.8611621856689453,2.8344573974609375,2.9274652004241943,2.970865249633789,2.933115243911743,2.8998889923095703,2.9265363216400146,2.9392502307891846,3.005810499191284,3.0709612369537354,3.099858045578003,3.1508941650390625,3.112353563308716,2.900283098220825,2.8731632232666016,2.7578725814819336,2.7183432579040527,2.679699182510376,2.6738967895507812,2.7241525650024414,2.789449691772461,2.837512493133545,2.890899658203125,2.8969497680664062,2.8770577907562256,2.701808452606201,2.712283134460449,2.6386935710906982,2.8360588550567627,2.6455130577087402,2.6485037803649902,2.6090874671936035,2.809161901473999,2.8779807090759277,2.7329375743865967,2.6902811527252197,2.743804693222046,2.8605730533599854,2.774468421936035,2.992976427078247,2.775160551071167,2.7966861724853516,2.8373489379882812,2.8356618881225586,2.7033143043518066,2.705536127090454,2.752103805541992,2.8169238567352295,2.769204616546631,2.75001859664917,2.795717716217041,2.7588937282562256,2.848160743713379,2.836791753768921,2.698854684829712,2.754166603088379,2.9634358882904053,2.7578423023223877,2.7288880348205566,2.7721974849700928,2.7816412448883057,2.8231942653656006,2.831780433654785,2.9800591468811035,2.811218023300171,2.686028242111206,2.5913071632385254,2.728933811187744,2.608915328979492,2.632331132888794,2.5983645915985107,2.6807122230529785,2.712270498275757,2.681535243988037,2.6784439086914062,2.697312355041504,2.619457960128784,2.574683904647827,2.636286735534668,2.6447713375091553,3.008488178253174,2.7175867557525635,2.696622610092163,2.737124443054199,2.773347854614258,2.8688645362854004,3.066166877746582,3.0739004611968994,3.0309484004974365,2.8453774452209473,2.765152931213379,2.66523814201355,2.6752636432647705,2.6265170574188232,2.580631732940674,2.669687509536743,2.6165332794189453,2.7159130573272705,2.807647943496704,2.729386568069458,2.8333182334899902,2.8380959033966064,2.7043979167938232,2.665971279144287,2.8232598304748535,2.731593370437622,2.6293840408325195,2.5894176959991455,2.634932279586792,2.634579658508301,2.672933340072632,2.5640530586242676,2.5563926696777344,2.564927577972412,2.560349702835083,2.5738885402679443,2.6721999645233154,2.632789373397827,2.6113462448120117,2.5817654132843018,2.5775845050811768,2.5698471069335938,2.7176685333251953,2.5755226612091064,2.5249640941619873,2.5116631984710693,2.5675361156463623,2.8199622631073,2.6289560794830322,2.589625835418701,2.6121017932891846,2.8060622215270996,2.88437557220459,2.6875216960906982,2.643587350845337,2.613450050354004,2.7838873863220215,2.864370822906494,2.7115955352783203,2.6549246311187744,2.644862651824951,2.5899651050567627,2.6304731369018555,2.601998805999756,2.5634567737579346,2.496750593185425,2.4743034839630127,2.5009329319000244,2.5017478466033936,2.64052152633667,2.6610119342803955,2.8480451107025146,2.5977678298950195,2.9298975467681885,2.686905860900879,2.5514252185821533,2.4921231269836426,2.5419955253601074,2.563300132751465,2.5829172134399414,2.5393013954162598,2.4810523986816406,2.631512403488159,2.6886749267578125,2.7498655319213867,2.7373926639556885,2.7217419147491455,2.6159451007843018,2.647867202758789,2.657350778579712,2.6528799533843994,2.6137313842773438,2.59281849861145,2.5683257579803467,2.5174825191497803,2.570977210998535,2.582284927368164,2.495102882385254,2.7777929306030273,2.706937313079834,2.718498945236206,2.720118522644043,2.601045608520508,2.701101303100586,2.7325756549835205,2.6612610816955566,2.556171178817749,2.6292998790740967,2.8657031059265137,2.939655065536499,2.810100793838501,2.786712408065796,
Loss:autoencoding_loss
Optimizer:Adam
Learning Rate:.001
Steps Per Epoch:50
States Per Step:512

Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 8)                 40        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 32)                544       
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 18        
=================================================================
Total params: 1,410
Trainable params: 1,410
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 8)                 24        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 16)                144       
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 32)                544       
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 16)                528       
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 8)                 136       
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 36        
=================================================================
Total params: 1,412
Trainable params: 1,412
Non-trainable params: 0
_________________________________________________________________
Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 1410      
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 1412      
=================================================================
Total params: 2,822
Trainable params: 2,822
Non-trainable params: 0
_________________________________________________________________
