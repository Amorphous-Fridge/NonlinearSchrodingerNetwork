2021-06-20
loss,20.30632972717285,7.9352593421936035,9.264496803283691,4.465307235717773,3.671278476715088,4.585659027099609,3.371079683303833,1.1106359958648682,1.9156749248504639,2.193037986755371,2.247994899749756,1.69966721534729,1.0722911357879639,1.3354072570800781,1.0974032878875732,0.7926018238067627,0.8819294571876526,2.5936217308044434,1.3927969932556152,1.1600059270858765,0.8345288634300232,1.125169277191162,1.7423690557479858,0.9917219281196594,1.0303540229797363,0.9670115113258362,0.8077916502952576,0.726253867149353,0.787283182144165,0.5206133127212524,1.0074595212936401,1.1235020160675049,1.047542929649353,1.0841158628463745,0.9942044019699097,1.142993450164795,0.707181990146637,0.6981789469718933,0.6198410987854004,0.8106486797332764,0.5671515464782715,0.8676738142967224,0.718766450881958,0.5903383493423462,0.5950114727020264,0.5656833052635193,0.5508604645729065,0.8339120745658875,0.7880304455757141,0.5097000002861023,1.1071045398712158,0.8235354423522949,0.6529596447944641,0.5335610508918762,0.6156789660453796,0.5860040187835693,0.789639413356781,0.7416967153549194,0.9002878665924072,0.7769076824188232,0.6379757523536682,0.7000337839126587,0.7036263942718506,0.7750721573829651,0.6858940124511719,0.7643571496009827,1.1349269151687622,0.7045095562934875,0.7227580547332764,1.5011122226715088,1.0204044580459595,0.7380660772323608,0.6114259958267212,0.6120238900184631,0.8856889605522156,0.7328613996505737,0.7293624877929688,0.5228557586669922,0.5313620567321777,0.8779377937316895,0.7000057697296143,0.5025700330734253,0.7856038808822632,0.6743403673171997,0.7025054693222046,0.5730583667755127,0.5843726396560669,0.5461313724517822,0.4439990222454071,0.7382736802101135,0.6865503191947937,0.43200352787971497,0.5611605048179626,0.511525571346283,0.42329156398773193,0.6104528903961182,0.7567974925041199,0.5566391944885254,0.6138269901275635,0.5066825747489929,0.7088609933853149,0.6768898963928223,0.6066281199455261,0.6081874966621399,0.6929932236671448,0.5628566741943359,0.6475644111633301,0.661480188369751,0.5168845653533936,0.7206043004989624,0.7591528296470642,0.625870943069458,0.5325781106948853,0.48495227098464966,0.6107347011566162,0.5398002862930298,0.5445234179496765,0.5982296466827393,0.5787325501441956,0.5503126382827759,0.6131210923194885,0.7346278429031372,0.6001598834991455,0.5643534064292908,0.6059150099754333,0.5335529446601868,0.47569525241851807,0.5259097814559937,0.5309493541717529,0.6621097326278687,0.48326897621154785,0.4667825400829315,0.5294461250305176,0.5955919027328491,0.47838303446769714,0.3993908762931824,0.749442994594574,0.638340175151825,0.6137404441833496,0.5606244206428528,0.4805068075656891,0.7567376494407654,0.5832973122596741,0.45869818329811096,0.4848460257053375,0.46983397006988525,0.43342289328575134,0.3810277581214905,0.7340123057365417,0.48904550075531006,0.9487760663032532,0.694089412689209,0.7465014457702637,0.5205963850021362,0.5528421998023987,0.5052292346954346,0.4606136083602905,0.7794241905212402,0.846127450466156,0.7340692281723022,0.7697888016700745,0.6500430107116699,0.5297901630401611,0.4465225636959076,0.4432638883590698,0.6163897514343262,0.5105369091033936,0.5275037288665771,0.49576032161712646,0.8059705495834351,0.6165109872817993,0.4634819030761719,0.44049471616744995,0.5058868527412415,0.7346990704536438,0.5869668126106262,0.3610488474369049,0.5472052097320557,0.5663695335388184,0.6027624607086182,0.5730936527252197,0.49009376764297485,0.4295180141925812,0.3786582052707672,0.3908567428588867,0.4437416195869446,0.4138774871826172,0.61124587059021,0.5418927669525146,0.46379098296165466,0.3624637722969055,1.0178667306900024,0.6906552910804749,1.2501031160354614,0.8725700378417969,0.5312210917472839,0.5100300312042236,0.5231970548629761,0.535544753074646,0.5532123446464539,
mse,0.725054919719696,0.6673051714897156,0.6356715559959412,0.6410791277885437,0.6370171904563904,0.4941631555557251,0.634339451789856,0.6499096751213074,0.6257807016372681,0.6397861838340759,0.6075797080993652,0.6510410308837891,0.6546914577484131,0.6512713432312012,0.6523045897483826,0.6594608426094055,0.6593745350837708,0.6606184244155884,0.6367857456207275,0.6565315127372742,0.6514437794685364,0.6534101963043213,0.6445288062095642,0.645592451095581,0.6628147959709167,0.6678564548492432,0.6606318950653076,0.6668981313705444,0.6531963348388672,0.6786243915557861,0.6804888248443604,0.6719922423362732,0.6675184369087219,0.6720497012138367,0.6695759296417236,0.6639983654022217,0.6718960404396057,0.6592444777488708,0.6663222312927246,0.6852548122406006,0.65540611743927,0.6591781377792358,0.6822054386138916,0.6692907810211182,0.6736565232276917,0.6527077555656433,0.6744241118431091,0.6775104403495789,0.6690851449966431,0.6713882684707642,0.6700043678283691,0.666066586971283,0.6722464561462402,0.6668199896812439,0.6605194211006165,0.6627857685089111,0.6738609075546265,0.6586325764656067,0.6692748069763184,0.6713024973869324,0.6713761687278748,0.6627456545829773,0.6653653979301453,0.6644085645675659,0.6816837191581726,0.6738369464874268,0.6711785197257996,0.6734066605567932,0.6776087880134583,0.6607859134674072,0.6764367818832397,0.6764159202575684,0.6808976531028748,0.6712377071380615,0.6750627756118774,0.6733052730560303,0.6753402948379517,0.6818743944168091,0.6656730771064758,0.6683530211448669,0.6878864765167236,0.6606674194335938,0.6843849420547485,0.6853253245353699,0.6680554151535034,0.6821430325508118,0.6768330931663513,0.6878695487976074,0.6759989261627197,0.6736820340156555,0.6808483004570007,0.6724308133125305,0.6750050187110901,0.6775698065757751,0.6854643225669861,0.6776918172836304,0.6702733635902405,0.6855155229568481,0.6708080172538757,0.6809130311012268,0.6825436353683472,0.6906161308288574,0.686901330947876,0.6809567213058472,0.6807031035423279,0.6860131025314331,0.6860416531562805,0.6785167455673218,0.6895208954811096,0.661547064781189,0.6749684810638428,0.6918274760246277,0.6871187686920166,0.6916466355323792,0.6856045722961426,0.6860127449035645,0.6873685717582703,0.6955255270004272,0.683933436870575,0.6856814622879028,0.6784529685974121,0.6994637250900269,0.6812246441841125,0.6886836290359497,0.6842429637908936,0.6691262125968933,0.6905591487884521,0.6684976816177368,0.6837090849876404,0.6947460770606995,0.6757627725601196,0.6837883591651917,0.6863890290260315,0.68761146068573,0.6858206987380981,0.6898922920227051,0.6817662715911865,0.682259202003479,0.6872760653495789,0.6948524713516235,0.6897760033607483,0.6852673888206482,0.6853069067001343,0.6868160367012024,0.6837369799613953,0.6881871819496155,0.6814565062522888,0.691245436668396,0.6815392971038818,0.682288646697998,0.6662335395812988,0.6969302296638489,0.6860978603363037,0.6868217587471008,0.6945816874504089,0.6867098212242126,0.6832653880119324,0.6917478442192078,0.7235820889472961,0.6970095634460449,0.6802964806556702,0.6949479579925537,0.6929475665092468,0.6905031800270081,0.6796521544456482,0.6870607733726501,0.6998512744903564,0.6765754222869873,0.6549705266952515,0.6757910251617432,0.687131404876709,0.6850509643554688,0.6871379613876343,0.6795379519462585,0.6610687971115112,0.6820605993270874,0.6872267127037048,0.696409285068512,0.6915472149848938,0.6922447681427002,0.6894618272781372,0.6978617310523987,0.6969358921051025,0.6919386982917786,0.6841114163398743,0.6830651760101318,0.6983616352081299,0.6785957217216492,0.684897243976593,0.6936686038970947,0.6882518529891968,0.6336067318916321,0.6627969145774841,0.5938720107078552,0.6447089910507202,0.6612251400947571,0.6639392375946045,0.6553226709365845,0.6358347535133362,0.6522118449211121,
mae,0.6627991199493408,0.6603987812995911,0.6592618823051453,0.6492905616760254,0.6392197608947754,0.5313761830329895,0.6154555678367615,0.6405763030052185,0.6071456074714661,0.6311606764793396,0.6003150343894958,0.6395822763442993,0.6402539014816284,0.6384678483009338,0.6388336420059204,0.6427444219589233,0.643157958984375,0.6538797616958618,0.6355375647544861,0.638347864151001,0.6309142112731934,0.6368284821510315,0.6294187307357788,0.6375428438186646,0.6420868635177612,0.644115686416626,0.6350595355033875,0.6406822204589844,0.6341798901557922,0.6508110761642456,0.6496930122375488,0.650465726852417,0.6459000110626221,0.6482909321784973,0.6439231038093567,0.6481171250343323,0.650014340877533,0.6407250165939331,0.6417516469955444,0.6575936675071716,0.6365252137184143,0.6366323828697205,0.6561743021011353,0.6441380381584167,0.6562556624412537,0.6325598359107971,0.6446838974952698,0.6495535373687744,0.6445964574813843,0.6425220966339111,0.6489700078964233,0.6483860015869141,0.6534890532493591,0.6486091613769531,0.6427702307701111,0.6447544693946838,0.6538958549499512,0.6434394717216492,0.6499066352844238,0.6509343981742859,0.6528958678245544,0.6410118341445923,0.6448437571525574,0.6413069367408752,0.656105101108551,0.6488980054855347,0.6419922709465027,0.6471696496009827,0.6493623852729797,0.6402825117111206,0.6538341045379639,0.6546107530593872,0.6608073711395264,0.6474621295928955,0.6553777456283569,0.654420793056488,0.6546639204025269,0.6580212116241455,0.6435155272483826,0.6426514387130737,0.666939914226532,0.6361726522445679,0.6558586359024048,0.6616377234458923,0.6424221992492676,0.6522818207740784,0.6488537788391113,0.6583455801010132,0.6493368744850159,0.6467355489730835,0.6545588970184326,0.6474484205245972,0.6513704657554626,0.6498481035232544,0.6588023900985718,0.6535035967826843,0.6467931866645813,0.6610837578773499,0.6481326222419739,0.6514976024627686,0.6520585417747498,0.6623968482017517,0.6618695855140686,0.6537254452705383,0.6514402627944946,0.658894956111908,0.6559404134750366,0.6498088836669922,0.6622412800788879,0.6448307037353516,0.6523725390434265,0.6610440611839294,0.658872663974762,0.6606388688087463,0.6570550799369812,0.6568908095359802,0.657345712184906,0.664121150970459,0.6554601788520813,0.6598576903343201,0.6513729691505432,0.669841468334198,0.6569503545761108,0.6595093607902527,0.6585039496421814,0.6443191766738892,0.6624077558517456,0.6428411602973938,0.6544660329818726,0.6670457720756531,0.6527756452560425,0.6544020175933838,0.6575966477394104,0.6599072217941284,0.6596155762672424,0.6642549633979797,0.6581053137779236,0.6555368900299072,0.6582278609275818,0.6662995219230652,0.6604081988334656,0.6544227004051208,0.6564151048660278,0.6585649251937866,0.6557832360267639,0.6610468029975891,0.6528449058532715,0.6625719666481018,0.6529436707496643,0.655194103717804,0.6400851607322693,0.6675306558609009,0.6582180261611938,0.6594426035881042,0.6737022399902344,0.6574591994285583,0.6525159478187561,0.6662567257881165,0.7098573446273804,0.6804766058921814,0.6632936596870422,0.6756895184516907,0.6738234162330627,0.6702093482017517,0.6581495404243469,0.6640500426292419,0.6731688976287842,0.6542611122131348,0.6394611597061157,0.651943564414978,0.661389172077179,0.662039577960968,0.6645001173019409,0.6570612192153931,0.6409838199615479,0.658854603767395,0.6616278290748596,0.6723019480705261,0.6694340705871582,0.6676279306411743,0.6654415130615234,0.6688886880874634,0.6711447238922119,0.6666698455810547,0.6582750678062439,0.6582481861114502,0.6698417663574219,0.6481211185455322,0.6561495065689087,0.6658395528793335,0.6589924097061157,0.6207054257392883,0.6486308574676514,0.600776731967926,0.6362476348876953,0.6468203663825989,0.6488832831382751,0.6402021050453186,0.6248395442962646,0.6326899528503418,
Loss,autoencoding_loss
Optimizer,Adam
Learning Rate,.001
Steps Per Epoch,50
Batch Size,4096
Epochs,200

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 2)                 35330     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 35332     
=================================================================
Total params: 70,662
Trainable params: 70,662
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 2)                 34        
=================================================================
Total params: 35,330
Trainable params: 35,330
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                48        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 35,332
Trainable params: 35,332
Non-trainable params: 0
_________________________________________________________________
