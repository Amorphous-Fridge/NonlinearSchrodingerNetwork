2021-06-20
loss,1629174890496.0,635323285504.0,337849712640.0,211265159168.0,144994893824.0,105778249728.0,80634028032.0,63486636032.0,51284938752.0,42263318528.0,35399192576.0,30067582976.0,25832574976.0,22412519424.0,19636062208.0,17331601408.0,15370327040.0,13730848768.0,12332261376.0,11128939520.0,10088454144.0,9175814144.0,8372197888.0,7667871232.0,7046601216.0,6486472192.0,5993590784.0,5546872832.0,5142972416.0,4783243776.0,4450948096.0,4153328896.0,3876504576.0,3628232192.0,3401991168.0,3190904832.0,3001358848.0,2823962368.0,2662044672.0,2506185216.0,2365982720.0,2234642176.0,2114122752.0,2001976832.0,1896370048.0,1797413888.0,1705436800.0,1619028864.0,1537411328.0,1461357824.0,1390769280.0,1324429440.0,1261448832.0,1201813504.0,1146257152.0,1092414336.0,1044016960.0,995931648.0,950499392.0,909667392.0,869617920.0,831937792.0,795755776.0,761435584.0,729324288.0,698599808.0,668900928.0,641224256.0,615182272.0,589336448.0,565337856.0,542682752.0,520883296.0,499467456.0,480248992.0,460781024.0,442361440.0,425163072.0,408538656.0,392632800.0,377676960.0,362865696.0,348847680.0,335676160.0,323065792.0,310616448.0,298869440.0,287719456.0,276986080.0,266505360.0,256693024.0,247044400.0,237875648.0,228794304.0,186911296.0,78240712.0,8909492.0,9.499715805053711,6.011618614196777,4.976931571960449,4.941420078277588,4.070769786834717,3.641744375228882,4.145279407501221,4.011100769042969,4.15548849105835,4.206106185913086,4.300322532653809,4.193408966064453,4.3236589431762695,3.9084272384643555,4.093482971191406,3.9561028480529785,3.0451853275299072,3.1797780990600586,3.562528610229492,3.6782400608062744,3.413862943649292,4.394918441772461,3.9004220962524414,3.204928398132324,3.5904464721679688,3.1972336769104004,3.359968900680542,3.2826192378997803,2.974621057510376,3.4323229789733887,3.285851240158081,2.9505198001861572,2.631908893585205,3.4927456378936768,3.008248805999756,3.3750460147857666,2.961651086807251,2.8596484661102295,3.308824062347412,2.8206374645233154,2.627002239227295,2.996804714202881,2.907651901245117,2.4440724849700928,2.8039815425872803,2.8096158504486084,3.5270912647247314,2.1857504844665527,2.995499610900879,3.189363956451416,2.7302334308624268,2.7008492946624756,2.664954423904419,3.271970272064209,2.4422171115875244,2.968900203704834,2.735776901245117,2.855151891708374,2.8882927894592285,3.6162726879119873,2.563149929046631,2.4683640003204346,2.3023571968078613,2.853896379470825,3.4897820949554443,2.938011884689331,3.029712200164795,3.7294631004333496,2.187626838684082,3.2384555339813232,2.1059436798095703,2.790497064590454,3.6686623096466064,2.514007329940796,2.4475650787353516,2.6444005966186523,2.6894452571868896,2.62042236328125,2.6583380699157715,3.203618049621582,2.521958112716675,4.086931228637695,2.9748010635375977,2.4955945014953613,2.178251266479492,2.9136569499969482,2.2713451385498047,2.7446885108947754,2.3072350025177,2.564182758331299,3.198307752609253,3.368975877761841,3.2813570499420166,2.0450310707092285,2.606642961502075,3.042100429534912,2.8628780841827393,2.654876708984375,2.7064733505249023,2.756121873855591,2.1662540435791016,3.249805212020874,3.79917049407959
mse,7.14796625788712e+20,1.0308811675013847e+20,2.8518802747765555e+19,1.1052021502055547e+19,5.182299018138485e+18,2.7509855143990395e+18,1.595740466844795e+18,9.881640852311245e+17,6.44329688075862e+17,4.373164906564813e+17,3.066592905448653e+17,2.2116968450490368e+17,1.6321128268877005e+17,1.2283012043086234e+17,9.42644389740544e+16,7.34262197265367e+16,5.774234348630835e+16,4.607842349114982e+16,3.716547299875226e+16,3.0263774086692864e+16,2.486814840664883e+16,2.0570460248866816e+16,1.7124315929509888e+16,1.4363470149451776e+16,1.2129645847642112e+16,1.0277638769737728e+16,8774808774901760.0,7515365449924608.0,6460647646691328.0,5588411729575936.0,4838621035102208.0,4213087234162688.0,3670177598144512.0,3215022197047296.0,2826586160103424.0,2486565410439168.0,2199980227952640.0,1947590367117312.0,1730633718038528.0,1533933611122688.0,1367045140643840.0,1219481875513344.0,1091456416612352.0,978749763878912.0,878189748420608.0,788931201204224.0,710243977789440.0,640083606634496.0,577202332631040.0,521490969657344.0,472338088853504.0,428338967478272.0,388561060757504.0,352699962884096.0,320838687522816.0,291399673053184.0,266156959072256.0,242202181632000.0,220607086067712.0,202059336908800.0,184660105625600.0,169004077416448.0,154622798856192.0,141571299213312.0,129884189884416.0,119169035010048.0,109253205426176.0,100398375370752.0,92409291603968.0,84807342096384.0,78041300598784.0,71911107198976.0,66249660825600.0,60914900402176.0,56314864599040.0,51843208052736.0,47780777164800.0,44137743122432.0,40753145315328.0,37642305536000.0,34829942915072.0,32150975938560.0,29715280691200.0,27512943935488.0,25484830179328.0,23558524764160.0,21810584223744.0,20213441495040.0,18733407928320.0,17342171971584.0,16088692686848.0,14902083190784.0,13816403329024.0,12782065942528.0,8706728656896.0,1721726009344.0,41012215808.0,0.459509938955307,0.48036521673202515,0.4623037576675415,0.4528929889202118,0.4508230984210968,0.45307621359825134,0.45529666543006897,0.45479995012283325,0.461640328168869,0.4568844735622406,0.44440996646881104,0.4530082941055298,0.4532362222671509,0.4444732666015625,0.4583514332771301,0.4547067880630493,0.45017296075820923,0.4457683563232422,0.45586147904396057,0.4463120996952057,0.44712716341018677,0.43317538499832153,0.4609934091567993,0.45379599928855896,0.44726958870887756,0.44722750782966614,0.4404110312461853,0.4557093381881714,0.44761067628860474,0.44731009006500244,0.4449903070926666,0.4457390606403351,0.44996878504753113,0.4481954276561737,0.44258254766464233,0.45502838492393494,0.45001110434532166,0.4396566152572632,0.4458969533443451,0.4457864761352539,0.4386686682701111,0.441767156124115,0.4380350112915039,0.4404957592487335,0.43954095244407654,0.43871065974235535,0.43494659662246704,0.4441750645637512,0.4409894049167633,0.4455608129501343,0.43638142943382263,0.4429000914096832,0.4340255856513977,0.44222965836524963,0.4376678168773651,0.43189144134521484,0.4451049864292145,0.43489930033683777,0.4355212450027466,0.4365598261356354,0.43563854694366455,0.43982574343681335,0.4394558072090149,0.4342268109321594,0.438991904258728,0.43781688809394836,0.4408996105194092,0.44620925188064575,0.44285327196121216,0.42681556940078735,0.44118553400039673,0.4349623918533325,0.4375379979610443,0.4360155165195465,0.4385426342487335,0.4404458701610565,0.43351346254348755,0.43621695041656494,0.43568840622901917,0.43789511919021606,0.44353678822517395,0.42746350169181824,0.4309728145599365,0.4329168200492859,0.43480372428894043,0.4373656213283539,0.43769344687461853,0.44287213683128357,0.4340667724609375,0.4299266040325165,0.4499996602535248,0.43415597081184387,0.431844025850296,0.4336063861846924,0.43577325344085693,0.4342578649520874,0.4341144263744354,0.43398937582969666,0.43330782651901245,0.43553271889686584,0.4384169280529022,0.44507157802581787,0.4371469020843506
mae,17435437056.0,6771365888.0,3590926080.0,2240837888.0,1535462144.0,1118596096.0,851710784.0,669905664.0,540698240.0,445186592.0,372624064.0,316286592.0,271567232.0,235461264.0,206191904.0,181899024.0,161236240.0,143969696.0,129254216.0,116594936.0,105650320.0,96060000.0,87611208.0,80215008.0,73691680.0,67814496.0,62641048.0,57956120.0,53720716.0,49949328.0,46465752.0,43348848.0,40446292.0,37848508.0,35478708.0,33269240.0,31288008.0,29432386.0,27739610.0,26107446.0,24642918.0,23270244.0,22010058.0,20839592.0,19736682.0,18702872.0,17742714.0,16840958.0,15988102.0,15194253.0,14458198.0,13766575.0,13109933.0,12487827.0,11909148.0,11347195.0,10843410.0,10341549.0,9867396.0,9443790.0,9026436.0,8634092.0,8256872.5,7899878.0,7565578.0,7245879.0,6936656.5,6648896.0,6377992.5,6108775.0,5859645.0,5623600.5,5397488.5,5174581.0,4974732.0,4773019.0,4581109.0,4402682.5,4229865.0,4064865.0,3909152.25,3755637.75,3609924.75,3473042.0,3342327.25,3213102.75,3091118.0,2975769.5,2864313.25,2755440.75,2653776.0,2553673.0,2458646.0,2364415.75,1932301.25,797756.375,80130.203125,0.4821026623249054,0.4861162304878235,0.48487889766693115,0.4839561879634857,0.4829104542732239,0.4847247004508972,0.4859146773815155,0.485280841588974,0.48726341128349304,0.4884755611419678,0.4857127070426941,0.487899512052536,0.4885329008102417,0.4875138998031616,0.4897177517414093,0.49030250310897827,0.4898647367954254,0.48901286721229553,0.49054640531539917,0.4894767701625824,0.4893336594104767,0.48798668384552,0.493163526058197,0.4920109808444977,0.4913768470287323,0.4922375977039337,0.49117377400398254,0.49452438950538635,0.4921737015247345,0.49185019731521606,0.4932921230792999,0.4935697913169861,0.4942125082015991,0.4939289391040802,0.4933493137359619,0.4967364966869354,0.49596312642097473,0.49378201365470886,0.49506327509880066,0.49497702717781067,0.49438154697418213,0.49488770961761475,0.49358150362968445,0.49524059891700745,0.4945189654827118,0.4941246807575226,0.49344363808631897,0.495730996131897,0.4949677288532257,0.49667710065841675,0.4950757622718811,0.4961238503456116,0.49490004777908325,0.4962655007839203,0.4957064390182495,0.49417629837989807,0.49767982959747314,0.4956328272819519,0.4960712194442749,0.4966678321361542,0.4963487982749939,0.49771177768707275,0.4974672198295593,0.49599897861480713,0.49742835760116577,0.4976252317428589,0.4978870749473572,0.499847412109375,0.4982341527938843,0.494904100894928,0.4984340965747833,0.4974059760570526,0.4978719651699066,0.4976167380809784,0.49866291880607605,0.49992072582244873,0.4976760149002075,0.49822503328323364,0.4979369342327118,0.4986787438392639,0.5000122785568237,0.4965866506099701,0.4965527355670929,0.497277170419693,0.49817100167274475,0.49878597259521484,0.49859046936035156,0.5003442168235779,0.49809250235557556,0.49756672978401184,0.501395583152771,0.49842891097068787,0.4979068338871002,0.4983946979045868,0.4987804889678955,0.49834415316581726,0.4982995092868805,0.4980315864086151,0.49749159812927246,0.4984211325645447,0.4993111491203308,0.5003567337989807,0.4991704821586609
Loss,autoencoding_loss,autoencoding_loss
Optimizer,Adam,Adam
Learning Rate,.001,.001
Steps Per Epoch,50,50
Batch Size,1024,1024
Epochs,100,100

Model: "Autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
Phi (Functional)             (None, 3)                 35347     
_________________________________________________________________
Phi_inv (Functional)         (None, 4)                 35348     
=================================================================
Total params: 70,695
Trainable params: 70,695
Non-trainable params: 0
_________________________________________________________________
Model: "Phi"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 4)]               0         
_________________________________________________________________
encoding_layer_1 (Dense)     (None, 16)                80        
_________________________________________________________________
encoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
encoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
encoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
encoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
bottleneck (Dense)           (None, 3)                 51        
=================================================================
Total params: 35,347
Trainable params: 35,347
Non-trainable params: 0
_________________________________________________________________
Model: "Phi_inv"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 3)]               0         
_________________________________________________________________
decoding_layer_1 (Dense)     (None, 16)                64        
_________________________________________________________________
decoding_layer_2 (Dense)     (None, 64)                1088      
_________________________________________________________________
decoding_layer_3 (Dense)     (None, 256)               16640     
_________________________________________________________________
decoding_layer_4 (Dense)     (None, 64)                16448     
_________________________________________________________________
decoding_layer_5 (Dense)     (None, 16)                1040      
_________________________________________________________________
decoded_layer (Dense)        (None, 4)                 68        
=================================================================
Total params: 35,348
Trainable params: 35,348
Non-trainable params: 0
_________________________________________________________________
