{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout  #Used for writing model architecture to datafiles\n",
    "import matplotlib.pyplot as plt         \n",
    "from datetime import date               #Used for datafiles\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "\n",
    "#Some GPU configuration\n",
    "#Always uses the 1st GPU avalible (if avalible) unless 1st line is uncommented, in which case no GPU is used\n",
    "\n",
    "#tf.config.set_visible_devices([], 'GPU') #uncomment to set tensorflow to use CPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) != 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETER SETUP\n",
    "\n",
    "- STATE_DIMENSION - The dimension of the original space.  Treating one complex dimension as two real dimensions\n",
    "- ANTIKOOPMAN_DIMENSION - The dimension of the reduced space.  Of form (dimension,) to keep tensorflow happy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_DIMENSION = 4    #Treating two complex dimensions as 4 real dimensions for now\n",
    "                          #Vector will be [real1, imag1, real2, imag2]\n",
    "ANTIKOOPMAN_DIMENSION = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA GENERATION\n",
    "\n",
    "Data will be valid states for our quantum system.  For the case of pure states on the Bloch sphere, these are 2 complex dimensional (4 real dimensional) vectors with an L2 norm of 1.\n",
    "\n",
    "For now, forming state $|\\alpha\\rangle =\\begin{bmatrix}x_1+iy_1\\\\ x_2+iy_2\\end{bmatrix}$ as the row vector $[x_1, y_1, x_2, y_2]$.  Could also try forming as 2x2 matrix $\\begin{bmatrix}x_1& y_1\\\\ x_2& y_2\\end{bmatrix}$.  Will likley be flattened when fed to the network though, so there is probably no difference in these methods, just how easy it is to read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pure_bloch(batch_size=16):\n",
    "    '''Generate random pure states on the bloch sphere.\n",
    "    These are two complex dimensional vectors with an L2 norm of 1.\n",
    "    Note that the state dimension of the Bloch sphere is always 4.\n",
    "    '''\n",
    "    bloch_state_dimension = 4\n",
    "    while True:\n",
    "        states = np.empty([batch_size, bloch_state_dimension])\n",
    "        for i in range(batch_size):\n",
    "            x1,y1,x2,y2 = np.random.random(4)\n",
    "            norm = np.sqrt(x1*x1 + y1*y1 + x2*x2 + y2*y2)\n",
    "            states[i] = 1/norm * np.array([x1,y1, x2,y2])\n",
    "        yield (states, states) #autoencoder, so data and label are the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "Things to test:\n",
    "- Various network depths\n",
    "- Various numbers of neurons in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layers for the encoder and decoder, respectivley\n",
    "initial_state = tf.keras.Input(shape = STATE_DIMENSION)\n",
    "antikoop_state = tf.keras.Input(shape = ANTIKOOPMAN_DIMENSION)\n",
    "\n",
    "##########################################ENCODER####################################################################\n",
    "encoding_layer_1 = tf.keras.layers.Dense(16, activation=\"relu\", name='encoding_layer_1')(initial_state)\n",
    "encoding_layer_2 = tf.keras.layers.Dense(64, activation=\"relu\", name='encoding_layer_2')(encoding_layer_1)\n",
    "encoding_layer_3 = tf.keras.layers.Dense(256, activation=\"relu\", name='encoding_layer_3')(encoding_layer_2)\n",
    "encoding_layer_4 = tf.keras.layers.Dense(64, activation=\"relu\", name='encoding_layer_4')(encoding_layer_3)\n",
    "encoding_layer_5 = tf.keras.layers.Dense(16, activation=\"relu\", name='encoding_layer_5')(encoding_layer_4)\n",
    "encoded_state = tf.keras.layers.Dense(ANTIKOOPMAN_DIMENSION, activation=\"relu\", name='bottleneck')(encoding_layer_5)\n",
    "#####################################################################################################################\n",
    "\n",
    "#########################################DECODER#####################################################################\n",
    "decoding_layer_1 = tf.keras.layers.Dense(16, activation = \"relu\", name='decoding_layer_1')(antikoop_state)\n",
    "decoding_layer_2 = tf.keras.layers.Dense(64, activation = \"relu\", name='decoding_layer_2')(decoding_layer_1)\n",
    "decoding_layer_3 = tf.keras.layers.Dense(256, activation = \"relu\", name='decoding_layer_3')(decoding_layer_2)\n",
    "decoding_layer_4 = tf.keras.layers.Dense(64, activation = \"relu\", name='decoding_layer_4')(decoding_layer_3)\n",
    "decoding_layer_5 = tf.keras.layers.Dense(16, activation = \"relu\", name='decoding_layer_5')(decoding_layer_4)\n",
    "decoded_state = tf.keras.layers.Dense(STATE_DIMENSION, activation = \"relu\", name='decoded_layer')(decoding_layer_5)\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "#Model declarations\n",
    "Phi = tf.keras.Model(inputs=initial_state, outputs = encoded_state, name='Phi')\n",
    "Phi_inv = tf.keras.Model(inputs = antikoop_state, outputs = decoded_state, name='Phi_inv')\n",
    "\n",
    "Autoencoder = tf.keras.models.Sequential([Phi, Phi_inv], name='Autoencoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and various utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoding_loss(y_true, y_pred):\n",
    "    '''The L2 norm of the input vector\n",
    "    and the autoencoded vector'''\n",
    "    return tf.norm(y_true-y_pred, ord = 2)\n",
    "\n",
    "\n",
    "def predict_single_state(state, encoder = Phi, decoder = Phi_inv):\n",
    "    '''Outputs the prediction of a single \n",
    "    state.  Primarily for sanity checks.\n",
    "    '''\n",
    "    encoded = encoder(np.array([state,]))\n",
    "    decoded = decoder(encoder(np.array([state,])))\n",
    "    return (state, encoded.numpy(), decoded.numpy())\n",
    "\n",
    "\n",
    "###################DATA WRITING FUNCTIONS#####################\n",
    "\n",
    "##############################################################\n",
    "def write_history(history, model, loss = 'autoencoding_loss', \n",
    "                  optimizer='Adam', lr='.001',spe='50',\n",
    "                  batch_size='1024', datadir='./Autoencoder_Trials/datafiles/'):\n",
    "    '''Writes training history to a datafile\n",
    "    This will create a new trial datafile.  If the model has \n",
    "    had additional training, append_history should be used instead.\n",
    "    \n",
    "    PARAMS:\n",
    "    -------\n",
    "    history - The history callback returned by the model.fit method in keras\n",
    "    model - The model (or list of models) which we want to write the architecture of to the datafile\n",
    "    string loss - The loss function the model was trained on\n",
    "    string optimizer - The optimizer the model was compiled with\n",
    "    string lr - The learning rate the model was initially compiled with\n",
    "    string spe - The number of steps per epoch\n",
    "    string batch_size - The number of samples trained on per step\n",
    "    string datadir - Directory where the datafiles are stored\n",
    "    '''\n",
    "    \n",
    "    rundatadir = datadir\n",
    "    filename = 'trial'+str(len(os.listdir(rundatadir)))\n",
    "\n",
    "    with open(rundatadir+filename+'.data', 'w') as f:\n",
    "        f.write(str(date.today())+'\\n')\n",
    "        for key in history.history.keys():\n",
    "            f.write(key+',')\n",
    "            for epoch in range(history.params['epochs']):\n",
    "                f.write(str(history.history[key][epoch])+',')\n",
    "            f.write('\\n')\n",
    "        f.write(\"Loss:{}\\nOptimizer:{}\\nLearning Rate:{}\\nSteps Per Epoch:{}\\nStates Per Step:{}\\n\".format(loss,optimizer,lr,spe,batch_size))\n",
    "        f.write('\\n')\n",
    "        with redirect_stdout(f):\n",
    "            for i in model:              \n",
    "                i.summary()\n",
    "    return rundatadir+filename+'.data'\n",
    "\n",
    "#####################################################################\n",
    "#####################################################################\n",
    "\n",
    "def append_history(history, trial, datadir='./Autoencoder_Trials/datafiles/'):\n",
    "    '''Appends new training data to trial datafile.\n",
    "    Note that this function only appends new loss/metrics data, not \n",
    "    loss functions, learning rates, etc.\n",
    "    '''\n",
    "    \n",
    "    filename = 'trial'+str(trial)+'.data'\n",
    "        \n",
    "    keys = history.history.keys()\n",
    "    newlines = []\n",
    "        \n",
    "    with open(datadir+filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            \n",
    "            tag = line.split(',')[0]\n",
    "            \n",
    "            if tag in keys:\n",
    "                newdata = [str(x) for x in history.history[tag]]\n",
    "                newlines.append(line.split(',')[:-1] + newdata ) #[:-1] to drop the newline\n",
    "            else:\n",
    "                newlines.append(line)\n",
    "    \n",
    "    with open('./test', 'w') as f:\n",
    "        for el in newlines:\n",
    "            if type(el) == list:\n",
    "                f.write(','.join(el))\n",
    "                f.write('\\n')\n",
    "            else:\n",
    "                f.write(el)\n",
    "    return\n",
    "    \n",
    "#####################################################################\n",
    "#####################################################################\n",
    "    \n",
    "def loss_plot(trial, trial_dir='./Autoencoder_Trials/datafiles/'):\n",
    "    '''Creates a plot of the loss for the given trial number\n",
    "    '''\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    with open(trial_dir+'trial'+str(trial)+'.data', 'r') as f:\n",
    "        lossline = f.readlines()[1]\n",
    "        for el in lossline.split(',')[1:-1]:\n",
    "            losses.append(el)\n",
    "            \n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize = (8,8))\n",
    "\n",
    "    \n",
    "    ax.plot(range(len(losses)), losses)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Trial '+str(trial)+' Loss')\n",
    "\n",
    "    fig.savefig('./Autoencoder_Trials/plots/trial{}.png'.format(trial))\n",
    "    \n",
    "    return None\n",
    "\n",
    "#####################################################################\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling/Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = .001), loss=autoencoding_loss, metrics = ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = Autoencoder.fit(generate_pure_bloch(1024), steps_per_epoch=50,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
