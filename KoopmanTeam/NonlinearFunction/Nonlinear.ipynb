{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Function\n",
    "\n",
    "Given a $\\phi$ and $\\phi^{-1}$ (trained in Quantum autoencoder) such that $\\phi^{-1}\\circ\\phi|\\alpha\\rangle = |\\alpha\\rangle$ and $dim(\\phi|\\alpha\\rangle) < dim(|\\alpha\\rangle)$, we want to find a function $f$ such that $\\phi^{-1}\\circ f\\circ\\phi|\\alpha_k\\rangle = |\\alpha_{k+1}\\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout  #Used for writing model architecture to datafiles\n",
    "import matplotlib.pyplot as plt         \n",
    "from datetime import date               #Used for datafiles\n",
    "import tensorflow as tf\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#Some GPU configuration\n",
    "#Always uses the 1st GPU avalible (if avalible) unless 1st line is uncommented, in which case no GPU is used\n",
    "\n",
    "#tf.config.set_visible_devices([], 'GPU') #uncomment to set tensorflow to use CPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) != 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "Phi = tf.keras.models.load_model('../Autoencoder/Autoencoder_Trials/models/trial12e300Phi.h5')\n",
    "Phi_inv = tf.keras.models.load_model('../Autoencoder/Autoencoder_Trials/models/trial12e300Phi_inv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_phi(states):\n",
    "    theta = np.math.atan2(states[1],states[0]) - np.math.atan2(states[3],states[2])\n",
    "    r = np.sqrt(states[0]*states[0]+states[1]*states[1])\n",
    "    return np.array([r, theta])\n",
    "\n",
    "def ideal_phi_inv(compressed):\n",
    "    r, theta = compressed[0], compressed[1]\n",
    "    \n",
    "    alpha = r*np.cos(theta)\n",
    "    beta = r*np.sin(theta)\n",
    "    gamma = np.sqrt(1-r*r)\n",
    "    delta = 0.\n",
    "    return np.array([alpha, beta, gamma, delta])\n",
    "\n",
    "def get_relative_phase(vector):\n",
    "    '''Returns the relative phase between\n",
    "    the two complex components of a two\n",
    "    complex dimensional vector\n",
    "    Assumes the vector is passed in as a \n",
    "    four dimensional real row vector of form\n",
    "    [real1, imag1, real2, imag2]\n",
    "    '''\n",
    "    \n",
    "\n",
    "    #Tensorflow likes to return a list of a single\n",
    "    #element sometimes, which breaks this function\n",
    "    #This does not happen during training, only when\n",
    "    #manually run on a single vector\n",
    "    if vector.shape == (4,):\n",
    "        return tf.atan2(vector[1], vector[0])%np.pi - tf.atan2(vector[3], vector[2])%np.pi\n",
    "\n",
    "    return tf.atan2(vector[:,1],vector[:,0])%np.pi - tf.atan2(vector[:,3],vector[:,2])%np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=Phi.layers[-1].output_shape[-1])\n",
    "\n",
    "nonlinear_layer_1 = tf.keras.layers.Dense(8, activation='selu', name='nonlinear_layer_1')(inputs)\n",
    "nonlinear_layer_2 = tf.keras.layers.Dense(16, activation='selu', name='nonlinear_layer_2')(nonlinear_layer_1)\n",
    "nonlinear_layer_3 = tf.keras.layers.Dense(32, activation='selu', name='nonlinear_layer_3')(nonlinear_layer_2)\n",
    "nonlinear_layer_4 = tf.keras.layers.Dense(16, activation='selu', name='nonlinear_layer_4')(nonlinear_layer_3)\n",
    "nonlinear_layer_5 = tf.keras.layers.Dense(8, activation='selu', name='nonlinear_layer_5')(nonlinear_layer_4)\n",
    "evolved = tf.keras.layers.Dense(Phi.layers[-1].output_shape[-1], activation='selu', name='evolved_state_layer')(nonlinear_layer_5)\n",
    "\n",
    "NonlinearEvolution = tf.keras.Model(inputs=inputs, outputs=evolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.44368029  0.01221893  0.76786864 -0.46192668]\n",
      "[0.44384851 0.56910604]\n",
      "[0.37389047 0.23918073 0.89610183 0.        ]\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "x1, y1, x2, y2 = np.random.uniform(low=-1, high=1, size=4)\n",
    "norm = np.sqrt(x1*x1+x2*x2+y1*y1+y2*y2)\n",
    "state = 1/norm * np.array([x1,y1, x2,y2])\n",
    "print(state)\n",
    "print(ideal_phi(state))\n",
    "print(ideal_phi_inv(ideal_phi(state)))\n",
    "print(get_relative_phase(state) - get_relative_phase(ideal_phi_inv(ideal_phi(state))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
